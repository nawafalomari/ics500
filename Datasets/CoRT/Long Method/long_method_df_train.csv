Code,Smelly
" public void badPattern ( ) { oidMarshaller . unmarshal ( ""xxx"" , RootOid . class ) ; }",No
 private static < S extends org . apache . thrift . scheme . IScheme > S scheme ( org . apache . thrift . protocol . TProtocol proto ) { return ( org . apache . thrift . scheme . StandardScheme . class . equals ( proto . getScheme ( ) ) ? STANDARD_SCHEME_FACTORY : TUPLE_SCHEME_FACTORY ) . getScheme ( ) ; },Smelly
" public T next ( ) { try { representativeWritable . readFields ( extendedDataInput ) ; } catch ( IOException e ) { throw new IllegalStateException ( ""next: readFields got IOException"" , e ) ; } return representativeWritable ; }",No
" public void looseMarshal ( OpenWireFormat wireFormat , Object o , DataOutput dataOut ) throws IOException { Message info = ( Message ) o ; info . beforeMarshall ( wireFormat ) ; super . looseMarshal ( wireFormat , o , dataOut ) ; looseMarshalCachedObject ( wireFormat , ( DataStructure ) info . getProducerId ( ) , dataOut ) ; looseMarshalCachedObject ( wireFormat , ( DataStructure ) info . getDestination ( ) , dataOut ) ; looseMarshalCachedObject ( wireFormat , ( DataStructure ) info . getTransactionId ( ) , dataOut ) ; looseMarshalCachedObject ( wireFormat , ( DataStructure ) info . getOriginalDestination ( ) , dataOut ) ; looseMarshalNestedObject ( wireFormat , ( DataStructure ) info . getMessageId ( ) , dataOut ) ; looseMarshalCachedObject ( wireFormat , ( DataStructure ) info . getOriginalTransactionId ( ) , dataOut ) ; looseMarshalString ( info . getGroupID ( ) , dataOut ) ; dataOut . writeInt ( info . getGroupSequence ( ) ) ; looseMarshalString ( info . getCorrelationId ( ) , dataOut ) ; dataOut . writeBoolean ( info . isPersistent ( ) ) ; looseMarshalLong ( wireFormat , info . getExpiration ( ) , dataOut ) ; dataOut . writeByte ( info . getPriority ( ) ) ; looseMarshalNestedObject ( wireFormat , ( DataStructure ) info . getReplyTo ( ) , dataOut ) ; looseMarshalLong ( wireFormat , info . getTimestamp ( ) , dataOut ) ; looseMarshalString ( info . getType ( ) , dataOut ) ; looseMarshalByteSequence ( wireFormat , info . getContent ( ) , dataOut ) ; looseMarshalByteSequence ( wireFormat , info . getMarshalledProperties ( ) , dataOut ) ; looseMarshalNestedObject ( wireFormat , ( DataStructure ) info . getDataStructure ( ) , dataOut ) ; looseMarshalCachedObject ( wireFormat , ( DataStructure ) info . getTargetConsumerId ( ) , dataOut ) ; dataOut . writeBoolean ( info . isCompressed ( ) ) ; dataOut . writeInt ( info . getRedeliveryCounter ( ) ) ; looseMarshalObjectArray ( wireFormat , info . getBrokerPath ( ) , dataOut ) ; looseMarshalLong ( wireFormat , info . getArrival ( ) , dataOut ) ; looseMarshalString ( info . getUserID ( ) , dataOut ) ; dataOut . writeBoolean ( info . isRecievedByDFBridge ( ) ) ; dataOut . writeBoolean ( info . isDroppable ( ) ) ; looseMarshalObjectArray ( wireFormat , info . getCluster ( ) , dataOut ) ; looseMarshalLong ( wireFormat , info . getBrokerInTime ( ) , dataOut ) ; looseMarshalLong ( wireFormat , info . getBrokerOutTime ( ) , dataOut ) ; }",Smelly
 private static < S extends org . apache . thrift . scheme . IScheme > S scheme ( org . apache . thrift . protocol . TProtocol proto ) { return ( org . apache . thrift . scheme . StandardScheme . class . equals ( proto . getScheme ( ) ) ? STANDARD_SCHEME_FACTORY : TUPLE_SCHEME_FACTORY ) . getScheme ( ) ; },Smelly
 public int doubleIt ( int numberToDouble ) { return numberToDouble * 2 ; },No
" public void read ( org . apache . thrift . protocol . TProtocol prot , getChildDataProducts_result struct ) throws org . apache . thrift . TException { TTupleProtocol iprot = ( TTupleProtocol ) prot ; BitSet incoming = iprot . readBitSet ( 5 ) ; if ( incoming . get ( 0 ) ) { { org . apache . thrift . protocol . TList _list283 = new org . apache . thrift . protocol . TList ( org . apache . thrift . protocol . TType . STRUCT , iprot . readI32 ( ) ) ; struct . success = new ArrayList < org . apache . airavata . model . data . replica . DataProductModel > ( _list283 . size ) ; org . apache . airavata . model . data . replica . DataProductModel _elem284 ; for ( int _i285 = 0 ; _i285 < _list283 . size ; ++ _i285 ) { _elem284 = new org . apache . airavata . model . data . replica . DataProductModel ( ) ; _elem284 . read ( iprot ) ; struct . success . add ( _elem284 ) ; } } struct . setSuccessIsSet ( true ) ; } if ( incoming . get ( 1 ) ) { struct . ire = new org . apache . airavata . model . error . InvalidRequestException ( ) ; struct . ire . read ( iprot ) ; struct . setIreIsSet ( true ) ; } if ( incoming . get ( 2 ) ) { struct . ace = new org . apache . airavata . model . error . AiravataClientException ( ) ; struct . ace . read ( iprot ) ; struct . setAceIsSet ( true ) ; } if ( incoming . get ( 3 ) ) { struct . ase = new org . apache . airavata . model . error . AiravataSystemException ( ) ; struct . ase . read ( iprot ) ; struct . setAseIsSet ( true ) ; } if ( incoming . get ( 4 ) ) { struct . ae = new org . apache . airavata . model . error . AuthorizationException ( ) ; struct . ae . read ( iprot ) ; struct . setAeIsSet ( true ) ; } }",Smelly
 public boolean isWhitespace ( char character ) { return Character . isWhitespace ( character ) ; },No
" public void process ( final K key , final Change < V > change ) { final long [ ] currentHash = change . newValue == null ? null : Murmur3 . hash128 ( valueSerializer . serialize ( repartitionTopicName , change . newValue ) ) ; if ( change . oldValue != null ) { final KO oldForeignKey = foreignKeyExtractor . apply ( change . oldValue ) ; if ( oldForeignKey == null ) { LOG . warn ( ""Skipping record due to null foreign key. value=[{}] topic=[{}] partition=[{}] offset=[{}]"" , change . oldValue , context ( ) . topic ( ) , context ( ) . partition ( ) , context ( ) . offset ( ) ) ; skippedRecordsSensor . record ( ) ; return ; } if ( change . newValue != null ) { final KO newForeignKey = foreignKeyExtractor . apply ( change . newValue ) ; if ( newForeignKey == null ) { LOG . warn ( ""Skipping record due to null foreign key. value=[{}] topic=[{}] partition=[{}] offset=[{}]"" , change . newValue , context ( ) . topic ( ) , context ( ) . partition ( ) , context ( ) . offset ( ) ) ; skippedRecordsSensor . record ( ) ; return ; } final byte [ ] serialOldForeignKey = foreignKeySerializer . serialize ( repartitionTopicName , oldForeignKey ) ; final byte [ ] serialNewForeignKey = foreignKeySerializer . serialize ( repartitionTopicName , newForeignKey ) ; if ( ! Arrays . equals ( serialNewForeignKey , serialOldForeignKey ) ) { context ( ) . forward ( oldForeignKey , new SubscriptionWrapper < > ( currentHash , DELETE_KEY_NO_PROPAGATE , key ) ) ; } context ( ) . forward ( newForeignKey , new SubscriptionWrapper < > ( currentHash , PROPAGATE_NULL_IF_NO_FK_VAL_AVAILABLE , key ) ) ; } else { context ( ) . forward ( oldForeignKey , new SubscriptionWrapper < > ( currentHash , DELETE_KEY_AND_PROPAGATE , key ) ) ; } } else if ( change . newValue != null ) { final SubscriptionWrapper . Instruction instruction ; if ( leftJoin ) { instruction = PROPAGATE_NULL_IF_NO_FK_VAL_AVAILABLE ; } else { instruction = PROPAGATE_ONLY_IF_FK_VAL_AVAILABLE ; } final KO newForeignKey = foreignKeyExtractor . apply ( change . newValue ) ; if ( newForeignKey == null ) { LOG . warn ( ""Skipping record due to null foreign key. value=[{}] topic=[{}] partition=[{}] offset=[{}]"" , change . newValue , context ( ) . topic ( ) , context ( ) . partition ( ) , context ( ) . offset ( ) ) ; skippedRecordsSensor . record ( ) ; } else { context ( ) . forward ( newForeignKey , new SubscriptionWrapper < > ( currentHash , instruction , key ) ) ; } } }",Smelly
 public Set < String > getLeafTaskHosts ( ) { return leafTaskHosts ; },No
 private static < S extends org . apache . thrift . scheme . IScheme > S scheme ( org . apache . thrift . protocol . TProtocol proto ) { return ( org . apache . thrift . scheme . StandardScheme . class . equals ( proto . getScheme ( ) ) ? STANDARD_SCHEME_FACTORY : TUPLE_SCHEME_FACTORY ) . getScheme ( ) ; },Smelly
" public static void main ( String [ ] args ) throws Exception { ManualComparisonOpts opts = new ManualComparisonOpts ( ) ; opts . parseArgs ( ""ManualComparison"" , args ) ; Connector conn = opts . getConnector ( ) ; Scanner s1 = conn . createScanner ( opts . table1 , Authorizations . EMPTY ) , s2 = conn . createScanner ( opts . table2 , Authorizations . EMPTY ) ; Iterator < Entry < Key , Value > > iter1 = s1 . iterator ( ) , iter2 = s2 . iterator ( ) ; boolean incrementFirst = true , incrementSecond = true ; Entry < Key , Value > entry1 = iter1 . next ( ) , entry2 = iter2 . next ( ) ; while ( iter1 . hasNext ( ) && iter2 . hasNext ( ) ) { if ( incrementFirst ) { entry1 = iter1 . next ( ) ; } if ( incrementSecond ) { entry2 = iter2 . next ( ) ; } incrementFirst = false ; incrementSecond = false ; if ( ! entry1 . equals ( entry2 ) ) { if ( entry1 . getKey ( ) . compareTo ( entry2 . getKey ( ) ) < 0 ) { System . out . println ( ""Exist in original "" + entry1 ) ; incrementFirst = true ; } else if ( entry2 . getKey ( ) . compareTo ( entry1 . getKey ( ) ) < 0 ) { System . out . println ( ""Exist in replica "" + entry2 ) ; incrementSecond = true ; } else { System . out . println ( ""Differ... "" + entry1 + "" "" + entry2 ) ; incrementFirst = true ; incrementSecond = true ; } } else { incrementFirst = true ; incrementSecond = true ; } } System . out . println ( ""\nExtra entries from "" + opts . table1 ) ; while ( iter1 . hasNext ( ) ) { System . out . println ( iter1 . next ( ) ) ; } System . out . println ( ""\nExtra entries from "" + opts . table2 ) ; while ( iter2 . hasNext ( ) ) { System . out . println ( iter2 . next ( ) ) ; } }",Smelly
 public void addTile ( Tile tile ) { this . tile = tile ; },No
" public void looseMarshal ( OpenWireFormat wireFormat , Object o , DataOutput dataOut ) throws IOException { ControlCommand info = ( ControlCommand ) o ; super . looseMarshal ( wireFormat , o , dataOut ) ; looseMarshalString ( info . getCommand ( ) , dataOut ) ; }",No
" public void read ( org . apache . thrift . protocol . TProtocol prot , show_compact_result struct ) throws org . apache . thrift . TException { TTupleProtocol iprot = ( TTupleProtocol ) prot ; BitSet incoming = iprot . readBitSet ( 1 ) ; if ( incoming . get ( 0 ) ) { struct . success = new ShowCompactResponse ( ) ; struct . success . read ( iprot ) ; struct . setSuccessIsSet ( true ) ; } }",No
 private static < S extends org . apache . thrift . scheme . IScheme > S scheme ( org . apache . thrift . protocol . TProtocol proto ) { return ( org . apache . thrift . scheme . StandardScheme . class . equals ( proto . getScheme ( ) ) ? STANDARD_SCHEME_FACTORY : TUPLE_SCHEME_FACTORY ) . getScheme ( ) ; },Smelly
 protected Locale getLocale ( ) { return Locale . FRENCH ; },No
" public void read ( org . apache . thrift . protocol . TProtocol prot , UserProfile struct ) throws org . apache . thrift . TException { TTupleProtocol iprot = ( TTupleProtocol ) prot ; struct . userModelVersion = iprot . readString ( ) ; struct . setUserModelVersionIsSet ( true ) ; struct . airavataInternalUserId = iprot . readString ( ) ; struct . setAiravataInternalUserIdIsSet ( true ) ; struct . userId = iprot . readString ( ) ; struct . setUserIdIsSet ( true ) ; { org . apache . thrift . protocol . TList _list44 = new org . apache . thrift . protocol . TList ( org . apache . thrift . protocol . TType . STRING , iprot . readI32 ( ) ) ; struct . emails = new ArrayList < String > ( _list44 . size ) ; String _elem45 ; for ( int _i46 = 0 ; _i46 < _list44 . size ; ++ _i46 ) { _elem45 = iprot . readString ( ) ; struct . emails . add ( _elem45 ) ; } } struct . setEmailsIsSet ( true ) ; struct . creationTime = iprot . readString ( ) ; struct . setCreationTimeIsSet ( true ) ; struct . lastAccessTime = iprot . readString ( ) ; struct . setLastAccessTimeIsSet ( true ) ; struct . validUntil = iprot . readString ( ) ; struct . setValidUntilIsSet ( true ) ; struct . State = org . apache . airavata . model . user . Status . findByValue ( iprot . readI32 ( ) ) ; struct . setStateIsSet ( true ) ; BitSet incoming = iprot . readBitSet ( 12 ) ; if ( incoming . get ( 0 ) ) { struct . userName = iprot . readString ( ) ; struct . setUserNameIsSet ( true ) ; } if ( incoming . get ( 1 ) ) { struct . orcidId = iprot . readString ( ) ; struct . setOrcidIdIsSet ( true ) ; } if ( incoming . get ( 2 ) ) { { org . apache . thrift . protocol . TList _list47 = new org . apache . thrift . protocol . TList ( org . apache . thrift . protocol . TType . STRING , iprot . readI32 ( ) ) ; struct . phones = new ArrayList < String > ( _list47 . size ) ; String _elem48 ; for ( int _i49 = 0 ; _i49 < _list47 . size ; ++ _i49 ) { _elem48 = iprot . readString ( ) ; struct . phones . add ( _elem48 ) ; } } struct . setPhonesIsSet ( true ) ; } if ( incoming . get ( 3 ) ) { struct . country = iprot . readString ( ) ; struct . setCountryIsSet ( true ) ; } if ( incoming . get ( 4 ) ) { { org . apache . thrift . protocol . TList _list50 = new org . apache . thrift . protocol . TList ( org . apache . thrift . protocol . TType . STRING , iprot . readI32 ( ) ) ; struct . nationality = new ArrayList < String > ( _list50 . size ) ; String _elem51 ; for ( int _i52 = 0 ; _i52 < _list50 . size ; ++ _i52 ) { _elem51 = iprot . readString ( ) ; struct . nationality . add ( _elem51 ) ; } } struct . setNationalityIsSet ( true ) ; } if ( incoming . get ( 5 ) ) { struct . homeOrganization = iprot . readString ( ) ; struct . setHomeOrganizationIsSet ( true ) ; } if ( incoming . get ( 6 ) ) { struct . orginationAffiliation = iprot . readString ( ) ; struct . setOrginationAffiliationIsSet ( true ) ; } if ( incoming . get ( 7 ) ) { struct . comments = iprot . readString ( ) ; struct . setCommentsIsSet ( true ) ; } if ( incoming . get ( 8 ) ) { { org . apache . thrift . protocol . TList _list53 = new org . apache . thrift . protocol . TList ( org . apache . thrift . protocol . TType . STRING , iprot . readI32 ( ) ) ; struct . labeledURI = new ArrayList < String > ( _list53 . size ) ; String _elem54 ; for ( int _i55 = 0 ; _i55 < _list53 . size ; ++ _i55 ) { _elem54 = iprot . readString ( ) ; struct . labeledURI . add ( _elem54 ) ; } } struct . setLabeledURIIsSet ( true ) ; } if ( incoming . get ( 9 ) ) { struct . gpgKey = iprot . readString ( ) ; struct . setGpgKeyIsSet ( true ) ; } if ( incoming . get ( 10 ) ) { struct . timeZone = iprot . readString ( ) ; struct . setTimeZoneIsSet ( true ) ; } if ( incoming . get ( 11 ) ) { struct . nsfDemographics = new NSFDemographics ( ) ; struct . nsfDemographics . read ( iprot ) ; struct . setNsfDemographicsIsSet ( true ) ; } }",Smelly
 public void setWriteListener ( WriteListener writeListener ) { throw new UnsupportedOperationException ( ) ; },No
" public void testBigIntKV ( ) throws Exception { long [ ] testNumbers = { Long . MIN_VALUE + 1 , Long . MIN_VALUE + 2 , - 2L , - 1L , 0L , 1L , 2L , Long . MAX_VALUE - 1 , Long . MAX_VALUE } ; ensureTableCreated ( getUrl ( ) , ""KVBigIntValueTest"" ) ; Properties props = new Properties ( ) ; Connection conn = DriverManager . getConnection ( getUrl ( ) , props ) ; String upsert = ""UPSERT INTO KVBigIntValueTest VALUES(?,?)"" ; PreparedStatement stmt = conn . prepareStatement ( upsert ) ; for ( int i = 0 ; i < testNumbers . length ; i ++ ) { stmt . setLong ( 1 , i ) ; stmt . setLong ( 2 , testNumbers [ i ] ) ; stmt . execute ( ) ; } conn . commit ( ) ; conn . close ( ) ; String select = ""SELECT COUNT(*) from KVBigIntValueTest"" ; ResultSet rs = conn . createStatement ( ) . executeQuery ( select ) ; assertTrue ( rs . next ( ) ) ; assertEquals ( testNumbers . length , rs . getInt ( 1 ) ) ; assertFalse ( rs . next ( ) ) ; select = ""SELECT count(*) FROM KVBigIntValueTest where kv >= "" + ( Long . MIN_VALUE + 1 ) ; rs = conn . createStatement ( ) . executeQuery ( select ) ; assertTrue ( rs . next ( ) ) ; assertEquals ( testNumbers . length , rs . getInt ( 1 ) ) ; assertFalse ( rs . next ( ) ) ; select = ""SELECT kv FROM KVBigIntValueTest WHERE kv >= "" + ( Long . MIN_VALUE + 1 ) + "" GROUP BY kv ORDER BY kv ASC NULLS LAST"" ; rs = conn . createStatement ( ) . executeQuery ( select ) ; for ( int i = 0 ; i < testNumbers . length ; i ++ ) { assertTrue ( rs . next ( ) ) ; assertEquals ( testNumbers [ i ] , rs . getLong ( 1 ) ) ; } assertFalse ( rs . next ( ) ) ; select = ""SELECT count(*) FROM KVBigIntValueTest where kv <= "" + Long . MAX_VALUE ; rs = conn . createStatement ( ) . executeQuery ( select ) ; assertTrue ( rs . next ( ) ) ; assertEquals ( testNumbers . length , rs . getInt ( 1 ) ) ; assertFalse ( rs . next ( ) ) ; select = ""SELECT kv FROM KVBigIntValueTest WHERE kv <= "" + Long . MAX_VALUE + "" GROUP BY kv ORDER BY kv DESC NULLS LAST"" ; rs = conn . createStatement ( ) . executeQuery ( select ) ; for ( int i = testNumbers . length - 1 ; i >= 0 ; i -- ) { assertTrue ( rs . next ( ) ) ; assertEquals ( testNumbers [ i ] , rs . getLong ( 1 ) ) ; } assertFalse ( rs . next ( ) ) ; }",Smelly
" public void setLastEventSent ( TezEvent lastEventSent ) { writeLock . lock ( ) ; try { if ( ! EnumSet . of ( TaskAttemptStateInternal . FAIL_IN_PROGRESS , TaskAttemptStateInternal . KILL_IN_PROGRESS , TaskAttemptStateInternal . FAILED , TaskAttemptStateInternal . KILLED , TaskAttemptStateInternal . SUCCEEDED ) . contains ( getInternalState ( ) ) ) { DataEventDependencyInfo info = new DataEventDependencyInfo ( lastEventSent . getEventReceivedTime ( ) , lastEventSent . getSourceInfo ( ) . getTaskAttemptID ( ) ) ; if ( appendNextDataEvent ) { appendNextDataEvent = false ; lastDataEvents . add ( info ) ; } else { lastDataEvents . set ( lastDataEvents . size ( ) - 1 , info ) ; } } } finally { writeLock . unlock ( ) ; } }",Smelly
 private boolean isVirtualColumn ( ColumnInfo column ) { for ( VirtualColumn vc : VirtualColumn . VIRTUAL_COLUMNS ) { if ( column . getInternalName ( ) . equals ( vc . getName ( ) ) ) { return true ; } } return false ; },Smelly
 public static void sleep ( final long duration ) { try { Thread . sleep ( duration ) ; } catch ( final Exception ignore ) { } },No
 public boolean isSingleton ( ) { return true ; },No
" private static MapOutput getMapOutputForDirectDiskFetch ( InputAttemptIdentifier srcAttemptId , Path filename , TezIndexRecord indexRecord , MergeManager merger ) throws IOException { return MapOutput . createLocalDiskMapOutput ( srcAttemptId , merger , filename , indexRecord . getStartOffset ( ) , indexRecord . getPartLength ( ) , true ) ; }",No
" public void read ( org . apache . thrift . protocol . TProtocol prot , show_compact_result struct ) throws org . apache . thrift . TException { TTupleProtocol iprot = ( TTupleProtocol ) prot ; BitSet incoming = iprot . readBitSet ( 1 ) ; if ( incoming . get ( 0 ) ) { struct . success = new ShowCompactResponse ( ) ; struct . success . read ( iprot ) ; struct . setSuccessIsSet ( true ) ; } }",Smelly
 public IFilenet make ( ) throws RemoteException { return new FilenetImpl ( ) ; },No
 public ClientConnection get ( ) throws ConfigurationException { DataChannel clientServerChannel = clientServerChannelProvider . get ( ) ; return new ProtostuffLocalConnection ( clientServerChannel ) ; },No
" public void read ( org . apache . thrift . protocol . TProtocol prot , ConditionalUpdates struct ) throws org . apache . thrift . TException { TTupleProtocol iprot = ( TTupleProtocol ) prot ; BitSet incoming = iprot . readBitSet ( 2 ) ; if ( incoming . get ( 0 ) ) { { org . apache . thrift . protocol . TList _list100 = new org . apache . thrift . protocol . TList ( org . apache . thrift . protocol . TType . STRUCT , iprot . readI32 ( ) ) ; struct . conditions = new ArrayList < Condition > ( _list100 . size ) ; for ( int _i101 = 0 ; _i101 < _list100 . size ; ++ _i101 ) { Condition _elem102 ; _elem102 = new Condition ( ) ; _elem102 . read ( iprot ) ; struct . conditions . add ( _elem102 ) ; } } struct . setConditionsIsSet ( true ) ; } if ( incoming . get ( 1 ) ) { { org . apache . thrift . protocol . TList _list103 = new org . apache . thrift . protocol . TList ( org . apache . thrift . protocol . TType . STRUCT , iprot . readI32 ( ) ) ; struct . updates = new ArrayList < ColumnUpdate > ( _list103 . size ) ; for ( int _i104 = 0 ; _i104 < _list103 . size ; ++ _i104 ) { ColumnUpdate _elem105 ; _elem105 = new ColumnUpdate ( ) ; _elem105 . read ( iprot ) ; struct . updates . add ( _elem105 ) ; } } struct . setUpdatesIsSet ( true ) ; } }",Smelly
 public void setProcessors ( Set < ProcessorEntity > processors ) { this . processors = processors ; },No
" public void handle ( LdapSession ldapSession , BindResponse bindResponse ) throws Exception { LOG . debug ( ""Message Sent : {}"" , bindResponse ) ; }",No
" public RelNode visit ( RelNode relNode ) { if ( relNode instanceof Aggregate ) { final Aggregate agg = ( Aggregate ) relNode ; return relBuilder . push ( visit ( agg . getInput ( ) ) ) . aggregate ( relBuilder . groupKey ( agg . getGroupSet ( ) , agg . groupSets ) , agg . getAggCallList ( ) ) . build ( ) ; } if ( relNode instanceof TableScan ) { return visit ( ( TableScan ) relNode ) ; } if ( relNode instanceof Filter ) { final Filter filter = ( Filter ) relNode ; return relBuilder . push ( visit ( filter . getInput ( ) ) ) . filter ( filter . getCondition ( ) ) . build ( ) ; } if ( relNode instanceof Project ) { final Project project = ( Project ) relNode ; return relBuilder . push ( visit ( project . getInput ( ) ) ) . project ( project . getProjects ( ) , project . getRowType ( ) . getFieldNames ( ) ) . build ( ) ; } if ( relNode instanceof Union ) { final Union union = ( Union ) relNode ; for ( RelNode rel : union . getInputs ( ) ) { relBuilder . push ( visit ( rel ) ) ; } return relBuilder . union ( union . all , union . getInputs ( ) . size ( ) ) . build ( ) ; } if ( relNode instanceof Join ) { final Join join = ( Join ) relNode ; return relBuilder . push ( visit ( join . getLeft ( ) ) ) . push ( visit ( join . getRight ( ) ) ) . join ( join . getJoinType ( ) , join . getCondition ( ) ) . build ( ) ; } if ( relNode instanceof Correlate ) { final Correlate corr = ( Correlate ) relNode ; return relBuilder . push ( visit ( corr . getLeft ( ) ) ) . push ( visit ( corr . getRight ( ) ) ) . join ( corr . getJoinType ( ) , relBuilder . literal ( true ) , corr . getVariablesSet ( ) ) . build ( ) ; } if ( relNode instanceof Values ) { final Values values = ( Values ) relNode ; return relBuilder . values ( values . tuples , values . getRowType ( ) ) . build ( ) ; } if ( relNode instanceof Sort ) { final Sort sort = ( Sort ) relNode ; return LogicalSort . create ( visit ( sort . getInput ( ) ) , sort . getCollation ( ) , sort . offset , sort . fetch ) ; } if ( relNode instanceof Window ) { final Window window = ( Window ) relNode ; final RelNode input = visit ( window . getInput ( ) ) ; return LogicalWindow . create ( input . getTraitSet ( ) , input , window . constants , window . getRowType ( ) , window . groups ) ; } if ( relNode instanceof Calc ) { final Calc calc = ( Calc ) relNode ; return LogicalCalc . create ( visit ( calc . getInput ( ) ) , calc . getProgram ( ) ) ; } if ( relNode instanceof EnumerableInterpreter || relNode instanceof JdbcToEnumerableConverter ) { return visit ( ( ( SingleRel ) relNode ) . getInput ( ) ) ; } if ( relNode instanceof EnumerableLimit ) { final EnumerableLimit limit = ( EnumerableLimit ) relNode ; RelNode logicalInput = visit ( limit . getInput ( ) ) ; RelCollation collation = RelCollations . of ( ) ; if ( logicalInput instanceof Sort ) { collation = ( ( Sort ) logicalInput ) . collation ; logicalInput = ( ( Sort ) logicalInput ) . getInput ( ) ; } return LogicalSort . create ( logicalInput , collation , limit . offset , limit . fetch ) ; } if ( relNode instanceof Uncollect ) { final Uncollect uncollect = ( Uncollect ) relNode ; final RelNode input = visit ( uncollect . getInput ( ) ) ; return new Uncollect ( input . getCluster ( ) , input . getTraitSet ( ) , input , uncollect . withOrdinality ) ; } throw new AssertionError ( ""Need to implement logical converter for "" + relNode . getClass ( ) . getName ( ) ) ; }",Smelly
 public String getNextId ( Entry entry ) throws Exception { return UUID . randomUUID ( ) . toString ( ) ; },No
" public void foo ( Integer a ) { throw new RuntimeException ( ""Intentional"" ) ; }",No
" protected void closeStream ( ) throws ManifoldCFException { try { stream . close ( ) ; stream = null ; } catch ( InterruptedIOException e ) { throw new ManifoldCFException ( ""Interrupted: "" + e . getMessage ( ) , e , ManifoldCFException . INTERRUPTED ) ; } catch ( IOException e ) { throw new ManifoldCFException ( ""IO exception closing stream: "" + e . getMessage ( ) , e , ManifoldCFException . GENERAL_ERROR ) ; } }",No
" private static boolean unionEquiv ( Schema w , Schema r , Map < SeenPair , Boolean > seen ) { Schema . Type wt = w . getType ( ) ; if ( wt != r . getType ( ) ) return false ; if ( ( wt == Schema . Type . RECORD || wt == Schema . Type . FIXED || wt == Schema . Type . ENUM ) && ! ( w . getName ( ) == null || w . getName ( ) . equals ( r . getName ( ) ) ) ) return false ; switch ( w . getType ( ) ) { case NULL : case BOOLEAN : case INT : case LONG : case FLOAT : case DOUBLE : case STRING : case BYTES : return true ; case ARRAY : return unionEquiv ( w . getElementType ( ) , r . getElementType ( ) , seen ) ; case MAP : return unionEquiv ( w . getValueType ( ) , r . getValueType ( ) , seen ) ; case FIXED : return w . getFixedSize ( ) == r . getFixedSize ( ) ; case ENUM : { List < String > ws = w . getEnumSymbols ( ) ; List < String > rs = r . getEnumSymbols ( ) ; if ( ws . size ( ) != rs . size ( ) ) return false ; int i = 0 ; for ( i = 0 ; i < ws . size ( ) ; i ++ ) if ( ! ws . get ( i ) . equals ( rs . get ( i ) ) ) break ; return i == ws . size ( ) ; } case UNION : { List < Schema > wb = w . getTypes ( ) ; List < Schema > rb = r . getTypes ( ) ; if ( wb . size ( ) != rb . size ( ) ) return false ; int i = 0 ; for ( i = 0 ; i < wb . size ( ) ; i ++ ) if ( ! unionEquiv ( wb . get ( i ) , rb . get ( i ) , seen ) ) break ; return i == wb . size ( ) ; } case RECORD : { SeenPair wsc = new SeenPair ( w , r ) ; if ( ! seen . containsKey ( wsc ) ) { seen . put ( wsc , true ) ; List < Field > wb = w . getFields ( ) ; List < Field > rb = r . getFields ( ) ; if ( wb . size ( ) != rb . size ( ) ) seen . put ( wsc , false ) ; else { int i = 0 ; for ( i = 0 ; i < wb . size ( ) ; i ++ ) if ( ! unionEquiv ( wb . get ( i ) . schema ( ) , rb . get ( i ) . schema ( ) , seen ) ) break ; seen . put ( wsc , ( i == wb . size ( ) ) ) ; } } return seen . get ( wsc ) ; } default : throw new IllegalArgumentException ( ""Unknown schema type: "" + w . getType ( ) ) ; } }",Smelly
" public void onMessage ( MessageContext message ) { if ( message . getType ( ) . equals ( MessageType . PROCESS ) ) { try { ProcessStatusChangeEvent processStatusChangeEvent = new ProcessStatusChangeEvent ( ) ; TBase event = message . getEvent ( ) ; byte [ ] bytes = ThriftUtils . serializeThriftObject ( event ) ; ThriftUtils . createThriftFromBytes ( bytes , processStatusChangeEvent ) ; ExperimentStatus status = new ExperimentStatus ( ) ; ProcessIdentifier processIdentity = processStatusChangeEvent . getProcessIdentity ( ) ; log . info ( ""expId: {}, processId: {} :- Process status changed event received for status {}"" , processIdentity . getExperimentId ( ) , processIdentity . getProcessId ( ) , processStatusChangeEvent . getState ( ) . name ( ) ) ; switch ( processStatusChangeEvent . getState ( ) ) { case STARTED : try { ExperimentStatus stat = OrchestratorUtils . getExperimentStatus ( processIdentity . getExperimentId ( ) ) ; if ( stat . getState ( ) == ExperimentState . CANCELING ) { status . setState ( ExperimentState . CANCELING ) ; status . setReason ( ""Process started but experiment cancelling is triggered"" ) ; } else { status . setState ( ExperimentState . EXECUTING ) ; status . setReason ( ""process  started"" ) ; } } catch ( RegistryException e ) { status . setState ( ExperimentState . EXECUTING ) ; status . setReason ( ""process  started"" ) ; } break ; case COMPLETED : try { ExperimentStatus stat = OrchestratorUtils . getExperimentStatus ( processIdentity . getExperimentId ( ) ) ; if ( stat . getState ( ) == ExperimentState . CANCELING ) { status . setState ( ExperimentState . CANCELED ) ; status . setReason ( ""Process competed but experiment cancelling is triggered"" ) ; } else { status . setState ( ExperimentState . COMPLETED ) ; status . setReason ( ""process  completed"" ) ; } } catch ( RegistryException e ) { status . setState ( ExperimentState . COMPLETED ) ; status . setReason ( ""process  completed"" ) ; } break ; case FAILED : try { ExperimentStatus stat = OrchestratorUtils . getExperimentStatus ( processIdentity . getExperimentId ( ) ) ; if ( stat . getState ( ) == ExperimentState . CANCELING ) { status . setState ( ExperimentState . CANCELED ) ; status . setReason ( ""Process failed but experiment cancelling is triggered"" ) ; } else { status . setState ( ExperimentState . FAILED ) ; status . setReason ( ""process  failed"" ) ; } } catch ( RegistryException e ) { status . setState ( ExperimentState . FAILED ) ; status . setReason ( ""process  failed"" ) ; } break ; case CANCELED : status . setState ( ExperimentState . CANCELED ) ; status . setReason ( ""process  cancelled"" ) ; break ; default : return ; } if ( status . getState ( ) != null ) { status . setTimeOfStateChange ( AiravataUtils . getCurrentTimestamp ( ) . getTime ( ) ) ; OrchestratorUtils . updageAndPublishExperimentStatus ( processIdentity . getExperimentId ( ) , status , publisher , processIdentity . getGatewayId ( ) ) ; log . info ( ""expId : "" + processIdentity . getExperimentId ( ) + "" :- Experiment status updated to "" + status . getState ( ) ) ; } } catch ( TException e ) { log . error ( ""Message Id : "" + message . getMessageId ( ) + "", Message type : "" + message . getType ( ) + ""Error"" + "" while prcessing process status change event"" ) ; } } else { System . out . println ( ""Message Recieved with message id "" + message . getMessageId ( ) + "" and with message "" + ""type "" + message . getType ( ) . name ( ) ) ; } }",Smelly
" public void read ( org . apache . thrift . protocol . TProtocol prot , getFollowing_result struct ) throws org . apache . thrift . TException { TTupleProtocol iprot = ( TTupleProtocol ) prot ; BitSet incoming = iprot . readBitSet ( 1 ) ; if ( incoming . get ( 0 ) ) { struct . success = new Key ( ) ; struct . success . read ( iprot ) ; struct . setSuccessIsSet ( true ) ; } }",No
" public void read ( org . apache . thrift . protocol . TProtocol prot , TMutation struct ) throws org . apache . thrift . TException { TTupleProtocol iprot = ( TTupleProtocol ) prot ; BitSet incoming = iprot . readBitSet ( 5 ) ; if ( incoming . get ( 0 ) ) { struct . row = iprot . readBinary ( ) ; struct . setRowIsSet ( true ) ; } if ( incoming . get ( 1 ) ) { struct . data = iprot . readBinary ( ) ; struct . setDataIsSet ( true ) ; } if ( incoming . get ( 2 ) ) { { org . apache . thrift . protocol . TList _list10 = new org . apache . thrift . protocol . TList ( org . apache . thrift . protocol . TType . STRING , iprot . readI32 ( ) ) ; struct . values = new ArrayList < ByteBuffer > ( _list10 . size ) ; for ( int _i11 = 0 ; _i11 < _list10 . size ; ++ _i11 ) { ByteBuffer _elem12 ; _elem12 = iprot . readBinary ( ) ; struct . values . add ( _elem12 ) ; } } struct . setValuesIsSet ( true ) ; } if ( incoming . get ( 3 ) ) { struct . entries = iprot . readI32 ( ) ; struct . setEntriesIsSet ( true ) ; } if ( incoming . get ( 4 ) ) { { org . apache . thrift . protocol . TList _list13 = new org . apache . thrift . protocol . TList ( org . apache . thrift . protocol . TType . STRING , iprot . readI32 ( ) ) ; struct . sources = new ArrayList < String > ( _list13 . size ) ; for ( int _i14 = 0 ; _i14 < _list13 . size ; ++ _i14 ) { String _elem15 ; _elem15 = iprot . readString ( ) ; struct . sources . add ( _elem15 ) ; } } struct . setSourcesIsSet ( true ) ; } }",Smelly
 private static < S extends org . apache . thrift . scheme . IScheme > S scheme ( org . apache . thrift . protocol . TProtocol proto ) { return ( org . apache . thrift . scheme . StandardScheme . class . equals ( proto . getScheme ( ) ) ? STANDARD_SCHEME_FACTORY : TUPLE_SCHEME_FACTORY ) . getScheme ( ) ; },Smelly
" public void read ( org . apache . thrift . protocol . TProtocol prot , getFollowing_result struct ) throws org . apache . thrift . TException { TTupleProtocol iprot = ( TTupleProtocol ) prot ; BitSet incoming = iprot . readBitSet ( 1 ) ; if ( incoming . get ( 0 ) ) { struct . success = new Key ( ) ; struct . success . read ( iprot ) ; struct . setSuccessIsSet ( true ) ; } }",Smelly
 public void tearDownAllModules ( ) { super . tearDownAllModules ( ) ; },Smelly
 public static boolean bytesToBool ( byte [ ] bytes ) { return ( ( int ) ( bytes [ 0 ] & 255 ) != 0 ) ; },No
" public void read ( org . apache . thrift . protocol . TProtocol prot , checkNamespaceClass_result struct ) throws org . apache . thrift . TException { TTupleProtocol iprot = ( TTupleProtocol ) prot ; BitSet incoming = iprot . readBitSet ( 3 ) ; if ( incoming . get ( 0 ) ) { struct . success = iprot . readBool ( ) ; struct . setSuccessIsSet ( true ) ; } if ( incoming . get ( 1 ) ) { struct . sec = new ThriftSecurityException ( ) ; struct . sec . read ( iprot ) ; struct . setSecIsSet ( true ) ; } if ( incoming . get ( 2 ) ) { struct . tope = new ThriftTableOperationException ( ) ; struct . tope . read ( iprot ) ; struct . setTopeIsSet ( true ) ; } }",Smelly
 public void waitOnLatch ( ) throws InterruptedException { if ( latch != null ) { latch . await ( ) ; } },No
 public void close ( ) throws IOException { super . close ( ) ; searchTerm = null ; field = null ; text = null ; },No
 private static < S extends org . apache . thrift . scheme . IScheme > S scheme ( org . apache . thrift . protocol . TProtocol proto ) { return ( org . apache . thrift . scheme . StandardScheme . class . equals ( proto . getScheme ( ) ) ? STANDARD_SCHEME_FACTORY : TUPLE_SCHEME_FACTORY ) . getScheme ( ) ; },Smelly
" private static Multimap < Class < ? extends RelNode > , RelNode > getNodeTypes ( RelNode rel , Class < ? extends RelNode > c , RelMetadataQuery mq ) { final Multimap < Class < ? extends RelNode > , RelNode > nodeTypeCount = ArrayListMultimap . create ( ) ; for ( RelNode input : rel . getInputs ( ) ) { Multimap < Class < ? extends RelNode > , RelNode > partialNodeTypeCount = mq . getNodeTypes ( input ) ; if ( partialNodeTypeCount == null ) { return null ; } nodeTypeCount . putAll ( partialNodeTypeCount ) ; } nodeTypeCount . put ( c , rel ) ; return nodeTypeCount ; }",No
" public void read ( org . apache . thrift . protocol . TProtocol prot , ExperimentStatusChangeEvent struct ) throws org . apache . thrift . TException { TTupleProtocol iprot = ( TTupleProtocol ) prot ; struct . state = org . apache . airavata . model . status . ExperimentState . findByValue ( iprot . readI32 ( ) ) ; struct . setStateIsSet ( true ) ; struct . experimentId = iprot . readString ( ) ; struct . setExperimentIdIsSet ( true ) ; struct . gatewayId = iprot . readString ( ) ; struct . setGatewayIdIsSet ( true ) ; }",Smelly
" private SecurityToken issueToken ( SoapMessage message , AssertionInfoMap aim , SecureConversationToken itok ) { STSClient client = STSUtils . getClient ( message , ""sct"" ) ; AddressingProperties maps = ( AddressingProperties ) message . get ( ""javax.xml.ws.addressing.context.outbound"" ) ; if ( maps == null ) { maps = ( AddressingProperties ) message . get ( ""javax.xml.ws.addressing.context"" ) ; } synchronized ( client ) { try { String s = SecureConversationTokenInterceptorProvider . setupClient ( client , message , aim , itok , false ) ; SecurityToken tok = null ; if ( maps != null ) { client . setAddressingNamespace ( maps . getNamespaceURI ( ) ) ; } tok = client . requestSecurityToken ( s ) ; String tokenType = tok . getTokenType ( ) ; tok . setTokenType ( tokenType ) ; if ( tokenType == null || """" . equals ( tokenType ) ) { tok . setTokenType ( WSConstants . WSC_SCT ) ; } return tok ; } catch ( RuntimeException e ) { throw e ; } catch ( Exception e ) { throw new Fault ( e ) ; } finally { client . setTrust ( ( Trust10 ) null ) ; client . setTrust ( ( Trust13 ) null ) ; client . setTemplate ( null ) ; client . setLocation ( null ) ; client . setAddressingNamespace ( null ) ; } } }",No
" private static URL getResourceURL ( String rsrc ) throws IOException { Enumeration < URL > urls = null ; try { ClassLoader cl = ContainerEMFTest . class . getClassLoader ( ) ; urls = AccessController . doPrivileged ( J2DoPrivHelper . getResourcesAction ( cl , rsrc ) ) ; } catch ( PrivilegedActionException pae ) { throw ( IOException ) pae . getException ( ) ; } return Collections . list ( urls ) . get ( 0 ) ; }",No
" public void read ( org . apache . thrift . protocol . TProtocol prot , ActionStats struct ) throws org . apache . thrift . TException { TTupleProtocol iprot = ( TTupleProtocol ) prot ; BitSet incoming = iprot . readBitSet ( 8 ) ; if ( incoming . get ( 0 ) ) { struct . status = iprot . readI32 ( ) ; struct . setStatusIsSet ( true ) ; } if ( incoming . get ( 1 ) ) { struct . elapsed = iprot . readDouble ( ) ; struct . setElapsedIsSet ( true ) ; } if ( incoming . get ( 2 ) ) { struct . num = iprot . readI32 ( ) ; struct . setNumIsSet ( true ) ; } if ( incoming . get ( 3 ) ) { struct . count = iprot . readI64 ( ) ; struct . setCountIsSet ( true ) ; } if ( incoming . get ( 4 ) ) { struct . sumDev = iprot . readDouble ( ) ; struct . setSumDevIsSet ( true ) ; } if ( incoming . get ( 5 ) ) { struct . fail = iprot . readI32 ( ) ; struct . setFailIsSet ( true ) ; } if ( incoming . get ( 6 ) ) { struct . queueTime = iprot . readDouble ( ) ; struct . setQueueTimeIsSet ( true ) ; } if ( incoming . get ( 7 ) ) { struct . queueSumDev = iprot . readDouble ( ) ; struct . setQueueSumDevIsSet ( true ) ; } }",Smelly
" public void read ( org . apache . thrift . protocol . TProtocol prot , TaskSubmitEvent struct ) throws org . apache . thrift . TException { TTupleProtocol iprot = ( TTupleProtocol ) prot ; struct . experimentId = iprot . readString ( ) ; struct . setExperimentIdIsSet ( true ) ; struct . taskId = iprot . readString ( ) ; struct . setTaskIdIsSet ( true ) ; struct . gatewayId = iprot . readString ( ) ; struct . setGatewayIdIsSet ( true ) ; struct . tokenId = iprot . readString ( ) ; struct . setTokenIdIsSet ( true ) ; }",Smelly
 org . apache . olingo . ext . proxy . api . Annotatable getCompanyAnnotations ( ) ;,No
" public void execute ( final String reportKey ) throws JobExecutionException { Report report = reportDAO . find ( reportKey ) ; if ( report == null ) { throw new JobExecutionException ( ""Report "" + reportKey + "" not found"" ) ; } if ( ! report . isActive ( ) ) { LOG . info ( ""Report {} not active, aborting..."" , reportKey ) ; return ; } ReportExec execution = entityFactory . newEntity ( ReportExec . class ) ; execution . setStatus ( ReportExecStatus . STARTED ) ; execution . setStart ( new Date ( ) ) ; execution . setReport ( report ) ; execution = reportExecDAO . save ( execution ) ; report . add ( execution ) ; report = reportDAO . save ( report ) ; TransformerHandler handler ; ByteArrayOutputStream baos = new ByteArrayOutputStream ( ) ; ZipOutputStream zos = new ZipOutputStream ( baos ) ; zos . setLevel ( Deflater . BEST_COMPRESSION ) ; try { SAXTransformerFactory tFactory = ( SAXTransformerFactory ) SAXTransformerFactory . newInstance ( ) ; tFactory . setFeature ( javax . xml . XMLConstants . FEATURE_SECURE_PROCESSING , true ) ; handler = tFactory . newTransformerHandler ( ) ; Transformer serializer = handler . getTransformer ( ) ; serializer . setOutputProperty ( OutputKeys . ENCODING , StandardCharsets . UTF_8 . name ( ) ) ; serializer . setOutputProperty ( OutputKeys . INDENT , ""yes"" ) ; zos . putNextEntry ( new ZipEntry ( report . getName ( ) ) ) ; handler . setResult ( new StreamResult ( zos ) ) ; } catch ( Exception e ) { throw new JobExecutionException ( ""While configuring for SAX generation"" , e , true ) ; } execution . setStatus ( ReportExecStatus . RUNNING ) ; execution = reportExecDAO . save ( execution ) ; StringBuilder reportExecutionMessage = new StringBuilder ( ) ; try { handler . startDocument ( ) ; AttributesImpl atts = new AttributesImpl ( ) ; atts . addAttribute ( """" , """" , ReportXMLConst . ATTR_NAME , ReportXMLConst . XSD_STRING , report . getName ( ) ) ; handler . startElement ( """" , """" , ReportXMLConst . ELEMENT_REPORT , atts ) ; for ( ReportletConf reportletConf : report . getReportletConfs ( ) ) { Class < ? extends Reportlet > reportletClass = implementationLookup . getReportletClass ( reportletConf . getClass ( ) ) ; if ( reportletClass == null ) { LOG . warn ( ""Could not find matching reportlet for {}"" , reportletConf . getClass ( ) ) ; } else { Reportlet reportlet ; if ( ApplicationContextProvider . getBeanFactory ( ) . containsSingleton ( reportletClass . getName ( ) ) ) { reportlet = ( Reportlet ) ApplicationContextProvider . getBeanFactory ( ) . getSingleton ( reportletClass . getName ( ) ) ; } else { reportlet = ( Reportlet ) ApplicationContextProvider . getBeanFactory ( ) . createBean ( reportletClass , AbstractBeanDefinition . AUTOWIRE_BY_TYPE , false ) ; ApplicationContextProvider . getBeanFactory ( ) . registerSingleton ( reportletClass . getName ( ) , reportlet ) ; } try { reportlet . extract ( reportletConf , handler ) ; } catch ( Throwable t ) { LOG . error ( ""While executing reportlet {} for report {}"" , reportlet , reportKey , t ) ; execution . setStatus ( ReportExecStatus . FAILURE ) ; Throwable effective = t instanceof ReportException ? t . getCause ( ) : t ; reportExecutionMessage . append ( ExceptionUtils2 . getFullStackTrace ( effective ) ) . append ( ""\n==================\n"" ) ; } } } handler . endElement ( """" , """" , ReportXMLConst . ELEMENT_REPORT ) ; handler . endDocument ( ) ; if ( ! ReportExecStatus . FAILURE . name ( ) . equals ( execution . getStatus ( ) ) ) { execution . setStatus ( ReportExecStatus . SUCCESS ) ; } } catch ( Exception e ) { execution . setStatus ( ReportExecStatus . FAILURE ) ; reportExecutionMessage . append ( ExceptionUtils2 . getFullStackTrace ( e ) ) ; throw new JobExecutionException ( e , true ) ; } finally { try { zos . closeEntry ( ) ; IOUtils . closeQuietly ( zos ) ; IOUtils . closeQuietly ( baos ) ; } catch ( IOException e ) { LOG . error ( ""While closing StreamResult's backend"" , e ) ; } execution . setExecResult ( baos . toByteArray ( ) ) ; execution . setMessage ( reportExecutionMessage . toString ( ) ) ; execution . setEnd ( new Date ( ) ) ; reportExecDAO . save ( execution ) ; } }",Smelly
" public void read ( org . apache . thrift . protocol . TProtocol prot , drainReplicationTable_result struct ) throws org . apache . thrift . TException { TTupleProtocol iprot = ( TTupleProtocol ) prot ; BitSet incoming = iprot . readBitSet ( 1 ) ; if ( incoming . get ( 0 ) ) { struct . success = iprot . readBool ( ) ; struct . setSuccessIsSet ( true ) ; } }",No
 public OutputCommitter getBaseOutputCommitter ( ) { return committer ; },No
 public int hashCode ( ) { int result = ( int ) ( eventTime ^ ( eventTime > > > 32 ) ) ; result = 31 * result + componentID . hashCode ( ) ; result = 31 * result + fileOffset . hashCode ( ) ; return result ; },No
" public void read ( org . apache . thrift . protocol . TProtocol prot , TGetTypeInfoResp struct ) throws org . apache . thrift . TException { TTupleProtocol iprot = ( TTupleProtocol ) prot ; struct . status = new TStatus ( ) ; struct . status . read ( iprot ) ; struct . setStatusIsSet ( true ) ; BitSet incoming = iprot . readBitSet ( 1 ) ; if ( incoming . get ( 0 ) ) { struct . operationHandle = new TOperationHandle ( ) ; struct . operationHandle . read ( iprot ) ; struct . setOperationHandleIsSet ( true ) ; } }",No
" protected void processMessage ( Message message , Session session ) { if ( message instanceof MimeMessage ) { MimeMessageWrapper wrapper = new MimeMessageWrapper ( session , ( MimeMessage ) message ) ; try { ServiceMcaUtil . evalRules ( dispatcher , wrapper , userLogin ) ; } catch ( GenericServiceException e ) { Debug . logError ( e , ""Problem processing message"" , module ) ; } } }",Smelly
" public void read ( org . apache . thrift . protocol . TProtocol prot , show_compact_result struct ) throws org . apache . thrift . TException { TTupleProtocol iprot = ( TTupleProtocol ) prot ; BitSet incoming = iprot . readBitSet ( 1 ) ; if ( incoming . get ( 0 ) ) { struct . success = new ShowCompactResponse ( ) ; struct . success . read ( iprot ) ; struct . setSuccessIsSet ( true ) ; } }",Smelly
" public void read ( org . apache . thrift . protocol . TProtocol prot , getChildDataProducts_result struct ) throws org . apache . thrift . TException { TTupleProtocol iprot = ( TTupleProtocol ) prot ; BitSet incoming = iprot . readBitSet ( 5 ) ; if ( incoming . get ( 0 ) ) { { org . apache . thrift . protocol . TList _list283 = new org . apache . thrift . protocol . TList ( org . apache . thrift . protocol . TType . STRUCT , iprot . readI32 ( ) ) ; struct . success = new ArrayList < org . apache . airavata . model . data . replica . DataProductModel > ( _list283 . size ) ; org . apache . airavata . model . data . replica . DataProductModel _elem284 ; for ( int _i285 = 0 ; _i285 < _list283 . size ; ++ _i285 ) { _elem284 = new org . apache . airavata . model . data . replica . DataProductModel ( ) ; _elem284 . read ( iprot ) ; struct . success . add ( _elem284 ) ; } } struct . setSuccessIsSet ( true ) ; } if ( incoming . get ( 1 ) ) { struct . ire = new org . apache . airavata . model . error . InvalidRequestException ( ) ; struct . ire . read ( iprot ) ; struct . setIreIsSet ( true ) ; } if ( incoming . get ( 2 ) ) { struct . ace = new org . apache . airavata . model . error . AiravataClientException ( ) ; struct . ace . read ( iprot ) ; struct . setAceIsSet ( true ) ; } if ( incoming . get ( 3 ) ) { struct . ase = new org . apache . airavata . model . error . AiravataSystemException ( ) ; struct . ase . read ( iprot ) ; struct . setAseIsSet ( true ) ; } if ( incoming . get ( 4 ) ) { struct . ae = new org . apache . airavata . model . error . AuthorizationException ( ) ; struct . ae . read ( iprot ) ; struct . setAeIsSet ( true ) ; } }",Smelly
" public String doIntercept ( ActionInvocation invocation ) throws Exception { if ( log . isDebugEnabled ( ) ) { log . debug ( ""Entering UISecurityInterceptor"" ) ; } final Object action = invocation . getAction ( ) ; if ( action instanceof UISecurityEnforced && action instanceof UIAction ) { if ( log . isDebugEnabled ( ) ) { log . debug ( ""action is UISecurityEnforced ... enforcing security rules"" ) ; } final UISecurityEnforced theAction = ( UISecurityEnforced ) action ; if ( theAction . isUserRequired ( ) ) { UserManager umgr = WebloggerFactory . getWeblogger ( ) . getUserManager ( ) ; User authenticatedUser = ( ( UIAction ) theAction ) . getAuthenticatedUser ( ) ; if ( authenticatedUser == null ) { if ( log . isDebugEnabled ( ) ) { log . debug ( ""DENIED: required user not found"" ) ; } return ""access-denied"" ; } if ( theAction . requiredGlobalPermissionActions ( ) != null && ! theAction . requiredGlobalPermissionActions ( ) . isEmpty ( ) ) { GlobalPermission perm = new GlobalPermission ( theAction . requiredGlobalPermissionActions ( ) ) ; if ( ! umgr . checkPermission ( perm , authenticatedUser ) ) { if ( log . isDebugEnabled ( ) ) { log . debug ( ""DENIED: user does not have permission = "" + perm . toString ( ) ) ; } return ""access-denied"" ; } } if ( theAction . isWeblogRequired ( ) ) { Weblog actionWeblog = ( ( UIAction ) theAction ) . getActionWeblog ( ) ; if ( actionWeblog == null ) { if ( log . isWarnEnabled ( ) ) { log . warn ( ""User "" + authenticatedUser . getUserName ( ) + "" unable to process action \"""" + ( ( UIAction ) theAction ) . getActionName ( ) + ""\"" because no weblog was defined (Check JSP form provides weblog value.)"" ) ; } return ""access-denied"" ; } if ( theAction . requiredWeblogPermissionActions ( ) != null && ! theAction . requiredWeblogPermissionActions ( ) . isEmpty ( ) ) { WeblogPermission required = new WeblogPermission ( actionWeblog , theAction . requiredWeblogPermissionActions ( ) ) ; if ( ! umgr . checkPermission ( required , authenticatedUser ) ) { if ( log . isDebugEnabled ( ) ) { log . debug ( ""DENIED: user does not have required weblog permissions = "" + required ) ; } return ""access-denied"" ; } } } } } return invocation . invoke ( ) ; }",Smelly
 private static < S extends org . apache . thrift . scheme . IScheme > S scheme ( org . apache . thrift . protocol . TProtocol proto ) { return ( org . apache . thrift . scheme . StandardScheme . class . equals ( proto . getScheme ( ) ) ? STANDARD_SCHEME_FACTORY : TUPLE_SCHEME_FACTORY ) . getScheme ( ) ; },No
" public void read ( org . apache . thrift . protocol . TProtocol prot , TableStatsRequest struct ) throws org . apache . thrift . TException { TTupleProtocol iprot = ( TTupleProtocol ) prot ; struct . dbName = iprot . readString ( ) ; struct . setDbNameIsSet ( true ) ; struct . tblName = iprot . readString ( ) ; struct . setTblNameIsSet ( true ) ; { org . apache . thrift . protocol . TList _list311 = new org . apache . thrift . protocol . TList ( org . apache . thrift . protocol . TType . STRING , iprot . readI32 ( ) ) ; struct . colNames = new ArrayList < String > ( _list311 . size ) ; for ( int _i312 = 0 ; _i312 < _list311 . size ; ++ _i312 ) { String _elem313 ; _elem313 = iprot . readString ( ) ; struct . colNames . add ( _elem313 ) ; } } struct . setColNamesIsSet ( true ) ; }",Smelly
" protected void setOctetString ( byte [ ] data , EncryptionKeyContainer encryptionKeyContainer ) { encryptionKeyContainer . getEncryptionKey ( ) . setKeyValue ( data ) ; encryptionKeyContainer . setGrammarEndAllowed ( true ) ; }",No
 public void testCloseSetsIsClosed ( ) { },No
 V getBaseVertex ( ) ;,No
" public static void main ( String [ ] args ) throws Exception { DateFormat dateFormat = new SimpleDateFormat ( ""yyyy-MM-dd hh:mm:ss,SSS"" ) ; Thread . setDefaultUncaughtExceptionHandler ( ( thread , exception ) -> { System . out . println ( String . format ( ""%s [%s] error Uncaught exception in thread %s: %s"" , dateFormat . format ( new Date ( ) ) , thread . getContextClassLoader ( ) , thread . getName ( ) , exception . getMessage ( ) ) ) ; } ) ; BrokerStarter starter = new BrokerStarter ( args ) ; Runtime . getRuntime ( ) . addShutdownHook ( new Thread ( ( ) -> { starter . shutdown ( ) ; } ) ) ; PulsarByteBufAllocator . registerOOMListener ( oomException -> { log . error ( ""-- Shutting down - Received OOM exception: {}"" , oomException . getMessage ( ) , oomException ) ; starter . shutdown ( ) ; } ) ; try { starter . start ( ) ; } catch ( Exception e ) { log . error ( ""Failed to start pulsar service."" , e ) ; Runtime . getRuntime ( ) . halt ( 1 ) ; } starter . join ( ) ; }",Smelly
" public void read ( org . apache . thrift . protocol . TProtocol prot , getFollowing_result struct ) throws org . apache . thrift . TException { TTupleProtocol iprot = ( TTupleProtocol ) prot ; BitSet incoming = iprot . readBitSet ( 1 ) ; if ( incoming . get ( 0 ) ) { struct . success = new Key ( ) ; struct . success . read ( iprot ) ; struct . setSuccessIsSet ( true ) ; } }",Smelly
" public void accept ( final ClassVisitor cv ) { FieldVisitor fv = cv . visitField ( access , name , desc , signature , value ) ; if ( fv == null ) { return ; } int i , n ; n = visibleAnnotations == null ? 0 : visibleAnnotations . size ( ) ; for ( i = 0 ; i < n ; ++ i ) { AnnotationNode an = visibleAnnotations . get ( i ) ; an . accept ( fv . visitAnnotation ( an . desc , true ) ) ; } n = invisibleAnnotations == null ? 0 : invisibleAnnotations . size ( ) ; for ( i = 0 ; i < n ; ++ i ) { AnnotationNode an = invisibleAnnotations . get ( i ) ; an . accept ( fv . visitAnnotation ( an . desc , false ) ) ; } n = attrs == null ? 0 : attrs . size ( ) ; for ( i = 0 ; i < n ; ++ i ) { fv . visitAttribute ( attrs . get ( i ) ) ; } fv . visitEnd ( ) ; }",No
 public abstract boolean next ( ) ;,No
" public void read ( org . apache . thrift . protocol . TProtocol prot , ApplicationInterfaceDescription struct ) throws org . apache . thrift . TException { TTupleProtocol iprot = ( TTupleProtocol ) prot ; struct . applicationInterfaceId = iprot . readString ( ) ; struct . setApplicationInterfaceIdIsSet ( true ) ; struct . applicationName = iprot . readString ( ) ; struct . setApplicationNameIsSet ( true ) ; BitSet incoming = iprot . readBitSet ( 6 ) ; if ( incoming . get ( 0 ) ) { struct . applicationDescription = iprot . readString ( ) ; struct . setApplicationDescriptionIsSet ( true ) ; } if ( incoming . get ( 1 ) ) { { org . apache . thrift . protocol . TList _list15 = new org . apache . thrift . protocol . TList ( org . apache . thrift . protocol . TType . STRING , iprot . readI32 ( ) ) ; struct . applicationModules = new ArrayList < String > ( _list15 . size ) ; String _elem16 ; for ( int _i17 = 0 ; _i17 < _list15 . size ; ++ _i17 ) { _elem16 = iprot . readString ( ) ; struct . applicationModules . add ( _elem16 ) ; } } struct . setApplicationModulesIsSet ( true ) ; } if ( incoming . get ( 2 ) ) { { org . apache . thrift . protocol . TList _list18 = new org . apache . thrift . protocol . TList ( org . apache . thrift . protocol . TType . STRUCT , iprot . readI32 ( ) ) ; struct . applicationInputs = new ArrayList < org . apache . airavata . model . application . io . InputDataObjectType > ( _list18 . size ) ; org . apache . airavata . model . application . io . InputDataObjectType _elem19 ; for ( int _i20 = 0 ; _i20 < _list18 . size ; ++ _i20 ) { _elem19 = new org . apache . airavata . model . application . io . InputDataObjectType ( ) ; _elem19 . read ( iprot ) ; struct . applicationInputs . add ( _elem19 ) ; } } struct . setApplicationInputsIsSet ( true ) ; } if ( incoming . get ( 3 ) ) { { org . apache . thrift . protocol . TList _list21 = new org . apache . thrift . protocol . TList ( org . apache . thrift . protocol . TType . STRUCT , iprot . readI32 ( ) ) ; struct . applicationOutputs = new ArrayList < org . apache . airavata . model . application . io . OutputDataObjectType > ( _list21 . size ) ; org . apache . airavata . model . application . io . OutputDataObjectType _elem22 ; for ( int _i23 = 0 ; _i23 < _list21 . size ; ++ _i23 ) { _elem22 = new org . apache . airavata . model . application . io . OutputDataObjectType ( ) ; _elem22 . read ( iprot ) ; struct . applicationOutputs . add ( _elem22 ) ; } } struct . setApplicationOutputsIsSet ( true ) ; } if ( incoming . get ( 4 ) ) { struct . archiveWorkingDirectory = iprot . readBool ( ) ; struct . setArchiveWorkingDirectoryIsSet ( true ) ; } if ( incoming . get ( 5 ) ) { struct . hasOptionalFileInputs = iprot . readBool ( ) ; struct . setHasOptionalFileInputsIsSet ( true ) ; } }",Smelly
 public Long getOutputWatermark ( ) { return null ; },No
 public void setType ( Class < ? > ctype ) { cls = ctype ; },No
" public static void main ( String [ ] args ) { String server1 , username1 , password1 , file1 ; String server2 , username2 , password2 , file2 ; String [ ] parts ; int port1 = 0 , port2 = 0 ; FTPClient ftp1 , ftp2 ; ProtocolCommandListener listener ; if ( args . length < 8 ) { System . err . println ( ""Usage: ftp <host1> <user1> <pass1> <file1> <host2> <user2> <pass2> <file2>"" ) ; System . exit ( 1 ) ; } server1 = args [ 0 ] ; parts = server1 . split ( "":"" ) ; if ( parts . length == 2 ) { server1 = parts [ 0 ] ; port1 = Integer . parseInt ( parts [ 1 ] ) ; } username1 = args [ 1 ] ; password1 = args [ 2 ] ; file1 = args [ 3 ] ; server2 = args [ 4 ] ; parts = server2 . split ( "":"" ) ; if ( parts . length == 2 ) { server2 = parts [ 0 ] ; port2 = Integer . parseInt ( parts [ 1 ] ) ; } username2 = args [ 5 ] ; password2 = args [ 6 ] ; file2 = args [ 7 ] ; listener = new PrintCommandListener ( new PrintWriter ( System . out ) , true ) ; ftp1 = new FTPClient ( ) ; ftp1 . addProtocolCommandListener ( listener ) ; ftp2 = new FTPClient ( ) ; ftp2 . addProtocolCommandListener ( listener ) ; try { int reply ; if ( port1 > 0 ) { ftp1 . connect ( server1 , port1 ) ; } else { ftp1 . connect ( server1 ) ; } System . out . println ( ""Connected to "" + server1 + ""."" ) ; reply = ftp1 . getReplyCode ( ) ; if ( ! FTPReply . isPositiveCompletion ( reply ) ) { ftp1 . disconnect ( ) ; System . err . println ( ""FTP server1 refused connection."" ) ; System . exit ( 1 ) ; } } catch ( IOException e ) { if ( ftp1 . isConnected ( ) ) { try { ftp1 . disconnect ( ) ; } catch ( IOException f ) { } } System . err . println ( ""Could not connect to server1."" ) ; e . printStackTrace ( ) ; System . exit ( 1 ) ; } try { int reply ; if ( port2 > 0 ) { ftp2 . connect ( server2 , port2 ) ; } else { ftp2 . connect ( server2 ) ; } System . out . println ( ""Connected to "" + server2 + ""."" ) ; reply = ftp2 . getReplyCode ( ) ; if ( ! FTPReply . isPositiveCompletion ( reply ) ) { ftp2 . disconnect ( ) ; System . err . println ( ""FTP server2 refused connection."" ) ; System . exit ( 1 ) ; } } catch ( IOException e ) { if ( ftp2 . isConnected ( ) ) { try { ftp2 . disconnect ( ) ; } catch ( IOException f ) { } } System . err . println ( ""Could not connect to server2."" ) ; e . printStackTrace ( ) ; System . exit ( 1 ) ; } __main : try { if ( ! ftp1 . login ( username1 , password1 ) ) { System . err . println ( ""Could not login to "" + server1 ) ; break __main ; } if ( ! ftp2 . login ( username2 , password2 ) ) { System . err . println ( ""Could not login to "" + server2 ) ; break __main ; } ftp2 . enterRemotePassiveMode ( ) ; ftp1 . enterRemoteActiveMode ( InetAddress . getByName ( ftp2 . getPassiveHost ( ) ) , ftp2 . getPassivePort ( ) ) ; if ( ftp1 . remoteRetrieve ( file1 ) && ftp2 . remoteStoreUnique ( file2 ) ) { ftp1 . completePendingCommand ( ) ; ftp2 . completePendingCommand ( ) ; } else { System . err . println ( ""Couldn't initiate transfer.  Check that filenames are valid."" ) ; break __main ; } } catch ( IOException e ) { e . printStackTrace ( ) ; System . exit ( 1 ) ; } finally { try { if ( ftp1 . isConnected ( ) ) { ftp1 . logout ( ) ; ftp1 . disconnect ( ) ; } } catch ( IOException e ) { } try { if ( ftp2 . isConnected ( ) ) { ftp2 . logout ( ) ; ftp2 . disconnect ( ) ; } } catch ( IOException e ) { } } }",Smelly
" public void clearZNodes ( String procedureName ) throws KeeperException { LOG . info ( ""Clearing all znodes for procedure "" + procedureName + ""including nodes "" + acquiredZnode + "" "" + reachedZnode + "" "" + abortZnode ) ; String acquiredBarrierNode = getAcquiredBarrierNode ( procedureName ) ; String reachedBarrierNode = getReachedBarrierNode ( procedureName ) ; String abortZNode = getAbortZNode ( procedureName ) ; ZKUtil . createAndFailSilent ( watcher , acquiredBarrierNode ) ; ZKUtil . createAndFailSilent ( watcher , abortZNode ) ; ZKUtil . deleteNodeRecursivelyMultiOrSequential ( watcher , true , acquiredBarrierNode , reachedBarrierNode , abortZNode ) ; if ( LOG . isTraceEnabled ( ) ) { logZKTree ( this . baseZNode ) ; } }",No
" public void read ( org . apache . thrift . protocol . TProtocol prot , onReceivedZeppelinResource_result struct ) throws org . apache . thrift . TException { TTupleProtocol iprot = ( TTupleProtocol ) prot ; }",Smelly
 String sayHi ( ) ;,No
 static Log getInstance ( String name ) { return new DirectJDKLog ( name ) ; },No
" public void read ( org . apache . thrift . protocol . TProtocol prot , getChildDataProducts_result struct ) throws org . apache . thrift . TException { TTupleProtocol iprot = ( TTupleProtocol ) prot ; BitSet incoming = iprot . readBitSet ( 5 ) ; if ( incoming . get ( 0 ) ) { { org . apache . thrift . protocol . TList _list283 = new org . apache . thrift . protocol . TList ( org . apache . thrift . protocol . TType . STRUCT , iprot . readI32 ( ) ) ; struct . success = new ArrayList < org . apache . airavata . model . data . replica . DataProductModel > ( _list283 . size ) ; org . apache . airavata . model . data . replica . DataProductModel _elem284 ; for ( int _i285 = 0 ; _i285 < _list283 . size ; ++ _i285 ) { _elem284 = new org . apache . airavata . model . data . replica . DataProductModel ( ) ; _elem284 . read ( iprot ) ; struct . success . add ( _elem284 ) ; } } struct . setSuccessIsSet ( true ) ; } if ( incoming . get ( 1 ) ) { struct . ire = new org . apache . airavata . model . error . InvalidRequestException ( ) ; struct . ire . read ( iprot ) ; struct . setIreIsSet ( true ) ; } if ( incoming . get ( 2 ) ) { struct . ace = new org . apache . airavata . model . error . AiravataClientException ( ) ; struct . ace . read ( iprot ) ; struct . setAceIsSet ( true ) ; } if ( incoming . get ( 3 ) ) { struct . ase = new org . apache . airavata . model . error . AiravataSystemException ( ) ; struct . ase . read ( iprot ) ; struct . setAseIsSet ( true ) ; } if ( incoming . get ( 4 ) ) { struct . ae = new org . apache . airavata . model . error . AuthorizationException ( ) ; struct . ae . read ( iprot ) ; struct . setAeIsSet ( true ) ; } }",Smelly
" public String getBeanName ( ) { return ""autocompleter"" ; }",No
" public void read ( org . apache . thrift . protocol . TProtocol prot , JobIdentifier struct ) throws org . apache . thrift . TException { TTupleProtocol iprot = ( TTupleProtocol ) prot ; struct . jobId = iprot . readString ( ) ; struct . setJobIdIsSet ( true ) ; struct . taskId = iprot . readString ( ) ; struct . setTaskIdIsSet ( true ) ; struct . processId = iprot . readString ( ) ; struct . setProcessIdIsSet ( true ) ; struct . experimentId = iprot . readString ( ) ; struct . setExperimentIdIsSet ( true ) ; struct . gatewayId = iprot . readString ( ) ; struct . setGatewayIdIsSet ( true ) ; }",Smelly
" public void test_1 ( ) throws Exception { executeTest ( MeldingPage . class , ""ExpectedResult.html"" ) ; }",No
 public void addBinary ( Binary binary ) { String str = binary . toStringUsingUTF8 ( ) ; parent . add ( str ) ; },No
" public void read ( org . apache . thrift . protocol . TProtocol prot , getChildDataProducts_result struct ) throws org . apache . thrift . TException { TTupleProtocol iprot = ( TTupleProtocol ) prot ; BitSet incoming = iprot . readBitSet ( 5 ) ; if ( incoming . get ( 0 ) ) { { org . apache . thrift . protocol . TList _list283 = new org . apache . thrift . protocol . TList ( org . apache . thrift . protocol . TType . STRUCT , iprot . readI32 ( ) ) ; struct . success = new ArrayList < org . apache . airavata . model . data . replica . DataProductModel > ( _list283 . size ) ; org . apache . airavata . model . data . replica . DataProductModel _elem284 ; for ( int _i285 = 0 ; _i285 < _list283 . size ; ++ _i285 ) { _elem284 = new org . apache . airavata . model . data . replica . DataProductModel ( ) ; _elem284 . read ( iprot ) ; struct . success . add ( _elem284 ) ; } } struct . setSuccessIsSet ( true ) ; } if ( incoming . get ( 1 ) ) { struct . ire = new org . apache . airavata . model . error . InvalidRequestException ( ) ; struct . ire . read ( iprot ) ; struct . setIreIsSet ( true ) ; } if ( incoming . get ( 2 ) ) { struct . ace = new org . apache . airavata . model . error . AiravataClientException ( ) ; struct . ace . read ( iprot ) ; struct . setAceIsSet ( true ) ; } if ( incoming . get ( 3 ) ) { struct . ase = new org . apache . airavata . model . error . AiravataSystemException ( ) ; struct . ase . read ( iprot ) ; struct . setAseIsSet ( true ) ; } if ( incoming . get ( 4 ) ) { struct . ae = new org . apache . airavata . model . error . AuthorizationException ( ) ; struct . ae . read ( iprot ) ; struct . setAeIsSet ( true ) ; } }",Smelly
" public ProcessingNode buildNode ( Configuration config ) throws Exception { return this . treeBuilder . setupNode ( new NullNode ( ) , config ) ; }",No
 private void loadContainer ( ) { if ( container == null ) { try { CsdlEntityContainer containerLocal = provider . getEntityContainer ( ) ; if ( containerLocal == null ) { containerLocal = new CsdlEntityContainer ( ) . setName ( getName ( ) ) ; } container = containerLocal ; } catch ( ODataException e ) { throw new EdmException ( e ) ; } } },No
" protected void populateObject ( Object object ) throws Exception { super . populateObject ( object ) ; ConsumerControl info = ( ConsumerControl ) object ; info . setDestination ( createActiveMQDestination ( ""Destination:1"" ) ) ; info . setClose ( true ) ; info . setConsumerId ( createConsumerId ( ""ConsumerId:2"" ) ) ; info . setPrefetch ( 1 ) ; info . setFlush ( false ) ; info . setStart ( true ) ; info . setStop ( false ) ; }",No
 public String getRelationName ( ) { return this . relationName ; },Smelly
" public void read ( org . apache . thrift . protocol . TProtocol prot , HiveClusterStatus struct ) throws org . apache . thrift . TException { TTupleProtocol iprot = ( TTupleProtocol ) prot ; BitSet incoming = iprot . readBitSet ( 6 ) ; if ( incoming . get ( 0 ) ) { struct . taskTrackers = iprot . readI32 ( ) ; struct . setTaskTrackersIsSet ( true ) ; } if ( incoming . get ( 1 ) ) { struct . mapTasks = iprot . readI32 ( ) ; struct . setMapTasksIsSet ( true ) ; } if ( incoming . get ( 2 ) ) { struct . reduceTasks = iprot . readI32 ( ) ; struct . setReduceTasksIsSet ( true ) ; } if ( incoming . get ( 3 ) ) { struct . maxMapTasks = iprot . readI32 ( ) ; struct . setMaxMapTasksIsSet ( true ) ; } if ( incoming . get ( 4 ) ) { struct . maxReduceTasks = iprot . readI32 ( ) ; struct . setMaxReduceTasksIsSet ( true ) ; } if ( incoming . get ( 5 ) ) { struct . state = JobTrackerState . findByValue ( iprot . readI32 ( ) ) ; struct . setStateIsSet ( true ) ; } }",Smelly
 public Version getPDFVersion ( ) { return pdfVersion ; },No
 protected Struct toStruct ( ) { return data . toStruct ( version ( ) ) ; },No
" private void readObject ( final ObjectInputStream in ) throws IOException , ClassNotFoundException { in . defaultReadObject ( ) ; setMap ( new HashMap < E , MutableInteger > ( ) ) ; super . doReadObject ( in ) ; }",No
" public void testCLI18 ( ) { Options options = new Options ( ) ; options . addOption ( new Option ( ""a"" , ""aaa"" , false , ""aaaaaaa"" ) ) ; options . addOption ( new Option ( null , ""bbb"" , false , ""bbbbbbb dksh fkshd fkhs dkfhsdk fhskd hksdks dhfowehfsdhfkjshf skfhkshf sf jkshfk sfh skfh skf f"" ) ) ; options . addOption ( new Option ( ""c"" , null , false , ""ccccccc"" ) ) ; HelpFormatter formatter = new HelpFormatter ( ) ; StringWriter out = new StringWriter ( ) ; formatter . printHelp ( new PrintWriter ( out ) , 80 , ""foobar"" , ""dsfkfsh kdh hsd hsdh fkshdf ksdh fskdh fsdh fkshfk sfdkjhskjh fkjh fkjsh khsdkj hfskdhf skjdfh ksf khf s"" , options , 2 , 2 , ""blort j jgj j jg jhghjghjgjhgjhg jgjhgj jhg jhg hjg jgjhghjg jhg hjg jhgjg jgjhghjg jg jgjhgjgjg jhg jhgjh"" + '\r' + '\n' + ""rarrr"" , true ) ; }",No
" public static Map < String , Object > createATPRequirementsForOrder ( DispatchContext ctx , Map < String , ? extends Object > context ) { Delegator delegator = ctx . getDelegator ( ) ; LocalDispatcher dispatcher = ctx . getDispatcher ( ) ; GenericValue userLogin = ( GenericValue ) context . get ( ""userLogin"" ) ; String orderId = ( String ) context . get ( ""orderId"" ) ; try { GenericValue order = delegator . findOne ( ""OrderHeader"" , UtilMisc . toMap ( ""orderId"" , orderId ) , false ) ; GenericValue productStore = order . getRelatedOne ( ""ProductStore"" , true ) ; if ( productStore == null ) { Debug . logInfo ( ""ProductStore for order ID "" + orderId + "" not found, ATP requirements not created"" , module ) ; return ServiceUtil . returnSuccess ( ) ; } String facilityId = productStore . getString ( ""inventoryFacilityId"" ) ; List < GenericValue > orderItems = order . getRelated ( ""OrderItem"" , null , null , false ) ; for ( GenericValue item : orderItems ) { GenericValue product = item . getRelatedOne ( ""Product"" , false ) ; if ( product == null ) continue ; if ( ! ( ""PRODRQM_ATP"" . equals ( product . get ( ""requirementMethodEnumId"" ) ) || ( ""PRODRQM_ATP"" . equals ( productStore . get ( ""requirementMethodEnumId"" ) ) && product . get ( ""requirementMethodEnumId"" ) == null ) ) ) continue ; BigDecimal quantity = item . getBigDecimal ( ""quantity"" ) ; BigDecimal cancelQuantity = item . getBigDecimal ( ""cancelQuantity"" ) ; BigDecimal ordered = quantity . subtract ( cancelQuantity == null ? BigDecimal . ZERO : cancelQuantity ) ; if ( ordered . compareTo ( BigDecimal . ZERO ) <= 0 ) continue ; GenericValue productFacility = delegator . findOne ( ""ProductFacility"" , UtilMisc . toMap ( ""facilityId"" , facilityId , ""productId"" , product . get ( ""productId"" ) ) , false ) ; BigDecimal minimumStock = BigDecimal . ZERO ; if ( productFacility != null && productFacility . get ( ""minimumStock"" ) != null ) { minimumStock = productFacility . getBigDecimal ( ""minimumStock"" ) ; } Map < String , Object > results = dispatcher . runSync ( ""getInventoryAvailableByFacility"" , UtilMisc . toMap ( ""userLogin"" , userLogin , ""productId"" , product . get ( ""productId"" ) , ""facilityId"" , facilityId ) ) ; if ( ServiceUtil . isError ( results ) ) return results ; BigDecimal atp = ( ( BigDecimal ) results . get ( ""availableToPromiseTotal"" ) ) ; BigDecimal pendingRequirements = BigDecimal . ZERO ; EntityConditionList < EntityExpr > ecl = EntityCondition . makeCondition ( UtilMisc . toList ( EntityCondition . makeCondition ( ""facilityId"" , EntityOperator . EQUALS , facilityId ) , EntityCondition . makeCondition ( ""productId"" , EntityOperator . EQUALS , product . get ( ""productId"" ) ) , EntityCondition . makeCondition ( ""requirementTypeId"" , EntityOperator . EQUALS , ""PRODUCT_REQUIREMENT"" ) , EntityCondition . makeCondition ( ""statusId"" , EntityOperator . NOT_EQUAL , ""REQ_ORDERED"" ) , EntityCondition . makeCondition ( ""statusId"" , EntityOperator . NOT_EQUAL , ""REQ_REJECTED"" ) ) , EntityOperator . AND ) ; List < GenericValue > requirements = delegator . findList ( ""Requirement"" , ecl , null , null , null , false ) ; for ( GenericValue requirement : requirements ) { pendingRequirements = pendingRequirements . add ( requirement . get ( ""quantity"" ) == null ? BigDecimal . ZERO : requirement . getBigDecimal ( ""quantity"" ) ) ; } BigDecimal shortfall = minimumStock . subtract ( atp ) . subtract ( pendingRequirements ) ; BigDecimal required = ordered . compareTo ( shortfall ) < 0 ? ordered : shortfall ; if ( required . compareTo ( BigDecimal . ZERO ) <= 0 ) continue ; Map < String , Object > input = UtilMisc . toMap ( ""userLogin"" , userLogin , ""facilityId"" , facilityId , ""productId"" , product . get ( ""productId"" ) , ""quantity"" , required , ""requirementTypeId"" , ""PRODUCT_REQUIREMENT"" ) ; results = dispatcher . runSync ( ""createRequirement"" , input ) ; if ( ServiceUtil . isError ( results ) ) return results ; String requirementId = ( String ) results . get ( ""requirementId"" ) ; input = UtilMisc . toMap ( ""userLogin"" , userLogin , ""orderId"" , order . get ( ""orderId"" ) , ""orderItemSeqId"" , item . get ( ""orderItemSeqId"" ) , ""requirementId"" , requirementId , ""quantity"" , required ) ; results = dispatcher . runSync ( ""createOrderRequirementCommitment"" , input ) ; if ( ServiceUtil . isError ( results ) ) return results ; } } catch ( GenericEntityException e ) { Debug . logError ( e , module ) ; } catch ( GenericServiceException e ) { Debug . logError ( e , module ) ; } return ServiceUtil . returnSuccess ( ) ; }",Smelly
" public void read ( org . apache . thrift . protocol . TProtocol prot , getFollowing_result struct ) throws org . apache . thrift . TException { TTupleProtocol iprot = ( TTupleProtocol ) prot ; BitSet incoming = iprot . readBitSet ( 1 ) ; if ( incoming . get ( 0 ) ) { struct . success = new Key ( ) ; struct . success . read ( iprot ) ; struct . setSuccessIsSet ( true ) ; } }",No
" public CAS evaluate ( CAS test , CAS run , Collection < String > excludedTypes , boolean includeSubtypes , boolean useAllTypes ) throws CASRuntimeException , CASException { Type annotationType = test . getAnnotationType ( ) ; Type falsePositiveType = run . getTypeSystem ( ) . getType ( ICasEvaluator . FALSE_POSITIVE ) ; Type falseNegativeType = run . getTypeSystem ( ) . getType ( ICasEvaluator . FALSE_NEGATIVE ) ; Type truePositveType = run . getTypeSystem ( ) . getType ( ICasEvaluator . TRUE_POSITIVE ) ; Feature feature = falsePositiveType . getFeatureByBaseName ( ICasEvaluator . ORIGINAL ) ; List < Type > types = getTypes ( test , excludedTypes , annotationType , useAllTypes ) ; List < AnnotationFS > testAnnotations = getAnnotations ( types , test , includeSubtypes ) ; List < AnnotationFS > runAnnotations = getAnnotations ( types , run , includeSubtypes ) ; Collection < AnnotationFS > matched = new HashSet < AnnotationFS > ( ) ; List < AnnotationFS > fp = new ArrayList < AnnotationFS > ( ) ; List < AnnotationFS > fn = new ArrayList < AnnotationFS > ( ) ; List < AnnotationFS > tp = new ArrayList < AnnotationFS > ( ) ; for ( AnnotationFS eachTest : testAnnotations ) { boolean found = false ; for ( AnnotationFS eachRun : runAnnotations ) { if ( match ( eachTest , eachRun ) ) { matched . add ( eachRun ) ; found = true ; break ; } } if ( ! found ) { AnnotationFS createAnnotation = run . createAnnotation ( falseNegativeType , eachTest . getBegin ( ) , eachTest . getEnd ( ) ) ; Type type = run . getTypeSystem ( ) . getType ( eachTest . getType ( ) . getName ( ) ) ; AnnotationFS original = run . createAnnotation ( type , eachTest . getBegin ( ) , eachTest . getEnd ( ) ) ; createAnnotation . setFeatureValue ( feature , original ) ; fn . add ( createAnnotation ) ; } else { AnnotationFS createAnnotation = run . createAnnotation ( truePositveType , eachTest . getBegin ( ) , eachTest . getEnd ( ) ) ; Type type = run . getTypeSystem ( ) . getType ( eachTest . getType ( ) . getName ( ) ) ; AnnotationFS original = run . createAnnotation ( type , eachTest . getBegin ( ) , eachTest . getEnd ( ) ) ; createAnnotation . setFeatureValue ( feature , original ) ; tp . add ( createAnnotation ) ; } } for ( AnnotationFS each : runAnnotations ) { if ( ! matched . contains ( each ) ) { AnnotationFS createAnnotation = run . createAnnotation ( falsePositiveType , each . getBegin ( ) , each . getEnd ( ) ) ; Type type = run . getTypeSystem ( ) . getType ( each . getType ( ) . getName ( ) ) ; AnnotationFS original = run . createAnnotation ( type , each . getBegin ( ) , each . getEnd ( ) ) ; createAnnotation . setFeatureValue ( feature , original ) ; fp . add ( createAnnotation ) ; } } for ( AnnotationFS annotationFS : fn ) { run . addFsToIndexes ( annotationFS ) ; } for ( AnnotationFS annotationFS : fp ) { run . addFsToIndexes ( annotationFS ) ; } for ( AnnotationFS annotationFS : tp ) { run . addFsToIndexes ( annotationFS ) ; } return run ; }",Smelly
" public void read ( org . apache . thrift . protocol . TProtocol prot , getFollowing_result struct ) throws org . apache . thrift . TException { TTupleProtocol iprot = ( TTupleProtocol ) prot ; BitSet incoming = iprot . readBitSet ( 1 ) ; if ( incoming . get ( 0 ) ) { struct . success = new Key ( ) ; struct . success . read ( iprot ) ; struct . setSuccessIsSet ( true ) ; } }",Smelly
" public void read ( org . apache . thrift . protocol . TProtocol prot , getChildDataProducts_result struct ) throws org . apache . thrift . TException { TTupleProtocol iprot = ( TTupleProtocol ) prot ; BitSet incoming = iprot . readBitSet ( 5 ) ; if ( incoming . get ( 0 ) ) { { org . apache . thrift . protocol . TList _list283 = new org . apache . thrift . protocol . TList ( org . apache . thrift . protocol . TType . STRUCT , iprot . readI32 ( ) ) ; struct . success = new ArrayList < org . apache . airavata . model . data . replica . DataProductModel > ( _list283 . size ) ; org . apache . airavata . model . data . replica . DataProductModel _elem284 ; for ( int _i285 = 0 ; _i285 < _list283 . size ; ++ _i285 ) { _elem284 = new org . apache . airavata . model . data . replica . DataProductModel ( ) ; _elem284 . read ( iprot ) ; struct . success . add ( _elem284 ) ; } } struct . setSuccessIsSet ( true ) ; } if ( incoming . get ( 1 ) ) { struct . ire = new org . apache . airavata . model . error . InvalidRequestException ( ) ; struct . ire . read ( iprot ) ; struct . setIreIsSet ( true ) ; } if ( incoming . get ( 2 ) ) { struct . ace = new org . apache . airavata . model . error . AiravataClientException ( ) ; struct . ace . read ( iprot ) ; struct . setAceIsSet ( true ) ; } if ( incoming . get ( 3 ) ) { struct . ase = new org . apache . airavata . model . error . AiravataSystemException ( ) ; struct . ase . read ( iprot ) ; struct . setAseIsSet ( true ) ; } if ( incoming . get ( 4 ) ) { struct . ae = new org . apache . airavata . model . error . AuthorizationException ( ) ; struct . ae . read ( iprot ) ; struct . setAeIsSet ( true ) ; } }",No
" public void read ( org . apache . thrift . protocol . TProtocol prot , ComputeResourcePreference struct ) throws org . apache . thrift . TException { TTupleProtocol iprot = ( TTupleProtocol ) prot ; struct . computeResourceId = iprot . readString ( ) ; struct . setComputeResourceIdIsSet ( true ) ; struct . overridebyAiravata = iprot . readBool ( ) ; struct . setOverridebyAiravataIsSet ( true ) ; BitSet incoming = iprot . readBitSet ( 8 ) ; if ( incoming . get ( 0 ) ) { struct . loginUserName = iprot . readString ( ) ; struct . setLoginUserNameIsSet ( true ) ; } if ( incoming . get ( 1 ) ) { struct . preferredJobSubmissionProtocol = org . apache . airavata . model . appcatalog . computeresource . JobSubmissionProtocol . findByValue ( iprot . readI32 ( ) ) ; struct . setPreferredJobSubmissionProtocolIsSet ( true ) ; } if ( incoming . get ( 2 ) ) { struct . preferredDataMovementProtocol = org . apache . airavata . model . data . movement . DataMovementProtocol . findByValue ( iprot . readI32 ( ) ) ; struct . setPreferredDataMovementProtocolIsSet ( true ) ; } if ( incoming . get ( 3 ) ) { struct . preferredBatchQueue = iprot . readString ( ) ; struct . setPreferredBatchQueueIsSet ( true ) ; } if ( incoming . get ( 4 ) ) { struct . scratchLocation = iprot . readString ( ) ; struct . setScratchLocationIsSet ( true ) ; } if ( incoming . get ( 5 ) ) { struct . allocationProjectNumber = iprot . readString ( ) ; struct . setAllocationProjectNumberIsSet ( true ) ; } if ( incoming . get ( 6 ) ) { struct . resourceSpecificCredentialStoreToken = iprot . readString ( ) ; struct . setResourceSpecificCredentialStoreTokenIsSet ( true ) ; } if ( incoming . get ( 7 ) ) { struct . usageReportingGatewayId = iprot . readString ( ) ; struct . setUsageReportingGatewayIdIsSet ( true ) ; } }",Smelly
" public void read ( org . apache . thrift . protocol . TProtocol prot , ExperimentModel struct ) throws org . apache . thrift . TException { TTupleProtocol iprot = ( TTupleProtocol ) prot ; struct . experimentId = iprot . readString ( ) ; struct . setExperimentIdIsSet ( true ) ; struct . projectId = iprot . readString ( ) ; struct . setProjectIdIsSet ( true ) ; struct . gatewayId = iprot . readString ( ) ; struct . setGatewayIdIsSet ( true ) ; struct . experimentType = org . apache . airavata . model . experiment . ExperimentType . findByValue ( iprot . readI32 ( ) ) ; struct . setExperimentTypeIsSet ( true ) ; struct . userName = iprot . readString ( ) ; struct . setUserNameIsSet ( true ) ; struct . experimentName = iprot . readString ( ) ; struct . setExperimentNameIsSet ( true ) ; BitSet incoming = iprot . readBitSet ( 13 ) ; if ( incoming . get ( 0 ) ) { struct . creationTime = iprot . readI64 ( ) ; struct . setCreationTimeIsSet ( true ) ; } if ( incoming . get ( 1 ) ) { struct . description = iprot . readString ( ) ; struct . setDescriptionIsSet ( true ) ; } if ( incoming . get ( 2 ) ) { struct . executionId = iprot . readString ( ) ; struct . setExecutionIdIsSet ( true ) ; } if ( incoming . get ( 3 ) ) { struct . gatewayExecutionId = iprot . readString ( ) ; struct . setGatewayExecutionIdIsSet ( true ) ; } if ( incoming . get ( 4 ) ) { struct . gatewayInstanceId = iprot . readString ( ) ; struct . setGatewayInstanceIdIsSet ( true ) ; } if ( incoming . get ( 5 ) ) { struct . enableEmailNotification = iprot . readBool ( ) ; struct . setEnableEmailNotificationIsSet ( true ) ; } if ( incoming . get ( 6 ) ) { { org . apache . thrift . protocol . TList _list25 = new org . apache . thrift . protocol . TList ( org . apache . thrift . protocol . TType . STRING , iprot . readI32 ( ) ) ; struct . emailAddresses = new ArrayList < String > ( _list25 . size ) ; String _elem26 ; for ( int _i27 = 0 ; _i27 < _list25 . size ; ++ _i27 ) { _elem26 = iprot . readString ( ) ; struct . emailAddresses . add ( _elem26 ) ; } } struct . setEmailAddressesIsSet ( true ) ; } if ( incoming . get ( 7 ) ) { struct . userConfigurationData = new UserConfigurationDataModel ( ) ; struct . userConfigurationData . read ( iprot ) ; struct . setUserConfigurationDataIsSet ( true ) ; } if ( incoming . get ( 8 ) ) { { org . apache . thrift . protocol . TList _list28 = new org . apache . thrift . protocol . TList ( org . apache . thrift . protocol . TType . STRUCT , iprot . readI32 ( ) ) ; struct . experimentInputs = new ArrayList < org . apache . airavata . model . application . io . InputDataObjectType > ( _list28 . size ) ; org . apache . airavata . model . application . io . InputDataObjectType _elem29 ; for ( int _i30 = 0 ; _i30 < _list28 . size ; ++ _i30 ) { _elem29 = new org . apache . airavata . model . application . io . InputDataObjectType ( ) ; _elem29 . read ( iprot ) ; struct . experimentInputs . add ( _elem29 ) ; } } struct . setExperimentInputsIsSet ( true ) ; } if ( incoming . get ( 9 ) ) { { org . apache . thrift . protocol . TList _list31 = new org . apache . thrift . protocol . TList ( org . apache . thrift . protocol . TType . STRUCT , iprot . readI32 ( ) ) ; struct . experimentOutputs = new ArrayList < org . apache . airavata . model . application . io . OutputDataObjectType > ( _list31 . size ) ; org . apache . airavata . model . application . io . OutputDataObjectType _elem32 ; for ( int _i33 = 0 ; _i33 < _list31 . size ; ++ _i33 ) { _elem32 = new org . apache . airavata . model . application . io . OutputDataObjectType ( ) ; _elem32 . read ( iprot ) ; struct . experimentOutputs . add ( _elem32 ) ; } } struct . setExperimentOutputsIsSet ( true ) ; } if ( incoming . get ( 10 ) ) { struct . experimentStatus = new org . apache . airavata . model . status . ExperimentStatus ( ) ; struct . experimentStatus . read ( iprot ) ; struct . setExperimentStatusIsSet ( true ) ; } if ( incoming . get ( 11 ) ) { { org . apache . thrift . protocol . TList _list34 = new org . apache . thrift . protocol . TList ( org . apache . thrift . protocol . TType . STRUCT , iprot . readI32 ( ) ) ; struct . errors = new ArrayList < org . apache . airavata . model . commons . ErrorModel > ( _list34 . size ) ; org . apache . airavata . model . commons . ErrorModel _elem35 ; for ( int _i36 = 0 ; _i36 < _list34 . size ; ++ _i36 ) { _elem35 = new org . apache . airavata . model . commons . ErrorModel ( ) ; _elem35 . read ( iprot ) ; struct . errors . add ( _elem35 ) ; } } struct . setErrorsIsSet ( true ) ; } if ( incoming . get ( 12 ) ) { { org . apache . thrift . protocol . TList _list37 = new org . apache . thrift . protocol . TList ( org . apache . thrift . protocol . TType . STRUCT , iprot . readI32 ( ) ) ; struct . processes = new ArrayList < org . apache . airavata . model . process . ProcessModel > ( _list37 . size ) ; org . apache . airavata . model . process . ProcessModel _elem38 ; for ( int _i39 = 0 ; _i39 < _list37 . size ; ++ _i39 ) { _elem38 = new org . apache . airavata . model . process . ProcessModel ( ) ; _elem38 . read ( iprot ) ; struct . processes . add ( _elem38 ) ; } } struct . setProcessesIsSet ( true ) ; } }",Smelly
" public void read ( org . apache . thrift . protocol . TProtocol prot , getChildDataProducts_result struct ) throws org . apache . thrift . TException { TTupleProtocol iprot = ( TTupleProtocol ) prot ; BitSet incoming = iprot . readBitSet ( 5 ) ; if ( incoming . get ( 0 ) ) { { org . apache . thrift . protocol . TList _list283 = new org . apache . thrift . protocol . TList ( org . apache . thrift . protocol . TType . STRUCT , iprot . readI32 ( ) ) ; struct . success = new ArrayList < org . apache . airavata . model . data . replica . DataProductModel > ( _list283 . size ) ; org . apache . airavata . model . data . replica . DataProductModel _elem284 ; for ( int _i285 = 0 ; _i285 < _list283 . size ; ++ _i285 ) { _elem284 = new org . apache . airavata . model . data . replica . DataProductModel ( ) ; _elem284 . read ( iprot ) ; struct . success . add ( _elem284 ) ; } } struct . setSuccessIsSet ( true ) ; } if ( incoming . get ( 1 ) ) { struct . ire = new org . apache . airavata . model . error . InvalidRequestException ( ) ; struct . ire . read ( iprot ) ; struct . setIreIsSet ( true ) ; } if ( incoming . get ( 2 ) ) { struct . ace = new org . apache . airavata . model . error . AiravataClientException ( ) ; struct . ace . read ( iprot ) ; struct . setAceIsSet ( true ) ; } if ( incoming . get ( 3 ) ) { struct . ase = new org . apache . airavata . model . error . AiravataSystemException ( ) ; struct . ase . read ( iprot ) ; struct . setAseIsSet ( true ) ; } if ( incoming . get ( 4 ) ) { struct . ae = new org . apache . airavata . model . error . AuthorizationException ( ) ; struct . ae . read ( iprot ) ; struct . setAeIsSet ( true ) ; } }",Smelly
" public Set < MessageHandler > getMessageHandlers ( Object pojo , Map < String , String > pathParameters , Session session , EndpointConfig config ) { Object [ ] params = new Object [ m . getParameterTypes ( ) . length ] ; for ( Map . Entry < Integer , PojoPathParam > entry : indexPathParams . entrySet ( ) ) { PojoPathParam pathParam = entry . getValue ( ) ; String valueString = pathParameters . get ( pathParam . getName ( ) ) ; Object value = null ; try { value = Util . coerceToType ( pathParam . getType ( ) , valueString ) ; } catch ( Exception e ) { DecodeException de = new DecodeException ( valueString , sm . getString ( ""pojoMethodMapping.decodePathParamFail"" , valueString , pathParam . getType ( ) ) , e ) ; params = new Object [ ] { de } ; } params [ entry . getKey ( ) . intValue ( ) ] = value ; } Set < MessageHandler > results = new HashSet < MessageHandler > ( 2 ) ; if ( indexBoolean == - 1 ) { if ( indexString != - 1 || indexPrimitive != - 1 ) { MessageHandler mh = new PojoMessageHandlerWholeText ( pojo , m , session , config , null , params , indexPayload , false , indexSession , maxMessageSize ) ; results . add ( mh ) ; } else if ( indexReader != - 1 ) { MessageHandler mh = new PojoMessageHandlerWholeText ( pojo , m , session , config , null , params , indexReader , true , indexSession , maxMessageSize ) ; results . add ( mh ) ; } else if ( indexByteArray != - 1 ) { MessageHandler mh = new PojoMessageHandlerWholeBinary ( pojo , m , session , config , null , params , indexByteArray , true , indexSession , false , maxMessageSize ) ; results . add ( mh ) ; } else if ( indexByteBuffer != - 1 ) { MessageHandler mh = new PojoMessageHandlerWholeBinary ( pojo , m , session , config , null , params , indexByteBuffer , false , indexSession , false , maxMessageSize ) ; results . add ( mh ) ; } else if ( indexInputStream != - 1 ) { MessageHandler mh = new PojoMessageHandlerWholeBinary ( pojo , m , session , config , null , params , indexInputStream , true , indexSession , true , maxMessageSize ) ; results . add ( mh ) ; } else if ( decoderMatch != null && decoderMatch . hasMatches ( ) ) { if ( decoderMatch . getBinaryDecoders ( ) . size ( ) > 0 ) { MessageHandler mh = new PojoMessageHandlerWholeBinary ( pojo , m , session , config , decoderMatch . getBinaryDecoders ( ) , params , indexPayload , true , indexSession , true , maxMessageSize ) ; results . add ( mh ) ; } if ( decoderMatch . getTextDecoders ( ) . size ( ) > 0 ) { MessageHandler mh = new PojoMessageHandlerWholeText ( pojo , m , session , config , decoderMatch . getTextDecoders ( ) , params , indexPayload , true , indexSession , maxMessageSize ) ; results . add ( mh ) ; } } else { MessageHandler mh = new PojoMessageHandlerWholePong ( pojo , m , session , params , indexPong , false , indexSession ) ; results . add ( mh ) ; } } else { if ( indexString != - 1 ) { MessageHandler mh = new PojoMessageHandlerPartialText ( pojo , m , session , params , indexString , false , indexBoolean , indexSession , maxMessageSize ) ; results . add ( mh ) ; } else if ( indexByteArray != - 1 ) { MessageHandler mh = new PojoMessageHandlerPartialBinary ( pojo , m , session , params , indexByteArray , true , indexBoolean , indexSession , maxMessageSize ) ; results . add ( mh ) ; } else { MessageHandler mh = new PojoMessageHandlerPartialBinary ( pojo , m , session , params , indexByteBuffer , false , indexBoolean , indexSession , maxMessageSize ) ; results . add ( mh ) ; } } return results ; }",Smelly
" public void run ( ) { resetManager . registerMe ( ) ; try { IThreadContext threadContext = ThreadContextFactory . make ( ) ; IRepositoryConnectionManager mgr = RepositoryConnectionManagerFactory . make ( threadContext ) ; IJobManager jobManager = JobManagerFactory . make ( threadContext ) ; ArrayList docList = new ArrayList ( ) ; IDBInterface database = DBInterfaceFactory . make ( threadContext , ManifoldCF . getMasterDatabaseName ( ) , ManifoldCF . getMasterDatabaseUsername ( ) , ManifoldCF . getMasterDatabasePassword ( ) ) ; int deleteChunkSize = database . getMaxInClause ( ) ; while ( true ) { try { resetManager . waitForReset ( threadContext ) ; if ( documentCleanupQueue . checkIfEmpty ( n ) == false ) { ManifoldCF . sleep ( 100L ) ; continue ; } Logging . threads . debug ( ""Document cleanup stuffer thread woke up"" ) ; long currentTime = System . currentTimeMillis ( ) ; DocumentSetAndFlags documentsToClean = jobManager . getNextCleanableDocuments ( deleteChunkSize , currentTime ) ; DocumentDescription [ ] descs = documentsToClean . getDocumentSet ( ) ; boolean [ ] removeFromIndex = documentsToClean . getFlags ( ) ; if ( descs . length == 0 ) { Logging . threads . debug ( ""Document cleanup stuffer thread found nothing to do"" ) ; ManifoldCF . sleep ( 1000L ) ; continue ; } if ( Logging . threads . isDebugEnabled ( ) ) Logging . threads . debug ( ""Document cleanup stuffer thread found "" + Integer . toString ( descs . length ) + "" documents"" ) ; Map jobMap = new HashMap ( ) ; int k = 0 ; while ( k < descs . length ) { CleanupQueuedDocument x = new CleanupQueuedDocument ( descs [ k ] , removeFromIndex [ k ] ) ; Long jobID = descs [ k ] . getJobID ( ) ; List y = ( List ) jobMap . get ( jobID ) ; if ( y == null ) { y = new ArrayList ( ) ; jobMap . put ( jobID , y ) ; } y . add ( x ) ; k ++ ; } Iterator iter = jobMap . keySet ( ) . iterator ( ) ; while ( iter . hasNext ( ) ) { Long jobID = ( Long ) iter . next ( ) ; IJobDescription jobDescription = jobManager . load ( jobID , true ) ; List y = ( List ) jobMap . get ( jobID ) ; CleanupQueuedDocument [ ] docDescs = new CleanupQueuedDocument [ y . size ( ) ] ; k = 0 ; while ( k < docDescs . length ) { docDescs [ k ] = ( CleanupQueuedDocument ) y . get ( k ) ; k ++ ; } DocumentCleanupSet set = new DocumentCleanupSet ( docDescs , jobDescription ) ; documentCleanupQueue . addDocuments ( set ) ; } yield ( ) ; } catch ( ManifoldCFException e ) { if ( e . getErrorCode ( ) == ManifoldCFException . INTERRUPTED ) break ; if ( e . getErrorCode ( ) == ManifoldCFException . DATABASE_CONNECTION_ERROR ) { resetManager . noteEvent ( ) ; Logging . threads . error ( ""Cleanup stuffer thread aborting and restarting due to database connection reset"" , e ) ; try { ManifoldCF . sleep ( 10000L ) ; } catch ( InterruptedException se ) { break ; } continue ; } Logging . threads . error ( ""Exception tossed: "" + e . getMessage ( ) , e ) ; if ( e . getErrorCode ( ) == ManifoldCFException . SETUP_ERROR ) { System . exit ( 1 ) ; } } catch ( InterruptedException e ) { break ; } catch ( OutOfMemoryError e ) { System . err . println ( ""agents process ran out of memory - shutting down"" ) ; e . printStackTrace ( System . err ) ; System . exit ( - 200 ) ; } catch ( Throwable e ) { Logging . threads . fatal ( ""Error tossed: "" + e . getMessage ( ) , e ) ; } } } catch ( Throwable e ) { System . err . println ( ""agents process could not start - shutting down"" ) ; Logging . threads . fatal ( ""DocumentCleanupStufferThread initialization error tossed: "" + e . getMessage ( ) , e ) ; System . exit ( - 300 ) ; } }",Smelly
 private static < S extends org . apache . thrift . scheme . IScheme > S scheme ( org . apache . thrift . protocol . TProtocol proto ) { return ( org . apache . thrift . scheme . StandardScheme . class . equals ( proto . getScheme ( ) ) ? STANDARD_SCHEME_FACTORY : TUPLE_SCHEME_FACTORY ) . getScheme ( ) ; },Smelly
" public void testUnmodifiableRequestHeaders ( ) throws Exception { Message m = control . createMock ( Message . class ) ; m . get ( Message . PROTOCOL_HEADERS ) ; MetadataMap < String , String > headers = createHeader ( HttpHeaders . ACCEPT_LANGUAGE , ""en;q=0.7, en-gb;q=0.8, da"" ) ; EasyMock . expectLastCall ( ) . andReturn ( headers ) ; control . replay ( ) ; HttpHeaders h = new HttpHeadersImpl ( m ) ; List < Locale > languages = h . getAcceptableLanguages ( ) ; assertEquals ( 3 , languages . size ( ) ) ; languages . clear ( ) ; languages = h . getAcceptableLanguages ( ) ; assertEquals ( 3 , languages . size ( ) ) ; MultivaluedMap < String , String > rHeaders = h . getRequestHeaders ( ) ; List < String > acceptL = rHeaders . get ( HttpHeaders . ACCEPT_LANGUAGE ) ; assertEquals ( 3 , acceptL . size ( ) ) ; try { rHeaders . clear ( ) ; fail ( ) ; } catch ( UnsupportedOperationException ex ) { } }",No
" public void read ( org . apache . thrift . protocol . TProtocol prot , drainReplicationTable_result struct ) throws org . apache . thrift . TException { TTupleProtocol iprot = ( TTupleProtocol ) prot ; BitSet incoming = iprot . readBitSet ( 1 ) ; if ( incoming . get ( 0 ) ) { struct . success = iprot . readBool ( ) ; struct . setSuccessIsSet ( true ) ; } }",Smelly
 public VertexTerminationCause getTerminationCause ( ) { return terminationCause ; },No
 String myStaticMethod ( OptionsWithStaticMethod o ) { return o . getMyMethod ( ) ; },No
" public void read ( org . apache . thrift . protocol . TProtocol prot , show_compact_result struct ) throws org . apache . thrift . TException { TTupleProtocol iprot = ( TTupleProtocol ) prot ; BitSet incoming = iprot . readBitSet ( 1 ) ; if ( incoming . get ( 0 ) ) { struct . success = new ShowCompactResponse ( ) ; struct . success . read ( iprot ) ; struct . setSuccessIsSet ( true ) ; } }",Smelly
" protected URLConnection openConnection ( URL u ) throws IOException { String name = new File ( u . getPath ( ) ) . getName ( ) ; return getClass ( ) . getResource ( ""/org/apache/karaf/features/"" + name + "".xml"" ) . openConnection ( ) ; }",No
" private void checkVector ( Vector3D v , double x , double y , double z ) { Assert . assertEquals ( x , v . getX ( ) , 1.0e-12 ) ; Assert . assertEquals ( y , v . getY ( ) , 1.0e-12 ) ; Assert . assertEquals ( z , v . getZ ( ) , 1.0e-12 ) ; }",No
 private static < S extends org . apache . thrift . scheme . IScheme > S scheme ( org . apache . thrift . protocol . TProtocol proto ) { return ( org . apache . thrift . scheme . StandardScheme . class . equals ( proto . getScheme ( ) ) ? STANDARD_SCHEME_FACTORY : TUPLE_SCHEME_FACTORY ) . getScheme ( ) ; },Smelly
 public void finish ( ) throws IOException { finishDocument ( this ) ; },No
" public void read ( org . apache . thrift . protocol . TProtocol prot , getChildDataProducts_result struct ) throws org . apache . thrift . TException { TTupleProtocol iprot = ( TTupleProtocol ) prot ; BitSet incoming = iprot . readBitSet ( 5 ) ; if ( incoming . get ( 0 ) ) { { org . apache . thrift . protocol . TList _list283 = new org . apache . thrift . protocol . TList ( org . apache . thrift . protocol . TType . STRUCT , iprot . readI32 ( ) ) ; struct . success = new ArrayList < org . apache . airavata . model . data . replica . DataProductModel > ( _list283 . size ) ; org . apache . airavata . model . data . replica . DataProductModel _elem284 ; for ( int _i285 = 0 ; _i285 < _list283 . size ; ++ _i285 ) { _elem284 = new org . apache . airavata . model . data . replica . DataProductModel ( ) ; _elem284 . read ( iprot ) ; struct . success . add ( _elem284 ) ; } } struct . setSuccessIsSet ( true ) ; } if ( incoming . get ( 1 ) ) { struct . ire = new org . apache . airavata . model . error . InvalidRequestException ( ) ; struct . ire . read ( iprot ) ; struct . setIreIsSet ( true ) ; } if ( incoming . get ( 2 ) ) { struct . ace = new org . apache . airavata . model . error . AiravataClientException ( ) ; struct . ace . read ( iprot ) ; struct . setAceIsSet ( true ) ; } if ( incoming . get ( 3 ) ) { struct . ase = new org . apache . airavata . model . error . AiravataSystemException ( ) ; struct . ase . read ( iprot ) ; struct . setAseIsSet ( true ) ; } if ( incoming . get ( 4 ) ) { struct . ae = new org . apache . airavata . model . error . AuthorizationException ( ) ; struct . ae . read ( iprot ) ; struct . setAeIsSet ( true ) ; } }",No
" public static IAgent make ( IThreadContext tc , String className ) throws ManifoldCFException { String agentName = agentIdentifier + className ; Object o = tc . get ( agentName ) ; if ( o == null || ! ( o instanceof IAgent ) ) { try { Class theClass = Class . forName ( className ) ; Class [ ] argumentClasses = new Class [ 1 ] ; argumentClasses [ 0 ] = IThreadContext . class ; Constructor c = theClass . getConstructor ( argumentClasses ) ; Object [ ] arguments = new Object [ 1 ] ; arguments [ 0 ] = tc ; o = c . newInstance ( arguments ) ; if ( ! ( o instanceof IAgent ) ) throw new ManifoldCFException ( ""Class '"" + className + ""' does not implement IAgent."" ) ; tc . save ( agentName , o ) ; } catch ( InvocationTargetException e ) { Throwable z = e . getTargetException ( ) ; if ( z instanceof Error ) throw ( Error ) z ; else throw ( ManifoldCFException ) z ; } catch ( ClassNotFoundException e ) { throw new ManifoldCFException ( ""No class implementing IAgent called '"" + className + ""'."" , e ) ; } catch ( NoSuchMethodException e ) { throw new ManifoldCFException ( ""No appropriate constructor for IAgent implementation '"" + className + ""'.  Need xxx(ConfigParams)."" , e ) ; } catch ( SecurityException e ) { throw new ManifoldCFException ( ""Protected constructor for IAgent implementation '"" + className + ""'"" , e ) ; } catch ( IllegalAccessException e ) { throw new ManifoldCFException ( ""Unavailable constructor for IAgent implementation '"" + className + ""'"" , e ) ; } catch ( IllegalArgumentException e ) { throw new ManifoldCFException ( ""Shouldn't happen!!!"" , e ) ; } catch ( InstantiationException e ) { throw new ManifoldCFException ( ""InstantiationException for IAgent implementation '"" + className + ""'"" , e ) ; } catch ( ExceptionInInitializerError e ) { throw new ManifoldCFException ( ""ExceptionInInitializerError for IAgent implementation '"" + className + ""'"" , e ) ; } } return ( IAgent ) o ; }",Smelly
" public void read ( org . apache . thrift . protocol . TProtocol prot , ComputeResourceDescription struct ) throws org . apache . thrift . TException { TTupleProtocol iprot = ( TTupleProtocol ) prot ; struct . computeResourceId = iprot . readString ( ) ; struct . setComputeResourceIdIsSet ( true ) ; struct . hostName = iprot . readString ( ) ; struct . setHostNameIsSet ( true ) ; BitSet incoming = iprot . readBitSet ( 12 ) ; if ( incoming . get ( 0 ) ) { { org . apache . thrift . protocol . TList _list67 = new org . apache . thrift . protocol . TList ( org . apache . thrift . protocol . TType . STRING , iprot . readI32 ( ) ) ; struct . hostAliases = new ArrayList < String > ( _list67 . size ) ; String _elem68 ; for ( int _i69 = 0 ; _i69 < _list67 . size ; ++ _i69 ) { _elem68 = iprot . readString ( ) ; struct . hostAliases . add ( _elem68 ) ; } } struct . setHostAliasesIsSet ( true ) ; } if ( incoming . get ( 1 ) ) { { org . apache . thrift . protocol . TList _list70 = new org . apache . thrift . protocol . TList ( org . apache . thrift . protocol . TType . STRING , iprot . readI32 ( ) ) ; struct . ipAddresses = new ArrayList < String > ( _list70 . size ) ; String _elem71 ; for ( int _i72 = 0 ; _i72 < _list70 . size ; ++ _i72 ) { _elem71 = iprot . readString ( ) ; struct . ipAddresses . add ( _elem71 ) ; } } struct . setIpAddressesIsSet ( true ) ; } if ( incoming . get ( 2 ) ) { struct . resourceDescription = iprot . readString ( ) ; struct . setResourceDescriptionIsSet ( true ) ; } if ( incoming . get ( 3 ) ) { struct . enabled = iprot . readBool ( ) ; struct . setEnabledIsSet ( true ) ; } if ( incoming . get ( 4 ) ) { { org . apache . thrift . protocol . TList _list73 = new org . apache . thrift . protocol . TList ( org . apache . thrift . protocol . TType . STRUCT , iprot . readI32 ( ) ) ; struct . batchQueues = new ArrayList < BatchQueue > ( _list73 . size ) ; BatchQueue _elem74 ; for ( int _i75 = 0 ; _i75 < _list73 . size ; ++ _i75 ) { _elem74 = new BatchQueue ( ) ; _elem74 . read ( iprot ) ; struct . batchQueues . add ( _elem74 ) ; } } struct . setBatchQueuesIsSet ( true ) ; } if ( incoming . get ( 5 ) ) { { org . apache . thrift . protocol . TMap _map76 = new org . apache . thrift . protocol . TMap ( org . apache . thrift . protocol . TType . I32 , org . apache . thrift . protocol . TType . STRING , iprot . readI32 ( ) ) ; struct . fileSystems = new HashMap < FileSystems , String > ( 2 * _map76 . size ) ; FileSystems _key77 ; String _val78 ; for ( int _i79 = 0 ; _i79 < _map76 . size ; ++ _i79 ) { _key77 = org . apache . airavata . model . appcatalog . computeresource . FileSystems . findByValue ( iprot . readI32 ( ) ) ; _val78 = iprot . readString ( ) ; struct . fileSystems . put ( _key77 , _val78 ) ; } } struct . setFileSystemsIsSet ( true ) ; } if ( incoming . get ( 6 ) ) { { org . apache . thrift . protocol . TList _list80 = new org . apache . thrift . protocol . TList ( org . apache . thrift . protocol . TType . STRUCT , iprot . readI32 ( ) ) ; struct . jobSubmissionInterfaces = new ArrayList < JobSubmissionInterface > ( _list80 . size ) ; JobSubmissionInterface _elem81 ; for ( int _i82 = 0 ; _i82 < _list80 . size ; ++ _i82 ) { _elem81 = new JobSubmissionInterface ( ) ; _elem81 . read ( iprot ) ; struct . jobSubmissionInterfaces . add ( _elem81 ) ; } } struct . setJobSubmissionInterfacesIsSet ( true ) ; } if ( incoming . get ( 7 ) ) { { org . apache . thrift . protocol . TList _list83 = new org . apache . thrift . protocol . TList ( org . apache . thrift . protocol . TType . STRUCT , iprot . readI32 ( ) ) ; struct . dataMovementInterfaces = new ArrayList < org . apache . airavata . model . data . movement . DataMovementInterface > ( _list83 . size ) ; org . apache . airavata . model . data . movement . DataMovementInterface _elem84 ; for ( int _i85 = 0 ; _i85 < _list83 . size ; ++ _i85 ) { _elem84 = new org . apache . airavata . model . data . movement . DataMovementInterface ( ) ; _elem84 . read ( iprot ) ; struct . dataMovementInterfaces . add ( _elem84 ) ; } } struct . setDataMovementInterfacesIsSet ( true ) ; } if ( incoming . get ( 8 ) ) { struct . maxMemoryPerNode = iprot . readI32 ( ) ; struct . setMaxMemoryPerNodeIsSet ( true ) ; } if ( incoming . get ( 9 ) ) { struct . gatewayUsageReporting = iprot . readBool ( ) ; struct . setGatewayUsageReportingIsSet ( true ) ; } if ( incoming . get ( 10 ) ) { struct . gatewayUsageModuleLoadCommand = iprot . readString ( ) ; struct . setGatewayUsageModuleLoadCommandIsSet ( true ) ; } if ( incoming . get ( 11 ) ) { struct . gatewayUsageExecutable = iprot . readString ( ) ; struct . setGatewayUsageExecutableIsSet ( true ) ; } }",Smelly
 public HttpURLConnection configure ( HttpURLConnection conn ) throws IOException { if ( conn instanceof HttpsURLConnection ) { HttpsURLConnection sslConn = ( HttpsURLConnection ) conn ; try { sslConn . setSSLSocketFactory ( createSSLSocketFactory ( ) ) ; } catch ( GeneralSecurityException ex ) { throw new IOException ( ex ) ; } sslConn . setHostnameVerifier ( getHostnameVerifier ( ) ) ; conn = sslConn ; } return conn ; },No
 String getAllEndpointStates ( ) ;,No
" public void read ( org . apache . thrift . protocol . TProtocol prot , getChildDataProducts_result struct ) throws org . apache . thrift . TException { TTupleProtocol iprot = ( TTupleProtocol ) prot ; BitSet incoming = iprot . readBitSet ( 5 ) ; if ( incoming . get ( 0 ) ) { { org . apache . thrift . protocol . TList _list283 = new org . apache . thrift . protocol . TList ( org . apache . thrift . protocol . TType . STRUCT , iprot . readI32 ( ) ) ; struct . success = new ArrayList < org . apache . airavata . model . data . replica . DataProductModel > ( _list283 . size ) ; org . apache . airavata . model . data . replica . DataProductModel _elem284 ; for ( int _i285 = 0 ; _i285 < _list283 . size ; ++ _i285 ) { _elem284 = new org . apache . airavata . model . data . replica . DataProductModel ( ) ; _elem284 . read ( iprot ) ; struct . success . add ( _elem284 ) ; } } struct . setSuccessIsSet ( true ) ; } if ( incoming . get ( 1 ) ) { struct . ire = new org . apache . airavata . model . error . InvalidRequestException ( ) ; struct . ire . read ( iprot ) ; struct . setIreIsSet ( true ) ; } if ( incoming . get ( 2 ) ) { struct . ace = new org . apache . airavata . model . error . AiravataClientException ( ) ; struct . ace . read ( iprot ) ; struct . setAceIsSet ( true ) ; } if ( incoming . get ( 3 ) ) { struct . ase = new org . apache . airavata . model . error . AiravataSystemException ( ) ; struct . ase . read ( iprot ) ; struct . setAseIsSet ( true ) ; } if ( incoming . get ( 4 ) ) { struct . ae = new org . apache . airavata . model . error . AuthorizationException ( ) ; struct . ae . read ( iprot ) ; struct . setAeIsSet ( true ) ; } }",No
" public abstract Type getInitialType ( MatchContext context , RutaStream stream ) ;",No
 public Short unwrap ( ByteWritable writableValue ) { return ( short ) writableValue . get ( ) ; },No
" public Method getEvalMethod ( List < TypeInfo > argTypeInfos ) throws UDFArgumentException { assert ( argTypeInfos . size ( ) == 2 ) ; List < TypeInfo > pTypeInfos = null ; if ( argTypeInfos . get ( 0 ) . equals ( TypeInfoFactory . voidTypeInfo ) || argTypeInfos . get ( 1 ) . equals ( TypeInfoFactory . voidTypeInfo ) ) { pTypeInfos = new ArrayList < TypeInfo > ( ) ; pTypeInfos . add ( TypeInfoFactory . doubleTypeInfo ) ; pTypeInfos . add ( TypeInfoFactory . doubleTypeInfo ) ; } else if ( argTypeInfos . get ( 0 ) . equals ( TypeInfoFactory . booleanTypeInfo ) && argTypeInfos . get ( 1 ) . equals ( TypeInfoFactory . booleanTypeInfo ) ) { pTypeInfos = new ArrayList < TypeInfo > ( ) ; pTypeInfos . add ( TypeInfoFactory . intTypeInfo ) ; pTypeInfos . add ( TypeInfoFactory . intTypeInfo ) ; } else if ( argTypeInfos . get ( 0 ) == argTypeInfos . get ( 1 ) ) { pTypeInfos = argTypeInfos ; } else { pTypeInfos = new ArrayList < TypeInfo > ( ) ; pTypeInfos . add ( TypeInfoFactory . doubleTypeInfo ) ; pTypeInfos . add ( TypeInfoFactory . doubleTypeInfo ) ; } Method udfMethod = null ; List < Method > evaluateMethods = new ArrayList < Method > ( ) ; for ( Method m : Arrays . asList ( udfClass . getMethods ( ) ) ) { if ( m . getName ( ) . equals ( ""evaluate"" ) ) { evaluateMethods . add ( m ) ; List < TypeInfo > acceptedTypeInfos = TypeInfoUtils . getParameterTypeInfos ( m , pTypeInfos . size ( ) ) ; if ( acceptedTypeInfos == null ) { continue ; } boolean match = ( acceptedTypeInfos . size ( ) == pTypeInfos . size ( ) ) ; for ( int i = 0 ; i < pTypeInfos . size ( ) && match ; i ++ ) { TypeInfo accepted = acceptedTypeInfos . get ( i ) ; if ( accepted != pTypeInfos . get ( i ) ) { match = false ; } } if ( match ) { if ( udfMethod != null ) { throw new AmbiguousMethodException ( udfClass , argTypeInfos , Arrays . asList ( new Method [ ] { udfMethod , m } ) ) ; } else { udfMethod = m ; } } } } if ( udfMethod == null ) { throw new NoMatchingMethodException ( udfClass , argTypeInfos , evaluateMethods ) ; } return udfMethod ; }",Smelly
" public void delete ( ) { if ( input . parameterNumber ( ) == 1 ) { try { final Scanner scanIn = new Scanner ( System . in ) ; System . out . println ( ""\nRunning this operation you will delete all the realm users managed by Syncope, "" + ""are you sure? [yes/no]"" ) ; final String answer = scanIn . nextLine ( ) ; if ( ""yes"" . equalsIgnoreCase ( answer ) ) { System . out . println ( ""\nUsername:"" ) ; final String username = scanIn . nextLine ( ) ; System . out . println ( ""\nPassword:"" ) ; final String password = scanIn . nextLine ( ) ; if ( userSyncopeOperations . auth ( username , password ) ) { System . out . println ( ""Deleting process started"" ) ; final String realm = input . firstParameter ( ) ; if ( ! realmSyncopeOperations . exists ( realm ) ) { userResultManager . notFoundError ( ""Realm"" , realm ) ; return ; } final Map < String , BulkActionResult . Status > results = userSyncopeOperations . deleteAll ( realm ) ; final Map < String , String > users = new HashMap < > ( ) ; int deletedUsers = 0 ; for ( final Map . Entry < String , BulkActionResult . Status > entrySet : results . entrySet ( ) ) { final String userId = entrySet . getKey ( ) ; final BulkActionResult . Status status = entrySet . getValue ( ) ; if ( ! BulkActionResult . Status . SUCCESS . equals ( status ) ) { users . put ( userId , status . name ( ) ) ; } else { deletedUsers ++ ; } } userResultManager . genericMessage ( ""Deleted users: "" + deletedUsers ) ; if ( ! users . isEmpty ( ) ) { userResultManager . printFailedUsers ( users ) ; } } else { userResultManager . genericError ( ""Authentication error"" ) ; } } else if ( ""no"" . equalsIgnoreCase ( answer ) ) { userResultManager . genericError ( ""Delete all operation skipped"" ) ; } else { userResultManager . genericError ( ""Invalid parameter, please use [yes/no]"" ) ; } } catch ( final SyncopeClientException ex ) { LOG . error ( ""Error deleting user"" , ex ) ; userResultManager . genericError ( ex . getMessage ( ) ) ; } } else { userResultManager . commandOptionError ( DELETE_ALL_HELP_MESSAGE ) ; } }",Smelly
" public static ConnectionParameterPage [ ] getConnectionParameterPages ( ) { IExtensionRegistry registry = Platform . getExtensionRegistry ( ) ; IExtensionPoint extensionPoint = registry . getExtensionPoint ( ""org.apache.directory.studio.connectionparameterpages"" ) ; IConfigurationElement [ ] members = extensionPoint . getConfigurationElements ( ) ; final Map < String , ConnectionParameterPage > pageMap = new ConcurrentHashMap < > ( ) ; for ( IConfigurationElement member : members ) { try { ConnectionParameterPage page = ( ConnectionParameterPage ) member . createExecutableExtension ( ""class"" ) ; page . setPageId ( member . getAttribute ( ""id"" ) ) ; page . setPageName ( member . getAttribute ( ""name"" ) ) ; page . setPageDescription ( member . getAttribute ( ""description"" ) ) ; page . setPageDependsOnId ( member . getAttribute ( ""dependsOnId"" ) ) ; pageMap . put ( page . getPageId ( ) , page ) ; } catch ( Exception e ) { ConnectionUIPlugin . getDefault ( ) . getLog ( ) . log ( new Status ( IStatus . ERROR , ConnectionUIConstants . PLUGIN_ID , 1 , Messages . getString ( ""ConnectionParameterPageManager.UnableCreateConnectionParamPage"" ) + member . getAttribute ( ""class"" ) , e ) ) ; } } final ConnectionParameterPage [ ] pages = pageMap . values ( ) . toArray ( new ConnectionParameterPage [ 0 ] ) ; Comparator < ? super ConnectionParameterPage > pageComparator = ( ConnectionParameterPage page1 , ConnectionParameterPage page2 ) -> { String dependsOnId1 = page1 . getPageDependsOnId ( ) ; String dependsOnId2 = page2 . getPageDependsOnId ( ) ; do { if ( ( dependsOnId1 == null ) && ( dependsOnId2 != null ) ) { return - 1 ; } else if ( ( dependsOnId2 == null ) && ( dependsOnId1 != null ) ) { return 1 ; } else if ( ( dependsOnId1 != null ) && dependsOnId1 . equals ( page2 . getPageId ( ) ) ) { return 1 ; } else if ( ( dependsOnId2 != null ) && dependsOnId2 . equals ( page1 . getPageId ( ) ) ) { return - 1 ; } ConnectionParameterPage page = pageMap . get ( dependsOnId1 ) ; if ( ( page != null ) && ! page . getPageDependsOnId ( ) . equals ( dependsOnId1 ) ) { dependsOnId1 = page . getPageDependsOnId ( ) ; } else { dependsOnId1 = null ; } } while ( ( dependsOnId1 != null ) && ! dependsOnId1 . equals ( page1 . getPageId ( ) ) ) ; dependsOnId1 = page1 . getPageDependsOnId ( ) ; dependsOnId2 = page2 . getPageDependsOnId ( ) ; do { if ( ( dependsOnId1 == null ) && ( dependsOnId2 != null ) ) { return - 1 ; } else if ( ( dependsOnId2 == null ) && ( dependsOnId1 != null ) ) { return 1 ; } else if ( ( dependsOnId1 != null ) && dependsOnId1 . equals ( page2 . getPageId ( ) ) ) { return 1 ; } else if ( ( dependsOnId2 != null ) && dependsOnId2 . equals ( page1 . getPageId ( ) ) ) { return - 1 ; } ConnectionParameterPage page = pageMap . get ( dependsOnId2 ) ; if ( page == null ) { dependsOnId2 = null ; } else { dependsOnId2 = page . getPageDependsOnId ( ) ; } } while ( ( dependsOnId2 != null ) && ! dependsOnId2 . equals ( page2 . getPageId ( ) ) ) ; return 0 ; } ; Arrays . sort ( pages , pageComparator ) ; return pages ; }",Smelly
" public void read ( org . apache . thrift . protocol . TProtocol prot , show_compact_result struct ) throws org . apache . thrift . TException { TTupleProtocol iprot = ( TTupleProtocol ) prot ; BitSet incoming = iprot . readBitSet ( 1 ) ; if ( incoming . get ( 0 ) ) { struct . success = new ShowCompactResponse ( ) ; struct . success . read ( iprot ) ; struct . setSuccessIsSet ( true ) ; } }",Smelly
" public void read ( org . apache . thrift . protocol . TProtocol prot , Database struct ) throws org . apache . thrift . TException { TTupleProtocol iprot = ( TTupleProtocol ) prot ; BitSet incoming = iprot . readBitSet ( 7 ) ; if ( incoming . get ( 0 ) ) { struct . name = iprot . readString ( ) ; struct . setNameIsSet ( true ) ; } if ( incoming . get ( 1 ) ) { struct . description = iprot . readString ( ) ; struct . setDescriptionIsSet ( true ) ; } if ( incoming . get ( 2 ) ) { struct . locationUri = iprot . readString ( ) ; struct . setLocationUriIsSet ( true ) ; } if ( incoming . get ( 3 ) ) { { org . apache . thrift . protocol . TMap _map100 = new org . apache . thrift . protocol . TMap ( org . apache . thrift . protocol . TType . STRING , org . apache . thrift . protocol . TType . STRING , iprot . readI32 ( ) ) ; struct . parameters = new HashMap < String , String > ( 2 * _map100 . size ) ; for ( int _i101 = 0 ; _i101 < _map100 . size ; ++ _i101 ) { String _key102 ; String _val103 ; _key102 = iprot . readString ( ) ; _val103 = iprot . readString ( ) ; struct . parameters . put ( _key102 , _val103 ) ; } } struct . setParametersIsSet ( true ) ; } if ( incoming . get ( 4 ) ) { struct . privileges = new PrincipalPrivilegeSet ( ) ; struct . privileges . read ( iprot ) ; struct . setPrivilegesIsSet ( true ) ; } if ( incoming . get ( 5 ) ) { struct . ownerName = iprot . readString ( ) ; struct . setOwnerNameIsSet ( true ) ; } if ( incoming . get ( 6 ) ) { struct . ownerType = PrincipalType . findByValue ( iprot . readI32 ( ) ) ; struct . setOwnerTypeIsSet ( true ) ; } }",No
" public static boolean quietlyInvokeMethodsWithAnnotation ( final Class < ? extends Annotation > annotation , final Object instance , final ComponentLog logger , final Object ... args ) { for ( final Method method : instance . getClass ( ) . getMethods ( ) ) { if ( method . isAnnotationPresent ( annotation ) ) { final boolean isAccessible = method . isAccessible ( ) ; method . setAccessible ( true ) ; try { final Class < ? > [ ] argumentTypes = method . getParameterTypes ( ) ; if ( argumentTypes . length > args . length ) { if ( logger == null ) { LOG . error ( ""Unable to invoke method {} on {} because method expects {} parameters but only {} were given"" , new Object [ ] { method . getName ( ) , instance , argumentTypes . length , args . length } ) ; } else { logger . error ( ""Unable to invoke method {} on {} because method expects {} parameters but only {} were given"" , new Object [ ] { method . getName ( ) , instance , argumentTypes . length , args . length } ) ; } return false ; } for ( int i = 0 ; i < argumentTypes . length ; i ++ ) { final Class < ? > argType = argumentTypes [ i ] ; if ( ! argType . isAssignableFrom ( args [ i ] . getClass ( ) ) ) { if ( logger == null ) { LOG . error ( ""Unable to invoke method {} on {} because method parameter {} is expected to be of type {} but argument passed was of type {}"" , new Object [ ] { method . getName ( ) , instance , i , argType , args [ i ] . getClass ( ) } ) ; } else { logger . error ( ""Unable to invoke method {} on {} because method parameter {} is expected to be of type {} but argument passed was of type {}"" , new Object [ ] { method . getName ( ) , instance , i , argType , args [ i ] . getClass ( ) } ) ; } return false ; } } try { if ( argumentTypes . length == args . length ) { method . invoke ( instance , args ) ; } else { final Object [ ] argsToPass = new Object [ argumentTypes . length ] ; for ( int i = 0 ; i < argsToPass . length ; i ++ ) { argsToPass [ i ] = args [ i ] ; } method . invoke ( instance , argsToPass ) ; } } catch ( final InvocationTargetException ite ) { if ( logger == null ) { LOG . error ( ""Unable to invoke method {} on {} due to {}"" , new Object [ ] { method . getName ( ) , instance , ite . getCause ( ) } ) ; LOG . error ( """" , ite . getCause ( ) ) ; } else { logger . error ( ""Unable to invoke method {} on {} due to {}"" , new Object [ ] { method . getName ( ) , instance , ite . getCause ( ) } ) ; } } catch ( final IllegalAccessException | IllegalArgumentException t ) { if ( logger == null ) { LOG . error ( ""Unable to invoke method {} on {} due to {}"" , new Object [ ] { method . getName ( ) , instance , t } ) ; LOG . error ( """" , t ) ; } else { logger . error ( ""Unable to invoke method {} on {} due to {}"" , new Object [ ] { method . getName ( ) , instance , t } ) ; } return false ; } } finally { if ( ! isAccessible ) { method . setAccessible ( false ) ; } } } } return true ; }",Smelly
" public void read ( org . apache . thrift . protocol . TProtocol prot , show_compact_result struct ) throws org . apache . thrift . TException { TTupleProtocol iprot = ( TTupleProtocol ) prot ; BitSet incoming = iprot . readBitSet ( 1 ) ; if ( incoming . get ( 0 ) ) { struct . success = new ShowCompactResponse ( ) ; struct . success . read ( iprot ) ; struct . setSuccessIsSet ( true ) ; } }",Smelly
 public void testVisitor ( ) throws IOException { BxmlNodeVisitor mock = mock ( BxmlNodeVisitor . class ) ; nameStringNode . accept ( mock ) ; verify ( mock ) . visit ( nameStringNode ) ; verifyNoMoreInteractions ( mock ) ; },No
" public void read ( org . apache . thrift . protocol . TProtocol prot , onReceivedZeppelinResource_result struct ) throws org . apache . thrift . TException { TTupleProtocol iprot = ( TTupleProtocol ) prot ; }",Smelly
" public void read ( org . apache . thrift . protocol . TProtocol prot , checkNamespaceClass_result struct ) throws org . apache . thrift . TException { TTupleProtocol iprot = ( TTupleProtocol ) prot ; BitSet incoming = iprot . readBitSet ( 3 ) ; if ( incoming . get ( 0 ) ) { struct . success = iprot . readBool ( ) ; struct . setSuccessIsSet ( true ) ; } if ( incoming . get ( 1 ) ) { struct . sec = new ThriftSecurityException ( ) ; struct . sec . read ( iprot ) ; struct . setSecIsSet ( true ) ; } if ( incoming . get ( 2 ) ) { struct . tope = new ThriftTableOperationException ( ) ; struct . tope . read ( iprot ) ; struct . setTopeIsSet ( true ) ; } }",Smelly
" public boolean validatePolicy ( AssertionInfoMap aim , Message message , List < WSSecurityEngineResult > results , List < WSSecurityEngineResult > signedResults , List < WSSecurityEngineResult > encryptedResults ) { Collection < AssertionInfo > ais = aim . get ( SP12Constants . SIGNED_ENDORSING_ENCRYPTED_SUPPORTING_TOKENS ) ; if ( ais == null || ais . isEmpty ( ) ) { return true ; } setMessage ( message ) ; setResults ( results ) ; setSignedResults ( signedResults ) ; setEncryptedResults ( encryptedResults ) ; for ( AssertionInfo ai : ais ) { SupportingToken binding = ( SupportingToken ) ai . getAssertion ( ) ; if ( SPConstants . SupportTokenType . SUPPORTING_TOKEN_SIGNED_ENDORSING_ENCRYPTED != binding . getTokenType ( ) ) { continue ; } ai . setAsserted ( true ) ; setSignedParts ( binding . getSignedParts ( ) ) ; setEncryptedParts ( binding . getEncryptedParts ( ) ) ; setSignedElements ( binding . getSignedElements ( ) ) ; setEncryptedElements ( binding . getEncryptedElements ( ) ) ; List < Token > tokens = binding . getTokens ( ) ; for ( Token token : tokens ) { if ( ! isTokenRequired ( token , message ) ) { continue ; } boolean derived = token . isDerivedKeys ( ) ; setDerived ( derived ) ; boolean processingFailed = false ; if ( token instanceof KerberosToken ) { if ( ! processKerberosTokens ( ) ) { processingFailed = true ; } } else if ( token instanceof SamlToken ) { if ( ! processSAMLTokens ( ) ) { processingFailed = true ; } } else if ( token instanceof X509Token ) { if ( ! processX509Tokens ( ) ) { processingFailed = true ; } } else if ( token instanceof KeyValueToken ) { if ( ! processKeyValueTokens ( ) ) { processingFailed = true ; } } else if ( token instanceof UsernameToken ) { if ( ! processUsernameTokens ( ) ) { processingFailed = true ; } } else if ( token instanceof SecurityContextToken ) { if ( ! processSCTokens ( ) ) { processingFailed = true ; } } else if ( ! ( token instanceof IssuedToken ) ) { processingFailed = true ; } if ( processingFailed ) { ai . setNotAsserted ( ""The received token does not match the signed endorsing encrypted "" + ""supporting token requirement"" ) ; return false ; } } } return true ; }",Smelly
" public static void main ( String [ ] args ) throws Exception { final ParameterTool parameterTool = ParameterTool . fromArgs ( args ) ; if ( parameterTool . getNumberOfParameters ( ) < 3 ) { System . out . println ( ""Missing parameters!"" ) ; System . out . println ( ""Usage: pulsar --service-url <pulsar-service-url> --input-topic <topic> --subscription <sub> --output-topic <topic>"" ) ; return ; } StreamExecutionEnvironment env = StreamExecutionEnvironment . getExecutionEnvironment ( ) ; env . getConfig ( ) . disableSysoutLogging ( ) ; env . getConfig ( ) . setRestartStrategy ( RestartStrategies . fixedDelayRestart ( 4 , 10000 ) ) ; env . enableCheckpointing ( 5000 ) ; env . getConfig ( ) . setGlobalJobParameters ( parameterTool ) ; env . setStreamTimeCharacteristic ( TimeCharacteristic . ProcessingTime ) ; StreamTableEnvironment tableEnvironment = StreamTableEnvironment . getTableEnvironment ( env ) ; String serviceUrl = parameterTool . getRequired ( ""service-url"" ) ; String inputTopic = parameterTool . getRequired ( ""input-topic"" ) ; String subscription = parameterTool . get ( ""subscription"" , ""flink-examples"" ) ; String outputTopic = parameterTool . get ( ""output-topic"" , null ) ; int parallelism = parameterTool . getInt ( ""parallelism"" , 1 ) ; System . out . println ( ""Parameters:"" ) ; System . out . println ( ""\tServiceUrl:\t"" + serviceUrl ) ; System . out . println ( ""\tInputTopic:\t"" + inputTopic ) ; System . out . println ( ""\tSubscription:\t"" + subscription ) ; System . out . println ( ""\tOutputTopic:\t"" + outputTopic ) ; System . out . println ( ""\tParallelism:\t"" + parallelism ) ; PulsarSourceBuilder < String > builder = PulsarSourceBuilder . builder ( new SimpleStringSchema ( ) ) . serviceUrl ( serviceUrl ) . topic ( inputTopic ) . subscriptionName ( subscription ) ; SourceFunction < String > src = builder . build ( ) ; DataStream < String > input = env . addSource ( src ) ; DataStream < WordWithCount > wc = input . flatMap ( ( FlatMapFunction < String , WordWithCount > ) ( line , collector ) -> { for ( String word : line . split ( ""\\s"" ) ) { collector . collect ( new WordWithCount ( word , 1 ) ) ; } } ) . returns ( WordWithCount . class ) . keyBy ( ROUTING_KEY ) . timeWindow ( Time . seconds ( 5 ) ) . reduce ( ( ReduceFunction < WordWithCount > ) ( c1 , c2 ) -> new WordWithCount ( c1 . word , c1 . count + c2 . count ) ) ; tableEnvironment . registerDataStream ( ""wc"" , wc ) ; Table table = tableEnvironment . sqlQuery ( ""select word, `count` from wc"" ) ; table . printSchema ( ) ; TableSink sink = null ; if ( null != outputTopic ) { sink = new PulsarJsonTableSink ( serviceUrl , outputTopic , new AuthenticationDisabled ( ) , ROUTING_KEY ) ; } else { sink = new CsvTableSink ( ""./examples/file"" , ""|"" ) ; } table . writeToSink ( sink ) ; env . execute ( ""Pulsar Stream WordCount"" ) ; }",Smelly
 public static void main ( String [ ] args ) { processCommandLineArgs ( args ) ; },No
" public void read ( org . apache . thrift . protocol . TProtocol prot , getFollowing_result struct ) throws org . apache . thrift . TException { TTupleProtocol iprot = ( TTupleProtocol ) prot ; BitSet incoming = iprot . readBitSet ( 1 ) ; if ( incoming . get ( 0 ) ) { struct . success = new Key ( ) ; struct . success . read ( iprot ) ; struct . setSuccessIsSet ( true ) ; } }",Smelly
" public void read ( org . apache . thrift . protocol . TProtocol prot , TI32Column struct ) throws org . apache . thrift . TException { TTupleProtocol iprot = ( TTupleProtocol ) prot ; { org . apache . thrift . protocol . TList _list83 = new org . apache . thrift . protocol . TList ( org . apache . thrift . protocol . TType . I32 , iprot . readI32 ( ) ) ; struct . values = new ArrayList < Integer > ( _list83 . size ) ; for ( int _i84 = 0 ; _i84 < _list83 . size ; ++ _i84 ) { int _elem85 ; _elem85 = iprot . readI32 ( ) ; struct . values . add ( _elem85 ) ; } } struct . setValuesIsSet ( true ) ; struct . nulls = iprot . readBinary ( ) ; struct . setNullsIsSet ( true ) ; }",Smelly
" public void read ( org . apache . thrift . protocol . TProtocol prot , show_compact_result struct ) throws org . apache . thrift . TException { TTupleProtocol iprot = ( TTupleProtocol ) prot ; BitSet incoming = iprot . readBitSet ( 1 ) ; if ( incoming . get ( 0 ) ) { struct . success = new ShowCompactResponse ( ) ; struct . success . read ( iprot ) ; struct . setSuccessIsSet ( true ) ; } }",Smelly
" public void read ( org . apache . thrift . protocol . TProtocol prot , replicateKeyValues_result struct ) throws org . apache . thrift . TException { TTupleProtocol iprot = ( TTupleProtocol ) prot ; BitSet incoming = iprot . readBitSet ( 2 ) ; if ( incoming . get ( 0 ) ) { struct . success = iprot . readI64 ( ) ; struct . setSuccessIsSet ( true ) ; } if ( incoming . get ( 1 ) ) { struct . e = new RemoteReplicationException ( ) ; struct . e . read ( iprot ) ; struct . setEIsSet ( true ) ; } }",Smelly
" public static boolean userLogin ( DispatchContext ctx , Map < String , ? > context ) { Debug . logVerbose ( ""Starting LDAP authentication"" , module ) ; Properties env = UtilProperties . getProperties ( ""jndiLdap"" ) ; String username = ( String ) context . get ( ""login.username"" ) ; if ( username == null ) { username = ( String ) context . get ( ""username"" ) ; } String password = ( String ) context . get ( ""login.password"" ) ; if ( password == null ) { password = ( String ) context . get ( ""password"" ) ; } String dn = null ; Delegator delegator = ctx . getDelegator ( ) ; boolean isServiceAuth = context . get ( ""isServiceAuth"" ) != null && ( ( Boolean ) context . get ( ""isServiceAuth"" ) ) . booleanValue ( ) ; GenericValue userLogin = null ; try { userLogin = delegator . findOne ( ""UserLogin"" , isServiceAuth , ""userLoginId"" , username ) ; } catch ( GenericEntityException e ) { Debug . logWarning ( e , """" , module ) ; } if ( userLogin != null ) { dn = userLogin . getString ( ""userLdapDn"" ) ; } if ( UtilValidate . isEmpty ( dn ) ) { String dnTemplate = ( String ) env . get ( ""ldap.dn.template"" ) ; if ( dnTemplate != null ) { dn = dnTemplate . replace ( ""%u"" , username ) ; } Debug . logVerbose ( ""Using DN template: "" + dn , module ) ; } else { Debug . logVerbose ( ""Using UserLogin.userLdapDn: "" + dn , module ) ; } env . put ( Context . SECURITY_PRINCIPAL , dn ) ; env . put ( Context . SECURITY_CREDENTIALS , password ) ; try { DirContext ldapCtx = new InitialDirContext ( env ) ; ldapCtx . close ( ) ; } catch ( NamingException e ) { Debug . logVerbose ( ""LDAP authentication failed: "" + e . getMessage ( ) , module ) ; return false ; } Debug . logVerbose ( ""LDAP authentication succeeded"" , module ) ; if ( ! ""true"" . equals ( env . get ( ""ldap.synchronize.passwords"" ) ) ) { return true ; } if ( userLogin != null ) { boolean useEncryption = ""true"" . equals ( UtilProperties . getPropertyValue ( ""security.properties"" , ""password.encrypt"" ) ) ; String currentPassword = userLogin . getString ( ""currentPassword"" ) ; boolean samePassword ; if ( useEncryption ) { samePassword = HashCrypt . comparePassword ( currentPassword , LoginServices . getHashType ( ) , password ) ; } else { samePassword = currentPassword . equals ( password ) ; } if ( ! samePassword ) { Debug . logVerbose ( ""Starting password synchronization"" , module ) ; userLogin . set ( ""currentPassword"" , useEncryption ? HashCrypt . cryptUTF8 ( LoginServices . getHashType ( ) , null , password ) : password , false ) ; Transaction parentTx = null ; boolean beganTransaction = false ; try { try { parentTx = TransactionUtil . suspend ( ) ; } catch ( GenericTransactionException e ) { Debug . logError ( e , ""Could not suspend transaction: "" + e . getMessage ( ) , module ) ; } try { beganTransaction = TransactionUtil . begin ( ) ; userLogin . store ( ) ; } catch ( GenericEntityException e ) { Debug . logError ( e , ""Error saving UserLogin"" , module ) ; try { TransactionUtil . rollback ( beganTransaction , ""Error saving UserLogin"" , e ) ; } catch ( GenericTransactionException e2 ) { Debug . logError ( e2 , ""Could not rollback nested transaction: "" + e2 . getMessage ( ) , module ) ; } } finally { try { TransactionUtil . commit ( beganTransaction ) ; Debug . logVerbose ( ""Password synchronized"" , module ) ; } catch ( GenericTransactionException e ) { Debug . logError ( e , ""Could not commit nested transaction: "" + e . getMessage ( ) , module ) ; } } } finally { if ( parentTx != null ) { try { TransactionUtil . resume ( parentTx ) ; Debug . logVerbose ( ""Resumed the parent transaction."" , module ) ; } catch ( GenericTransactionException e ) { Debug . logError ( e , ""Could not resume parent nested transaction: "" + e . getMessage ( ) , module ) ; } } } } } return true ; }",Smelly
" public void absoluteBaseURI ( ) { String absoluteBase = ""test:///absolute/"" ; FontManager fontManager = setBaseAndGetManager ( absoluteBase ) ; assertEquals ( URI . create ( absoluteBase ) , fontManager . getResourceResolver ( ) . getBaseURI ( ) ) ; }",No
" public void onAuthenticationFailure ( HttpServletRequest request , HttpServletResponse response , AuthenticationException exception ) throws IOException , ServletException { String ajaxRequestHeader = request . getHeader ( ""X-Requested-With"" ) ; if ( logger . isDebugEnabled ( ) ) { logger . debug ( ""commence() X-Requested-With="" + ajaxRequestHeader ) ; } response . setContentType ( ""application/json;charset=UTF-8"" ) ; response . setHeader ( ""Cache-Control"" , ""no-cache"" ) ; response . setHeader ( ""X-Frame-Options"" , ""DENY"" ) ; String jsonResp = """" ; try { String msg = exception . getMessage ( ) ; VXResponse vXResponse = new VXResponse ( ) ; if ( msg != null && ! msg . isEmpty ( ) ) { if ( CLIUtil . getMessage ( ""AbstractUserDetailsAuthenticationProvider.badCredentials"" , request ) . equalsIgnoreCase ( msg ) ) { vXResponse . setStatusCode ( HttpServletResponse . SC_UNAUTHORIZED ) ; vXResponse . setMsgDesc ( ""The username or password you entered is incorrect..."" ) ; logger . info ( ""Error Message : "" + msg ) ; } else if ( msg . contains ( ""Could not get JDBC Connection; nested exception is java.sql.SQLException: Connections could not be acquired from the underlying database!"" ) ) { vXResponse . setStatusCode ( HttpServletResponse . SC_UNAUTHORIZED ) ; vXResponse . setMsgDesc ( ""Unable to connect to DB..."" ) ; } else if ( msg . contains ( ""Communications link failure"" ) ) { vXResponse . setStatusCode ( HttpServletResponse . SC_UNAUTHORIZED ) ; vXResponse . setMsgDesc ( ""Unable to connect to DB..."" ) ; } else if ( CLIUtil . getMessage ( ""AbstractUserDetailsAuthenticationProvider.disabled"" , request ) . equalsIgnoreCase ( msg ) ) { vXResponse . setStatusCode ( HttpServletResponse . SC_UNAUTHORIZED ) ; vXResponse . setMsgDesc ( ""The username or password you entered is disable..."" ) ; } } jsonResp = jsonUtil . writeObjectAsString ( vXResponse ) ; response . getWriter ( ) . write ( jsonResp ) ; response . setStatus ( HttpServletResponse . SC_UNAUTHORIZED ) ; } catch ( IOException e ) { logger . info ( ""Error while writing JSON in HttpServletResponse"" ) ; } if ( ajaxRequestHeader != null && ""XMLHttpRequest"" . equalsIgnoreCase ( ajaxRequestHeader ) ) { if ( logger . isDebugEnabled ( ) ) { logger . debug ( ""Sending login failed response : "" + jsonResp ) ; } } }",Smelly
" public void read ( org . apache . thrift . protocol . TProtocol prot , getChildDataProducts_result struct ) throws org . apache . thrift . TException { TTupleProtocol iprot = ( TTupleProtocol ) prot ; BitSet incoming = iprot . readBitSet ( 5 ) ; if ( incoming . get ( 0 ) ) { { org . apache . thrift . protocol . TList _list283 = new org . apache . thrift . protocol . TList ( org . apache . thrift . protocol . TType . STRUCT , iprot . readI32 ( ) ) ; struct . success = new ArrayList < org . apache . airavata . model . data . replica . DataProductModel > ( _list283 . size ) ; org . apache . airavata . model . data . replica . DataProductModel _elem284 ; for ( int _i285 = 0 ; _i285 < _list283 . size ; ++ _i285 ) { _elem284 = new org . apache . airavata . model . data . replica . DataProductModel ( ) ; _elem284 . read ( iprot ) ; struct . success . add ( _elem284 ) ; } } struct . setSuccessIsSet ( true ) ; } if ( incoming . get ( 1 ) ) { struct . ire = new org . apache . airavata . model . error . InvalidRequestException ( ) ; struct . ire . read ( iprot ) ; struct . setIreIsSet ( true ) ; } if ( incoming . get ( 2 ) ) { struct . ace = new org . apache . airavata . model . error . AiravataClientException ( ) ; struct . ace . read ( iprot ) ; struct . setAceIsSet ( true ) ; } if ( incoming . get ( 3 ) ) { struct . ase = new org . apache . airavata . model . error . AiravataSystemException ( ) ; struct . ase . read ( iprot ) ; struct . setAseIsSet ( true ) ; } if ( incoming . get ( 4 ) ) { struct . ae = new org . apache . airavata . model . error . AuthorizationException ( ) ; struct . ae . read ( iprot ) ; struct . setAeIsSet ( true ) ; } }",Smelly
" public void renderHead ( final IHeaderResponse response ) { super . renderHead ( response ) ; response . render ( CssHeaderItem . forReference ( new CssResourceReference ( DefaultCssAutoCompleteTextField . class , ""DefaultCssAutoCompleteTextField.css"" ) ) ) ; }",No
" public static < D > D detach ( final Object object ) { if ( object instanceof Element ) { return ( D ) ReferenceFactory . detach ( ( Element ) object ) ; } else if ( object instanceof Property ) { return ( D ) ReferenceFactory . detach ( ( Property ) object ) ; } else if ( object instanceof Path ) { return ( D ) ReferenceFactory . detach ( ( Path ) object ) ; } else if ( object instanceof List ) { final List list = new ArrayList ( ( ( List ) object ) . size ( ) ) ; for ( final Object item : ( List ) object ) { list . add ( ReferenceFactory . detach ( item ) ) ; } return ( D ) list ; } else if ( object instanceof BulkSet ) { final BulkSet set = new BulkSet ( ) ; for ( Map . Entry < Object , Long > entry : ( ( BulkSet < Object > ) object ) . asBulk ( ) . entrySet ( ) ) { set . add ( ReferenceFactory . detach ( entry . getKey ( ) ) , entry . getValue ( ) ) ; } return ( D ) set ; } else if ( object instanceof Set ) { final Set set = object instanceof LinkedHashSet ? new LinkedHashSet ( ( ( Set ) object ) . size ( ) ) : new HashSet ( ( ( Set ) object ) . size ( ) ) ; for ( final Object item : ( Set ) object ) { set . add ( ReferenceFactory . detach ( item ) ) ; } return ( D ) set ; } else if ( object instanceof Map ) { final Map map = object instanceof Tree ? new Tree ( ) : object instanceof LinkedHashMap ? new LinkedHashMap ( ( ( Map ) object ) . size ( ) ) : new HashMap ( ( ( Map ) object ) . size ( ) ) ; for ( final Map . Entry < Object , Object > entry : ( ( Map < Object , Object > ) object ) . entrySet ( ) ) { map . put ( ReferenceFactory . detach ( entry . getKey ( ) ) , ReferenceFactory . detach ( entry . getValue ( ) ) ) ; } return ( D ) map ; } else { return ( D ) object ; } }",No
" public void testAnnotatedType ( ) { AnnotatedType < PortableType1 > type = WebBeansContext . getInstance ( ) . getAnnotatedElementFactory ( ) . newAnnotatedType ( PortableType1 . class ) ; Set < Annotation > annotations = type . getAnnotations ( ) ; Set < Class < ? extends Annotation > > clazzesAnnots = new HashSet < Class < ? extends Annotation > > ( ) ; for ( Annotation ann : annotations ) { clazzesAnnots . add ( ann . annotationType ( ) ) ; } Assert . assertTrue ( clazzesAnnots . contains ( Named . class ) ) ; Assert . assertTrue ( clazzesAnnots . contains ( Default . class ) ) ; Assert . assertTrue ( clazzesAnnots . contains ( Binding1 . class ) ) ; Assert . assertTrue ( clazzesAnnots . contains ( Binding2 . class ) ) ; Assert . assertTrue ( clazzesAnnots . contains ( Interceptor . class ) ) ; Set < AnnotatedConstructor < PortableType1 > > cs = type . getConstructors ( ) ; Assert . assertEquals ( 1 , cs . size ( ) ) ; AnnotatedConstructor < PortableType1 > c = cs . iterator ( ) . next ( ) ; Assert . assertTrue ( c . isAnnotationPresent ( Inject . class ) ) ; Set < AnnotatedField < ? super PortableType1 > > fields = type . getFields ( ) ; Assert . assertEquals ( 3 , fields . size ( ) ) ; for ( AnnotatedField < ? super PortableType1 > field : fields ) { if ( field . getJavaMember ( ) . getName ( ) . equals ( ""payment"" ) ) { Assert . assertTrue ( field . isAnnotationPresent ( Default . class ) ) ; Assert . assertEquals ( IPayment . class , field . getBaseType ( ) ) ; } else if ( field . getJavaMember ( ) . getName ( ) . equals ( ""book"" ) ) { Assert . assertTrue ( field . isAnnotationPresent ( Default . class ) ) ; Assert . assertTrue ( field . isAnnotationPresent ( Binding2 . class ) ) ; Assert . assertEquals ( Book . class , field . getBaseType ( ) ) ; } else { Assert . assertTrue ( field . isAnnotationPresent ( Produces . class ) ) ; Assert . assertTrue ( field . isAnnotationPresent ( BindingType2 . class ) ) ; Assert . assertEquals ( CheckWithCheckPayment . class , field . getBaseType ( ) ) ; } } Set < AnnotatedMethod < ? super PortableType1 > > methods = type . getMethods ( ) ; Assert . assertEquals ( 8 , methods . size ( ) ) ; for ( AnnotatedMethod < ? super PortableType1 > method : methods ) { if ( method . getJavaMember ( ) . getName ( ) . equals ( ""getDao"" ) ) { Assert . assertTrue ( method . isAnnotationPresent ( Produces . class ) ) ; Assert . assertEquals ( Dao . class , ( ( ParameterizedType ) method . getBaseType ( ) ) . getRawType ( ) ) ; List < ? > list = method . getParameters ( ) ; Assert . assertTrue ( list . size ( ) == 1 ) ; AnnotatedParameter < ? > param = ( AnnotatedParameter < ? > ) list . iterator ( ) . next ( ) ; Assert . assertTrue ( param . getAnnotations ( ) . size ( ) == 1 ) ; Assert . assertTrue ( param . isAnnotationPresent ( BindingType1 . class ) ) ; } else if ( method . getJavaMember ( ) . getName ( ) . equals ( ""notify"" ) ) { Assert . assertTrue ( method . getAnnotations ( ) . isEmpty ( ) ) ; Assert . assertEquals ( void . class , method . getBaseType ( ) ) ; List < ? > list = method . getParameters ( ) ; Assert . assertTrue ( list . size ( ) == 1 ) ; AnnotatedParameter < ? > param = ( AnnotatedParameter < ? > ) list . iterator ( ) . next ( ) ; Assert . assertTrue ( param . getAnnotations ( ) . size ( ) == 2 ) ; Assert . assertTrue ( param . isAnnotationPresent ( Binding2 . class ) ) ; Assert . assertTrue ( param . isAnnotationPresent ( Observes . class ) ) ; } } }",Smelly
" public void read ( org . apache . thrift . protocol . TProtocol prot , drainReplicationTable_result struct ) throws org . apache . thrift . TException { TTupleProtocol iprot = ( TTupleProtocol ) prot ; BitSet incoming = iprot . readBitSet ( 1 ) ; if ( incoming . get ( 0 ) ) { struct . success = iprot . readBool ( ) ; struct . setSuccessIsSet ( true ) ; } }",Smelly
" public void testEOF ( ) throws IOException { ByteArrayOutputStream baos = new ByteArrayOutputStream ( ) ; Encoder e = EncoderFactory . get ( ) . binaryEncoder ( baos , null ) ; e . writeLong ( 0x10000000000000L ) ; e . flush ( ) ; Decoder d = newDecoder ( new ByteArrayInputStream ( baos . toByteArray ( ) ) ) ; Assert . assertEquals ( 0x10000000000000L , d . readLong ( ) ) ; d . readInt ( ) ; }",No
 private static < S extends org . apache . thrift . scheme . IScheme > S scheme ( org . apache . thrift . protocol . TProtocol proto ) { return ( org . apache . thrift . scheme . StandardScheme . class . equals ( proto . getScheme ( ) ) ? STANDARD_SCHEME_FACTORY : TUPLE_SCHEME_FACTORY ) . getScheme ( ) ; },No
" public Control createControl ( Composite parent ) { initializeDialogUnits ( parent ) ; Composite composite = new Composite ( parent , SWT . NONE ) ; composite . setLayout ( new GridLayout ( ) ) ; return composite ; }",No
" public void read ( org . apache . thrift . protocol . TProtocol prot , TabletServerStatus struct ) throws org . apache . thrift . TException { TTupleProtocol iprot = ( TTupleProtocol ) prot ; BitSet incoming = iprot . readBitSet ( 13 ) ; if ( incoming . get ( 0 ) ) { { org . apache . thrift . protocol . TMap _map11 = new org . apache . thrift . protocol . TMap ( org . apache . thrift . protocol . TType . STRING , org . apache . thrift . protocol . TType . STRUCT , iprot . readI32 ( ) ) ; struct . tableMap = new HashMap < String , TableInfo > ( 2 * _map11 . size ) ; for ( int _i12 = 0 ; _i12 < _map11 . size ; ++ _i12 ) { String _key13 ; TableInfo _val14 ; _key13 = iprot . readString ( ) ; _val14 = new TableInfo ( ) ; _val14 . read ( iprot ) ; struct . tableMap . put ( _key13 , _val14 ) ; } } struct . setTableMapIsSet ( true ) ; } if ( incoming . get ( 1 ) ) { struct . lastContact = iprot . readI64 ( ) ; struct . setLastContactIsSet ( true ) ; } if ( incoming . get ( 2 ) ) { struct . name = iprot . readString ( ) ; struct . setNameIsSet ( true ) ; } if ( incoming . get ( 3 ) ) { struct . osLoad = iprot . readDouble ( ) ; struct . setOsLoadIsSet ( true ) ; } if ( incoming . get ( 4 ) ) { struct . holdTime = iprot . readI64 ( ) ; struct . setHoldTimeIsSet ( true ) ; } if ( incoming . get ( 5 ) ) { struct . lookups = iprot . readI64 ( ) ; struct . setLookupsIsSet ( true ) ; } if ( incoming . get ( 6 ) ) { struct . indexCacheHits = iprot . readI64 ( ) ; struct . setIndexCacheHitsIsSet ( true ) ; } if ( incoming . get ( 7 ) ) { struct . indexCacheRequest = iprot . readI64 ( ) ; struct . setIndexCacheRequestIsSet ( true ) ; } if ( incoming . get ( 8 ) ) { struct . dataCacheHits = iprot . readI64 ( ) ; struct . setDataCacheHitsIsSet ( true ) ; } if ( incoming . get ( 9 ) ) { struct . dataCacheRequest = iprot . readI64 ( ) ; struct . setDataCacheRequestIsSet ( true ) ; } if ( incoming . get ( 10 ) ) { { org . apache . thrift . protocol . TList _list15 = new org . apache . thrift . protocol . TList ( org . apache . thrift . protocol . TType . STRUCT , iprot . readI32 ( ) ) ; struct . logSorts = new ArrayList < RecoveryStatus > ( _list15 . size ) ; for ( int _i16 = 0 ; _i16 < _list15 . size ; ++ _i16 ) { RecoveryStatus _elem17 ; _elem17 = new RecoveryStatus ( ) ; _elem17 . read ( iprot ) ; struct . logSorts . add ( _elem17 ) ; } } struct . setLogSortsIsSet ( true ) ; } if ( incoming . get ( 11 ) ) { struct . flushs = iprot . readI64 ( ) ; struct . setFlushsIsSet ( true ) ; } if ( incoming . get ( 12 ) ) { struct . syncs = iprot . readI64 ( ) ; struct . setSyncsIsSet ( true ) ; } }",Smelly
" public void read ( org . apache . thrift . protocol . TProtocol prot , show_compact_result struct ) throws org . apache . thrift . TException { TTupleProtocol iprot = ( TTupleProtocol ) prot ; BitSet incoming = iprot . readBitSet ( 1 ) ; if ( incoming . get ( 0 ) ) { struct . success = new ShowCompactResponse ( ) ; struct . success . read ( iprot ) ; struct . setSuccessIsSet ( true ) ; } }",No
" public void read ( org . apache . thrift . protocol . TProtocol prot , getChildDataProducts_result struct ) throws org . apache . thrift . TException { TTupleProtocol iprot = ( TTupleProtocol ) prot ; BitSet incoming = iprot . readBitSet ( 5 ) ; if ( incoming . get ( 0 ) ) { { org . apache . thrift . protocol . TList _list283 = new org . apache . thrift . protocol . TList ( org . apache . thrift . protocol . TType . STRUCT , iprot . readI32 ( ) ) ; struct . success = new ArrayList < org . apache . airavata . model . data . replica . DataProductModel > ( _list283 . size ) ; org . apache . airavata . model . data . replica . DataProductModel _elem284 ; for ( int _i285 = 0 ; _i285 < _list283 . size ; ++ _i285 ) { _elem284 = new org . apache . airavata . model . data . replica . DataProductModel ( ) ; _elem284 . read ( iprot ) ; struct . success . add ( _elem284 ) ; } } struct . setSuccessIsSet ( true ) ; } if ( incoming . get ( 1 ) ) { struct . ire = new org . apache . airavata . model . error . InvalidRequestException ( ) ; struct . ire . read ( iprot ) ; struct . setIreIsSet ( true ) ; } if ( incoming . get ( 2 ) ) { struct . ace = new org . apache . airavata . model . error . AiravataClientException ( ) ; struct . ace . read ( iprot ) ; struct . setAceIsSet ( true ) ; } if ( incoming . get ( 3 ) ) { struct . ase = new org . apache . airavata . model . error . AiravataSystemException ( ) ; struct . ase . read ( iprot ) ; struct . setAseIsSet ( true ) ; } if ( incoming . get ( 4 ) ) { struct . ae = new org . apache . airavata . model . error . AuthorizationException ( ) ; struct . ae . read ( iprot ) ; struct . setAeIsSet ( true ) ; } }",Smelly
" public void read ( org . apache . thrift . protocol . TProtocol prot , getFollowing_result struct ) throws org . apache . thrift . TException { TTupleProtocol iprot = ( TTupleProtocol ) prot ; BitSet incoming = iprot . readBitSet ( 1 ) ; if ( incoming . get ( 0 ) ) { struct . success = new Key ( ) ; struct . success . read ( iprot ) ; struct . setSuccessIsSet ( true ) ; } }",Smelly
" abstract void write ( DataOutput out , ReferenceMap referenceMap ) throws IOException ;",No
" public void read ( org . apache . thrift . protocol . TProtocol prot , drainReplicationTable_result struct ) throws org . apache . thrift . TException { TTupleProtocol iprot = ( TTupleProtocol ) prot ; BitSet incoming = iprot . readBitSet ( 1 ) ; if ( incoming . get ( 0 ) ) { struct . success = iprot . readBool ( ) ; struct . setSuccessIsSet ( true ) ; } }",No
" public static IDBInterface make ( IThreadContext context , String databaseName , String userName , String password ) throws ManifoldCFException { String dbName = dbinterfaceInstancePrefix + databaseName ; Object x = context . get ( dbName ) ; if ( x == null || ! ( x instanceof IDBInterface ) ) { String implementationClass = ManifoldCF . getProperty ( ManifoldCF . databaseImplementation ) ; if ( implementationClass == null ) implementationClass = ""org.apache.manifoldcf.core.database.DBInterfacePostgreSQL"" ; try { Class c = Class . forName ( implementationClass ) ; Constructor constructor = c . getConstructor ( new Class [ ] { IThreadContext . class , String . class , String . class , String . class } ) ; x = constructor . newInstance ( new Object [ ] { context , databaseName , userName , password } ) ; if ( ! ( x instanceof IDBInterface ) ) throw new ManifoldCFException ( ""Database implementation class "" + implementationClass + "" does not implement IDBInterface"" , ManifoldCFException . SETUP_ERROR ) ; context . save ( dbName , x ) ; } catch ( ClassNotFoundException e ) { throw new ManifoldCFException ( ""Database implementation class "" + implementationClass + "" could not be found: "" + e . getMessage ( ) , e , ManifoldCFException . SETUP_ERROR ) ; } catch ( ExceptionInInitializerError e ) { throw new ManifoldCFException ( ""Database implementation class "" + implementationClass + "" could not be instantiated: "" + e . getMessage ( ) , e , ManifoldCFException . SETUP_ERROR ) ; } catch ( LinkageError e ) { throw new ManifoldCFException ( ""Database implementation class "" + implementationClass + "" could not be linked: "" + e . getMessage ( ) , e , ManifoldCFException . SETUP_ERROR ) ; } catch ( InstantiationException e ) { throw new ManifoldCFException ( ""Database implementation class "" + implementationClass + "" could not be instantiated: "" + e . getMessage ( ) , e , ManifoldCFException . SETUP_ERROR ) ; } catch ( InvocationTargetException e ) { throw new ManifoldCFException ( ""Database implementation class "" + implementationClass + "" could not be instantiated: "" + e . getMessage ( ) , e , ManifoldCFException . SETUP_ERROR ) ; } catch ( NoSuchMethodException e ) { throw new ManifoldCFException ( ""Database implementation class "" + implementationClass + "" had no constructor taking (IThreadContext, String, String, String): "" + e . getMessage ( ) , e , ManifoldCFException . SETUP_ERROR ) ; } catch ( IllegalAccessException e ) { throw new ManifoldCFException ( ""Database implementation class "" + implementationClass + "" had no public constructor taking (IThreadContext, String, String, String): "" + e . getMessage ( ) , e , ManifoldCFException . SETUP_ERROR ) ; } } return ( IDBInterface ) x ; }",Smelly
" public void read ( org . apache . thrift . protocol . TProtocol prot , show_compact_result struct ) throws org . apache . thrift . TException { TTupleProtocol iprot = ( TTupleProtocol ) prot ; BitSet incoming = iprot . readBitSet ( 1 ) ; if ( incoming . get ( 0 ) ) { struct . success = new ShowCompactResponse ( ) ; struct . success . read ( iprot ) ; struct . setSuccessIsSet ( true ) ; } }",Smelly
 public final void setTitle ( String title ) { this . title = title ; },No
" void runCmd ( ) throws Exception { admin . sinks ( ) . getBuiltInSinks ( ) . stream ( ) . filter ( x -> isNotBlank ( x . getSinkClass ( ) ) ) . forEach ( connector -> { System . out . println ( connector . getName ( ) ) ; System . out . println ( WordUtils . wrap ( connector . getDescription ( ) , 80 ) ) ; System . out . println ( ""----------------------------------------"" ) ; } ) ; }",No
" public void read ( org . apache . thrift . protocol . TProtocol prot , ComputationalResourceSchedulingModel struct ) throws org . apache . thrift . TException { TTupleProtocol iprot = ( TTupleProtocol ) prot ; BitSet incoming = iprot . readBitSet ( 12 ) ; if ( incoming . get ( 0 ) ) { struct . resourceHostId = iprot . readString ( ) ; struct . setResourceHostIdIsSet ( true ) ; } if ( incoming . get ( 1 ) ) { struct . totalCPUCount = iprot . readI32 ( ) ; struct . setTotalCPUCountIsSet ( true ) ; } if ( incoming . get ( 2 ) ) { struct . nodeCount = iprot . readI32 ( ) ; struct . setNodeCountIsSet ( true ) ; } if ( incoming . get ( 3 ) ) { struct . numberOfThreads = iprot . readI32 ( ) ; struct . setNumberOfThreadsIsSet ( true ) ; } if ( incoming . get ( 4 ) ) { struct . queueName = iprot . readString ( ) ; struct . setQueueNameIsSet ( true ) ; } if ( incoming . get ( 5 ) ) { struct . wallTimeLimit = iprot . readI32 ( ) ; struct . setWallTimeLimitIsSet ( true ) ; } if ( incoming . get ( 6 ) ) { struct . totalPhysicalMemory = iprot . readI32 ( ) ; struct . setTotalPhysicalMemoryIsSet ( true ) ; } if ( incoming . get ( 7 ) ) { struct . chessisNumber = iprot . readString ( ) ; struct . setChessisNumberIsSet ( true ) ; } if ( incoming . get ( 8 ) ) { struct . staticWorkingDir = iprot . readString ( ) ; struct . setStaticWorkingDirIsSet ( true ) ; } if ( incoming . get ( 9 ) ) { struct . overrideLoginUserName = iprot . readString ( ) ; struct . setOverrideLoginUserNameIsSet ( true ) ; } if ( incoming . get ( 10 ) ) { struct . overrideScratchLocation = iprot . readString ( ) ; struct . setOverrideScratchLocationIsSet ( true ) ; } if ( incoming . get ( 11 ) ) { struct . overrideAllocationProjectNumber = iprot . readString ( ) ; struct . setOverrideAllocationProjectNumberIsSet ( true ) ; } }",Smelly
" PropertyState [ ] resolvePropertyStates ( NodeState nodeState ) throws ItemStateException { List < NodeState > nodeStates = new ArrayList < NodeState > ( ) ; resolve ( nodeState , nodeStates , 0 ) ; List < PropertyState > propStates = new ArrayList < PropertyState > ( ) ; for ( NodeState state : nodeStates ) { if ( state . hasPropertyName ( propertyName ) ) { PropertyId propId = new PropertyId ( state . getNodeId ( ) , propertyName ) ; propStates . add ( ( PropertyState ) ism . getItemState ( propId ) ) ; } } return propStates . toArray ( new PropertyState [ propStates . size ( ) ] ) ; }",No
" public void read ( org . apache . thrift . protocol . TProtocol prot , getChildDataProducts_result struct ) throws org . apache . thrift . TException { TTupleProtocol iprot = ( TTupleProtocol ) prot ; BitSet incoming = iprot . readBitSet ( 5 ) ; if ( incoming . get ( 0 ) ) { { org . apache . thrift . protocol . TList _list283 = new org . apache . thrift . protocol . TList ( org . apache . thrift . protocol . TType . STRUCT , iprot . readI32 ( ) ) ; struct . success = new ArrayList < org . apache . airavata . model . data . replica . DataProductModel > ( _list283 . size ) ; org . apache . airavata . model . data . replica . DataProductModel _elem284 ; for ( int _i285 = 0 ; _i285 < _list283 . size ; ++ _i285 ) { _elem284 = new org . apache . airavata . model . data . replica . DataProductModel ( ) ; _elem284 . read ( iprot ) ; struct . success . add ( _elem284 ) ; } } struct . setSuccessIsSet ( true ) ; } if ( incoming . get ( 1 ) ) { struct . ire = new org . apache . airavata . model . error . InvalidRequestException ( ) ; struct . ire . read ( iprot ) ; struct . setIreIsSet ( true ) ; } if ( incoming . get ( 2 ) ) { struct . ace = new org . apache . airavata . model . error . AiravataClientException ( ) ; struct . ace . read ( iprot ) ; struct . setAceIsSet ( true ) ; } if ( incoming . get ( 3 ) ) { struct . ase = new org . apache . airavata . model . error . AiravataSystemException ( ) ; struct . ase . read ( iprot ) ; struct . setAseIsSet ( true ) ; } if ( incoming . get ( 4 ) ) { struct . ae = new org . apache . airavata . model . error . AuthorizationException ( ) ; struct . ae . read ( iprot ) ; struct . setAeIsSet ( true ) ; } }",No
" public void read ( org . apache . thrift . protocol . TProtocol prot , show_compact_result struct ) throws org . apache . thrift . TException { TTupleProtocol iprot = ( TTupleProtocol ) prot ; BitSet incoming = iprot . readBitSet ( 1 ) ; if ( incoming . get ( 0 ) ) { struct . success = new ShowCompactResponse ( ) ; struct . success . read ( iprot ) ; struct . setSuccessIsSet ( true ) ; } }",Smelly
" public void read ( org . apache . thrift . protocol . TProtocol prot , show_compact_result struct ) throws org . apache . thrift . TException { TTupleProtocol iprot = ( TTupleProtocol ) prot ; BitSet incoming = iprot . readBitSet ( 1 ) ; if ( incoming . get ( 0 ) ) { struct . success = new ShowCompactResponse ( ) ; struct . success . read ( iprot ) ; struct . setSuccessIsSet ( true ) ; } }",Smelly
" public void read ( org . apache . thrift . protocol . TProtocol prot , onReceivedZeppelinResource_result struct ) throws org . apache . thrift . TException { TTupleProtocol iprot = ( TTupleProtocol ) prot ; }",No
" public AtlasObjectId deserialize ( final JsonElement json , final Type type , final JsonDeserializationContext context ) throws JsonParseException { try { return mapper . readValue ( json . toString ( ) , AtlasObjectId . class ) ; } catch ( IOException excp ) { throw new JsonParseException ( excp ) ; } }",No
" public void read ( org . apache . thrift . protocol . TProtocol prot , checkNamespaceClass_result struct ) throws org . apache . thrift . TException { TTupleProtocol iprot = ( TTupleProtocol ) prot ; BitSet incoming = iprot . readBitSet ( 3 ) ; if ( incoming . get ( 0 ) ) { struct . success = iprot . readBool ( ) ; struct . setSuccessIsSet ( true ) ; } if ( incoming . get ( 1 ) ) { struct . sec = new ThriftSecurityException ( ) ; struct . sec . read ( iprot ) ; struct . setSecIsSet ( true ) ; } if ( incoming . get ( 2 ) ) { struct . tope = new ThriftTableOperationException ( ) ; struct . tope . read ( iprot ) ; struct . setTopeIsSet ( true ) ; } }",Smelly
" public void read ( org . apache . thrift . protocol . TProtocol prot , getFollowing_result struct ) throws org . apache . thrift . TException { TTupleProtocol iprot = ( TTupleProtocol ) prot ; BitSet incoming = iprot . readBitSet ( 1 ) ; if ( incoming . get ( 0 ) ) { struct . success = new Key ( ) ; struct . success . read ( iprot ) ; struct . setSuccessIsSet ( true ) ; } }",Smelly
" public String toString ( ) { return ""FragmentNode [root="" + root + "", sendingExchange="" + sendingExchange + "", receivingExchangePairs="" + receivingExchangePairs + ""]"" ; }",No
" protected void addMetadata ( String value ) { if ( value != null && value . length ( ) > 0 ) { if ( metadata . isMultiValued ( name ) ) { List < String > previous = Arrays . asList ( metadata . getValues ( name ) ) ; if ( ! previous . contains ( value ) ) { if ( property != null ) { metadata . add ( property , value ) ; } else { metadata . add ( name , value ) ; } } } else { String previous = metadata . get ( name ) ; if ( previous != null && previous . length ( ) > 0 ) { if ( ! previous . equals ( value ) ) { if ( property != null ) { if ( property . isMultiValuePermitted ( ) ) { metadata . add ( property , value ) ; } else { metadata . set ( property , value ) ; } } else { metadata . add ( name , value ) ; } } } else { if ( property != null ) { metadata . set ( property , value ) ; } else { metadata . set ( name , value ) ; } } } } }",No
" public void process ( String input , Emitter < M > emitter ) { if ( input != null && ! input . isEmpty ( ) ) { Builder b = msgInstance . newBuilderForType ( ) ; Iterator < String > iter = splitter . split ( input ) . iterator ( ) ; boolean parseError = false ; for ( FieldDescriptor fd : fields ) { if ( iter . hasNext ( ) ) { String value = iter . next ( ) ; if ( value != null && ! value . isEmpty ( ) ) { Object parsedValue = null ; try { switch ( fd . getJavaType ( ) ) { case STRING : parsedValue = value ; break ; case INT : parsedValue = Integer . valueOf ( value ) ; break ; case LONG : parsedValue = Long . valueOf ( value ) ; break ; case FLOAT : parsedValue = Float . valueOf ( value ) ; break ; case DOUBLE : parsedValue = Double . valueOf ( value ) ; break ; case BOOLEAN : parsedValue = Boolean . valueOf ( value ) ; break ; case ENUM : parsedValue = fd . getEnumType ( ) . findValueByName ( value ) ; break ; } b . setField ( fd , parsedValue ) ; } catch ( NumberFormatException nfe ) { increment ( ParseErrors . NUMBER_FORMAT ) ; parseError = true ; break ; } } } } if ( parseError ) { increment ( ParseErrors . TOTAL ) ; } else { emitter . emit ( ( M ) b . build ( ) ) ; } } }",Smelly
" public void read ( org . apache . thrift . protocol . TProtocol prot , ActiveCompaction struct ) throws org . apache . thrift . TException { TTupleProtocol iprot = ( TTupleProtocol ) prot ; BitSet incoming = iprot . readBitSet ( 11 ) ; if ( incoming . get ( 0 ) ) { struct . extent = new org . apache . accumulo . core . data . thrift . TKeyExtent ( ) ; struct . extent . read ( iprot ) ; struct . setExtentIsSet ( true ) ; } if ( incoming . get ( 1 ) ) { struct . age = iprot . readI64 ( ) ; struct . setAgeIsSet ( true ) ; } if ( incoming . get ( 2 ) ) { { org . apache . thrift . protocol . TList _list74 = new org . apache . thrift . protocol . TList ( org . apache . thrift . protocol . TType . STRING , iprot . readI32 ( ) ) ; struct . inputFiles = new ArrayList < String > ( _list74 . size ) ; for ( int _i75 = 0 ; _i75 < _list74 . size ; ++ _i75 ) { String _elem76 ; _elem76 = iprot . readString ( ) ; struct . inputFiles . add ( _elem76 ) ; } } struct . setInputFilesIsSet ( true ) ; } if ( incoming . get ( 3 ) ) { struct . outputFile = iprot . readString ( ) ; struct . setOutputFileIsSet ( true ) ; } if ( incoming . get ( 4 ) ) { struct . type = CompactionType . findByValue ( iprot . readI32 ( ) ) ; struct . setTypeIsSet ( true ) ; } if ( incoming . get ( 5 ) ) { struct . reason = CompactionReason . findByValue ( iprot . readI32 ( ) ) ; struct . setReasonIsSet ( true ) ; } if ( incoming . get ( 6 ) ) { struct . localityGroup = iprot . readString ( ) ; struct . setLocalityGroupIsSet ( true ) ; } if ( incoming . get ( 7 ) ) { struct . entriesRead = iprot . readI64 ( ) ; struct . setEntriesReadIsSet ( true ) ; } if ( incoming . get ( 8 ) ) { struct . entriesWritten = iprot . readI64 ( ) ; struct . setEntriesWrittenIsSet ( true ) ; } if ( incoming . get ( 9 ) ) { { org . apache . thrift . protocol . TList _list77 = new org . apache . thrift . protocol . TList ( org . apache . thrift . protocol . TType . STRUCT , iprot . readI32 ( ) ) ; struct . ssiList = new ArrayList < org . apache . accumulo . core . data . thrift . IterInfo > ( _list77 . size ) ; for ( int _i78 = 0 ; _i78 < _list77 . size ; ++ _i78 ) { org . apache . accumulo . core . data . thrift . IterInfo _elem79 ; _elem79 = new org . apache . accumulo . core . data . thrift . IterInfo ( ) ; _elem79 . read ( iprot ) ; struct . ssiList . add ( _elem79 ) ; } } struct . setSsiListIsSet ( true ) ; } if ( incoming . get ( 10 ) ) { { org . apache . thrift . protocol . TMap _map80 = new org . apache . thrift . protocol . TMap ( org . apache . thrift . protocol . TType . STRING , org . apache . thrift . protocol . TType . MAP , iprot . readI32 ( ) ) ; struct . ssio = new HashMap < String , Map < String , String > > ( 2 * _map80 . size ) ; for ( int _i81 = 0 ; _i81 < _map80 . size ; ++ _i81 ) { String _key82 ; Map < String , String > _val83 ; _key82 = iprot . readString ( ) ; { org . apache . thrift . protocol . TMap _map84 = new org . apache . thrift . protocol . TMap ( org . apache . thrift . protocol . TType . STRING , org . apache . thrift . protocol . TType . STRING , iprot . readI32 ( ) ) ; _val83 = new HashMap < String , String > ( 2 * _map84 . size ) ; for ( int _i85 = 0 ; _i85 < _map84 . size ; ++ _i85 ) { String _key86 ; String _val87 ; _key86 = iprot . readString ( ) ; _val87 = iprot . readString ( ) ; _val83 . put ( _key86 , _val87 ) ; } } struct . ssio . put ( _key82 , _val83 ) ; } } struct . setSsioIsSet ( true ) ; } }",Smelly
" protected SpatialArguments extractObjectArguments ( Node predicate , PropFuncArg object , SRSInfo indexSRSInfo ) { try { List < Node > objectArgs = object . getArgList ( ) ; if ( objectArgs . size ( ) < 3 ) { throw new ExprEvalException ( FmtUtils . stringForNode ( predicate ) + "": Minimum of 3 arguments."" ) ; } else if ( objectArgs . size ( ) > 5 ) { throw new ExprEvalException ( FmtUtils . stringForNode ( predicate ) + "": Maximum of 5 arguments."" ) ; } Node lat = objectArgs . get ( LAT_POS ) ; Node lon = objectArgs . get ( LON_POS ) ; NodeValue radiusNode = NodeValue . makeNode ( objectArgs . get ( RADIUS_POS ) ) ; if ( lat . isVariable ( ) || lon . isVariable ( ) || ! radiusNode . isDouble ( ) ) { throw new ExprEvalException ( ""Arguments are not all concrete: "" + FmtUtils . stringForNode ( lat ) + "", "" + FmtUtils . stringForNode ( lon ) + "", "" + FmtUtils . stringForNode ( radiusNode . asNode ( ) ) ) ; } radius = radiusNode . getDouble ( ) ; if ( objectArgs . size ( ) > UNITS_POS ) { Node unitsNode = objectArgs . get ( UNITS_POS ) ; if ( ! unitsNode . isURI ( ) ) { throw new ExprEvalException ( ""Not a URI: "" + FmtUtils . stringForNode ( unitsNode ) ) ; } unitsURI = unitsNode . getURI ( ) ; } else { unitsURI = DEFAULT_UNITS ; } int limit ; if ( objectArgs . size ( ) > LIMIT_POS ) { NodeValue limitNode = NodeValue . makeNode ( objectArgs . get ( LIMIT_POS ) ) ; if ( ! limitNode . isInteger ( ) ) { throw new ExprEvalException ( ""Not an integer: "" + FmtUtils . stringForNode ( limitNode . getNode ( ) ) ) ; } limit = limitNode . getInteger ( ) . intValue ( ) ; } else { limit = DEFAULT_LIMIT ; } GeometryWrapper geometryWrapper = ConvertLatLon . toGeometryWrapper ( lat , lon ) ; SearchEnvelope searchEnvelope = SearchEnvelope . build ( geometryWrapper , indexSRSInfo , radius , unitsURI ) ; return new SpatialArguments ( limit , geometryWrapper , searchEnvelope ) ; } catch ( DatatypeFormatException ex ) { throw new ExprEvalException ( ex . getMessage ( ) , ex ) ; } }",Smelly
" public void read ( org . apache . thrift . protocol . TProtocol prot , getFollowing_result struct ) throws org . apache . thrift . TException { TTupleProtocol iprot = ( TTupleProtocol ) prot ; BitSet incoming = iprot . readBitSet ( 1 ) ; if ( incoming . get ( 0 ) ) { struct . success = new Key ( ) ; struct . success . read ( iprot ) ; struct . setSuccessIsSet ( true ) ; } }",Smelly
" public void read ( org . apache . thrift . protocol . TProtocol prot , getFollowing_result struct ) throws org . apache . thrift . TException { TTupleProtocol iprot = ( TTupleProtocol ) prot ; BitSet incoming = iprot . readBitSet ( 1 ) ; if ( incoming . get ( 0 ) ) { struct . success = new Key ( ) ; struct . success . read ( iprot ) ; struct . setSuccessIsSet ( true ) ; } }",Smelly
" static Object removeAll ( final Object array , final BitSet indices ) { final int srcLength = ArrayUtils . getLength ( array ) ; final int removals = indices . cardinality ( ) ; final Object result = Array . newInstance ( array . getClass ( ) . getComponentType ( ) , srcLength - removals ) ; int srcIndex = 0 ; int destIndex = 0 ; int count ; int set ; while ( ( set = indices . nextSetBit ( srcIndex ) ) != - 1 ) { count = set - srcIndex ; if ( count > 0 ) { System . arraycopy ( array , srcIndex , result , destIndex , count ) ; destIndex += count ; } srcIndex = indices . nextClearBit ( set ) ; } count = srcLength - srcIndex ; if ( count > 0 ) { System . arraycopy ( array , srcIndex , result , destIndex , count ) ; } return result ; }",No
 public boolean isOptimized ( ) { ensureOpen ( ) ; return in . isOptimized ( ) ; },No
" private Attribute_InnerClasses parseInnerClasses ( ) throws ParsingException , GrammerException { Scanner sc ; sc = Scanner . partialScanner ( scanner . getContent ( ) , scanner . getOffset ( ) + 1 , scanner . getLength ( ) - 2 , scanner . getColumnNumberStart ( ) + 1 , scanner . getLineNumberStart ( ) ) ; ArrayList ins = new ArrayList ( ) ; int access_flag = 0 , inner_name_index , inner_class_info , outer_class_info ; sc . nextToken ( ) ; if ( sc . nextToken ( ) != Colon ) { exception ( sc , ""':'.expected"" ) ; } sc . nextToken ( ) ; while ( sc . tokenType ( ) != EOF ) { if ( ""access"" . equals ( sc . token ( ) ) == false ) { exception ( sc , ""'access'.expected.here"" ) ; } if ( sc . nextToken ( ) != Equal ) { exception ( sc , ""'='.expected.here"" ) ; } while ( sc . nextToken ( ) == AccessFlag ) { access_flag = Util . getAccessFlag_Class ( sc . token ( ) ) | access_flag ; } if ( sc . tokenType ( ) != Comma ) { exception ( sc , ""','.expected.here"" ) ; } sc . nextToken ( ) ; if ( ""name"" . equals ( sc . token ( ) ) == false ) { exception ( sc , ""'name'.expected.here"" ) ; } if ( sc . nextToken ( ) != Equal ) { exception ( sc , ""'='.expected.here"" ) ; } sc . nextToken ( ) ; if ( ""0"" . equals ( sc . token ( ) ) == true ) { inner_name_index = 0 ; } else { inner_name_index = cpl . addUtf8 ( sc . token ( ) ) ; } if ( sc . nextToken ( ) != Comma ) { exception ( sc , ""','.expected.here"" ) ; } sc . nextToken ( ) ; if ( ""fullname"" . equals ( sc . token ( ) ) == false ) { exception ( sc , ""'fullname'.expected.here"" ) ; } if ( sc . nextToken ( ) != Equal ) { exception ( sc , ""'='.expected.here"" ) ; } sc . nextToken ( ) ; inner_class_info = cpl . addClass ( sc . token ( ) ) ; if ( sc . nextToken ( ) != Comma ) { exception ( sc , ""','.expected.here"" ) ; } sc . nextToken ( ) ; if ( ""outername"" . equals ( sc . token ( ) ) == false ) { exception ( sc , ""'outername'.expected.here"" ) ; } if ( sc . nextToken ( ) != Equal ) { exception ( sc , ""'='.expected.here"" ) ; } sc . nextToken ( ) ; if ( ""0"" . equals ( sc . token ( ) ) ) { outer_class_info = 0 ; } else { outer_class_info = cpl . addClass ( sc . token ( ) ) ; } sc . nextToken ( ) ; ins . add ( new Attribute_InnerClasses . InnerClass ( inner_class_info , outer_class_info , inner_name_index , access_flag ) ) ; } Attribute_InnerClasses ret = new Attribute_InnerClasses ( 8 * ins . size ( ) + 2 , ins . size ( ) , ( Attribute_InnerClasses . InnerClass [ ] ) ins . toArray ( new Attribute_InnerClasses . InnerClass [ ins . size ( ) ] ) ) ; ret . attribute_name_index = cpl . addUtf8 ( ""InnerClasses"" ) ; return ret ; }",Smelly
" public NutchDocument filter ( NutchDocument doc , Parse parse , Text url , CrawlDatum datum , Inlinks inlinks ) throws IndexingException { for ( int i = 0 ; i < this . indexingFilters . length ; i ++ ) { doc = this . indexingFilters [ i ] . filter ( doc , parse , url , datum , inlinks ) ; if ( doc == null ) return null ; } return doc ; }",No
" public void fn_error_02 ( ) { try { LibTestExpr . eval ( ""fn:error('MESSAGE')"" ) ; fail ( ""No exception"" ) ; } catch ( ExprEvalException ex ) { assertEquals ( ""MESSAGE"" , ex . getMessage ( ) ) ; } }",No
" public String toString ( ) { return new ToStringBuilder ( this ) . append ( ""targetClass"" , clazz ) . append ( ""id"" , id ) . append ( ""shadedSerializer"" , shadedSerializer ) . append ( ""serializerShim"" , serializerShim ) . append ( ""functionOfShadedKryo"" , functionOfShadedKryo ) . toString ( ) ; }",No
" private long determineCleanupInterval ( NiFiProperties properties ) { long cleanupInterval = MIN_CLEANUP_INTERVAL_MILLIS ; String archiveCleanupFrequency = properties . getProperty ( NiFiProperties . CONTENT_ARCHIVE_CLEANUP_FREQUENCY ) ; if ( archiveCleanupFrequency != null ) { try { cleanupInterval = FormatUtils . getTimeDuration ( archiveCleanupFrequency . trim ( ) , TimeUnit . MILLISECONDS ) ; } catch ( Exception e ) { throw new RuntimeException ( ""Invalid value set for property "" + NiFiProperties . CONTENT_ARCHIVE_CLEANUP_FREQUENCY ) ; } if ( cleanupInterval < MIN_CLEANUP_INTERVAL_MILLIS ) { LOG . warn ( ""The value of "" + NiFiProperties . CONTENT_ARCHIVE_CLEANUP_FREQUENCY + "" property is set to '"" + archiveCleanupFrequency + ""' which is "" + ""below the allowed minimum of 1 second (1000 milliseconds). Minimum value of 1 sec will be used as scheduling interval for archive cleanup task."" ) ; cleanupInterval = MIN_CLEANUP_INTERVAL_MILLIS ; } } return cleanupInterval ; }",Smelly
" public static boolean checkIfPartitionSelection ( EvalNode node , Schema partSchema ) { if ( node != null && node instanceof BinaryEval ) { BinaryEval eval = ( BinaryEval ) node ; EvalNode left = eval . getLeftExpr ( ) ; EvalNode right = eval . getRightExpr ( ) ; EvalType type = eval . getType ( ) ; if ( type == EvalType . EQUAL ) { if ( left instanceof FieldEval && right instanceof ConstEval && partSchema . contains ( ( ( FieldEval ) left ) . getColumnName ( ) ) ) { return true ; } else if ( left instanceof ConstEval && right instanceof FieldEval && partSchema . contains ( ( ( FieldEval ) right ) . getColumnName ( ) ) ) { return true ; } } else if ( ( type == EvalType . AND || type == EvalType . OR ) && left instanceof BinaryEval && right instanceof BinaryEval ) { return checkIfPartitionSelection ( left , partSchema ) && checkIfPartitionSelection ( right , partSchema ) ; } } return false ; }",Smelly
" public void read ( org . apache . thrift . protocol . TProtocol prot , getChildDataProducts_result struct ) throws org . apache . thrift . TException { TTupleProtocol iprot = ( TTupleProtocol ) prot ; BitSet incoming = iprot . readBitSet ( 5 ) ; if ( incoming . get ( 0 ) ) { { org . apache . thrift . protocol . TList _list283 = new org . apache . thrift . protocol . TList ( org . apache . thrift . protocol . TType . STRUCT , iprot . readI32 ( ) ) ; struct . success = new ArrayList < org . apache . airavata . model . data . replica . DataProductModel > ( _list283 . size ) ; org . apache . airavata . model . data . replica . DataProductModel _elem284 ; for ( int _i285 = 0 ; _i285 < _list283 . size ; ++ _i285 ) { _elem284 = new org . apache . airavata . model . data . replica . DataProductModel ( ) ; _elem284 . read ( iprot ) ; struct . success . add ( _elem284 ) ; } } struct . setSuccessIsSet ( true ) ; } if ( incoming . get ( 1 ) ) { struct . ire = new org . apache . airavata . model . error . InvalidRequestException ( ) ; struct . ire . read ( iprot ) ; struct . setIreIsSet ( true ) ; } if ( incoming . get ( 2 ) ) { struct . ace = new org . apache . airavata . model . error . AiravataClientException ( ) ; struct . ace . read ( iprot ) ; struct . setAceIsSet ( true ) ; } if ( incoming . get ( 3 ) ) { struct . ase = new org . apache . airavata . model . error . AiravataSystemException ( ) ; struct . ase . read ( iprot ) ; struct . setAseIsSet ( true ) ; } if ( incoming . get ( 4 ) ) { struct . ae = new org . apache . airavata . model . error . AuthorizationException ( ) ; struct . ae . read ( iprot ) ; struct . setAeIsSet ( true ) ; } }",Smelly
" public void read ( org . apache . thrift . protocol . TProtocol prot , getFollowing_result struct ) throws org . apache . thrift . TException { TTupleProtocol iprot = ( TTupleProtocol ) prot ; BitSet incoming = iprot . readBitSet ( 1 ) ; if ( incoming . get ( 0 ) ) { struct . success = new Key ( ) ; struct . success . read ( iprot ) ; struct . setSuccessIsSet ( true ) ; } }",Smelly
" public void read ( org . apache . thrift . protocol . TProtocol prot , TI16Column struct ) throws org . apache . thrift . TException { TTupleProtocol iprot = ( TTupleProtocol ) prot ; { org . apache . thrift . protocol . TList _list75 = new org . apache . thrift . protocol . TList ( org . apache . thrift . protocol . TType . I16 , iprot . readI32 ( ) ) ; struct . values = new ArrayList < Short > ( _list75 . size ) ; for ( int _i76 = 0 ; _i76 < _list75 . size ; ++ _i76 ) { short _elem77 ; _elem77 = iprot . readI16 ( ) ; struct . values . add ( _elem77 ) ; } } struct . setValuesIsSet ( true ) ; struct . nulls = iprot . readBinary ( ) ; struct . setNullsIsSet ( true ) ; }",Smelly
" public void testChangeUserProperties ( ) throws Exception { createUser ( userId ) ; modify ( ""/"" , PrivilegeConstants . JCR_MODIFY_PROPERTIES , true ) ; UserManager testUserMgr = getUserManager ( testSession ) ; Authorizable a = testUserMgr . getAuthorizable ( userId ) ; a . setProperty ( ""someProp"" , testSession . getValueFactory ( ) . createValue ( ""value"" ) ) ; testSession . save ( ) ; a . setProperty ( ""someProperty"" , testSession . getValueFactory ( ) . createValue ( ""modified"" ) ) ; testSession . save ( ) ; a . removeProperty ( ""someProperty"" ) ; testSession . save ( ) ; }",No
 RebalanceProtocol getProtocol ( ) { return protocol ; },Smelly
" public void read ( org . apache . thrift . protocol . TProtocol prot , show_compact_result struct ) throws org . apache . thrift . TException { TTupleProtocol iprot = ( TTupleProtocol ) prot ; BitSet incoming = iprot . readBitSet ( 1 ) ; if ( incoming . get ( 0 ) ) { struct . success = new ShowCompactResponse ( ) ; struct . success . read ( iprot ) ; struct . setSuccessIsSet ( true ) ; } }",Smelly
" public void deploy ( File source , Artifact artifact , ArtifactRepository deploymentRepository , ArtifactRepository localRepository ) throws ArtifactDeploymentException { RepositorySystemSession session = LegacyLocalRepositoryManager . overlay ( localRepository , legacySupport . getRepositorySession ( ) , repoSystem ) ; DeployRequest request = new DeployRequest ( ) ; request . setTrace ( RequestTrace . newChild ( null , legacySupport . getSession ( ) . getCurrentProject ( ) ) ) ; org . eclipse . aether . artifact . Artifact mainArtifact = RepositoryUtils . toArtifact ( artifact ) ; mainArtifact = mainArtifact . setFile ( source ) ; request . addArtifact ( mainArtifact ) ; String versionKey = artifact . getGroupId ( ) + ':' + artifact . getArtifactId ( ) ; String snapshotKey = null ; if ( artifact . isSnapshot ( ) ) { snapshotKey = versionKey + ':' + artifact . getBaseVersion ( ) ; request . addMetadata ( relatedMetadata . get ( snapshotKey ) ) ; } request . addMetadata ( relatedMetadata . get ( versionKey ) ) ; for ( ArtifactMetadata metadata : artifact . getMetadataList ( ) ) { if ( metadata instanceof ProjectArtifactMetadata ) { org . eclipse . aether . artifact . Artifact pomArtifact = new SubArtifact ( mainArtifact , """" , ""pom"" ) ; pomArtifact = pomArtifact . setFile ( ( ( ProjectArtifactMetadata ) metadata ) . getFile ( ) ) ; request . addArtifact ( pomArtifact ) ; } else if ( metadata instanceof SnapshotArtifactRepositoryMetadata || metadata instanceof ArtifactRepositoryMetadata ) { } else { request . addMetadata ( new MetadataBridge ( metadata ) ) ; } } RemoteRepository remoteRepo = RepositoryUtils . toRepo ( deploymentRepository ) ; if ( deploymentRepository instanceof DefaultArtifactRepository && deploymentRepository . getAuthentication ( ) == null ) { RemoteRepository . Builder builder = new RemoteRepository . Builder ( remoteRepo ) ; builder . setAuthentication ( session . getAuthenticationSelector ( ) . getAuthentication ( remoteRepo ) ) ; builder . setProxy ( session . getProxySelector ( ) . getProxy ( remoteRepo ) ) ; remoteRepo = builder . build ( ) ; } request . setRepository ( remoteRepo ) ; DeployResult result ; try { result = repoSystem . deploy ( session , request ) ; } catch ( DeploymentException e ) { throw new ArtifactDeploymentException ( e . getMessage ( ) , e ) ; } for ( Object metadata : result . getMetadata ( ) ) { if ( metadata . getClass ( ) . getName ( ) . endsWith ( "".internal.VersionsMetadata"" ) ) { relatedMetadata . put ( versionKey , ( MergeableMetadata ) metadata ) ; } if ( snapshotKey != null && metadata . getClass ( ) . getName ( ) . endsWith ( "".internal.RemoteSnapshotMetadata"" ) ) { relatedMetadata . put ( snapshotKey , ( MergeableMetadata ) metadata ) ; } } artifact . setResolvedVersion ( result . getArtifacts ( ) . iterator ( ) . next ( ) . getVersion ( ) ) ; }",Smelly
" public void read ( org . apache . thrift . protocol . TProtocol prot , getFollowing_result struct ) throws org . apache . thrift . TException { TTupleProtocol iprot = ( TTupleProtocol ) prot ; BitSet incoming = iprot . readBitSet ( 1 ) ; if ( incoming . get ( 0 ) ) { struct . success = new Key ( ) ; struct . success . read ( iprot ) ; struct . setSuccessIsSet ( true ) ; } }",Smelly
" protected PersistenceAdapter createPersistenceAdapter ( boolean delete ) throws IOException { KahaDBStore kaha = new KahaDBStore ( ) ; kaha . setDirectory ( new File ( ""target/activemq-data/kahadb"" ) ) ; if ( delete ) { kaha . deleteAllMessages ( ) ; } return kaha ; }",No
" protected AbstractApplicationContext createApplicationContext ( ) { return new ClassPathXmlApplicationContext ( ""org/apache/activemq/filter/dummyPolicy.xml"" ) ; }",No
" protected void readState ( ObjectInputStream in ) throws IOException , ClassNotFoundException { super . readState ( in ) ; this . galleryName = ( String ) in . readObject ( ) ; this . exhibitArray = in . readObject ( ) ; this . paintingArray = in . readObject ( ) ; }",No
 public void stop ( ) throws IOException { },No
" public String getLogger ( ) { String parts [ ] = logPath . split ( ""/"" ) ; return Joiner . on ( "":"" ) . join ( parts [ parts . length - 2 ] . split ( ""[+]"" ) ) ; }",Smelly
" public void read ( org . apache . thrift . protocol . TProtocol prot , Task struct ) throws org . apache . thrift . TException { TTupleProtocol iprot = ( TTupleProtocol ) prot ; BitSet incoming = iprot . readBitSet ( 8 ) ; if ( incoming . get ( 0 ) ) { struct . taskId = iprot . readString ( ) ; struct . setTaskIdIsSet ( true ) ; } if ( incoming . get ( 1 ) ) { struct . taskType = TaskType . findByValue ( iprot . readI32 ( ) ) ; struct . setTaskTypeIsSet ( true ) ; } if ( incoming . get ( 2 ) ) { { org . apache . thrift . protocol . TMap _map61 = new org . apache . thrift . protocol . TMap ( org . apache . thrift . protocol . TType . STRING , org . apache . thrift . protocol . TType . STRING , iprot . readI32 ( ) ) ; struct . taskAttributes = new HashMap < String , String > ( 2 * _map61 . size ) ; for ( int _i62 = 0 ; _i62 < _map61 . size ; ++ _i62 ) { String _key63 ; String _val64 ; _key63 = iprot . readString ( ) ; _val64 = iprot . readString ( ) ; struct . taskAttributes . put ( _key63 , _val64 ) ; } } struct . setTaskAttributesIsSet ( true ) ; } if ( incoming . get ( 3 ) ) { { org . apache . thrift . protocol . TMap _map65 = new org . apache . thrift . protocol . TMap ( org . apache . thrift . protocol . TType . STRING , org . apache . thrift . protocol . TType . I64 , iprot . readI32 ( ) ) ; struct . taskCounters = new HashMap < String , Long > ( 2 * _map65 . size ) ; for ( int _i66 = 0 ; _i66 < _map65 . size ; ++ _i66 ) { String _key67 ; long _val68 ; _key67 = iprot . readString ( ) ; _val68 = iprot . readI64 ( ) ; struct . taskCounters . put ( _key67 , _val68 ) ; } } struct . setTaskCountersIsSet ( true ) ; } if ( incoming . get ( 4 ) ) { struct . operatorGraph = new Graph ( ) ; struct . operatorGraph . read ( iprot ) ; struct . setOperatorGraphIsSet ( true ) ; } if ( incoming . get ( 5 ) ) { { org . apache . thrift . protocol . TList _list69 = new org . apache . thrift . protocol . TList ( org . apache . thrift . protocol . TType . STRUCT , iprot . readI32 ( ) ) ; struct . operatorList = new ArrayList < Operator > ( _list69 . size ) ; for ( int _i70 = 0 ; _i70 < _list69 . size ; ++ _i70 ) { Operator _elem71 ; _elem71 = new Operator ( ) ; _elem71 . read ( iprot ) ; struct . operatorList . add ( _elem71 ) ; } } struct . setOperatorListIsSet ( true ) ; } if ( incoming . get ( 6 ) ) { struct . done = iprot . readBool ( ) ; struct . setDoneIsSet ( true ) ; } if ( incoming . get ( 7 ) ) { struct . started = iprot . readBool ( ) ; struct . setStartedIsSet ( true ) ; } }",Smelly
" public void visit ( State state , Environment env , Properties props ) throws Exception { Random rand = new Random ( ) ; long numWrites = state . getLong ( ""numWrites"" ) ; int maxVerify = Integer . parseInt ( props . getProperty ( ""maxVerify"" , ""2000"" ) ) ; long numVerify = rand . nextInt ( maxVerify - 1 ) + 1 ; if ( numVerify > ( numWrites / 4 ) ) { numVerify = numWrites / 4 ; } Connector conn = env . getConnector ( ) ; BatchScanner scanner = conn . createBatchScanner ( state . getString ( ""seqTableName"" ) , new Authorizations ( ) , 2 ) ; try { int count = 0 ; List < Range > ranges = new ArrayList < > ( ) ; while ( count < numVerify ) { long rangeStart = rand . nextInt ( ( int ) numWrites ) ; long rangeEnd = rangeStart + 99 ; if ( rangeEnd > ( numWrites - 1 ) ) { rangeEnd = numWrites - 1 ; } count += rangeEnd - rangeStart + 1 ; ranges . add ( new Range ( new Text ( String . format ( ""%010d"" , rangeStart ) ) , new Text ( String . format ( ""%010d"" , rangeEnd ) ) ) ) ; } ranges = Range . mergeOverlapping ( ranges ) ; if ( ranges . size ( ) > 1 ) { Collections . sort ( ranges ) ; } if ( count == 0 || ranges . size ( ) == 0 ) return ; log . debug ( String . format ( ""scanning %d rows in the following %d ranges:"" , count , ranges . size ( ) ) ) ; for ( Range r : ranges ) { log . debug ( r ) ; } scanner . setRanges ( ranges ) ; List < Key > keys = new ArrayList < > ( ) ; for ( Entry < Key , Value > entry : scanner ) { keys . add ( entry . getKey ( ) ) ; } log . debug ( ""scan returned "" + keys . size ( ) + "" rows. now verifying..."" ) ; Collections . sort ( keys ) ; Iterator < Key > iterator = keys . iterator ( ) ; int curKey = Integer . parseInt ( iterator . next ( ) . getRow ( ) . toString ( ) ) ; boolean done = false ; for ( Range r : ranges ) { int start = Integer . parseInt ( r . getStartKey ( ) . getRow ( ) . toString ( ) ) ; int end = Integer . parseInt ( String . copyValueOf ( r . getEndKey ( ) . getRow ( ) . toString ( ) . toCharArray ( ) , 0 , 10 ) ) ; for ( int i = start ; i <= end ; i ++ ) { if ( done ) { log . error ( ""missing key "" + i ) ; break ; } while ( curKey < i ) { log . error ( ""extra key "" + curKey ) ; if ( iterator . hasNext ( ) == false ) { done = true ; break ; } curKey = Integer . parseInt ( iterator . next ( ) . getRow ( ) . toString ( ) ) ; } if ( curKey > i ) { log . error ( ""missing key "" + i ) ; } if ( iterator . hasNext ( ) ) { curKey = Integer . parseInt ( iterator . next ( ) . getRow ( ) . toString ( ) ) ; } else { done = true ; } } } log . debug ( ""verify is now complete"" ) ; } finally { scanner . close ( ) ; } }",Smelly
" public void handle ( Callback [ ] callbacks ) throws IOException , UnsupportedCallbackException { NameCallback nc = null ; PasswordCallback pc = null ; AuthorizeCallback ac = null ; for ( Callback callback : callbacks ) { if ( callback instanceof AuthorizeCallback ) { ac = ( AuthorizeCallback ) callback ; } else if ( callback instanceof NameCallback ) { nc = ( NameCallback ) callback ; } else if ( callback instanceof PasswordCallback ) { pc = ( PasswordCallback ) callback ; } else if ( callback instanceof RealmCallback ) { continue ; } else { throw new UnsupportedCallbackException ( callback , ""handle: Unrecognized SASL DIGEST-MD5 Callback"" ) ; } } if ( pc != null ) { JobTokenIdentifier tokenIdentifier = getIdentifier ( nc . getDefaultName ( ) , secretManager ) ; char [ ] password = encodePassword ( secretManager . retrievePassword ( tokenIdentifier ) ) ; if ( LOG . isDebugEnabled ( ) ) { LOG . debug ( ""handle: SASL server DIGEST-MD5 callback: setting "" + ""password for client: "" + tokenIdentifier . getUser ( ) ) ; } pc . setPassword ( password ) ; } if ( ac != null ) { String authid = ac . getAuthenticationID ( ) ; String authzid = ac . getAuthorizationID ( ) ; if ( authid . equals ( authzid ) ) { ac . setAuthorized ( true ) ; } else { ac . setAuthorized ( false ) ; } if ( ac . isAuthorized ( ) ) { if ( LOG . isDebugEnabled ( ) ) { String username = getIdentifier ( authzid , secretManager ) . getUser ( ) . getUserName ( ) ; if ( LOG . isDebugEnabled ( ) ) { LOG . debug ( ""handle: SASL server DIGEST-MD5 callback: setting "" + ""canonicalized client ID: "" + username ) ; } } ac . setAuthorizedID ( authzid ) ; } } }",Smelly
" public void read ( org . apache . thrift . protocol . TProtocol prot , getChildDataProducts_result struct ) throws org . apache . thrift . TException { TTupleProtocol iprot = ( TTupleProtocol ) prot ; BitSet incoming = iprot . readBitSet ( 5 ) ; if ( incoming . get ( 0 ) ) { { org . apache . thrift . protocol . TList _list283 = new org . apache . thrift . protocol . TList ( org . apache . thrift . protocol . TType . STRUCT , iprot . readI32 ( ) ) ; struct . success = new ArrayList < org . apache . airavata . model . data . replica . DataProductModel > ( _list283 . size ) ; org . apache . airavata . model . data . replica . DataProductModel _elem284 ; for ( int _i285 = 0 ; _i285 < _list283 . size ; ++ _i285 ) { _elem284 = new org . apache . airavata . model . data . replica . DataProductModel ( ) ; _elem284 . read ( iprot ) ; struct . success . add ( _elem284 ) ; } } struct . setSuccessIsSet ( true ) ; } if ( incoming . get ( 1 ) ) { struct . ire = new org . apache . airavata . model . error . InvalidRequestException ( ) ; struct . ire . read ( iprot ) ; struct . setIreIsSet ( true ) ; } if ( incoming . get ( 2 ) ) { struct . ace = new org . apache . airavata . model . error . AiravataClientException ( ) ; struct . ace . read ( iprot ) ; struct . setAceIsSet ( true ) ; } if ( incoming . get ( 3 ) ) { struct . ase = new org . apache . airavata . model . error . AiravataSystemException ( ) ; struct . ase . read ( iprot ) ; struct . setAseIsSet ( true ) ; } if ( incoming . get ( 4 ) ) { struct . ae = new org . apache . airavata . model . error . AuthorizationException ( ) ; struct . ae . read ( iprot ) ; struct . setAeIsSet ( true ) ; } }",Smelly
 public String getName ( ) throws RepositoryException { return jcrName ; },No
" protected void populateStreamDict ( Object lengthEntry ) { if ( get ( ""Matrix"" ) == null ) { put ( ""Matrix"" , new PDFArray ( this , new int [ ] { 1 , 0 , 0 , 1 , 0 , 0 } ) ) ; } super . populateStreamDict ( lengthEntry ) ; }",No
 private static < S extends org . apache . thrift . scheme . IScheme > S scheme ( org . apache . thrift . protocol . TProtocol proto ) { return ( org . apache . thrift . scheme . StandardScheme . class . equals ( proto . getScheme ( ) ) ? STANDARD_SCHEME_FACTORY : TUPLE_SCHEME_FACTORY ) . getScheme ( ) ; },Smelly
 private static < S extends org . apache . thrift . scheme . IScheme > S scheme ( org . apache . thrift . protocol . TProtocol proto ) { return ( org . apache . thrift . scheme . StandardScheme . class . equals ( proto . getScheme ( ) ) ? STANDARD_SCHEME_FACTORY : TUPLE_SCHEME_FACTORY ) . getScheme ( ) ; },Smelly
" public void read ( org . apache . thrift . protocol . TProtocol prot , getFollowing_result struct ) throws org . apache . thrift . TException { TTupleProtocol iprot = ( TTupleProtocol ) prot ; BitSet incoming = iprot . readBitSet ( 1 ) ; if ( incoming . get ( 0 ) ) { struct . success = new Key ( ) ; struct . success . read ( iprot ) ; struct . setSuccessIsSet ( true ) ; } }",Smelly
 protected void useBundleClasses ( ) throws Exception { IoBuffer . allocate ( 100 ) ; },No
" public void read ( org . apache . thrift . protocol . TProtocol prot , DataReplicaLocationModel struct ) throws org . apache . thrift . TException { TTupleProtocol iprot = ( TTupleProtocol ) prot ; BitSet incoming = iprot . readBitSet ( 12 ) ; if ( incoming . get ( 0 ) ) { struct . replicaId = iprot . readString ( ) ; struct . setReplicaIdIsSet ( true ) ; } if ( incoming . get ( 1 ) ) { struct . productUri = iprot . readString ( ) ; struct . setProductUriIsSet ( true ) ; } if ( incoming . get ( 2 ) ) { struct . replicaName = iprot . readString ( ) ; struct . setReplicaNameIsSet ( true ) ; } if ( incoming . get ( 3 ) ) { struct . replicaDescription = iprot . readString ( ) ; struct . setReplicaDescriptionIsSet ( true ) ; } if ( incoming . get ( 4 ) ) { struct . creationTime = iprot . readI64 ( ) ; struct . setCreationTimeIsSet ( true ) ; } if ( incoming . get ( 5 ) ) { struct . lastModifiedTime = iprot . readI64 ( ) ; struct . setLastModifiedTimeIsSet ( true ) ; } if ( incoming . get ( 6 ) ) { struct . validUntilTime = iprot . readI64 ( ) ; struct . setValidUntilTimeIsSet ( true ) ; } if ( incoming . get ( 7 ) ) { struct . replicaLocationCategory = org . apache . airavata . model . data . replica . ReplicaLocationCategory . findByValue ( iprot . readI32 ( ) ) ; struct . setReplicaLocationCategoryIsSet ( true ) ; } if ( incoming . get ( 8 ) ) { struct . replicaPersistentType = org . apache . airavata . model . data . replica . ReplicaPersistentType . findByValue ( iprot . readI32 ( ) ) ; struct . setReplicaPersistentTypeIsSet ( true ) ; } if ( incoming . get ( 9 ) ) { struct . storageResourceId = iprot . readString ( ) ; struct . setStorageResourceIdIsSet ( true ) ; } if ( incoming . get ( 10 ) ) { struct . filePath = iprot . readString ( ) ; struct . setFilePathIsSet ( true ) ; } if ( incoming . get ( 11 ) ) { { org . apache . thrift . protocol . TMap _map24 = new org . apache . thrift . protocol . TMap ( org . apache . thrift . protocol . TType . STRING , org . apache . thrift . protocol . TType . STRING , iprot . readI32 ( ) ) ; struct . replicaMetadata = new HashMap < String , String > ( 2 * _map24 . size ) ; String _key25 ; String _val26 ; for ( int _i27 = 0 ; _i27 < _map24 . size ; ++ _i27 ) { _key25 = iprot . readString ( ) ; _val26 = iprot . readString ( ) ; struct . replicaMetadata . put ( _key25 , _val26 ) ; } } struct . setReplicaMetadataIsSet ( true ) ; } }",Smelly
" public Table create ( SchemaPlus schema , String name , Map operand , RelDataType rowType ) { final DruidSchema druidSchema = schema . unwrap ( DruidSchema . class ) ; final String dataSource = ( String ) operand . get ( ""dataSource"" ) ; final Set < String > metricNameBuilder = new LinkedHashSet < > ( ) ; final Map < String , SqlTypeName > fieldBuilder = new LinkedHashMap < > ( ) ; final Map < String , List < ComplexMetric > > complexMetrics = new HashMap < > ( ) ; final String timestampColumnName ; final SqlTypeName timestampColumnType ; final Object timestampInfo = operand . get ( ""timestampColumn"" ) ; if ( timestampInfo != null ) { if ( timestampInfo instanceof Map ) { Map map = ( Map ) timestampInfo ; if ( ! ( map . get ( ""name"" ) instanceof String ) ) { throw new IllegalArgumentException ( ""timestampColumn array must have name"" ) ; } timestampColumnName = ( String ) map . get ( ""name"" ) ; if ( ! ( map . get ( ""type"" ) instanceof String ) || map . get ( ""type"" ) . equals ( ""timestamp with local time zone"" ) ) { timestampColumnType = SqlTypeName . TIMESTAMP_WITH_LOCAL_TIME_ZONE ; } else if ( map . get ( ""type"" ) . equals ( ""timestamp"" ) ) { timestampColumnType = SqlTypeName . TIMESTAMP ; } else { throw new IllegalArgumentException ( ""unexpected type for timestampColumn array"" ) ; } } else { timestampColumnName = ( String ) timestampInfo ; timestampColumnType = SqlTypeName . TIMESTAMP_WITH_LOCAL_TIME_ZONE ; } } else { timestampColumnName = DruidTable . DEFAULT_TIMESTAMP_COLUMN ; timestampColumnType = SqlTypeName . TIMESTAMP_WITH_LOCAL_TIME_ZONE ; } fieldBuilder . put ( timestampColumnName , timestampColumnType ) ; final Object dimensionsRaw = operand . get ( ""dimensions"" ) ; if ( dimensionsRaw instanceof List ) { final List < String > dimensions = ( List < String > ) dimensionsRaw ; for ( String dimension : dimensions ) { fieldBuilder . put ( dimension , SqlTypeName . VARCHAR ) ; } } final Object complexMetricsRaw = operand . get ( ""complexMetrics"" ) ; if ( complexMetricsRaw instanceof List ) { final List < String > complexMetricList = ( List < String > ) complexMetricsRaw ; for ( String metric : complexMetricList ) { complexMetrics . put ( metric , new ArrayList < > ( ) ) ; } } final Object metricsRaw = operand . get ( ""metrics"" ) ; if ( metricsRaw instanceof List ) { final List metrics = ( List ) metricsRaw ; for ( Object metric : metrics ) { DruidType druidType = DruidType . LONG ; final String metricName ; String fieldName = null ; if ( metric instanceof Map ) { Map map2 = ( Map ) metric ; if ( ! ( map2 . get ( ""name"" ) instanceof String ) ) { throw new IllegalArgumentException ( ""metric must have name"" ) ; } metricName = ( String ) map2 . get ( ""name"" ) ; final String type = ( String ) map2 . get ( ""type"" ) ; fieldName = ( String ) map2 . get ( ""fieldName"" ) ; druidType = DruidType . getTypeFromMetric ( type ) ; } else { metricName = ( String ) metric ; } if ( ! druidType . isComplex ( ) ) { fieldBuilder . put ( metricName , druidType . sqlType ) ; metricNameBuilder . add ( metricName ) ; } else { assert fieldName != null ; if ( complexMetrics . containsKey ( fieldName ) ) { SqlTypeName type = fieldBuilder . get ( fieldName ) ; if ( type != SqlTypeName . VARCHAR ) { fieldBuilder . put ( fieldName , SqlTypeName . VARBINARY ) ; } complexMetrics . get ( fieldName ) . add ( new ComplexMetric ( metricName , druidType ) ) ; } } } } final Object interval = operand . get ( ""interval"" ) ; final List < Interval > intervals ; if ( interval instanceof String ) { intervals = ImmutableList . of ( new Interval ( ( String ) interval , ISOChronology . getInstanceUTC ( ) ) ) ; } else { intervals = null ; } final String dataSourceName = Util . first ( dataSource , name ) ; if ( dimensionsRaw == null || metricsRaw == null ) { DruidConnectionImpl connection = new DruidConnectionImpl ( druidSchema . url , druidSchema . url . replace ( "":8082"" , "":8081"" ) ) ; return DruidTable . create ( druidSchema , dataSourceName , intervals , fieldBuilder , metricNameBuilder , timestampColumnName , connection , complexMetrics ) ; } else { return DruidTable . create ( druidSchema , dataSourceName , intervals , fieldBuilder , metricNameBuilder , timestampColumnName , complexMetrics ) ; } }",Smelly
" public static ClientBuilder getClientBuilder ( Properties properties ) { ClientBuilder clientBuilder = PulsarClient . builder ( ) ; if ( properties . containsKey ( AUTHENTICATION_CLASS ) ) { String className = properties . getProperty ( AUTHENTICATION_CLASS ) ; try { if ( properties . containsKey ( AUTHENTICATION_PARAMS_STRING ) ) { String authParamsString = ( String ) properties . get ( AUTHENTICATION_PARAMS_STRING ) ; clientBuilder . authentication ( className , authParamsString ) ; } else if ( properties . containsKey ( AUTHENTICATION_PARAMS_MAP ) ) { Map < String , String > authParams = ( Map < String , String > ) properties . get ( AUTHENTICATION_PARAMS_MAP ) ; clientBuilder . authentication ( className , authParams ) ; } else { @ SuppressWarnings ( ""unchecked"" ) Class < Authentication > clazz = ( Class < Authentication > ) Class . forName ( className ) ; Authentication auth = clazz . newInstance ( ) ; clientBuilder . authentication ( auth ) ; } } catch ( Exception e ) { throw new RuntimeException ( e ) ; } } clientBuilder . enableTls ( Boolean . parseBoolean ( properties . getProperty ( USE_TLS , ""false"" ) ) ) ; clientBuilder . allowTlsInsecureConnection ( Boolean . parseBoolean ( properties . getProperty ( TLS_ALLOW_INSECURE_CONNECTION , ""false"" ) ) ) ; clientBuilder . enableTlsHostnameVerification ( Boolean . parseBoolean ( properties . getProperty ( TLS_HOSTNAME_VERIFICATION , ""false"" ) ) ) ; if ( properties . containsKey ( TLS_TRUST_CERTS_FILE_PATH ) ) { clientBuilder . tlsTrustCertsFilePath ( properties . getProperty ( TLS_TRUST_CERTS_FILE_PATH ) ) ; } if ( properties . containsKey ( OPERATION_TIMEOUT_MS ) ) { clientBuilder . operationTimeout ( Integer . parseInt ( properties . getProperty ( OPERATION_TIMEOUT_MS ) ) , TimeUnit . MILLISECONDS ) ; } if ( properties . containsKey ( STATS_INTERVAL_SECONDS ) ) { clientBuilder . statsInterval ( Integer . parseInt ( properties . getProperty ( STATS_INTERVAL_SECONDS ) ) , TimeUnit . SECONDS ) ; } if ( properties . containsKey ( NUM_IO_THREADS ) ) { clientBuilder . ioThreads ( Integer . parseInt ( properties . getProperty ( NUM_IO_THREADS ) ) ) ; } if ( properties . containsKey ( CONNECTIONS_PER_BROKER ) ) { clientBuilder . connectionsPerBroker ( Integer . parseInt ( properties . getProperty ( CONNECTIONS_PER_BROKER ) ) ) ; } if ( properties . containsKey ( USE_TCP_NODELAY ) ) { clientBuilder . enableTcpNoDelay ( Boolean . parseBoolean ( properties . getProperty ( USE_TCP_NODELAY ) ) ) ; } if ( properties . containsKey ( CONCURRENT_LOOKUP_REQUESTS ) ) { clientBuilder . maxConcurrentLookupRequests ( Integer . parseInt ( properties . getProperty ( CONCURRENT_LOOKUP_REQUESTS ) ) ) ; } if ( properties . containsKey ( MAX_NUMBER_OF_REJECTED_REQUESTS_PER_CONNECTION ) ) { clientBuilder . maxNumberOfRejectedRequestPerConnection ( Integer . parseInt ( properties . getProperty ( MAX_NUMBER_OF_REJECTED_REQUESTS_PER_CONNECTION ) ) ) ; } return clientBuilder ; }",Smelly
" public String toString ( ) { return myInt + "","" + myLong + "","" + myString ; }",No
 public void run ( ) { try { testBuilder . go ( ) ; } catch ( Exception e ) { throw new RuntimeException ( e ) ; } },No
" public void read ( org . apache . thrift . protocol . TProtocol prot , getChildDataProducts_result struct ) throws org . apache . thrift . TException { TTupleProtocol iprot = ( TTupleProtocol ) prot ; BitSet incoming = iprot . readBitSet ( 5 ) ; if ( incoming . get ( 0 ) ) { { org . apache . thrift . protocol . TList _list283 = new org . apache . thrift . protocol . TList ( org . apache . thrift . protocol . TType . STRUCT , iprot . readI32 ( ) ) ; struct . success = new ArrayList < org . apache . airavata . model . data . replica . DataProductModel > ( _list283 . size ) ; org . apache . airavata . model . data . replica . DataProductModel _elem284 ; for ( int _i285 = 0 ; _i285 < _list283 . size ; ++ _i285 ) { _elem284 = new org . apache . airavata . model . data . replica . DataProductModel ( ) ; _elem284 . read ( iprot ) ; struct . success . add ( _elem284 ) ; } } struct . setSuccessIsSet ( true ) ; } if ( incoming . get ( 1 ) ) { struct . ire = new org . apache . airavata . model . error . InvalidRequestException ( ) ; struct . ire . read ( iprot ) ; struct . setIreIsSet ( true ) ; } if ( incoming . get ( 2 ) ) { struct . ace = new org . apache . airavata . model . error . AiravataClientException ( ) ; struct . ace . read ( iprot ) ; struct . setAceIsSet ( true ) ; } if ( incoming . get ( 3 ) ) { struct . ase = new org . apache . airavata . model . error . AiravataSystemException ( ) ; struct . ase . read ( iprot ) ; struct . setAseIsSet ( true ) ; } if ( incoming . get ( 4 ) ) { struct . ae = new org . apache . airavata . model . error . AuthorizationException ( ) ; struct . ae . read ( iprot ) ; struct . setAeIsSet ( true ) ; } }",Smelly
" public QueueStatusBean run ( String user , String id ) throws NotAuthorizedException , BadParam , IOException , InterruptedException { UserGroupInformation ugi = UgiFactory . getUgi ( user ) ; WebHCatJTShim tracker = null ; JobState state = null ; try { tracker = ShimLoader . getHadoopShims ( ) . getWebHCatShim ( appConf , ugi ) ; JobID jobid = StatusDelegator . StringToJobID ( id ) ; if ( jobid == null ) throw new BadParam ( ""Invalid jobid: "" + id ) ; tracker . killJob ( jobid ) ; state = new JobState ( id , Main . getAppConfigInstance ( ) ) ; List < JobState > children = state . getChildren ( ) ; if ( children != null ) { for ( JobState child : children ) { try { tracker . killJob ( StatusDelegator . StringToJobID ( child . getId ( ) ) ) ; } catch ( IOException e ) { LOG . warn ( ""templeton: fail to kill job "" + child . getId ( ) ) ; } } } return StatusDelegator . makeStatus ( tracker , jobid , state ) ; } catch ( IllegalStateException e ) { throw new BadParam ( e . getMessage ( ) ) ; } finally { if ( tracker != null ) tracker . close ( ) ; if ( state != null ) state . close ( ) ; } }",No
" public void onProcessFailed ( ExecuteException e ) { pythonscriptRunning = false ; logger . error ( ""python process failed"" , e ) ; }",No
 private static < S extends org . apache . thrift . scheme . IScheme > S scheme ( org . apache . thrift . protocol . TProtocol proto ) { return ( org . apache . thrift . scheme . StandardScheme . class . equals ( proto . getScheme ( ) ) ? STANDARD_SCHEME_FACTORY : TUPLE_SCHEME_FACTORY ) . getScheme ( ) ; },No
" private static String sanitizeTrackingUrl ( String url ) { return ( url == null || url . trim ( ) . isEmpty ( ) ) ? ""N/A"" : url ; }",No
" public static void generateOrcFile ( Configuration conf , FileSystem fs , Path outputPath , Class recordClass ) throws IOException , InstantiationException , IllegalAccessException , InvocationTargetException { ObjectInspector inspector ; synchronized ( TestVectorizedORCReader . class ) { inspector = ObjectInspectorFactory . getReflectionObjectInspector ( recordClass , ObjectInspectorFactory . ObjectInspectorOptions . JAVA ) ; } Writer writer = OrcFile . createWriter ( fs , outputPath , conf , inspector , 100000 , CompressionKind . ZLIB , 10000 , 10000 ) ; try { Constructor [ ] constructors = recordClass . getConstructors ( ) ; if ( constructors . length != 1 ) { throw new UnsupportedOperationException ( ""The provided recordClass must have exactly one constructor."" ) ; } BatchDataDistribution [ ] dataDist = BatchDataDistribution . values ( ) ; Class [ ] columns = constructors [ 0 ] . getParameterTypes ( ) ; for ( int i = 0 ; i < dataDist . length * 3 ; i ++ ) { Object [ ] [ ] rows = new Object [ columns . length ] [ VectorizedRowBatch . DEFAULT_SIZE ] ; for ( int c = 0 ; c < columns . length ; c ++ ) { if ( ! TYPE_TO_BATCH_GEN_MAP . containsKey ( columns [ c ] ) ) { throw new UnsupportedOperationException ( ""No batch generator defined for type "" + columns [ c ] . getName ( ) ) ; } rows [ c ] = TYPE_TO_BATCH_GEN_MAP . get ( columns [ c ] ) . generateBatch ( dataDist [ ( i + c ) % dataDist . length ] ) ; } for ( int r = 0 ; r < VectorizedRowBatch . DEFAULT_SIZE ; r ++ ) { Object [ ] row = new Object [ columns . length ] ; for ( int c = 0 ; c < columns . length ; c ++ ) { row [ c ] = rows [ c ] [ r ] ; } writer . addRow ( constructors [ 0 ] . newInstance ( row ) ) ; } } } finally { writer . close ( ) ; } }",No
" public PCollection < KV < K , Iterable < V > > > expand ( PCollection < KeyedWorkItem < K , V > > input ) { KeyedWorkItemCoder < K , V > inputCoder = getKeyedWorkItemCoder ( input . getCoder ( ) ) ; return PCollection . createPrimitiveOutputInternal ( input . getPipeline ( ) , outputWindowingStrategy , input . isBounded ( ) , KvCoder . of ( inputCoder . getKeyCoder ( ) , IterableCoder . of ( inputCoder . getElementCoder ( ) ) ) ) ; }",No
" public void run ( ) { resetManager . registerMe ( ) ; try { IThreadContext threadContext = ThreadContextFactory . make ( ) ; IJobManager jobManager = JobManagerFactory . make ( threadContext ) ; Logging . threads . debug ( ""Expire stuffer thread: Maximum document count per check is "" + Integer . toString ( n ) ) ; HashMap documentSets = new HashMap ( ) ; HashMap jobDescriptionMap = new HashMap ( ) ; IDBInterface database = DBInterfaceFactory . make ( threadContext , ManifoldCF . getMasterDatabaseName ( ) , ManifoldCF . getMasterDatabaseUsername ( ) , ManifoldCF . getMasterDatabasePassword ( ) ) ; int deleteChunkSize = database . getMaxInClause ( ) ; while ( true ) { try { if ( Thread . currentThread ( ) . isInterrupted ( ) ) throw new ManifoldCFException ( ""Interrupted"" , ManifoldCFException . INTERRUPTED ) ; resetManager . waitForReset ( threadContext ) ; boolean isEmpty = documentQueue . checkIfEmpty ( n * 3 ) ; if ( isEmpty == false ) { sleep ( 1000 ) ; continue ; } Logging . threads . debug ( ""Expiration stuffer thread woke up"" ) ; long currentTime = System . currentTimeMillis ( ) ; DocumentSetAndFlags docsAndFlags = jobManager . getExpiredDocuments ( deleteChunkSize , currentTime ) ; DocumentDescription [ ] descs = docsAndFlags . getDocumentSet ( ) ; boolean [ ] deleteFromIndex = docsAndFlags . getFlags ( ) ; if ( Thread . currentThread ( ) . isInterrupted ( ) ) throw new ManifoldCFException ( ""Interrupted"" , ManifoldCFException . INTERRUPTED ) ; if ( Logging . threads . isDebugEnabled ( ) ) { Logging . threads . debug ( ""Expiration stuffer thread: Found "" + Integer . toString ( descs . length ) + "" documents to expire"" ) ; } if ( descs . length == 0 ) { ManifoldCF . sleep ( 60000L ) ; continue ; } Map jobMap = new HashMap ( ) ; int k = 0 ; while ( k < descs . length ) { CleanupQueuedDocument x = new CleanupQueuedDocument ( descs [ k ] , deleteFromIndex [ k ] ) ; Long jobID = descs [ k ] . getJobID ( ) ; List y = ( List ) jobMap . get ( jobID ) ; if ( y == null ) { y = new ArrayList ( ) ; jobMap . put ( jobID , y ) ; } y . add ( x ) ; k ++ ; } Iterator iter = jobMap . keySet ( ) . iterator ( ) ; while ( iter . hasNext ( ) ) { Long jobID = ( Long ) iter . next ( ) ; IJobDescription jobDescription = jobManager . load ( jobID , true ) ; List y = ( List ) jobMap . get ( jobID ) ; CleanupQueuedDocument [ ] docDescs = new CleanupQueuedDocument [ y . size ( ) ] ; k = 0 ; while ( k < docDescs . length ) { docDescs [ k ] = ( CleanupQueuedDocument ) y . get ( k ) ; k ++ ; } DocumentCleanupSet set = new DocumentCleanupSet ( docDescs , jobDescription ) ; documentQueue . addDocuments ( set ) ; } yield ( ) ; } catch ( ManifoldCFException e ) { if ( e . getErrorCode ( ) == ManifoldCFException . INTERRUPTED ) break ; if ( e . getErrorCode ( ) == ManifoldCFException . DATABASE_CONNECTION_ERROR ) { resetManager . noteEvent ( ) ; Logging . threads . error ( ""Expiration stuffer thread aborting and restarting due to database connection reset: "" + e . getMessage ( ) , e ) ; try { ManifoldCF . sleep ( 10000L ) ; } catch ( InterruptedException se ) { break ; } continue ; } Logging . threads . error ( ""Exception tossed: "" + e . getMessage ( ) , e ) ; if ( e . getErrorCode ( ) == ManifoldCFException . SETUP_ERROR ) { System . exit ( 1 ) ; } } catch ( InterruptedException e ) { break ; } catch ( OutOfMemoryError e ) { System . err . println ( ""agents process ran out of memory - shutting down"" ) ; e . printStackTrace ( System . err ) ; System . exit ( - 200 ) ; } catch ( Throwable e ) { Logging . threads . fatal ( ""Error tossed: "" + e . getMessage ( ) , e ) ; } } } catch ( Throwable e ) { System . err . println ( ""agents process could not start - shutting down"" ) ; Logging . threads . fatal ( ""ExpirationStufferThread initialization error tossed: "" + e . getMessage ( ) , e ) ; System . exit ( - 300 ) ; } }",Smelly
" public abstract void renewDelegationToken ( SessionHandle sessionHandle , HiveAuthFactory authFactory , String tokenStr ) throws HiveSQLException ;",No
" public Map act ( Redirector redirector , SourceResolver resolver , Map objectModel , String source , Parameters par ) throws Exception { if ( this . getLogger ( ) . isDebugEnabled ( ) ) { this . getLogger ( ) . debug ( ""BEGIN act resolver="" + resolver + "", objectModel="" + objectModel + "", source="" + source + "", par="" + par ) ; } Map result ; PortalService service = null ; try { service = ( PortalService ) this . manager . lookup ( PortalService . ROLE ) ; service . setPortalName ( par . getParameter ( ""portal-name"" ) ) ; PortalManager portalManager = null ; try { portalManager = ( PortalManager ) this . manager . lookup ( PortalManager . ROLE ) ; portalManager . process ( ) ; } finally { this . manager . release ( portalManager ) ; } final Request request = ObjectModelHelper . getRequest ( objectModel ) ; final Session session = request . getSession ( false ) ; final List events = new ArrayList ( ) ; final String historyValue = request . getParameter ( this . historyParameterName ) ; if ( historyValue != null && session != null ) { final List history = ( List ) session . getAttribute ( ""portal-history"" ) ; if ( history != null ) { final int index = Integer . parseInt ( historyValue ) ; final List state = ( List ) history . get ( index ) ; if ( state != null ) { final Iterator iter = state . iterator ( ) ; while ( iter . hasNext ( ) ) { Mapping m = ( Mapping ) iter . next ( ) ; events . add ( m . getEvent ( service , null ) ) ; } while ( history . size ( ) > index ) { history . remove ( history . size ( ) - 1 ) ; } } } } Enumeration enumeration = request . getParameterNames ( ) ; while ( enumeration . hasMoreElements ( ) ) { String name = ( String ) enumeration . nextElement ( ) ; String value = request . getParameter ( name ) ; Mapping m = ( Mapping ) this . eventMap . get ( name ) ; if ( m != null ) { events . add ( m . getEvent ( service , value ) ) ; } } String uri = service . getComponentManager ( ) . getLinkService ( ) . getLinkURI ( events ) ; result = new HashMap ( ) ; result . put ( ""uri"" , uri . substring ( uri . indexOf ( '?' ) + 1 ) ) ; } catch ( ParameterException pe ) { throw new ProcessingException ( ""Parameter portal-name is required."" ) ; } catch ( ServiceException ce ) { throw new ProcessingException ( ""Unable to lookup portal service."" , ce ) ; } finally { this . manager . release ( service ) ; } if ( this . getLogger ( ) . isDebugEnabled ( ) ) { this . getLogger ( ) . debug ( ""END act map={}"" ) ; } return result ; }",Smelly
" public String toString ( ) { return this . getClass ( ) . getSimpleName ( ) + "" ["" + this . id + ""]"" ; }",No
" public void execute ( ) throws MojoExecutionException { outputDir . mkdirs ( ) ; if ( wsdltoidlOptions == null ) { throw new MojoExecutionException ( ""Please specify the wsdltoidl options"" ) ; } List < URL > urlList = new ArrayList < URL > ( ) ; StringBuilder buf = new StringBuilder ( ) ; try { urlList . add ( outputDir . toURI ( ) . toURL ( ) ) ; } catch ( MalformedURLException e ) { } buf . append ( outputDir . getAbsolutePath ( ) ) ; buf . append ( File . pathSeparatorChar ) ; List < ? > artifacts = useCompileClasspath ? project . getCompileArtifacts ( ) : project . getTestArtifacts ( ) ; for ( Artifact a : CastUtils . cast ( artifacts , Artifact . class ) ) { try { if ( a . getFile ( ) != null && a . getFile ( ) . exists ( ) ) { urlList . add ( a . getFile ( ) . toURI ( ) . toURL ( ) ) ; buf . append ( a . getFile ( ) . getAbsolutePath ( ) ) ; buf . append ( File . pathSeparatorChar ) ; } } catch ( MalformedURLException e ) { } } ClassLoader origContext = Thread . currentThread ( ) . getContextClassLoader ( ) ; URLClassLoader loader = new URLClassLoader ( urlList . toArray ( new URL [ urlList . size ( ) ] ) , origContext ) ; String newCp = buf . toString ( ) ; Map < Object , Object > origProps = new HashMap < Object , Object > ( System . getProperties ( ) ) ; String cp = System . getProperty ( ""java.class.path"" ) ; try { Thread . currentThread ( ) . setContextClassLoader ( loader ) ; System . setProperty ( ""java.class.path"" , newCp ) ; for ( int x = 0 ; x < wsdltoidlOptions . length ; x ++ ) { File file = new File ( wsdltoidlOptions [ x ] . getWSDL ( ) ) ; File doneFile = new File ( outputDir , ""."" + file . getName ( ) + "".DONE"" ) ; boolean doWork = file . lastModified ( ) > doneFile . lastModified ( ) ; if ( ! doneFile . exists ( ) ) { doWork = true ; } else if ( file . lastModified ( ) > doneFile . lastModified ( ) ) { doWork = true ; } if ( doWork ) { List < String > list = new ArrayList < String > ( ) ; list . add ( ""-d"" ) ; list . add ( outputDir . getAbsolutePath ( ) ) ; if ( wsdltoidlOptions [ x ] . isCorbaEnabled ( ) ) { list . add ( ""-corba"" ) ; } if ( wsdltoidlOptions [ x ] . isIdlEnabled ( ) ) { list . add ( ""-idl"" ) ; } if ( wsdltoidlOptions [ x ] . getExtraargs ( ) != null ) { list . addAll ( wsdltoidlOptions [ x ] . getExtraargs ( ) ) ; } list . add ( wsdltoidlOptions [ x ] . getWSDL ( ) ) ; try { WSDLToIDL . run ( list . toArray ( new String [ list . size ( ) ] ) ) ; doneFile . delete ( ) ; doneFile . createNewFile ( ) ; } catch ( Throwable e ) { e . printStackTrace ( ) ; throw new MojoExecutionException ( e . getMessage ( ) , e ) ; } } } } finally { Bus bus = BusFactory . getDefaultBus ( false ) ; if ( bus != null ) { bus . shutdown ( true ) ; } Thread . currentThread ( ) . setContextClassLoader ( origContext ) ; System . setProperty ( ""java.class.path"" , cp ) ; Map < Object , Object > newProps = new HashMap < Object , Object > ( System . getProperties ( ) ) ; for ( Object o : newProps . keySet ( ) ) { if ( ! origProps . containsKey ( o ) ) { System . clearProperty ( o . toString ( ) ) ; } } System . getProperties ( ) . putAll ( origProps ) ; } }",Smelly
 IsisSessionFactory getIsisSessionFactory ( ) { return IsisContext . getSessionFactory ( ) ; },No
 boolean isMarshallAware ( ) ;,No
" public void read ( org . apache . thrift . protocol . TProtocol prot , getFollowing_result struct ) throws org . apache . thrift . TException { TTupleProtocol iprot = ( TTupleProtocol ) prot ; BitSet incoming = iprot . readBitSet ( 1 ) ; if ( incoming . get ( 0 ) ) { struct . success = new Key ( ) ; struct . success . read ( iprot ) ; struct . setSuccessIsSet ( true ) ; } }",Smelly
" public void looseMarshal ( OpenWireFormat wireFormat , Object o , DataOutput dataOut ) throws IOException { ConnectionControl info = ( ConnectionControl ) o ; super . looseMarshal ( wireFormat , o , dataOut ) ; dataOut . writeBoolean ( info . isClose ( ) ) ; dataOut . writeBoolean ( info . isExit ( ) ) ; dataOut . writeBoolean ( info . isFaultTolerant ( ) ) ; dataOut . writeBoolean ( info . isResume ( ) ) ; dataOut . writeBoolean ( info . isSuspend ( ) ) ; looseMarshalString ( info . getConnectedBrokers ( ) , dataOut ) ; looseMarshalString ( info . getReconnectTo ( ) , dataOut ) ; dataOut . writeBoolean ( info . isRebalanceConnection ( ) ) ; }",No
" public void read ( org . apache . thrift . protocol . TProtocol prot , DataStagingTaskModel struct ) throws org . apache . thrift . TException { TTupleProtocol iprot = ( TTupleProtocol ) prot ; struct . source = iprot . readString ( ) ; struct . setSourceIsSet ( true ) ; struct . destination = iprot . readString ( ) ; struct . setDestinationIsSet ( true ) ; struct . type = org . apache . airavata . model . task . DataStageType . findByValue ( iprot . readI32 ( ) ) ; struct . setTypeIsSet ( true ) ; BitSet incoming = iprot . readBitSet ( 5 ) ; if ( incoming . get ( 0 ) ) { struct . transferStartTime = iprot . readI64 ( ) ; struct . setTransferStartTimeIsSet ( true ) ; } if ( incoming . get ( 1 ) ) { struct . transferEndTime = iprot . readI64 ( ) ; struct . setTransferEndTimeIsSet ( true ) ; } if ( incoming . get ( 2 ) ) { struct . transferRate = iprot . readString ( ) ; struct . setTransferRateIsSet ( true ) ; } if ( incoming . get ( 3 ) ) { struct . processInput = new org . apache . airavata . model . application . io . InputDataObjectType ( ) ; struct . processInput . read ( iprot ) ; struct . setProcessInputIsSet ( true ) ; } if ( incoming . get ( 4 ) ) { struct . processOutput = new org . apache . airavata . model . application . io . OutputDataObjectType ( ) ; struct . processOutput . read ( iprot ) ; struct . setProcessOutputIsSet ( true ) ; } }",Smelly
" private void initTaskAttemptStatus ( TaskAttemptStatus result ) { result . progress = 0.0f ; result . phase = Phase . STARTING ; result . stateString = ""NEW"" ; result . taskState = TaskAttemptState . NEW ; Counters counters = EMPTY_COUNTERS ; result . counters = counters ; }",No
" public void read ( org . apache . thrift . protocol . TProtocol prot , getFollowing_result struct ) throws org . apache . thrift . TException { TTupleProtocol iprot = ( TTupleProtocol ) prot ; BitSet incoming = iprot . readBitSet ( 1 ) ; if ( incoming . get ( 0 ) ) { struct . success = new Key ( ) ; struct . success . read ( iprot ) ; struct . setSuccessIsSet ( true ) ; } }",No
 private static < S extends org . apache . thrift . scheme . IScheme > S scheme ( org . apache . thrift . protocol . TProtocol proto ) { return ( org . apache . thrift . scheme . StandardScheme . class . equals ( proto . getScheme ( ) ) ? STANDARD_SCHEME_FACTORY : TUPLE_SCHEME_FACTORY ) . getScheme ( ) ; },No
" public void onMatch ( RelOptRuleCall call ) { final Aggregate aggregate = call . rel ( 0 ) ; final Filter filter = call . rel ( 1 ) ; final ImmutableBitSet filterColumns = RelOptUtil . InputFinder . bits ( filter . getCondition ( ) ) ; final ImmutableBitSet newGroupSet = aggregate . getGroupSet ( ) . union ( filterColumns ) ; final RelNode input = filter . getInput ( ) ; final RelMetadataQuery mq = call . getMetadataQuery ( ) ; final Boolean unique = mq . areColumnsUnique ( input , newGroupSet ) ; if ( unique != null && unique ) { return ; } final boolean allColumnsInAggregate = aggregate . getGroupSet ( ) . contains ( filterColumns ) ; final Aggregate newAggregate = aggregate . copy ( aggregate . getTraitSet ( ) , input , newGroupSet , null , aggregate . getAggCallList ( ) ) ; final Mappings . TargetMapping mapping = Mappings . target ( newGroupSet :: indexOf , input . getRowType ( ) . getFieldCount ( ) , newGroupSet . cardinality ( ) ) ; final RexNode newCondition = RexUtil . apply ( mapping , filter . getCondition ( ) ) ; final Filter newFilter = filter . copy ( filter . getTraitSet ( ) , newAggregate , newCondition ) ; if ( allColumnsInAggregate && aggregate . getGroupType ( ) == Group . SIMPLE ) { assert newGroupSet . equals ( aggregate . getGroupSet ( ) ) ; call . transformTo ( newFilter ) ; } else { final ImmutableBitSet . Builder topGroupSet = ImmutableBitSet . builder ( ) ; for ( int c : aggregate . getGroupSet ( ) ) { topGroupSet . set ( newGroupSet . indexOf ( c ) ) ; } ImmutableList < ImmutableBitSet > newGroupingSets = null ; if ( aggregate . getGroupType ( ) != Group . SIMPLE ) { ImmutableList . Builder < ImmutableBitSet > newGroupingSetsBuilder = ImmutableList . builder ( ) ; for ( ImmutableBitSet groupingSet : aggregate . getGroupSets ( ) ) { final ImmutableBitSet . Builder newGroupingSet = ImmutableBitSet . builder ( ) ; for ( int c : groupingSet ) { newGroupingSet . set ( newGroupSet . indexOf ( c ) ) ; } newGroupingSetsBuilder . add ( newGroupingSet . build ( ) ) ; } newGroupingSets = newGroupingSetsBuilder . build ( ) ; } final List < AggregateCall > topAggCallList = new ArrayList < > ( ) ; int i = newGroupSet . cardinality ( ) ; for ( AggregateCall aggregateCall : aggregate . getAggCallList ( ) ) { final SqlAggFunction rollup = SubstitutionVisitor . getRollup ( aggregateCall . getAggregation ( ) ) ; if ( rollup == null ) { return ; } if ( aggregateCall . isDistinct ( ) ) { return ; } topAggCallList . add ( AggregateCall . create ( rollup , aggregateCall . isDistinct ( ) , aggregateCall . isApproximate ( ) , aggregateCall . ignoreNulls ( ) , ImmutableList . of ( i ++ ) , - 1 , aggregateCall . collation , aggregateCall . type , aggregateCall . name ) ) ; } final Aggregate topAggregate = aggregate . copy ( aggregate . getTraitSet ( ) , newFilter , topGroupSet . build ( ) , newGroupingSets , topAggCallList ) ; call . transformTo ( topAggregate ) ; } }",Smelly
" public void read ( org . apache . thrift . protocol . TProtocol prot , drainReplicationTable_result struct ) throws org . apache . thrift . TException { TTupleProtocol iprot = ( TTupleProtocol ) prot ; BitSet incoming = iprot . readBitSet ( 1 ) ; if ( incoming . get ( 0 ) ) { struct . success = iprot . readBool ( ) ; struct . setSuccessIsSet ( true ) ; } }",Smelly
 public void setUrl ( String url ) { this . url = url ; },No
" public void signInJustDelegatesToAuthenticateAndSavesState ( ) { context . checking ( new Expectations ( ) { { one ( mockAuthMgr ) . authenticate ( with ( any ( AuthenticationRequest . class ) ) ) ; } } ) ; webSession = new AuthenticatedWebSessionForIsis ( stubRequest ) { private static final long serialVersionUID = 1L ; @ Override protected AuthenticationManager getAuthenticationManager ( ) { return mockAuthMgr ; } } ; webSession . signIn ( ""john"" , ""secret"" ) ; assertThat ( webSession . isSignedIn ( ) , is ( true ) ) ; }",No
" XScriptObject removeFirst ( XScriptVariableScope pageScope , Map objectModel , String name ) throws IllegalArgumentException ;",No
" boolean hasEntry ( long entryId , int bookieIndex ) ;",No
" private static String sanitizeTrackingUrl ( String url ) { return ( url == null || url . trim ( ) . isEmpty ( ) ) ? ""N/A"" : url ; }",No
" public com . google . protobuf . ExtensionRegistry assignDescriptors ( com . google . protobuf . Descriptors . FileDescriptor root ) { descriptor = root ; internal_static_Status_descriptor = getDescriptor ( ) . getMessageTypes ( ) . get ( 0 ) ; internal_static_Status_fieldAccessorTable = new com . google . protobuf . GeneratedMessage . FieldAccessorTable ( internal_static_Status_descriptor , new java . lang . String [ ] { ""Begin"" , ""End"" , ""InfiniteEnd"" , ""Closed"" , ""CreatedTime"" , } ) ; return null ; }",No
 String getPathStr ( ) ;,No
" public Set < ContainerModel > group ( Set < TaskModel > taskModels , GrouperMetadata grouperMetadata ) { Map < TaskName , LocationId > taskLocality = grouperMetadata . getTaskLocality ( ) ; Preconditions . checkArgument ( ! taskModels . isEmpty ( ) , ""No tasks found. Likely due to no input partitions. Can't run a job with no tasks."" ) ; if ( MapUtils . isEmpty ( grouperMetadata . getProcessorLocality ( ) ) ) { LOG . info ( ""ProcessorLocality is empty. Generating with the default group method."" ) ; return group ( taskModels , new ArrayList < > ( ) ) ; } Map < String , LocationId > processorLocality = new TreeMap < > ( grouperMetadata . getProcessorLocality ( ) ) ; if ( processorLocality . size ( ) > taskModels . size ( ) ) { processorLocality = processorLocality . entrySet ( ) . stream ( ) . limit ( taskModels . size ( ) ) . collect ( Collectors . toMap ( Map . Entry :: getKey , Map . Entry :: getValue ) ) ; } Map < LocationId , List < String > > locationIdToProcessors = new HashMap < > ( ) ; Map < String , TaskGroup > processorIdToTaskGroup = new HashMap < > ( ) ; processorLocality . forEach ( ( processorId , locationId ) -> { List < String > processorIds = locationIdToProcessors . getOrDefault ( locationId , new ArrayList < > ( ) ) ; processorIds . add ( processorId ) ; locationIdToProcessors . put ( locationId , processorIds ) ; processorIdToTaskGroup . put ( processorId , new TaskGroup ( processorId , new ArrayList < > ( ) ) ) ; } ) ; int numTasksPerProcessor = taskModels . size ( ) / processorLocality . size ( ) ; Set < TaskName > assignedTasks = new HashSet < > ( ) ; for ( TaskModel taskModel : taskModels ) { LocationId taskLocationId = taskLocality . get ( taskModel . getTaskName ( ) ) ; if ( taskLocationId != null ) { List < String > processorIds = locationIdToProcessors . getOrDefault ( taskLocationId , new ArrayList < > ( ) ) ; for ( String processorId : processorIds ) { TaskGroup taskGroup = processorIdToTaskGroup . get ( processorId ) ; if ( taskGroup . size ( ) < numTasksPerProcessor ) { taskGroup . addTaskName ( taskModel . getTaskName ( ) . getTaskName ( ) ) ; assignedTasks . add ( taskModel . getTaskName ( ) ) ; break ; } } } } Iterator < String > processorIdsCyclicIterator = Iterators . cycle ( processorLocality . keySet ( ) ) ; List < TaskGroup > taskGroups = new ArrayList < > ( processorIdToTaskGroup . values ( ) ) ; taskGroups . sort ( Comparator . comparing ( TaskGroup :: getContainerId ) ) ; for ( TaskModel taskModel : taskModels ) { if ( ! assignedTasks . contains ( taskModel . getTaskName ( ) ) ) { Optional < TaskGroup > underAssignedTaskGroup = taskGroups . stream ( ) . filter ( taskGroup -> taskGroup . size ( ) < numTasksPerProcessor ) . findFirst ( ) ; if ( underAssignedTaskGroup . isPresent ( ) ) { underAssignedTaskGroup . get ( ) . addTaskName ( taskModel . getTaskName ( ) . getTaskName ( ) ) ; } else { TaskGroup taskGroup = processorIdToTaskGroup . get ( processorIdsCyclicIterator . next ( ) ) ; taskGroup . addTaskName ( taskModel . getTaskName ( ) . getTaskName ( ) ) ; } assignedTasks . add ( taskModel . getTaskName ( ) ) ; } } return TaskGroup . buildContainerModels ( taskModels , taskGroups ) ; }",Smelly
" public void parentAlreadyEncountered ( ) throws Exception { final ApplicationFeatureId packageId = ApplicationFeatureId . newPackage ( ""com.mycompany"" ) ; final ApplicationFeature pkg = new ApplicationFeature ( ) ; pkg . setFeatureId ( packageId ) ; applicationFeatureRepository . packageFeatures . put ( packageId , pkg ) ; final ApplicationFeatureId classFeatureId = ApplicationFeatureId . newClass ( ""com.mycompany.Bar"" ) ; final ApplicationFeatureId applicationFeatureId = applicationFeatureRepository . addClassParent ( classFeatureId ) ; Assert . assertThat ( applicationFeatureId , is ( equalTo ( packageId ) ) ) ; }",Smelly
" public int getType ( ) throws RepositoryException , RemoteException { try { return property . getType ( ) ; } catch ( RepositoryException ex ) { throw getRepositoryException ( ex ) ; } }",No
" public void dropIndexes ( ) { try { connection ( ) . exec ( ""DROP INDEX PredObj IF EXISTS"" ) ; connection ( ) . exec ( ""DROP INDEX ObjSubj IF EXISTS"" ) ; } catch ( SQLException ex ) { throw new SDBExceptionSQL ( ""SQLException dropping indexes for table 'Triples'"" , ex ) ; } }",No
 public ArrayList < String > getPt3 ( ) { return this . pt3 ; },No
" public void read ( org . apache . thrift . protocol . TProtocol prot , getChildDataProducts_result struct ) throws org . apache . thrift . TException { TTupleProtocol iprot = ( TTupleProtocol ) prot ; BitSet incoming = iprot . readBitSet ( 5 ) ; if ( incoming . get ( 0 ) ) { { org . apache . thrift . protocol . TList _list283 = new org . apache . thrift . protocol . TList ( org . apache . thrift . protocol . TType . STRUCT , iprot . readI32 ( ) ) ; struct . success = new ArrayList < org . apache . airavata . model . data . replica . DataProductModel > ( _list283 . size ) ; org . apache . airavata . model . data . replica . DataProductModel _elem284 ; for ( int _i285 = 0 ; _i285 < _list283 . size ; ++ _i285 ) { _elem284 = new org . apache . airavata . model . data . replica . DataProductModel ( ) ; _elem284 . read ( iprot ) ; struct . success . add ( _elem284 ) ; } } struct . setSuccessIsSet ( true ) ; } if ( incoming . get ( 1 ) ) { struct . ire = new org . apache . airavata . model . error . InvalidRequestException ( ) ; struct . ire . read ( iprot ) ; struct . setIreIsSet ( true ) ; } if ( incoming . get ( 2 ) ) { struct . ace = new org . apache . airavata . model . error . AiravataClientException ( ) ; struct . ace . read ( iprot ) ; struct . setAceIsSet ( true ) ; } if ( incoming . get ( 3 ) ) { struct . ase = new org . apache . airavata . model . error . AiravataSystemException ( ) ; struct . ase . read ( iprot ) ; struct . setAseIsSet ( true ) ; } if ( incoming . get ( 4 ) ) { struct . ae = new org . apache . airavata . model . error . AuthorizationException ( ) ; struct . ae . read ( iprot ) ; struct . setAeIsSet ( true ) ; } }",Smelly
" void delete_node_blobstore ( String path , String nimbusHostPortInfo ) ;",No
 public DoubleWritable createInitialValue ( ) { return new DoubleWritable ( Double . NEGATIVE_INFINITY ) ; },No
" protected ClientCsdlParameter doDeserialize ( final JsonParser jp , final DeserializationContext ctxt ) throws IOException { final ClientCsdlParameter parameter = new ClientCsdlParameter ( ) ; for ( ; jp . getCurrentToken ( ) != JsonToken . END_OBJECT ; jp . nextToken ( ) ) { final JsonToken token = jp . getCurrentToken ( ) ; if ( token == JsonToken . FIELD_NAME ) { if ( ""Name"" . equals ( jp . getCurrentName ( ) ) ) { parameter . setName ( jp . nextTextValue ( ) ) ; } else if ( ""Type"" . equals ( jp . getCurrentName ( ) ) ) { String metadataTypeName = jp . nextTextValue ( ) ; if ( metadataTypeName . startsWith ( ""Collection("" ) ) { parameter . setType ( metadataTypeName . substring ( metadataTypeName . indexOf ( ""("" ) + 1 , metadataTypeName . length ( ) - 1 ) ) ; parameter . setCollection ( true ) ; } else { parameter . setType ( metadataTypeName ) ; parameter . setCollection ( false ) ; } } else if ( ""Nullable"" . equals ( jp . getCurrentName ( ) ) ) { parameter . setNullable ( BooleanUtils . toBoolean ( jp . nextTextValue ( ) ) ) ; } else if ( ""MaxLength"" . equals ( jp . getCurrentName ( ) ) ) { final String maxLenght = jp . nextTextValue ( ) ; parameter . setMaxLength ( maxLenght . equalsIgnoreCase ( ""max"" ) ? Integer . MAX_VALUE : Integer . valueOf ( maxLenght ) ) ; } else if ( ""Precision"" . equals ( jp . getCurrentName ( ) ) ) { parameter . setPrecision ( Integer . valueOf ( jp . nextTextValue ( ) ) ) ; } else if ( ""Scale"" . equals ( jp . getCurrentName ( ) ) ) { final String scale = jp . nextTextValue ( ) ; parameter . setScale ( scale . equalsIgnoreCase ( ""variable"" ) ? 0 : Integer . valueOf ( scale ) ) ; } else if ( ""SRID"" . equals ( jp . getCurrentName ( ) ) ) { final String srid = jp . nextTextValue ( ) ; if ( srid != null ) { parameter . setSrid ( SRID . valueOf ( srid ) ) ; } } else if ( ""Annotation"" . equals ( jp . getCurrentName ( ) ) ) { jp . nextToken ( ) ; parameter . getAnnotations ( ) . add ( jp . readValueAs ( ClientCsdlAnnotation . class ) ) ; } } } return parameter ; }",Smelly
 private Instant ts ( long millis ) { return new Instant ( millis ) ; },No
" public String toString ( ) { StringBuilder builder = new StringBuilder ( ""AfterAll.of("" ) ; Joiner . on ( "", "" ) . appendTo ( builder , subTriggers ) ; builder . append ( "")"" ) ; return builder . toString ( ) ; }",No
" public void read ( org . apache . thrift . protocol . TProtocol prot , getFollowing_result struct ) throws org . apache . thrift . TException { TTupleProtocol iprot = ( TTupleProtocol ) prot ; BitSet incoming = iprot . readBitSet ( 1 ) ; if ( incoming . get ( 0 ) ) { struct . success = new Key ( ) ; struct . success . read ( iprot ) ; struct . setSuccessIsSet ( true ) ; } }",Smelly
 public void setPresettle ( boolean presettle ) { this . presettle = presettle ; },No
 private static < S extends org . apache . thrift . scheme . IScheme > S scheme ( org . apache . thrift . protocol . TProtocol proto ) { return ( org . apache . thrift . scheme . StandardScheme . class . equals ( proto . getScheme ( ) ) ? STANDARD_SCHEME_FACTORY : TUPLE_SCHEME_FACTORY ) . getScheme ( ) ; },Smelly
" public Void call ( ) throws Exception { log . info ( ""Shutting down TaskManager{}."" , stopAgents ? "" and agents"" : """" ) ; for ( NodeManager nodeManager : nodeManagers . values ( ) ) { nodeManager . beginShutdown ( stopAgents ) ; } for ( NodeManager nodeManager : nodeManagers . values ( ) ) { nodeManager . waitForShutdown ( ) ; } executor . shutdown ( ) ; return null ; }",Smelly
" public void read ( org . apache . thrift . protocol . TProtocol prot , getFollowing_result struct ) throws org . apache . thrift . TException { TTupleProtocol iprot = ( TTupleProtocol ) prot ; BitSet incoming = iprot . readBitSet ( 1 ) ; if ( incoming . get ( 0 ) ) { struct . success = new Key ( ) ; struct . success . read ( iprot ) ; struct . setSuccessIsSet ( true ) ; } }",Smelly
" private final void checkLength ( Tuple < ? > tuple ) { if ( CHECKING ) { if ( tuple . len ( ) != length ( ) ) throw new IllegalArgumentException ( ""Tuple length "" + tuple . len ( ) + "": not of length "" + length ( ) ) ; } }",No
 public String getInfo ( ) { return null ; },No
" public void read ( org . apache . thrift . protocol . TProtocol prot , onReceivedZeppelinResource_result struct ) throws org . apache . thrift . TException { TTupleProtocol iprot = ( TTupleProtocol ) prot ; }",No
" public void read ( org . apache . thrift . protocol . TProtocol prot , CommunityUser struct ) throws org . apache . thrift . TException { TTupleProtocol iprot = ( TTupleProtocol ) prot ; struct . gatewayName = iprot . readString ( ) ; struct . setGatewayNameIsSet ( true ) ; struct . username = iprot . readString ( ) ; struct . setUsernameIsSet ( true ) ; struct . userEmail = iprot . readString ( ) ; struct . setUserEmailIsSet ( true ) ; }",Smelly
" public void read ( org . apache . thrift . protocol . TProtocol prot , getFollowing_result struct ) throws org . apache . thrift . TException { TTupleProtocol iprot = ( TTupleProtocol ) prot ; BitSet incoming = iprot . readBitSet ( 1 ) ; if ( incoming . get ( 0 ) ) { struct . success = new Key ( ) ; struct . success . read ( iprot ) ; struct . setSuccessIsSet ( true ) ; } }",Smelly
 void abort ( ) { },No
 private static < S extends org . apache . thrift . scheme . IScheme > S scheme ( org . apache . thrift . protocol . TProtocol proto ) { return ( org . apache . thrift . scheme . StandardScheme . class . equals ( proto . getScheme ( ) ) ? STANDARD_SCHEME_FACTORY : TUPLE_SCHEME_FACTORY ) . getScheme ( ) ; },Smelly
" public void read ( org . apache . thrift . protocol . TProtocol prot , onReceivedZeppelinResource_result struct ) throws org . apache . thrift . TException { TTupleProtocol iprot = ( TTupleProtocol ) prot ; }",Smelly
" public void read ( org . apache . thrift . protocol . TProtocol prot , OutputDataObjectType struct ) throws org . apache . thrift . TException { TTupleProtocol iprot = ( TTupleProtocol ) prot ; struct . name = iprot . readString ( ) ; struct . setNameIsSet ( true ) ; BitSet incoming = iprot . readBitSet ( 10 ) ; if ( incoming . get ( 0 ) ) { struct . value = iprot . readString ( ) ; struct . setValueIsSet ( true ) ; } if ( incoming . get ( 1 ) ) { struct . type = org . apache . airavata . model . application . io . DataType . findByValue ( iprot . readI32 ( ) ) ; struct . setTypeIsSet ( true ) ; } if ( incoming . get ( 2 ) ) { struct . applicationArgument = iprot . readString ( ) ; struct . setApplicationArgumentIsSet ( true ) ; } if ( incoming . get ( 3 ) ) { struct . isRequired = iprot . readBool ( ) ; struct . setIsRequiredIsSet ( true ) ; } if ( incoming . get ( 4 ) ) { struct . requiredToAddedToCommandLine = iprot . readBool ( ) ; struct . setRequiredToAddedToCommandLineIsSet ( true ) ; } if ( incoming . get ( 5 ) ) { struct . dataMovement = iprot . readBool ( ) ; struct . setDataMovementIsSet ( true ) ; } if ( incoming . get ( 6 ) ) { struct . location = iprot . readString ( ) ; struct . setLocationIsSet ( true ) ; } if ( incoming . get ( 7 ) ) { struct . searchQuery = iprot . readString ( ) ; struct . setSearchQueryIsSet ( true ) ; } if ( incoming . get ( 8 ) ) { struct . outputStreaming = iprot . readBool ( ) ; struct . setOutputStreamingIsSet ( true ) ; } if ( incoming . get ( 9 ) ) { struct . storageResourceId = iprot . readString ( ) ; struct . setStorageResourceIdIsSet ( true ) ; } }",Smelly
" public void read ( org . apache . thrift . protocol . TProtocol prot , getChildDataProducts_result struct ) throws org . apache . thrift . TException { TTupleProtocol iprot = ( TTupleProtocol ) prot ; BitSet incoming = iprot . readBitSet ( 5 ) ; if ( incoming . get ( 0 ) ) { { org . apache . thrift . protocol . TList _list283 = new org . apache . thrift . protocol . TList ( org . apache . thrift . protocol . TType . STRUCT , iprot . readI32 ( ) ) ; struct . success = new ArrayList < org . apache . airavata . model . data . replica . DataProductModel > ( _list283 . size ) ; org . apache . airavata . model . data . replica . DataProductModel _elem284 ; for ( int _i285 = 0 ; _i285 < _list283 . size ; ++ _i285 ) { _elem284 = new org . apache . airavata . model . data . replica . DataProductModel ( ) ; _elem284 . read ( iprot ) ; struct . success . add ( _elem284 ) ; } } struct . setSuccessIsSet ( true ) ; } if ( incoming . get ( 1 ) ) { struct . ire = new org . apache . airavata . model . error . InvalidRequestException ( ) ; struct . ire . read ( iprot ) ; struct . setIreIsSet ( true ) ; } if ( incoming . get ( 2 ) ) { struct . ace = new org . apache . airavata . model . error . AiravataClientException ( ) ; struct . ace . read ( iprot ) ; struct . setAceIsSet ( true ) ; } if ( incoming . get ( 3 ) ) { struct . ase = new org . apache . airavata . model . error . AiravataSystemException ( ) ; struct . ase . read ( iprot ) ; struct . setAseIsSet ( true ) ; } if ( incoming . get ( 4 ) ) { struct . ae = new org . apache . airavata . model . error . AuthorizationException ( ) ; struct . ae . read ( iprot ) ; struct . setAeIsSet ( true ) ; } }",Smelly
" public int compare ( Object o1 , Object o2 ) { List < String > o1Names = null ; List < String > o2Names = null ; if ( ( o1 instanceof AttributeTypeDifference ) && ( o2 instanceof AttributeTypeDifference ) ) { AttributeTypeDifference atd1 = ( AttributeTypeDifference ) o1 ; AttributeTypeDifference atd2 = ( AttributeTypeDifference ) o2 ; switch ( atd1 . getType ( ) ) { case ADDED : o1Names = ( ( SchemaObject ) atd1 . getDestination ( ) ) . getNames ( ) ; break ; case MODIFIED : o1Names = ( ( SchemaObject ) atd1 . getDestination ( ) ) . getNames ( ) ; break ; case REMOVED : o1Names = ( ( SchemaObject ) atd1 . getSource ( ) ) . getNames ( ) ; break ; case IDENTICAL : o1Names = ( ( SchemaObject ) atd1 . getDestination ( ) ) . getNames ( ) ; break ; } switch ( atd2 . getType ( ) ) { case ADDED : o2Names = ( ( SchemaObject ) atd2 . getDestination ( ) ) . getNames ( ) ; break ; case MODIFIED : o2Names = ( ( SchemaObject ) atd2 . getDestination ( ) ) . getNames ( ) ; break ; case REMOVED : o2Names = ( ( SchemaObject ) atd2 . getSource ( ) ) . getNames ( ) ; break ; case IDENTICAL : o2Names = ( ( SchemaObject ) atd2 . getDestination ( ) ) . getNames ( ) ; break ; } } else if ( ( o1 instanceof ObjectClassDifference ) && ( o2 instanceof ObjectClassDifference ) ) { ObjectClassDifference ocd1 = ( ObjectClassDifference ) o1 ; ObjectClassDifference ocd2 = ( ObjectClassDifference ) o2 ; switch ( ocd1 . getType ( ) ) { case ADDED : o1Names = ( ( SchemaObject ) ocd1 . getDestination ( ) ) . getNames ( ) ; break ; case MODIFIED : o1Names = ( ( SchemaObject ) ocd1 . getDestination ( ) ) . getNames ( ) ; break ; case REMOVED : o1Names = ( ( SchemaObject ) ocd1 . getSource ( ) ) . getNames ( ) ; break ; case IDENTICAL : o1Names = ( ( SchemaObject ) ocd1 . getDestination ( ) ) . getNames ( ) ; break ; } switch ( ocd2 . getType ( ) ) { case ADDED : o2Names = ( ( SchemaObject ) ocd2 . getDestination ( ) ) . getNames ( ) ; break ; case MODIFIED : o2Names = ( ( SchemaObject ) ocd2 . getDestination ( ) ) . getNames ( ) ; break ; case REMOVED : o2Names = ( ( SchemaObject ) ocd2 . getSource ( ) ) . getNames ( ) ; break ; case IDENTICAL : o2Names = ( ( SchemaObject ) ocd2 . getDestination ( ) ) . getNames ( ) ; break ; } } else if ( ( o1 instanceof AttributeTypeDifference ) && ( o2 instanceof ObjectClassDifference ) ) { AttributeTypeDifference atd = ( AttributeTypeDifference ) o1 ; ObjectClassDifference ocd = ( ObjectClassDifference ) o2 ; switch ( atd . getType ( ) ) { case ADDED : o1Names = ( ( SchemaObject ) atd . getDestination ( ) ) . getNames ( ) ; break ; case MODIFIED : o1Names = ( ( SchemaObject ) atd . getDestination ( ) ) . getNames ( ) ; break ; case REMOVED : o1Names = ( ( SchemaObject ) atd . getSource ( ) ) . getNames ( ) ; break ; case IDENTICAL : o1Names = ( ( SchemaObject ) atd . getDestination ( ) ) . getNames ( ) ; break ; } switch ( ocd . getType ( ) ) { case ADDED : o2Names = ( ( SchemaObject ) ocd . getDestination ( ) ) . getNames ( ) ; break ; case MODIFIED : o2Names = ( ( SchemaObject ) ocd . getDestination ( ) ) . getNames ( ) ; break ; case REMOVED : o2Names = ( ( SchemaObject ) ocd . getSource ( ) ) . getNames ( ) ; break ; case IDENTICAL : o2Names = ( ( SchemaObject ) ocd . getDestination ( ) ) . getNames ( ) ; break ; } } else if ( ( o1 instanceof ObjectClassDifference ) && ( o2 instanceof AttributeTypeDifference ) ) { ObjectClassDifference ocd = ( ObjectClassDifference ) o1 ; AttributeTypeDifference atd = ( AttributeTypeDifference ) o2 ; switch ( ocd . getType ( ) ) { case ADDED : o1Names = ( ( SchemaObject ) ocd . getDestination ( ) ) . getNames ( ) ; break ; case MODIFIED : o1Names = ( ( SchemaObject ) ocd . getDestination ( ) ) . getNames ( ) ; break ; case REMOVED : o1Names = ( ( SchemaObject ) ocd . getSource ( ) ) . getNames ( ) ; break ; case IDENTICAL : o1Names = ( ( SchemaObject ) ocd . getDestination ( ) ) . getNames ( ) ; break ; } switch ( atd . getType ( ) ) { case ADDED : o2Names = ( ( SchemaObject ) atd . getDestination ( ) ) . getNames ( ) ; break ; case MODIFIED : o2Names = ( ( SchemaObject ) atd . getDestination ( ) ) . getNames ( ) ; break ; case REMOVED : o2Names = ( ( SchemaObject ) atd . getSource ( ) ) . getNames ( ) ; break ; case IDENTICAL : o2Names = ( ( SchemaObject ) atd . getDestination ( ) ) . getNames ( ) ; break ; } } if ( ( o1Names != null ) && ( o2Names != null ) ) { if ( ( o1Names . size ( ) > 0 ) && ( o2Names . size ( ) > 0 ) ) { return o1Names . get ( 0 ) . compareToIgnoreCase ( o2Names . get ( 0 ) ) ; } else if ( ( o1Names . size ( ) == 0 ) && ( o2Names . size ( ) > 0 ) ) { return """" . compareToIgnoreCase ( o2Names . get ( 0 ) ) ; } else if ( ( o1Names . size ( ) > 0 ) && ( o2Names . size ( ) == 0 ) ) { return o1Names . get ( 0 ) . compareToIgnoreCase ( """" ) ; } } return o1 . toString ( ) . compareToIgnoreCase ( o2 . toString ( ) ) ; }",Smelly
" protected boolean combine ( Object [ ] srcs , TupleWritable dst ) { assert srcs . length == dst . size ( ) ; return true ; }",No
 public void setStudent ( List < Student > student ) { this . student = student ; },No
" public void read ( org . apache . thrift . protocol . TProtocol prot , clean_result struct ) throws org . apache . thrift . TException { TTupleProtocol iprot = ( TTupleProtocol ) prot ; }",Smelly
 void setIdentifierUtil ( DBIdentifierUtil util ) ;,No
 private static < S extends org . apache . thrift . scheme . IScheme > S scheme ( org . apache . thrift . protocol . TProtocol proto ) { return ( org . apache . thrift . scheme . StandardScheme . class . equals ( proto . getScheme ( ) ) ? STANDARD_SCHEME_FACTORY : TUPLE_SCHEME_FACTORY ) . getScheme ( ) ; },Smelly
" public static void main ( final String [ ] args ) { if ( args . length == 0 ) { System . err . println ( ""Please pass the name of a file as parameter."" ) ; System . err . println ( ""e.g. java org.apache.commons.vfs2.example.ShowProperties LICENSE.txt"" ) ; return ; } for ( final String arg : args ) { try { final FileSystemManager mgr = VFS . getManager ( ) ; System . out . println ( ) ; System . out . println ( ""Parsing: "" + arg ) ; final FileObject file = mgr . resolveFile ( arg ) ; System . out . println ( ""URL: "" + file . getURL ( ) ) ; System . out . println ( ""getName(): "" + file . getName ( ) ) ; System . out . println ( ""BaseName: "" + file . getName ( ) . getBaseName ( ) ) ; System . out . println ( ""Extension: "" + file . getName ( ) . getExtension ( ) ) ; System . out . println ( ""Path: "" + file . getName ( ) . getPath ( ) ) ; System . out . println ( ""Scheme: "" + file . getName ( ) . getScheme ( ) ) ; System . out . println ( ""URI: "" + file . getName ( ) . getURI ( ) ) ; System . out . println ( ""Root URI: "" + file . getName ( ) . getRootURI ( ) ) ; System . out . println ( ""Parent: "" + file . getName ( ) . getParent ( ) ) ; System . out . println ( ""Type: "" + file . getType ( ) ) ; System . out . println ( ""Exists: "" + file . exists ( ) ) ; System . out . println ( ""Readable: "" + file . isReadable ( ) ) ; System . out . println ( ""Writeable: "" + file . isWriteable ( ) ) ; System . out . println ( ""Root path: "" + file . getFileSystem ( ) . getRoot ( ) . getName ( ) . getPath ( ) ) ; if ( file . exists ( ) ) { if ( file . getType ( ) . equals ( FileType . FILE ) ) { System . out . println ( ""Size: "" + file . getContent ( ) . getSize ( ) + "" bytes"" ) ; } else if ( file . getType ( ) . equals ( FileType . FOLDER ) && file . isReadable ( ) ) { final FileObject [ ] children = file . getChildren ( ) ; System . out . println ( ""Directory with "" + children . length + "" files"" ) ; for ( int iterChildren = 0 ; iterChildren < children . length ; iterChildren ++ ) { System . out . println ( ""#"" + iterChildren + "": "" + children [ iterChildren ] . getName ( ) ) ; if ( iterChildren > SHOW_MAX ) { break ; } } } System . out . println ( ""Last modified: "" + DateFormat . getInstance ( ) . format ( new Date ( file . getContent ( ) . getLastModifiedTime ( ) ) ) ) ; } else { System . out . println ( ""The file does not exist"" ) ; } file . close ( ) ; } catch ( final FileSystemException ex ) { ex . printStackTrace ( ) ; } } }",Smelly
 public List < StageResult > getStageResults ( ) { return stageResults ; },No
" public void read ( org . apache . thrift . protocol . TProtocol prot , getChildDataProducts_result struct ) throws org . apache . thrift . TException { TTupleProtocol iprot = ( TTupleProtocol ) prot ; BitSet incoming = iprot . readBitSet ( 5 ) ; if ( incoming . get ( 0 ) ) { { org . apache . thrift . protocol . TList _list283 = new org . apache . thrift . protocol . TList ( org . apache . thrift . protocol . TType . STRUCT , iprot . readI32 ( ) ) ; struct . success = new ArrayList < org . apache . airavata . model . data . replica . DataProductModel > ( _list283 . size ) ; org . apache . airavata . model . data . replica . DataProductModel _elem284 ; for ( int _i285 = 0 ; _i285 < _list283 . size ; ++ _i285 ) { _elem284 = new org . apache . airavata . model . data . replica . DataProductModel ( ) ; _elem284 . read ( iprot ) ; struct . success . add ( _elem284 ) ; } } struct . setSuccessIsSet ( true ) ; } if ( incoming . get ( 1 ) ) { struct . ire = new org . apache . airavata . model . error . InvalidRequestException ( ) ; struct . ire . read ( iprot ) ; struct . setIreIsSet ( true ) ; } if ( incoming . get ( 2 ) ) { struct . ace = new org . apache . airavata . model . error . AiravataClientException ( ) ; struct . ace . read ( iprot ) ; struct . setAceIsSet ( true ) ; } if ( incoming . get ( 3 ) ) { struct . ase = new org . apache . airavata . model . error . AiravataSystemException ( ) ; struct . ase . read ( iprot ) ; struct . setAseIsSet ( true ) ; } if ( incoming . get ( 4 ) ) { struct . ae = new org . apache . airavata . model . error . AuthorizationException ( ) ; struct . ae . read ( iprot ) ; struct . setAeIsSet ( true ) ; } }",Smelly
 Class < T > getObjectClass ( ) ;,No
" public void read ( org . apache . thrift . protocol . TProtocol prot , getChildDataProducts_result struct ) throws org . apache . thrift . TException { TTupleProtocol iprot = ( TTupleProtocol ) prot ; BitSet incoming = iprot . readBitSet ( 5 ) ; if ( incoming . get ( 0 ) ) { { org . apache . thrift . protocol . TList _list283 = new org . apache . thrift . protocol . TList ( org . apache . thrift . protocol . TType . STRUCT , iprot . readI32 ( ) ) ; struct . success = new ArrayList < org . apache . airavata . model . data . replica . DataProductModel > ( _list283 . size ) ; org . apache . airavata . model . data . replica . DataProductModel _elem284 ; for ( int _i285 = 0 ; _i285 < _list283 . size ; ++ _i285 ) { _elem284 = new org . apache . airavata . model . data . replica . DataProductModel ( ) ; _elem284 . read ( iprot ) ; struct . success . add ( _elem284 ) ; } } struct . setSuccessIsSet ( true ) ; } if ( incoming . get ( 1 ) ) { struct . ire = new org . apache . airavata . model . error . InvalidRequestException ( ) ; struct . ire . read ( iprot ) ; struct . setIreIsSet ( true ) ; } if ( incoming . get ( 2 ) ) { struct . ace = new org . apache . airavata . model . error . AiravataClientException ( ) ; struct . ace . read ( iprot ) ; struct . setAceIsSet ( true ) ; } if ( incoming . get ( 3 ) ) { struct . ase = new org . apache . airavata . model . error . AiravataSystemException ( ) ; struct . ase . read ( iprot ) ; struct . setAseIsSet ( true ) ; } if ( incoming . get ( 4 ) ) { struct . ae = new org . apache . airavata . model . error . AuthorizationException ( ) ; struct . ae . read ( iprot ) ; struct . setAeIsSet ( true ) ; } }",Smelly
" public void testAsMap ( ) { ConcurrentLongLongHashMap lmap = new ConcurrentLongLongHashMap ( 16 , 1 ) ; lmap . put ( 1 , 11 ) ; lmap . put ( 2 , 22 ) ; lmap . put ( 3 , 33 ) ; Map < Long , Long > map = Maps . newTreeMap ( ) ; map . put ( 1L , 11L ) ; map . put ( 2L , 22L ) ; map . put ( 3L , 33L ) ; assertEquals ( map , lmap . asMap ( ) ) ; }",No
 public boolean isSpooling ( ) { return spooling ; },No
" public void testEncodedTypeDescriptor ( ) throws Exception { assertThat ( TEST_CODER . getEncodedTypeDescriptor ( ) , equalTo ( TypeDescriptor . of ( Long . class ) ) ) ; }",No
" public static String receiveOfflinePayment ( HttpServletRequest request , HttpServletResponse response ) { HttpSession session = request . getSession ( ) ; LocalDispatcher dispatcher = ( LocalDispatcher ) request . getAttribute ( ""dispatcher"" ) ; Delegator delegator = ( Delegator ) request . getAttribute ( ""delegator"" ) ; GenericValue userLogin = ( GenericValue ) session . getAttribute ( ""userLogin"" ) ; Locale locale = UtilHttp . getLocale ( request ) ; String orderId = request . getParameter ( ""orderId"" ) ; String partyId = request . getParameter ( ""partyId"" ) ; GenericValue orderHeader = null ; List < GenericValue > orderRoles = null ; try { orderHeader = delegator . findOne ( ""OrderHeader"" , UtilMisc . toMap ( ""orderId"" , orderId ) , false ) ; orderRoles = delegator . findList ( ""OrderRole"" , EntityCondition . makeCondition ( ""orderId"" , EntityOperator . EQUALS , orderId ) , null , null , null , false ) ; } catch ( GenericEntityException e ) { Debug . logError ( e , ""Problems reading order header from datasource."" , module ) ; request . setAttribute ( ""_ERROR_MESSAGE_"" , UtilProperties . getMessage ( resource_error , ""OrderProblemsReadingOrderHeaderInformation"" , locale ) ) ; return ""error"" ; } BigDecimal grandTotal = BigDecimal . ZERO ; if ( orderHeader != null ) { grandTotal = orderHeader . getBigDecimal ( ""grandTotal"" ) ; } List < GenericValue > paymentMethodTypes = null ; try { EntityExpr ee = EntityCondition . makeCondition ( ""paymentMethodTypeId"" , EntityOperator . NOT_EQUAL , ""EXT_OFFLINE"" ) ; paymentMethodTypes = delegator . findList ( ""PaymentMethodType"" , ee , null , null , null , false ) ; } catch ( GenericEntityException e ) { Debug . logError ( e , ""Problems getting payment types"" , module ) ; request . setAttribute ( ""_ERROR_MESSAGE_"" , UtilProperties . getMessage ( resource_error , ""OrderProblemsWithPaymentTypeLookup"" , locale ) ) ; return ""error"" ; } if ( paymentMethodTypes == null ) { request . setAttribute ( ""_ERROR_MESSAGE_"" , UtilProperties . getMessage ( resource_error , ""OrderProblemsWithPaymentTypeLookup"" , locale ) ) ; return ""error"" ; } List < GenericValue > paymentMethods = null ; try { EntityExpr ee = EntityCondition . makeCondition ( ""partyId"" , EntityOperator . EQUALS , partyId ) ; paymentMethods = delegator . findList ( ""PaymentMethod"" , ee , null , null , null , false ) ; } catch ( GenericEntityException e ) { Debug . logError ( e , ""Problems getting payment methods"" , module ) ; request . setAttribute ( ""_ERROR_MESSAGE_"" , UtilProperties . getMessage ( resource_error , ""OrderProblemsWithPaymentMethodLookup"" , locale ) ) ; return ""error"" ; } GenericValue placingCustomer = null ; try { List < GenericValue > pRoles = delegator . findByAnd ( ""OrderRole"" , UtilMisc . toMap ( ""orderId"" , orderId , ""roleTypeId"" , ""PLACING_CUSTOMER"" ) , null , false ) ; if ( UtilValidate . isNotEmpty ( pRoles ) ) placingCustomer = EntityUtil . getFirst ( pRoles ) ; } catch ( GenericEntityException e ) { Debug . logError ( e , ""Problems looking up order payment preferences"" , module ) ; request . setAttribute ( ""_ERROR_MESSAGE_"" , UtilProperties . getMessage ( resource_error , ""OrderErrorProcessingOfflinePayments"" , locale ) ) ; return ""error"" ; } for ( GenericValue paymentMethod : paymentMethods ) { String paymentMethodId = paymentMethod . getString ( ""paymentMethodId"" ) ; String paymentMethodAmountStr = request . getParameter ( paymentMethodId + ""_amount"" ) ; String paymentMethodReference = request . getParameter ( paymentMethodId + ""_reference"" ) ; if ( ! UtilValidate . isEmpty ( paymentMethodAmountStr ) ) { BigDecimal paymentMethodAmount = BigDecimal . ZERO ; try { paymentMethodAmount = ( BigDecimal ) ObjectType . simpleTypeConvert ( paymentMethodAmountStr , ""BigDecimal"" , null , locale ) ; } catch ( GeneralException e ) { request . setAttribute ( ""_ERROR_MESSAGE_"" , UtilProperties . getMessage ( resource_error , ""OrderProblemsPaymentParsingAmount"" , locale ) ) ; return ""error"" ; } if ( paymentMethodAmount . compareTo ( BigDecimal . ZERO ) > 0 ) { Map < String , Object > results = null ; try { results = dispatcher . runSync ( ""createPaymentFromOrder"" , UtilMisc . toMap ( ""orderId"" , orderId , ""paymentMethodId"" , paymentMethodId , ""paymentRefNum"" , paymentMethodReference , ""comments"" , ""Payment received offline and manually entered."" , ""userLogin"" , userLogin ) ) ; } catch ( GenericServiceException e ) { Debug . logError ( e , ""Failed to execute service createPaymentFromOrder"" , module ) ; request . setAttribute ( ""_ERROR_MESSAGE_"" , e . getMessage ( ) ) ; return ""error"" ; } if ( ( results == null ) || ( results . get ( ModelService . RESPONSE_MESSAGE ) . equals ( ModelService . RESPOND_ERROR ) ) ) { Debug . logError ( ( String ) results . get ( ModelService . ERROR_MESSAGE ) , module ) ; request . setAttribute ( ""_ERROR_MESSAGE_"" , results . get ( ModelService . ERROR_MESSAGE ) ) ; return ""error"" ; } } OrderChangeHelper . approveOrder ( dispatcher , userLogin , orderId ) ; return ""success"" ; } } List < GenericValue > toBeStored = FastList . newInstance ( ) ; for ( GenericValue paymentMethodType : paymentMethodTypes ) { String paymentMethodTypeId = paymentMethodType . getString ( ""paymentMethodTypeId"" ) ; String amountStr = request . getParameter ( paymentMethodTypeId + ""_amount"" ) ; String paymentReference = request . getParameter ( paymentMethodTypeId + ""_reference"" ) ; if ( ! UtilValidate . isEmpty ( amountStr ) ) { BigDecimal paymentTypeAmount = BigDecimal . ZERO ; try { paymentTypeAmount = ( BigDecimal ) ObjectType . simpleTypeConvert ( amountStr , ""BigDecimal"" , null , locale ) ; } catch ( GeneralException e ) { request . setAttribute ( ""_ERROR_MESSAGE_"" , UtilProperties . getMessage ( resource_error , ""OrderProblemsPaymentParsingAmount"" , locale ) ) ; return ""error"" ; } if ( paymentTypeAmount . compareTo ( BigDecimal . ZERO ) > 0 ) { Map < String , String > prefFields = UtilMisc . < String , String > toMap ( ""orderPaymentPreferenceId"" , delegator . getNextSeqId ( ""OrderPaymentPreference"" ) ) ; GenericValue paymentPreference = delegator . makeValue ( ""OrderPaymentPreference"" , prefFields ) ; paymentPreference . set ( ""paymentMethodTypeId"" , paymentMethodType . getString ( ""paymentMethodTypeId"" ) ) ; paymentPreference . set ( ""maxAmount"" , paymentTypeAmount ) ; paymentPreference . set ( ""statusId"" , ""PAYMENT_RECEIVED"" ) ; paymentPreference . set ( ""orderId"" , orderId ) ; paymentPreference . set ( ""createdDate"" , UtilDateTime . nowTimestamp ( ) ) ; if ( userLogin != null ) { paymentPreference . set ( ""createdByUserLogin"" , userLogin . getString ( ""userLoginId"" ) ) ; } try { delegator . create ( paymentPreference ) ; } catch ( GenericEntityException ex ) { Debug . logError ( ex , ""Cannot create a new OrderPaymentPreference"" , module ) ; request . setAttribute ( ""_ERROR_MESSAGE_"" , ex . getMessage ( ) ) ; return ""error"" ; } Map < String , Object > results = null ; try { results = dispatcher . runSync ( ""createPaymentFromPreference"" , UtilMisc . toMap ( ""userLogin"" , userLogin , ""orderPaymentPreferenceId"" , paymentPreference . get ( ""orderPaymentPreferenceId"" ) , ""paymentRefNum"" , paymentReference , ""paymentFromId"" , placingCustomer . getString ( ""partyId"" ) , ""comments"" , ""Payment received offline and manually entered."" ) ) ; } catch ( GenericServiceException e ) { Debug . logError ( e , ""Failed to execute service createPaymentFromPreference"" , module ) ; request . setAttribute ( ""_ERROR_MESSAGE_"" , e . getMessage ( ) ) ; return ""error"" ; } if ( ( results == null ) || ( results . get ( ModelService . RESPONSE_MESSAGE ) . equals ( ModelService . RESPOND_ERROR ) ) ) { Debug . logError ( ( String ) results . get ( ModelService . ERROR_MESSAGE ) , module ) ; request . setAttribute ( ""_ERROR_MESSAGE_"" , results . get ( ModelService . ERROR_MESSAGE ) ) ; return ""error"" ; } } } } GenericValue offlineValue = null ; List < GenericValue > currentPrefs = null ; BigDecimal paymentTally = BigDecimal . ZERO ; try { EntityConditionList < EntityExpr > ecl = EntityCondition . makeCondition ( UtilMisc . toList ( EntityCondition . makeCondition ( ""orderId"" , EntityOperator . EQUALS , orderId ) , EntityCondition . makeCondition ( ""statusId"" , EntityOperator . NOT_EQUAL , ""PAYMENT_CANCELLED"" ) ) , EntityOperator . AND ) ; currentPrefs = delegator . findList ( ""OrderPaymentPreference"" , ecl , null , null , null , false ) ; } catch ( GenericEntityException e ) { Debug . logError ( e , ""ERROR: Unable to get existing payment preferences from order"" , module ) ; } if ( UtilValidate . isNotEmpty ( currentPrefs ) ) { for ( GenericValue cp : currentPrefs ) { String paymentMethodType = cp . getString ( ""paymentMethodTypeId"" ) ; if ( ""EXT_OFFLINE"" . equals ( paymentMethodType ) ) { offlineValue = cp ; } else { BigDecimal cpAmt = cp . getBigDecimal ( ""maxAmount"" ) ; if ( cpAmt != null ) { paymentTally = paymentTally . add ( cpAmt ) ; } } } } boolean okayToApprove = false ; if ( paymentTally . compareTo ( grandTotal ) >= 0 ) { okayToApprove = true ; if ( offlineValue != null ) { offlineValue . set ( ""statusId"" , ""PAYMENT_CANCELLED"" ) ; toBeStored . add ( offlineValue ) ; } } try { delegator . storeAll ( toBeStored ) ; } catch ( GenericEntityException e ) { Debug . logError ( e , ""Problems storing payment information"" , module ) ; request . setAttribute ( ""_ERROR_MESSAGE_"" , UtilProperties . getMessage ( resource_error , ""OrderProblemStoringReceivedPaymentInformation"" , locale ) ) ; return ""error"" ; } if ( okayToApprove ) { OrderChangeHelper . approveOrder ( dispatcher , userLogin , orderId ) ; } return ""success"" ; }",Smelly
 public void testFilterList ( ) { PDFFilterList filterList = new PDFFilterList ( ) ; assertFalse ( filterList . isInitialized ( ) ) ; },No
" public HttpServiceResponse handle ( HttpServiceRequest request ) throws Exception { HttpServiceResponse response = new HttpServiceResponse ( ) ; String requestBody = request . getBody ( ) ; RecoveryRequestJsonBody requestJsonBody ; if ( requestBody == null ) { response . setCode ( HttpServer . StatusCode . NOT_FOUND ) ; response . setBody ( ""No request body provide."" ) ; return response ; } try { requestJsonBody = JsonUtil . fromJson ( requestBody , RecoveryRequestJsonBody . class ) ; LOG . debug ( ""bookie_src: ["" + requestJsonBody . bookie_src . get ( 0 ) + ""],  delete_cookie: ["" + requestJsonBody . delete_cookie + ""]"" ) ; } catch ( JsonUtil . ParseJsonException e ) { LOG . error ( ""Meet Exception: "" , e ) ; response . setCode ( HttpServer . StatusCode . NOT_FOUND ) ; response . setBody ( ""ERROR parameters: "" + e . getMessage ( ) ) ; return response ; } if ( HttpServer . Method . PUT == request . getMethod ( ) && ! requestJsonBody . bookie_src . isEmpty ( ) ) { Class < ? extends RegistrationManager > rmClass = conf . getRegistrationManagerClass ( ) ; RegistrationManager rm = ReflectionUtils . newInstance ( rmClass ) ; rm . initialize ( conf , ( ) -> { } , NullStatsLogger . INSTANCE ) ; String bookieSrcString [ ] = requestJsonBody . bookie_src . get ( 0 ) . split ( "":"" ) ; BookieSocketAddress bookieSrc = new BookieSocketAddress ( bookieSrcString [ 0 ] , Integer . parseInt ( bookieSrcString [ 1 ] ) ) ; boolean deleteCookie = requestJsonBody . delete_cookie ; executor . execute ( ( ) -> { try { LOG . info ( ""Start recovering bookie."" ) ; bka . recoverBookieData ( bookieSrc ) ; if ( deleteCookie ) { Versioned < Cookie > cookie = Cookie . readFromRegistrationManager ( rm , bookieSrc ) ; cookie . getValue ( ) . deleteFromRegistrationManager ( rm , bookieSrc , cookie . getVersion ( ) ) ; } LOG . info ( ""Complete recovering bookie"" ) ; } catch ( Exception e ) { LOG . error ( ""Exception occurred while recovering bookie"" , e ) ; } } ) ; response . setCode ( HttpServer . StatusCode . OK ) ; response . setBody ( ""Success send recovery request command."" ) ; return response ; } else { response . setCode ( HttpServer . StatusCode . NOT_FOUND ) ; response . setBody ( ""Not found method. Should be PUT method"" ) ; return response ; } }",Smelly
 public ProfileBuilderBolt withMessageDistributor ( MessageDistributor messageDistributor ) { this . messageDistributor = messageDistributor ; return this ; },No
 public static ColumnPrunerMapJoinProc getMapJoinProc ( ) { return new ColumnPrunerMapJoinProc ( ) ; },Smelly
" private Method readMethod ( DataInputStream in ) throws IOException { int access_flags = in . readUnsignedShort ( ) ; int name_index = in . readUnsignedShort ( ) ; int descriptor_index = in . readUnsignedShort ( ) ; int attributes_count = in . readUnsignedShort ( ) ; prt ( ""#method :"" + constantPool . getConstant ( name_index ) ) ; Attribute [ ] attributes = null ; if ( attributes_count != 0 ) { attributes = new Attribute [ attributes_count ] ; for ( int i = 0 ; i < attributes_count ; i ++ ) { attributes [ i ] = readAttribute ( in ) ; } } return new Method ( access_flags , name_index , descriptor_index , attributes_count , attributes ) ; }",Smelly
 static Stream < Set < TupleSlot > > tripleQueryPatterns ( ) { return quadQueryPatterns ( ) . filter ( s -> ! s . contains ( GRAPH ) ) ; },No
" public boolean eval ( Map < String , Object > context ) { Map < String , Object > sectionsList = UtilGenerics . toMap ( context . get ( ""sections"" ) ) ; return ! sectionsList . containsKey ( this . sectionExdr . expandString ( context ) ) ; }",Smelly
" public void read ( org . apache . thrift . protocol . TProtocol prot , Database struct ) throws org . apache . thrift . TException { TTupleProtocol iprot = ( TTupleProtocol ) prot ; BitSet incoming = iprot . readBitSet ( 7 ) ; if ( incoming . get ( 0 ) ) { struct . name = iprot . readString ( ) ; struct . setNameIsSet ( true ) ; } if ( incoming . get ( 1 ) ) { struct . description = iprot . readString ( ) ; struct . setDescriptionIsSet ( true ) ; } if ( incoming . get ( 2 ) ) { struct . locationUri = iprot . readString ( ) ; struct . setLocationUriIsSet ( true ) ; } if ( incoming . get ( 3 ) ) { { org . apache . thrift . protocol . TMap _map100 = new org . apache . thrift . protocol . TMap ( org . apache . thrift . protocol . TType . STRING , org . apache . thrift . protocol . TType . STRING , iprot . readI32 ( ) ) ; struct . parameters = new HashMap < String , String > ( 2 * _map100 . size ) ; for ( int _i101 = 0 ; _i101 < _map100 . size ; ++ _i101 ) { String _key102 ; String _val103 ; _key102 = iprot . readString ( ) ; _val103 = iprot . readString ( ) ; struct . parameters . put ( _key102 , _val103 ) ; } } struct . setParametersIsSet ( true ) ; } if ( incoming . get ( 4 ) ) { struct . privileges = new PrincipalPrivilegeSet ( ) ; struct . privileges . read ( iprot ) ; struct . setPrivilegesIsSet ( true ) ; } if ( incoming . get ( 5 ) ) { struct . ownerName = iprot . readString ( ) ; struct . setOwnerNameIsSet ( true ) ; } if ( incoming . get ( 6 ) ) { struct . ownerType = PrincipalType . findByValue ( iprot . readI32 ( ) ) ; struct . setOwnerTypeIsSet ( true ) ; } }",Smelly
" public void stop ( ) { if ( null != functionMetaDataManager ) { try { functionMetaDataManager . close ( ) ; } catch ( Exception e ) { log . warn ( ""Failed to close function metadata manager"" , e ) ; } } if ( null != functionRuntimeManager ) { try { functionRuntimeManager . close ( ) ; } catch ( Exception e ) { log . warn ( ""Failed to close function runtime manager"" , e ) ; } } if ( null != client ) { try { client . close ( ) ; } catch ( PulsarClientException e ) { log . warn ( ""Failed to close pulsar client"" , e ) ; } } if ( null != clusterServiceCoordinator ) { clusterServiceCoordinator . close ( ) ; } if ( null != membershipManager ) { try { membershipManager . close ( ) ; } catch ( PulsarClientException e ) { log . warn ( ""Failed to close membership manager"" , e ) ; } } if ( null != schedulerManager ) { schedulerManager . close ( ) ; } if ( null != this . brokerAdmin ) { this . brokerAdmin . close ( ) ; } if ( null != this . functionAdmin ) { this . functionAdmin . close ( ) ; } if ( null != this . stateStoreAdminClient ) { this . stateStoreAdminClient . close ( ) ; } if ( null != this . dlogNamespace ) { this . dlogNamespace . close ( ) ; } if ( this . executor != null ) { this . executor . shutdown ( ) ; } }",Smelly
" private void assertRecordType ( Type actual ) { String errorMessage = ""Type {"" + actual . getTypeName ( ) + ""} is not a subtype of Types.RecordType"" ; assertTrue ( errorMessage , actual instanceof Types . RecordType ) ; }",No
" public RecordReader < LongWritable , TripleWritable > createRecordReader ( InputSplit split , TaskAttemptContext context ) { return new RdfJsonReader ( ) ; }",No
" public boolean validatePolicy ( AssertionInfoMap aim , Message message , List < WSSecurityEngineResult > results , List < WSSecurityEngineResult > signedResults , List < WSSecurityEngineResult > encryptedResults ) { Collection < AssertionInfo > ais = aim . get ( SP12Constants . ENDORSING_SUPPORTING_TOKENS ) ; if ( ais == null || ais . isEmpty ( ) ) { return true ; } setMessage ( message ) ; setResults ( results ) ; setSignedResults ( signedResults ) ; setEncryptedResults ( encryptedResults ) ; for ( AssertionInfo ai : ais ) { SupportingToken binding = ( SupportingToken ) ai . getAssertion ( ) ; if ( SPConstants . SupportTokenType . SUPPORTING_TOKEN_ENDORSING != binding . getTokenType ( ) ) { continue ; } ai . setAsserted ( true ) ; setSignedParts ( binding . getSignedParts ( ) ) ; setEncryptedParts ( binding . getEncryptedParts ( ) ) ; setSignedElements ( binding . getSignedElements ( ) ) ; setEncryptedElements ( binding . getEncryptedElements ( ) ) ; List < Token > tokens = binding . getTokens ( ) ; for ( Token token : tokens ) { if ( ! isTokenRequired ( token , message ) ) { continue ; } boolean derived = token . isDerivedKeys ( ) ; setDerived ( derived ) ; boolean processingFailed = false ; if ( token instanceof KerberosToken ) { if ( ! processKerberosTokens ( ) ) { processingFailed = true ; } } else if ( token instanceof X509Token ) { if ( ! processX509Tokens ( ) ) { processingFailed = true ; } } else if ( token instanceof KeyValueToken ) { if ( ! processKeyValueTokens ( ) ) { processingFailed = true ; } } else if ( token instanceof UsernameToken ) { if ( ! processUsernameTokens ( ) ) { processingFailed = true ; } } else if ( token instanceof SecurityContextToken ) { if ( ! processSCTokens ( ) ) { processingFailed = true ; } } else if ( token instanceof SamlToken ) { if ( ! processSAMLTokens ( ) ) { processingFailed = true ; } } else if ( ! ( token instanceof IssuedToken ) ) { processingFailed = true ; } if ( processingFailed ) { ai . setNotAsserted ( ""The received token does not match the endorsing supporting token requirement"" ) ; return false ; } } } return true ; }",Smelly
" private < T , MethodArgT , MethodResultT > T proxyMethod ( T target , Class < ? super T > proxyInterface , String methodName , Function < MethodArgT , MethodResultT > resultTransformer ) { return ( T ) Proxy . newProxyInstance ( this . getClass ( ) . getClassLoader ( ) , new Class [ ] { proxyInterface } , ( proxy , method , args ) -> { Object result = method . invoke ( target , args ) ; if ( method . getName ( ) . equals ( methodName ) ) { result = resultTransformer . apply ( ( MethodArgT ) result ) ; } return result ; } ) ; }",No
" public void read ( org . apache . thrift . protocol . TProtocol prot , ActiveScan struct ) throws org . apache . thrift . TException { TTupleProtocol iprot = ( TTupleProtocol ) prot ; BitSet incoming = iprot . readBitSet ( 13 ) ; if ( incoming . get ( 0 ) ) { struct . client = iprot . readString ( ) ; struct . setClientIsSet ( true ) ; } if ( incoming . get ( 1 ) ) { struct . user = iprot . readString ( ) ; struct . setUserIsSet ( true ) ; } if ( incoming . get ( 2 ) ) { struct . tableId = iprot . readString ( ) ; struct . setTableIdIsSet ( true ) ; } if ( incoming . get ( 3 ) ) { struct . age = iprot . readI64 ( ) ; struct . setAgeIsSet ( true ) ; } if ( incoming . get ( 4 ) ) { struct . idleTime = iprot . readI64 ( ) ; struct . setIdleTimeIsSet ( true ) ; } if ( incoming . get ( 5 ) ) { struct . type = ScanType . findByValue ( iprot . readI32 ( ) ) ; struct . setTypeIsSet ( true ) ; } if ( incoming . get ( 6 ) ) { struct . state = ScanState . findByValue ( iprot . readI32 ( ) ) ; struct . setStateIsSet ( true ) ; } if ( incoming . get ( 7 ) ) { struct . extent = new org . apache . accumulo . core . data . thrift . TKeyExtent ( ) ; struct . extent . read ( iprot ) ; struct . setExtentIsSet ( true ) ; } if ( incoming . get ( 8 ) ) { { org . apache . thrift . protocol . TList _list35 = new org . apache . thrift . protocol . TList ( org . apache . thrift . protocol . TType . STRUCT , iprot . readI32 ( ) ) ; struct . columns = new ArrayList < org . apache . accumulo . core . data . thrift . TColumn > ( _list35 . size ) ; for ( int _i36 = 0 ; _i36 < _list35 . size ; ++ _i36 ) { org . apache . accumulo . core . data . thrift . TColumn _elem37 ; _elem37 = new org . apache . accumulo . core . data . thrift . TColumn ( ) ; _elem37 . read ( iprot ) ; struct . columns . add ( _elem37 ) ; } } struct . setColumnsIsSet ( true ) ; } if ( incoming . get ( 9 ) ) { { org . apache . thrift . protocol . TList _list38 = new org . apache . thrift . protocol . TList ( org . apache . thrift . protocol . TType . STRUCT , iprot . readI32 ( ) ) ; struct . ssiList = new ArrayList < org . apache . accumulo . core . data . thrift . IterInfo > ( _list38 . size ) ; for ( int _i39 = 0 ; _i39 < _list38 . size ; ++ _i39 ) { org . apache . accumulo . core . data . thrift . IterInfo _elem40 ; _elem40 = new org . apache . accumulo . core . data . thrift . IterInfo ( ) ; _elem40 . read ( iprot ) ; struct . ssiList . add ( _elem40 ) ; } } struct . setSsiListIsSet ( true ) ; } if ( incoming . get ( 10 ) ) { { org . apache . thrift . protocol . TMap _map41 = new org . apache . thrift . protocol . TMap ( org . apache . thrift . protocol . TType . STRING , org . apache . thrift . protocol . TType . MAP , iprot . readI32 ( ) ) ; struct . ssio = new HashMap < String , Map < String , String > > ( 2 * _map41 . size ) ; for ( int _i42 = 0 ; _i42 < _map41 . size ; ++ _i42 ) { String _key43 ; Map < String , String > _val44 ; _key43 = iprot . readString ( ) ; { org . apache . thrift . protocol . TMap _map45 = new org . apache . thrift . protocol . TMap ( org . apache . thrift . protocol . TType . STRING , org . apache . thrift . protocol . TType . STRING , iprot . readI32 ( ) ) ; _val44 = new HashMap < String , String > ( 2 * _map45 . size ) ; for ( int _i46 = 0 ; _i46 < _map45 . size ; ++ _i46 ) { String _key47 ; String _val48 ; _key47 = iprot . readString ( ) ; _val48 = iprot . readString ( ) ; _val44 . put ( _key47 , _val48 ) ; } } struct . ssio . put ( _key43 , _val44 ) ; } } struct . setSsioIsSet ( true ) ; } if ( incoming . get ( 11 ) ) { { org . apache . thrift . protocol . TList _list49 = new org . apache . thrift . protocol . TList ( org . apache . thrift . protocol . TType . STRING , iprot . readI32 ( ) ) ; struct . authorizations = new ArrayList < ByteBuffer > ( _list49 . size ) ; for ( int _i50 = 0 ; _i50 < _list49 . size ; ++ _i50 ) { ByteBuffer _elem51 ; _elem51 = iprot . readBinary ( ) ; struct . authorizations . add ( _elem51 ) ; } } struct . setAuthorizationsIsSet ( true ) ; } if ( incoming . get ( 12 ) ) { struct . scanId = iprot . readI64 ( ) ; struct . setScanIdIsSet ( true ) ; } }",Smelly
" public void handleOutput ( List < GenericValue > results , Map < String , Object > context , FlexibleMapAccessor < Object > listAcsr ) { listAcsr . put ( context , results ) ; }",Smelly
" public String toString ( ) { return ( ""org.apache.openjpa.persistence.compatible.EntityContact: "" + "" id: "" + getId ( ) + "" email: "" + getEmail ( ) + "" phone: "" + getPhone ( ) + "" type: "" + getType ( ) + "" address: "" + getAddress ( ) ) ; }",No
" protected Endpoint selectEndpoint ( Message message , Set < Endpoint > eps ) { InputStream is = message . getContent ( InputStream . class ) ; if ( is == null ) { return null ; } CachedOutputStream bos = new CachedOutputStream ( 4096 ) ; try { IOUtils . copy ( is , bos ) ; is . close ( ) ; message . setContent ( InputStream . class , bos . getInputStream ( ) ) ; String encoding = ( String ) message . get ( Message . ENCODING ) ; XMLStreamReader xsr ; XMLInputFactory factory = StaxInInterceptor . getXMLInputFactory ( message ) ; if ( factory == null ) { xsr = StaxUtils . createXMLStreamReader ( bos . getInputStream ( ) , encoding ) ; } else { synchronized ( factory ) { xsr = factory . createXMLStreamReader ( bos . getInputStream ( ) , encoding ) ; } } while ( true ) { xsr . nextTag ( ) ; if ( ""Body"" . equals ( xsr . getName ( ) . getLocalPart ( ) ) ) { break ; } } xsr . nextTag ( ) ; if ( ! xsr . isStartElement ( ) ) { return null ; } String methodName = xsr . getName ( ) . getLocalPart ( ) ; for ( Endpoint ep : eps ) { if ( methodName . indexOf ( ""sayHi"" ) != - 1 ) { if ( ""2"" . equals ( ep . get ( ""version"" ) ) ) { return ep ; } } else if ( ""1"" . equals ( ep . get ( ""version"" ) ) ) { return ep ; } } bos . close ( ) ; } catch ( Exception e ) { throw new Fault ( e ) ; } return null ; }",Smelly
 public Authorizations getAuthorizations ( ) { return null ; },No
" public Metrics add ( String namespace ) { publishMsgLatency . refresh ( ) ; long [ ] latencyBuckets = publishMsgLatency . getBuckets ( ) ; Map < String , String > dimensionMap = Maps . newHashMap ( ) ; dimensionMap . put ( ""namespace"" , namespace ) ; Metrics dMetrics = Metrics . create ( dimensionMap ) ; dMetrics . put ( ""ns_msg_publish_rate"" , numberOfMsgPublished ) ; dMetrics . put ( ""ns_byte_publish_rate"" , numberOfBytesPublished ) ; dMetrics . put ( ""ns_msg_failure_rate"" , numberOfPublishFailure ) ; dMetrics . put ( ""ns_msg_deliver_rate"" , numberOfMsgDelivered ) ; dMetrics . put ( ""ns_byte_deliver_rate"" , numberOfBytesDelivered ) ; dMetrics . put ( ""ns_msg_ack_rate"" , numberOfMsgsAcked ) ; for ( int i = 0 ; i < latencyBuckets . length ; i ++ ) { final String latencyBucket = i >= ENTRY_LATENCY_BUCKETS_USEC . length ? ENTRY_LATENCY_BUCKETS_USEC [ ENTRY_LATENCY_BUCKETS_USEC . length - 1 ] + ""_higher"" : Long . toString ( ENTRY_LATENCY_BUCKETS_USEC [ i ] ) ; dMetrics . put ( ""ns_msg_publish_latency_"" + latencyBucket , latencyBuckets [ i ] ) ; } return dMetrics ; }",No
" public void read ( org . apache . thrift . protocol . TProtocol prot , getChildDataProducts_result struct ) throws org . apache . thrift . TException { TTupleProtocol iprot = ( TTupleProtocol ) prot ; BitSet incoming = iprot . readBitSet ( 5 ) ; if ( incoming . get ( 0 ) ) { { org . apache . thrift . protocol . TList _list283 = new org . apache . thrift . protocol . TList ( org . apache . thrift . protocol . TType . STRUCT , iprot . readI32 ( ) ) ; struct . success = new ArrayList < org . apache . airavata . model . data . replica . DataProductModel > ( _list283 . size ) ; org . apache . airavata . model . data . replica . DataProductModel _elem284 ; for ( int _i285 = 0 ; _i285 < _list283 . size ; ++ _i285 ) { _elem284 = new org . apache . airavata . model . data . replica . DataProductModel ( ) ; _elem284 . read ( iprot ) ; struct . success . add ( _elem284 ) ; } } struct . setSuccessIsSet ( true ) ; } if ( incoming . get ( 1 ) ) { struct . ire = new org . apache . airavata . model . error . InvalidRequestException ( ) ; struct . ire . read ( iprot ) ; struct . setIreIsSet ( true ) ; } if ( incoming . get ( 2 ) ) { struct . ace = new org . apache . airavata . model . error . AiravataClientException ( ) ; struct . ace . read ( iprot ) ; struct . setAceIsSet ( true ) ; } if ( incoming . get ( 3 ) ) { struct . ase = new org . apache . airavata . model . error . AiravataSystemException ( ) ; struct . ase . read ( iprot ) ; struct . setAseIsSet ( true ) ; } if ( incoming . get ( 4 ) ) { struct . ae = new org . apache . airavata . model . error . AuthorizationException ( ) ; struct . ae . read ( iprot ) ; struct . setAeIsSet ( true ) ; } }",Smelly
 public void configure ( Binder binder ) { binder . bind ( RequestHandler . class ) . to ( SessionContextRequestHandler . class ) . withoutScope ( ) ; },No
 public void setSelectorExecutor ( Executor selectorExecutor ) { this . selectorExecutor = selectorExecutor ; },No
" public void testNestedRowArrayElementAccess ( ) { Schema resultSchema = Schema . builder ( ) . addStringField ( ""f_nestedArrayStringField"" ) . build ( ) ; Schema nestedSchema = Schema . builder ( ) . addInt32Field ( ""f_nestedInt"" ) . addStringField ( ""f_nestedString"" ) . addInt32Field ( ""f_nestedIntPlusOne"" ) . addArrayField ( ""f_nestedArray"" , Schema . FieldType . STRING ) . build ( ) ; Schema inputType = Schema . builder ( ) . addInt32Field ( ""f_int"" ) . addRowField ( ""f_nestedRow"" , nestedSchema ) . build ( ) ; PCollection < Row > input = pipeline . apply ( Create . of ( Row . withSchema ( inputType ) . addValues ( 1 , Row . withSchema ( nestedSchema ) . addValues ( 312 , ""CC"" , 313 , Arrays . asList ( ""one"" , ""two"" ) ) . build ( ) ) . build ( ) , Row . withSchema ( inputType ) . addValues ( 2 , Row . withSchema ( nestedSchema ) . addValues ( 412 , ""DD"" , 413 , Arrays . asList ( ""three"" , ""four"" ) ) . build ( ) ) . build ( ) ) . withSchema ( inputType , SerializableFunctions . identity ( ) , SerializableFunctions . identity ( ) ) ) ; PCollection < Row > result = input . apply ( SqlTransform . query ( ""SELECT `PCOLLECTION`.`f_nestedRow`.`f_nestedArray`[2] FROM PCOLLECTION"" ) ) . setRowSchema ( resultSchema ) ; PAssert . that ( result ) . containsInAnyOrder ( Row . withSchema ( resultSchema ) . addValues ( ""two"" ) . build ( ) , Row . withSchema ( resultSchema ) . addValues ( ""four"" ) . build ( ) ) ; pipeline . run ( ) ; }",No
" public void read ( org . apache . thrift . protocol . TProtocol prot , show_compact_result struct ) throws org . apache . thrift . TException { TTupleProtocol iprot = ( TTupleProtocol ) prot ; BitSet incoming = iprot . readBitSet ( 1 ) ; if ( incoming . get ( 0 ) ) { struct . success = new ShowCompactResponse ( ) ; struct . success . read ( iprot ) ; struct . setSuccessIsSet ( true ) ; } }",Smelly
" protected void readState ( ObjectInputStream in ) throws IOException , ClassNotFoundException { super . readState ( in ) ; this . toMaster = in . readObject ( ) ; }",No
" public void read ( org . apache . thrift . protocol . TProtocol prot , getFollowing_result struct ) throws org . apache . thrift . TException { TTupleProtocol iprot = ( TTupleProtocol ) prot ; BitSet incoming = iprot . readBitSet ( 1 ) ; if ( incoming . get ( 0 ) ) { struct . success = new Key ( ) ; struct . success . read ( iprot ) ; struct . setSuccessIsSet ( true ) ; } }",Smelly
" public void eval ( ) { if ( in . isSet == 0 ) { out . value = 0 ; } else { java . math . BigDecimal input = org . apache . drill . exec . util . DecimalUtility . getBigDecimalFromSparse ( in . buffer , in . start , in . nDecimalDigits , in . scale ) ; out . value = org . apache . drill . exec . expr . fn . impl . HashHelper . hash64 ( input . doubleValue ( ) , 0 ) ; } }",No
" public void read ( org . apache . thrift . protocol . TProtocol prot , getChildDataProducts_result struct ) throws org . apache . thrift . TException { TTupleProtocol iprot = ( TTupleProtocol ) prot ; BitSet incoming = iprot . readBitSet ( 5 ) ; if ( incoming . get ( 0 ) ) { { org . apache . thrift . protocol . TList _list283 = new org . apache . thrift . protocol . TList ( org . apache . thrift . protocol . TType . STRUCT , iprot . readI32 ( ) ) ; struct . success = new ArrayList < org . apache . airavata . model . data . replica . DataProductModel > ( _list283 . size ) ; org . apache . airavata . model . data . replica . DataProductModel _elem284 ; for ( int _i285 = 0 ; _i285 < _list283 . size ; ++ _i285 ) { _elem284 = new org . apache . airavata . model . data . replica . DataProductModel ( ) ; _elem284 . read ( iprot ) ; struct . success . add ( _elem284 ) ; } } struct . setSuccessIsSet ( true ) ; } if ( incoming . get ( 1 ) ) { struct . ire = new org . apache . airavata . model . error . InvalidRequestException ( ) ; struct . ire . read ( iprot ) ; struct . setIreIsSet ( true ) ; } if ( incoming . get ( 2 ) ) { struct . ace = new org . apache . airavata . model . error . AiravataClientException ( ) ; struct . ace . read ( iprot ) ; struct . setAceIsSet ( true ) ; } if ( incoming . get ( 3 ) ) { struct . ase = new org . apache . airavata . model . error . AiravataSystemException ( ) ; struct . ase . read ( iprot ) ; struct . setAseIsSet ( true ) ; } if ( incoming . get ( 4 ) ) { struct . ae = new org . apache . airavata . model . error . AuthorizationException ( ) ; struct . ae . read ( iprot ) ; struct . setAeIsSet ( true ) ; } }",Smelly
" abstract void accept ( CompositeRecordReader . JoinCollector jc , K key ) throws IOException , InterruptedException ;",No
" public void read ( org . apache . thrift . protocol . TProtocol prot , drainReplicationTable_result struct ) throws org . apache . thrift . TException { TTupleProtocol iprot = ( TTupleProtocol ) prot ; BitSet incoming = iprot . readBitSet ( 1 ) ; if ( incoming . get ( 0 ) ) { struct . success = iprot . readBool ( ) ; struct . setSuccessIsSet ( true ) ; } }",Smelly
" public void run ( ) { Logging . threads . debug ( ""Start up idle cleanup thread"" ) ; try { IThreadContext threadContext = ThreadContextFactory . make ( ) ; ICacheManager cacheManager = CacheManagerFactory . make ( threadContext ) ; while ( true ) { try { RepositoryConnectorFactory . pollAllConnectors ( threadContext ) ; OutputConnectorFactory . pollAllConnectors ( threadContext ) ; cacheManager . expireObjects ( System . currentTimeMillis ( ) ) ; ManifoldCF . sleep ( 15000L ) ; } catch ( ManifoldCFException e ) { if ( e . getErrorCode ( ) == ManifoldCFException . INTERRUPTED ) break ; if ( e . getErrorCode ( ) == ManifoldCFException . DATABASE_CONNECTION_ERROR ) { Logging . threads . error ( ""Idle cleanup thread aborting and restarting due to database connection reset: "" + e . getMessage ( ) , e ) ; try { ManifoldCF . sleep ( 10000L ) ; } catch ( InterruptedException se ) { break ; } continue ; } Logging . threads . error ( ""Exception tossed: "" + e . getMessage ( ) , e ) ; if ( e . getErrorCode ( ) == ManifoldCFException . SETUP_ERROR ) { System . exit ( 1 ) ; } } catch ( InterruptedException e ) { break ; } catch ( OutOfMemoryError e ) { System . err . println ( ""agents process ran out of memory - shutting down"" ) ; e . printStackTrace ( System . err ) ; System . exit ( - 200 ) ; } catch ( Throwable e ) { Logging . threads . fatal ( ""Error tossed: "" + e . getMessage ( ) , e ) ; } } } catch ( Throwable e ) { System . err . println ( ""agents process could not start - shutting down"" ) ; Logging . threads . fatal ( ""IdleCleanupThread initialization error tossed: "" + e . getMessage ( ) , e ) ; System . exit ( - 300 ) ; } }",Smelly
" public void read ( org . apache . thrift . protocol . TProtocol prot , getChildDataProducts_result struct ) throws org . apache . thrift . TException { TTupleProtocol iprot = ( TTupleProtocol ) prot ; BitSet incoming = iprot . readBitSet ( 5 ) ; if ( incoming . get ( 0 ) ) { { org . apache . thrift . protocol . TList _list283 = new org . apache . thrift . protocol . TList ( org . apache . thrift . protocol . TType . STRUCT , iprot . readI32 ( ) ) ; struct . success = new ArrayList < org . apache . airavata . model . data . replica . DataProductModel > ( _list283 . size ) ; org . apache . airavata . model . data . replica . DataProductModel _elem284 ; for ( int _i285 = 0 ; _i285 < _list283 . size ; ++ _i285 ) { _elem284 = new org . apache . airavata . model . data . replica . DataProductModel ( ) ; _elem284 . read ( iprot ) ; struct . success . add ( _elem284 ) ; } } struct . setSuccessIsSet ( true ) ; } if ( incoming . get ( 1 ) ) { struct . ire = new org . apache . airavata . model . error . InvalidRequestException ( ) ; struct . ire . read ( iprot ) ; struct . setIreIsSet ( true ) ; } if ( incoming . get ( 2 ) ) { struct . ace = new org . apache . airavata . model . error . AiravataClientException ( ) ; struct . ace . read ( iprot ) ; struct . setAceIsSet ( true ) ; } if ( incoming . get ( 3 ) ) { struct . ase = new org . apache . airavata . model . error . AiravataSystemException ( ) ; struct . ase . read ( iprot ) ; struct . setAseIsSet ( true ) ; } if ( incoming . get ( 4 ) ) { struct . ae = new org . apache . airavata . model . error . AuthorizationException ( ) ; struct . ae . read ( iprot ) ; struct . setAeIsSet ( true ) ; } }",Smelly
" protected void populateObject ( Object object ) throws Exception { super . populateObject ( object ) ; ProducerAck info = ( ProducerAck ) object ; info . setProducerId ( createProducerId ( ""ProducerId:1"" ) ) ; info . setSize ( 1 ) ; }",No
" public static void main ( final String [ ] args ) throws Exception { int res = ToolRunner . run ( new PerformanceEvaluation ( HBaseConfiguration . create ( ) ) , args ) ; System . exit ( res ) ; }",No
" protected Mapper < LongWritable , QuadWritable , NodeWritable , QuadWritable > getInstance ( ) { return new QuadGroupByGraphMapper < LongWritable > ( ) ; }",No
 void close ( ) { },No
" public void read ( org . apache . thrift . protocol . TProtocol prot , Project struct ) throws org . apache . thrift . TException { TTupleProtocol iprot = ( TTupleProtocol ) prot ; struct . projectID = iprot . readString ( ) ; struct . setProjectIDIsSet ( true ) ; struct . owner = iprot . readString ( ) ; struct . setOwnerIsSet ( true ) ; struct . name = iprot . readString ( ) ; struct . setNameIsSet ( true ) ; BitSet incoming = iprot . readBitSet ( 4 ) ; if ( incoming . get ( 0 ) ) { struct . description = iprot . readString ( ) ; struct . setDescriptionIsSet ( true ) ; } if ( incoming . get ( 1 ) ) { struct . creationTime = iprot . readI64 ( ) ; struct . setCreationTimeIsSet ( true ) ; } if ( incoming . get ( 2 ) ) { { org . apache . thrift . protocol . TList _list10 = new org . apache . thrift . protocol . TList ( org . apache . thrift . protocol . TType . STRING , iprot . readI32 ( ) ) ; struct . sharedUsers = new ArrayList < String > ( _list10 . size ) ; String _elem11 ; for ( int _i12 = 0 ; _i12 < _list10 . size ; ++ _i12 ) { _elem11 = iprot . readString ( ) ; struct . sharedUsers . add ( _elem11 ) ; } } struct . setSharedUsersIsSet ( true ) ; } if ( incoming . get ( 3 ) ) { { org . apache . thrift . protocol . TList _list13 = new org . apache . thrift . protocol . TList ( org . apache . thrift . protocol . TType . STRING , iprot . readI32 ( ) ) ; struct . sharedGroups = new ArrayList < String > ( _list13 . size ) ; String _elem14 ; for ( int _i15 = 0 ; _i15 < _list13 . size ; ++ _i15 ) { _elem14 = iprot . readString ( ) ; struct . sharedGroups . add ( _elem14 ) ; } } struct . setSharedGroupsIsSet ( true ) ; } }",Smelly
 public void setEndDateString ( String endDateString ) { this . endDateString = endDateString ; },No
" static String add_escapes ( String str ) { StringBuffer retval = new StringBuffer ( ) ; char ch ; for ( int i = 0 ; i < str . length ( ) ; i ++ ) { switch ( str . charAt ( i ) ) { case 0 : continue ; case '\b' : retval . append ( ""\\b"" ) ; continue ; case '\t' : retval . append ( ""\\t"" ) ; continue ; case '\n' : retval . append ( ""\\n"" ) ; continue ; case '\f' : retval . append ( ""\\f"" ) ; continue ; case '\r' : retval . append ( ""\\r"" ) ; continue ; case '\""' : retval . append ( ""\\\"""" ) ; continue ; case '\'' : retval . append ( ""\\\'"" ) ; continue ; case '\\' : retval . append ( ""\\\\"" ) ; continue ; default : if ( ( ch = str . charAt ( i ) ) < 0x20 || ch > 0x7e ) { String s = ""0000"" + Integer . toString ( ch , 16 ) ; retval . append ( ""\\u"" + s . substring ( s . length ( ) - 4 , s . length ( ) ) ) ; } else { retval . append ( ch ) ; } continue ; } } return retval . toString ( ) ; }",Smelly
 protected void reloadAction ( ) { action = getAction ( ) ; ( ( DefaultArchivaAdministration ) action . getArchivaAdministration ( ) ) . setArchivaConfiguration ( configuration ) ; },No
 public SerDeStats getSerDeStats ( ) { assert ( status != LAST_OPERATION . UNKNOWN ) ; if ( status == LAST_OPERATION . SERIALIZE ) { stats . setRawDataSize ( serializedSize ) ; } else { stats . setRawDataSize ( deserializedSize ) ; } return stats ; },No
" public static void main ( final String [ ] args ) throws Exception { int res = ToolRunner . run ( new PerformanceEvaluation ( HBaseConfiguration . create ( ) ) , args ) ; System . exit ( res ) ; }",No
 private static < S extends org . apache . thrift . scheme . IScheme > S scheme ( org . apache . thrift . protocol . TProtocol proto ) { return ( org . apache . thrift . scheme . StandardScheme . class . equals ( proto . getScheme ( ) ) ? STANDARD_SCHEME_FACTORY : TUPLE_SCHEME_FACTORY ) . getScheme ( ) ; },Smelly
" public void onMatch ( RelOptRuleCall call ) { final Union union = call . rel ( 0 ) ; final int count = union . getRowType ( ) . getFieldCount ( ) ; if ( count == 1 ) { return ; } final RexBuilder rexBuilder = union . getCluster ( ) . getRexBuilder ( ) ; final RelMetadataQuery mq = call . getMetadataQuery ( ) ; final RelOptPredicateList predicates = mq . getPulledUpPredicates ( union ) ; if ( predicates == null ) { return ; } final Map < Integer , RexNode > constants = new HashMap < > ( ) ; for ( Map . Entry < RexNode , RexNode > e : predicates . constantMap . entrySet ( ) ) { if ( e . getKey ( ) instanceof RexInputRef ) { constants . put ( ( ( RexInputRef ) e . getKey ( ) ) . getIndex ( ) , e . getValue ( ) ) ; } } if ( constants . isEmpty ( ) ) { return ; } List < RelDataTypeField > fields = union . getRowType ( ) . getFieldList ( ) ; List < RexNode > topChildExprs = new ArrayList < > ( ) ; List < String > topChildExprsFields = new ArrayList < > ( ) ; List < RexNode > refs = new ArrayList < > ( ) ; ImmutableBitSet . Builder refsIndexBuilder = ImmutableBitSet . builder ( ) ; for ( RelDataTypeField field : fields ) { final RexNode constant = constants . get ( field . getIndex ( ) ) ; if ( constant != null ) { topChildExprs . add ( constant ) ; topChildExprsFields . add ( field . getName ( ) ) ; } else { final RexNode expr = rexBuilder . makeInputRef ( union , field . getIndex ( ) ) ; topChildExprs . add ( expr ) ; topChildExprsFields . add ( field . getName ( ) ) ; refs . add ( expr ) ; refsIndexBuilder . set ( field . getIndex ( ) ) ; } } ImmutableBitSet refsIndex = refsIndexBuilder . build ( ) ; final Mappings . TargetMapping mapping = RelOptUtil . permutation ( refs , union . getInput ( 0 ) . getRowType ( ) ) . inverse ( ) ; topChildExprs = ImmutableList . copyOf ( RexUtil . apply ( mapping , topChildExprs ) ) ; final RelBuilder relBuilder = call . builder ( ) ; for ( RelNode input : union . getInputs ( ) ) { List < Pair < RexNode , String > > newChildExprs = new ArrayList < > ( ) ; for ( int j : refsIndex ) { newChildExprs . add ( Pair . of ( rexBuilder . makeInputRef ( input , j ) , input . getRowType ( ) . getFieldList ( ) . get ( j ) . getName ( ) ) ) ; } if ( newChildExprs . isEmpty ( ) ) { newChildExprs . add ( Pair . of ( topChildExprs . get ( 0 ) , topChildExprsFields . get ( 0 ) ) ) ; } relBuilder . push ( input ) ; relBuilder . project ( Pair . left ( newChildExprs ) , Pair . right ( newChildExprs ) ) ; } relBuilder . union ( union . all , union . getInputs ( ) . size ( ) ) ; relBuilder . project ( topChildExprs , topChildExprsFields ) ; relBuilder . convert ( union . getRowType ( ) , false ) ; call . transformTo ( relBuilder . build ( ) ) ; }",Smelly
 public static NodeProcessor getDefaultProc ( ) { return new DefaultLineage ( ) ; },Smelly
" public void read ( org . apache . thrift . protocol . TProtocol prot , SkewedInfo struct ) throws org . apache . thrift . TException { TTupleProtocol iprot = ( TTupleProtocol ) prot ; BitSet incoming = iprot . readBitSet ( 3 ) ; if ( incoming . get ( 0 ) ) { { org . apache . thrift . protocol . TList _list140 = new org . apache . thrift . protocol . TList ( org . apache . thrift . protocol . TType . STRING , iprot . readI32 ( ) ) ; struct . skewedColNames = new ArrayList < String > ( _list140 . size ) ; for ( int _i141 = 0 ; _i141 < _list140 . size ; ++ _i141 ) { String _elem142 ; _elem142 = iprot . readString ( ) ; struct . skewedColNames . add ( _elem142 ) ; } } struct . setSkewedColNamesIsSet ( true ) ; } if ( incoming . get ( 1 ) ) { { org . apache . thrift . protocol . TList _list143 = new org . apache . thrift . protocol . TList ( org . apache . thrift . protocol . TType . LIST , iprot . readI32 ( ) ) ; struct . skewedColValues = new ArrayList < List < String > > ( _list143 . size ) ; for ( int _i144 = 0 ; _i144 < _list143 . size ; ++ _i144 ) { List < String > _elem145 ; { org . apache . thrift . protocol . TList _list146 = new org . apache . thrift . protocol . TList ( org . apache . thrift . protocol . TType . STRING , iprot . readI32 ( ) ) ; _elem145 = new ArrayList < String > ( _list146 . size ) ; for ( int _i147 = 0 ; _i147 < _list146 . size ; ++ _i147 ) { String _elem148 ; _elem148 = iprot . readString ( ) ; _elem145 . add ( _elem148 ) ; } } struct . skewedColValues . add ( _elem145 ) ; } } struct . setSkewedColValuesIsSet ( true ) ; } if ( incoming . get ( 2 ) ) { { org . apache . thrift . protocol . TMap _map149 = new org . apache . thrift . protocol . TMap ( org . apache . thrift . protocol . TType . LIST , org . apache . thrift . protocol . TType . STRING , iprot . readI32 ( ) ) ; struct . skewedColValueLocationMaps = new HashMap < List < String > , String > ( 2 * _map149 . size ) ; for ( int _i150 = 0 ; _i150 < _map149 . size ; ++ _i150 ) { List < String > _key151 ; String _val152 ; { org . apache . thrift . protocol . TList _list153 = new org . apache . thrift . protocol . TList ( org . apache . thrift . protocol . TType . STRING , iprot . readI32 ( ) ) ; _key151 = new ArrayList < String > ( _list153 . size ) ; for ( int _i154 = 0 ; _i154 < _list153 . size ; ++ _i154 ) { String _elem155 ; _elem155 = iprot . readString ( ) ; _key151 . add ( _elem155 ) ; } } _val152 = iprot . readString ( ) ; struct . skewedColValueLocationMaps . put ( _key151 , _val152 ) ; } } struct . setSkewedColValueLocationMapsIsSet ( true ) ; } }",Smelly
 public long getEncodedLength ( final byte [ ] pArray ) { long len = ( ( pArray . length + unencodedBlockSize - 1 ) / unencodedBlockSize ) * ( long ) encodedBlockSize ; if ( lineLength > 0 ) { len += ( ( len + lineLength - 1 ) / lineLength ) * chunkSeparatorLength ; } return len ; },No
" public void read ( org . apache . thrift . protocol . TProtocol prot , getFollowing_result struct ) throws org . apache . thrift . TException { TTupleProtocol iprot = ( TTupleProtocol ) prot ; BitSet incoming = iprot . readBitSet ( 1 ) ; if ( incoming . get ( 0 ) ) { struct . success = new Key ( ) ; struct . success . read ( iprot ) ; struct . setSuccessIsSet ( true ) ; } }",Smelly
" public void read ( org . apache . thrift . protocol . TProtocol prot , getActiveLogs_result struct ) throws org . apache . thrift . TException { TTupleProtocol iprot = ( TTupleProtocol ) prot ; BitSet incoming = iprot . readBitSet ( 1 ) ; if ( incoming . get ( 0 ) ) { { org . apache . thrift . protocol . TList _list327 = new org . apache . thrift . protocol . TList ( org . apache . thrift . protocol . TType . STRING , iprot . readI32 ( ) ) ; struct . success = new ArrayList < String > ( _list327 . size ) ; for ( int _i328 = 0 ; _i328 < _list327 . size ; ++ _i328 ) { String _elem329 ; _elem329 = iprot . readString ( ) ; struct . success . add ( _elem329 ) ; } } struct . setSuccessIsSet ( true ) ; } }",Smelly
" public void read ( org . apache . thrift . protocol . TProtocol prot , getFollowing_result struct ) throws org . apache . thrift . TException { TTupleProtocol iprot = ( TTupleProtocol ) prot ; BitSet incoming = iprot . readBitSet ( 1 ) ; if ( incoming . get ( 0 ) ) { struct . success = new Key ( ) ; struct . success . read ( iprot ) ; struct . setSuccessIsSet ( true ) ; } }",Smelly
 protected abstract Object createEntry ( String name ) ;,No
" public static Map < Object , Constructor < ? extends StoragePlugin > > findAvailablePlugins ( final ScanResult classpathScan ) { Map < Object , Constructor < ? extends StoragePlugin > > availablePlugins = new HashMap < Object , Constructor < ? extends StoragePlugin > > ( ) ; final Collection < Class < ? extends StoragePlugin > > pluginClasses = classpathScan . getImplementations ( StoragePlugin . class ) ; final String lineBrokenList = pluginClasses . size ( ) == 0 ? """" : ""\n\t- "" + Joiner . on ( ""\n\t- "" ) . join ( pluginClasses ) ; logger . debug ( ""Found {} storage plugin configuration classes: {}."" , pluginClasses . size ( ) , lineBrokenList ) ; for ( Class < ? extends StoragePlugin > plugin : pluginClasses ) { int i = 0 ; for ( Constructor < ? > c : plugin . getConstructors ( ) ) { Class < ? > [ ] params = c . getParameterTypes ( ) ; if ( params . length != 3 || params [ 1 ] != DrillbitContext . class || ! StoragePluginConfig . class . isAssignableFrom ( params [ 0 ] ) || params [ 2 ] != String . class ) { logger . info ( ""Skipping StoragePlugin constructor {} for plugin class {} since it doesn't implement a "" + ""[constructor(StoragePluginConfig, DrillbitContext, String)]"" , c , plugin ) ; continue ; } availablePlugins . put ( params [ 0 ] , ( Constructor < ? extends StoragePlugin > ) c ) ; i ++ ; } if ( i == 0 ) { logger . debug ( ""Skipping registration of StoragePlugin {} as it doesn't have a constructor with the parameters "" + ""of (StorangePluginConfig, Config)"" , plugin . getCanonicalName ( ) ) ; } } return availablePlugins ; }",Smelly
" public boolean isEdgesDirty ( java . util . Map < java . lang . CharSequence , java . lang . CharSequence > value ) { throw new java . lang . UnsupportedOperationException ( ""IsDirty is not supported on tombstones"" ) ; }",No
 public void listAll ( ) throws Exception { ListServices listServices = new ListServices ( ) ; listServices . setBundleContext ( new TestBundleFactory ( ) . createBundleContext ( ) ) ; listServices . execute ( ) ; },No
 public NodeTypeProvider getNodeTypeProvider ( ) { return nodeTypeProvider ; },No
" public void read ( org . apache . thrift . protocol . TProtocol prot , getChildDataProducts_result struct ) throws org . apache . thrift . TException { TTupleProtocol iprot = ( TTupleProtocol ) prot ; BitSet incoming = iprot . readBitSet ( 5 ) ; if ( incoming . get ( 0 ) ) { { org . apache . thrift . protocol . TList _list283 = new org . apache . thrift . protocol . TList ( org . apache . thrift . protocol . TType . STRUCT , iprot . readI32 ( ) ) ; struct . success = new ArrayList < org . apache . airavata . model . data . replica . DataProductModel > ( _list283 . size ) ; org . apache . airavata . model . data . replica . DataProductModel _elem284 ; for ( int _i285 = 0 ; _i285 < _list283 . size ; ++ _i285 ) { _elem284 = new org . apache . airavata . model . data . replica . DataProductModel ( ) ; _elem284 . read ( iprot ) ; struct . success . add ( _elem284 ) ; } } struct . setSuccessIsSet ( true ) ; } if ( incoming . get ( 1 ) ) { struct . ire = new org . apache . airavata . model . error . InvalidRequestException ( ) ; struct . ire . read ( iprot ) ; struct . setIreIsSet ( true ) ; } if ( incoming . get ( 2 ) ) { struct . ace = new org . apache . airavata . model . error . AiravataClientException ( ) ; struct . ace . read ( iprot ) ; struct . setAceIsSet ( true ) ; } if ( incoming . get ( 3 ) ) { struct . ase = new org . apache . airavata . model . error . AiravataSystemException ( ) ; struct . ase . read ( iprot ) ; struct . setAseIsSet ( true ) ; } if ( incoming . get ( 4 ) ) { struct . ae = new org . apache . airavata . model . error . AuthorizationException ( ) ; struct . ae . read ( iprot ) ; struct . setAeIsSet ( true ) ; } }",Smelly
 IResultRow [ ] getRows ( ) ;,No
 public Consistency getConsistency ( ) { return Consistency . NONE ; },No
" public void read ( org . apache . thrift . protocol . TProtocol prot , ProcessModel struct ) throws org . apache . thrift . TException { TTupleProtocol iprot = ( TTupleProtocol ) prot ; struct . processId = iprot . readString ( ) ; struct . setProcessIdIsSet ( true ) ; struct . experimentId = iprot . readString ( ) ; struct . setExperimentIdIsSet ( true ) ; BitSet incoming = iprot . readBitSet ( 21 ) ; if ( incoming . get ( 0 ) ) { struct . creationTime = iprot . readI64 ( ) ; struct . setCreationTimeIsSet ( true ) ; } if ( incoming . get ( 1 ) ) { struct . lastUpdateTime = iprot . readI64 ( ) ; struct . setLastUpdateTimeIsSet ( true ) ; } if ( incoming . get ( 2 ) ) { struct . processStatus = new org . apache . airavata . model . status . ProcessStatus ( ) ; struct . processStatus . read ( iprot ) ; struct . setProcessStatusIsSet ( true ) ; } if ( incoming . get ( 3 ) ) { struct . processDetail = iprot . readString ( ) ; struct . setProcessDetailIsSet ( true ) ; } if ( incoming . get ( 4 ) ) { struct . applicationInterfaceId = iprot . readString ( ) ; struct . setApplicationInterfaceIdIsSet ( true ) ; } if ( incoming . get ( 5 ) ) { struct . applicationDeploymentId = iprot . readString ( ) ; struct . setApplicationDeploymentIdIsSet ( true ) ; } if ( incoming . get ( 6 ) ) { struct . computeResourceId = iprot . readString ( ) ; struct . setComputeResourceIdIsSet ( true ) ; } if ( incoming . get ( 7 ) ) { { org . apache . thrift . protocol . TList _list20 = new org . apache . thrift . protocol . TList ( org . apache . thrift . protocol . TType . STRUCT , iprot . readI32 ( ) ) ; struct . processInputs = new ArrayList < org . apache . airavata . model . application . io . InputDataObjectType > ( _list20 . size ) ; org . apache . airavata . model . application . io . InputDataObjectType _elem21 ; for ( int _i22 = 0 ; _i22 < _list20 . size ; ++ _i22 ) { _elem21 = new org . apache . airavata . model . application . io . InputDataObjectType ( ) ; _elem21 . read ( iprot ) ; struct . processInputs . add ( _elem21 ) ; } } struct . setProcessInputsIsSet ( true ) ; } if ( incoming . get ( 8 ) ) { { org . apache . thrift . protocol . TList _list23 = new org . apache . thrift . protocol . TList ( org . apache . thrift . protocol . TType . STRUCT , iprot . readI32 ( ) ) ; struct . processOutputs = new ArrayList < org . apache . airavata . model . application . io . OutputDataObjectType > ( _list23 . size ) ; org . apache . airavata . model . application . io . OutputDataObjectType _elem24 ; for ( int _i25 = 0 ; _i25 < _list23 . size ; ++ _i25 ) { _elem24 = new org . apache . airavata . model . application . io . OutputDataObjectType ( ) ; _elem24 . read ( iprot ) ; struct . processOutputs . add ( _elem24 ) ; } } struct . setProcessOutputsIsSet ( true ) ; } if ( incoming . get ( 9 ) ) { struct . resourceSchedule = new org . apache . airavata . model . scheduling . ComputationalResourceSchedulingModel ( ) ; struct . resourceSchedule . read ( iprot ) ; struct . setResourceScheduleIsSet ( true ) ; } if ( incoming . get ( 10 ) ) { { org . apache . thrift . protocol . TList _list26 = new org . apache . thrift . protocol . TList ( org . apache . thrift . protocol . TType . STRUCT , iprot . readI32 ( ) ) ; struct . tasks = new ArrayList < org . apache . airavata . model . task . TaskModel > ( _list26 . size ) ; org . apache . airavata . model . task . TaskModel _elem27 ; for ( int _i28 = 0 ; _i28 < _list26 . size ; ++ _i28 ) { _elem27 = new org . apache . airavata . model . task . TaskModel ( ) ; _elem27 . read ( iprot ) ; struct . tasks . add ( _elem27 ) ; } } struct . setTasksIsSet ( true ) ; } if ( incoming . get ( 11 ) ) { struct . taskDag = iprot . readString ( ) ; struct . setTaskDagIsSet ( true ) ; } if ( incoming . get ( 12 ) ) { struct . processError = new org . apache . airavata . model . commons . ErrorModel ( ) ; struct . processError . read ( iprot ) ; struct . setProcessErrorIsSet ( true ) ; } if ( incoming . get ( 13 ) ) { struct . gatewayExecutionId = iprot . readString ( ) ; struct . setGatewayExecutionIdIsSet ( true ) ; } if ( incoming . get ( 14 ) ) { struct . enableEmailNotification = iprot . readBool ( ) ; struct . setEnableEmailNotificationIsSet ( true ) ; } if ( incoming . get ( 15 ) ) { { org . apache . thrift . protocol . TList _list29 = new org . apache . thrift . protocol . TList ( org . apache . thrift . protocol . TType . STRING , iprot . readI32 ( ) ) ; struct . emailAddresses = new ArrayList < String > ( _list29 . size ) ; String _elem30 ; for ( int _i31 = 0 ; _i31 < _list29 . size ; ++ _i31 ) { _elem30 = iprot . readString ( ) ; struct . emailAddresses . add ( _elem30 ) ; } } struct . setEmailAddressesIsSet ( true ) ; } if ( incoming . get ( 16 ) ) { struct . storageResourceId = iprot . readString ( ) ; struct . setStorageResourceIdIsSet ( true ) ; } if ( incoming . get ( 17 ) ) { struct . userDn = iprot . readString ( ) ; struct . setUserDnIsSet ( true ) ; } if ( incoming . get ( 18 ) ) { struct . generateCert = iprot . readBool ( ) ; struct . setGenerateCertIsSet ( true ) ; } if ( incoming . get ( 19 ) ) { struct . experimentDataDir = iprot . readString ( ) ; struct . setExperimentDataDirIsSet ( true ) ; } if ( incoming . get ( 20 ) ) { struct . userName = iprot . readString ( ) ; struct . setUserNameIsSet ( true ) ; } }",Smelly
 public BigDecimal toBigDecimal ( BigDecimal record ) { return record ; },No
 public void addDimension ( Column column ) { dimensionListBuilder . add ( column ) ; },No
" public GroupedTableOperationRepartitionNode < K , V > build ( ) { return new GroupedTableOperationRepartitionNode < > ( nodeName , keySerde , valueSerde , sinkName , sourceName , repartitionTopic , processorParameters ) ; }",No
 public String getProjectGroupName ( ) throws ContinuumException { if ( StringUtils . isEmpty ( projectGroupName ) ) { if ( projectGroupId != 0 ) { projectGroupName = getContinuum ( ) . getProjectGroup ( projectGroupId ) . getName ( ) ; } else { projectGroupName = getContinuum ( ) . getProjectGroupByProjectId ( projectId ) . getName ( ) ; } } return projectGroupName ; },No
" private HashMap propagateParameters ( Configuration conf , ResultSet rs , Session session ) { Configuration table = conf . getChild ( ""table"" ) ; Configuration [ ] select = table . getChildren ( ""select"" ) ; String session_param ; HashMap map = new HashMap ( ) ; try { for ( int i = 0 ; i < select . length ; i ++ ) { try { session_param = select [ i ] . getAttribute ( ""to-session"" ) ; if ( session_param != null && ! session_param . trim ( ) . equals ( """" ) ) { String s = rs . getString ( i + 1 ) ; Object o = null ; String type = select [ i ] . getAttribute ( ""type"" , """" ) ; if ( StringUtils . isEmpty ( type . trim ( ) ) || ""string"" . equals ( type ) ) { o = s ; } else if ( ""long"" . equals ( type ) ) { Long l = Long . decode ( s ) ; o = l ; } else if ( ""double"" . equals ( type ) ) { Double d = Double . valueOf ( s ) ; o = d ; } if ( session != null ) { session . setAttribute ( session_param , o ) ; if ( getLogger ( ) . isDebugEnabled ( ) ) { getLogger ( ) . debug ( ""DBCOOKIEAUTH: propagating param "" + session_param + ""="" + s ) ; } } map . put ( session_param , o ) ; } } catch ( Exception e ) { } } return map ; } catch ( Exception e ) { getLogger ( ) . error ( ""Exception: "" , e ) ; } return null ; }",Smelly
" public void read ( org . apache . thrift . protocol . TProtocol prot , getChildDataProducts_result struct ) throws org . apache . thrift . TException { TTupleProtocol iprot = ( TTupleProtocol ) prot ; BitSet incoming = iprot . readBitSet ( 5 ) ; if ( incoming . get ( 0 ) ) { { org . apache . thrift . protocol . TList _list283 = new org . apache . thrift . protocol . TList ( org . apache . thrift . protocol . TType . STRUCT , iprot . readI32 ( ) ) ; struct . success = new ArrayList < org . apache . airavata . model . data . replica . DataProductModel > ( _list283 . size ) ; org . apache . airavata . model . data . replica . DataProductModel _elem284 ; for ( int _i285 = 0 ; _i285 < _list283 . size ; ++ _i285 ) { _elem284 = new org . apache . airavata . model . data . replica . DataProductModel ( ) ; _elem284 . read ( iprot ) ; struct . success . add ( _elem284 ) ; } } struct . setSuccessIsSet ( true ) ; } if ( incoming . get ( 1 ) ) { struct . ire = new org . apache . airavata . model . error . InvalidRequestException ( ) ; struct . ire . read ( iprot ) ; struct . setIreIsSet ( true ) ; } if ( incoming . get ( 2 ) ) { struct . ace = new org . apache . airavata . model . error . AiravataClientException ( ) ; struct . ace . read ( iprot ) ; struct . setAceIsSet ( true ) ; } if ( incoming . get ( 3 ) ) { struct . ase = new org . apache . airavata . model . error . AiravataSystemException ( ) ; struct . ase . read ( iprot ) ; struct . setAseIsSet ( true ) ; } if ( incoming . get ( 4 ) ) { struct . ae = new org . apache . airavata . model . error . AuthorizationException ( ) ; struct . ae . read ( iprot ) ; struct . setAeIsSet ( true ) ; } }",Smelly
" static String buildNavPath ( UriHelper helper , EdmEntityType rootType , LinkedList < UriResourceNavigation > navigations , boolean includeLastPredicates ) throws SerializerException { if ( navigations . isEmpty ( ) ) { return null ; } StringBuilder sb = new StringBuilder ( ) ; boolean containsTarget = false ; EdmEntityType type = rootType ; for ( UriResourceNavigation nav : navigations ) { String name = nav . getProperty ( ) . getName ( ) ; EdmNavigationProperty property = type . getNavigationProperty ( name ) ; if ( property . containsTarget ( ) ) { containsTarget = true ; } type = nav . getProperty ( ) . getType ( ) ; } if ( containsTarget ) { for ( int i = 0 ; i < navigations . size ( ) ; i ++ ) { UriResourceNavigation nav = navigations . get ( i ) ; if ( i > 0 ) { sb . append ( ""/"" ) ; } sb . append ( nav . getProperty ( ) . getName ( ) ) ; boolean skipKeys = false ; if ( navigations . size ( ) == i + 1 && ! includeLastPredicates ) { skipKeys = true ; } if ( ! skipKeys && ! nav . getKeyPredicates ( ) . isEmpty ( ) ) { sb . append ( ""("" ) ; sb . append ( helper . buildContextURLKeyPredicate ( nav . getKeyPredicates ( ) ) ) ; sb . append ( "")"" ) ; } if ( nav . getTypeFilterOnCollection ( ) != null ) { sb . append ( ""/"" ) . append ( nav . getTypeFilterOnCollection ( ) . getFullQualifiedName ( ) . getFullQualifiedNameAsString ( ) ) ; } else if ( nav . getTypeFilterOnEntry ( ) != null ) { sb . append ( ""/"" ) . append ( nav . getTypeFilterOnEntry ( ) . getFullQualifiedName ( ) . getFullQualifiedNameAsString ( ) ) ; } } } return sb . toString ( ) ; }",No
" public void read ( org . apache . thrift . protocol . TProtocol prot , show_compact_result struct ) throws org . apache . thrift . TException { TTupleProtocol iprot = ( TTupleProtocol ) prot ; BitSet incoming = iprot . readBitSet ( 1 ) ; if ( incoming . get ( 0 ) ) { struct . success = new ShowCompactResponse ( ) ; struct . success . read ( iprot ) ; struct . setSuccessIsSet ( true ) ; } }",Smelly
" public void read ( org . apache . thrift . protocol . TProtocol prot , TStringColumn struct ) throws org . apache . thrift . TException { TTupleProtocol iprot = ( TTupleProtocol ) prot ; { org . apache . thrift . protocol . TList _list107 = new org . apache . thrift . protocol . TList ( org . apache . thrift . protocol . TType . STRING , iprot . readI32 ( ) ) ; struct . values = new ArrayList < String > ( _list107 . size ) ; for ( int _i108 = 0 ; _i108 < _list107 . size ; ++ _i108 ) { String _elem109 ; _elem109 = iprot . readString ( ) ; struct . values . add ( _elem109 ) ; } } struct . setValuesIsSet ( true ) ; struct . nulls = iprot . readBinary ( ) ; struct . setNullsIsSet ( true ) ; }",Smelly
" private SortedSet < String > getConfusionMatrixTagset ( Map < String , ConfusionMatrixLine > data ) { SortedSet < String > tags = new TreeSet < > ( getMatrixLabelComparator ( data ) ) ; tags . addAll ( data . keySet ( ) ) ; List < String > col = new LinkedList < > ( ) ; for ( String t : tags ) { col . addAll ( data . get ( t ) . line . keySet ( ) ) ; } tags . addAll ( col ) ; return Collections . unmodifiableSortedSet ( tags ) ; }",Smelly
 private static < S extends org . apache . thrift . scheme . IScheme > S scheme ( org . apache . thrift . protocol . TProtocol proto ) { return ( org . apache . thrift . scheme . StandardScheme . class . equals ( proto . getScheme ( ) ) ? STANDARD_SCHEME_FACTORY : TUPLE_SCHEME_FACTORY ) . getScheme ( ) ; },Smelly
 public String [ ] getArgs ( ) { return args ; },Smelly
 private static < S extends org . apache . thrift . scheme . IScheme > S scheme ( org . apache . thrift . protocol . TProtocol proto ) { return ( org . apache . thrift . scheme . StandardScheme . class . equals ( proto . getScheme ( ) ) ? STANDARD_SCHEME_FACTORY : TUPLE_SCHEME_FACTORY ) . getScheme ( ) ; },No
" public final void compareMarkupWithString ( IMarkupFragment markup , String testMarkup ) throws IOException { testMarkup = testMarkup . replaceAll ( ""\r"" , """" ) ; testMarkup = testMarkup . replaceAll ( ""\n"" , """" ) ; testMarkup = testMarkup . replaceAll ( ""\t"" , """" ) ; String doc = markup . toString ( true ) ; doc = doc . replaceAll ( ""\n"" , """" ) ; doc = doc . replaceAll ( ""\r"" , """" ) ; doc = doc . replaceAll ( ""\t"" , """" ) ; assertEquals ( doc , testMarkup ) ; }",No
" public void visit ( State state , Environment env , Properties props ) throws Exception { String target = props . getProperty ( ""target"" ) ; String source = props . getProperty ( ""source"" ) ; String principal ; AuthenticationToken token ; if ( source . equals ( ""system"" ) ) { principal = WalkingSecurity . get ( state , env ) . getSysUserName ( ) ; token = WalkingSecurity . get ( state , env ) . getSysToken ( ) ; } else { principal = WalkingSecurity . get ( state , env ) . getTabUserName ( ) ; token = WalkingSecurity . get ( state , env ) . getTabToken ( ) ; } Connector conn = env . getInstance ( ) . getConnector ( principal , token ) ; boolean hasPerm ; boolean targetExists ; if ( target . equals ( ""table"" ) ) { target = WalkingSecurity . get ( state , env ) . getTabUserName ( ) ; } else target = WalkingSecurity . get ( state , env ) . getSysUserName ( ) ; targetExists = WalkingSecurity . get ( state , env ) . userExists ( target ) ; hasPerm = WalkingSecurity . get ( state , env ) . canChangePassword ( new Credentials ( principal , token ) . toThrift ( env . getInstance ( ) ) , target ) ; Random r = new Random ( ) ; byte [ ] newPassw = new byte [ r . nextInt ( 50 ) + 1 ] ; for ( int i = 0 ; i < newPassw . length ; i ++ ) newPassw [ i ] = ( byte ) ( ( r . nextInt ( 26 ) + 65 ) & 0xFF ) ; PasswordToken newPass = new PasswordToken ( newPassw ) ; try { conn . securityOperations ( ) . changeLocalUserPassword ( target , newPass ) ; } catch ( AccumuloSecurityException ae ) { switch ( ae . getSecurityErrorCode ( ) ) { case PERMISSION_DENIED : if ( hasPerm ) throw new AccumuloException ( ""Change failed when it should have succeeded to change "" + target + ""'s password"" , ae ) ; return ; case USER_DOESNT_EXIST : if ( targetExists ) throw new AccumuloException ( ""User "" + target + "" doesn't exist and they SHOULD."" , ae ) ; return ; case BAD_CREDENTIALS : if ( ! WalkingSecurity . get ( state , env ) . userPassTransient ( conn . whoami ( ) ) ) throw new AccumuloException ( ""Bad credentials for user "" + conn . whoami ( ) ) ; return ; default : throw new AccumuloException ( ""Got unexpected exception"" , ae ) ; } } WalkingSecurity . get ( state , env ) . changePassword ( target , newPass ) ; Thread . sleep ( 1000 ) ; if ( ! hasPerm ) throw new AccumuloException ( ""Password change succeeded when it should have failed for "" + source + "" changing the password for "" + target + ""."" ) ; }",Smelly
" private final Component resolveAutomaticLink ( final PathInfo pathInfo , final String id , final ComponentTag tag ) { final MarkupContainer container = pathInfo . getContainer ( ) ; final Page page = container . getPage ( ) ; final String autoId = id + Integer . toString ( page . getAutoIndex ( ) ) ; final String tagName = tag . getName ( ) ; if ( tag . getId ( ) == null ) { tag . setAutoComponentTag ( true ) ; } IAutolinkResolverDelegate autolinkResolverDelegate = tagNameToAutolinkResolverDelegates . get ( tagName ) ; Component autoComponent = null ; if ( autolinkResolverDelegate != null ) { autoComponent = autolinkResolverDelegate . newAutoComponent ( autoId , pathInfo ) ; } if ( autoComponent == null ) { autoComponent = new AutolinkExternalLink ( autoId , pathInfo . reference ) ; } return autoComponent ; }",Smelly
 public Numeric getNumeric ( ) { return this ; },No
" public void read ( org . apache . thrift . protocol . TProtocol prot , MegaStruct struct ) throws org . apache . thrift . TException { TTupleProtocol iprot = ( TTupleProtocol ) prot ; BitSet incoming = iprot . readBitSet ( 20 ) ; if ( incoming . get ( 0 ) ) { struct . my_bool = iprot . readBool ( ) ; struct . setMy_boolIsSet ( true ) ; } if ( incoming . get ( 1 ) ) { struct . my_byte = iprot . readByte ( ) ; struct . setMy_byteIsSet ( true ) ; } if ( incoming . get ( 2 ) ) { struct . my_16bit_int = iprot . readI16 ( ) ; struct . setMy_16bit_intIsSet ( true ) ; } if ( incoming . get ( 3 ) ) { struct . my_32bit_int = iprot . readI32 ( ) ; struct . setMy_32bit_intIsSet ( true ) ; } if ( incoming . get ( 4 ) ) { struct . my_64bit_int = iprot . readI64 ( ) ; struct . setMy_64bit_intIsSet ( true ) ; } if ( incoming . get ( 5 ) ) { struct . my_double = iprot . readDouble ( ) ; struct . setMy_doubleIsSet ( true ) ; } if ( incoming . get ( 6 ) ) { struct . my_string = iprot . readString ( ) ; struct . setMy_stringIsSet ( true ) ; } if ( incoming . get ( 7 ) ) { struct . my_binary = iprot . readBinary ( ) ; struct . setMy_binaryIsSet ( true ) ; } if ( incoming . get ( 8 ) ) { { org . apache . thrift . protocol . TMap _map76 = new org . apache . thrift . protocol . TMap ( org . apache . thrift . protocol . TType . STRING , org . apache . thrift . protocol . TType . STRING , iprot . readI32 ( ) ) ; struct . my_string_string_map = new HashMap < String , String > ( 2 * _map76 . size ) ; for ( int _i77 = 0 ; _i77 < _map76 . size ; ++ _i77 ) { String _key78 ; String _val79 ; _key78 = iprot . readString ( ) ; _val79 = iprot . readString ( ) ; struct . my_string_string_map . put ( _key78 , _val79 ) ; } } struct . setMy_string_string_mapIsSet ( true ) ; } if ( incoming . get ( 9 ) ) { { org . apache . thrift . protocol . TMap _map80 = new org . apache . thrift . protocol . TMap ( org . apache . thrift . protocol . TType . STRING , org . apache . thrift . protocol . TType . I32 , iprot . readI32 ( ) ) ; struct . my_string_enum_map = new HashMap < String , MyEnum > ( 2 * _map80 . size ) ; for ( int _i81 = 0 ; _i81 < _map80 . size ; ++ _i81 ) { String _key82 ; MyEnum _val83 ; _key82 = iprot . readString ( ) ; _val83 = MyEnum . findByValue ( iprot . readI32 ( ) ) ; struct . my_string_enum_map . put ( _key82 , _val83 ) ; } } struct . setMy_string_enum_mapIsSet ( true ) ; } if ( incoming . get ( 10 ) ) { { org . apache . thrift . protocol . TMap _map84 = new org . apache . thrift . protocol . TMap ( org . apache . thrift . protocol . TType . I32 , org . apache . thrift . protocol . TType . STRING , iprot . readI32 ( ) ) ; struct . my_enum_string_map = new HashMap < MyEnum , String > ( 2 * _map84 . size ) ; for ( int _i85 = 0 ; _i85 < _map84 . size ; ++ _i85 ) { MyEnum _key86 ; String _val87 ; _key86 = MyEnum . findByValue ( iprot . readI32 ( ) ) ; _val87 = iprot . readString ( ) ; struct . my_enum_string_map . put ( _key86 , _val87 ) ; } } struct . setMy_enum_string_mapIsSet ( true ) ; } if ( incoming . get ( 11 ) ) { { org . apache . thrift . protocol . TMap _map88 = new org . apache . thrift . protocol . TMap ( org . apache . thrift . protocol . TType . I32 , org . apache . thrift . protocol . TType . STRUCT , iprot . readI32 ( ) ) ; struct . my_enum_struct_map = new HashMap < MyEnum , MiniStruct > ( 2 * _map88 . size ) ; for ( int _i89 = 0 ; _i89 < _map88 . size ; ++ _i89 ) { MyEnum _key90 ; MiniStruct _val91 ; _key90 = MyEnum . findByValue ( iprot . readI32 ( ) ) ; _val91 = new MiniStruct ( ) ; _val91 . read ( iprot ) ; struct . my_enum_struct_map . put ( _key90 , _val91 ) ; } } struct . setMy_enum_struct_mapIsSet ( true ) ; } if ( incoming . get ( 12 ) ) { { org . apache . thrift . protocol . TMap _map92 = new org . apache . thrift . protocol . TMap ( org . apache . thrift . protocol . TType . I32 , org . apache . thrift . protocol . TType . LIST , iprot . readI32 ( ) ) ; struct . my_enum_stringlist_map = new HashMap < MyEnum , List < String > > ( 2 * _map92 . size ) ; for ( int _i93 = 0 ; _i93 < _map92 . size ; ++ _i93 ) { MyEnum _key94 ; List < String > _val95 ; _key94 = MyEnum . findByValue ( iprot . readI32 ( ) ) ; { org . apache . thrift . protocol . TList _list96 = new org . apache . thrift . protocol . TList ( org . apache . thrift . protocol . TType . STRING , iprot . readI32 ( ) ) ; _val95 = new ArrayList < String > ( _list96 . size ) ; for ( int _i97 = 0 ; _i97 < _list96 . size ; ++ _i97 ) { String _elem98 ; _elem98 = iprot . readString ( ) ; _val95 . add ( _elem98 ) ; } } struct . my_enum_stringlist_map . put ( _key94 , _val95 ) ; } } struct . setMy_enum_stringlist_mapIsSet ( true ) ; } if ( incoming . get ( 13 ) ) { { org . apache . thrift . protocol . TMap _map99 = new org . apache . thrift . protocol . TMap ( org . apache . thrift . protocol . TType . I32 , org . apache . thrift . protocol . TType . LIST , iprot . readI32 ( ) ) ; struct . my_enum_structlist_map = new HashMap < MyEnum , List < MiniStruct > > ( 2 * _map99 . size ) ; for ( int _i100 = 0 ; _i100 < _map99 . size ; ++ _i100 ) { MyEnum _key101 ; List < MiniStruct > _val102 ; _key101 = MyEnum . findByValue ( iprot . readI32 ( ) ) ; { org . apache . thrift . protocol . TList _list103 = new org . apache . thrift . protocol . TList ( org . apache . thrift . protocol . TType . STRUCT , iprot . readI32 ( ) ) ; _val102 = new ArrayList < MiniStruct > ( _list103 . size ) ; for ( int _i104 = 0 ; _i104 < _list103 . size ; ++ _i104 ) { MiniStruct _elem105 ; _elem105 = new MiniStruct ( ) ; _elem105 . read ( iprot ) ; _val102 . add ( _elem105 ) ; } } struct . my_enum_structlist_map . put ( _key101 , _val102 ) ; } } struct . setMy_enum_structlist_mapIsSet ( true ) ; } if ( incoming . get ( 14 ) ) { { org . apache . thrift . protocol . TList _list106 = new org . apache . thrift . protocol . TList ( org . apache . thrift . protocol . TType . STRING , iprot . readI32 ( ) ) ; struct . my_stringlist = new ArrayList < String > ( _list106 . size ) ; for ( int _i107 = 0 ; _i107 < _list106 . size ; ++ _i107 ) { String _elem108 ; _elem108 = iprot . readString ( ) ; struct . my_stringlist . add ( _elem108 ) ; } } struct . setMy_stringlistIsSet ( true ) ; } if ( incoming . get ( 15 ) ) { { org . apache . thrift . protocol . TList _list109 = new org . apache . thrift . protocol . TList ( org . apache . thrift . protocol . TType . STRUCT , iprot . readI32 ( ) ) ; struct . my_structlist = new ArrayList < MiniStruct > ( _list109 . size ) ; for ( int _i110 = 0 ; _i110 < _list109 . size ; ++ _i110 ) { MiniStruct _elem111 ; _elem111 = new MiniStruct ( ) ; _elem111 . read ( iprot ) ; struct . my_structlist . add ( _elem111 ) ; } } struct . setMy_structlistIsSet ( true ) ; } if ( incoming . get ( 16 ) ) { { org . apache . thrift . protocol . TList _list112 = new org . apache . thrift . protocol . TList ( org . apache . thrift . protocol . TType . I32 , iprot . readI32 ( ) ) ; struct . my_enumlist = new ArrayList < MyEnum > ( _list112 . size ) ; for ( int _i113 = 0 ; _i113 < _list112 . size ; ++ _i113 ) { MyEnum _elem114 ; _elem114 = MyEnum . findByValue ( iprot . readI32 ( ) ) ; struct . my_enumlist . add ( _elem114 ) ; } } struct . setMy_enumlistIsSet ( true ) ; } if ( incoming . get ( 17 ) ) { { org . apache . thrift . protocol . TSet _set115 = new org . apache . thrift . protocol . TSet ( org . apache . thrift . protocol . TType . STRING , iprot . readI32 ( ) ) ; struct . my_stringset = new HashSet < String > ( 2 * _set115 . size ) ; for ( int _i116 = 0 ; _i116 < _set115 . size ; ++ _i116 ) { String _elem117 ; _elem117 = iprot . readString ( ) ; struct . my_stringset . add ( _elem117 ) ; } } struct . setMy_stringsetIsSet ( true ) ; } if ( incoming . get ( 18 ) ) { { org . apache . thrift . protocol . TSet _set118 = new org . apache . thrift . protocol . TSet ( org . apache . thrift . protocol . TType . I32 , iprot . readI32 ( ) ) ; struct . my_enumset = new HashSet < MyEnum > ( 2 * _set118 . size ) ; for ( int _i119 = 0 ; _i119 < _set118 . size ; ++ _i119 ) { MyEnum _elem120 ; _elem120 = MyEnum . findByValue ( iprot . readI32 ( ) ) ; struct . my_enumset . add ( _elem120 ) ; } } struct . setMy_enumsetIsSet ( true ) ; } if ( incoming . get ( 19 ) ) { { org . apache . thrift . protocol . TSet _set121 = new org . apache . thrift . protocol . TSet ( org . apache . thrift . protocol . TType . STRUCT , iprot . readI32 ( ) ) ; struct . my_structset = new HashSet < MiniStruct > ( 2 * _set121 . size ) ; for ( int _i122 = 0 ; _i122 < _set121 . size ; ++ _i122 ) { MiniStruct _elem123 ; _elem123 = new MiniStruct ( ) ; _elem123 . read ( iprot ) ; struct . my_structset . add ( _elem123 ) ; } } struct . setMy_structsetIsSet ( true ) ; } }",Smelly
" public void read ( org . apache . thrift . protocol . TProtocol prot , onReceivedZeppelinResource_result struct ) throws org . apache . thrift . TException { TTupleProtocol iprot = ( TTupleProtocol ) prot ; }",Smelly
" public void eval ( ) { final int len = in . end - in . start ; out . start = 0 ; out . end = len ; out . buffer = buffer = buffer . reallocIfNeeded ( len ) ; int charLen ; int index = out . end ; int innerIndex ; for ( int id = in . start ; id < in . end ; id += charLen ) { innerIndex = charLen = org . apache . drill . exec . expr . fn . impl . StringFunctionUtil . utf8CharLen ( in . buffer , id ) ; while ( innerIndex > 0 ) { out . buffer . setByte ( index - innerIndex , in . buffer . getByte ( id + ( charLen - innerIndex ) ) ) ; innerIndex -- ; } index -= charLen ; } }",Smelly
" public void read ( org . apache . thrift . protocol . TProtocol prot , drainReplicationTable_result struct ) throws org . apache . thrift . TException { TTupleProtocol iprot = ( TTupleProtocol ) prot ; BitSet incoming = iprot . readBitSet ( 1 ) ; if ( incoming . get ( 0 ) ) { struct . success = iprot . readBool ( ) ; struct . setSuccessIsSet ( true ) ; } }",Smelly
 public void setName ( String name ) { this . name = name ; },No
" public void read ( org . apache . thrift . protocol . TProtocol prot , DropPartitionsResult struct ) throws org . apache . thrift . TException { TTupleProtocol iprot = ( TTupleProtocol ) prot ; BitSet incoming = iprot . readBitSet ( 1 ) ; if ( incoming . get ( 0 ) ) { { org . apache . thrift . protocol . TList _list351 = new org . apache . thrift . protocol . TList ( org . apache . thrift . protocol . TType . STRUCT , iprot . readI32 ( ) ) ; struct . partitions = new ArrayList < Partition > ( _list351 . size ) ; for ( int _i352 = 0 ; _i352 < _list351 . size ; ++ _i352 ) { Partition _elem353 ; _elem353 = new Partition ( ) ; _elem353 . read ( iprot ) ; struct . partitions . add ( _elem353 ) ; } } struct . setPartitionsIsSet ( true ) ; } }",No
 public abstract Repository getRepository ( ) ;,No
" public void read ( org . apache . thrift . protocol . TProtocol prot , getActiveLogs_result struct ) throws org . apache . thrift . TException { TTupleProtocol iprot = ( TTupleProtocol ) prot ; BitSet incoming = iprot . readBitSet ( 1 ) ; if ( incoming . get ( 0 ) ) { { org . apache . thrift . protocol . TList _list327 = new org . apache . thrift . protocol . TList ( org . apache . thrift . protocol . TType . STRING , iprot . readI32 ( ) ) ; struct . success = new ArrayList < String > ( _list327 . size ) ; for ( int _i328 = 0 ; _i328 < _list327 . size ; ++ _i328 ) { String _elem329 ; _elem329 = iprot . readString ( ) ; struct . success . add ( _elem329 ) ; } } struct . setSuccessIsSet ( true ) ; } }",Smelly
" public Object getObjectInstance ( Object obj , Name name , Context nameCtx , Hashtable < ? , ? > environment ) throws Exception { if ( obj instanceof ResourceEnvRef ) { Reference ref = ( Reference ) obj ; ObjectFactory factory = null ; RefAddr factoryRefAddr = ref . get ( Constants . FACTORY ) ; if ( factoryRefAddr != null ) { String factoryClassName = factoryRefAddr . getContent ( ) . toString ( ) ; ClassLoader tcl = Thread . currentThread ( ) . getContextClassLoader ( ) ; Class < ? > factoryClass = null ; if ( tcl != null ) { try { factoryClass = tcl . loadClass ( factoryClassName ) ; } catch ( ClassNotFoundException e ) { NamingException ex = new NamingException ( ""Could not load resource factory class"" ) ; ex . initCause ( e ) ; throw ex ; } } else { try { factoryClass = Class . forName ( factoryClassName ) ; } catch ( ClassNotFoundException e ) { NamingException ex = new NamingException ( ""Could not load resource factory class"" ) ; ex . initCause ( e ) ; throw ex ; } } if ( factoryClass != null ) { try { factory = ( ObjectFactory ) factoryClass . newInstance ( ) ; } catch ( Throwable t ) { if ( t instanceof NamingException ) throw ( NamingException ) t ; NamingException ex = new NamingException ( ""Could not create resource factory instance"" ) ; ex . initCause ( t ) ; throw ex ; } } } if ( factory != null ) { return factory . getObjectInstance ( obj , name , nameCtx , environment ) ; } else { throw new NamingException ( ""Cannot create resource instance"" ) ; } } return null ; }",Smelly
" public void read ( org . apache . thrift . protocol . TProtocol prot , JobSubmissionInterface struct ) throws org . apache . thrift . TException { TTupleProtocol iprot = ( TTupleProtocol ) prot ; struct . jobSubmissionInterfaceId = iprot . readString ( ) ; struct . setJobSubmissionInterfaceIdIsSet ( true ) ; struct . jobSubmissionProtocol = org . apache . airavata . model . appcatalog . computeresource . JobSubmissionProtocol . findByValue ( iprot . readI32 ( ) ) ; struct . setJobSubmissionProtocolIsSet ( true ) ; struct . priorityOrder = iprot . readI32 ( ) ; struct . setPriorityOrderIsSet ( true ) ; }",No
" public void read ( org . apache . thrift . protocol . TProtocol prot , getChildDataProducts_result struct ) throws org . apache . thrift . TException { TTupleProtocol iprot = ( TTupleProtocol ) prot ; BitSet incoming = iprot . readBitSet ( 5 ) ; if ( incoming . get ( 0 ) ) { { org . apache . thrift . protocol . TList _list283 = new org . apache . thrift . protocol . TList ( org . apache . thrift . protocol . TType . STRUCT , iprot . readI32 ( ) ) ; struct . success = new ArrayList < org . apache . airavata . model . data . replica . DataProductModel > ( _list283 . size ) ; org . apache . airavata . model . data . replica . DataProductModel _elem284 ; for ( int _i285 = 0 ; _i285 < _list283 . size ; ++ _i285 ) { _elem284 = new org . apache . airavata . model . data . replica . DataProductModel ( ) ; _elem284 . read ( iprot ) ; struct . success . add ( _elem284 ) ; } } struct . setSuccessIsSet ( true ) ; } if ( incoming . get ( 1 ) ) { struct . ire = new org . apache . airavata . model . error . InvalidRequestException ( ) ; struct . ire . read ( iprot ) ; struct . setIreIsSet ( true ) ; } if ( incoming . get ( 2 ) ) { struct . ace = new org . apache . airavata . model . error . AiravataClientException ( ) ; struct . ace . read ( iprot ) ; struct . setAceIsSet ( true ) ; } if ( incoming . get ( 3 ) ) { struct . ase = new org . apache . airavata . model . error . AiravataSystemException ( ) ; struct . ase . read ( iprot ) ; struct . setAseIsSet ( true ) ; } if ( incoming . get ( 4 ) ) { struct . ae = new org . apache . airavata . model . error . AuthorizationException ( ) ; struct . ae . read ( iprot ) ; struct . setAeIsSet ( true ) ; } }",Smelly
 void pollFor ( Duration duration ) ;,No
" public void read ( org . apache . thrift . protocol . TProtocol prot , getChildDataProducts_result struct ) throws org . apache . thrift . TException { TTupleProtocol iprot = ( TTupleProtocol ) prot ; BitSet incoming = iprot . readBitSet ( 5 ) ; if ( incoming . get ( 0 ) ) { { org . apache . thrift . protocol . TList _list283 = new org . apache . thrift . protocol . TList ( org . apache . thrift . protocol . TType . STRUCT , iprot . readI32 ( ) ) ; struct . success = new ArrayList < org . apache . airavata . model . data . replica . DataProductModel > ( _list283 . size ) ; org . apache . airavata . model . data . replica . DataProductModel _elem284 ; for ( int _i285 = 0 ; _i285 < _list283 . size ; ++ _i285 ) { _elem284 = new org . apache . airavata . model . data . replica . DataProductModel ( ) ; _elem284 . read ( iprot ) ; struct . success . add ( _elem284 ) ; } } struct . setSuccessIsSet ( true ) ; } if ( incoming . get ( 1 ) ) { struct . ire = new org . apache . airavata . model . error . InvalidRequestException ( ) ; struct . ire . read ( iprot ) ; struct . setIreIsSet ( true ) ; } if ( incoming . get ( 2 ) ) { struct . ace = new org . apache . airavata . model . error . AiravataClientException ( ) ; struct . ace . read ( iprot ) ; struct . setAceIsSet ( true ) ; } if ( incoming . get ( 3 ) ) { struct . ase = new org . apache . airavata . model . error . AiravataSystemException ( ) ; struct . ase . read ( iprot ) ; struct . setAseIsSet ( true ) ; } if ( incoming . get ( 4 ) ) { struct . ae = new org . apache . airavata . model . error . AuthorizationException ( ) ; struct . ae . read ( iprot ) ; struct . setAeIsSet ( true ) ; } }",Smelly
" public void setAttribute ( Attribute attribute ) throws AttributeNotFoundException , MBeanException , ReflectionException { if ( attribute == null ) throw new RuntimeOperationsException ( new IllegalArgumentException ( ""Attribute is null"" ) , ""Attribute is null"" ) ; String name = attribute . getName ( ) ; Object value = attribute . getValue ( ) ; if ( name == null ) throw new RuntimeOperationsException ( new IllegalArgumentException ( ""Attribute name is null"" ) , ""Attribute name is null"" ) ; ContextResource cr = null ; try { cr = ( ContextResource ) getManagedResource ( ) ; } catch ( InstanceNotFoundException e ) { throw new MBeanException ( e ) ; } catch ( InvalidTargetObjectTypeException e ) { throw new MBeanException ( e ) ; } if ( ""auth"" . equals ( name ) ) { cr . setAuth ( ( String ) value ) ; } else if ( ""description"" . equals ( name ) ) { cr . setDescription ( ( String ) value ) ; } else if ( ""name"" . equals ( name ) ) { cr . setName ( ( String ) value ) ; } else if ( ""scope"" . equals ( name ) ) { cr . setScope ( ( String ) value ) ; } else if ( ""type"" . equals ( name ) ) { cr . setType ( ( String ) value ) ; } else { cr . setProperty ( name , """" + value ) ; } NamingResources nr = cr . getNamingResources ( ) ; nr . removeResource ( cr . getName ( ) ) ; nr . addResource ( cr ) ; }",No
" public void read ( org . apache . thrift . protocol . TProtocol prot , Database struct ) throws org . apache . thrift . TException { TTupleProtocol iprot = ( TTupleProtocol ) prot ; BitSet incoming = iprot . readBitSet ( 7 ) ; if ( incoming . get ( 0 ) ) { struct . name = iprot . readString ( ) ; struct . setNameIsSet ( true ) ; } if ( incoming . get ( 1 ) ) { struct . description = iprot . readString ( ) ; struct . setDescriptionIsSet ( true ) ; } if ( incoming . get ( 2 ) ) { struct . locationUri = iprot . readString ( ) ; struct . setLocationUriIsSet ( true ) ; } if ( incoming . get ( 3 ) ) { { org . apache . thrift . protocol . TMap _map100 = new org . apache . thrift . protocol . TMap ( org . apache . thrift . protocol . TType . STRING , org . apache . thrift . protocol . TType . STRING , iprot . readI32 ( ) ) ; struct . parameters = new HashMap < String , String > ( 2 * _map100 . size ) ; for ( int _i101 = 0 ; _i101 < _map100 . size ; ++ _i101 ) { String _key102 ; String _val103 ; _key102 = iprot . readString ( ) ; _val103 = iprot . readString ( ) ; struct . parameters . put ( _key102 , _val103 ) ; } } struct . setParametersIsSet ( true ) ; } if ( incoming . get ( 4 ) ) { struct . privileges = new PrincipalPrivilegeSet ( ) ; struct . privileges . read ( iprot ) ; struct . setPrivilegesIsSet ( true ) ; } if ( incoming . get ( 5 ) ) { struct . ownerName = iprot . readString ( ) ; struct . setOwnerNameIsSet ( true ) ; } if ( incoming . get ( 6 ) ) { struct . ownerType = PrincipalType . findByValue ( iprot . readI32 ( ) ) ; struct . setOwnerTypeIsSet ( true ) ; } }",Smelly
" protected void doGet ( HttpServletRequest request , HttpServletResponse response ) throws IOException { response . setContentType ( ""text/plain"" ) ; response . getWriter ( ) . write ( request . getRequestURL ( ) . toString ( ) + ""?"" + request . getQueryString ( ) ) ; }",No
" public void testPropertyStoreException ( ) { PropertyStoreException exception = new PropertyStoreException ( ""msg"" ) ; AssertJUnit . assertEquals ( exception . getMessage ( ) , ""msg"" ) ; exception = new PropertyStoreException ( ) ; AssertJUnit . assertNull ( exception . getMessage ( ) ) ; }",No
" public LongWritable evaluate ( LongWritable a , LongWritable b ) { if ( a == null || b == null ) { return null ; } longWritable . set ( a . get ( ) | b . get ( ) ) ; return longWritable ; }",No
" public void read ( org . apache . thrift . protocol . TProtocol prot , checkNamespaceClass_result struct ) throws org . apache . thrift . TException { TTupleProtocol iprot = ( TTupleProtocol ) prot ; BitSet incoming = iprot . readBitSet ( 3 ) ; if ( incoming . get ( 0 ) ) { struct . success = iprot . readBool ( ) ; struct . setSuccessIsSet ( true ) ; } if ( incoming . get ( 1 ) ) { struct . sec = new ThriftSecurityException ( ) ; struct . sec . read ( iprot ) ; struct . setSecIsSet ( true ) ; } if ( incoming . get ( 2 ) ) { struct . tope = new ThriftTableOperationException ( ) ; struct . tope . read ( iprot ) ; struct . setTopeIsSet ( true ) ; } }",Smelly
" public void visit ( State state , Environment env , Properties props ) throws Exception { Connector conn = env . getInstance ( ) . getConnector ( WalkingSecurity . get ( state , env ) . getTabUserName ( ) , WalkingSecurity . get ( state , env ) . getTabToken ( ) ) ; String action = props . getProperty ( ""action"" , ""_random"" ) ; TablePermission tp ; if ( ""_random"" . equalsIgnoreCase ( action ) ) { Random r = new Random ( ) ; tp = TablePermission . values ( ) [ r . nextInt ( TablePermission . values ( ) . length ) ] ; } else { tp = TablePermission . valueOf ( action ) ; } boolean tableExists = WalkingSecurity . get ( state , env ) . getTableExists ( ) ; String tableName = WalkingSecurity . get ( state , env ) . getTableName ( ) ; String namespaceName = WalkingSecurity . get ( state , env ) . getNamespaceName ( ) ; switch ( tp ) { case READ : { boolean canRead = WalkingSecurity . get ( state , env ) . canScan ( WalkingSecurity . get ( state , env ) . getTabCredentials ( ) , tableName , namespaceName ) ; Authorizations auths = WalkingSecurity . get ( state , env ) . getUserAuthorizations ( WalkingSecurity . get ( state , env ) . getTabCredentials ( ) ) ; boolean ambiguousZone = WalkingSecurity . get ( state , env ) . inAmbiguousZone ( conn . whoami ( ) , tp ) ; boolean ambiguousAuths = WalkingSecurity . get ( state , env ) . ambiguousAuthorizations ( conn . whoami ( ) ) ; Scanner scan = null ; try { scan = conn . createScanner ( tableName , conn . securityOperations ( ) . getUserAuthorizations ( conn . whoami ( ) ) ) ; int seen = 0 ; Iterator < Entry < Key , Value > > iter = scan . iterator ( ) ; while ( iter . hasNext ( ) ) { Entry < Key , Value > entry = iter . next ( ) ; Key k = entry . getKey ( ) ; seen ++ ; if ( ! auths . contains ( k . getColumnVisibilityData ( ) ) && ! ambiguousAuths ) throw new AccumuloException ( ""Got data I should not be capable of seeing: "" + k + "" table "" + tableName ) ; } if ( ! canRead && ! ambiguousZone ) throw new AccumuloException ( ""Was able to read when I shouldn't have had the perm with connection user "" + conn . whoami ( ) + "" table "" + tableName ) ; for ( Entry < String , Integer > entry : WalkingSecurity . get ( state , env ) . getAuthsMap ( ) . entrySet ( ) ) { if ( auths . contains ( entry . getKey ( ) . getBytes ( UTF_8 ) ) ) seen = seen - entry . getValue ( ) ; } if ( seen != 0 && ! ambiguousAuths ) throw new AccumuloException ( ""Got mismatched amounts of data"" ) ; } catch ( TableNotFoundException tnfe ) { if ( tableExists ) throw new AccumuloException ( ""Accumulo and test suite out of sync: table "" + tableName , tnfe ) ; return ; } catch ( AccumuloSecurityException ae ) { if ( ae . getSecurityErrorCode ( ) . equals ( SecurityErrorCode . PERMISSION_DENIED ) ) { if ( canRead && ! ambiguousZone ) throw new AccumuloException ( ""Table read permission out of sync with Accumulo: table "" + tableName , ae ) ; else return ; } if ( ae . getSecurityErrorCode ( ) . equals ( SecurityErrorCode . BAD_AUTHORIZATIONS ) ) { if ( ambiguousAuths ) return ; else throw new AccumuloException ( ""Mismatched authorizations! "" , ae ) ; } throw new AccumuloException ( ""Unexpected exception!"" , ae ) ; } catch ( RuntimeException re ) { if ( re . getCause ( ) instanceof AccumuloSecurityException && ( ( AccumuloSecurityException ) re . getCause ( ) ) . getSecurityErrorCode ( ) . equals ( SecurityErrorCode . PERMISSION_DENIED ) ) { if ( canRead && ! ambiguousZone ) throw new AccumuloException ( ""Table read permission out of sync with Accumulo: table "" + tableName , re . getCause ( ) ) ; else return ; } if ( re . getCause ( ) instanceof AccumuloSecurityException && ( ( AccumuloSecurityException ) re . getCause ( ) ) . getSecurityErrorCode ( ) . equals ( SecurityErrorCode . BAD_AUTHORIZATIONS ) ) { if ( ambiguousAuths ) return ; else throw new AccumuloException ( ""Mismatched authorizations! "" , re . getCause ( ) ) ; } throw new AccumuloException ( ""Unexpected exception!"" , re ) ; } finally { if ( scan != null ) { scan . close ( ) ; scan = null ; } } break ; } case WRITE : boolean canWrite = WalkingSecurity . get ( state , env ) . canWrite ( WalkingSecurity . get ( state , env ) . getTabCredentials ( ) , tableName , namespaceName ) ; boolean ambiguousZone = WalkingSecurity . get ( state , env ) . inAmbiguousZone ( conn . whoami ( ) , tp ) ; String key = WalkingSecurity . get ( state , env ) . getLastKey ( ) + ""1"" ; Mutation m = new Mutation ( new Text ( key ) ) ; for ( String s : WalkingSecurity . get ( state , env ) . getAuthsArray ( ) ) { m . put ( new Text ( ) , new Text ( ) , new ColumnVisibility ( s ) , new Value ( ""value"" . getBytes ( UTF_8 ) ) ) ; } BatchWriter writer = null ; try { try { writer = conn . createBatchWriter ( tableName , new BatchWriterConfig ( ) . setMaxMemory ( 9000l ) . setMaxWriteThreads ( 1 ) ) ; } catch ( TableNotFoundException tnfe ) { if ( tableExists ) throw new AccumuloException ( ""Table didn't exist when it should have: "" + tableName ) ; return ; } boolean works = true ; try { writer . addMutation ( m ) ; writer . close ( ) ; } catch ( MutationsRejectedException mre ) { if ( ! canWrite ) return ; if ( ambiguousZone ) { Thread . sleep ( 1000 ) ; try { writer = conn . createBatchWriter ( tableName , new BatchWriterConfig ( ) . setMaxWriteThreads ( 1 ) ) ; writer . addMutation ( m ) ; writer . close ( ) ; writer = null ; } catch ( MutationsRejectedException mre2 ) { throw new AccumuloException ( ""Mutation exception!"" , mre2 ) ; } } } if ( works ) for ( String s : WalkingSecurity . get ( state , env ) . getAuthsArray ( ) ) WalkingSecurity . get ( state , env ) . increaseAuthMap ( s , 1 ) ; } finally { if ( writer != null ) { writer . close ( ) ; writer = null ; } } break ; case BULK_IMPORT : key = WalkingSecurity . get ( state , env ) . getLastKey ( ) + ""1"" ; SortedSet < Key > keys = new TreeSet < > ( ) ; for ( String s : WalkingSecurity . get ( state , env ) . getAuthsArray ( ) ) { Key k = new Key ( key , """" , """" , s ) ; keys . add ( k ) ; } Path dir = new Path ( ""/tmp"" , ""bulk_"" + UUID . randomUUID ( ) . toString ( ) ) ; Path fail = new Path ( dir . toString ( ) + ""_fail"" ) ; FileSystem fs = WalkingSecurity . get ( state , env ) . getFs ( ) ; FileSKVWriter f = FileOperations . getInstance ( ) . openWriter ( dir + ""/securityBulk."" + RFile . EXTENSION , fs , fs . getConf ( ) , AccumuloConfiguration . getDefaultConfiguration ( ) ) ; f . startDefaultLocalityGroup ( ) ; fs . mkdirs ( fail ) ; for ( Key k : keys ) f . append ( k , new Value ( ""Value"" . getBytes ( UTF_8 ) ) ) ; f . close ( ) ; try { conn . tableOperations ( ) . importDirectory ( tableName , dir . toString ( ) , fail . toString ( ) , true ) ; } catch ( TableNotFoundException tnfe ) { if ( tableExists ) throw new AccumuloException ( ""Table didn't exist when it should have: "" + tableName ) ; return ; } catch ( AccumuloSecurityException ae ) { if ( ae . getSecurityErrorCode ( ) . equals ( SecurityErrorCode . PERMISSION_DENIED ) ) { if ( WalkingSecurity . get ( state , env ) . canBulkImport ( WalkingSecurity . get ( state , env ) . getTabCredentials ( ) , tableName , namespaceName ) ) throw new AccumuloException ( ""Bulk Import failed when it should have worked: "" + tableName ) ; return ; } else if ( ae . getSecurityErrorCode ( ) . equals ( SecurityErrorCode . BAD_CREDENTIALS ) ) { if ( WalkingSecurity . get ( state , env ) . userPassTransient ( conn . whoami ( ) ) ) return ; } throw new AccumuloException ( ""Unexpected exception!"" , ae ) ; } for ( String s : WalkingSecurity . get ( state , env ) . getAuthsArray ( ) ) WalkingSecurity . get ( state , env ) . increaseAuthMap ( s , 1 ) ; fs . delete ( dir , true ) ; fs . delete ( fail , true ) ; if ( ! WalkingSecurity . get ( state , env ) . canBulkImport ( WalkingSecurity . get ( state , env ) . getTabCredentials ( ) , tableName , namespaceName ) ) throw new AccumuloException ( ""Bulk Import succeeded when it should have failed: "" + dir + "" table "" + tableName ) ; break ; case ALTER_TABLE : AlterTable . renameTable ( conn , state , env , tableName , tableName + ""plus"" , WalkingSecurity . get ( state , env ) . canAlterTable ( WalkingSecurity . get ( state , env ) . getTabCredentials ( ) , tableName , namespaceName ) , tableExists ) ; break ; case GRANT : props . setProperty ( ""task"" , ""grant"" ) ; props . setProperty ( ""perm"" , ""random"" ) ; props . setProperty ( ""source"" , ""table"" ) ; props . setProperty ( ""target"" , ""system"" ) ; AlterTablePerm . alter ( state , env , props ) ; break ; case DROP_TABLE : props . setProperty ( ""source"" , ""table"" ) ; DropTable . dropTable ( state , env , props ) ; break ; } }",Smelly
 public boolean accept ( final FileSelectInfo fileInfo ) throws FileSystemException { return fileInfo . getFile ( ) . getType ( ) == FileType . FILE ; },No
" public void read ( org . apache . thrift . protocol . TProtocol prot , getActiveLogs_result struct ) throws org . apache . thrift . TException { TTupleProtocol iprot = ( TTupleProtocol ) prot ; BitSet incoming = iprot . readBitSet ( 1 ) ; if ( incoming . get ( 0 ) ) { { org . apache . thrift . protocol . TList _list327 = new org . apache . thrift . protocol . TList ( org . apache . thrift . protocol . TType . STRING , iprot . readI32 ( ) ) ; struct . success = new ArrayList < String > ( _list327 . size ) ; for ( int _i328 = 0 ; _i328 < _list327 . size ; ++ _i328 ) { String _elem329 ; _elem329 = iprot . readString ( ) ; struct . success . add ( _elem329 ) ; } } struct . setSuccessIsSet ( true ) ; } }",Smelly
" public void run ( ) { try { IThreadContext threadContext = ThreadContextFactory . make ( ) ; IRepositoryConnectionManager mgr = RepositoryConnectionManagerFactory . make ( threadContext ) ; IJobManager jobManager = JobManagerFactory . make ( threadContext ) ; Logging . threads . debug ( ""Set priority thread coming up"" ) ; HashMap jobDescriptionMap = new HashMap ( ) ; HashMap connectionMap = new HashMap ( ) ; while ( true ) { try { if ( Thread . currentThread ( ) . isInterrupted ( ) ) throw new ManifoldCFException ( ""Interrupted"" , ManifoldCFException . INTERRUPTED ) ; Logging . threads . debug ( ""Set priority thread woke up"" ) ; long currentTime = System . currentTimeMillis ( ) ; jobDescriptionMap . clear ( ) ; connectionMap . clear ( ) ; int processedCount = 0 ; while ( true ) { if ( Thread . currentThread ( ) . isInterrupted ( ) ) throw new ManifoldCFException ( ""Interrupted"" , ManifoldCFException . INTERRUPTED ) ; if ( processedCount >= cycleCount ) { Logging . threads . debug ( ""Done reprioritizing because exceeded cycle count"" ) ; break ; } DocumentDescription desc = blockingDocuments . getBlockingDocument ( ) ; if ( desc != null ) { ManifoldCF . writeDocumentPriorities ( threadContext , mgr , jobManager , new DocumentDescription [ ] { desc } , connectionMap , jobDescriptionMap , queueTracker , currentTime ) ; processedCount ++ ; continue ; } Logging . threads . debug ( ""Done reprioritizing because no more documents to reprioritize"" ) ; ManifoldCF . sleep ( 30000L ) ; break ; } } catch ( ManifoldCFException e ) { if ( e . getErrorCode ( ) == ManifoldCFException . INTERRUPTED ) break ; if ( e . getErrorCode ( ) == ManifoldCFException . DATABASE_CONNECTION_ERROR ) { Logging . threads . error ( ""Set priority thread aborting and restarting due to database connection reset: "" + e . getMessage ( ) , e ) ; try { ManifoldCF . sleep ( 10000L ) ; } catch ( InterruptedException se ) { break ; } continue ; } Logging . threads . error ( ""Exception tossed: "" + e . getMessage ( ) , e ) ; if ( e . getErrorCode ( ) == ManifoldCFException . SETUP_ERROR ) { System . exit ( 1 ) ; } } catch ( InterruptedException e ) { break ; } catch ( OutOfMemoryError e ) { System . err . println ( ""agents process ran out of memory - shutting down"" ) ; e . printStackTrace ( System . err ) ; System . exit ( - 200 ) ; } catch ( Throwable e ) { Logging . threads . fatal ( ""Error tossed: "" + e . getMessage ( ) , e ) ; } } } catch ( Throwable e ) { System . err . println ( ""agents process could not start - shutting down"" ) ; Logging . threads . fatal ( ""SetPriorityThread initialization error tossed: "" + e . getMessage ( ) , e ) ; System . exit ( - 300 ) ; } }",Smelly
" public void read ( org . apache . thrift . protocol . TProtocol prot , show_compact_result struct ) throws org . apache . thrift . TException { TTupleProtocol iprot = ( TTupleProtocol ) prot ; BitSet incoming = iprot . readBitSet ( 1 ) ; if ( incoming . get ( 0 ) ) { struct . success = new ShowCompactResponse ( ) ; struct . success . read ( iprot ) ; struct . setSuccessIsSet ( true ) ; } }",Smelly
" public void read ( org . apache . thrift . protocol . TProtocol prot , show_compact_result struct ) throws org . apache . thrift . TException { TTupleProtocol iprot = ( TTupleProtocol ) prot ; BitSet incoming = iprot . readBitSet ( 1 ) ; if ( incoming . get ( 0 ) ) { struct . success = new ShowCompactResponse ( ) ; struct . success . read ( iprot ) ; struct . setSuccessIsSet ( true ) ; } }",Smelly
" void allowingPublishingConfigurationToReturn ( final String value ) { context . checking ( new Expectations ( ) { { allowing ( mockConfiguration ) . getString ( ""isis.services.publish.actions"" ) ; will ( returnValue ( value ) ) ; } } ) ; }",No
" public void read ( org . apache . thrift . protocol . TProtocol prot , getFollowing_result struct ) throws org . apache . thrift . TException { TTupleProtocol iprot = ( TTupleProtocol ) prot ; BitSet incoming = iprot . readBitSet ( 1 ) ; if ( incoming . get ( 0 ) ) { struct . success = new Key ( ) ; struct . success . read ( iprot ) ; struct . setSuccessIsSet ( true ) ; } }",Smelly
" public void read ( org . apache . thrift . protocol . TProtocol prot , show_compact_result struct ) throws org . apache . thrift . TException { TTupleProtocol iprot = ( TTupleProtocol ) prot ; BitSet incoming = iprot . readBitSet ( 1 ) ; if ( incoming . get ( 0 ) ) { struct . success = new ShowCompactResponse ( ) ; struct . success . read ( iprot ) ; struct . setSuccessIsSet ( true ) ; } }",Smelly
" public void read ( org . apache . thrift . protocol . TProtocol prot , show_compact_result struct ) throws org . apache . thrift . TException { TTupleProtocol iprot = ( TTupleProtocol ) prot ; BitSet incoming = iprot . readBitSet ( 1 ) ; if ( incoming . get ( 0 ) ) { struct . success = new ShowCompactResponse ( ) ; struct . success . read ( iprot ) ; struct . setSuccessIsSet ( true ) ; } }",Smelly
 private static < S extends org . apache . thrift . scheme . IScheme > S scheme ( org . apache . thrift . protocol . TProtocol proto ) { return ( org . apache . thrift . scheme . StandardScheme . class . equals ( proto . getScheme ( ) ) ? STANDARD_SCHEME_FACTORY : TUPLE_SCHEME_FACTORY ) . getScheme ( ) ; },No
 public abstract SqlNode copy ( ) ;,No
 String runCommand ( String [ ] command ) throws IOException ;,No
 public int hashCode ( ) { int result = option . hashCode ( ) ; result = 31 * result + value . hashCode ( ) ; result = 31 * result + separator . hashCode ( ) ; return result ; },No
 PCollection < OutputT > expand ( PCollectionList < InputT > inputs ) ;,No
 private static < S extends org . apache . thrift . scheme . IScheme > S scheme ( org . apache . thrift . protocol . TProtocol proto ) { return ( org . apache . thrift . scheme . StandardScheme . class . equals ( proto . getScheme ( ) ) ? STANDARD_SCHEME_FACTORY : TUPLE_SCHEME_FACTORY ) . getScheme ( ) ; },Smelly
" public void read ( org . apache . thrift . protocol . TProtocol prot , getFollowing_result struct ) throws org . apache . thrift . TException { TTupleProtocol iprot = ( TTupleProtocol ) prot ; BitSet incoming = iprot . readBitSet ( 1 ) ; if ( incoming . get ( 0 ) ) { struct . success = new Key ( ) ; struct . success . read ( iprot ) ; struct . setSuccessIsSet ( true ) ; } }",Smelly
" public void read ( org . apache . thrift . protocol . TProtocol prot , getFollowing_result struct ) throws org . apache . thrift . TException { TTupleProtocol iprot = ( TTupleProtocol ) prot ; BitSet incoming = iprot . readBitSet ( 1 ) ; if ( incoming . get ( 0 ) ) { struct . success = new Key ( ) ; struct . success . read ( iprot ) ; struct . setSuccessIsSet ( true ) ; } }",Smelly
" protected QName getNodeName ( Node nd ) { return new QName ( nd . getNamespaceURI ( ) , nd . getLocalName ( ) ) ; }",No
 public GSSContext getGSSContext ( ) { return context ; },No
" private static String getAbsolutePath ( String relativePath ) { return new File ( TestDirHelper . getTestDir ( ) , relativePath ) . getAbsolutePath ( ) ; }",No
" public void looseMarshal ( OpenWireFormat wireFormat , Object o , DataOutput dataOut ) throws IOException { Message info = ( Message ) o ; info . beforeMarshall ( wireFormat ) ; super . looseMarshal ( wireFormat , o , dataOut ) ; looseMarshalCachedObject ( wireFormat , ( DataStructure ) info . getProducerId ( ) , dataOut ) ; looseMarshalCachedObject ( wireFormat , ( DataStructure ) info . getDestination ( ) , dataOut ) ; looseMarshalCachedObject ( wireFormat , ( DataStructure ) info . getTransactionId ( ) , dataOut ) ; looseMarshalCachedObject ( wireFormat , ( DataStructure ) info . getOriginalDestination ( ) , dataOut ) ; looseMarshalNestedObject ( wireFormat , ( DataStructure ) info . getMessageId ( ) , dataOut ) ; looseMarshalCachedObject ( wireFormat , ( DataStructure ) info . getOriginalTransactionId ( ) , dataOut ) ; looseMarshalString ( info . getGroupID ( ) , dataOut ) ; dataOut . writeInt ( info . getGroupSequence ( ) ) ; looseMarshalString ( info . getCorrelationId ( ) , dataOut ) ; dataOut . writeBoolean ( info . isPersistent ( ) ) ; looseMarshalLong ( wireFormat , info . getExpiration ( ) , dataOut ) ; dataOut . writeByte ( info . getPriority ( ) ) ; looseMarshalNestedObject ( wireFormat , ( DataStructure ) info . getReplyTo ( ) , dataOut ) ; looseMarshalLong ( wireFormat , info . getTimestamp ( ) , dataOut ) ; looseMarshalString ( info . getType ( ) , dataOut ) ; looseMarshalByteSequence ( wireFormat , info . getContent ( ) , dataOut ) ; looseMarshalByteSequence ( wireFormat , info . getMarshalledProperties ( ) , dataOut ) ; looseMarshalNestedObject ( wireFormat , ( DataStructure ) info . getDataStructure ( ) , dataOut ) ; looseMarshalCachedObject ( wireFormat , ( DataStructure ) info . getTargetConsumerId ( ) , dataOut ) ; dataOut . writeBoolean ( info . isCompressed ( ) ) ; dataOut . writeInt ( info . getRedeliveryCounter ( ) ) ; looseMarshalObjectArray ( wireFormat , info . getBrokerPath ( ) , dataOut ) ; looseMarshalLong ( wireFormat , info . getArrival ( ) , dataOut ) ; looseMarshalString ( info . getUserID ( ) , dataOut ) ; dataOut . writeBoolean ( info . isRecievedByDFBridge ( ) ) ; dataOut . writeBoolean ( info . isDroppable ( ) ) ; looseMarshalObjectArray ( wireFormat , info . getCluster ( ) , dataOut ) ; looseMarshalLong ( wireFormat , info . getBrokerInTime ( ) , dataOut ) ; looseMarshalLong ( wireFormat , info . getBrokerOutTime ( ) , dataOut ) ; }",Smelly
 protected void init ( final ProcessorInitializationContext context ) { },No
" public void read ( org . apache . thrift . protocol . TProtocol prot , Key struct ) throws org . apache . thrift . TException { TTupleProtocol iprot = ( TTupleProtocol ) prot ; BitSet incoming = iprot . readBitSet ( 5 ) ; if ( incoming . get ( 0 ) ) { struct . row = iprot . readBinary ( ) ; struct . setRowIsSet ( true ) ; } if ( incoming . get ( 1 ) ) { struct . colFamily = iprot . readBinary ( ) ; struct . setColFamilyIsSet ( true ) ; } if ( incoming . get ( 2 ) ) { struct . colQualifier = iprot . readBinary ( ) ; struct . setColQualifierIsSet ( true ) ; } if ( incoming . get ( 3 ) ) { struct . colVisibility = iprot . readBinary ( ) ; struct . setColVisibilityIsSet ( true ) ; } if ( incoming . get ( 4 ) ) { struct . timestamp = iprot . readI64 ( ) ; struct . setTimestampIsSet ( true ) ; } }",Smelly
" public void read ( org . apache . thrift . protocol . TProtocol prot , getChildDataProducts_result struct ) throws org . apache . thrift . TException { TTupleProtocol iprot = ( TTupleProtocol ) prot ; BitSet incoming = iprot . readBitSet ( 5 ) ; if ( incoming . get ( 0 ) ) { { org . apache . thrift . protocol . TList _list283 = new org . apache . thrift . protocol . TList ( org . apache . thrift . protocol . TType . STRUCT , iprot . readI32 ( ) ) ; struct . success = new ArrayList < org . apache . airavata . model . data . replica . DataProductModel > ( _list283 . size ) ; org . apache . airavata . model . data . replica . DataProductModel _elem284 ; for ( int _i285 = 0 ; _i285 < _list283 . size ; ++ _i285 ) { _elem284 = new org . apache . airavata . model . data . replica . DataProductModel ( ) ; _elem284 . read ( iprot ) ; struct . success . add ( _elem284 ) ; } } struct . setSuccessIsSet ( true ) ; } if ( incoming . get ( 1 ) ) { struct . ire = new org . apache . airavata . model . error . InvalidRequestException ( ) ; struct . ire . read ( iprot ) ; struct . setIreIsSet ( true ) ; } if ( incoming . get ( 2 ) ) { struct . ace = new org . apache . airavata . model . error . AiravataClientException ( ) ; struct . ace . read ( iprot ) ; struct . setAceIsSet ( true ) ; } if ( incoming . get ( 3 ) ) { struct . ase = new org . apache . airavata . model . error . AiravataSystemException ( ) ; struct . ase . read ( iprot ) ; struct . setAseIsSet ( true ) ; } if ( incoming . get ( 4 ) ) { struct . ae = new org . apache . airavata . model . error . AuthorizationException ( ) ; struct . ae . read ( iprot ) ; struct . setAeIsSet ( true ) ; } }",Smelly
" public void testWritePartialUpdate ( ) throws Exception { ElasticSearchIOTestUtils . copyIndex ( restClient , readConnectionConfiguration . getIndex ( ) , updateConnectionConfiguration . getIndex ( ) ) ; ElasticsearchIOTestCommon elasticsearchIOTestCommonUpdate = new ElasticsearchIOTestCommon ( updateConnectionConfiguration , restClient , true ) ; elasticsearchIOTestCommonUpdate . setPipeline ( pipeline ) ; elasticsearchIOTestCommonUpdate . testWritePartialUpdate ( ) ; }",No
" protected void assertActivation ( boolean active , Profile profile , ProfileActivationContext context ) { SimpleProblemCollector problems = new SimpleProblemCollector ( ) ; assertEquals ( active , activator . isActive ( profile , context , problems ) ) ; assertEquals ( problems . getErrors ( ) . toString ( ) , 0 , problems . getErrors ( ) . size ( ) ) ; assertEquals ( problems . getWarnings ( ) . toString ( ) , 0 , problems . getWarnings ( ) . size ( ) ) ; }",No
" public int compare ( Object o1 , Object o2 ) { String oid1 = """" ; String oid2 = """" ; if ( ( o1 instanceof AttributeTypeDifference ) && ( o2 instanceof AttributeTypeDifference ) ) { AttributeTypeDifference atd1 = ( AttributeTypeDifference ) o1 ; AttributeTypeDifference atd2 = ( AttributeTypeDifference ) o2 ; switch ( atd1 . getType ( ) ) { case ADDED : oid1 = ( ( SchemaObject ) atd1 . getDestination ( ) ) . getOid ( ) ; break ; case MODIFIED : oid1 = ( ( SchemaObject ) atd1 . getDestination ( ) ) . getOid ( ) ; break ; case REMOVED : oid1 = ( ( SchemaObject ) atd1 . getSource ( ) ) . getOid ( ) ; break ; case IDENTICAL : oid1 = ( ( SchemaObject ) atd1 . getDestination ( ) ) . getOid ( ) ; break ; } switch ( atd2 . getType ( ) ) { case ADDED : oid2 = ( ( SchemaObject ) atd2 . getDestination ( ) ) . getOid ( ) ; break ; case MODIFIED : oid2 = ( ( SchemaObject ) atd2 . getDestination ( ) ) . getOid ( ) ; break ; case REMOVED : oid2 = ( ( SchemaObject ) atd2 . getSource ( ) ) . getOid ( ) ; break ; case IDENTICAL : oid2 = ( ( SchemaObject ) atd2 . getDestination ( ) ) . getOid ( ) ; break ; } } else if ( ( o1 instanceof ObjectClassDifference ) && ( o2 instanceof ObjectClassDifference ) ) { ObjectClassDifference ocd1 = ( ObjectClassDifference ) o1 ; ObjectClassDifference ocd2 = ( ObjectClassDifference ) o2 ; switch ( ocd1 . getType ( ) ) { case ADDED : oid1 = ( ( SchemaObject ) ocd1 . getDestination ( ) ) . getOid ( ) ; break ; case MODIFIED : oid1 = ( ( SchemaObject ) ocd1 . getDestination ( ) ) . getOid ( ) ; break ; case REMOVED : oid1 = ( ( SchemaObject ) ocd1 . getSource ( ) ) . getOid ( ) ; break ; case IDENTICAL : oid1 = ( ( SchemaObject ) ocd1 . getDestination ( ) ) . getOid ( ) ; break ; } switch ( ocd2 . getType ( ) ) { case ADDED : oid2 = ( ( SchemaObject ) ocd2 . getDestination ( ) ) . getOid ( ) ; break ; case MODIFIED : oid2 = ( ( SchemaObject ) ocd2 . getDestination ( ) ) . getOid ( ) ; break ; case REMOVED : oid2 = ( ( SchemaObject ) ocd2 . getSource ( ) ) . getOid ( ) ; break ; case IDENTICAL : oid2 = ( ( SchemaObject ) ocd2 . getDestination ( ) ) . getOid ( ) ; break ; } } else if ( ( o1 instanceof AttributeTypeDifference ) && ( o2 instanceof ObjectClassDifference ) ) { AttributeTypeDifference atd = ( AttributeTypeDifference ) o1 ; ObjectClassDifference ocd = ( ObjectClassDifference ) o2 ; switch ( atd . getType ( ) ) { case ADDED : oid1 = ( ( SchemaObject ) atd . getDestination ( ) ) . getOid ( ) ; break ; case MODIFIED : oid1 = ( ( SchemaObject ) atd . getDestination ( ) ) . getOid ( ) ; break ; case REMOVED : oid1 = ( ( SchemaObject ) atd . getSource ( ) ) . getOid ( ) ; break ; case IDENTICAL : oid1 = ( ( SchemaObject ) atd . getDestination ( ) ) . getOid ( ) ; break ; } switch ( ocd . getType ( ) ) { case ADDED : oid2 = ( ( SchemaObject ) ocd . getDestination ( ) ) . getOid ( ) ; break ; case MODIFIED : oid2 = ( ( SchemaObject ) ocd . getDestination ( ) ) . getOid ( ) ; break ; case REMOVED : oid2 = ( ( SchemaObject ) ocd . getSource ( ) ) . getOid ( ) ; break ; case IDENTICAL : oid2 = ( ( SchemaObject ) ocd . getDestination ( ) ) . getOid ( ) ; break ; } } else if ( ( o1 instanceof ObjectClassDifference ) && ( o2 instanceof AttributeTypeDifference ) ) { ObjectClassDifference ocd = ( ObjectClassDifference ) o1 ; AttributeTypeDifference atd = ( AttributeTypeDifference ) o2 ; switch ( ocd . getType ( ) ) { case ADDED : oid1 = ( ( SchemaObject ) ocd . getDestination ( ) ) . getOid ( ) ; break ; case MODIFIED : oid1 = ( ( SchemaObject ) ocd . getDestination ( ) ) . getOid ( ) ; break ; case REMOVED : oid1 = ( ( SchemaObject ) ocd . getSource ( ) ) . getOid ( ) ; break ; case IDENTICAL : oid1 = ( ( SchemaObject ) ocd . getDestination ( ) ) . getOid ( ) ; break ; } switch ( atd . getType ( ) ) { case ADDED : oid2 = ( ( SchemaObject ) atd . getDestination ( ) ) . getOid ( ) ; break ; case MODIFIED : oid2 = ( ( SchemaObject ) atd . getDestination ( ) ) . getOid ( ) ; break ; case REMOVED : oid2 = ( ( SchemaObject ) atd . getSource ( ) ) . getOid ( ) ; break ; case IDENTICAL : oid2 = ( ( SchemaObject ) atd . getDestination ( ) ) . getOid ( ) ; break ; } } return oid1 . compareToIgnoreCase ( oid2 ) ; }",Smelly
" public void read ( org . apache . thrift . protocol . TProtocol prot , deletePWDCredential_result struct ) throws org . apache . thrift . TException { TTupleProtocol iprot = ( TTupleProtocol ) prot ; BitSet incoming = iprot . readBitSet ( 2 ) ; if ( incoming . get ( 0 ) ) { struct . success = iprot . readBool ( ) ; struct . setSuccessIsSet ( true ) ; } if ( incoming . get ( 1 ) ) { struct . csException = new org . apache . airavata . credential . store . exception . CredentialStoreException ( ) ; struct . csException . read ( iprot ) ; struct . setCsExceptionIsSet ( true ) ; } }",Smelly
" public void read ( org . apache . thrift . protocol . TProtocol prot , getFollowing_result struct ) throws org . apache . thrift . TException { TTupleProtocol iprot = ( TTupleProtocol ) prot ; BitSet incoming = iprot . readBitSet ( 1 ) ; if ( incoming . get ( 0 ) ) { struct . success = new Key ( ) ; struct . success . read ( iprot ) ; struct . setSuccessIsSet ( true ) ; } }",Smelly
" public void read ( org . apache . thrift . protocol . TProtocol prot , getActiveLogs_result struct ) throws org . apache . thrift . TException { TTupleProtocol iprot = ( TTupleProtocol ) prot ; BitSet incoming = iprot . readBitSet ( 1 ) ; if ( incoming . get ( 0 ) ) { { org . apache . thrift . protocol . TList _list327 = new org . apache . thrift . protocol . TList ( org . apache . thrift . protocol . TType . STRING , iprot . readI32 ( ) ) ; struct . success = new ArrayList < String > ( _list327 . size ) ; for ( int _i328 = 0 ; _i328 < _list327 . size ; ++ _i328 ) { String _elem329 ; _elem329 = iprot . readString ( ) ; struct . success . add ( _elem329 ) ; } } struct . setSuccessIsSet ( true ) ; } }",Smelly
" protected void handle ( Message message ) { AssertionInfoMap aim = message . get ( AssertionInfoMap . class ) ; if ( null == aim ) { return ; } Exchange exchange = message . getExchange ( ) ; BindingOperationInfo boi = exchange . get ( BindingOperationInfo . class ) ; if ( null == boi ) { LOG . fine ( ""No binding operation info."" ) ; return ; } Endpoint e = exchange . get ( Endpoint . class ) ; if ( null == e ) { LOG . fine ( ""No endpoint."" ) ; return ; } EndpointInfo ei = e . getEndpointInfo ( ) ; Bus bus = exchange . get ( Bus . class ) ; PolicyEngine pe = bus . getExtension ( PolicyEngine . class ) ; if ( null == pe ) { return ; } if ( MessageUtils . isPartialResponse ( message ) ) { LOG . fine ( ""Not verifying policies on inbound partial response."" ) ; return ; } getTransportAssertions ( message ) ; EffectivePolicy effectivePolicy = message . get ( EffectivePolicy . class ) ; if ( effectivePolicy == null ) { if ( MessageUtils . isRequestor ( message ) ) { effectivePolicy = pe . getEffectiveClientResponsePolicy ( ei , boi ) ; } else { effectivePolicy = pe . getEffectiveServerRequestPolicy ( ei , boi ) ; } } try { List < List < Assertion > > usedAlternatives = aim . checkEffectivePolicy ( effectivePolicy . getPolicy ( ) ) ; if ( usedAlternatives != null && ! usedAlternatives . isEmpty ( ) && message . getExchange ( ) != null ) { message . getExchange ( ) . put ( ""ws-policy.validated.alternatives"" , usedAlternatives ) ; } } catch ( PolicyException ex ) { if ( ex . getMessage ( ) . indexOf ( ""Addressing"" ) > - 1 ) { throw new Fault ( ""A required header representing a Message Addressing Property "" + ""is not present"" , LOG ) . setFaultCode ( new QName ( ""http://www.w3.org/2005/08/addressing"" , ""MessageAddressingHeaderRequired"" ) ) ; } throw ex ; } LOG . fine ( ""Verified policies for inbound message."" ) ; }",Smelly
" public void read ( org . apache . thrift . protocol . TProtocol prot , ShowLocksResponseElement struct ) throws org . apache . thrift . TException { TTupleProtocol iprot = ( TTupleProtocol ) prot ; struct . lockid = iprot . readI64 ( ) ; struct . setLockidIsSet ( true ) ; struct . dbname = iprot . readString ( ) ; struct . setDbnameIsSet ( true ) ; struct . state = LockState . findByValue ( iprot . readI32 ( ) ) ; struct . setStateIsSet ( true ) ; struct . type = LockType . findByValue ( iprot . readI32 ( ) ) ; struct . setTypeIsSet ( true ) ; struct . lastheartbeat = iprot . readI64 ( ) ; struct . setLastheartbeatIsSet ( true ) ; struct . user = iprot . readString ( ) ; struct . setUserIsSet ( true ) ; struct . hostname = iprot . readString ( ) ; struct . setHostnameIsSet ( true ) ; BitSet incoming = iprot . readBitSet ( 4 ) ; if ( incoming . get ( 0 ) ) { struct . tablename = iprot . readString ( ) ; struct . setTablenameIsSet ( true ) ; } if ( incoming . get ( 1 ) ) { struct . partname = iprot . readString ( ) ; struct . setPartnameIsSet ( true ) ; } if ( incoming . get ( 2 ) ) { struct . txnid = iprot . readI64 ( ) ; struct . setTxnidIsSet ( true ) ; } if ( incoming . get ( 3 ) ) { struct . acquiredat = iprot . readI64 ( ) ; struct . setAcquiredatIsSet ( true ) ; } }",Smelly
" public void read ( org . apache . thrift . protocol . TProtocol prot , getFollowing_result struct ) throws org . apache . thrift . TException { TTupleProtocol iprot = ( TTupleProtocol ) prot ; BitSet incoming = iprot . readBitSet ( 1 ) ; if ( incoming . get ( 0 ) ) { struct . success = new Key ( ) ; struct . success . read ( iprot ) ; struct . setSuccessIsSet ( true ) ; } }",Smelly
" private Field parseField ( ) throws ParsingException , GrammerException { if ( scanner . tokenType ( ) == Attribute || scanner . tokenType ( ) == Bracket_Right ) { return null ; } scanner . mark ( ) ; int acc = 0 ; while ( scanner . tokenType ( ) == AccessFlag ) { acc = acc | Util . getAccessFlag_Field ( scanner . token ( ) ) ; scanner . nextToken ( ) ; } String fieldType = scanner . token ( ) ; scanner . nextToken ( ) ; String fieldName = scanner . token ( ) ; scanner . nextToken ( ) ; String maybeEuqal = scanner . token ( ) ; if ( fieldType . indexOf ( '(' ) != - 1 || fieldName . indexOf ( '(' ) != - 1 || maybeEuqal . indexOf ( '(' ) != - 1 ) { scanner . restore ( ) ; return null ; } ArrayList attributes = new ArrayList ( 3 ) ; fieldType = Util . toInnerType ( fieldType ) ; if ( scanner . tokenType ( ) == Equal ) { scanner . nextToken ( ) ; String constValue = scanner . token ( ) ; int const_index ; Attribute_ConstantValue con = null ; switch ( fieldType . charAt ( 0 ) ) { case 'B' : case 'C' : case 'I' : case 'S' : case 'Z' : const_index = cpl . addInteger ( parseInteger ( constValue ) ) ; con = new Attribute_ConstantValue ( 2 , const_index ) ; break ; case 'D' : const_index = cpl . addDouble ( parseDouble ( constValue ) ) ; con = new Attribute_ConstantValue ( 2 , const_index ) ; break ; case 'F' : const_index = cpl . addFloat ( parseFloat ( constValue ) ) ; con = new Attribute_ConstantValue ( 2 , const_index ) ; break ; case 'J' : const_index = cpl . addLong ( parseLong ( constValue ) ) ; con = new Attribute_ConstantValue ( 2 , const_index ) ; break ; case 'L' : if ( fieldType . equals ( ""Ljava/lang/String;"" ) == true ) { const_index = cpl . addString ( Util . parseViewableString ( constValue . substring ( 1 , constValue . length ( ) - 1 ) ) ) ; con = new Attribute_ConstantValue ( 2 , const_index ) ; break ; } default : exception ( scanner , ""can.not.assign.contant.value.to.this.field.type.only.primitive.types.and.string.allowed"" ) ; } con . attribute_name_index = cpl . addUtf8 ( ""ConstantValue"" ) ; attributes . add ( con ) ; scanner . nextToken ( ) ; } while ( scanner . tokenType ( ) == Attribute ) { attributes . add ( parseAttribute ( ) ) ; } Field ret = new Field ( acc , cpl . addUtf8 ( fieldName ) , cpl . addUtf8 ( fieldType ) , attributes . size ( ) , ( Attribute [ ] ) attributes . toArray ( new Attribute [ attributes . size ( ) ] ) ) ; return ret ; }",Smelly
 public void setIncludeProperties ( boolean includeProperties ) { this . includeProperties = includeProperties ; },Smelly
" public Value toValue ( ExpressionFactory factory , CriteriaQueryImpl < ? > c ) { return factory . getKey ( getParent ( ) . toValue ( factory , c ) ) ; }",No
" public void process ( ClusterEvent event ) throws Exception { Cluster cluster = event . getAttribute ( ""Cluster"" ) ; Map < ResourceId , ResourceConfig > resourceMap = event . getAttribute ( AttributeName . RESOURCES . toString ( ) ) ; if ( cluster == null || resourceMap == null ) { throw new StageException ( ""Missing attributes in event:"" + event + "". Requires Cluster|RESOURCE"" ) ; } ResourceCurrentState currentStateOutput = new ResourceCurrentState ( ) ; for ( Participant liveParticipant : cluster . getLiveParticipantMap ( ) . values ( ) ) { ParticipantId participantId = liveParticipant . getId ( ) ; Map < MessageId , Message > instanceMsgs = liveParticipant . getMessageMap ( ) ; for ( Message message : instanceMsgs . values ( ) ) { if ( ! MessageType . STATE_TRANSITION . toString ( ) . equalsIgnoreCase ( message . getMsgType ( ) ) ) { continue ; } if ( ! liveParticipant . getLiveInstance ( ) . getSessionId ( ) . equals ( message . getTgtSessionId ( ) ) ) { continue ; } ResourceId resourceId = message . getResourceId ( ) ; ResourceConfig resource = resourceMap . get ( resourceId ) ; if ( resource == null ) { continue ; } IdealState idealState = resource . getIdealState ( ) ; if ( ! message . getBatchMessageMode ( ) ) { PartitionId partitionId = message . getPartitionId ( ) ; if ( idealState . getPartitionIdSet ( ) . contains ( partitionId ) ) { currentStateOutput . setPendingState ( resourceId , partitionId , participantId , message . getTypedToState ( ) ) ; } else { } } else { List < PartitionId > partitionNames = message . getPartitionIds ( ) ; if ( ! partitionNames . isEmpty ( ) ) { for ( PartitionId partitionId : partitionNames ) { if ( idealState . getPartitionIdSet ( ) . contains ( partitionId ) ) { currentStateOutput . setPendingState ( resourceId , partitionId , participantId , message . getTypedToState ( ) ) ; } else { } } } } } SessionId sessionId = SessionId . from ( liveParticipant . getLiveInstance ( ) . getSessionId ( ) ) ; Map < ResourceId , CurrentState > curStateMap = liveParticipant . getCurrentStateMap ( ) ; for ( CurrentState curState : curStateMap . values ( ) ) { if ( ! sessionId . equals ( curState . getTypedSessionId ( ) ) ) { continue ; } ResourceId resourceId = curState . getResourceId ( ) ; StateModelDefId stateModelDefId = curState . getStateModelDefId ( ) ; ResourceConfig resource = resourceMap . get ( resourceId ) ; if ( resource == null ) { continue ; } if ( stateModelDefId != null ) { currentStateOutput . setResourceStateModelDef ( resourceId , stateModelDefId ) ; } currentStateOutput . setBucketSize ( resourceId , curState . getBucketSize ( ) ) ; Map < PartitionId , State > partitionStateMap = curState . getTypedPartitionStateMap ( ) ; for ( PartitionId partitionId : partitionStateMap . keySet ( ) ) { currentStateOutput . setCurrentState ( resourceId , partitionId , participantId , curState . getState ( partitionId ) ) ; currentStateOutput . setRequestedState ( resourceId , partitionId , participantId , curState . getRequestedState ( partitionId ) ) ; currentStateOutput . setInfo ( resourceId , partitionId , participantId , curState . getInfo ( partitionId ) ) ; } } } event . addAttribute ( AttributeName . CURRENT_STATE . toString ( ) , currentStateOutput ) ; }",Smelly
" public static void main ( String [ ] args ) { Factory < SecurityManager > factory = new IniSecurityManagerFactory ( ""classpath:shiro.ini"" ) ; SecurityManager securityManager = factory . getInstance ( ) ; SecurityUtils . setSecurityManager ( securityManager ) ; Subject currentUser = SecurityUtils . getSubject ( ) ; Session session = currentUser . getSession ( ) ; session . setAttribute ( ""someKey"" , ""aValue"" ) ; String value = ( String ) session . getAttribute ( ""someKey"" ) ; if ( value . equals ( ""aValue"" ) ) { log . info ( ""Retrieved the correct value! ["" + value + ""]"" ) ; } if ( ! currentUser . isAuthenticated ( ) ) { UsernamePasswordToken token = new UsernamePasswordToken ( ""lonestarr"" , ""vespa"" ) ; token . setRememberMe ( true ) ; try { currentUser . login ( token ) ; } catch ( UnknownAccountException uae ) { log . info ( ""There is no user with username of "" + token . getPrincipal ( ) ) ; } catch ( IncorrectCredentialsException ice ) { log . info ( ""Password for account "" + token . getPrincipal ( ) + "" was incorrect!"" ) ; } catch ( LockedAccountException lae ) { log . info ( ""The account for username "" + token . getPrincipal ( ) + "" is locked.  "" + ""Please contact your administrator to unlock it."" ) ; } catch ( AuthenticationException ae ) { } } log . info ( ""User ["" + currentUser . getPrincipal ( ) + ""] logged in successfully."" ) ; if ( currentUser . hasRole ( ""schwartz"" ) ) { log . info ( ""May the Schwartz be with you!"" ) ; } else { log . info ( ""Hello, mere mortal."" ) ; } if ( currentUser . isPermitted ( ""lightsaber:wield"" ) ) { log . info ( ""You may use a lightsaber ring.  Use it wisely."" ) ; } else { log . info ( ""Sorry, lightsaber rings are for schwartz masters only."" ) ; } if ( currentUser . isPermitted ( ""winnebago:drive:eagle5"" ) ) { log . info ( ""You are permitted to 'drive' the winnebago with license plate (id) 'eagle5'.  "" + ""Here are the keys - have fun!"" ) ; } else { log . info ( ""Sorry, you aren't allowed to drive the 'eagle5' winnebago!"" ) ; } currentUser . logout ( ) ; System . exit ( 0 ) ; }",Smelly
" public void read ( org . apache . thrift . protocol . TProtocol prot , getChildDataProducts_result struct ) throws org . apache . thrift . TException { TTupleProtocol iprot = ( TTupleProtocol ) prot ; BitSet incoming = iprot . readBitSet ( 5 ) ; if ( incoming . get ( 0 ) ) { { org . apache . thrift . protocol . TList _list283 = new org . apache . thrift . protocol . TList ( org . apache . thrift . protocol . TType . STRUCT , iprot . readI32 ( ) ) ; struct . success = new ArrayList < org . apache . airavata . model . data . replica . DataProductModel > ( _list283 . size ) ; org . apache . airavata . model . data . replica . DataProductModel _elem284 ; for ( int _i285 = 0 ; _i285 < _list283 . size ; ++ _i285 ) { _elem284 = new org . apache . airavata . model . data . replica . DataProductModel ( ) ; _elem284 . read ( iprot ) ; struct . success . add ( _elem284 ) ; } } struct . setSuccessIsSet ( true ) ; } if ( incoming . get ( 1 ) ) { struct . ire = new org . apache . airavata . model . error . InvalidRequestException ( ) ; struct . ire . read ( iprot ) ; struct . setIreIsSet ( true ) ; } if ( incoming . get ( 2 ) ) { struct . ace = new org . apache . airavata . model . error . AiravataClientException ( ) ; struct . ace . read ( iprot ) ; struct . setAceIsSet ( true ) ; } if ( incoming . get ( 3 ) ) { struct . ase = new org . apache . airavata . model . error . AiravataSystemException ( ) ; struct . ase . read ( iprot ) ; struct . setAseIsSet ( true ) ; } if ( incoming . get ( 4 ) ) { struct . ae = new org . apache . airavata . model . error . AuthorizationException ( ) ; struct . ae . read ( iprot ) ; struct . setAeIsSet ( true ) ; } }",Smelly
" public void read ( org . apache . thrift . protocol . TProtocol prot , getChildDataProducts_result struct ) throws org . apache . thrift . TException { TTupleProtocol iprot = ( TTupleProtocol ) prot ; BitSet incoming = iprot . readBitSet ( 5 ) ; if ( incoming . get ( 0 ) ) { { org . apache . thrift . protocol . TList _list283 = new org . apache . thrift . protocol . TList ( org . apache . thrift . protocol . TType . STRUCT , iprot . readI32 ( ) ) ; struct . success = new ArrayList < org . apache . airavata . model . data . replica . DataProductModel > ( _list283 . size ) ; org . apache . airavata . model . data . replica . DataProductModel _elem284 ; for ( int _i285 = 0 ; _i285 < _list283 . size ; ++ _i285 ) { _elem284 = new org . apache . airavata . model . data . replica . DataProductModel ( ) ; _elem284 . read ( iprot ) ; struct . success . add ( _elem284 ) ; } } struct . setSuccessIsSet ( true ) ; } if ( incoming . get ( 1 ) ) { struct . ire = new org . apache . airavata . model . error . InvalidRequestException ( ) ; struct . ire . read ( iprot ) ; struct . setIreIsSet ( true ) ; } if ( incoming . get ( 2 ) ) { struct . ace = new org . apache . airavata . model . error . AiravataClientException ( ) ; struct . ace . read ( iprot ) ; struct . setAceIsSet ( true ) ; } if ( incoming . get ( 3 ) ) { struct . ase = new org . apache . airavata . model . error . AiravataSystemException ( ) ; struct . ase . read ( iprot ) ; struct . setAseIsSet ( true ) ; } if ( incoming . get ( 4 ) ) { struct . ae = new org . apache . airavata . model . error . AuthorizationException ( ) ; struct . ae . read ( iprot ) ; struct . setAeIsSet ( true ) ; } }",Smelly
" public void visit ( State state , Environment env , Properties props ) throws Exception { }",No
" public ChaosMonkey build ( ) { Action [ ] actions1 = new Action [ ] { new CompactTableAction ( tableName , 0.5f ) , new CompactRandomRegionOfTableAction ( tableName , 0.6f ) , new FlushTableAction ( tableName ) , new FlushRandomRegionOfTableAction ( tableName ) } ; Action [ ] actions2 = new Action [ ] { new SplitRandomRegionOfTableAction ( tableName ) , new MergeRandomAdjacentRegionsOfTableAction ( tableName ) , new AddColumnAction ( tableName ) , new RemoveColumnAction ( tableName , columnFamilies ) , new MoveRegionsOfTableAction ( MonkeyConstants . DEFAULT_MOVE_REGIONS_SLEEP_TIME , 1600 , tableName ) , new MoveRandomRegionOfTableAction ( MonkeyConstants . DEFAULT_MOVE_RANDOM_REGION_SLEEP_TIME , tableName ) , new RestartRandomRsAction ( MonkeyConstants . DEFAULT_RESTART_RANDOM_RS_SLEEP_TIME ) , new BatchRestartRsAction ( MonkeyConstants . DEFAULT_ROLLING_BATCH_RESTART_RS_SLEEP_TIME , 0.5f ) , new RollingBatchRestartRsAction ( MonkeyConstants . DEFAULT_BATCH_RESTART_RS_SLEEP_TIME , 1.0f ) , new RestartRsHoldingMetaAction ( MonkeyConstants . DEFAULT_RESTART_RS_HOLDING_META_SLEEP_TIME ) , new ChangeSplitPolicyAction ( tableName ) , new SplitAllRegionOfTableAction ( tableName ) , new DecreaseMaxHFileSizeAction ( MonkeyConstants . DEFAULT_DECREASE_HFILE_SIZE_SLEEP_TIME , tableName ) , } ; Action [ ] actions3 = new Action [ ] { new DumpClusterStatusAction ( ) } ; return new PolicyBasedChaosMonkey ( util , new PeriodicRandomActionPolicy ( 90 * 1000 , actions1 ) , new CompositeSequentialPolicy ( new DoActionsOncePolicy ( 90 * 1000 , actions2 ) , new PeriodicRandomActionPolicy ( 90 * 1000 , actions2 ) ) , new PeriodicRandomActionPolicy ( 90 * 1000 , actions3 ) ) ; }",No
 private void itemPermissionSelected ( ) { ItemPermissionWrapper itemPermissionWrapper = getSelectedItemPermissionWrapper ( ) ; if ( itemPermissionWrapper == null ) { editButton . setEnabled ( false ) ; deleteButton . setEnabled ( false ) ; } else { editButton . setEnabled ( true ) ; deleteButton . setEnabled ( true ) ; } },Smelly
" public void read ( org . apache . thrift . protocol . TProtocol prot , show_compact_result struct ) throws org . apache . thrift . TException { TTupleProtocol iprot = ( TTupleProtocol ) prot ; BitSet incoming = iprot . readBitSet ( 1 ) ; if ( incoming . get ( 0 ) ) { struct . success = new ShowCompactResponse ( ) ; struct . success . read ( iprot ) ; struct . setSuccessIsSet ( true ) ; } }",Smelly
" private static void assertNext ( Iterator < ImageResourceCacheKey > iterator , Class < ? > resourceClass , String resourceName ) { assertThat ( iterator . hasNext ( ) , is ( true ) ) ; final ImageResourceCacheKey next = iterator . next ( ) ; assertEquals ( resourceClass , next . getResourceClass ( ) ) ; assertEquals ( resourceName , next . getResourceName ( ) ) ; }",Smelly
" protected ByteSequence looseUnmarshalByteSequence ( DataInput dataIn ) throws IOException { ByteSequence rc = null ; if ( dataIn . readBoolean ( ) ) { int size = dataIn . readInt ( ) ; byte [ ] t = new byte [ size ] ; dataIn . readFully ( t ) ; rc = new ByteSequence ( t , 0 , size ) ; } return rc ; }",No
 private boolean isFiltered ( Object [ ] args ) { return args != null && Boolean . TRUE . equals ( args [ 0 ] ) ; },Smelly
" public void read ( org . apache . thrift . protocol . TProtocol prot , UpdateErrors struct ) throws org . apache . thrift . TException { TTupleProtocol iprot = ( TTupleProtocol ) prot ; BitSet incoming = iprot . readBitSet ( 3 ) ; if ( incoming . get ( 0 ) ) { { org . apache . thrift . protocol . TMap _map75 = new org . apache . thrift . protocol . TMap ( org . apache . thrift . protocol . TType . STRUCT , org . apache . thrift . protocol . TType . I64 , iprot . readI32 ( ) ) ; struct . failedExtents = new HashMap < TKeyExtent , Long > ( 2 * _map75 . size ) ; for ( int _i76 = 0 ; _i76 < _map75 . size ; ++ _i76 ) { TKeyExtent _key77 ; long _val78 ; _key77 = new TKeyExtent ( ) ; _key77 . read ( iprot ) ; _val78 = iprot . readI64 ( ) ; struct . failedExtents . put ( _key77 , _val78 ) ; } } struct . setFailedExtentsIsSet ( true ) ; } if ( incoming . get ( 1 ) ) { { org . apache . thrift . protocol . TList _list79 = new org . apache . thrift . protocol . TList ( org . apache . thrift . protocol . TType . STRUCT , iprot . readI32 ( ) ) ; struct . violationSummaries = new ArrayList < TConstraintViolationSummary > ( _list79 . size ) ; for ( int _i80 = 0 ; _i80 < _list79 . size ; ++ _i80 ) { TConstraintViolationSummary _elem81 ; _elem81 = new TConstraintViolationSummary ( ) ; _elem81 . read ( iprot ) ; struct . violationSummaries . add ( _elem81 ) ; } } struct . setViolationSummariesIsSet ( true ) ; } if ( incoming . get ( 2 ) ) { { org . apache . thrift . protocol . TMap _map82 = new org . apache . thrift . protocol . TMap ( org . apache . thrift . protocol . TType . STRUCT , org . apache . thrift . protocol . TType . I32 , iprot . readI32 ( ) ) ; struct . authorizationFailures = new HashMap < TKeyExtent , org . apache . accumulo . core . client . impl . thrift . SecurityErrorCode > ( 2 * _map82 . size ) ; for ( int _i83 = 0 ; _i83 < _map82 . size ; ++ _i83 ) { TKeyExtent _key84 ; org . apache . accumulo . core . client . impl . thrift . SecurityErrorCode _val85 ; _key84 = new TKeyExtent ( ) ; _key84 . read ( iprot ) ; _val85 = org . apache . accumulo . core . client . impl . thrift . SecurityErrorCode . findByValue ( iprot . readI32 ( ) ) ; struct . authorizationFailures . put ( _key84 , _val85 ) ; } } struct . setAuthorizationFailuresIsSet ( true ) ; } }",Smelly
" public void read ( org . apache . thrift . protocol . TProtocol prot , show_compact_result struct ) throws org . apache . thrift . TException { TTupleProtocol iprot = ( TTupleProtocol ) prot ; BitSet incoming = iprot . readBitSet ( 1 ) ; if ( incoming . get ( 0 ) ) { struct . success = new ShowCompactResponse ( ) ; struct . success . read ( iprot ) ; struct . setSuccessIsSet ( true ) ; } }",Smelly
" public void removeFromPaintings ( Painting object ) { if ( objectContext != null ) { objectContext . prepareForAccess ( this , ""paintings"" , true ) ; } else if ( this . paintings == null ) { this . paintings = new PersistentObjectList ( this , ""paintings"" ) ; } this . paintings . remove ( object ) ; }",No
" public void read ( org . apache . thrift . protocol . TProtocol prot , getChildDataProducts_result struct ) throws org . apache . thrift . TException { TTupleProtocol iprot = ( TTupleProtocol ) prot ; BitSet incoming = iprot . readBitSet ( 5 ) ; if ( incoming . get ( 0 ) ) { { org . apache . thrift . protocol . TList _list283 = new org . apache . thrift . protocol . TList ( org . apache . thrift . protocol . TType . STRUCT , iprot . readI32 ( ) ) ; struct . success = new ArrayList < org . apache . airavata . model . data . replica . DataProductModel > ( _list283 . size ) ; org . apache . airavata . model . data . replica . DataProductModel _elem284 ; for ( int _i285 = 0 ; _i285 < _list283 . size ; ++ _i285 ) { _elem284 = new org . apache . airavata . model . data . replica . DataProductModel ( ) ; _elem284 . read ( iprot ) ; struct . success . add ( _elem284 ) ; } } struct . setSuccessIsSet ( true ) ; } if ( incoming . get ( 1 ) ) { struct . ire = new org . apache . airavata . model . error . InvalidRequestException ( ) ; struct . ire . read ( iprot ) ; struct . setIreIsSet ( true ) ; } if ( incoming . get ( 2 ) ) { struct . ace = new org . apache . airavata . model . error . AiravataClientException ( ) ; struct . ace . read ( iprot ) ; struct . setAceIsSet ( true ) ; } if ( incoming . get ( 3 ) ) { struct . ase = new org . apache . airavata . model . error . AiravataSystemException ( ) ; struct . ase . read ( iprot ) ; struct . setAseIsSet ( true ) ; } if ( incoming . get ( 4 ) ) { struct . ae = new org . apache . airavata . model . error . AuthorizationException ( ) ; struct . ae . read ( iprot ) ; struct . setAeIsSet ( true ) ; } }",Smelly
" public void exceptionCaught ( ChannelHandlerContext ctx , ExceptionEvent e ) throws Exception { Channel ch = e . getChannel ( ) ; Throwable cause = e . getCause ( ) ; if ( cause instanceof TooLongFrameException ) { sendError ( ctx , BAD_REQUEST ) ; return ; } else if ( cause instanceof IOException ) { if ( cause instanceof ClosedChannelException ) { LOG . debug ( ""Ignoring closed channel error"" , cause ) ; return ; } String message = String . valueOf ( cause . getMessage ( ) ) ; if ( IGNORABLE_ERROR_MESSAGE . matcher ( message ) . matches ( ) ) { LOG . debug ( ""Ignoring client socket close"" , cause ) ; return ; } } LOG . error ( ""Shuffle error: "" , cause ) ; if ( ch . isConnected ( ) ) { LOG . error ( ""Shuffle error "" + e ) ; sendError ( ctx , INTERNAL_SERVER_ERROR ) ; } }",No
" public int complete ( String buf , int pos , List cand ) { if ( beeLine . getDatabaseConnection ( ) == null ) { return - 1 ; } return new SimpleCompletor ( beeLine . getDatabaseConnection ( ) . getTableNames ( true ) ) . complete ( buf , pos , cand ) ; }",No
" public void read ( org . apache . thrift . protocol . TProtocol prot , ProcessSubmitEvent struct ) throws org . apache . thrift . TException { TTupleProtocol iprot = ( TTupleProtocol ) prot ; struct . processId = iprot . readString ( ) ; struct . setProcessIdIsSet ( true ) ; struct . gatewayId = iprot . readString ( ) ; struct . setGatewayIdIsSet ( true ) ; struct . experimentId = iprot . readString ( ) ; struct . setExperimentIdIsSet ( true ) ; struct . tokenId = iprot . readString ( ) ; struct . setTokenIdIsSet ( true ) ; }",Smelly
 private static < S extends org . apache . thrift . scheme . IScheme > S scheme ( org . apache . thrift . protocol . TProtocol proto ) { return ( org . apache . thrift . scheme . StandardScheme . class . equals ( proto . getScheme ( ) ) ? STANDARD_SCHEME_FACTORY : TUPLE_SCHEME_FACTORY ) . getScheme ( ) ; },Smelly
" protected void doExecute ( RepositoryAdmin admin ) throws Exception { List < Repository > repositories = new ArrayList < > ( ) ; repositories . add ( admin . getSystemRepository ( ) ) ; if ( ! noLocal ) { repositories . add ( admin . getLocalRepository ( ) ) ; } if ( ! noRemote ) { repositories . addAll ( Arrays . asList ( admin . listRepositories ( ) ) ) ; } Resolver resolver = admin . resolver ( repositories . toArray ( new Repository [ repositories . size ( ) ] ) ) ; for ( Requirement requirement : parseRequirements ( admin , requirements ) ) { resolver . add ( requirement ) ; } if ( resolver . resolve ( optional ? 0 : Resolver . NO_OPTIONAL_RESOURCES ) ) { Resource [ ] resources ; resources = resolver . getRequiredResources ( ) ; if ( ( resources != null ) && ( resources . length > 0 ) ) { System . out . println ( ""Required resource(s):"" ) ; printUnderline ( System . out , 21 ) ; for ( Resource resource : resources ) { System . out . println ( ""   "" + resource . getPresentationName ( ) + "" ("" + resource . getVersion ( ) + "")"" ) ; if ( why ) { Reason [ ] req = resolver . getReason ( resource ) ; for ( int reqIdx = 0 ; req != null && reqIdx < req . length ; reqIdx ++ ) { if ( ! req [ reqIdx ] . getRequirement ( ) . isOptional ( ) ) { Resource r = req [ reqIdx ] . getResource ( ) ; if ( r != null ) { System . out . println ( ""      - "" + r . getPresentationName ( ) + "" / "" + req [ reqIdx ] . getRequirement ( ) . getName ( ) + "":"" + req [ reqIdx ] . getRequirement ( ) . getFilter ( ) ) ; } else { System . out . println ( ""      - "" + req [ reqIdx ] . getRequirement ( ) . getName ( ) + "":"" + req [ reqIdx ] . getRequirement ( ) . getFilter ( ) ) ; } } } } } } resources = resolver . getOptionalResources ( ) ; if ( ( resources != null ) && ( resources . length > 0 ) ) { System . out . println ( ) ; System . out . println ( ""Optional resource(s):"" ) ; printUnderline ( System . out , 21 ) ; for ( Resource resource : resources ) { System . out . println ( ""   "" + resource . getPresentationName ( ) + "" ("" + resource . getVersion ( ) + "")"" ) ; if ( why ) { Reason [ ] req = resolver . getReason ( resource ) ; for ( int reqIdx = 0 ; req != null && reqIdx < req . length ; reqIdx ++ ) { if ( ! req [ reqIdx ] . getRequirement ( ) . isOptional ( ) ) { Resource r = req [ reqIdx ] . getResource ( ) ; if ( r != null ) { System . out . println ( ""      - "" + r . getPresentationName ( ) + "" / "" + req [ reqIdx ] . getRequirement ( ) . getName ( ) + "":"" + req [ reqIdx ] . getRequirement ( ) . getFilter ( ) ) ; } else { System . out . println ( ""      - "" + req [ reqIdx ] . getRequirement ( ) . getName ( ) + "":"" + req [ reqIdx ] . getRequirement ( ) . getFilter ( ) ) ; } } } } } } if ( deploy || start ) { try { System . out . print ( ""\nDeploying..."" ) ; resolver . deploy ( start ? Resolver . START : 0 ) ; System . out . println ( ""done."" ) ; } catch ( IllegalStateException ex ) { System . err . println ( ex ) ; } } } else { Reason [ ] reqs = resolver . getUnsatisfiedRequirements ( ) ; if ( ( reqs != null ) && ( reqs . length > 0 ) ) { System . out . println ( ""Unsatisfied requirement(s):"" ) ; printUnderline ( System . out , 27 ) ; for ( Reason req : reqs ) { System . out . println ( ""   "" + req . getRequirement ( ) . getName ( ) + "":"" + req . getRequirement ( ) . getFilter ( ) ) ; System . out . println ( ""      "" + req . getResource ( ) . getPresentationName ( ) ) ; } } else { System . out . println ( ""Could not resolve targets."" ) ; } } }",Smelly
" public void removeFromTargets ( ClientIdMapToManyTarget object ) { if ( objectContext != null ) { objectContext . prepareForAccess ( this , ""targets"" , true ) ; } this . targets . remove ( getMapKey ( ""targets"" , object ) ) ; }",No
" public void read ( org . apache . thrift . protocol . TProtocol prot , show_compact_result struct ) throws org . apache . thrift . TException { TTupleProtocol iprot = ( TTupleProtocol ) prot ; BitSet incoming = iprot . readBitSet ( 1 ) ; if ( incoming . get ( 0 ) ) { struct . success = new ShowCompactResponse ( ) ; struct . success . read ( iprot ) ; struct . setSuccessIsSet ( true ) ; } }",Smelly
" public void handleMessage ( Message message ) throws Fault { W3CDOMStreamWriter domWriter = ( W3CDOMStreamWriter ) message . getContent ( XMLStreamWriter . class ) ; XMLStreamWriter origWriter = ( XMLStreamWriter ) message . get ( LogicalHandlerFaultOutInterceptor . ORIGINAL_WRITER ) ; HandlerChainInvoker invoker = getInvoker ( message ) ; LogicalMessageContextImpl lctx = new LogicalMessageContextImpl ( message ) ; invoker . setLogicalMessageContext ( lctx ) ; boolean requestor = isRequestor ( message ) ; XMLStreamReader reader = ( XMLStreamReader ) message . get ( ""LogicalHandlerInterceptor.INREADER"" ) ; SOAPMessage origMessage = null ; if ( reader != null ) { origMessage = message . getContent ( SOAPMessage . class ) ; message . setContent ( XMLStreamReader . class , reader ) ; message . removeContent ( SOAPMessage . class ) ; } else if ( domWriter . getDocument ( ) . getDocumentElement ( ) != null ) { Source source = new DOMSource ( domWriter . getDocument ( ) ) ; message . setContent ( Source . class , source ) ; message . setContent ( Node . class , domWriter . getDocument ( ) ) ; message . setContent ( XMLStreamReader . class , StaxUtils . createXMLStreamReader ( domWriter . getDocument ( ) ) ) ; } try { if ( ! invoker . invokeLogicalHandlersHandleFault ( requestor , lctx ) ) { } } catch ( RuntimeException exception ) { Exchange exchange = message . getExchange ( ) ; Exception ex = new Fault ( exception ) ; FaultMode mode = message . get ( FaultMode . class ) ; Message faultMessage = exchange . getOutMessage ( ) ; if ( null == faultMessage ) { faultMessage = new MessageImpl ( ) ; faultMessage . setExchange ( message . getExchange ( ) ) ; faultMessage = exchange . get ( Endpoint . class ) . getBinding ( ) . createMessage ( faultMessage ) ; } faultMessage . setContent ( Exception . class , ex ) ; if ( null != mode ) { faultMessage . put ( FaultMode . class , mode ) ; } exchange . setOutMessage ( null ) ; exchange . setOutFaultMessage ( faultMessage ) ; InterceptorChain ic = message . getInterceptorChain ( ) ; ic . reset ( ) ; onCompletion ( message ) ; faultMessage . setInterceptorChain ( ic ) ; ic . doIntercept ( faultMessage ) ; return ; } if ( origMessage != null ) { message . setContent ( SOAPMessage . class , origMessage ) ; } try { reader = message . getContent ( XMLStreamReader . class ) ; message . removeContent ( XMLStreamReader . class ) ; if ( reader != null ) { StaxUtils . copy ( reader , origWriter ) ; } else if ( domWriter . getDocument ( ) . getDocumentElement ( ) != null ) { StaxUtils . copy ( domWriter . getDocument ( ) , origWriter ) ; } message . setContent ( XMLStreamWriter . class , origWriter ) ; } catch ( XMLStreamException e ) { throw new Fault ( e ) ; } }",Smelly
" public int run ( String [ ] args ) throws Exception { Option helpOpt = new Option ( ""h"" , ""help"" , false , ""show this help message"" ) ; Option normOpt = new Option ( ""n"" , ""normalize"" , false , ""whether to use URLNormalizers on the URL's in the segment"" ) ; Option filtOpt = new Option ( ""f"" , ""filter"" , false , ""whether to use URLFilters on the URL's in the segment"" ) ; @ SuppressWarnings ( ""static-access"" ) Option graphOpt = OptionBuilder . withArgName ( ""webgraphdb"" ) . hasArg ( ) . withDescription ( ""the web graph database to create (if none exists) or use if one does"" ) . create ( ""webgraphdb"" ) ; @ SuppressWarnings ( ""static-access"" ) Option segOpt = OptionBuilder . withArgName ( ""segment"" ) . hasArgs ( ) . withDescription ( ""the segment(s) to use"" ) . create ( ""segment"" ) ; @ SuppressWarnings ( ""static-access"" ) Option segDirOpt = OptionBuilder . withArgName ( ""segmentDir"" ) . hasArgs ( ) . withDescription ( ""the segment directory to use"" ) . create ( ""segmentDir"" ) ; Options options = new Options ( ) ; options . addOption ( helpOpt ) ; options . addOption ( normOpt ) ; options . addOption ( filtOpt ) ; options . addOption ( graphOpt ) ; options . addOption ( segOpt ) ; options . addOption ( segDirOpt ) ; CommandLineParser parser = new GnuParser ( ) ; try { CommandLine line = parser . parse ( options , args ) ; if ( line . hasOption ( ""help"" ) || ! line . hasOption ( ""webgraphdb"" ) || ( ! line . hasOption ( ""segment"" ) && ! line . hasOption ( ""segmentDir"" ) ) ) { HelpFormatter formatter = new HelpFormatter ( ) ; formatter . printHelp ( ""WebGraph"" , options , true ) ; return - 1 ; } String webGraphDb = line . getOptionValue ( ""webgraphdb"" ) ; Path [ ] segPaths = null ; if ( line . hasOption ( ""segment"" ) ) { String [ ] segments = line . getOptionValues ( ""segment"" ) ; segPaths = new Path [ segments . length ] ; for ( int i = 0 ; i < segments . length ; i ++ ) { segPaths [ i ] = new Path ( segments [ i ] ) ; } } if ( line . hasOption ( ""segmentDir"" ) ) { Path dir = new Path ( line . getOptionValue ( ""segmentDir"" ) ) ; FileSystem fs = dir . getFileSystem ( getConf ( ) ) ; FileStatus [ ] fstats = fs . listStatus ( dir , HadoopFSUtil . getPassDirectoriesFilter ( fs ) ) ; segPaths = HadoopFSUtil . getPaths ( fstats ) ; } boolean normalize = false ; if ( line . hasOption ( ""normalize"" ) ) { normalize = true ; } boolean filter = false ; if ( line . hasOption ( ""filter"" ) ) { filter = true ; } createWebGraph ( new Path ( webGraphDb ) , segPaths , normalize , filter ) ; return 0 ; } catch ( Exception e ) { LOG . error ( ""WebGraph: "" + StringUtils . stringifyException ( e ) ) ; return - 2 ; } }",No
" public void writeThenReadAll ( ) { TextIO . TypedWrite < String , Object > write = TextIO . write ( ) . to ( filenamePrefix ) . withOutputFilenames ( ) . withCompression ( compressionType ) ; PCollection < String > testFilenames = pipeline . apply ( ""Generate sequence"" , GenerateSequence . from ( 0 ) . to ( numberOfTextLines ) ) . apply ( ""Produce text lines"" , ParDo . of ( new FileBasedIOITHelper . DeterministicallyConstructTestTextLineFn ( ) ) ) . apply ( ""Write content to files"" , write ) . getPerDestinationOutputFilenames ( ) . apply ( Values . create ( ) ) ; PCollection < String > consolidatedHashcode = testFilenames . apply ( ""Read all files"" , TextIO . readAll ( ) . withCompression ( AUTO ) ) . apply ( ""Calculate hashcode"" , Combine . globally ( new HashingFn ( ) ) ) ; String expectedHash = getExpectedHashForLineCount ( numberOfTextLines ) ; PAssert . thatSingleton ( consolidatedHashcode ) . isEqualTo ( expectedHash ) ; testFilenames . apply ( ""Delete test files"" , ParDo . of ( new DeleteFileFn ( ) ) . withSideInputs ( consolidatedHashcode . apply ( View . asSingleton ( ) ) ) ) ; pipeline . run ( ) . waitUntilFinish ( ) ; }",No
" public void read ( org . apache . thrift . protocol . TProtocol prot , getChildDataProducts_result struct ) throws org . apache . thrift . TException { TTupleProtocol iprot = ( TTupleProtocol ) prot ; BitSet incoming = iprot . readBitSet ( 5 ) ; if ( incoming . get ( 0 ) ) { { org . apache . thrift . protocol . TList _list283 = new org . apache . thrift . protocol . TList ( org . apache . thrift . protocol . TType . STRUCT , iprot . readI32 ( ) ) ; struct . success = new ArrayList < org . apache . airavata . model . data . replica . DataProductModel > ( _list283 . size ) ; org . apache . airavata . model . data . replica . DataProductModel _elem284 ; for ( int _i285 = 0 ; _i285 < _list283 . size ; ++ _i285 ) { _elem284 = new org . apache . airavata . model . data . replica . DataProductModel ( ) ; _elem284 . read ( iprot ) ; struct . success . add ( _elem284 ) ; } } struct . setSuccessIsSet ( true ) ; } if ( incoming . get ( 1 ) ) { struct . ire = new org . apache . airavata . model . error . InvalidRequestException ( ) ; struct . ire . read ( iprot ) ; struct . setIreIsSet ( true ) ; } if ( incoming . get ( 2 ) ) { struct . ace = new org . apache . airavata . model . error . AiravataClientException ( ) ; struct . ace . read ( iprot ) ; struct . setAceIsSet ( true ) ; } if ( incoming . get ( 3 ) ) { struct . ase = new org . apache . airavata . model . error . AiravataSystemException ( ) ; struct . ase . read ( iprot ) ; struct . setAseIsSet ( true ) ; } if ( incoming . get ( 4 ) ) { struct . ae = new org . apache . airavata . model . error . AuthorizationException ( ) ; struct . ae . read ( iprot ) ; struct . setAeIsSet ( true ) ; } }",No
" public void onMatch ( RelOptRuleCall call ) { final Sort sort = call . rel ( 0 ) ; final Join join = call . rel ( 1 ) ; final RelMetadataQuery metadataQuery = call . getMetadataQuery ( ) ; final RelNode newLeftInput ; final RelNode newRightInput ; final List < RelFieldCollation > leftFieldCollation = new ArrayList < > ( ) ; final List < RelFieldCollation > rightFieldCollation = new ArrayList < > ( ) ; for ( RelFieldCollation relFieldCollation : sort . getCollation ( ) . getFieldCollations ( ) ) { if ( relFieldCollation . getFieldIndex ( ) >= join . getLeft ( ) . getRowType ( ) . getFieldCount ( ) ) { rightFieldCollation . add ( relFieldCollation ) ; } else { leftFieldCollation . add ( relFieldCollation ) ; } } if ( leftFieldCollation . isEmpty ( ) ) { newLeftInput = join . getLeft ( ) ; } else { final RelCollation leftCollation = RelCollationTraitDef . INSTANCE . canonize ( RelCollations . of ( leftFieldCollation ) ) ; if ( RelMdUtil . checkInputForCollationAndLimit ( metadataQuery , join . getLeft ( ) , leftCollation , null , null ) ) { newLeftInput = join . getLeft ( ) ; } else { newLeftInput = sort . copy ( sort . getTraitSet ( ) . replaceIf ( RelCollationTraitDef . INSTANCE , ( ) -> leftCollation ) , join . getLeft ( ) , leftCollation , null , null ) ; } } if ( rightFieldCollation . isEmpty ( ) ) { newRightInput = join . getRight ( ) ; } else { final RelCollation rightCollation = RelCollationTraitDef . INSTANCE . canonize ( RelCollations . shift ( RelCollations . of ( rightFieldCollation ) , - join . getLeft ( ) . getRowType ( ) . getFieldCount ( ) ) ) ; if ( RelMdUtil . checkInputForCollationAndLimit ( metadataQuery , join . getRight ( ) , rightCollation , null , null ) ) { newRightInput = join . getRight ( ) ; } else { newRightInput = sort . copy ( sort . getTraitSet ( ) . replaceIf ( RelCollationTraitDef . INSTANCE , ( ) -> rightCollation ) , join . getRight ( ) , rightCollation , null , null ) ; } } if ( newLeftInput == join . getLeft ( ) && newRightInput == join . getRight ( ) ) { return ; } final RelNode joinCopy = join . copy ( join . getTraitSet ( ) , join . getCondition ( ) , newLeftInput , newRightInput , join . getJoinType ( ) , join . isSemiJoinDone ( ) ) ; final RelNode sortCopy = sort . copy ( sort . getTraitSet ( ) , joinCopy , sort . getCollation ( ) , sort . offset , sort . fetch ) ; call . transformTo ( sortCopy ) ; }",Smelly
" public void read ( org . apache . thrift . protocol . TProtocol prot , GlobusJobSubmission struct ) throws org . apache . thrift . TException { TTupleProtocol iprot = ( TTupleProtocol ) prot ; struct . jobSubmissionInterfaceId = iprot . readString ( ) ; struct . setJobSubmissionInterfaceIdIsSet ( true ) ; struct . securityProtocol = org . apache . airavata . model . data . movement . SecurityProtocol . findByValue ( iprot . readI32 ( ) ) ; struct . setSecurityProtocolIsSet ( true ) ; BitSet incoming = iprot . readBitSet ( 1 ) ; if ( incoming . get ( 0 ) ) { { org . apache . thrift . protocol . TList _list33 = new org . apache . thrift . protocol . TList ( org . apache . thrift . protocol . TType . STRING , iprot . readI32 ( ) ) ; struct . globusGateKeeperEndPoint = new ArrayList < String > ( _list33 . size ) ; String _elem34 ; for ( int _i35 = 0 ; _i35 < _list33 . size ; ++ _i35 ) { _elem34 = iprot . readString ( ) ; struct . globusGateKeeperEndPoint . add ( _elem34 ) ; } } struct . setGlobusGateKeeperEndPointIsSet ( true ) ; } }",Smelly
" public void read ( org . apache . thrift . protocol . TProtocol prot , getChildDataProducts_result struct ) throws org . apache . thrift . TException { TTupleProtocol iprot = ( TTupleProtocol ) prot ; BitSet incoming = iprot . readBitSet ( 5 ) ; if ( incoming . get ( 0 ) ) { { org . apache . thrift . protocol . TList _list283 = new org . apache . thrift . protocol . TList ( org . apache . thrift . protocol . TType . STRUCT , iprot . readI32 ( ) ) ; struct . success = new ArrayList < org . apache . airavata . model . data . replica . DataProductModel > ( _list283 . size ) ; org . apache . airavata . model . data . replica . DataProductModel _elem284 ; for ( int _i285 = 0 ; _i285 < _list283 . size ; ++ _i285 ) { _elem284 = new org . apache . airavata . model . data . replica . DataProductModel ( ) ; _elem284 . read ( iprot ) ; struct . success . add ( _elem284 ) ; } } struct . setSuccessIsSet ( true ) ; } if ( incoming . get ( 1 ) ) { struct . ire = new org . apache . airavata . model . error . InvalidRequestException ( ) ; struct . ire . read ( iprot ) ; struct . setIreIsSet ( true ) ; } if ( incoming . get ( 2 ) ) { struct . ace = new org . apache . airavata . model . error . AiravataClientException ( ) ; struct . ace . read ( iprot ) ; struct . setAceIsSet ( true ) ; } if ( incoming . get ( 3 ) ) { struct . ase = new org . apache . airavata . model . error . AiravataSystemException ( ) ; struct . ase . read ( iprot ) ; struct . setAseIsSet ( true ) ; } if ( incoming . get ( 4 ) ) { struct . ae = new org . apache . airavata . model . error . AuthorizationException ( ) ; struct . ae . read ( iprot ) ; struct . setAeIsSet ( true ) ; } }",Smelly
" public void read ( org . apache . thrift . protocol . TProtocol prot , ExperimentStatistics struct ) throws org . apache . thrift . TException { TTupleProtocol iprot = ( TTupleProtocol ) prot ; struct . allExperimentCount = iprot . readI32 ( ) ; struct . setAllExperimentCountIsSet ( true ) ; struct . completedExperimentCount = iprot . readI32 ( ) ; struct . setCompletedExperimentCountIsSet ( true ) ; struct . failedExperimentCount = iprot . readI32 ( ) ; struct . setFailedExperimentCountIsSet ( true ) ; struct . createdExperimentCount = iprot . readI32 ( ) ; struct . setCreatedExperimentCountIsSet ( true ) ; struct . runningExperimentCount = iprot . readI32 ( ) ; struct . setRunningExperimentCountIsSet ( true ) ; { org . apache . thrift . protocol . TList _list70 = new org . apache . thrift . protocol . TList ( org . apache . thrift . protocol . TType . STRUCT , iprot . readI32 ( ) ) ; struct . allExperiments = new ArrayList < ExperimentSummaryModel > ( _list70 . size ) ; ExperimentSummaryModel _elem71 ; for ( int _i72 = 0 ; _i72 < _list70 . size ; ++ _i72 ) { _elem71 = new ExperimentSummaryModel ( ) ; _elem71 . read ( iprot ) ; struct . allExperiments . add ( _elem71 ) ; } } struct . setAllExperimentsIsSet ( true ) ; BitSet incoming = iprot . readBitSet ( 6 ) ; if ( incoming . get ( 0 ) ) { struct . cancelledExperimentCount = iprot . readI32 ( ) ; struct . setCancelledExperimentCountIsSet ( true ) ; } if ( incoming . get ( 1 ) ) { { org . apache . thrift . protocol . TList _list73 = new org . apache . thrift . protocol . TList ( org . apache . thrift . protocol . TType . STRUCT , iprot . readI32 ( ) ) ; struct . completedExperiments = new ArrayList < ExperimentSummaryModel > ( _list73 . size ) ; ExperimentSummaryModel _elem74 ; for ( int _i75 = 0 ; _i75 < _list73 . size ; ++ _i75 ) { _elem74 = new ExperimentSummaryModel ( ) ; _elem74 . read ( iprot ) ; struct . completedExperiments . add ( _elem74 ) ; } } struct . setCompletedExperimentsIsSet ( true ) ; } if ( incoming . get ( 2 ) ) { { org . apache . thrift . protocol . TList _list76 = new org . apache . thrift . protocol . TList ( org . apache . thrift . protocol . TType . STRUCT , iprot . readI32 ( ) ) ; struct . failedExperiments = new ArrayList < ExperimentSummaryModel > ( _list76 . size ) ; ExperimentSummaryModel _elem77 ; for ( int _i78 = 0 ; _i78 < _list76 . size ; ++ _i78 ) { _elem77 = new ExperimentSummaryModel ( ) ; _elem77 . read ( iprot ) ; struct . failedExperiments . add ( _elem77 ) ; } } struct . setFailedExperimentsIsSet ( true ) ; } if ( incoming . get ( 3 ) ) { { org . apache . thrift . protocol . TList _list79 = new org . apache . thrift . protocol . TList ( org . apache . thrift . protocol . TType . STRUCT , iprot . readI32 ( ) ) ; struct . cancelledExperiments = new ArrayList < ExperimentSummaryModel > ( _list79 . size ) ; ExperimentSummaryModel _elem80 ; for ( int _i81 = 0 ; _i81 < _list79 . size ; ++ _i81 ) { _elem80 = new ExperimentSummaryModel ( ) ; _elem80 . read ( iprot ) ; struct . cancelledExperiments . add ( _elem80 ) ; } } struct . setCancelledExperimentsIsSet ( true ) ; } if ( incoming . get ( 4 ) ) { { org . apache . thrift . protocol . TList _list82 = new org . apache . thrift . protocol . TList ( org . apache . thrift . protocol . TType . STRUCT , iprot . readI32 ( ) ) ; struct . createdExperiments = new ArrayList < ExperimentSummaryModel > ( _list82 . size ) ; ExperimentSummaryModel _elem83 ; for ( int _i84 = 0 ; _i84 < _list82 . size ; ++ _i84 ) { _elem83 = new ExperimentSummaryModel ( ) ; _elem83 . read ( iprot ) ; struct . createdExperiments . add ( _elem83 ) ; } } struct . setCreatedExperimentsIsSet ( true ) ; } if ( incoming . get ( 5 ) ) { { org . apache . thrift . protocol . TList _list85 = new org . apache . thrift . protocol . TList ( org . apache . thrift . protocol . TType . STRUCT , iprot . readI32 ( ) ) ; struct . runningExperiments = new ArrayList < ExperimentSummaryModel > ( _list85 . size ) ; ExperimentSummaryModel _elem86 ; for ( int _i87 = 0 ; _i87 < _list85 . size ; ++ _i87 ) { _elem86 = new ExperimentSummaryModel ( ) ; _elem86 . read ( iprot ) ; struct . runningExperiments . add ( _elem86 ) ; } } struct . setRunningExperimentsIsSet ( true ) ; } }",Smelly
 void onRemove ( InetAddress endpoint ) ;,No
" public void run ( ) { Logging . threads . debug ( ""Start up finisher thread"" ) ; try { IThreadContext threadContext = ThreadContextFactory . make ( ) ; IJobManager jobManager = JobManagerFactory . make ( threadContext ) ; IRepositoryConnectionManager connectionManager = RepositoryConnectionManagerFactory . make ( threadContext ) ; while ( true ) { try { Logging . threads . debug ( ""Cleaning up completed jobs..."" ) ; jobManager . finishJobs ( ) ; Logging . threads . debug ( ""Done cleaning up completed jobs"" ) ; ManifoldCF . sleep ( 10000L ) ; } catch ( ManifoldCFException e ) { if ( e . getErrorCode ( ) == ManifoldCFException . INTERRUPTED ) break ; if ( e . getErrorCode ( ) == ManifoldCFException . DATABASE_CONNECTION_ERROR ) { Logging . threads . error ( ""Finisher thread aborting and restarting due to database connection reset: "" + e . getMessage ( ) , e ) ; try { ManifoldCF . sleep ( 10000L ) ; } catch ( InterruptedException se ) { break ; } continue ; } Logging . threads . error ( ""Exception tossed: "" + e . getMessage ( ) , e ) ; if ( e . getErrorCode ( ) == ManifoldCFException . SETUP_ERROR ) { System . exit ( 1 ) ; } } catch ( InterruptedException e ) { break ; } catch ( OutOfMemoryError e ) { System . err . println ( ""agents process ran out of memory - shutting down"" ) ; e . printStackTrace ( System . err ) ; System . exit ( - 200 ) ; } catch ( Throwable e ) { Logging . threads . fatal ( ""Error tossed: "" + e . getMessage ( ) , e ) ; } } } catch ( Throwable e ) { System . err . println ( ""agents process could not start - shutting down"" ) ; Logging . threads . fatal ( ""FinisherThread initialization error tossed: "" + e . getMessage ( ) , e ) ; System . exit ( - 300 ) ; } }",Smelly
" public void read ( org . apache . thrift . protocol . TProtocol prot , getChildDataProducts_result struct ) throws org . apache . thrift . TException { TTupleProtocol iprot = ( TTupleProtocol ) prot ; BitSet incoming = iprot . readBitSet ( 5 ) ; if ( incoming . get ( 0 ) ) { { org . apache . thrift . protocol . TList _list283 = new org . apache . thrift . protocol . TList ( org . apache . thrift . protocol . TType . STRUCT , iprot . readI32 ( ) ) ; struct . success = new ArrayList < org . apache . airavata . model . data . replica . DataProductModel > ( _list283 . size ) ; org . apache . airavata . model . data . replica . DataProductModel _elem284 ; for ( int _i285 = 0 ; _i285 < _list283 . size ; ++ _i285 ) { _elem284 = new org . apache . airavata . model . data . replica . DataProductModel ( ) ; _elem284 . read ( iprot ) ; struct . success . add ( _elem284 ) ; } } struct . setSuccessIsSet ( true ) ; } if ( incoming . get ( 1 ) ) { struct . ire = new org . apache . airavata . model . error . InvalidRequestException ( ) ; struct . ire . read ( iprot ) ; struct . setIreIsSet ( true ) ; } if ( incoming . get ( 2 ) ) { struct . ace = new org . apache . airavata . model . error . AiravataClientException ( ) ; struct . ace . read ( iprot ) ; struct . setAceIsSet ( true ) ; } if ( incoming . get ( 3 ) ) { struct . ase = new org . apache . airavata . model . error . AiravataSystemException ( ) ; struct . ase . read ( iprot ) ; struct . setAseIsSet ( true ) ; } if ( incoming . get ( 4 ) ) { struct . ae = new org . apache . airavata . model . error . AuthorizationException ( ) ; struct . ae . read ( iprot ) ; struct . setAeIsSet ( true ) ; } }",Smelly
" public void testPartialJob ( ) throws Exception { JobId jobId = new JobIdPBImpl ( ) ; jobId . setId ( 0 ) ; JobIndexInfo jii = new JobIndexInfo ( 0L , System . currentTimeMillis ( ) , ""user"" , ""jobName"" , jobId , 3 , 2 , ""JobStatus"" ) ; PartialJob test = new PartialJob ( jii , jobId ) ; assertEquals ( 1.0f , test . getProgress ( ) , 0.001 ) ; assertNull ( test . getAllCounters ( ) ) ; assertNull ( test . getTasks ( ) ) ; assertNull ( test . getTasks ( TaskType . MAP ) ) ; assertNull ( test . getTask ( new TaskIdPBImpl ( ) ) ) ; assertNull ( test . getTaskAttemptCompletionEvents ( 0 , 100 ) ) ; assertNull ( test . getMapAttemptCompletionEvents ( 0 , 100 ) ) ; assertTrue ( test . checkAccess ( UserGroupInformation . getCurrentUser ( ) , null ) ) ; assertNull ( test . getAMInfos ( ) ) ; }",No
 public int getMinBufferSize ( ) { return minBufferSize ; },No
 void finish ( String name ) ;,No
" public void read ( org . apache . thrift . protocol . TProtocol prot , getChildDataProducts_result struct ) throws org . apache . thrift . TException { TTupleProtocol iprot = ( TTupleProtocol ) prot ; BitSet incoming = iprot . readBitSet ( 5 ) ; if ( incoming . get ( 0 ) ) { { org . apache . thrift . protocol . TList _list283 = new org . apache . thrift . protocol . TList ( org . apache . thrift . protocol . TType . STRUCT , iprot . readI32 ( ) ) ; struct . success = new ArrayList < org . apache . airavata . model . data . replica . DataProductModel > ( _list283 . size ) ; org . apache . airavata . model . data . replica . DataProductModel _elem284 ; for ( int _i285 = 0 ; _i285 < _list283 . size ; ++ _i285 ) { _elem284 = new org . apache . airavata . model . data . replica . DataProductModel ( ) ; _elem284 . read ( iprot ) ; struct . success . add ( _elem284 ) ; } } struct . setSuccessIsSet ( true ) ; } if ( incoming . get ( 1 ) ) { struct . ire = new org . apache . airavata . model . error . InvalidRequestException ( ) ; struct . ire . read ( iprot ) ; struct . setIreIsSet ( true ) ; } if ( incoming . get ( 2 ) ) { struct . ace = new org . apache . airavata . model . error . AiravataClientException ( ) ; struct . ace . read ( iprot ) ; struct . setAceIsSet ( true ) ; } if ( incoming . get ( 3 ) ) { struct . ase = new org . apache . airavata . model . error . AiravataSystemException ( ) ; struct . ase . read ( iprot ) ; struct . setAseIsSet ( true ) ; } if ( incoming . get ( 4 ) ) { struct . ae = new org . apache . airavata . model . error . AuthorizationException ( ) ; struct . ae . read ( iprot ) ; struct . setAeIsSet ( true ) ; } }",Smelly
" public void read ( org . apache . thrift . protocol . TProtocol prot , Table struct ) throws org . apache . thrift . TException { TTupleProtocol iprot = ( TTupleProtocol ) prot ; BitSet incoming = iprot . readBitSet ( 13 ) ; if ( incoming . get ( 0 ) ) { struct . tableName = iprot . readString ( ) ; struct . setTableNameIsSet ( true ) ; } if ( incoming . get ( 1 ) ) { struct . dbName = iprot . readString ( ) ; struct . setDbNameIsSet ( true ) ; } if ( incoming . get ( 2 ) ) { struct . owner = iprot . readString ( ) ; struct . setOwnerIsSet ( true ) ; } if ( incoming . get ( 3 ) ) { struct . createTime = iprot . readI32 ( ) ; struct . setCreateTimeIsSet ( true ) ; } if ( incoming . get ( 4 ) ) { struct . lastAccessTime = iprot . readI32 ( ) ; struct . setLastAccessTimeIsSet ( true ) ; } if ( incoming . get ( 5 ) ) { struct . retention = iprot . readI32 ( ) ; struct . setRetentionIsSet ( true ) ; } if ( incoming . get ( 6 ) ) { struct . sd = new StorageDescriptor ( ) ; struct . sd . read ( iprot ) ; struct . setSdIsSet ( true ) ; } if ( incoming . get ( 7 ) ) { { org . apache . thrift . protocol . TList _list201 = new org . apache . thrift . protocol . TList ( org . apache . thrift . protocol . TType . STRUCT , iprot . readI32 ( ) ) ; struct . partitionKeys = new ArrayList < FieldSchema > ( _list201 . size ) ; for ( int _i202 = 0 ; _i202 < _list201 . size ; ++ _i202 ) { FieldSchema _elem203 ; _elem203 = new FieldSchema ( ) ; _elem203 . read ( iprot ) ; struct . partitionKeys . add ( _elem203 ) ; } } struct . setPartitionKeysIsSet ( true ) ; } if ( incoming . get ( 8 ) ) { { org . apache . thrift . protocol . TMap _map204 = new org . apache . thrift . protocol . TMap ( org . apache . thrift . protocol . TType . STRING , org . apache . thrift . protocol . TType . STRING , iprot . readI32 ( ) ) ; struct . parameters = new HashMap < String , String > ( 2 * _map204 . size ) ; for ( int _i205 = 0 ; _i205 < _map204 . size ; ++ _i205 ) { String _key206 ; String _val207 ; _key206 = iprot . readString ( ) ; _val207 = iprot . readString ( ) ; struct . parameters . put ( _key206 , _val207 ) ; } } struct . setParametersIsSet ( true ) ; } if ( incoming . get ( 9 ) ) { struct . viewOriginalText = iprot . readString ( ) ; struct . setViewOriginalTextIsSet ( true ) ; } if ( incoming . get ( 10 ) ) { struct . viewExpandedText = iprot . readString ( ) ; struct . setViewExpandedTextIsSet ( true ) ; } if ( incoming . get ( 11 ) ) { struct . tableType = iprot . readString ( ) ; struct . setTableTypeIsSet ( true ) ; } if ( incoming . get ( 12 ) ) { struct . privileges = new PrincipalPrivilegeSet ( ) ; struct . privileges . read ( iprot ) ; struct . setPrivilegesIsSet ( true ) ; } }",Smelly
" public void read ( org . apache . thrift . protocol . TProtocol prot , ThriftTestObj struct ) throws org . apache . thrift . TException { TTupleProtocol iprot = ( TTupleProtocol ) prot ; BitSet incoming = iprot . readBitSet ( 3 ) ; if ( incoming . get ( 0 ) ) { struct . field1 = iprot . readI32 ( ) ; struct . setField1IsSet ( true ) ; } if ( incoming . get ( 1 ) ) { struct . field2 = iprot . readString ( ) ; struct . setField2IsSet ( true ) ; } if ( incoming . get ( 2 ) ) { { org . apache . thrift . protocol . TList _list5 = new org . apache . thrift . protocol . TList ( org . apache . thrift . protocol . TType . STRUCT , iprot . readI32 ( ) ) ; struct . field3 = new ArrayList < InnerStruct > ( _list5 . size ) ; for ( int _i6 = 0 ; _i6 < _list5 . size ; ++ _i6 ) { InnerStruct _elem7 ; _elem7 = new InnerStruct ( ) ; _elem7 . read ( iprot ) ; struct . field3 . add ( _elem7 ) ; } } struct . setField3IsSet ( true ) ; } }",Smelly
" public void read ( org . apache . thrift . protocol . TProtocol prot , drainReplicationTable_result struct ) throws org . apache . thrift . TException { TTupleProtocol iprot = ( TTupleProtocol ) prot ; BitSet incoming = iprot . readBitSet ( 1 ) ; if ( incoming . get ( 0 ) ) { struct . success = iprot . readBool ( ) ; struct . setSuccessIsSet ( true ) ; } }",Smelly
" public void testCli ( ) throws IOException , TTransportException , ConfigurationException { new EmbeddedCassandraService ( ) . start ( ) ; ByteArrayOutputStream errStream = new ByteArrayOutputStream ( ) ; ByteArrayOutputStream outStream = new ByteArrayOutputStream ( ) ; CliMain . connect ( ""127.0.0.1"" , 9170 ) ; CliMain . sessionState . setOut ( new PrintStream ( outStream ) ) ; CliMain . sessionState . setErr ( new PrintStream ( errStream ) ) ; CliMain . processStatement ( ""drop keyspace TestKeySpace;"" ) ; CliMain . processStatement ( ""create keyspace TestKeySpace;"" ) ; for ( String statement : statements ) { errStream . reset ( ) ; CliMain . processStatement ( statement ) ; String result = outStream . toString ( ) ; assertEquals ( errStream . toString ( ) + "" processing "" + statement , """" , errStream . toString ( ) ) ; if ( statement . startsWith ( ""drop "" ) || statement . startsWith ( ""create "" ) || statement . startsWith ( ""update "" ) ) { assert Pattern . compile ( ""(.{8})-(.{4})-(.{4})-(.{4})-(.{12}).*"" , Pattern . DOTALL ) . matcher ( result ) . matches ( ) : result ; } else if ( statement . startsWith ( ""set "" ) ) { assertEquals ( result , ""Value inserted.\n"" ) ; } else if ( statement . startsWith ( ""get "" ) ) { if ( statement . contains ( ""where"" ) ) { assertTrue ( result . startsWith ( ""-------------------\nRowKey:"" ) ) ; } else { assertTrue ( result . startsWith ( ""=> (column="" ) || result . startsWith ( ""Value was not found"" ) ) ; } } else if ( statement . startsWith ( ""truncate "" ) ) { assertTrue ( result . contains ( "" truncated."" ) ) ; } else if ( statement . startsWith ( ""assume "" ) ) { assertTrue ( result . contains ( ""successfully."" ) ) ; } outStream . reset ( ) ; errStream . reset ( ) ; } }",No
 public T process ( Iterable < T > input ) { Iterator < T > itr = input . iterator ( ) ; if ( itr . hasNext ( ) ) { return itr . next ( ) ; } return null ; },No
" public static void main ( String [ ] args ) throws Exception { int result = ToolRunner . run ( NutchConfiguration . create ( ) , new SegmentMerger ( ) , args ) ; System . exit ( result ) ; }",Smelly
 boolean getTaskRescheduleRelaxedLocality ( ) ;,No
 public DoubleWritable evaluate ( DoubleWritable i ) { if ( i == null ) { return null ; } else { result . set ( Math . toRadians ( i . get ( ) ) ) ; return result ; } },No
" public void read ( org . apache . thrift . protocol . TProtocol prot , show_compact_result struct ) throws org . apache . thrift . TException { TTupleProtocol iprot = ( TTupleProtocol ) prot ; BitSet incoming = iprot . readBitSet ( 1 ) ; if ( incoming . get ( 0 ) ) { struct . success = new ShowCompactResponse ( ) ; struct . success . read ( iprot ) ; struct . setSuccessIsSet ( true ) ; } }",Smelly
" public void read ( org . apache . thrift . protocol . TProtocol prot , RDF_Decimal struct ) throws org . apache . thrift . TException { TTupleProtocol iprot = ( TTupleProtocol ) prot ; struct . value = iprot . readI64 ( ) ; struct . setValueIsSet ( true ) ; struct . scale = iprot . readI32 ( ) ; struct . setScaleIsSet ( true ) ; }",No
 private static < S extends org . apache . thrift . scheme . IScheme > S scheme ( org . apache . thrift . protocol . TProtocol proto ) { return ( org . apache . thrift . scheme . StandardScheme . class . equals ( proto . getScheme ( ) ) ? STANDARD_SCHEME_FACTORY : TUPLE_SCHEME_FACTORY ) . getScheme ( ) ; },Smelly
" public void read ( org . apache . thrift . protocol . TProtocol prot , RDF_Triple struct ) throws org . apache . thrift . TException { TTupleProtocol iprot = ( TTupleProtocol ) prot ; struct . S = new RDF_Term ( ) ; struct . S . read ( iprot ) ; struct . setSIsSet ( true ) ; struct . P = new RDF_Term ( ) ; struct . P . read ( iprot ) ; struct . setPIsSet ( true ) ; struct . O = new RDF_Term ( ) ; struct . O . read ( iprot ) ; struct . setOIsSet ( true ) ; }",Smelly
 public void close ( ) { ctx . close ( ) ; },No
 public void publish ( LogRecord record ) { super . publish ( record ) ; flush ( ) ; },No
 public void configure ( IFDocumentHandler documentHandler ) throws FOPException { ( ( PDFDocumentHandler ) documentHandler ) . mergeRendererOptionsConfig ( ( ( PDFRendererConfig ) getRendererConfig ( documentHandler ) ) . getConfigOptions ( ) ) ; },No
" public void read ( org . apache . thrift . protocol . TProtocol prot , getChildDataProducts_result struct ) throws org . apache . thrift . TException { TTupleProtocol iprot = ( TTupleProtocol ) prot ; BitSet incoming = iprot . readBitSet ( 5 ) ; if ( incoming . get ( 0 ) ) { { org . apache . thrift . protocol . TList _list283 = new org . apache . thrift . protocol . TList ( org . apache . thrift . protocol . TType . STRUCT , iprot . readI32 ( ) ) ; struct . success = new ArrayList < org . apache . airavata . model . data . replica . DataProductModel > ( _list283 . size ) ; org . apache . airavata . model . data . replica . DataProductModel _elem284 ; for ( int _i285 = 0 ; _i285 < _list283 . size ; ++ _i285 ) { _elem284 = new org . apache . airavata . model . data . replica . DataProductModel ( ) ; _elem284 . read ( iprot ) ; struct . success . add ( _elem284 ) ; } } struct . setSuccessIsSet ( true ) ; } if ( incoming . get ( 1 ) ) { struct . ire = new org . apache . airavata . model . error . InvalidRequestException ( ) ; struct . ire . read ( iprot ) ; struct . setIreIsSet ( true ) ; } if ( incoming . get ( 2 ) ) { struct . ace = new org . apache . airavata . model . error . AiravataClientException ( ) ; struct . ace . read ( iprot ) ; struct . setAceIsSet ( true ) ; } if ( incoming . get ( 3 ) ) { struct . ase = new org . apache . airavata . model . error . AiravataSystemException ( ) ; struct . ase . read ( iprot ) ; struct . setAseIsSet ( true ) ; } if ( incoming . get ( 4 ) ) { struct . ae = new org . apache . airavata . model . error . AuthorizationException ( ) ; struct . ae . read ( iprot ) ; struct . setAeIsSet ( true ) ; } }",Smelly
 void displayAllContinuations ( ) ;,No
" public int specialStateTransition ( int s , IntStream _input ) throws NoViableAltException { TokenStream input = ( TokenStream ) _input ; int _s = s ; switch ( s ) { case 0 : int LA162_1 = input . LA ( 1 ) ; int index162_1 = input . index ( ) ; input . rewind ( ) ; s = - 1 ; if ( ( synpred262_Java ( ) ) ) { s = 32 ; } else if ( ( true ) ) { s = 2 ; } input . seek ( index162_1 ) ; if ( s >= 0 ) return s ; break ; } if ( state . backtracking > 0 ) { state . failed = true ; return - 1 ; } NoViableAltException nvae = new NoViableAltException ( getDescription ( ) , 162 , _s , input ) ; error ( nvae ) ; throw nvae ; }",Smelly
 public void getFieldReference ( FieldReference fieldReference ) { this . fieldReference = fieldReference ; },No
" public void read ( org . apache . thrift . protocol . TProtocol prot , Stage struct ) throws org . apache . thrift . TException { TTupleProtocol iprot = ( TTupleProtocol ) prot ; BitSet incoming = iprot . readBitSet ( 7 ) ; if ( incoming . get ( 0 ) ) { struct . stageId = iprot . readString ( ) ; struct . setStageIdIsSet ( true ) ; } if ( incoming . get ( 1 ) ) { struct . stageType = StageType . findByValue ( iprot . readI32 ( ) ) ; struct . setStageTypeIsSet ( true ) ; } if ( incoming . get ( 2 ) ) { { org . apache . thrift . protocol . TMap _map89 = new org . apache . thrift . protocol . TMap ( org . apache . thrift . protocol . TType . STRING , org . apache . thrift . protocol . TType . STRING , iprot . readI32 ( ) ) ; struct . stageAttributes = new HashMap < String , String > ( 2 * _map89 . size ) ; for ( int _i90 = 0 ; _i90 < _map89 . size ; ++ _i90 ) { String _key91 ; String _val92 ; _key91 = iprot . readString ( ) ; _val92 = iprot . readString ( ) ; struct . stageAttributes . put ( _key91 , _val92 ) ; } } struct . setStageAttributesIsSet ( true ) ; } if ( incoming . get ( 3 ) ) { { org . apache . thrift . protocol . TMap _map93 = new org . apache . thrift . protocol . TMap ( org . apache . thrift . protocol . TType . STRING , org . apache . thrift . protocol . TType . I64 , iprot . readI32 ( ) ) ; struct . stageCounters = new HashMap < String , Long > ( 2 * _map93 . size ) ; for ( int _i94 = 0 ; _i94 < _map93 . size ; ++ _i94 ) { String _key95 ; long _val96 ; _key95 = iprot . readString ( ) ; _val96 = iprot . readI64 ( ) ; struct . stageCounters . put ( _key95 , _val96 ) ; } } struct . setStageCountersIsSet ( true ) ; } if ( incoming . get ( 4 ) ) { { org . apache . thrift . protocol . TList _list97 = new org . apache . thrift . protocol . TList ( org . apache . thrift . protocol . TType . STRUCT , iprot . readI32 ( ) ) ; struct . taskList = new ArrayList < Task > ( _list97 . size ) ; for ( int _i98 = 0 ; _i98 < _list97 . size ; ++ _i98 ) { Task _elem99 ; _elem99 = new Task ( ) ; _elem99 . read ( iprot ) ; struct . taskList . add ( _elem99 ) ; } } struct . setTaskListIsSet ( true ) ; } if ( incoming . get ( 5 ) ) { struct . done = iprot . readBool ( ) ; struct . setDoneIsSet ( true ) ; } if ( incoming . get ( 6 ) ) { struct . started = iprot . readBool ( ) ; struct . setStartedIsSet ( true ) ; } }",Smelly
" public static void main ( String [ ] args ) throws Exception { Help opts = new Help ( ) ; JCommander jc = new JCommander ( opts ) ; jc . setProgramName ( FateAdmin . class . getName ( ) ) ; LinkedHashMap < String , TxOpts > txOpts = new LinkedHashMap < > ( 2 ) ; txOpts . put ( ""fail"" , new FailOpts ( ) ) ; txOpts . put ( ""delete"" , new DeleteOpts ( ) ) ; for ( Entry < String , TxOpts > entry : txOpts . entrySet ( ) ) { jc . addCommand ( entry . getKey ( ) , entry . getValue ( ) ) ; } jc . addCommand ( ""print"" , new PrintOpts ( ) ) ; jc . parse ( args ) ; if ( opts . help || jc . getParsedCommand ( ) == null ) { jc . usage ( ) ; System . exit ( 1 ) ; } System . err . printf ( ""This tool has been deprecated%nFATE administration now available within 'accumulo shell'%n$ fate fail <txid>... | delete <txid>... | print [<txid>...]%n%n"" ) ; AdminUtil < Master > admin = new AdminUtil < > ( ) ; Instance instance = HdfsZooInstance . getInstance ( ) ; String path = ZooUtil . getRoot ( instance ) + Constants . ZFATE ; String masterPath = ZooUtil . getRoot ( instance ) + Constants . ZMASTER_LOCK ; IZooReaderWriter zk = ZooReaderWriter . getInstance ( ) ; ZooStore < Master > zs = new ZooStore < > ( path , zk ) ; if ( jc . getParsedCommand ( ) . equals ( ""fail"" ) ) { for ( String txid : txOpts . get ( jc . getParsedCommand ( ) ) . txids ) { if ( ! admin . prepFail ( zs , zk , masterPath , txid ) ) { System . exit ( 1 ) ; } } } else if ( jc . getParsedCommand ( ) . equals ( ""delete"" ) ) { for ( String txid : txOpts . get ( jc . getParsedCommand ( ) ) . txids ) { if ( ! admin . prepDelete ( zs , zk , masterPath , txid ) ) { System . exit ( 1 ) ; } admin . deleteLocks ( zs , zk , ZooUtil . getRoot ( instance ) + Constants . ZTABLE_LOCKS , txid ) ; } } else if ( jc . getParsedCommand ( ) . equals ( ""print"" ) ) { admin . print ( new ReadOnlyStore < > ( zs ) , zk , ZooUtil . getRoot ( instance ) + Constants . ZTABLE_LOCKS ) ; } }",Smelly
" public void annotate ( final JavaAnnotatable clz ) { WrapperBeanClass beanClass = null ; if ( clz instanceof WrapperBeanClass ) { beanClass = ( WrapperBeanClass ) clz ; } else { throw new RuntimeException ( ""WrapperBeanAnnotator expect JavaClass as input"" ) ; } JAnnotation xmlRootElement = new JAnnotation ( XmlRootElement . class ) ; xmlRootElement . addElement ( new JAnnotationElement ( ""name"" , beanClass . getElementName ( ) . getLocalPart ( ) ) ) ; xmlRootElement . addElement ( new JAnnotationElement ( ""namespace"" , beanClass . getElementName ( ) . getNamespaceURI ( ) ) ) ; JAnnotation xmlAccessorType = new JAnnotation ( XmlAccessorType . class ) ; xmlAccessorType . addElement ( new JAnnotationElement ( null , XmlAccessType . FIELD ) ) ; XmlType tp = null ; if ( sourceClass != null ) { tp = sourceClass . getAnnotation ( XmlType . class ) ; } JAnnotation xmlType = new JAnnotation ( XmlType . class ) ; if ( tp == null ) { xmlType . addElement ( new JAnnotationElement ( ""name"" , beanClass . getElementName ( ) . getLocalPart ( ) ) ) ; xmlType . addElement ( new JAnnotationElement ( ""namespace"" , beanClass . getElementName ( ) . getNamespaceURI ( ) ) ) ; } else { if ( ! ""##default"" . equals ( tp . name ( ) ) ) { xmlType . addElement ( new JAnnotationElement ( ""name"" , tp . name ( ) ) ) ; } if ( ! ""##default"" . equals ( tp . namespace ( ) ) ) { xmlType . addElement ( new JAnnotationElement ( ""namespace"" , tp . namespace ( ) ) ) ; } if ( ! StringUtils . isEmpty ( tp . factoryMethod ( ) ) ) { xmlType . addElement ( new JAnnotationElement ( ""factoryMethod"" , tp . factoryMethod ( ) ) ) ; } if ( tp . propOrder ( ) . length != 1 || ! StringUtils . isEmpty ( tp . propOrder ( ) [ 0 ] ) ) { xmlType . addElement ( new JAnnotationElement ( ""propOrder"" , tp . propOrder ( ) ) ) ; } } List < String > props = new ArrayList < String > ( ) ; for ( JavaField f : beanClass . getFields ( ) ) { props . add ( f . getParaName ( ) ) ; } if ( props . size ( ) > 1 ) { xmlType . addElement ( new JAnnotationElement ( ""propOrder"" , props ) ) ; } beanClass . addAnnotation ( xmlRootElement ) ; beanClass . addAnnotation ( xmlAccessorType ) ; beanClass . addAnnotation ( xmlType ) ; }",Smelly
" protected void populateObject ( Object object ) throws Exception { super . populateObject ( object ) ; Message info = ( Message ) object ; info . setProducerId ( createProducerId ( ""ProducerId:1"" ) ) ; info . setDestination ( createActiveMQDestination ( ""Destination:2"" ) ) ; info . setTransactionId ( createTransactionId ( ""TransactionId:3"" ) ) ; info . setOriginalDestination ( createActiveMQDestination ( ""OriginalDestination:4"" ) ) ; info . setMessageId ( createMessageId ( ""MessageId:5"" ) ) ; info . setOriginalTransactionId ( createTransactionId ( ""OriginalTransactionId:6"" ) ) ; info . setGroupID ( ""GroupID:7"" ) ; info . setGroupSequence ( 1 ) ; info . setCorrelationId ( ""CorrelationId:8"" ) ; info . setPersistent ( true ) ; info . setExpiration ( 1 ) ; info . setPriority ( ( byte ) 1 ) ; info . setReplyTo ( createActiveMQDestination ( ""ReplyTo:9"" ) ) ; info . setTimestamp ( 2 ) ; info . setType ( ""Type:10"" ) ; { byte data [ ] = ""Content:11"" . getBytes ( ) ; info . setContent ( new org . apache . activemq . util . ByteSequence ( data , 0 , data . length ) ) ; } { byte data [ ] = ""MarshalledProperties:12"" . getBytes ( ) ; info . setMarshalledProperties ( new org . apache . activemq . util . ByteSequence ( data , 0 , data . length ) ) ; } info . setDataStructure ( createDataStructure ( ""DataStructure:13"" ) ) ; info . setTargetConsumerId ( createConsumerId ( ""TargetConsumerId:14"" ) ) ; info . setCompressed ( false ) ; info . setRedeliveryCounter ( 2 ) ; { BrokerId value [ ] = new BrokerId [ 2 ] ; for ( int i = 0 ; i < 2 ; i ++ ) { value [ i ] = createBrokerId ( ""BrokerPath:15"" ) ; } info . setBrokerPath ( value ) ; } info . setArrival ( 3 ) ; info . setUserID ( ""UserID:16"" ) ; info . setRecievedByDFBridge ( true ) ; info . setDroppable ( false ) ; { BrokerId value [ ] = new BrokerId [ 2 ] ; for ( int i = 0 ; i < 2 ; i ++ ) { value [ i ] = createBrokerId ( ""Cluster:17"" ) ; } info . setCluster ( value ) ; } info . setBrokerInTime ( 4 ) ; info . setBrokerOutTime ( 5 ) ; }",Smelly
 public void tearDown ( ) throws Exception { if ( executor != null ) { executor . shutdownNow ( ) ; } store . stop ( ) ; exceptions . clear ( ) ; },Smelly
" public void restore ( InputStream backupData , TcProvider target ) throws IOException { ZipInputStream compressedTcs = new ZipInputStream ( backupData ) ; Map < String , Graph > extractedTc = new HashMap < String , Graph > ( ) ; String folder = """" ; ZipEntry entry ; ImmutableGraph metaGraph = null ; while ( ( entry = compressedTcs . getNextEntry ( ) ) != null ) { String entryName = entry . getName ( ) ; if ( entry . isDirectory ( ) ) { folder = entryName ; } else { File tempFile = File . createTempFile ( ""graph"" , ""data"" ) ; OutputStream fos = new FileOutputStream ( tempFile ) ; int count ; byte buffer [ ] = new byte [ 2048 ] ; while ( ( count = compressedTcs . read ( buffer , 0 , 2048 ) ) != - 1 ) { fos . write ( buffer , 0 , count ) ; } fos . close ( ) ; InputStream serializedGraph = new FileInputStream ( tempFile ) ; if ( entryName . equals ( ""triplecollections.nt"" ) ) { metaGraph = parser . parse ( serializedGraph , SupportedFormat . N_TRIPLE , null ) ; } else { ImmutableGraph deserializedGraph = parser . parse ( serializedGraph , SupportedFormat . N_TRIPLE , null ) ; extractedTc . put ( entryName , deserializedGraph ) ; } serializedGraph . close ( ) ; } } if ( metaGraph == null ) { throw new RuntimeException ( ""No metadata graph found in backup."" ) ; } compressedTcs . close ( ) ; { final Iterator < Triple > mGraphIterator = metaGraph . filter ( null , RDF . type , BACKUP . Graph ) ; while ( mGraphIterator . hasNext ( ) ) { GraphNode graphGN = new GraphNode ( mGraphIterator . next ( ) . getSubject ( ) , metaGraph ) ; String fileName = graphGN . getLiterals ( BACKUP . file ) . next ( ) . getLexicalForm ( ) ; Graph extracted = extractedTc . get ( fileName ) ; Graph mGraph ; boolean created = false ; try { mGraph = target . getMGraph ( ( IRI ) graphGN . getNode ( ) ) ; try { mGraph . clear ( ) ; } catch ( UnsupportedOperationException ex ) { log . warn ( ""could not restore "" + graphGN . getNode ( ) + "" as the exsting triple "" + ""collection could not be cleared"" ) ; continue ; } } catch ( NoSuchEntityException ex ) { mGraph = target . createGraph ( ( IRI ) graphGN . getNode ( ) ) ; created = true ; } try { mGraph . addAll ( extracted ) ; } catch ( Exception ex ) { String actionDone = created ? ""created"" : ""cleared"" ; log . error ( ""after the mgraph "" + graphGN . getNode ( ) + "" could successfully be "" + actionDone + "", an exception occured adding the data"" , ex ) ; } } } { final Iterator < Triple > graphIterator = metaGraph . filter ( null , RDF . type , BACKUP . Graph ) ; while ( graphIterator . hasNext ( ) ) { GraphNode graphGN = new GraphNode ( graphIterator . next ( ) . getSubject ( ) , metaGraph ) ; String fileName = graphGN . getLiterals ( BACKUP . file ) . next ( ) . getLexicalForm ( ) ; Graph extracted = extractedTc . get ( fileName ) ; try { target . deleteGraph ( ( IRI ) graphGN . getNode ( ) ) ; } catch ( UnsupportedOperationException ex ) { log . warn ( ""could not restore "" + graphGN . getNode ( ) + "" as the exsting triple "" + ""collection could not be deleted"" ) ; continue ; } catch ( NoSuchEntityException ex ) { log . debug ( ""could not remove "" + graphGN . getNode ( ) + "", no such entity"" ) ; } target . createImmutableGraph ( ( IRI ) graphGN . getNode ( ) , extracted ) ; } } for ( Map . Entry < String , Graph > pathTcPair : extractedTc . entrySet ( ) ) { Literal fileNameLit = LiteralFactory . getInstance ( ) . createTypedLiteral ( pathTcPair . getKey ( ) ) ; Iterator < Triple > graphResIterator = metaGraph . filter ( null , BACKUP . file , fileNameLit ) ; } }",Smelly
" public boolean validatePolicy ( AssertionInfoMap aim , Message message , List < WSSecurityEngineResult > results , List < WSSecurityEngineResult > signedResults , List < WSSecurityEngineResult > encryptedResults ) { Collection < AssertionInfo > ais = aim . get ( SP12Constants . SUPPORTING_TOKENS ) ; if ( ais == null || ais . isEmpty ( ) ) { return true ; } setMessage ( message ) ; setResults ( results ) ; setSignedResults ( signedResults ) ; setEncryptedResults ( encryptedResults ) ; for ( AssertionInfo ai : ais ) { SupportingToken binding = ( SupportingToken ) ai . getAssertion ( ) ; if ( SPConstants . SupportTokenType . SUPPORTING_TOKEN_SUPPORTING != binding . getTokenType ( ) ) { continue ; } ai . setAsserted ( true ) ; setSignedParts ( binding . getSignedParts ( ) ) ; setEncryptedParts ( binding . getEncryptedParts ( ) ) ; setSignedElements ( binding . getSignedElements ( ) ) ; setEncryptedElements ( binding . getEncryptedElements ( ) ) ; List < Token > tokens = binding . getTokens ( ) ; for ( Token token : tokens ) { if ( ! isTokenRequired ( token , message ) ) { continue ; } boolean processingFailed = false ; if ( token instanceof UsernameToken ) { if ( ! processUsernameTokens ( ) ) { processingFailed = true ; } } else if ( token instanceof SamlToken ) { if ( ! processSAMLTokens ( ) ) { processingFailed = true ; } } else if ( token instanceof KerberosToken ) { if ( ! processKerberosTokens ( ) ) { processingFailed = true ; } } else if ( token instanceof X509Token ) { if ( ! processX509Tokens ( ) ) { processingFailed = true ; } } else if ( token instanceof KeyValueToken ) { if ( ! processKeyValueTokens ( ) ) { processingFailed = true ; } } else if ( token instanceof SecurityContextToken ) { if ( ! processSCTokens ( ) ) { processingFailed = true ; } } else if ( ! ( token instanceof IssuedToken ) ) { processingFailed = true ; } if ( processingFailed ) { ai . setNotAsserted ( ""The received token does not match the supporting token requirement"" ) ; return false ; } } } return true ; }",Smelly
" protected Object get ( Map < String , ? extends Object > context , TimeZone timeZone , Locale locale ) { Object obj = null ; try { obj = UelUtil . evaluate ( context , new String ( this . bracketedOriginal ) ) ; } catch ( PropertyNotFoundException e ) { if ( Debug . verboseOn ( ) ) { Debug . logVerbose ( ""Error evaluating expression "" + this + "": "" + e , module ) ; } } catch ( Exception e ) { Debug . logError ( ""Error evaluating expression "" + this + "": "" + e , module ) ; } return obj ; }",No
" public static File getBaseDir ( ) { return new File ( ""."" ) . getAbsoluteFile ( ) ; }",No
" public void read ( org . apache . thrift . protocol . TProtocol prot , Adjacency struct ) throws org . apache . thrift . TException { TTupleProtocol iprot = ( TTupleProtocol ) prot ; BitSet incoming = iprot . readBitSet ( 3 ) ; if ( incoming . get ( 0 ) ) { struct . node = iprot . readString ( ) ; struct . setNodeIsSet ( true ) ; } if ( incoming . get ( 1 ) ) { { org . apache . thrift . protocol . TList _list5 = new org . apache . thrift . protocol . TList ( org . apache . thrift . protocol . TType . STRING , iprot . readI32 ( ) ) ; struct . children = new ArrayList < String > ( _list5 . size ) ; for ( int _i6 = 0 ; _i6 < _list5 . size ; ++ _i6 ) { String _elem7 ; _elem7 = iprot . readString ( ) ; struct . children . add ( _elem7 ) ; } } struct . setChildrenIsSet ( true ) ; } if ( incoming . get ( 2 ) ) { struct . adjacencyType = AdjacencyType . findByValue ( iprot . readI32 ( ) ) ; struct . setAdjacencyTypeIsSet ( true ) ; } }",Smelly
" public void read ( org . apache . thrift . protocol . TProtocol prot , getChildDataProducts_result struct ) throws org . apache . thrift . TException { TTupleProtocol iprot = ( TTupleProtocol ) prot ; BitSet incoming = iprot . readBitSet ( 5 ) ; if ( incoming . get ( 0 ) ) { { org . apache . thrift . protocol . TList _list283 = new org . apache . thrift . protocol . TList ( org . apache . thrift . protocol . TType . STRUCT , iprot . readI32 ( ) ) ; struct . success = new ArrayList < org . apache . airavata . model . data . replica . DataProductModel > ( _list283 . size ) ; org . apache . airavata . model . data . replica . DataProductModel _elem284 ; for ( int _i285 = 0 ; _i285 < _list283 . size ; ++ _i285 ) { _elem284 = new org . apache . airavata . model . data . replica . DataProductModel ( ) ; _elem284 . read ( iprot ) ; struct . success . add ( _elem284 ) ; } } struct . setSuccessIsSet ( true ) ; } if ( incoming . get ( 1 ) ) { struct . ire = new org . apache . airavata . model . error . InvalidRequestException ( ) ; struct . ire . read ( iprot ) ; struct . setIreIsSet ( true ) ; } if ( incoming . get ( 2 ) ) { struct . ace = new org . apache . airavata . model . error . AiravataClientException ( ) ; struct . ace . read ( iprot ) ; struct . setAceIsSet ( true ) ; } if ( incoming . get ( 3 ) ) { struct . ase = new org . apache . airavata . model . error . AiravataSystemException ( ) ; struct . ase . read ( iprot ) ; struct . setAseIsSet ( true ) ; } if ( incoming . get ( 4 ) ) { struct . ae = new org . apache . airavata . model . error . AuthorizationException ( ) ; struct . ae . read ( iprot ) ; struct . setAeIsSet ( true ) ; } }",Smelly
" public static Map < String , Map < AtlasResourceTypes , List < String > > > createPermissionMap ( List < PolicyDef > policyDefList , AtlasActionTypes permissionType , SimpleAtlasAuthorizer . AtlasAccessorTypes principalType ) { if ( isDebugEnabled ) { LOG . debug ( ""==> PolicyUtil createPermissionMap\nCreating Permission Map for :: {} & {}"" , permissionType , principalType ) ; } Map < String , Map < AtlasResourceTypes , List < String > > > userReadMap = new HashMap < > ( ) ; for ( PolicyDef policyDef : policyDefList ) { if ( LOG . isDebugEnabled ( ) ) { LOG . debug ( ""Processing policy def : {}"" , policyDef ) ; } Map < String , List < AtlasActionTypes > > principalMap = principalType . equals ( SimpleAtlasAuthorizer . AtlasAccessorTypes . USER ) ? policyDef . getUsers ( ) : policyDef . getGroups ( ) ; for ( Entry < String , List < AtlasActionTypes > > e : principalMap . entrySet ( ) ) { if ( ! e . getValue ( ) . contains ( permissionType ) ) { continue ; } String username = e . getKey ( ) ; Map < AtlasResourceTypes , List < String > > userResourceList = userReadMap . get ( username ) ; if ( userResourceList == null ) { if ( isDebugEnabled ) { LOG . debug ( ""Resource list not found for {}, creating it"" , username ) ; } userResourceList = new HashMap < > ( ) ; } for ( Entry < AtlasResourceTypes , List < String > > resourceTypeMap : policyDef . getResources ( ) . entrySet ( ) ) { AtlasResourceTypes type = resourceTypeMap . getKey ( ) ; List < String > resourceList = userResourceList . get ( type ) ; if ( resourceList == null ) { resourceList = new ArrayList < > ( ) ; resourceList . addAll ( resourceTypeMap . getValue ( ) ) ; } else { resourceList . removeAll ( resourceTypeMap . getValue ( ) ) ; resourceList . addAll ( resourceTypeMap . getValue ( ) ) ; } userResourceList . put ( type , resourceList ) ; } userReadMap . put ( username , userResourceList ) ; if ( LOG . isDebugEnabled ( ) ) { LOG . debug ( ""userReadMap {}"" , userReadMap ) ; } } } if ( isDebugEnabled ) { LOG . debug ( ""Returning Map for {} :: {}"" , principalType , userReadMap ) ; LOG . debug ( ""<== PolicyUtil createPermissionMap"" ) ; } return userReadMap ; }",Smelly
" public void read ( org . apache . thrift . protocol . TProtocol prot , getChildDataProducts_result struct ) throws org . apache . thrift . TException { TTupleProtocol iprot = ( TTupleProtocol ) prot ; BitSet incoming = iprot . readBitSet ( 5 ) ; if ( incoming . get ( 0 ) ) { { org . apache . thrift . protocol . TList _list283 = new org . apache . thrift . protocol . TList ( org . apache . thrift . protocol . TType . STRUCT , iprot . readI32 ( ) ) ; struct . success = new ArrayList < org . apache . airavata . model . data . replica . DataProductModel > ( _list283 . size ) ; org . apache . airavata . model . data . replica . DataProductModel _elem284 ; for ( int _i285 = 0 ; _i285 < _list283 . size ; ++ _i285 ) { _elem284 = new org . apache . airavata . model . data . replica . DataProductModel ( ) ; _elem284 . read ( iprot ) ; struct . success . add ( _elem284 ) ; } } struct . setSuccessIsSet ( true ) ; } if ( incoming . get ( 1 ) ) { struct . ire = new org . apache . airavata . model . error . InvalidRequestException ( ) ; struct . ire . read ( iprot ) ; struct . setIreIsSet ( true ) ; } if ( incoming . get ( 2 ) ) { struct . ace = new org . apache . airavata . model . error . AiravataClientException ( ) ; struct . ace . read ( iprot ) ; struct . setAceIsSet ( true ) ; } if ( incoming . get ( 3 ) ) { struct . ase = new org . apache . airavata . model . error . AiravataSystemException ( ) ; struct . ase . read ( iprot ) ; struct . setAseIsSet ( true ) ; } if ( incoming . get ( 4 ) ) { struct . ae = new org . apache . airavata . model . error . AuthorizationException ( ) ; struct . ae . read ( iprot ) ; struct . setAeIsSet ( true ) ; } }",Smelly
" public void testUserInjectAccessControlSubentries ( ) throws Exception { userConnection = IntegrationUtils . getConnectionAs ( getService ( ) , ""cn=testUser,ou=system"" , ""test"" ) ; Entry sap = new DefaultEntry ( ""ou=dummy,ou=system"" , ""objectClass: organizationalUnit"" , ""objectClass: top"" , ""ou: dummy"" , ""accessControlSubentries: ou=system"" ) ; try { userConnection . add ( sap ) ; } finally { userConnection . close ( ) ; } }",No
" protected Mapper < LongWritable , TripleWritable , NodeWritable , TripleWritable > getInstance ( ) { return new TripleGroupByObjectMapper < LongWritable > ( ) ; }",No
" public void read ( org . apache . thrift . protocol . TProtocol prot , onReceivedZeppelinResource_result struct ) throws org . apache . thrift . TException { TTupleProtocol iprot = ( TTupleProtocol ) prot ; }",No
 private static Node [ ] toArray ( NodeIterator iter ) { ArrayList list = new ArrayList ( ) ; while ( iter . hasNext ( ) ) { list . add ( iter . nextNode ( ) ) ; } Node [ ] result = new Node [ list . size ( ) ] ; list . toArray ( result ) ; return result ; },No
" private static void validateKerberosContext ( RemoteConfigurationRegistryJAASConfig config , String entryName , String principal , String keyTab , boolean useKeyTab , boolean useTicketCache ) throws Exception { AppConfigurationEntry [ ] myContextEntries = config . getAppConfigurationEntry ( entryName ) ; assertNotNull ( myContextEntries ) ; assertEquals ( 1 , myContextEntries . length ) ; AppConfigurationEntry entry = myContextEntries [ 0 ] ; assertTrue ( entry . getLoginModuleName ( ) . endsWith ( "".security.auth.module.Krb5LoginModule"" ) ) ; Map < String , ? > entryOpts = entry . getOptions ( ) ; assertEquals ( principal , entryOpts . get ( ""principal"" ) ) ; assertEquals ( keyTab , entryOpts . get ( ""keyTab"" ) ) ; assertEquals ( useKeyTab , Boolean . valueOf ( ( String ) entryOpts . get ( ""isUseKeyTab"" ) ) ) ; assertEquals ( useTicketCache , Boolean . valueOf ( ( String ) entryOpts . get ( ""isUseTicketCache"" ) ) ) ; }",No
" public abstract void watch ( Object oldObject , Object newObject , InterpreterContext context ) ;",No
" public boolean equalTo ( Op op2 , NodeIsomorphismMap labelMap ) { if ( ! ( op2 instanceof OpDatasetNames ) ) return false ; OpDatasetNames other = ( OpDatasetNames ) op2 ; return graphNode . equals ( other . graphNode ) ; }",No
" public void read ( org . apache . thrift . protocol . TProtocol prot , checkNamespaceClass_result struct ) throws org . apache . thrift . TException { TTupleProtocol iprot = ( TTupleProtocol ) prot ; BitSet incoming = iprot . readBitSet ( 3 ) ; if ( incoming . get ( 0 ) ) { struct . success = iprot . readBool ( ) ; struct . setSuccessIsSet ( true ) ; } if ( incoming . get ( 1 ) ) { struct . sec = new ThriftSecurityException ( ) ; struct . sec . read ( iprot ) ; struct . setSecIsSet ( true ) ; } if ( incoming . get ( 2 ) ) { struct . tope = new ThriftTableOperationException ( ) ; struct . tope . read ( iprot ) ; struct . setTopeIsSet ( true ) ; } }",Smelly
" public void testBasicReader ( ) throws IOException { File f = new File ( ""src/test/resources/dict/DW_SITES"" ) ; DFSFileTableReader reader = new DFSFileTableReader ( ""file://"" + f . getAbsolutePath ( ) , DFSFileTable . DELIM_AUTO , 10 ) ; while ( reader . next ( ) ) { assertEquals ( ""[-1, Korea Auction.co.kr, S, 48, 0, 111, 2009-02-11, , DW_OFFPLAT, ]"" , Arrays . toString ( reader . getRow ( ) ) ) ; break ; } reader . close ( ) ; }",No
" void deleteFile ( ActiveMQBlobMessage message ) throws IOException , JMSException ;",No
" public void read ( org . apache . thrift . protocol . TProtocol prot , getChildDataProducts_result struct ) throws org . apache . thrift . TException { TTupleProtocol iprot = ( TTupleProtocol ) prot ; BitSet incoming = iprot . readBitSet ( 5 ) ; if ( incoming . get ( 0 ) ) { { org . apache . thrift . protocol . TList _list283 = new org . apache . thrift . protocol . TList ( org . apache . thrift . protocol . TType . STRUCT , iprot . readI32 ( ) ) ; struct . success = new ArrayList < org . apache . airavata . model . data . replica . DataProductModel > ( _list283 . size ) ; org . apache . airavata . model . data . replica . DataProductModel _elem284 ; for ( int _i285 = 0 ; _i285 < _list283 . size ; ++ _i285 ) { _elem284 = new org . apache . airavata . model . data . replica . DataProductModel ( ) ; _elem284 . read ( iprot ) ; struct . success . add ( _elem284 ) ; } } struct . setSuccessIsSet ( true ) ; } if ( incoming . get ( 1 ) ) { struct . ire = new org . apache . airavata . model . error . InvalidRequestException ( ) ; struct . ire . read ( iprot ) ; struct . setIreIsSet ( true ) ; } if ( incoming . get ( 2 ) ) { struct . ace = new org . apache . airavata . model . error . AiravataClientException ( ) ; struct . ace . read ( iprot ) ; struct . setAceIsSet ( true ) ; } if ( incoming . get ( 3 ) ) { struct . ase = new org . apache . airavata . model . error . AiravataSystemException ( ) ; struct . ase . read ( iprot ) ; struct . setAseIsSet ( true ) ; } if ( incoming . get ( 4 ) ) { struct . ae = new org . apache . airavata . model . error . AuthorizationException ( ) ; struct . ae . read ( iprot ) ; struct . setAeIsSet ( true ) ; } }",No
" public static Map < String , Object > processExtendSubscriptionByOrder ( DispatchContext dctx , Map < String , ? extends Object > context ) throws GenericServiceException { Delegator delegator = dctx . getDelegator ( ) ; LocalDispatcher dispatcher = dctx . getDispatcher ( ) ; Map < String , Object > subContext = UtilMisc . makeMapWritable ( context ) ; String orderId = ( String ) context . get ( ""orderId"" ) ; Locale locale = ( Locale ) context . get ( ""locale"" ) ; Debug . logInfo ( ""In processExtendSubscriptionByOrder service with orderId: "" + orderId , module ) ; GenericValue orderHeader = null ; try { List < GenericValue > orderRoleList = delegator . findByAnd ( ""OrderRole"" , UtilMisc . toMap ( ""orderId"" , orderId , ""roleTypeId"" , ""END_USER_CUSTOMER"" ) , null , false ) ; if ( orderRoleList . size ( ) > 0 ) { GenericValue orderRole = orderRoleList . get ( 0 ) ; String partyId = ( String ) orderRole . get ( ""partyId"" ) ; subContext . put ( ""partyId"" , partyId ) ; } else { return ServiceUtil . returnFailure ( UtilProperties . getMessage ( resourceOrderError , ""OrderErrorCannotGetOrderRoleEntity"" , UtilMisc . toMap ( ""itemMsgInfo"" , orderId ) , locale ) ) ; } orderHeader = delegator . findOne ( ""OrderHeader"" , UtilMisc . toMap ( ""orderId"" , orderId ) , false ) ; if ( orderHeader == null ) { return ServiceUtil . returnError ( UtilProperties . getMessage ( resourceOrderError , ""OrderErrorNoValidOrderHeaderFoundForOrderId"" , UtilMisc . toMap ( ""orderId"" , orderId ) , locale ) ) ; } Timestamp orderCreatedDate = ( Timestamp ) orderHeader . get ( ""orderDate"" ) ; subContext . put ( ""orderCreatedDate"" , orderCreatedDate ) ; List < GenericValue > orderItemList = orderHeader . getRelated ( ""OrderItem"" , null , null , false ) ; for ( GenericValue orderItem : orderItemList ) { BigDecimal qty = orderItem . getBigDecimal ( ""quantity"" ) ; String productId = orderItem . getString ( ""productId"" ) ; if ( UtilValidate . isEmpty ( productId ) ) { continue ; } List < GenericValue > productSubscriptionResourceList = delegator . findByAnd ( ""ProductSubscriptionResource"" , UtilMisc . toMap ( ""productId"" , productId ) , null , true ) ; List < GenericValue > productSubscriptionResourceListFiltered = EntityUtil . filterByDate ( productSubscriptionResourceList , true ) ; if ( productSubscriptionResourceListFiltered . size ( ) > 0 ) { subContext . put ( ""subscriptionTypeId"" , ""PRODUCT_SUBSCR"" ) ; subContext . put ( ""productId"" , productId ) ; subContext . put ( ""orderId"" , orderId ) ; subContext . put ( ""orderItemSeqId"" , orderItem . get ( ""orderItemSeqId"" ) ) ; subContext . put ( ""inventoryItemId"" , orderItem . get ( ""fromInventoryItemId"" ) ) ; subContext . put ( ""quantity"" , Integer . valueOf ( qty . intValue ( ) ) ) ; Map < String , Object > ctx = dctx . getModelService ( ""processExtendSubscriptionByProduct"" ) . makeValid ( subContext , ModelService . IN_PARAM ) ; Map < String , Object > thisResult = dispatcher . runSync ( ""processExtendSubscriptionByProduct"" , ctx ) ; if ( ServiceUtil . isError ( thisResult ) ) { return ServiceUtil . returnError ( UtilProperties . getMessage ( resource , ""ProductSubscriptionByOrderError"" , UtilMisc . toMap ( ""orderId"" , orderId ) , locale ) , null , null , thisResult ) ; } } } } catch ( GenericEntityException e ) { Debug . logError ( e . toString ( ) , module ) ; return ServiceUtil . returnError ( e . toString ( ) ) ; } return ServiceUtil . returnSuccess ( ) ; }",Smelly
 public void testImportString ( ) { },No
" public void read ( org . apache . thrift . protocol . TProtocol prot , ErrorModel struct ) throws org . apache . thrift . TException { TTupleProtocol iprot = ( TTupleProtocol ) prot ; struct . errorId = iprot . readString ( ) ; struct . setErrorIdIsSet ( true ) ; BitSet incoming = iprot . readBitSet ( 5 ) ; if ( incoming . get ( 0 ) ) { struct . creationTime = iprot . readI64 ( ) ; struct . setCreationTimeIsSet ( true ) ; } if ( incoming . get ( 1 ) ) { struct . actualErrorMessage = iprot . readString ( ) ; struct . setActualErrorMessageIsSet ( true ) ; } if ( incoming . get ( 2 ) ) { struct . userFriendlyMessage = iprot . readString ( ) ; struct . setUserFriendlyMessageIsSet ( true ) ; } if ( incoming . get ( 3 ) ) { struct . transientOrPersistent = iprot . readBool ( ) ; struct . setTransientOrPersistentIsSet ( true ) ; } if ( incoming . get ( 4 ) ) { { org . apache . thrift . protocol . TList _list5 = new org . apache . thrift . protocol . TList ( org . apache . thrift . protocol . TType . STRING , iprot . readI32 ( ) ) ; struct . rootCauseErrorIdList = new ArrayList < String > ( _list5 . size ) ; String _elem6 ; for ( int _i7 = 0 ; _i7 < _list5 . size ; ++ _i7 ) { _elem6 = iprot . readString ( ) ; struct . rootCauseErrorIdList . add ( _elem6 ) ; } } struct . setRootCauseErrorIdListIsSet ( true ) ; } }",Smelly
" private void mergeParts ( ) throws IOException , InterruptedException { long finalOutFileSize = 0 ; long finalIndexFileSize = 0 ; final Path [ ] filename = new Path [ numSpills ] ; final String taskIdentifier = outputContext . getUniqueIdentifier ( ) ; for ( int i = 0 ; i < numSpills ; i ++ ) { filename [ i ] = spillFilePaths . get ( i ) ; finalOutFileSize += rfs . getFileStatus ( filename [ i ] ) . getLen ( ) ; } if ( numSpills == 1 ) { TezSpillRecord spillRecord = null ; if ( isFinalMergeEnabled ( ) ) { finalOutputFile = mapOutputFile . getOutputFileForWriteInVolume ( filename [ 0 ] ) ; finalIndexFile = mapOutputFile . getOutputIndexFileForWriteInVolume ( filename [ 0 ] ) ; sameVolRename ( filename [ 0 ] , finalOutputFile ) ; if ( indexCacheList . size ( ) == 0 ) { sameVolRename ( spillFileIndexPaths . get ( 0 ) , finalIndexFile ) ; spillRecord = new TezSpillRecord ( finalIndexFile , conf ) ; } else { spillRecord = indexCacheList . get ( 0 ) ; spillRecord . writeToFile ( finalIndexFile , conf ) ; } } else { List < Event > events = Lists . newLinkedList ( ) ; spillRecord = indexCacheList . get ( 0 ) ; Path indexPath = mapOutputFile . getSpillIndexFileForWrite ( numSpills - 1 , partitions * MAP_OUTPUT_INDEX_RECORD_LENGTH ) ; spillRecord . writeToFile ( indexPath , conf ) ; maybeSendEventForSpill ( events , true , spillRecord , 0 , true ) ; fileOutputByteCounter . increment ( rfs . getFileStatus ( spillFilePaths . get ( 0 ) ) . getLen ( ) ) ; } if ( spillRecord != null && reportPartitionStats ( ) ) { for ( int i = 0 ; i < spillRecord . size ( ) ; i ++ ) { partitionStats [ i ] += spillRecord . getIndex ( i ) . getPartLength ( ) ; } } numShuffleChunks . setValue ( numSpills ) ; return ; } for ( int i = indexCacheList . size ( ) ; i < numSpills ; ++ i ) { Path indexFileName = spillFileIndexPaths . get ( i ) ; indexCacheList . add ( new TezSpillRecord ( indexFileName , conf ) ) ; } if ( numSpills > 0 && ! isFinalMergeEnabled ( ) ) { maybeAddEventsForSpills ( ) ; return ; } finalOutFileSize += partitions * APPROX_HEADER_LENGTH ; finalIndexFileSize = partitions * MAP_OUTPUT_INDEX_RECORD_LENGTH ; if ( isFinalMergeEnabled ( ) ) { finalOutputFile = mapOutputFile . getOutputFileForWrite ( finalOutFileSize ) ; finalIndexFile = mapOutputFile . getOutputIndexFileForWrite ( finalIndexFileSize ) ; } else if ( numSpills == 0 ) { finalOutputFile = mapOutputFile . getSpillFileForWrite ( numSpills , finalOutFileSize ) ; finalIndexFile = mapOutputFile . getSpillIndexFileForWrite ( numSpills , finalIndexFileSize ) ; } FSDataOutputStream finalOut = rfs . create ( finalOutputFile , true , 4096 ) ; if ( numSpills == 0 ) { long rawLength = 0 ; long partLength = 0 ; TezSpillRecord sr = new TezSpillRecord ( partitions ) ; try { for ( int i = 0 ; i < partitions ; i ++ ) { long segmentStart = finalOut . getPos ( ) ; if ( ! sendEmptyPartitionDetails ) { Writer writer = new Writer ( conf , finalOut , keyClass , valClass , codec , null , null ) ; writer . close ( ) ; rawLength = writer . getRawLength ( ) ; partLength = writer . getCompressedLength ( ) ; } TezIndexRecord rec = new TezIndexRecord ( segmentStart , rawLength , partLength ) ; outputBytesWithOverheadCounter . increment ( rawLength ) ; sr . putIndex ( rec , i ) ; } sr . writeToFile ( finalIndexFile , conf ) ; } finally { finalOut . close ( ) ; } ++ numSpills ; if ( ! isFinalMergeEnabled ( ) ) { List < Event > events = Lists . newLinkedList ( ) ; maybeSendEventForSpill ( events , true , sr , 0 , true ) ; fileOutputByteCounter . increment ( rfs . getFileStatus ( finalOutputFile ) . getLen ( ) ) ; } numShuffleChunks . setValue ( numSpills ) ; return ; } else { final TezSpillRecord spillRec = new TezSpillRecord ( partitions ) ; for ( int parts = 0 ; parts < partitions ; parts ++ ) { boolean shouldWrite = false ; List < Segment > segmentList = new ArrayList < Segment > ( numSpills ) ; for ( int i = 0 ; i < numSpills ; i ++ ) { outputContext . notifyProgress ( ) ; TezIndexRecord indexRecord = indexCacheList . get ( i ) . getIndex ( parts ) ; if ( indexRecord . hasData ( ) || ! sendEmptyPartitionDetails ) { shouldWrite = true ; DiskSegment s = new DiskSegment ( rfs , filename [ i ] , indexRecord . getStartOffset ( ) , indexRecord . getPartLength ( ) , codec , ifileReadAhead , ifileReadAheadLength , ifileBufferSize , true ) ; segmentList . add ( s ) ; } if ( LOG . isDebugEnabled ( ) ) { LOG . debug ( outputContext . getDestinationVertexName ( ) + "": "" + ""TaskIdentifier="" + taskIdentifier + "" Partition="" + parts + ""Spill ="" + i + ""("" + indexRecord . getStartOffset ( ) + "","" + indexRecord . getRawLength ( ) + "", "" + indexRecord . getPartLength ( ) + "")"" ) ; } } int mergeFactor = this . conf . getInt ( TezRuntimeConfiguration . TEZ_RUNTIME_IO_SORT_FACTOR , TezRuntimeConfiguration . TEZ_RUNTIME_IO_SORT_FACTOR_DEFAULT ) ; boolean sortSegments = segmentList . size ( ) > mergeFactor ; TezRawKeyValueIterator kvIter = TezMerger . merge ( conf , rfs , keyClass , valClass , codec , segmentList , mergeFactor , new Path ( taskIdentifier ) , ( RawComparator ) ConfigUtils . getIntermediateOutputKeyComparator ( conf ) , progressable , sortSegments , true , null , spilledRecordsCounter , additionalSpillBytesRead , null ) ; long segmentStart = finalOut . getPos ( ) ; long rawLength = 0 ; long partLength = 0 ; if ( shouldWrite ) { Writer writer = new Writer ( conf , finalOut , keyClass , valClass , codec , spilledRecordsCounter , null ) ; if ( combiner == null || numSpills < minSpillsForCombine ) { TezMerger . writeFile ( kvIter , writer , progressable , TezRuntimeConfiguration . TEZ_RUNTIME_RECORDS_BEFORE_PROGRESS_DEFAULT ) ; } else { runCombineProcessor ( kvIter , writer ) ; } writer . close ( ) ; rawLength = writer . getRawLength ( ) ; partLength = writer . getCompressedLength ( ) ; } outputBytesWithOverheadCounter . increment ( rawLength ) ; final TezIndexRecord rec = new TezIndexRecord ( segmentStart , rawLength , partLength ) ; spillRec . putIndex ( rec , parts ) ; if ( reportPartitionStats ( ) ) { partitionStats [ parts ] += partLength ; } } numShuffleChunks . setValue ( 1 ) ; spillRec . writeToFile ( finalIndexFile , conf ) ; finalOut . close ( ) ; for ( int i = 0 ; i < numSpills ; i ++ ) { rfs . delete ( filename [ i ] , true ) ; } } }",Smelly
" public void read ( org . apache . thrift . protocol . TProtocol prot , getChildDataProducts_result struct ) throws org . apache . thrift . TException { TTupleProtocol iprot = ( TTupleProtocol ) prot ; BitSet incoming = iprot . readBitSet ( 5 ) ; if ( incoming . get ( 0 ) ) { { org . apache . thrift . protocol . TList _list283 = new org . apache . thrift . protocol . TList ( org . apache . thrift . protocol . TType . STRUCT , iprot . readI32 ( ) ) ; struct . success = new ArrayList < org . apache . airavata . model . data . replica . DataProductModel > ( _list283 . size ) ; org . apache . airavata . model . data . replica . DataProductModel _elem284 ; for ( int _i285 = 0 ; _i285 < _list283 . size ; ++ _i285 ) { _elem284 = new org . apache . airavata . model . data . replica . DataProductModel ( ) ; _elem284 . read ( iprot ) ; struct . success . add ( _elem284 ) ; } } struct . setSuccessIsSet ( true ) ; } if ( incoming . get ( 1 ) ) { struct . ire = new org . apache . airavata . model . error . InvalidRequestException ( ) ; struct . ire . read ( iprot ) ; struct . setIreIsSet ( true ) ; } if ( incoming . get ( 2 ) ) { struct . ace = new org . apache . airavata . model . error . AiravataClientException ( ) ; struct . ace . read ( iprot ) ; struct . setAceIsSet ( true ) ; } if ( incoming . get ( 3 ) ) { struct . ase = new org . apache . airavata . model . error . AiravataSystemException ( ) ; struct . ase . read ( iprot ) ; struct . setAseIsSet ( true ) ; } if ( incoming . get ( 4 ) ) { struct . ae = new org . apache . airavata . model . error . AuthorizationException ( ) ; struct . ae . read ( iprot ) ; struct . setAeIsSet ( true ) ; } }",Smelly
 UnivariateMatrixFunction derivative ( ) ;,No
" public static void main ( String [ ] args ) throws Exception { String s = ""line1\n\rline2\n\rline3"" ; ByteArrayInputStream in = new ByteArrayInputStream ( s . getBytes ( Charset . forName ( ""UTF-8"" ) ) ) ; ByteArrayReadLine readLine = new ByteArrayReadLine ( in ) ; String line = readLine . next ( ) ; while ( line != null ) { System . out . println ( line ) ; line = readLine . next ( ) ; } System . out . println ( ""--------- test 2 ----------"" ) ; s = ""line1\n\rline2\n\rline3\n\r\n\r"" ; in = new ByteArrayInputStream ( s . getBytes ( StandardCharsets . UTF_8 ) ) ; readLine = new ByteArrayReadLine ( in ) ; line = readLine . next ( ) ; while ( line != null ) { System . out . println ( line ) ; line = readLine . next ( ) ; } }",No
" SelectTranslator translator ( SelectQuery < ? > query , DbAdapter adapter , EntityResolver entityResolver ) ;",No
" protected void handle ( Message msg ) { Exchange exchange = msg . getExchange ( ) ; Bus bus = exchange . get ( Bus . class ) ; BindingOperationInfo boi = exchange . get ( BindingOperationInfo . class ) ; if ( null == boi ) { LOG . fine ( ""No binding operation info."" ) ; return ; } Endpoint e = exchange . get ( Endpoint . class ) ; if ( null == e ) { LOG . fine ( ""No endpoint."" ) ; return ; } EndpointInfo ei = e . getEndpointInfo ( ) ; PolicyEngine pe = bus . getExtension ( PolicyEngine . class ) ; if ( null == pe ) { return ; } List < Interceptor < ? extends Message > > interceptors = new ArrayList < Interceptor < ? extends Message > > ( ) ; Collection < Assertion > assertions = new ArrayList < Assertion > ( ) ; Policy p = ( Policy ) msg . getContextualProperty ( PolicyConstants . POLICY_OVERRIDE ) ; if ( p != null ) { EndpointPolicyImpl endpi = new EndpointPolicyImpl ( p ) ; EffectivePolicyImpl effectivePolicy = new EffectivePolicyImpl ( ) ; effectivePolicy . initialise ( endpi , ( PolicyEngineImpl ) pe , false ) ; msg . put ( EffectivePolicy . class , effectivePolicy ) ; PolicyUtils . logPolicy ( LOG , Level . FINEST , ""Using effective policy: "" , effectivePolicy . getPolicy ( ) ) ; interceptors . addAll ( effectivePolicy . getInterceptors ( ) ) ; assertions . addAll ( effectivePolicy . getChosenAlternative ( ) ) ; } else if ( MessageUtils . isRequestor ( msg ) ) { Conduit conduit = exchange . getConduit ( msg ) ; EffectivePolicy effectivePolicy = pe . getEffectiveClientRequestPolicy ( ei , boi , conduit ) ; msg . put ( EffectivePolicy . class , effectivePolicy ) ; PolicyUtils . logPolicy ( LOG , Level . FINEST , ""Using effective policy: "" , effectivePolicy . getPolicy ( ) ) ; if ( effectivePolicy != null ) { interceptors . addAll ( effectivePolicy . getInterceptors ( ) ) ; assertions . addAll ( effectivePolicy . getChosenAlternative ( ) ) ; } } else { Destination destination = exchange . getDestination ( ) ; List < List < Assertion > > incoming = CastUtils . cast ( ( List < ? > ) exchange . get ( ""ws-policy.validated.alternatives"" ) ) ; EffectivePolicy effectivePolicy = pe . getEffectiveServerResponsePolicy ( ei , boi , destination , incoming ) ; msg . put ( EffectivePolicy . class , effectivePolicy ) ; PolicyUtils . logPolicy ( LOG , Level . FINEST , ""Using effective policy: "" , effectivePolicy . getPolicy ( ) ) ; if ( effectivePolicy != null ) { interceptors . addAll ( effectivePolicy . getInterceptors ( ) ) ; assertions . addAll ( effectivePolicy . getChosenAlternative ( ) ) ; } } for ( Interceptor < ? extends Message > oi : interceptors ) { msg . getInterceptorChain ( ) . add ( oi ) ; LOG . log ( Level . FINE , ""Added interceptor of type {0}"" , oi . getClass ( ) . getSimpleName ( ) ) ; } if ( null != assertions && ! assertions . isEmpty ( ) ) { if ( LOG . isLoggable ( Level . FINEST ) ) { StringBuilder buf = new StringBuilder ( ) ; buf . append ( ""Chosen alternative: "" ) ; String nl = SystemPropertyAction . getProperty ( ""line.separator"" ) ; buf . append ( nl ) ; for ( Assertion a : assertions ) { PolicyUtils . printPolicyComponent ( a , buf , 1 ) ; } LOG . finest ( buf . toString ( ) ) ; } msg . put ( AssertionInfoMap . class , new AssertionInfoMap ( assertions ) ) ; msg . getInterceptorChain ( ) . add ( PolicyVerificationOutInterceptor . INSTANCE ) ; } }",Smelly
" private RequestSecurityTokenResponseType createResponse ( TokenValidatorResponse tokenResponse , TokenProviderResponse tokenProviderResponse , TokenRequirements tokenRequirements ) throws WSSecurityException { RequestSecurityTokenResponseType response = QNameConstants . WS_TRUST_FACTORY . createRequestSecurityTokenResponseType ( ) ; String context = tokenRequirements . getContext ( ) ; if ( context != null ) { response . setContext ( context ) ; } boolean valid = tokenResponse . getToken ( ) . getState ( ) == STATE . VALID ; String tokenType = tokenRequirements . getTokenType ( ) ; if ( valid || STSConstants . STATUS . equals ( tokenType ) ) { JAXBElement < String > jaxbTokenType = QNameConstants . WS_TRUST_FACTORY . createTokenType ( tokenType ) ; response . getAny ( ) . add ( jaxbTokenType ) ; } StatusType statusType = QNameConstants . WS_TRUST_FACTORY . createStatusType ( ) ; if ( valid ) { statusType . setCode ( STSConstants . VALID_CODE ) ; statusType . setReason ( STSConstants . VALID_REASON ) ; } else { statusType . setCode ( STSConstants . INVALID_CODE ) ; statusType . setReason ( STSConstants . INVALID_REASON ) ; } JAXBElement < StatusType > status = QNameConstants . WS_TRUST_FACTORY . createStatus ( statusType ) ; response . getAny ( ) . add ( status ) ; if ( valid && ! STSConstants . STATUS . equals ( tokenType ) && tokenProviderResponse != null && tokenProviderResponse . getToken ( ) != null ) { RequestedSecurityTokenType requestedTokenType = QNameConstants . WS_TRUST_FACTORY . createRequestedSecurityTokenType ( ) ; JAXBElement < RequestedSecurityTokenType > requestedToken = QNameConstants . WS_TRUST_FACTORY . createRequestedSecurityToken ( requestedTokenType ) ; requestedTokenType . setAny ( tokenProviderResponse . getToken ( ) ) ; response . getAny ( ) . add ( requestedToken ) ; LifetimeType lifetime = createLifetime ( tokenProviderResponse . getLifetime ( ) ) ; JAXBElement < LifetimeType > lifetimeType = QNameConstants . WS_TRUST_FACTORY . createLifetime ( lifetime ) ; response . getAny ( ) . add ( lifetimeType ) ; if ( returnReferences ) { TokenReference attachedReference = tokenProviderResponse . getAttachedReference ( ) ; RequestedReferenceType requestedAttachedReferenceType = null ; if ( attachedReference != null ) { requestedAttachedReferenceType = createRequestedReference ( attachedReference , true ) ; } else { requestedAttachedReferenceType = createRequestedReference ( tokenProviderResponse . getTokenId ( ) , tokenRequirements . getTokenType ( ) , true ) ; } JAXBElement < RequestedReferenceType > requestedAttachedReference = QNameConstants . WS_TRUST_FACTORY . createRequestedAttachedReference ( requestedAttachedReferenceType ) ; response . getAny ( ) . add ( requestedAttachedReference ) ; TokenReference unAttachedReference = tokenProviderResponse . getUnAttachedReference ( ) ; RequestedReferenceType requestedUnattachedReferenceType = null ; if ( unAttachedReference != null ) { requestedUnattachedReferenceType = createRequestedReference ( unAttachedReference , false ) ; } else { requestedUnattachedReferenceType = createRequestedReference ( tokenProviderResponse . getTokenId ( ) , tokenRequirements . getTokenType ( ) , false ) ; } JAXBElement < RequestedReferenceType > requestedUnattachedReference = QNameConstants . WS_TRUST_FACTORY . createRequestedUnattachedReference ( requestedUnattachedReferenceType ) ; response . getAny ( ) . add ( requestedUnattachedReference ) ; } } return response ; }",Smelly
" public void read ( org . apache . thrift . protocol . TProtocol prot , getChildDataProducts_result struct ) throws org . apache . thrift . TException { TTupleProtocol iprot = ( TTupleProtocol ) prot ; BitSet incoming = iprot . readBitSet ( 5 ) ; if ( incoming . get ( 0 ) ) { { org . apache . thrift . protocol . TList _list283 = new org . apache . thrift . protocol . TList ( org . apache . thrift . protocol . TType . STRUCT , iprot . readI32 ( ) ) ; struct . success = new ArrayList < org . apache . airavata . model . data . replica . DataProductModel > ( _list283 . size ) ; org . apache . airavata . model . data . replica . DataProductModel _elem284 ; for ( int _i285 = 0 ; _i285 < _list283 . size ; ++ _i285 ) { _elem284 = new org . apache . airavata . model . data . replica . DataProductModel ( ) ; _elem284 . read ( iprot ) ; struct . success . add ( _elem284 ) ; } } struct . setSuccessIsSet ( true ) ; } if ( incoming . get ( 1 ) ) { struct . ire = new org . apache . airavata . model . error . InvalidRequestException ( ) ; struct . ire . read ( iprot ) ; struct . setIreIsSet ( true ) ; } if ( incoming . get ( 2 ) ) { struct . ace = new org . apache . airavata . model . error . AiravataClientException ( ) ; struct . ace . read ( iprot ) ; struct . setAceIsSet ( true ) ; } if ( incoming . get ( 3 ) ) { struct . ase = new org . apache . airavata . model . error . AiravataSystemException ( ) ; struct . ase . read ( iprot ) ; struct . setAseIsSet ( true ) ; } if ( incoming . get ( 4 ) ) { struct . ae = new org . apache . airavata . model . error . AuthorizationException ( ) ; struct . ae . read ( iprot ) ; struct . setAeIsSet ( true ) ; } }",Smelly
" public void read ( org . apache . thrift . protocol . TProtocol prot , show_compact_result struct ) throws org . apache . thrift . TException { TTupleProtocol iprot = ( TTupleProtocol ) prot ; BitSet incoming = iprot . readBitSet ( 1 ) ; if ( incoming . get ( 0 ) ) { struct . success = new ShowCompactResponse ( ) ; struct . success . read ( iprot ) ; struct . setSuccessIsSet ( true ) ; } }",Smelly
" protected ResWrap < Property > doDeserialize ( final JsonParser parser ) throws IOException { final ObjectNode tree = parser . getCodec ( ) . readTree ( parser ) ; final String metadataETag ; final URI contextURL ; final Property property = new Property ( ) ; if ( tree . hasNonNull ( Constants . JSON_METADATA_ETAG ) ) { metadataETag = tree . get ( Constants . JSON_METADATA_ETAG ) . textValue ( ) ; tree . remove ( Constants . JSON_METADATA_ETAG ) ; } else { metadataETag = null ; } if ( tree . hasNonNull ( Constants . JSON_CONTEXT ) ) { contextURL = URI . create ( tree . get ( Constants . JSON_CONTEXT ) . textValue ( ) ) ; property . setName ( StringUtils . substringAfterLast ( contextURL . toASCIIString ( ) , ""/"" ) ) ; tree . remove ( Constants . JSON_CONTEXT ) ; } else if ( tree . hasNonNull ( Constants . JSON_METADATA ) ) { contextURL = URI . create ( tree . get ( Constants . JSON_METADATA ) . textValue ( ) ) ; property . setType ( new EdmTypeInfo . Builder ( ) . setTypeExpression ( StringUtils . substringAfterLast ( contextURL . toASCIIString ( ) , ""#"" ) ) . build ( ) . internal ( ) ) ; tree . remove ( Constants . JSON_METADATA ) ; } else { contextURL = null ; } if ( tree . has ( Constants . JSON_TYPE ) ) { property . setType ( new EdmTypeInfo . Builder ( ) . setTypeExpression ( tree . get ( Constants . JSON_TYPE ) . textValue ( ) ) . build ( ) . internal ( ) ) ; tree . remove ( Constants . JSON_TYPE ) ; } if ( tree . has ( Constants . JSON_NULL ) && tree . get ( Constants . JSON_NULL ) . asBoolean ( ) ) { property . setValue ( ValueType . PRIMITIVE , null ) ; tree . remove ( Constants . JSON_NULL ) ; } if ( property . getValue ( ) == null ) { try { value ( property , tree . has ( Constants . VALUE ) ? tree . get ( Constants . VALUE ) : tree , parser . getCodec ( ) ) ; } catch ( final EdmPrimitiveTypeException e ) { throw new IOException ( e ) ; } tree . remove ( Constants . VALUE ) ; } Set < String > toRemove = new HashSet < String > ( ) ; for ( final Iterator < Map . Entry < String , JsonNode > > itor = tree . fields ( ) ; itor . hasNext ( ) ; ) { final Map . Entry < String , JsonNode > field = itor . next ( ) ; if ( field . getKey ( ) . charAt ( 0 ) == '@' ) { final Annotation annotation = new Annotation ( ) ; annotation . setTerm ( field . getKey ( ) . substring ( 1 ) ) ; try { value ( annotation , field . getValue ( ) , parser . getCodec ( ) ) ; } catch ( final EdmPrimitiveTypeException e ) { throw new IOException ( e ) ; } property . getAnnotations ( ) . add ( annotation ) ; } else if ( field . getKey ( ) . charAt ( 0 ) == '#' ) { final Operation operation = new Operation ( ) ; operation . setMetadataAnchor ( field . getKey ( ) ) ; final ObjectNode opNode = ( ObjectNode ) tree . get ( field . getKey ( ) ) ; operation . setTitle ( opNode . get ( Constants . ATTR_TITLE ) . asText ( ) ) ; operation . setTarget ( URI . create ( opNode . get ( Constants . ATTR_TARGET ) . asText ( ) ) ) ; property . getOperations ( ) . add ( operation ) ; toRemove . add ( field . getKey ( ) ) ; } } tree . remove ( toRemove ) ; return new ResWrap < Property > ( contextURL , metadataETag , property ) ; }",Smelly
" public void read ( org . apache . thrift . protocol . TProtocol prot , getChildDataProducts_result struct ) throws org . apache . thrift . TException { TTupleProtocol iprot = ( TTupleProtocol ) prot ; BitSet incoming = iprot . readBitSet ( 5 ) ; if ( incoming . get ( 0 ) ) { { org . apache . thrift . protocol . TList _list283 = new org . apache . thrift . protocol . TList ( org . apache . thrift . protocol . TType . STRUCT , iprot . readI32 ( ) ) ; struct . success = new ArrayList < org . apache . airavata . model . data . replica . DataProductModel > ( _list283 . size ) ; org . apache . airavata . model . data . replica . DataProductModel _elem284 ; for ( int _i285 = 0 ; _i285 < _list283 . size ; ++ _i285 ) { _elem284 = new org . apache . airavata . model . data . replica . DataProductModel ( ) ; _elem284 . read ( iprot ) ; struct . success . add ( _elem284 ) ; } } struct . setSuccessIsSet ( true ) ; } if ( incoming . get ( 1 ) ) { struct . ire = new org . apache . airavata . model . error . InvalidRequestException ( ) ; struct . ire . read ( iprot ) ; struct . setIreIsSet ( true ) ; } if ( incoming . get ( 2 ) ) { struct . ace = new org . apache . airavata . model . error . AiravataClientException ( ) ; struct . ace . read ( iprot ) ; struct . setAceIsSet ( true ) ; } if ( incoming . get ( 3 ) ) { struct . ase = new org . apache . airavata . model . error . AiravataSystemException ( ) ; struct . ase . read ( iprot ) ; struct . setAseIsSet ( true ) ; } if ( incoming . get ( 4 ) ) { struct . ae = new org . apache . airavata . model . error . AuthorizationException ( ) ; struct . ae . read ( iprot ) ; struct . setAeIsSet ( true ) ; } }",Smelly
" public void read ( org . apache . thrift . protocol . TProtocol prot , Index struct ) throws org . apache . thrift . TException { TTupleProtocol iprot = ( TTupleProtocol ) prot ; BitSet incoming = iprot . readBitSet ( 10 ) ; if ( incoming . get ( 0 ) ) { struct . indexName = iprot . readString ( ) ; struct . setIndexNameIsSet ( true ) ; } if ( incoming . get ( 1 ) ) { struct . indexHandlerClass = iprot . readString ( ) ; struct . setIndexHandlerClassIsSet ( true ) ; } if ( incoming . get ( 2 ) ) { struct . dbName = iprot . readString ( ) ; struct . setDbNameIsSet ( true ) ; } if ( incoming . get ( 3 ) ) { struct . origTableName = iprot . readString ( ) ; struct . setOrigTableNameIsSet ( true ) ; } if ( incoming . get ( 4 ) ) { struct . createTime = iprot . readI32 ( ) ; struct . setCreateTimeIsSet ( true ) ; } if ( incoming . get ( 5 ) ) { struct . lastAccessTime = iprot . readI32 ( ) ; struct . setLastAccessTimeIsSet ( true ) ; } if ( incoming . get ( 6 ) ) { struct . indexTableName = iprot . readString ( ) ; struct . setIndexTableNameIsSet ( true ) ; } if ( incoming . get ( 7 ) ) { struct . sd = new StorageDescriptor ( ) ; struct . sd . read ( iprot ) ; struct . setSdIsSet ( true ) ; } if ( incoming . get ( 8 ) ) { { org . apache . thrift . protocol . TMap _map232 = new org . apache . thrift . protocol . TMap ( org . apache . thrift . protocol . TType . STRING , org . apache . thrift . protocol . TType . STRING , iprot . readI32 ( ) ) ; struct . parameters = new HashMap < String , String > ( 2 * _map232 . size ) ; for ( int _i233 = 0 ; _i233 < _map232 . size ; ++ _i233 ) { String _key234 ; String _val235 ; _key234 = iprot . readString ( ) ; _val235 = iprot . readString ( ) ; struct . parameters . put ( _key234 , _val235 ) ; } } struct . setParametersIsSet ( true ) ; } if ( incoming . get ( 9 ) ) { struct . deferredRebuild = iprot . readBool ( ) ; struct . setDeferredRebuildIsSet ( true ) ; } }",Smelly
" public String toString ( ) { StringBuilder builder = null ; for ( MapEntry entry : getEntries ( ) ) { if ( builder == null ) { builder = new StringBuilder ( ""{ "" ) ; } else { builder . append ( "", "" ) ; } builder . append ( entry ) ; } if ( builder == null ) { return ""{}"" ; } else { builder . append ( "" }"" ) ; return builder . toString ( ) ; } }",No
" public void parse ( InputStream stream , ContentHandler ignore , Metadata metadata , ParseContext context ) throws IOException , SAXException , TikaException { if ( maxEmbeddedResources > - 1 && metadatas . size ( ) >= maxEmbeddedResources ) { hitMaxEmbeddedResources = true ; return ; } String objectName = getResourceName ( metadata ) ; String objectLocation = this . location + objectName ; metadata . add ( EMBEDDED_RESOURCE_PATH , objectLocation ) ; ContentHandler localHandler = contentHandlerFactory . getNewContentHandler ( ) ; Parser preContextParser = context . get ( Parser . class ) ; context . set ( Parser . class , new EmbeddedParserDecorator ( objectLocation ) ) ; long started = new Date ( ) . getTime ( ) ; try { super . parse ( stream , localHandler , metadata , context ) ; } catch ( SAXException e ) { boolean wlr = isWriteLimitReached ( e ) ; if ( wlr == true ) { metadata . add ( WRITE_LIMIT_REACHED , ""true"" ) ; } else { if ( catchEmbeddedExceptions ) { String trace = ExceptionUtils . getStackTrace ( e ) ; metadata . set ( EMBEDDED_EXCEPTION , trace ) ; } else { throw e ; } } } catch ( IOException | TikaException e ) { if ( catchEmbeddedExceptions ) { String trace = ExceptionUtils . getStackTrace ( e ) ; metadata . set ( EMBEDDED_EXCEPTION , trace ) ; } else { throw e ; } } finally { context . set ( Parser . class , preContextParser ) ; long elapsedMillis = new Date ( ) . getTime ( ) - started ; metadata . set ( PARSE_TIME_MILLIS , Long . toString ( elapsedMillis ) ) ; } if ( maxEmbeddedResources > - 1 && metadatas . size ( ) >= maxEmbeddedResources ) { hitMaxEmbeddedResources = true ; return ; } addContent ( localHandler , metadata ) ; metadatas . add ( deepCopy ( metadata ) ) ; }",Smelly
 public String getTypeName ( ) { return type ; },No
" public void read ( org . apache . thrift . protocol . TProtocol prot , TColumn struct ) throws org . apache . thrift . TException { TTupleProtocol iprot = ( TTupleProtocol ) prot ; BitSet incoming = iprot . readBitSet ( 3 ) ; if ( incoming . get ( 0 ) ) { struct . columnFamily = iprot . readBinary ( ) ; struct . setColumnFamilyIsSet ( true ) ; } if ( incoming . get ( 1 ) ) { struct . columnQualifier = iprot . readBinary ( ) ; struct . setColumnQualifierIsSet ( true ) ; } if ( incoming . get ( 2 ) ) { struct . columnVisibility = iprot . readBinary ( ) ; struct . setColumnVisibilityIsSet ( true ) ; } }",Smelly
 public void visit ( AttributeGenerator n ) throws JasperException { doVisit ( n ) ; },No
" protected void init ( ) { super . init ( ) ; getSharedResources ( ) . add ( ""cancelButton"" , new DefaultButtonImageResource ( ""Cancel"" ) ) ; }",No
" public void put ( int field$ , java . lang . Object value$ ) { switch ( field$ ) { case 0 : pageKey = ( java . lang . CharSequence ) value$ ; break ; case 1 : profileId = ( java . lang . Integer ) value$ ; break ; default : throw new org . apache . avro . AvroRuntimeException ( ""Bad index"" ) ; } }",No
 public int getInnerValueCountAt ( int index ) { return offsets . getAccessor ( ) . get ( index + 1 ) - offsets . getAccessor ( ) . get ( index ) ; },No
" public void testJPQLWithoutIdentificationVariable ( ) { try { em . createQuery ( ""select o from ManyOneEntity o "" + ""where rel.name = :name"" ) . compile ( ) ; } catch ( RuntimeException e ) { assertTrue ( e . getMessage ( ) . contains ( ""Perhaps you forgot to prefix the path"" ) ) ; } }",No
" public void read ( org . apache . thrift . protocol . TProtocol prot , getFollowing_result struct ) throws org . apache . thrift . TException { TTupleProtocol iprot = ( TTupleProtocol ) prot ; BitSet incoming = iprot . readBitSet ( 1 ) ; if ( incoming . get ( 0 ) ) { struct . success = new Key ( ) ; struct . success . read ( iprot ) ; struct . setSuccessIsSet ( true ) ; } }",Smelly
" List getNextKnuthElements ( LayoutContext context , int alignment , Stack lmStack , Position positionAtIPDChange , LayoutManager restartAtLM ) ;",No
 public void check ( Put p ) { },No
" public void read ( org . apache . thrift . protocol . TProtocol prot , getActiveLogs_result struct ) throws org . apache . thrift . TException { TTupleProtocol iprot = ( TTupleProtocol ) prot ; BitSet incoming = iprot . readBitSet ( 1 ) ; if ( incoming . get ( 0 ) ) { { org . apache . thrift . protocol . TList _list327 = new org . apache . thrift . protocol . TList ( org . apache . thrift . protocol . TType . STRING , iprot . readI32 ( ) ) ; struct . success = new ArrayList < String > ( _list327 . size ) ; for ( int _i328 = 0 ; _i328 < _list327 . size ; ++ _i328 ) { String _elem329 ; _elem329 = iprot . readString ( ) ; struct . success . add ( _elem329 ) ; } } struct . setSuccessIsSet ( true ) ; } }",Smelly
 void set ( long value ) ;,No
" public void read ( org . apache . thrift . protocol . TProtocol prot , getChildDataProducts_result struct ) throws org . apache . thrift . TException { TTupleProtocol iprot = ( TTupleProtocol ) prot ; BitSet incoming = iprot . readBitSet ( 5 ) ; if ( incoming . get ( 0 ) ) { { org . apache . thrift . protocol . TList _list283 = new org . apache . thrift . protocol . TList ( org . apache . thrift . protocol . TType . STRUCT , iprot . readI32 ( ) ) ; struct . success = new ArrayList < org . apache . airavata . model . data . replica . DataProductModel > ( _list283 . size ) ; org . apache . airavata . model . data . replica . DataProductModel _elem284 ; for ( int _i285 = 0 ; _i285 < _list283 . size ; ++ _i285 ) { _elem284 = new org . apache . airavata . model . data . replica . DataProductModel ( ) ; _elem284 . read ( iprot ) ; struct . success . add ( _elem284 ) ; } } struct . setSuccessIsSet ( true ) ; } if ( incoming . get ( 1 ) ) { struct . ire = new org . apache . airavata . model . error . InvalidRequestException ( ) ; struct . ire . read ( iprot ) ; struct . setIreIsSet ( true ) ; } if ( incoming . get ( 2 ) ) { struct . ace = new org . apache . airavata . model . error . AiravataClientException ( ) ; struct . ace . read ( iprot ) ; struct . setAceIsSet ( true ) ; } if ( incoming . get ( 3 ) ) { struct . ase = new org . apache . airavata . model . error . AiravataSystemException ( ) ; struct . ase . read ( iprot ) ; struct . setAseIsSet ( true ) ; } if ( incoming . get ( 4 ) ) { struct . ae = new org . apache . airavata . model . error . AuthorizationException ( ) ; struct . ae . read ( iprot ) ; struct . setAeIsSet ( true ) ; } }",No
" private static Implementation getMapType ( TypeDescriptor valueType , int index ) { if ( valueType . isSubtypeOf ( TypeDescriptor . of ( Map . class ) ) ) { TypeDescriptor < Collection < ? > > map = valueType . getSupertype ( Map . class ) ; if ( map . getType ( ) instanceof ParameterizedType ) { ParameterizedType ptype = ( ParameterizedType ) map . getType ( ) ; java . lang . reflect . Type [ ] params = ptype . getActualTypeArguments ( ) ; return FixedValue . reference ( params [ index ] ) ; } else { throw new RuntimeException ( ""Map type is not parameterized! "" + map ) ; } } return FixedValue . nullValue ( ) ; }",No
" public String toString ( ) { return MoreObjects . toStringHelper ( BigtableConfig . class ) . add ( ""projectId"" , getProjectId ( ) ) . add ( ""instanceId"" , getInstanceId ( ) ) . add ( ""tableId"" , getTableId ( ) ) . add ( ""bigtableOptionsConfigurator"" , getBigtableOptionsConfigurator ( ) == null ? null : getBigtableOptionsConfigurator ( ) . getClass ( ) . getName ( ) ) . add ( ""options"" , getBigtableOptions ( ) ) . toString ( ) ; }",No
" public void mergeAffectedComponents ( final Set < AffectedComponentEntity > affectedComponents , final Map < NodeIdentifier , Set < AffectedComponentEntity > > affectedComponentMap ) { final Map < String , Integer > activeThreadCounts = new HashMap < > ( ) ; final Map < String , String > states = new HashMap < > ( ) ; final Map < String , PermissionsDTO > canReads = new HashMap < > ( ) ; for ( final Map . Entry < NodeIdentifier , Set < AffectedComponentEntity > > nodeEntry : affectedComponentMap . entrySet ( ) ) { final Set < AffectedComponentEntity > nodeAffectedComponents = nodeEntry . getValue ( ) ; if ( nodeAffectedComponents != null ) { for ( final AffectedComponentEntity nodeAffectedComponentEntity : nodeAffectedComponents ) { final AffectedComponentDTO nodeAffectedComponent = nodeAffectedComponentEntity . getComponent ( ) ; if ( nodeAffectedComponentEntity . getPermissions ( ) . getCanRead ( ) ) { if ( nodeAffectedComponent . getActiveThreadCount ( ) != null && nodeAffectedComponent . getActiveThreadCount ( ) > 0 ) { final Integer current = activeThreadCounts . get ( nodeAffectedComponent . getId ( ) ) ; if ( current == null ) { activeThreadCounts . put ( nodeAffectedComponent . getId ( ) , nodeAffectedComponent . getActiveThreadCount ( ) ) ; } else { activeThreadCounts . put ( nodeAffectedComponent . getId ( ) , nodeAffectedComponent . getActiveThreadCount ( ) + current ) ; } } final String state = states . get ( nodeAffectedComponent . getId ( ) ) ; if ( state == null ) { if ( ControllerServiceState . DISABLING . name ( ) . equals ( nodeAffectedComponent . getState ( ) ) ) { states . put ( nodeAffectedComponent . getId ( ) , ControllerServiceState . DISABLING . name ( ) ) ; } else if ( ControllerServiceState . ENABLING . name ( ) . equals ( nodeAffectedComponent . getState ( ) ) ) { states . put ( nodeAffectedComponent . getId ( ) , ControllerServiceState . ENABLING . name ( ) ) ; } } } final PermissionsDTO mergedPermissions = canReads . get ( nodeAffectedComponentEntity . getId ( ) ) ; final PermissionsDTO permissions = nodeAffectedComponentEntity . getPermissions ( ) ; if ( permissions != null ) { if ( mergedPermissions == null ) { canReads . put ( nodeAffectedComponentEntity . getId ( ) , permissions ) ; } else { PermissionsDtoMerger . mergePermissions ( mergedPermissions , permissions ) ; } } } } } if ( affectedComponents != null ) { for ( final AffectedComponentEntity affectedComponent : affectedComponents ) { final PermissionsDTO permissions = canReads . get ( affectedComponent . getId ( ) ) ; if ( permissions != null && permissions . getCanRead ( ) != null && permissions . getCanRead ( ) ) { final Integer activeThreadCount = activeThreadCounts . get ( affectedComponent . getId ( ) ) ; if ( activeThreadCount != null ) { affectedComponent . getComponent ( ) . setActiveThreadCount ( activeThreadCount ) ; } final String state = states . get ( affectedComponent . getId ( ) ) ; if ( state != null ) { affectedComponent . getComponent ( ) . setState ( state ) ; } } else { affectedComponent . setPermissions ( permissions ) ; affectedComponent . setComponent ( null ) ; } } } }",Smelly
" public ParseResult filter ( Content content , ParseResult parseResult , HTMLMetaTags metaTags , DocumentFragment doc ) { for ( int i = 0 ; i < this . htmlParseFilters . length ; i ++ ) { parseResult = htmlParseFilters [ i ] . filter ( content , parseResult , metaTags , doc ) ; if ( ! parseResult . isSuccess ( ) ) { parseResult . filter ( ) ; return parseResult ; } } return parseResult ; }",No
 public DbAdapter getAdapter ( ) { return adapter ; },No
" static String add_escapes ( String str ) { StringBuffer retval = new StringBuffer ( ) ; char ch ; for ( int i = 0 ; i < str . length ( ) ; i ++ ) { switch ( str . charAt ( i ) ) { case 0 : continue ; case '\b' : retval . append ( ""\\b"" ) ; continue ; case '\t' : retval . append ( ""\\t"" ) ; continue ; case '\n' : retval . append ( ""\\n"" ) ; continue ; case '\f' : retval . append ( ""\\f"" ) ; continue ; case '\r' : retval . append ( ""\\r"" ) ; continue ; case '\""' : retval . append ( ""\\\"""" ) ; continue ; case '\'' : retval . append ( ""\\\'"" ) ; continue ; case '\\' : retval . append ( ""\\\\"" ) ; continue ; default : if ( ( ch = str . charAt ( i ) ) < 0x20 || ch > 0x7e ) { String s = ""0000"" + Integer . toString ( ch , 16 ) ; retval . append ( ""\\u"" + s . substring ( s . length ( ) - 4 , s . length ( ) ) ) ; } else { retval . append ( ch ) ; } continue ; } } return retval . toString ( ) ; }",Smelly
" public void jetstreamCreateDeleteNetworkTest ( ) { try { CloudInterface cloudIntf = new OpenstackIntfImpl ( ""jetstream_openrc.properties"" ) ; String networkName = properties . getProperty ( ""jetstream_network_name"" ) ; String subnetCIDR = properties . getProperty ( ""jetstream_subnet_cidr"" ) ; Integer ipVersion = Integer . valueOf ( properties . getProperty ( ""jetstream_ip_version"" , Constants . OS_IP_VERSION_DEFAULT . toString ( ) ) ) ; String externalGateway = properties . getProperty ( ""jetstream_public_network_name"" ) ; String subnetName = ""subnet-"" + networkName ; String routerName = ""router-"" + networkName ; logger . info ( ""Creating network with name = "" + networkName ) ; Network network = ( Network ) cloudIntf . createNetwork ( networkName ) ; assertTrue ( network != null && network . getName ( ) . equals ( networkName ) ) ; logger . info ( ""Creating subnet with name = "" + subnetName + "", and CIDR = "" + subnetCIDR + "", and version = "" + ipVersion ) ; Subnet subnet = ( Subnet ) cloudIntf . createSubnet ( subnetName , networkName , subnetCIDR , ipVersion ) ; assertTrue ( subnet != null && subnet . getName ( ) . equals ( subnetName ) && subnet . getCidr ( ) . equals ( subnetCIDR ) && subnet . getIpVersion ( ) . getVersion ( ) == ipVersion . intValue ( ) ) ; logger . info ( ""Creating router with name = "" + routerName + "", and external gateway = "" + externalGateway ) ; Router router = ( Router ) cloudIntf . createRouter ( routerName , externalGateway ) ; assertTrue ( router != null && router . getName ( ) . equals ( routerName ) ) ; logger . info ( ""Creating interface between router = "" + routerName + "", and subnet = "" + subnetName ) ; RouterInterface iface = ( RouterInterface ) cloudIntf . createRouterSubnetInterface ( routerName , subnetName ) ; assertTrue ( iface != null && iface . getSubnetId ( ) . equals ( subnet . getId ( ) ) ) ; logger . info ( ""Deleting interface between router = "" + routerName + "", and subnet = "" + subnetName ) ; cloudIntf . deleteRouterSubnetInterface ( routerName , subnetName ) ; logger . info ( ""Creating router with name = "" + routerName ) ; cloudIntf . deleteRouter ( routerName ) ; logger . info ( ""Creating subnet with name = "" + subnetName ) ; cloudIntf . deleteSubnet ( subnetName ) ; logger . info ( ""Deleting network with name = "" + networkName ) ; cloudIntf . deleteNetwork ( networkName ) ; } catch ( Exception ex ) { ex . printStackTrace ( ) ; fail ( ) ; } }",Smelly
 public Vertex getBaseVertex ( ) { return this . adjacentVertex ; },No
" public void read ( org . apache . thrift . protocol . TProtocol prot , show_compact_result struct ) throws org . apache . thrift . TException { TTupleProtocol iprot = ( TTupleProtocol ) prot ; BitSet incoming = iprot . readBitSet ( 1 ) ; if ( incoming . get ( 0 ) ) { struct . success = new ShowCompactResponse ( ) ; struct . success . read ( iprot ) ; struct . setSuccessIsSet ( true ) ; } }",Smelly
" void start ( ) throws Exception { System . out . println ( ""Run standard"" ) ; run ( ) ; System . out . println ( ""Run span"" ) ; mode = SPAN ; run ( ) ; }",No
 CreateAdvBuilder makeAdv ( ) ;,No
" public void createNifiKeystoresAndTrustStores ( StandaloneConfig standaloneConfig ) throws GeneralSecurityException , IOException { File baseDir = standaloneConfig . getBaseDir ( ) ; if ( ! baseDir . exists ( ) && ! baseDir . mkdirs ( ) ) { throw new IOException ( baseDir + "" doesn't exist and unable to create it."" ) ; } if ( ! baseDir . isDirectory ( ) ) { throw new IOException ( ""Expected directory to output to"" ) ; } String signingAlgorithm = standaloneConfig . getSigningAlgorithm ( ) ; int days = standaloneConfig . getDays ( ) ; String keyPairAlgorithm = standaloneConfig . getKeyPairAlgorithm ( ) ; int keySize = standaloneConfig . getKeySize ( ) ; File nifiCert = new File ( baseDir , NIFI_CERT + "".pem"" ) ; File nifiKey = new File ( baseDir , NIFI_KEY + "".key"" ) ; X509Certificate certificate ; KeyPair caKeyPair ; if ( logger . isInfoEnabled ( ) ) { logger . info ( ""Running standalone certificate generation with output directory "" + baseDir ) ; } if ( nifiCert . exists ( ) ) { if ( ! nifiKey . exists ( ) ) { throw new IOException ( nifiCert + "" exists already, but "" + nifiKey + "" does not, we need both certificate and key to continue with an existing CA."" ) ; } try ( FileReader pemEncodedCertificate = new FileReader ( nifiCert ) ) { certificate = TlsHelper . parseCertificate ( pemEncodedCertificate ) ; } try ( FileReader pemEncodedKeyPair = new FileReader ( nifiKey ) ) { caKeyPair = TlsHelper . parseKeyPairFromReader ( pemEncodedKeyPair ) ; } List < X509Certificate > signingCertificates = new ArrayList < > ( ) ; if ( ! StringUtils . isBlank ( standaloneConfig . getAdditionalCACertificate ( ) ) ) { X509Certificate signingCertificate ; final File additionalCACertFile = new File ( standaloneConfig . getAdditionalCACertificate ( ) ) ; if ( ! additionalCACertFile . exists ( ) ) { throw new IOException ( ""The additional CA certificate does not exist at "" + additionalCACertFile . getAbsolutePath ( ) ) ; } try ( FileReader pemEncodedCACertificate = new FileReader ( additionalCACertFile ) ) { signingCertificate = TlsHelper . parseCertificate ( pemEncodedCACertificate ) ; } signingCertificates . add ( signingCertificate ) ; } signingCertificates . add ( certificate ) ; boolean signatureValid = TlsHelper . verifyCertificateSignature ( certificate , signingCertificates ) ; if ( ! signatureValid ) { throw new SignatureException ( ""The signing certificate was not signed by any known certificates"" ) ; } if ( ! caKeyPair . getPublic ( ) . equals ( certificate . getPublicKey ( ) ) ) { throw new IOException ( ""Expected "" + nifiKey + "" to correspond to CA certificate at "" + nifiCert ) ; } if ( logger . isInfoEnabled ( ) ) { logger . info ( ""Using existing CA certificate "" + nifiCert + "" and key "" + nifiKey ) ; } } else if ( nifiKey . exists ( ) ) { throw new IOException ( nifiKey + "" exists already, but "" + nifiCert + "" does not, we need both certificate and key to continue with an existing CA."" ) ; } else { TlsCertificateAuthorityManager tlsCertificateAuthorityManager = new TlsCertificateAuthorityManager ( standaloneConfig ) ; KeyStore . PrivateKeyEntry privateKeyEntry = tlsCertificateAuthorityManager . getOrGenerateCertificateAuthority ( ) ; certificate = ( X509Certificate ) privateKeyEntry . getCertificateChain ( ) [ 0 ] ; caKeyPair = new KeyPair ( certificate . getPublicKey ( ) , privateKeyEntry . getPrivateKey ( ) ) ; try ( PemWriter pemWriter = new PemWriter ( new OutputStreamWriter ( outputStreamFactory . create ( nifiCert ) ) ) ) { pemWriter . writeObject ( new JcaMiscPEMGenerator ( certificate ) ) ; } try ( PemWriter pemWriter = new PemWriter ( new OutputStreamWriter ( outputStreamFactory . create ( nifiKey ) ) ) ) { pemWriter . writeObject ( new JcaMiscPEMGenerator ( caKeyPair ) ) ; } if ( logger . isInfoEnabled ( ) ) { logger . info ( ""Generated new CA certificate "" + nifiCert + "" and key "" + nifiKey ) ; } } NiFiPropertiesWriterFactory niFiPropertiesWriterFactory = standaloneConfig . getNiFiPropertiesWriterFactory ( ) ; boolean overwrite = standaloneConfig . isOverwrite ( ) ; List < InstanceDefinition > instanceDefinitions = standaloneConfig . getInstanceDefinitions ( ) ; if ( instanceDefinitions . isEmpty ( ) && logger . isInfoEnabled ( ) ) { logger . info ( ""No "" + TlsToolkitStandaloneCommandLine . HOSTNAMES_ARG + "" specified, not generating any host certificates or configuration."" ) ; } for ( InstanceDefinition instanceDefinition : instanceDefinitions ) { String hostname = instanceDefinition . getHostname ( ) ; File hostDir ; int hostIdentifierNumber = instanceDefinition . getInstanceIdentifier ( ) . getNumber ( ) ; if ( hostIdentifierNumber == 1 ) { hostDir = new File ( baseDir , hostname ) ; } else { hostDir = new File ( baseDir , hostname + ""_"" + hostIdentifierNumber ) ; } TlsClientConfig tlsClientConfig = new TlsClientConfig ( standaloneConfig ) ; File keystore = new File ( hostDir , ""keystore."" + tlsClientConfig . getKeyStoreType ( ) . toLowerCase ( ) ) ; File truststore = new File ( hostDir , ""truststore."" + tlsClientConfig . getTrustStoreType ( ) . toLowerCase ( ) ) ; if ( hostDir . exists ( ) ) { if ( ! hostDir . isDirectory ( ) ) { throw new IOException ( hostDir + "" exists but is not a directory."" ) ; } else if ( overwrite ) { if ( logger . isInfoEnabled ( ) ) { logger . info ( ""Overwriting any existing ssl configuration in "" + hostDir ) ; } keystore . delete ( ) ; if ( keystore . exists ( ) ) { throw new IOException ( ""Keystore "" + keystore + "" already exists and couldn't be deleted."" ) ; } truststore . delete ( ) ; if ( truststore . exists ( ) ) { throw new IOException ( ""Truststore "" + truststore + "" already exists and couldn't be deleted."" ) ; } } else { throw new IOException ( hostDir + "" exists and overwrite is not set."" ) ; } } else if ( ! hostDir . mkdirs ( ) ) { throw new IOException ( ""Unable to make directory: "" + hostDir . getAbsolutePath ( ) ) ; } else if ( logger . isInfoEnabled ( ) ) { logger . info ( ""Writing new ssl configuration to "" + hostDir ) ; } tlsClientConfig . setKeyStore ( keystore . getAbsolutePath ( ) ) ; tlsClientConfig . setKeyStorePassword ( instanceDefinition . getKeyStorePassword ( ) ) ; tlsClientConfig . setKeyPassword ( instanceDefinition . getKeyPassword ( ) ) ; tlsClientConfig . setTrustStore ( truststore . getAbsolutePath ( ) ) ; tlsClientConfig . setTrustStorePassword ( instanceDefinition . getTrustStorePassword ( ) ) ; TlsClientManager tlsClientManager = new TlsClientManager ( tlsClientConfig ) ; KeyPair keyPair = TlsHelper . generateKeyPair ( keyPairAlgorithm , keySize ) ; Extensions sanDnsExtensions = TlsHelper . createDomainAlternativeNamesExtensions ( tlsClientConfig . getDomainAlternativeNames ( ) , tlsClientConfig . calcDefaultDn ( hostname ) ) ; tlsClientManager . addPrivateKeyToKeyStore ( keyPair , NIFI_KEY , CertificateUtils . generateIssuedCertificate ( tlsClientConfig . calcDefaultDn ( hostname ) , keyPair . getPublic ( ) , sanDnsExtensions , certificate , caKeyPair , signingAlgorithm , days ) , certificate ) ; tlsClientManager . setCertificateEntry ( NIFI_CERT , certificate ) ; tlsClientManager . addClientConfigurationWriter ( new NifiPropertiesTlsClientConfigWriter ( niFiPropertiesWriterFactory , new File ( hostDir , ""nifi.properties"" ) , hostname , instanceDefinition . getNumber ( ) ) ) ; tlsClientManager . write ( outputStreamFactory ) ; if ( logger . isInfoEnabled ( ) ) { logger . info ( ""Successfully generated TLS configuration for "" + hostname + "" "" + hostIdentifierNumber + "" in "" + hostDir ) ; } } List < String > clientDns = standaloneConfig . getClientDns ( ) ; if ( standaloneConfig . getClientDns ( ) . isEmpty ( ) && logger . isInfoEnabled ( ) ) { logger . info ( ""No "" + TlsToolkitStandaloneCommandLine . CLIENT_CERT_DN_ARG + "" specified, not generating any client certificates."" ) ; } List < String > clientPasswords = standaloneConfig . getClientPasswords ( ) ; for ( int i = 0 ; i < clientDns . size ( ) ; i ++ ) { String reorderedDn = CertificateUtils . reorderDn ( clientDns . get ( i ) ) ; String clientDnFile = TlsHelper . escapeFilename ( reorderedDn ) ; File clientCertFile = new File ( baseDir , clientDnFile + "".p12"" ) ; if ( clientCertFile . exists ( ) ) { if ( overwrite ) { if ( logger . isInfoEnabled ( ) ) { logger . info ( ""Overwriting existing client cert "" + clientCertFile ) ; } } else { throw new IOException ( clientCertFile + "" exists and overwrite is not set."" ) ; } } else if ( logger . isInfoEnabled ( ) ) { logger . info ( ""Generating new client certificate "" + clientCertFile ) ; } KeyPair keyPair = TlsHelper . generateKeyPair ( keyPairAlgorithm , keySize ) ; X509Certificate clientCert = CertificateUtils . generateIssuedCertificate ( reorderedDn , keyPair . getPublic ( ) , null , certificate , caKeyPair , signingAlgorithm , days ) ; KeyStore keyStore = KeyStoreUtils . getKeyStore ( KeystoreType . PKCS12 . toString ( ) ) ; keyStore . load ( null , null ) ; keyStore . setKeyEntry ( NIFI_KEY , keyPair . getPrivate ( ) , null , new Certificate [ ] { clientCert , certificate } ) ; String password = TlsHelper . writeKeyStore ( keyStore , outputStreamFactory , clientCertFile , clientPasswords . get ( i ) , standaloneConfig . isClientPasswordsGenerated ( ) ) ; try ( FileWriter fileWriter = new FileWriter ( new File ( baseDir , clientDnFile + "".password"" ) ) ) { fileWriter . write ( password ) ; } if ( logger . isInfoEnabled ( ) ) { logger . info ( ""Successfully generated client certificate "" + clientCertFile ) ; } } if ( logger . isInfoEnabled ( ) ) { logger . info ( ""tls-toolkit standalone completed successfully"" ) ; } }",Smelly
" public void read ( org . apache . thrift . protocol . TProtocol prot , getChildDataProducts_result struct ) throws org . apache . thrift . TException { TTupleProtocol iprot = ( TTupleProtocol ) prot ; BitSet incoming = iprot . readBitSet ( 5 ) ; if ( incoming . get ( 0 ) ) { { org . apache . thrift . protocol . TList _list283 = new org . apache . thrift . protocol . TList ( org . apache . thrift . protocol . TType . STRUCT , iprot . readI32 ( ) ) ; struct . success = new ArrayList < org . apache . airavata . model . data . replica . DataProductModel > ( _list283 . size ) ; org . apache . airavata . model . data . replica . DataProductModel _elem284 ; for ( int _i285 = 0 ; _i285 < _list283 . size ; ++ _i285 ) { _elem284 = new org . apache . airavata . model . data . replica . DataProductModel ( ) ; _elem284 . read ( iprot ) ; struct . success . add ( _elem284 ) ; } } struct . setSuccessIsSet ( true ) ; } if ( incoming . get ( 1 ) ) { struct . ire = new org . apache . airavata . model . error . InvalidRequestException ( ) ; struct . ire . read ( iprot ) ; struct . setIreIsSet ( true ) ; } if ( incoming . get ( 2 ) ) { struct . ace = new org . apache . airavata . model . error . AiravataClientException ( ) ; struct . ace . read ( iprot ) ; struct . setAceIsSet ( true ) ; } if ( incoming . get ( 3 ) ) { struct . ase = new org . apache . airavata . model . error . AiravataSystemException ( ) ; struct . ase . read ( iprot ) ; struct . setAseIsSet ( true ) ; } if ( incoming . get ( 4 ) ) { struct . ae = new org . apache . airavata . model . error . AuthorizationException ( ) ; struct . ae . read ( iprot ) ; struct . setAeIsSet ( true ) ; } }",Smelly
 public Muppet setUid ( String uid ) { this . uid = uid ; return this ; },No
" private Attribute readAttribute ( DataInputStream in ) throws IOException { prt ( ""#Attribute"" ) ; Attribute attribute = null ; int attribute_name_index = in . readUnsignedShort ( ) ; int attribute_length = in . readInt ( ) ; String attribute_name = ( ( Constant_Utf8 ) constantPool . getConstant ( attribute_name_index ) ) . bytes ; int i = 0 ; for ( ; i < Constants . ATTRIBUTE_NAMES . length ; i ++ ) { if ( attribute_name . equals ( Constants . ATTRIBUTE_NAMES [ i ] ) == true ) { break ; } } if ( i != Constants . ATTRIBUTE_NAMES . length ) { switch ( i ) { case Constants . ATTRIBUTE_SourceFile : attribute = new Attribute_SourceFile ( attribute_length , in . readUnsignedShort ( ) ) ; break ; case Constants . ATTRIBUTE_ConstantValue : attribute = new Attribute_ConstantValue ( attribute_length , in . readUnsignedShort ( ) ) ; break ; case Constants . ATTRIBUTE_Code : int max_stack = in . readUnsignedShort ( ) ; int max_locals = in . readUnsignedShort ( ) ; int code_length = in . readInt ( ) ; Attribute_Code . Opcode [ ] codes = null ; if ( code_length != 0 ) { byte [ ] bcode = new byte [ code_length ] ; in . read ( bcode ) ; codes = parseOpcodes ( bcode ) ; } int exception_table_length = in . readUnsignedShort ( ) ; Attribute_Code . ExceptionTableItem [ ] exceptionTable = null ; if ( exception_table_length != 0 ) { exceptionTable = new Attribute_Code . ExceptionTableItem [ exception_table_length ] ; for ( int counter = 0 ; counter < exception_table_length ; counter ++ ) { exceptionTable [ counter ] = readExceptionTableItem ( in ) ; } } int attributes_count = in . readUnsignedShort ( ) ; Attribute [ ] attributes = null ; if ( attributes_count != 0 ) { attributes = new Attribute [ attributes_count ] ; for ( int counter = 0 ; counter < attributes_count ; counter ++ ) { attributes [ counter ] = readAttribute ( in ) ; } } attribute = new Attribute_Code ( attribute_length , max_stack , max_locals , code_length , codes , exception_table_length , exceptionTable , attributes_count , attributes ) ; break ; case Constants . ATTRIBUTE_Exceptions : int number_of_exceptions = in . readUnsignedShort ( ) ; int [ ] exception_index_table = null ; if ( number_of_exceptions != 0 ) { exception_index_table = new int [ number_of_exceptions ] ; for ( int counter = 0 ; counter < number_of_exceptions ; counter ++ ) { exception_index_table [ counter ] = in . readUnsignedShort ( ) ; } } attribute = new Attribute_Exceptions ( attribute_length , number_of_exceptions , exception_index_table ) ; break ; case Constants . ATTRIBUTE_InnerClasses : int number_of_classes = in . readUnsignedShort ( ) ; Attribute_InnerClasses . InnerClass [ ] innerClasses = null ; if ( number_of_classes != 0 ) { innerClasses = new Attribute_InnerClasses . InnerClass [ number_of_classes ] ; for ( int counter = 0 ; counter < number_of_classes ; counter ++ ) { innerClasses [ counter ] = readInnerClass ( in ) ; } } attribute = new Attribute_InnerClasses ( attribute_length , number_of_classes , innerClasses ) ; break ; case Constants . ATTRIBUTE_Synthetic : attribute = new Attribute_Synthetic ( ) ; break ; case Constants . ATTRIBUTE_LineNumberTable : int line_number_table_length = in . readUnsignedShort ( ) ; Attribute_LineNumberTable . LineNumber [ ] line_number_table = null ; if ( line_number_table_length != 0 ) { line_number_table = new Attribute_LineNumberTable . LineNumber [ line_number_table_length ] ; for ( int counter = 0 ; counter < line_number_table_length ; counter ++ ) { line_number_table [ counter ] = readLineNumber ( in ) ; } } attribute = new Attribute_LineNumberTable ( attribute_length , line_number_table_length , line_number_table ) ; break ; case Constants . ATTRIBUTE_LocalVariableTable : int local_variable_table_length = in . readUnsignedShort ( ) ; Attribute_LocalVariableTable . LocalVariable [ ] local_variable_table = null ; if ( local_variable_table_length != 0 ) { local_variable_table = new Attribute_LocalVariableTable . LocalVariable [ local_variable_table_length ] ; for ( int counter = 0 ; counter < local_variable_table_length ; counter ++ ) { local_variable_table [ counter ] = readLocalVariable ( in ) ; } } attribute = new Attribute_LocalVariableTable ( attribute_length , local_variable_table_length , local_variable_table ) ; break ; case Constants . ATTRIBUTE_Deprecated : attribute = new Attribute_Deprecated ( ) ; break ; } } else { byte [ ] info = new byte [ attribute_length ] ; in . read ( info ) ; attribute = new Attribute ( attribute_name_index , attribute_length , info ) ; } return attribute ; }",Smelly
" public void read ( org . apache . thrift . protocol . TProtocol prot , show_compact_result struct ) throws org . apache . thrift . TException { TTupleProtocol iprot = ( TTupleProtocol ) prot ; BitSet incoming = iprot . readBitSet ( 1 ) ; if ( incoming . get ( 0 ) ) { struct . success = new ShowCompactResponse ( ) ; struct . success . read ( iprot ) ; struct . setSuccessIsSet ( true ) ; } }",Smelly
 private static < S extends org . apache . thrift . scheme . IScheme > S scheme ( org . apache . thrift . protocol . TProtocol proto ) { return ( org . apache . thrift . scheme . StandardScheme . class . equals ( proto . getScheme ( ) ) ? STANDARD_SCHEME_FACTORY : TUPLE_SCHEME_FACTORY ) . getScheme ( ) ; },Smelly
 protected Handler createHandler ( ) { return new AtomPushHandler ( conf . createEngine ( ) ) ; },No
 public void preStore ( Object parameter ) throws Exception { },No
" public void run ( ) { mLogger . info ( this . id + "" Started."" ) ; while ( ! Thread . currentThread ( ) . isInterrupted ( ) ) { super . run ( ) ; try { mLogger . debug ( this . id + "" SLEEPING for "" + this . sleepTime + "" milliseconds ..."" ) ; this . sleep ( this . sleepTime ) ; } catch ( InterruptedException e ) { mLogger . info ( this . id + "" INTERRUPT: "" + e . getMessage ( ) ) ; break ; } } mLogger . info ( this . id + "" Done."" ) ; }",No
" public String toString ( ) { return this . getClass ( ) . getSimpleName ( ) + "":"" + this . snmp . toString ( ) ; }",No
 public String [ ] getColumnNames ( ) { return resultCols ; },Smelly
" public static void main ( String [ ] args ) { String from , subject , newsgroup , filename , server , organization ; String references ; BufferedReader stdin ; FileReader fileReader = null ; SimpleNNTPHeader header ; NNTPClient client ; if ( args . length < 1 ) { System . err . println ( ""Usage: post newsserver"" ) ; System . exit ( 1 ) ; } server = args [ 0 ] ; stdin = new BufferedReader ( new InputStreamReader ( System . in ) ) ; try { System . out . print ( ""From: "" ) ; System . out . flush ( ) ; from = stdin . readLine ( ) ; System . out . print ( ""Subject: "" ) ; System . out . flush ( ) ; subject = stdin . readLine ( ) ; header = new SimpleNNTPHeader ( from , subject ) ; System . out . print ( ""Newsgroup: "" ) ; System . out . flush ( ) ; newsgroup = stdin . readLine ( ) ; header . addNewsgroup ( newsgroup ) ; while ( true ) { System . out . print ( ""Additional Newsgroup <Hit enter to end>: "" ) ; System . out . flush ( ) ; newsgroup = stdin . readLine ( ) . trim ( ) ; if ( newsgroup . length ( ) == 0 ) { break ; } header . addNewsgroup ( newsgroup ) ; } System . out . print ( ""Organization: "" ) ; System . out . flush ( ) ; organization = stdin . readLine ( ) ; System . out . print ( ""References: "" ) ; System . out . flush ( ) ; references = stdin . readLine ( ) ; if ( organization != null && organization . length ( ) > 0 ) { header . addHeaderField ( ""Organization"" , organization ) ; } if ( references != null && references . length ( ) > 0 ) { header . addHeaderField ( ""References"" , references ) ; } header . addHeaderField ( ""X-Newsreader"" , ""NetComponents"" ) ; System . out . print ( ""Filename: "" ) ; System . out . flush ( ) ; filename = stdin . readLine ( ) ; try { fileReader = new FileReader ( filename ) ; } catch ( FileNotFoundException e ) { System . err . println ( ""File not found. "" + e . getMessage ( ) ) ; System . exit ( 1 ) ; } client = new NNTPClient ( ) ; client . addProtocolCommandListener ( new PrintCommandListener ( new PrintWriter ( System . out ) , true ) ) ; client . connect ( server ) ; if ( ! NNTPReply . isPositiveCompletion ( client . getReplyCode ( ) ) ) { client . disconnect ( ) ; System . err . println ( ""NNTP server refused connection."" ) ; System . exit ( 1 ) ; } if ( client . isAllowedToPost ( ) ) { Writer writer = client . postArticle ( ) ; if ( writer != null ) { writer . write ( header . toString ( ) ) ; Util . copyReader ( fileReader , writer ) ; writer . close ( ) ; client . completePendingCommand ( ) ; } } if ( fileReader != null ) { fileReader . close ( ) ; } client . logout ( ) ; client . disconnect ( ) ; } catch ( IOException e ) { e . printStackTrace ( ) ; System . exit ( 1 ) ; } }",Smelly
" public void read ( org . apache . thrift . protocol . TProtocol prot , TAuthenticationTokenIdentifier struct ) throws org . apache . thrift . TException { TTupleProtocol iprot = ( TTupleProtocol ) prot ; BitSet incoming = iprot . readBitSet ( 5 ) ; if ( incoming . get ( 0 ) ) { struct . principal = iprot . readString ( ) ; struct . setPrincipalIsSet ( true ) ; } if ( incoming . get ( 1 ) ) { struct . keyId = iprot . readI32 ( ) ; struct . setKeyIdIsSet ( true ) ; } if ( incoming . get ( 2 ) ) { struct . issueDate = iprot . readI64 ( ) ; struct . setIssueDateIsSet ( true ) ; } if ( incoming . get ( 3 ) ) { struct . expirationDate = iprot . readI64 ( ) ; struct . setExpirationDateIsSet ( true ) ; } if ( incoming . get ( 4 ) ) { struct . instanceId = iprot . readString ( ) ; struct . setInstanceIdIsSet ( true ) ; } }",No
" protected void addAnnotationToLabel ( AnnotationFS annotation , MatchContext context ) { if ( StringUtils . isBlank ( label ) ) { return ; } RutaEnvironment environment = context . getParent ( ) . getEnvironment ( ) ; Class < ? > variableType = environment . getVariableType ( label ) ; if ( List . class . equals ( variableType ) && AnnotationFS . class . equals ( environment . getVariableGenericType ( label ) ) ) { environment . setVariableValue ( label , Arrays . asList ( annotation ) ) ; } else if ( AnnotationFS . class . equals ( variableType ) ) { environment . setVariableValue ( label , annotation ) ; } }",No
 protected Credentials getCredentials ( HttpServletRequest request ) { return null ; },No
" public void read ( org . apache . thrift . protocol . TProtocol prot , getChildDataProducts_result struct ) throws org . apache . thrift . TException { TTupleProtocol iprot = ( TTupleProtocol ) prot ; BitSet incoming = iprot . readBitSet ( 5 ) ; if ( incoming . get ( 0 ) ) { { org . apache . thrift . protocol . TList _list283 = new org . apache . thrift . protocol . TList ( org . apache . thrift . protocol . TType . STRUCT , iprot . readI32 ( ) ) ; struct . success = new ArrayList < org . apache . airavata . model . data . replica . DataProductModel > ( _list283 . size ) ; org . apache . airavata . model . data . replica . DataProductModel _elem284 ; for ( int _i285 = 0 ; _i285 < _list283 . size ; ++ _i285 ) { _elem284 = new org . apache . airavata . model . data . replica . DataProductModel ( ) ; _elem284 . read ( iprot ) ; struct . success . add ( _elem284 ) ; } } struct . setSuccessIsSet ( true ) ; } if ( incoming . get ( 1 ) ) { struct . ire = new org . apache . airavata . model . error . InvalidRequestException ( ) ; struct . ire . read ( iprot ) ; struct . setIreIsSet ( true ) ; } if ( incoming . get ( 2 ) ) { struct . ace = new org . apache . airavata . model . error . AiravataClientException ( ) ; struct . ace . read ( iprot ) ; struct . setAceIsSet ( true ) ; } if ( incoming . get ( 3 ) ) { struct . ase = new org . apache . airavata . model . error . AiravataSystemException ( ) ; struct . ase . read ( iprot ) ; struct . setAseIsSet ( true ) ; } if ( incoming . get ( 4 ) ) { struct . ae = new org . apache . airavata . model . error . AuthorizationException ( ) ; struct . ae . read ( iprot ) ; struct . setAeIsSet ( true ) ; } }",Smelly
" public void stop ( Platform platform ) throws Exception { if ( ! running . compareAndSet ( true , false ) ) { throw new IllegalStateException ( ""ProduceBenchWorker is not running."" ) ; } log . info ( ""{}: Deactivating ProduceBenchWorker."" , id ) ; doneFuture . complete ( """" ) ; executor . shutdownNow ( ) ; executor . awaitTermination ( 1 , TimeUnit . DAYS ) ; this . executor = null ; this . status = null ; this . doneFuture = null ; }",No
 private Object readResolve ( ) { return LazyHolder . INSTANCE ; },No
" public void read ( org . apache . thrift . protocol . TProtocol prot , TabletSplit struct ) throws org . apache . thrift . TException { TTupleProtocol iprot = ( TTupleProtocol ) prot ; BitSet incoming = iprot . readBitSet ( 2 ) ; if ( incoming . get ( 0 ) ) { struct . oldTablet = new org . apache . accumulo . core . data . thrift . TKeyExtent ( ) ; struct . oldTablet . read ( iprot ) ; struct . setOldTabletIsSet ( true ) ; } if ( incoming . get ( 1 ) ) { { org . apache . thrift . protocol . TList _list67 = new org . apache . thrift . protocol . TList ( org . apache . thrift . protocol . TType . STRUCT , iprot . readI32 ( ) ) ; struct . newTablets = new ArrayList < org . apache . accumulo . core . data . thrift . TKeyExtent > ( _list67 . size ) ; for ( int _i68 = 0 ; _i68 < _list67 . size ; ++ _i68 ) { org . apache . accumulo . core . data . thrift . TKeyExtent _elem69 ; _elem69 = new org . apache . accumulo . core . data . thrift . TKeyExtent ( ) ; _elem69 . read ( iprot ) ; struct . newTablets . add ( _elem69 ) ; } } struct . setNewTabletsIsSet ( true ) ; } }",Smelly
" public void read ( org . apache . thrift . protocol . TProtocol prot , getActiveLogs_result struct ) throws org . apache . thrift . TException { TTupleProtocol iprot = ( TTupleProtocol ) prot ; BitSet incoming = iprot . readBitSet ( 1 ) ; if ( incoming . get ( 0 ) ) { { org . apache . thrift . protocol . TList _list327 = new org . apache . thrift . protocol . TList ( org . apache . thrift . protocol . TType . STRING , iprot . readI32 ( ) ) ; struct . success = new ArrayList < String > ( _list327 . size ) ; for ( int _i328 = 0 ; _i328 < _list327 . size ; ++ _i328 ) { String _elem329 ; _elem329 = iprot . readString ( ) ; struct . success . add ( _elem329 ) ; } } struct . setSuccessIsSet ( true ) ; } }",Smelly
" public String input ( ) throws Exception { return ""input"" ; }",No
" PendingMessageCursor getSubscriberPendingMessageCursor ( Broker broker , String name , int maxBatchSize , Subscription subs ) ;",No
 public void setId ( java . lang . String value ) { this . id = value ; },No
" protected boolean isMatch ( final String fieldValue , final String comparison ) { return fieldValue . contains ( comparison ) ; }",No
" public void read ( org . apache . thrift . protocol . TProtocol prot , PasswordCredential struct ) throws org . apache . thrift . TException { TTupleProtocol iprot = ( TTupleProtocol ) prot ; struct . gatewayId = iprot . readString ( ) ; struct . setGatewayIdIsSet ( true ) ; struct . portalUserName = iprot . readString ( ) ; struct . setPortalUserNameIsSet ( true ) ; struct . loginUserName = iprot . readString ( ) ; struct . setLoginUserNameIsSet ( true ) ; struct . password = iprot . readString ( ) ; struct . setPasswordIsSet ( true ) ; BitSet incoming = iprot . readBitSet ( 3 ) ; if ( incoming . get ( 0 ) ) { struct . description = iprot . readString ( ) ; struct . setDescriptionIsSet ( true ) ; } if ( incoming . get ( 1 ) ) { struct . persistedTime = iprot . readI64 ( ) ; struct . setPersistedTimeIsSet ( true ) ; } if ( incoming . get ( 2 ) ) { struct . token = iprot . readString ( ) ; struct . setTokenIsSet ( true ) ; } }",Smelly
 private static < S extends org . apache . thrift . scheme . IScheme > S scheme ( org . apache . thrift . protocol . TProtocol proto ) { return ( org . apache . thrift . scheme . StandardScheme . class . equals ( proto . getScheme ( ) ) ? STANDARD_SCHEME_FACTORY : TUPLE_SCHEME_FACTORY ) . getScheme ( ) ; },No
" public void read ( org . apache . thrift . protocol . TProtocol prot , getChildDataProducts_result struct ) throws org . apache . thrift . TException { TTupleProtocol iprot = ( TTupleProtocol ) prot ; BitSet incoming = iprot . readBitSet ( 5 ) ; if ( incoming . get ( 0 ) ) { { org . apache . thrift . protocol . TList _list283 = new org . apache . thrift . protocol . TList ( org . apache . thrift . protocol . TType . STRUCT , iprot . readI32 ( ) ) ; struct . success = new ArrayList < org . apache . airavata . model . data . replica . DataProductModel > ( _list283 . size ) ; org . apache . airavata . model . data . replica . DataProductModel _elem284 ; for ( int _i285 = 0 ; _i285 < _list283 . size ; ++ _i285 ) { _elem284 = new org . apache . airavata . model . data . replica . DataProductModel ( ) ; _elem284 . read ( iprot ) ; struct . success . add ( _elem284 ) ; } } struct . setSuccessIsSet ( true ) ; } if ( incoming . get ( 1 ) ) { struct . ire = new org . apache . airavata . model . error . InvalidRequestException ( ) ; struct . ire . read ( iprot ) ; struct . setIreIsSet ( true ) ; } if ( incoming . get ( 2 ) ) { struct . ace = new org . apache . airavata . model . error . AiravataClientException ( ) ; struct . ace . read ( iprot ) ; struct . setAceIsSet ( true ) ; } if ( incoming . get ( 3 ) ) { struct . ase = new org . apache . airavata . model . error . AiravataSystemException ( ) ; struct . ase . read ( iprot ) ; struct . setAseIsSet ( true ) ; } if ( incoming . get ( 4 ) ) { struct . ae = new org . apache . airavata . model . error . AuthorizationException ( ) ; struct . ae . read ( iprot ) ; struct . setAeIsSet ( true ) ; } }",Smelly
" public static String checkProtectedView ( HttpServletRequest request , HttpServletResponse response ) { HttpSession session = request . getSession ( ) ; String viewNameId = RequestHandler . getRequestUri ( request . getPathInfo ( ) ) ; GenericValue userLogin = ( GenericValue ) session . getAttribute ( ""userLogin"" ) ; Delegator delegator = ( Delegator ) request . getAttribute ( ""delegator"" ) ; String returnValue = ""success"" ; if ( userLogin != null ) { String userLoginId = userLogin . getString ( ""userLoginId"" ) ; try { List < GenericValue > protectedViews = delegator . findByAnd ( ""UserLoginAndProtectedView"" , UtilMisc . toMap ( ""userLoginId"" , userLoginId , ""viewNameId"" , viewNameId ) , null , true ) ; if ( UtilValidate . isNotEmpty ( protectedViews ) ) { Long now = System . currentTimeMillis ( ) ; List < GenericValue > tarpittedLoginViews = delegator . findByAnd ( ""TarpittedLoginView"" , UtilMisc . toMap ( ""userLoginId"" , userLoginId , ""viewNameId"" , viewNameId ) , null , true ) ; String viewNameUserLoginId = viewNameId + userLoginId ; if ( UtilValidate . isNotEmpty ( tarpittedLoginViews ) ) { GenericValue tarpittedLoginView = tarpittedLoginViews . get ( 0 ) ; Long tarpitReleaseDateTime = ( Long ) tarpittedLoginView . get ( ""tarpitReleaseDateTime"" ) ; if ( now < tarpitReleaseDateTime ) { String tarpittedMessage = UtilProperties . getMessage ( resourceWebapp , ""protectedviewevents.tarpitted_message"" , UtilHttp . getLocale ( request ) ) ; hitsByViewAccessed . put ( viewNameUserLoginId , new Long ( 0 ) ) ; return "":_protect_:"" + tarpittedMessage ; } } GenericValue protectedView = protectedViews . get ( 0 ) ; Long curMaxHits = hitsByViewAccessed . get ( viewNameUserLoginId ) ; if ( UtilValidate . isEmpty ( curMaxHits ) ) { hitsByViewAccessed . put ( viewNameUserLoginId , one ) ; Long maxHitsDuration = ( Long ) protectedView . get ( ""maxHitsDuration"" ) * 1000 ; durationByViewAccessed . put ( viewNameUserLoginId , now + maxHitsDuration ) ; } else { Long maxDuration = durationByViewAccessed . get ( viewNameUserLoginId ) ; Long newMaxHits = curMaxHits + one ; hitsByViewAccessed . put ( viewNameUserLoginId , newMaxHits ) ; if ( now < maxDuration ) { if ( newMaxHits > protectedView . getLong ( ""maxHits"" ) ) { String blockedMessage = UtilProperties . getMessage ( resourceWebapp , ""protectedviewevents.blocked_message"" , UtilHttp . getLocale ( request ) ) ; returnValue = "":_protect_:"" + blockedMessage ; Long tarpitDuration = ( Long ) protectedView . get ( ""tarpitDuration"" ) * 1000 ; GenericValue tarpittedLoginView = delegator . makeValue ( ""TarpittedLoginView"" ) ; tarpittedLoginView . set ( ""userLoginId"" , userLoginId ) ; tarpittedLoginView . set ( ""viewNameId"" , viewNameId ) ; tarpittedLoginView . set ( ""tarpitReleaseDateTime"" , now + tarpitDuration ) ; try { delegator . createOrStore ( tarpittedLoginView ) ; } catch ( GenericEntityException e ) { Debug . logError ( e , ""Could not save TarpittedLoginView:"" , module ) ; } } } else { hitsByViewAccessed . put ( viewNameUserLoginId , one ) ; Long maxHitsDuration = ( Long ) protectedView . get ( ""maxHitsDuration"" ) * 1000 ; durationByViewAccessed . put ( viewNameUserLoginId , now + maxHitsDuration ) ; } } } } catch ( GenericEntityException e ) { Map < String , String > messageMap = UtilMisc . toMap ( ""errMessage"" , e . getMessage ( ) ) ; String errMsg = UtilProperties . getMessage ( ""CommonUiLabels"" , ""CommonDatabaseProblem"" , messageMap , UtilHttp . getLocale ( request ) ) ; Debug . logError ( e , errMsg , module ) ; } } return returnValue ; }",Smelly
 public void setVersionControlInformation ( final VersionControlInformationDTO versionControlInformation ) { this . versionControlInformation = versionControlInformation ; },No
 private static < S extends org . apache . thrift . scheme . IScheme > S scheme ( org . apache . thrift . protocol . TProtocol proto ) { return ( org . apache . thrift . scheme . StandardScheme . class . equals ( proto . getScheme ( ) ) ? STANDARD_SCHEME_FACTORY : TUPLE_SCHEME_FACTORY ) . getScheme ( ) ; },No
" public void read ( org . apache . thrift . protocol . TProtocol prot , getChildDataProducts_result struct ) throws org . apache . thrift . TException { TTupleProtocol iprot = ( TTupleProtocol ) prot ; BitSet incoming = iprot . readBitSet ( 5 ) ; if ( incoming . get ( 0 ) ) { { org . apache . thrift . protocol . TList _list283 = new org . apache . thrift . protocol . TList ( org . apache . thrift . protocol . TType . STRUCT , iprot . readI32 ( ) ) ; struct . success = new ArrayList < org . apache . airavata . model . data . replica . DataProductModel > ( _list283 . size ) ; org . apache . airavata . model . data . replica . DataProductModel _elem284 ; for ( int _i285 = 0 ; _i285 < _list283 . size ; ++ _i285 ) { _elem284 = new org . apache . airavata . model . data . replica . DataProductModel ( ) ; _elem284 . read ( iprot ) ; struct . success . add ( _elem284 ) ; } } struct . setSuccessIsSet ( true ) ; } if ( incoming . get ( 1 ) ) { struct . ire = new org . apache . airavata . model . error . InvalidRequestException ( ) ; struct . ire . read ( iprot ) ; struct . setIreIsSet ( true ) ; } if ( incoming . get ( 2 ) ) { struct . ace = new org . apache . airavata . model . error . AiravataClientException ( ) ; struct . ace . read ( iprot ) ; struct . setAceIsSet ( true ) ; } if ( incoming . get ( 3 ) ) { struct . ase = new org . apache . airavata . model . error . AiravataSystemException ( ) ; struct . ase . read ( iprot ) ; struct . setAseIsSet ( true ) ; } if ( incoming . get ( 4 ) ) { struct . ae = new org . apache . airavata . model . error . AuthorizationException ( ) ; struct . ae . read ( iprot ) ; struct . setAeIsSet ( true ) ; } }",Smelly
" public void read ( org . apache . thrift . protocol . TProtocol prot , getChildDataProducts_result struct ) throws org . apache . thrift . TException { TTupleProtocol iprot = ( TTupleProtocol ) prot ; BitSet incoming = iprot . readBitSet ( 5 ) ; if ( incoming . get ( 0 ) ) { { org . apache . thrift . protocol . TList _list283 = new org . apache . thrift . protocol . TList ( org . apache . thrift . protocol . TType . STRUCT , iprot . readI32 ( ) ) ; struct . success = new ArrayList < org . apache . airavata . model . data . replica . DataProductModel > ( _list283 . size ) ; org . apache . airavata . model . data . replica . DataProductModel _elem284 ; for ( int _i285 = 0 ; _i285 < _list283 . size ; ++ _i285 ) { _elem284 = new org . apache . airavata . model . data . replica . DataProductModel ( ) ; _elem284 . read ( iprot ) ; struct . success . add ( _elem284 ) ; } } struct . setSuccessIsSet ( true ) ; } if ( incoming . get ( 1 ) ) { struct . ire = new org . apache . airavata . model . error . InvalidRequestException ( ) ; struct . ire . read ( iprot ) ; struct . setIreIsSet ( true ) ; } if ( incoming . get ( 2 ) ) { struct . ace = new org . apache . airavata . model . error . AiravataClientException ( ) ; struct . ace . read ( iprot ) ; struct . setAceIsSet ( true ) ; } if ( incoming . get ( 3 ) ) { struct . ase = new org . apache . airavata . model . error . AiravataSystemException ( ) ; struct . ase . read ( iprot ) ; struct . setAseIsSet ( true ) ; } if ( incoming . get ( 4 ) ) { struct . ae = new org . apache . airavata . model . error . AuthorizationException ( ) ; struct . ae . read ( iprot ) ; struct . setAeIsSet ( true ) ; } }",Smelly
 public EJBQLExpressionVisitor getConditionTranslator ( EJBQLTranslationContext context ) { context . setCaseInsensitive ( caseInsensitive ) ; return new FirebirdEJBQLConditionTranslator ( context ) ; },No
" public static void skip ( RecordInput rin , String tag , TypeID typeID ) throws IOException { switch ( typeID . typeVal ) { case TypeID . RIOType . BOOL : rin . readBool ( tag ) ; break ; case TypeID . RIOType . BUFFER : rin . readBuffer ( tag ) ; break ; case TypeID . RIOType . BYTE : rin . readByte ( tag ) ; break ; case TypeID . RIOType . DOUBLE : rin . readDouble ( tag ) ; break ; case TypeID . RIOType . FLOAT : rin . readFloat ( tag ) ; break ; case TypeID . RIOType . INT : rin . readInt ( tag ) ; break ; case TypeID . RIOType . LONG : rin . readLong ( tag ) ; break ; case TypeID . RIOType . MAP : org . apache . hadoop . record . Index midx1 = rin . startMap ( tag ) ; MapTypeID mtID = ( MapTypeID ) typeID ; for ( ; ! midx1 . done ( ) ; midx1 . incr ( ) ) { skip ( rin , tag , mtID . getKeyTypeID ( ) ) ; skip ( rin , tag , mtID . getValueTypeID ( ) ) ; } rin . endMap ( tag ) ; break ; case TypeID . RIOType . STRING : rin . readString ( tag ) ; break ; case TypeID . RIOType . STRUCT : rin . startRecord ( tag ) ; StructTypeID stID = ( StructTypeID ) typeID ; Iterator < FieldTypeInfo > it = stID . getFieldTypeInfos ( ) . iterator ( ) ; while ( it . hasNext ( ) ) { FieldTypeInfo tInfo = it . next ( ) ; skip ( rin , tag , tInfo . getTypeID ( ) ) ; } rin . endRecord ( tag ) ; break ; case TypeID . RIOType . VECTOR : org . apache . hadoop . record . Index vidx1 = rin . startVector ( tag ) ; VectorTypeID vtID = ( VectorTypeID ) typeID ; for ( ; ! vidx1 . done ( ) ; vidx1 . incr ( ) ) { skip ( rin , tag , vtID . getElementTypeID ( ) ) ; } rin . endVector ( tag ) ; break ; default : throw new IOException ( ""Unknown typeID when skipping bytes"" ) ; } }",Smelly
" public Object apply ( List < Object > args ) { StatisticsProvider stats = convert ( args . get ( 0 ) , StatisticsProvider . class ) ; Double value = convert ( args . get ( 1 ) , Double . class ) ; final List < Number > bins = args . size ( ) > 2 ? BinSplits . getSplit ( args . get ( 2 ) ) : BinSplits . QUARTILE . split ; if ( stats == null || value == null || bins . size ( ) == 0 ) { return - 1 ; } return BinFunctions . Bin . getBin ( value , bins . size ( ) , bin -> stats . getPercentile ( bins . get ( bin ) . doubleValue ( ) ) ) ; }",No
" static public Test suite ( ) { TestSuite test0 = new TestSuite ( ""ARP"" ) ; WGTestSuite test1 = new org . apache . jena . rdfxml . xmlinput . WGTestSuite ( new InputStreamFactoryTests ( IRIFactory . iriImplementation ( ) . create ( ""http://www.w3.org/2000/10/rdf-tests/rdfcore/"" ) , ""wg"" ) , ""WG Parser Tests"" , false ) ; TestSuite test2 = new TestSuite ( ""APPROVED"" ) ; Test test3 = test1 . createPositiveTest ( ""http://www.w3.org/2000/10/rdf-tests/rdfcore/rdfms-rdf-names-use/Manifest.rdf#test-024"" , ""http://www.w3.org/2000/10/rdf-tests/rdfcore/rdfms-rdf-names-use/test-024.rdf"" , true , ""http://www.w3.org/2000/10/rdf-tests/rdfcore/rdfms-rdf-names-use/test-024.nt"" , false ) ; test2 . addTest ( test3 ) ; Test test4 = test1 . createPositiveTest ( ""http://www.w3.org/2000/10/rdf-tests/rdfcore/rdfms-rdf-names-use/Manifest.rdf#test-025"" , ""http://www.w3.org/2000/10/rdf-tests/rdfcore/rdfms-rdf-names-use/test-025.rdf"" , true , ""http://www.w3.org/2000/10/rdf-tests/rdfcore/rdfms-rdf-names-use/test-025.nt"" , false ) ; test2 . addTest ( test4 ) ; Test test5 = test1 . createPositiveTest ( ""http://www.w3.org/2000/10/rdf-tests/rdfcore/rdfms-empty-property-elements/Manifest.rdf#test003"" , ""http://www.w3.org/2000/10/rdf-tests/rdfcore/rdfms-empty-property-elements/test003.rdf"" , true , ""http://www.w3.org/2000/10/rdf-tests/rdfcore/rdfms-empty-property-elements/test003.nt"" , false ) ; test2 . addTest ( test5 ) ; Test test6 = test1 . createPositiveTest ( ""http://www.w3.org/2000/10/rdf-tests/rdfcore/rdfms-empty-property-elements/Manifest.rdf#test004"" , ""http://www.w3.org/2000/10/rdf-tests/rdfcore/rdfms-empty-property-elements/test004.rdf"" , true , ""http://www.w3.org/2000/10/rdf-tests/rdfcore/rdfms-empty-property-elements/test004.nt"" , false ) ; test2 . addTest ( test6 ) ; Test test7 = test1 . createNegativeTest ( ""http://www.w3.org/2000/10/rdf-tests/rdfcore/rdfms-rdf-names-use/Manifest.rdf#error-019"" , ""http://www.w3.org/2000/10/rdf-tests/rdfcore/rdfms-rdf-names-use/error-019.rdf"" , true , new int [ ] { 205 , } ) ; test2 . addTest ( test7 ) ; Test test8 = test1 . createPositiveTest ( ""http://www.w3.org/2000/10/rdf-tests/rdfcore/rdfms-rdf-names-use/Manifest.rdf#test-017"" , ""http://www.w3.org/2000/10/rdf-tests/rdfcore/rdfms-rdf-names-use/test-017.rdf"" , true , ""http://www.w3.org/2000/10/rdf-tests/rdfcore/rdfms-rdf-names-use/test-017.nt"" , false ) ; test2 . addTest ( test8 ) ; Test test9 = test1 . createPositiveTest ( ""http://www.w3.org/2000/10/rdf-tests/rdfcore/rdfms-rdf-names-use/Manifest.rdf#test-018"" , ""http://www.w3.org/2000/10/rdf-tests/rdfcore/rdfms-rdf-names-use/test-018.rdf"" , true , ""http://www.w3.org/2000/10/rdf-tests/rdfcore/rdfms-rdf-names-use/test-018.nt"" , false ) ; test2 . addTest ( test9 ) ; Test test10 = test1 . createPositiveTest ( ""http://www.w3.org/2000/10/rdf-tests/rdfcore/rdf-element-not-mandatory/Manifest.rdf#test001"" , ""http://www.w3.org/2000/10/rdf-tests/rdfcore/rdf-element-not-mandatory/test001.rdf"" , true , ""http://www.w3.org/2000/10/rdf-tests/rdfcore/rdf-element-not-mandatory/test001.nt"" , false ) ; test2 . addTest ( test10 ) ; Test test11 = test1 . createPositiveTest ( ""http://www.w3.org/2000/10/rdf-tests/rdfcore/datatypes/Manifest.rdf#test001"" , ""http://www.w3.org/2000/10/rdf-tests/rdfcore/datatypes/test001.rdf"" , true , ""http://www.w3.org/2000/10/rdf-tests/rdfcore/datatypes/test001.nt"" , false ) ; test2 . addTest ( test11 ) ; Test test12 = test1 . createPositiveTest ( ""http://www.w3.org/2000/10/rdf-tests/rdfcore/rdfms-xmllang/Manifest.rdf#test005"" , ""http://www.w3.org/2000/10/rdf-tests/rdfcore/rdfms-xmllang/test005.rdf"" , true , ""http://www.w3.org/2000/10/rdf-tests/rdfcore/rdfms-xmllang/test005.nt"" , false ) ; test2 . addTest ( test12 ) ; Test test13 = test1 . createPositiveTest ( ""http://www.w3.org/2000/10/rdf-tests/rdfcore/rdfms-xmllang/Manifest.rdf#test006"" , ""http://www.w3.org/2000/10/rdf-tests/rdfcore/rdfms-xmllang/test006.rdf"" , true , ""http://www.w3.org/2000/10/rdf-tests/rdfcore/rdfms-xmllang/test006.nt"" , false ) ; test2 . addTest ( test13 ) ; Test test14 = test1 . createNegativeTest ( ""http://www.w3.org/2000/10/rdf-tests/rdfcore/rdfms-rdf-names-use/Manifest.rdf#error-001"" , ""http://www.w3.org/2000/10/rdf-tests/rdfcore/rdfms-rdf-names-use/error-001.rdf"" , true , new int [ ] { 205 , } ) ; test2 . addTest ( test14 ) ; Test test15 = test1 . createPositiveTest ( ""http://www.w3.org/2000/10/rdf-tests/rdfcore/xmlbase/Manifest.rdf#test011"" , ""http://www.w3.org/2000/10/rdf-tests/rdfcore/xmlbase/test011.rdf"" , true , ""http://www.w3.org/2000/10/rdf-tests/rdfcore/xmlbase/test011.nt"" , false ) ; test2 . addTest ( test15 ) ; Test test16 = test1 . createPositiveTest ( ""http://www.w3.org/2000/10/rdf-tests/rdfcore/xmlbase/Manifest.rdf#test010"" , ""http://www.w3.org/2000/10/rdf-tests/rdfcore/xmlbase/test010.rdf"" , true , ""http://www.w3.org/2000/10/rdf-tests/rdfcore/xmlbase/test010.nt"" , false ) ; test2 . addTest ( test16 ) ; Test test17 = test1 . createPositiveTest ( ""http://www.w3.org/2000/10/rdf-tests/rdfcore/rdf-ns-prefix-confusion/Manifest.rdf#test0013"" , ""http://www.w3.org/2000/10/rdf-tests/rdfcore/rdf-ns-prefix-confusion/test0013.rdf"" , true , ""http://www.w3.org/2000/10/rdf-tests/rdfcore/rdf-ns-prefix-confusion/test0013.nt"" , false ) ; test2 . addTest ( test17 ) ; Test test18 = test1 . createPositiveTest ( ""http://www.w3.org/2000/10/rdf-tests/rdfcore/rdf-ns-prefix-confusion/Manifest.rdf#test0012"" , ""http://www.w3.org/2000/10/rdf-tests/rdfcore/rdf-ns-prefix-confusion/test0012.rdf"" , true , ""http://www.w3.org/2000/10/rdf-tests/rdfcore/rdf-ns-prefix-confusion/test0012.nt"" , false ) ; test2 . addTest ( test18 ) ; Test test19 = test1 . createPositiveTest ( ""http://www.w3.org/2000/10/rdf-tests/rdfcore/unrecognised-xml-attributes/Manifest.rdf#test002"" , ""http://www.w3.org/2000/10/rdf-tests/rdfcore/unrecognised-xml-attributes/test002.rdf"" , true , ""http://www.w3.org/2000/10/rdf-tests/rdfcore/unrecognised-xml-attributes/test002.nt"" , false ) ; test2 . addTest ( test19 ) ; Test test20 = test1 . createPositiveTest ( ""http://www.w3.org/2000/10/rdf-tests/rdfcore/unrecognised-xml-attributes/Manifest.rdf#test001"" , ""http://www.w3.org/2000/10/rdf-tests/rdfcore/unrecognised-xml-attributes/test001.rdf"" , true , ""http://www.w3.org/2000/10/rdf-tests/rdfcore/unrecognised-xml-attributes/test001.nt"" , false ) ; test2 . addTest ( test20 ) ; Test test21 = test1 . createPositiveTest ( ""http://www.w3.org/2000/10/rdf-tests/rdfcore/xmlbase/Manifest.rdf#test002"" , ""http://www.w3.org/2000/10/rdf-tests/rdfcore/xmlbase/test002.rdf"" , true , ""http://www.w3.org/2000/10/rdf-tests/rdfcore/xmlbase/test002.nt"" , false ) ; test2 . addTest ( test21 ) ; Test test22 = test1 . createPositiveTest ( ""http://www.w3.org/2000/10/rdf-tests/rdfcore/xmlbase/Manifest.rdf#test001"" , ""http://www.w3.org/2000/10/rdf-tests/rdfcore/xmlbase/test001.rdf"" , true , ""http://www.w3.org/2000/10/rdf-tests/rdfcore/xmlbase/test001.nt"" , false ) ; test2 . addTest ( test22 ) ; Test test23 = test1 . createPositiveTest ( ""http://www.w3.org/2000/10/rdf-tests/rdfcore/rdfs-domain-and-range/Manifest.rdf#test002"" , ""http://www.w3.org/2000/10/rdf-tests/rdfcore/rdfs-domain-and-range/test002.rdf"" , true , ""http://www.w3.org/2000/10/rdf-tests/rdfcore/rdfs-domain-and-range/test002.nt"" , false ) ; test2 . addTest ( test23 ) ; Test test24 = test1 . createPositiveTest ( ""http://www.w3.org/2000/10/rdf-tests/rdfcore/rdfs-domain-and-range/Manifest.rdf#test001"" , ""http://www.w3.org/2000/10/rdf-tests/rdfcore/rdfs-domain-and-range/test001.rdf"" , true , ""http://www.w3.org/2000/10/rdf-tests/rdfcore/rdfs-domain-and-range/test001.nt"" , false ) ; test2 . addTest ( test24 ) ; Test test25 = test1 . createPositiveTest ( ""http://www.w3.org/2000/10/rdf-tests/rdfcore/rdfms-xml-literal-namespaces/Manifest.rdf#test001"" , ""http://www.w3.org/2000/10/rdf-tests/rdfcore/rdfms-xml-literal-namespaces/test001.rdf"" , true , ""http://www.w3.org/2000/10/rdf-tests/rdfcore/rdfms-xml-literal-namespaces/test001.nt"" , false ) ; test2 . addTest ( test25 ) ; Test test26 = test1 . createPositiveTest ( ""http://www.w3.org/2000/10/rdf-tests/rdfcore/xmlbase/Manifest.rdf#test009"" , ""http://www.w3.org/2000/10/rdf-tests/rdfcore/xmlbase/test009.rdf"" , true , ""http://www.w3.org/2000/10/rdf-tests/rdfcore/xmlbase/test009.nt"" , false ) ; test2 . addTest ( test26 ) ; Test test27 = test1 . createNegativeTest ( ""http://www.w3.org/2000/10/rdf-tests/rdfcore/rdfms-rdf-names-use/Manifest.rdf#error-004"" , ""http://www.w3.org/2000/10/rdf-tests/rdfcore/rdfms-rdf-names-use/error-004.rdf"" , true , new int [ ] { 205 , } ) ; test2 . addTest ( test27 ) ; Test test28 = test1 . createNegativeTest ( ""http://www.w3.org/2000/10/rdf-tests/rdfcore/rdfms-rdf-names-use/Manifest.rdf#error-005"" , ""http://www.w3.org/2000/10/rdf-tests/rdfcore/rdfms-rdf-names-use/error-005.rdf"" , true , new int [ ] { 205 , } ) ; test2 . addTest ( test28 ) ; Test test29 = test1 . createPositiveTest ( ""http://www.w3.org/2000/10/rdf-tests/rdfcore/rdfms-rdf-names-use/Manifest.rdf#test-028"" , ""http://www.w3.org/2000/10/rdf-tests/rdfcore/rdfms-rdf-names-use/test-028.rdf"" , true , ""http://www.w3.org/2000/10/rdf-tests/rdfcore/rdfms-rdf-names-use/test-028.nt"" , false ) ; test2 . addTest ( test29 ) ; Test test30 = test1 . createPositiveTest ( ""http://www.w3.org/2000/10/rdf-tests/rdfcore/rdfms-rdf-names-use/Manifest.rdf#test-029"" , ""http://www.w3.org/2000/10/rdf-tests/rdfcore/rdfms-rdf-names-use/test-029.rdf"" , true , ""http://www.w3.org/2000/10/rdf-tests/rdfcore/rdfms-rdf-names-use/test-029.nt"" , false ) ; test2 . addTest ( test30 ) ; Test test31 = test1 . createPositiveTest ( ""http://www.w3.org/2000/10/rdf-tests/rdfcore/rdfms-empty-property-elements/Manifest.rdf#test012"" , ""http://www.w3.org/2000/10/rdf-tests/rdfcore/rdfms-empty-property-elements/test012.rdf"" , true , ""http://www.w3.org/2000/10/rdf-tests/rdfcore/rdfms-empty-property-elements/test012.nt"" , false ) ; test2 . addTest ( test31 ) ; Test test32 = test1 . createPositiveTest ( ""http://www.w3.org/2000/10/rdf-tests/rdfcore/rdfms-empty-property-elements/Manifest.rdf#test013"" , ""http://www.w3.org/2000/10/rdf-tests/rdfcore/rdfms-empty-property-elements/test013.rdf"" , true , ""http://www.w3.org/2000/10/rdf-tests/rdfcore/rdfms-empty-property-elements/test013.nt"" , false ) ; test2 . addTest ( test32 ) ; Test test33 = test1 . createPositiveTest ( ""http://www.w3.org/2000/10/rdf-tests/rdfcore/rdf-containers-syntax-vs-schema/Manifest.rdf#test002"" , ""http://www.w3.org/2000/10/rdf-tests/rdfcore/rdf-containers-syntax-vs-schema/test002.rdf"" , true , ""http://www.w3.org/2000/10/rdf-tests/rdfcore/rdf-containers-syntax-vs-schema/test002.nt"" , false ) ; test2 . addTest ( test33 ) ; Test test34 = test1 . createPositiveTest ( ""http://www.w3.org/2000/10/rdf-tests/rdfcore/rdf-containers-syntax-vs-schema/Manifest.rdf#test003"" , ""http://www.w3.org/2000/10/rdf-tests/rdfcore/rdf-containers-syntax-vs-schema/test003.rdf"" , true , ""http://www.w3.org/2000/10/rdf-tests/rdfcore/rdf-containers-syntax-vs-schema/test003.nt"" , false ) ; test2 . addTest ( test34 ) ; Test test35 = test1 . createPositiveTest ( ""http://www.w3.org/2000/10/rdf-tests/rdfcore/rdf-ns-prefix-confusion/Manifest.rdf#test0006"" , ""http://www.w3.org/2000/10/rdf-tests/rdfcore/rdf-ns-prefix-confusion/test0006.rdf"" , true , ""http://www.w3.org/2000/10/rdf-tests/rdfcore/rdf-ns-prefix-confusion/test0006.nt"" , false ) ; test2 . addTest ( test35 ) ; Test test36 = test1 . createPositiveTest ( ""http://www.w3.org/2000/10/rdf-tests/rdfcore/rdf-ns-prefix-confusion/Manifest.rdf#test0005"" , ""http://www.w3.org/2000/10/rdf-tests/rdfcore/rdf-ns-prefix-confusion/test0005.rdf"" , true , ""http://www.w3.org/2000/10/rdf-tests/rdfcore/rdf-ns-prefix-confusion/test0005.nt"" , false ) ; test2 . addTest ( test36 ) ; Test test37 = test1 . createPositiveTest ( ""http://www.w3.org/2000/10/rdf-tests/rdfcore/rdfms-reification-required/Manifest.rdf#test001"" , ""http://www.w3.org/2000/10/rdf-tests/rdfcore/rdfms-reification-required/test001.rdf"" , true , ""http://www.w3.org/2000/10/rdf-tests/rdfcore/rdfms-reification-required/test001.nt"" , false ) ; test2 . addTest ( test37 ) ; Test test38 = test1 . createPositiveTest ( ""http://www.w3.org/2000/10/rdf-tests/rdfcore/rdfms-rdf-names-use/Manifest.rdf#test-021"" , ""http://www.w3.org/2000/10/rdf-tests/rdfcore/rdfms-rdf-names-use/test-021.rdf"" , true , ""http://www.w3.org/2000/10/rdf-tests/rdfcore/rdfms-rdf-names-use/test-021.nt"" , false ) ; test2 . addTest ( test38 ) ; Test test39 = test1 . createPositiveTest ( ""http://www.w3.org/2000/10/rdf-tests/rdfcore/rdfms-rdf-names-use/Manifest.rdf#test-020"" , ""http://www.w3.org/2000/10/rdf-tests/rdfcore/rdfms-rdf-names-use/test-020.rdf"" , true , ""http://www.w3.org/2000/10/rdf-tests/rdfcore/rdfms-rdf-names-use/test-020.nt"" , false ) ; test2 . addTest ( test39 ) ; Test test40 = test1 . createPositiveTest ( ""http://www.w3.org/2000/10/rdf-tests/rdfcore/rdfms-empty-property-elements/Manifest.rdf#test008"" , ""http://www.w3.org/2000/10/rdf-tests/rdfcore/rdfms-empty-property-elements/test008.rdf"" , true , ""http://www.w3.org/2000/10/rdf-tests/rdfcore/rdfms-empty-property-elements/test008.nt"" , false ) ; test2 . addTest ( test40 ) ; Test test41 = test1 . createPositiveTest ( ""http://www.w3.org/2000/10/rdf-tests/rdfcore/rdfms-empty-property-elements/Manifest.rdf#test007"" , ""http://www.w3.org/2000/10/rdf-tests/rdfcore/rdfms-empty-property-elements/test007.rdf"" , true , ""http://www.w3.org/2000/10/rdf-tests/rdfcore/rdfms-empty-property-elements/test007.nt"" , false ) ; test2 . addTest ( test41 ) ; Test test42 = test1 . createPositiveTest ( ""http://www.w3.org/2000/10/rdf-tests/rdfcore/rdf-containers-syntax-vs-schema/Manifest.rdf#test006"" , ""http://www.w3.org/2000/10/rdf-tests/rdfcore/rdf-containers-syntax-vs-schema/test006.rdf"" , true , ""http://www.w3.org/2000/10/rdf-tests/rdfcore/rdf-containers-syntax-vs-schema/test006.nt"" , false ) ; test2 . addTest ( test42 ) ; Test test43 = test1 . createNegativeTest ( ""http://www.w3.org/2000/10/rdf-tests/rdfcore/rdfms-rdf-names-use/Manifest.rdf#error-016"" , ""http://www.w3.org/2000/10/rdf-tests/rdfcore/rdfms-rdf-names-use/error-016.rdf"" , true , new int [ ] { 205 , } ) ; test2 . addTest ( test43 ) ; Test test44 = test1 . createPositiveTest ( ""http://www.w3.org/2000/10/rdf-tests/rdfcore/rdf-containers-syntax-vs-schema/Manifest.rdf#test007"" , ""http://www.w3.org/2000/10/rdf-tests/rdfcore/rdf-containers-syntax-vs-schema/test007.rdf"" , true , ""http://www.w3.org/2000/10/rdf-tests/rdfcore/rdf-containers-syntax-vs-schema/test007.nt"" , false ) ; test2 . addTest ( test44 ) ; Test test45 = test1 . createNegativeTest ( ""http://www.w3.org/2000/10/rdf-tests/rdfcore/rdfms-rdf-names-use/Manifest.rdf#error-015"" , ""http://www.w3.org/2000/10/rdf-tests/rdfcore/rdfms-rdf-names-use/error-015.rdf"" , true , new int [ ] { 205 , } ) ; test2 . addTest ( test45 ) ; Test test46 = test1 . createNegativeTest ( ""http://www.w3.org/2000/10/rdf-tests/rdfcore/rdfms-syntax-incomplete/Manifest.rdf#error005"" , ""http://www.w3.org/2000/10/rdf-tests/rdfcore/rdfms-syntax-incomplete/error005.rdf"" , true , null ) ; test2 . addTest ( test46 ) ; Test test47 = test1 . createNegativeTest ( ""http://www.w3.org/2000/10/rdf-tests/rdfcore/rdfms-syntax-incomplete/Manifest.rdf#error004"" , ""http://www.w3.org/2000/10/rdf-tests/rdfcore/rdfms-syntax-incomplete/error004.rdf"" , true , null ) ; test2 . addTest ( test47 ) ; Test test48 = test1 . createPositiveTest ( ""http://www.w3.org/2000/10/rdf-tests/rdfcore/rdf-ns-prefix-confusion/Manifest.rdf#test0003"" , ""http://www.w3.org/2000/10/rdf-tests/rdfcore/rdf-ns-prefix-confusion/test0003.rdf"" , true , ""http://www.w3.org/2000/10/rdf-tests/rdfcore/rdf-ns-prefix-confusion/test0003.nt"" , false ) ; test2 . addTest ( test48 ) ; Test test49 = test1 . createPositiveTest ( ""http://www.w3.org/2000/10/rdf-tests/rdfcore/rdf-ns-prefix-confusion/Manifest.rdf#test0004"" , ""http://www.w3.org/2000/10/rdf-tests/rdfcore/rdf-ns-prefix-confusion/test0004.rdf"" , true , ""http://www.w3.org/2000/10/rdf-tests/rdfcore/rdf-ns-prefix-confusion/test0004.nt"" , false ) ; test2 . addTest ( test49 ) ; Test test50 = test1 . createPositiveTest ( ""http://www.w3.org/2000/10/rdf-tests/rdfcore/rdfms-identity-anon-resources/Manifest.rdf#test005"" , ""http://www.w3.org/2000/10/rdf-tests/rdfcore/rdfms-identity-anon-resources/test005.rdf"" , true , ""http://www.w3.org/2000/10/rdf-tests/rdfcore/rdfms-identity-anon-resources/test005.nt"" , false ) ; test2 . addTest ( test50 ) ; Test test51 = test1 . createPositiveTest ( ""http://www.w3.org/2000/10/rdf-tests/rdfcore/xmlbase/Manifest.rdf#test014"" , ""http://www.w3.org/2000/10/rdf-tests/rdfcore/xmlbase/test014.rdf"" , true , ""http://www.w3.org/2000/10/rdf-tests/rdfcore/xmlbase/test014.nt"" , false ) ; test2 . addTest ( test51 ) ; Test test52 = test1 . createPositiveTest ( ""http://www.w3.org/2000/10/rdf-tests/rdfcore/rdf-ns-prefix-confusion/Manifest.rdf#test0009"" , ""http://www.w3.org/2000/10/rdf-tests/rdfcore/rdf-ns-prefix-confusion/test0009.rdf"" , true , ""http://www.w3.org/2000/10/rdf-tests/rdfcore/rdf-ns-prefix-confusion/test0009.nt"" , false ) ; test2 . addTest ( test52 ) ; Test test53 = test1 . createNegativeTest ( ""http://www.w3.org/2000/10/rdf-tests/rdfcore/rdfms-rdf-id/Manifest.rdf#error004"" , ""http://www.w3.org/2000/10/rdf-tests/rdfcore/rdfms-rdf-id/error004.rdf"" , true , null ) ; test2 . addTest ( test53 ) ; Test test54 = test1 . createNegativeTest ( ""http://www.w3.org/2000/10/rdf-tests/rdfcore/rdfms-rdf-id/Manifest.rdf#error005"" , ""http://www.w3.org/2000/10/rdf-tests/rdfcore/rdfms-rdf-id/error005.rdf"" , true , null ) ; test2 . addTest ( test54 ) ; Test test55 = test1 . createNegativeTest ( ""http://www.w3.org/2000/10/rdf-tests/rdfcore/rdfms-rdf-id/Manifest.rdf#error007"" , ""http://www.w3.org/2000/10/rdf-tests/rdfcore/rdfms-rdf-id/error007.rdf"" , true , null ) ; test2 . addTest ( test55 ) ; Test test56 = test1 . createNegativeTest ( ""http://www.w3.org/2000/10/rdf-tests/rdfcore/rdfms-rdf-id/Manifest.rdf#error006"" , ""http://www.w3.org/2000/10/rdf-tests/rdfcore/rdfms-rdf-id/error006.rdf"" , true , null ) ; test2 . addTest ( test56 ) ; Test test57 = test1 . createPositiveTest ( ""http://www.w3.org/2000/10/rdf-tests/rdfcore/amp-in-url/Manifest.rdf#test001"" , ""http://www.w3.org/2000/10/rdf-tests/rdfcore/amp-in-url/test001.rdf"" , true , ""http://www.w3.org/2000/10/rdf-tests/rdfcore/amp-in-url/test001.nt"" , false ) ; test2 . addTest ( test57 ) ; Test test58 = test1 . createPositiveTest ( ""http://www.w3.org/2000/10/rdf-tests/rdfcore/rdfms-syntax-incomplete/Manifest.rdf#test001"" , ""http://www.w3.org/2000/10/rdf-tests/rdfcore/rdfms-syntax-incomplete/test001.rdf"" , true , ""http://www.w3.org/2000/10/rdf-tests/rdfcore/rdfms-syntax-incomplete/test001.nt"" , false ) ; test2 . addTest ( test58 ) ; Test test59 = test1 . createNegativeTest ( ""http://www.w3.org/2000/10/rdf-tests/rdfcore/rdfms-abouteach/Manifest.rdf#error002"" , ""http://www.w3.org/2000/10/rdf-tests/rdfcore/rdfms-abouteach/error002.rdf"" , true , new int [ ] { 206 , } ) ; test2 . addTest ( test59 ) ; Test test60 = test1 . createNegativeTest ( ""http://www.w3.org/2000/10/rdf-tests/rdfcore/rdfms-rdf-id/Manifest.rdf#error002"" , ""http://www.w3.org/2000/10/rdf-tests/rdfcore/rdfms-rdf-id/error002.rdf"" , true , null ) ; test2 . addTest ( test60 ) ; Test test61 = test1 . createPositiveTest ( ""http://www.w3.org/2000/10/rdf-tests/rdfcore/rdf-containers-syntax-vs-schema/Manifest.rdf#test004"" , ""http://www.w3.org/2000/10/rdf-tests/rdfcore/rdf-containers-syntax-vs-schema/test004.rdf"" , true , ""http://www.w3.org/2000/10/rdf-tests/rdfcore/rdf-containers-syntax-vs-schema/test004.nt"" , false ) ; test2 . addTest ( test61 ) ; Test test62 = test1 . createNegativeTest ( ""http://www.w3.org/2000/10/rdf-tests/rdfcore/rdfms-rdf-id/Manifest.rdf#error003"" , ""http://www.w3.org/2000/10/rdf-tests/rdfcore/rdfms-rdf-id/error003.rdf"" , true , null ) ; test2 . addTest ( test62 ) ; Test test63 = test1 . createPositiveTest ( ""http://www.w3.org/2000/10/rdf-tests/rdfcore/datatypes/Manifest.rdf#test002"" , ""http://www.w3.org/2000/10/rdf-tests/rdfcore/datatypes/test002.rdf"" , true , ""http://www.w3.org/2000/10/rdf-tests/rdfcore/datatypes/test002.nt"" , false ) ; test2 . addTest ( test63 ) ; Test test64 = test1 . createPositiveTest ( ""http://www.w3.org/2000/10/rdf-tests/rdfcore/xmlbase/Manifest.rdf#test004"" , ""http://www.w3.org/2000/10/rdf-tests/rdfcore/xmlbase/test004.rdf"" , true , ""http://www.w3.org/2000/10/rdf-tests/rdfcore/xmlbase/test004.nt"" , false ) ; test2 . addTest ( test64 ) ; Test test65 = test1 . createPositiveTest ( ""http://www.w3.org/2000/10/rdf-tests/rdfcore/xmlbase/Manifest.rdf#test003"" , ""http://www.w3.org/2000/10/rdf-tests/rdfcore/xmlbase/test003.rdf"" , true , ""http://www.w3.org/2000/10/rdf-tests/rdfcore/xmlbase/test003.nt"" , false ) ; test2 . addTest ( test65 ) ; Test test66 = test1 . createNegativeTest ( ""http://www.w3.org/2000/10/rdf-tests/rdfcore/rdfms-difference-between-ID-and-about/Manifest.rdf#error1"" , ""http://www.w3.org/2000/10/rdf-tests/rdfcore/rdfms-difference-between-ID-and-about/error1.rdf"" , true , new int [ ] { 105 , } ) ; test2 . addTest ( test66 ) ; Test test67 = test1 . createPositiveTest ( ""http://www.w3.org/2000/10/rdf-tests/rdfcore/rdfms-rdf-names-use/Manifest.rdf#test-030"" , ""http://www.w3.org/2000/10/rdf-tests/rdfcore/rdfms-rdf-names-use/test-030.rdf"" , true , ""http://www.w3.org/2000/10/rdf-tests/rdfcore/rdfms-rdf-names-use/test-030.nt"" , false ) ; test2 . addTest ( test67 ) ; Test test68 = test1 . createPositiveTest ( ""http://www.w3.org/2000/10/rdf-tests/rdfcore/rdfms-identity-anon-resources/Manifest.rdf#test001"" , ""http://www.w3.org/2000/10/rdf-tests/rdfcore/rdfms-identity-anon-resources/test001.rdf"" , true , ""http://www.w3.org/2000/10/rdf-tests/rdfcore/rdfms-identity-anon-resources/test001.nt"" , false ) ; test2 . addTest ( test68 ) ; Test test69 = test1 . createPositiveTest ( ""http://www.w3.org/2000/10/rdf-tests/rdfcore/rdfms-identity-anon-resources/Manifest.rdf#test002"" , ""http://www.w3.org/2000/10/rdf-tests/rdfcore/rdfms-identity-anon-resources/test002.rdf"" , true , ""http://www.w3.org/2000/10/rdf-tests/rdfcore/rdfms-identity-anon-resources/test002.nt"" , false ) ; test2 . addTest ( test69 ) ; Test test70 = test1 . createPositiveTest ( ""http://www.w3.org/2000/10/rdf-tests/rdfcore/rdfms-syntax-incomplete/Manifest.rdf#test004"" , ""http://www.w3.org/2000/10/rdf-tests/rdfcore/rdfms-syntax-incomplete/test004.rdf"" , true , ""http://www.w3.org/2000/10/rdf-tests/rdfcore/rdfms-syntax-incomplete/test004.nt"" , false ) ; test2 . addTest ( test70 ) ; Test test71 = test1 . createWarningTest ( ""http://www.w3.org/2000/10/rdf-tests/rdfcore/rdfms-rdf-names-use/Manifest.rdf#warn-001"" , ""http://www.w3.org/2000/10/rdf-tests/rdfcore/rdfms-rdf-names-use/warn-001.rdf"" , true , ""http://www.w3.org/2000/10/rdf-tests/rdfcore/rdfms-rdf-names-use/warn-001.nt"" , false , null ) ; test2 . addTest ( test71 ) ; Test test72 = test1 . createPositiveTest ( ""http://www.w3.org/2000/10/rdf-tests/rdfcore/xml-canon/Manifest.rdf#test001"" , ""http://www.w3.org/2000/10/rdf-tests/rdfcore/xml-canon/test001.rdf"" , true , ""http://www.w3.org/2000/10/rdf-tests/rdfcore/xml-canon/test001.nt"" , false ) ; test2 . addTest ( test72 ) ; Test test73 = test1 . createNegativeTest ( ""http://www.w3.org/2000/10/rdf-tests/rdfcore/rdfms-abouteach/Manifest.rdf#error001"" , ""http://www.w3.org/2000/10/rdf-tests/rdfcore/rdfms-abouteach/error001.rdf"" , true , new int [ ] { 206 , } ) ; test2 . addTest ( test73 ) ; Test test74 = test1 . createPositiveTest ( ""http://www.w3.org/2000/10/rdf-tests/rdfcore/rdfms-not-id-and-resource-attr/Manifest.rdf#test001"" , ""http://www.w3.org/2000/10/rdf-tests/rdfcore/rdfms-not-id-and-resource-attr/test001.rdf"" , true , ""http://www.w3.org/2000/10/rdf-tests/rdfcore/rdfms-not-id-and-resource-attr/test001.nt"" , false ) ; test2 . addTest ( test74 ) ; Test test75 = test1 . createPositiveTest ( ""http://www.w3.org/2000/10/rdf-tests/rdfcore/rdfms-para196/Manifest.rdf#test001"" , ""http://www.w3.org/2000/10/rdf-tests/rdfcore/rdfms-para196/test001.rdf"" , true , ""http://www.w3.org/2000/10/rdf-tests/rdfcore/rdfms-para196/test001.nt"" , false ) ; test2 . addTest ( test75 ) ; Test test76 = test1 . createPositiveTest ( ""http://www.w3.org/2000/10/rdf-tests/rdfcore/rdfms-rdf-names-use/Manifest.rdf#test-006"" , ""http://www.w3.org/2000/10/rdf-tests/rdfcore/rdfms-rdf-names-use/test-006.rdf"" , true , ""http://www.w3.org/2000/10/rdf-tests/rdfcore/rdfms-rdf-names-use/test-006.nt"" , false ) ; test2 . addTest ( test76 ) ; Test test77 = test1 . createPositiveTest ( ""http://www.w3.org/2000/10/rdf-tests/rdfcore/rdfms-rdf-names-use/Manifest.rdf#test-007"" , ""http://www.w3.org/2000/10/rdf-tests/rdfcore/rdfms-rdf-names-use/test-007.rdf"" , true , ""http://www.w3.org/2000/10/rdf-tests/rdfcore/rdfms-rdf-names-use/test-007.nt"" , false ) ; test2 . addTest ( test77 ) ; Test test78 = test1 . createNegativeTest ( ""http://www.w3.org/2000/10/rdf-tests/rdfcore/rdf-containers-syntax-vs-schema/Manifest.rdf#error002"" , ""http://www.w3.org/2000/10/rdf-tests/rdfcore/rdf-containers-syntax-vs-schema/error002.rdf"" , true , new int [ ] { 204 , } ) ; test2 . addTest ( test78 ) ; Test test79 = test1 . createPositiveTest ( ""http://www.w3.org/2000/10/rdf-tests/rdfcore/rdfms-not-id-and-resource-attr/Manifest.rdf#test005"" , ""http://www.w3.org/2000/10/rdf-tests/rdfcore/rdfms-not-id-and-resource-attr/test005.rdf"" , true , ""http://www.w3.org/2000/10/rdf-tests/rdfcore/rdfms-not-id-and-resource-attr/test005.nt"" , false ) ; test2 . addTest ( test79 ) ; Test test80 = test1 . createPositiveTest ( ""http://www.w3.org/2000/10/rdf-tests/rdfcore/rdfms-not-id-and-resource-attr/Manifest.rdf#test004"" , ""http://www.w3.org/2000/10/rdf-tests/rdfcore/rdfms-not-id-and-resource-attr/test004.rdf"" , true , ""http://www.w3.org/2000/10/rdf-tests/rdfcore/rdfms-not-id-and-resource-attr/test004.nt"" , false ) ; test2 . addTest ( test80 ) ; Test test81 = test1 . createPositiveTest ( ""http://www.w3.org/2000/10/rdf-tests/rdfcore/rdf-charmod-uris/Manifest.rdf#test001"" , ""http://www.w3.org/2000/10/rdf-tests/rdfcore/rdf-charmod-uris/test001.rdf"" , true , ""http://www.w3.org/2000/10/rdf-tests/rdfcore/rdf-charmod-uris/test001.nt"" , false ) ; test2 . addTest ( test81 ) ; Test test82 = test1 . createPositiveTest ( ""http://www.w3.org/2000/10/rdf-tests/rdfcore/rdfms-rdf-names-use/Manifest.rdf#test-002"" , ""http://www.w3.org/2000/10/rdf-tests/rdfcore/rdfms-rdf-names-use/test-002.rdf"" , true , ""http://www.w3.org/2000/10/rdf-tests/rdfcore/rdfms-rdf-names-use/test-002.nt"" , false ) ; test2 . addTest ( test82 ) ; Test test83 = test1 . createPositiveTest ( ""http://www.w3.org/2000/10/rdf-tests/rdfcore/rdfms-duplicate-member-props/Manifest.rdf#test001"" , ""http://www.w3.org/2000/10/rdf-tests/rdfcore/rdfms-duplicate-member-props/test001.rdf"" , true , ""http://www.w3.org/2000/10/rdf-tests/rdfcore/rdfms-duplicate-member-props/test001.nt"" , false ) ; test2 . addTest ( test83 ) ; Test test84 = test1 . createPositiveTest ( ""http://www.w3.org/2000/10/rdf-tests/rdfcore/rdfms-rdf-names-use/Manifest.rdf#test-003"" , ""http://www.w3.org/2000/10/rdf-tests/rdfcore/rdfms-rdf-names-use/test-003.rdf"" , true , ""http://www.w3.org/2000/10/rdf-tests/rdfcore/rdfms-rdf-names-use/test-003.nt"" , false ) ; test2 . addTest ( test84 ) ; Test test85 = test1 . createPositiveTest ( ""http://www.w3.org/2000/10/rdf-tests/rdfcore/rdfms-seq-representation/Manifest.rdf#test001"" , ""http://www.w3.org/2000/10/rdf-tests/rdfcore/rdfms-seq-representation/test001.rdf"" , true , ""http://www.w3.org/2000/10/rdf-tests/rdfcore/rdfms-seq-representation/test001.nt"" , false ) ; test2 . addTest ( test85 ) ; Test test86 = test1 . createPositiveTest ( ""http://www.w3.org/2000/10/rdf-tests/rdfcore/rdf-containers-syntax-vs-schema/Manifest.rdf#test001"" , ""http://www.w3.org/2000/10/rdf-tests/rdfcore/rdf-containers-syntax-vs-schema/test001.rdf"" , true , ""http://www.w3.org/2000/10/rdf-tests/rdfcore/rdf-containers-syntax-vs-schema/test001.nt"" , false ) ; test2 . addTest ( test86 ) ; Test test87 = test1 . createNegativeTest ( ""http://www.w3.org/2000/10/rdf-tests/rdfcore/rdfms-rdf-names-use/Manifest.rdf#error-020"" , ""http://www.w3.org/2000/10/rdf-tests/rdfcore/rdfms-rdf-names-use/error-020.rdf"" , true , new int [ ] { 205 , } ) ; test2 . addTest ( test87 ) ; Test test88 = test1 . createPositiveTest ( ""http://www.w3.org/2000/10/rdf-tests/rdfcore/rdfms-rdf-names-use/Manifest.rdf#test-015"" , ""http://www.w3.org/2000/10/rdf-tests/rdfcore/rdfms-rdf-names-use/test-015.rdf"" , true , ""http://www.w3.org/2000/10/rdf-tests/rdfcore/rdfms-rdf-names-use/test-015.nt"" , false ) ; test2 . addTest ( test88 ) ; Test test89 = test1 . createPositiveTest ( ""http://www.w3.org/2000/10/rdf-tests/rdfcore/rdfms-rdf-names-use/Manifest.rdf#test-016"" , ""http://www.w3.org/2000/10/rdf-tests/rdfcore/rdfms-rdf-names-use/test-016.rdf"" , true , ""http://www.w3.org/2000/10/rdf-tests/rdfcore/rdfms-rdf-names-use/test-016.nt"" , false ) ; test2 . addTest ( test89 ) ; Test test90 = test1 . createPositiveTest ( ""http://www.w3.org/2000/10/rdf-tests/rdfcore/rdfms-difference-between-ID-and-about/Manifest.rdf#test1"" , ""http://www.w3.org/2000/10/rdf-tests/rdfcore/rdfms-difference-between-ID-and-about/test1.rdf"" , true , ""http://www.w3.org/2000/10/rdf-tests/rdfcore/rdfms-difference-between-ID-and-about/test1.nt"" , false ) ; test2 . addTest ( test90 ) ; Test test91 = test1 . createPositiveTest ( ""http://www.w3.org/2000/10/rdf-tests/rdfcore/xmlbase/Manifest.rdf#test007"" , ""http://www.w3.org/2000/10/rdf-tests/rdfcore/xmlbase/test007.rdf"" , true , ""http://www.w3.org/2000/10/rdf-tests/rdfcore/xmlbase/test007.nt"" , false ) ; test2 . addTest ( test91 ) ; Test test92 = test1 . createPositiveTest ( ""http://www.w3.org/2000/10/rdf-tests/rdfcore/xmlbase/Manifest.rdf#test008"" , ""http://www.w3.org/2000/10/rdf-tests/rdfcore/xmlbase/test008.rdf"" , true , ""http://www.w3.org/2000/10/rdf-tests/rdfcore/xmlbase/test008.nt"" , false ) ; test2 . addTest ( test92 ) ; Test test93 = test1 . createPositiveTest ( ""http://www.w3.org/2000/10/rdf-tests/rdfcore/rdfms-empty-property-elements/Manifest.rdf#test005"" , ""http://www.w3.org/2000/10/rdf-tests/rdfcore/rdfms-empty-property-elements/test005.rdf"" , true , ""http://www.w3.org/2000/10/rdf-tests/rdfcore/rdfms-empty-property-elements/test005.nt"" , false ) ; test2 . addTest ( test93 ) ; Test test94 = test1 . createPositiveTest ( ""http://www.w3.org/2000/10/rdf-tests/rdfcore/rdfms-empty-property-elements/Manifest.rdf#test006"" , ""http://www.w3.org/2000/10/rdf-tests/rdfcore/rdfms-empty-property-elements/test006.rdf"" , true , ""http://www.w3.org/2000/10/rdf-tests/rdfcore/rdfms-empty-property-elements/test006.nt"" , false ) ; test2 . addTest ( test94 ) ; Test test95 = test1 . createNegativeTest ( ""http://www.w3.org/2000/10/rdf-tests/rdfcore/rdfms-rdf-id/Manifest.rdf#error001"" , ""http://www.w3.org/2000/10/rdf-tests/rdfcore/rdfms-rdf-id/error001.rdf"" , true , null ) ; test2 . addTest ( test95 ) ; Test test96 = test1 . createPositiveTest ( ""http://www.w3.org/2000/10/rdf-tests/rdfcore/rdfms-rdf-names-use/Manifest.rdf#test-010"" , ""http://www.w3.org/2000/10/rdf-tests/rdfcore/rdfms-rdf-names-use/test-010.rdf"" , true , ""http://www.w3.org/2000/10/rdf-tests/rdfcore/rdfms-rdf-names-use/test-010.nt"" , false ) ; test2 . addTest ( test96 ) ; Test test97 = test1 . createPositiveTest ( ""http://www.w3.org/2000/10/rdf-tests/rdfcore/rdfms-xmllang/Manifest.rdf#test003"" , ""http://www.w3.org/2000/10/rdf-tests/rdfcore/rdfms-xmllang/test003.rdf"" , true , ""http://www.w3.org/2000/10/rdf-tests/rdfcore/rdfms-xmllang/test003.nt"" , false ) ; test2 . addTest ( test97 ) ; Test test98 = test1 . createPositiveTest ( ""http://www.w3.org/2000/10/rdf-tests/rdfcore/rdfms-xmllang/Manifest.rdf#test004"" , ""http://www.w3.org/2000/10/rdf-tests/rdfcore/rdfms-xmllang/test004.rdf"" , true , ""http://www.w3.org/2000/10/rdf-tests/rdfcore/rdfms-xmllang/test004.nt"" , false ) ; test2 . addTest ( test98 ) ; Test test99 = test1 . createNegativeTest ( ""http://www.w3.org/2000/10/rdf-tests/rdfcore/rdfms-empty-property-elements/Manifest.rdf#error001"" , ""http://www.w3.org/2000/10/rdf-tests/rdfcore/rdfms-empty-property-elements/error001.rdf"" , true , new int [ ] { 201 , } ) ; test2 . addTest ( test99 ) ; Test test100 = test1 . createNegativeTest ( ""http://www.w3.org/2000/10/rdf-tests/rdfcore/rdfms-empty-property-elements/Manifest.rdf#error002"" , ""http://www.w3.org/2000/10/rdf-tests/rdfcore/rdfms-empty-property-elements/error002.rdf"" , true , new int [ ] { 201 , } ) ; test2 . addTest ( test100 ) ; Test test101 = test1 . createPositiveTest ( ""http://www.w3.org/2000/10/rdf-tests/rdfcore/rdfms-rdf-names-use/Manifest.rdf#test-013"" , ""http://www.w3.org/2000/10/rdf-tests/rdfcore/rdfms-rdf-names-use/test-013.rdf"" , true , ""http://www.w3.org/2000/10/rdf-tests/rdfcore/rdfms-rdf-names-use/test-013.nt"" , false ) ; test2 . addTest ( test101 ) ; Test test102 = test1 . createPositiveTest ( ""http://www.w3.org/2000/10/rdf-tests/rdfcore/rdfms-rdf-names-use/Manifest.rdf#test-014"" , ""http://www.w3.org/2000/10/rdf-tests/rdfcore/rdfms-rdf-names-use/test-014.rdf"" , true , ""http://www.w3.org/2000/10/rdf-tests/rdfcore/rdfms-rdf-names-use/test-014.nt"" , false ) ; test2 . addTest ( test102 ) ; Test test103 = test1 . createPositiveTest ( ""http://www.w3.org/2000/10/rdf-tests/rdfcore/rdfms-rdf-names-use/Manifest.rdf#test-001"" , ""http://www.w3.org/2000/10/rdf-tests/rdfcore/rdfms-rdf-names-use/test-001.rdf"" , true , ""http://www.w3.org/2000/10/rdf-tests/rdfcore/rdfms-rdf-names-use/test-001.nt"" , false ) ; test2 . addTest ( test103 ) ; Test test104 = test1 . createPositiveTest ( ""http://www.w3.org/2000/10/rdf-tests/rdfcore/rdf-charmod-literals/Manifest.rdf#test001"" , ""http://www.w3.org/2000/10/rdf-tests/rdfcore/rdf-charmod-literals/test001.rdf"" , true , ""http://www.w3.org/2000/10/rdf-tests/rdfcore/rdf-charmod-literals/test001.nt"" , false ) ; test2 . addTest ( test104 ) ; Test test105 = test1 . createNegativeTest ( ""http://www.w3.org/2000/10/rdf-tests/rdfcore/rdfms-rdf-names-use/Manifest.rdf#error-007"" , ""http://www.w3.org/2000/10/rdf-tests/rdfcore/rdfms-rdf-names-use/error-007.rdf"" , true , new int [ ] { 205 , } ) ; test2 . addTest ( test105 ) ; Test test106 = test1 . createNegativeTest ( ""http://www.w3.org/2000/10/rdf-tests/rdfcore/rdfms-rdf-names-use/Manifest.rdf#error-006"" , ""http://www.w3.org/2000/10/rdf-tests/rdfcore/rdfms-rdf-names-use/error-006.rdf"" , true , new int [ ] { 205 , } ) ; test2 . addTest ( test106 ) ; Test test107 = test1 . createWarningTest ( ""http://www.w3.org/2000/10/rdf-tests/rdfcore/rdfms-rdf-names-use/Manifest.rdf#warn-003"" , ""http://www.w3.org/2000/10/rdf-tests/rdfcore/rdfms-rdf-names-use/warn-003.rdf"" , true , ""http://www.w3.org/2000/10/rdf-tests/rdfcore/rdfms-rdf-names-use/warn-003.nt"" , false , null ) ; test2 . addTest ( test107 ) ; Test test108 = test1 . createWarningTest ( ""http://www.w3.org/2000/10/rdf-tests/rdfcore/rdfms-rdf-names-use/Manifest.rdf#warn-002"" , ""http://www.w3.org/2000/10/rdf-tests/rdfcore/rdfms-rdf-names-use/warn-002.rdf"" , true , ""http://www.w3.org/2000/10/rdf-tests/rdfcore/rdfms-rdf-names-use/warn-002.nt"" , false , null ) ; test2 . addTest ( test108 ) ; Test test109 = test1 . createNegativeTest ( ""http://www.w3.org/2000/10/rdf-tests/rdfcore/rdfms-rdf-names-use/Manifest.rdf#error-014"" , ""http://www.w3.org/2000/10/rdf-tests/rdfcore/rdfms-rdf-names-use/error-014.rdf"" , true , new int [ ] { 205 , } ) ; test2 . addTest ( test109 ) ; Test test110 = test1 . createNegativeTest ( ""http://www.w3.org/2000/10/rdf-tests/rdfcore/rdfms-rdf-names-use/Manifest.rdf#error-013"" , ""http://www.w3.org/2000/10/rdf-tests/rdfcore/rdfms-rdf-names-use/error-013.rdf"" , true , new int [ ] { 205 , } ) ; test2 . addTest ( test110 ) ; Test test111 = test1 . createPositiveTest ( ""http://www.w3.org/2000/10/rdf-tests/rdfcore/rdfms-identity-anon-resources/Manifest.rdf#test003"" , ""http://www.w3.org/2000/10/rdf-tests/rdfcore/rdfms-identity-anon-resources/test003.rdf"" , true , ""http://www.w3.org/2000/10/rdf-tests/rdfcore/rdfms-identity-anon-resources/test003.nt"" , false ) ; test2 . addTest ( test111 ) ; Test test112 = test1 . createPositiveTest ( ""http://www.w3.org/2000/10/rdf-tests/rdfcore/rdfms-identity-anon-resources/Manifest.rdf#test004"" , ""http://www.w3.org/2000/10/rdf-tests/rdfcore/rdfms-identity-anon-resources/test004.rdf"" , true , ""http://www.w3.org/2000/10/rdf-tests/rdfcore/rdfms-identity-anon-resources/test004.nt"" , false ) ; test2 . addTest ( test112 ) ; Test test113 = test1 . createNegativeTest ( ""http://www.w3.org/2000/10/rdf-tests/rdfcore/rdfms-rdf-names-use/Manifest.rdf#error-017"" , ""http://www.w3.org/2000/10/rdf-tests/rdfcore/rdfms-rdf-names-use/error-017.rdf"" , true , new int [ ] { 205 , } ) ; test2 . addTest ( test113 ) ; Test test114 = test1 . createNegativeTest ( ""http://www.w3.org/2000/10/rdf-tests/rdfcore/rdfms-rdf-names-use/Manifest.rdf#error-018"" , ""http://www.w3.org/2000/10/rdf-tests/rdfcore/rdfms-rdf-names-use/error-018.rdf"" , true , new int [ ] { 205 , } ) ; test2 . addTest ( test114 ) ; Test test115 = test1 . createPositiveTest ( ""http://www.w3.org/2000/10/rdf-tests/rdfcore/rdfms-empty-property-elements/Manifest.rdf#test009"" , ""http://www.w3.org/2000/10/rdf-tests/rdfcore/rdfms-empty-property-elements/test009.rdf"" , true , ""http://www.w3.org/2000/10/rdf-tests/rdfcore/rdfms-empty-property-elements/test009.nt"" , false ) ; test2 . addTest ( test115 ) ; Test test116 = test1 . createPositiveTest ( ""http://www.w3.org/2000/10/rdf-tests/rdfcore/rdfms-xml-literal-namespaces/Manifest.rdf#test002"" , ""http://www.w3.org/2000/10/rdf-tests/rdfcore/rdfms-xml-literal-namespaces/test002.rdf"" , true , ""http://www.w3.org/2000/10/rdf-tests/rdfcore/rdfms-xml-literal-namespaces/test002.nt"" , false ) ; test2 . addTest ( test116 ) ; Test test117 = test1 . createPositiveTest ( ""http://www.w3.org/2000/10/rdf-tests/rdfcore/rdfms-xmllang/Manifest.rdf#test001"" , ""http://www.w3.org/2000/10/rdf-tests/rdfcore/rdfms-xmllang/test001.rdf"" , true , ""http://www.w3.org/2000/10/rdf-tests/rdfcore/rdfms-xmllang/test001.nt"" , false ) ; test2 . addTest ( test117 ) ; Test test118 = test1 . createPositiveTest ( ""http://www.w3.org/2000/10/rdf-tests/rdfcore/rdfms-xmllang/Manifest.rdf#test002"" , ""http://www.w3.org/2000/10/rdf-tests/rdfcore/rdfms-xmllang/test002.rdf"" , true , ""http://www.w3.org/2000/10/rdf-tests/rdfcore/rdfms-xmllang/test002.nt"" , false ) ; test2 . addTest ( test118 ) ; Test test119 = test1 . createNegativeTest ( ""http://www.w3.org/2000/10/rdf-tests/rdfcore/rdfms-syntax-incomplete/Manifest.rdf#error006"" , ""http://www.w3.org/2000/10/rdf-tests/rdfcore/rdfms-syntax-incomplete/error006.rdf"" , true , null ) ; test2 . addTest ( test119 ) ; Test test120 = test1 . createPositiveTest ( ""http://www.w3.org/2000/10/rdf-tests/rdfcore/rdf-containers-syntax-vs-schema/Manifest.rdf#test008"" , ""http://www.w3.org/2000/10/rdf-tests/rdfcore/rdf-containers-syntax-vs-schema/test008.rdf"" , true , ""http://www.w3.org/2000/10/rdf-tests/rdfcore/rdf-containers-syntax-vs-schema/test008.nt"" , false ) ; test2 . addTest ( test120 ) ; Test test121 = test1 . createPositiveTest ( ""http://www.w3.org/2000/10/rdf-tests/rdfcore/rdfms-rdf-names-use/Manifest.rdf#test-026"" , ""http://www.w3.org/2000/10/rdf-tests/rdfcore/rdfms-rdf-names-use/test-026.rdf"" , true , ""http://www.w3.org/2000/10/rdf-tests/rdfcore/rdfms-rdf-names-use/test-026.nt"" , false ) ; test2 . addTest ( test121 ) ; Test test122 = test1 . createPositiveTest ( ""http://www.w3.org/2000/10/rdf-tests/rdfcore/rdfms-rdf-names-use/Manifest.rdf#test-027"" , ""http://www.w3.org/2000/10/rdf-tests/rdfcore/rdfms-rdf-names-use/test-027.rdf"" , true , ""http://www.w3.org/2000/10/rdf-tests/rdfcore/rdfms-rdf-names-use/test-027.nt"" , false ) ; test2 . addTest ( test122 ) ; Test test123 = test1 . createNegativeTest ( ""http://www.w3.org/2000/10/rdf-tests/rdfcore/rdfms-rdf-names-use/Manifest.rdf#error-010"" , ""http://www.w3.org/2000/10/rdf-tests/rdfcore/rdfms-rdf-names-use/error-010.rdf"" , true , new int [ ] { 205 , } ) ; test2 . addTest ( test123 ) ; Test test124 = test1 . createPositiveTest ( ""http://www.w3.org/2000/10/rdf-tests/rdfcore/rdfms-empty-property-elements/Manifest.rdf#test011"" , ""http://www.w3.org/2000/10/rdf-tests/rdfcore/rdfms-empty-property-elements/test011.rdf"" , true , ""http://www.w3.org/2000/10/rdf-tests/rdfcore/rdfms-empty-property-elements/test011.nt"" , false ) ; test2 . addTest ( test124 ) ; Test test125 = test1 . createPositiveTest ( ""http://www.w3.org/2000/10/rdf-tests/rdfcore/rdfms-empty-property-elements/Manifest.rdf#test010"" , ""http://www.w3.org/2000/10/rdf-tests/rdfcore/rdfms-empty-property-elements/test010.rdf"" , true , ""http://www.w3.org/2000/10/rdf-tests/rdfcore/rdfms-empty-property-elements/test010.nt"" , false ) ; test2 . addTest ( test125 ) ; Test test126 = test1 . createPositiveTest ( ""http://www.w3.org/2000/10/rdf-tests/rdfcore/rdfms-rdf-names-use/Manifest.rdf#test-019"" , ""http://www.w3.org/2000/10/rdf-tests/rdfcore/rdfms-rdf-names-use/test-019.rdf"" , true , ""http://www.w3.org/2000/10/rdf-tests/rdfcore/rdfms-rdf-names-use/test-019.nt"" , false ) ; test2 . addTest ( test126 ) ; Test test127 = test1 . createPositiveTest ( ""http://www.w3.org/2000/10/rdf-tests/rdfcore/rdfms-empty-property-elements/Manifest.rdf#test001"" , ""http://www.w3.org/2000/10/rdf-tests/rdfcore/rdfms-empty-property-elements/test001.rdf"" , true , ""http://www.w3.org/2000/10/rdf-tests/rdfcore/rdfms-empty-property-elements/test001.nt"" , false ) ; test2 . addTest ( test127 ) ; Test test128 = test1 . createPositiveTest ( ""http://www.w3.org/2000/10/rdf-tests/rdfcore/rdfms-empty-property-elements/Manifest.rdf#test002"" , ""http://www.w3.org/2000/10/rdf-tests/rdfcore/rdfms-empty-property-elements/test002.rdf"" , true , ""http://www.w3.org/2000/10/rdf-tests/rdfcore/rdfms-empty-property-elements/test002.nt"" , false ) ; test2 . addTest ( test128 ) ; Test test129 = test1 . createPositiveTest ( ""http://www.w3.org/2000/10/rdf-tests/rdfcore/rdf-ns-prefix-confusion/Manifest.rdf#test0014"" , ""http://www.w3.org/2000/10/rdf-tests/rdfcore/rdf-ns-prefix-confusion/test0014.rdf"" , true , ""http://www.w3.org/2000/10/rdf-tests/rdfcore/rdf-ns-prefix-confusion/test0014.nt"" , false ) ; test2 . addTest ( test129 ) ; Test test130 = test1 . createNegativeTest ( ""http://www.w3.org/2000/10/rdf-tests/rdfcore/rdf-containers-syntax-vs-schema/Manifest.rdf#error001"" , ""http://www.w3.org/2000/10/rdf-tests/rdfcore/rdf-containers-syntax-vs-schema/error001.rdf"" , true , new int [ ] { 206 , } ) ; test2 . addTest ( test130 ) ; Test test131 = test1 . createPositiveTest ( ""http://www.w3.org/2000/10/rdf-tests/rdfcore/rdfms-syntax-incomplete/Manifest.rdf#test003"" , ""http://www.w3.org/2000/10/rdf-tests/rdfcore/rdfms-syntax-incomplete/test003.rdf"" , true , ""http://www.w3.org/2000/10/rdf-tests/rdfcore/rdfms-syntax-incomplete/test003.nt"" , false ) ; test2 . addTest ( test131 ) ; Test test132 = test1 . createPositiveTest ( ""http://www.w3.org/2000/10/rdf-tests/rdfcore/rdfms-syntax-incomplete/Manifest.rdf#test002"" , ""http://www.w3.org/2000/10/rdf-tests/rdfcore/rdfms-syntax-incomplete/test002.rdf"" , true , ""http://www.w3.org/2000/10/rdf-tests/rdfcore/rdfms-syntax-incomplete/test002.nt"" , false ) ; test2 . addTest ( test132 ) ; Test test133 = test1 . createNegativeTest ( ""http://www.w3.org/2000/10/rdf-tests/rdfcore/rdfms-rdf-names-use/Manifest.rdf#error-012"" , ""http://www.w3.org/2000/10/rdf-tests/rdfcore/rdfms-rdf-names-use/error-012.rdf"" , true , new int [ ] { 205 , } ) ; test2 . addTest ( test133 ) ; Test test134 = test1 . createNegativeTest ( ""http://www.w3.org/2000/10/rdf-tests/rdfcore/rdfms-rdf-names-use/Manifest.rdf#error-011"" , ""http://www.w3.org/2000/10/rdf-tests/rdfcore/rdfms-rdf-names-use/error-011.rdf"" , true , new int [ ] { 205 , } ) ; test2 . addTest ( test134 ) ; Test test135 = test1 . createNegativeTest ( ""http://www.w3.org/2000/10/rdf-tests/rdfcore/rdfms-syntax-incomplete/Manifest.rdf#error001"" , ""http://www.w3.org/2000/10/rdf-tests/rdfcore/rdfms-syntax-incomplete/error001.rdf"" , true , null ) ; test2 . addTest ( test135 ) ; Test test136 = test1 . createPositiveTest ( ""http://www.w3.org/2000/10/rdf-tests/rdfcore/rdfms-rdf-names-use/Manifest.rdf#test-034"" , ""http://www.w3.org/2000/10/rdf-tests/rdfcore/rdfms-rdf-names-use/test-034.rdf"" , true , ""http://www.w3.org/2000/10/rdf-tests/rdfcore/rdfms-rdf-names-use/test-034.nt"" , false ) ; test2 . addTest ( test136 ) ; Test test137 = test1 . createPositiveTest ( ""http://www.w3.org/2000/10/rdf-tests/rdfcore/rdfms-rdf-names-use/Manifest.rdf#test-033"" , ""http://www.w3.org/2000/10/rdf-tests/rdfcore/rdfms-rdf-names-use/test-033.rdf"" , true , ""http://www.w3.org/2000/10/rdf-tests/rdfcore/rdfms-rdf-names-use/test-033.nt"" , false ) ; test2 . addTest ( test137 ) ; Test test138 = test1 . createPositiveTest ( ""http://www.w3.org/2000/10/rdf-tests/rdfcore/rdfms-rdf-names-use/Manifest.rdf#test-037"" , ""http://www.w3.org/2000/10/rdf-tests/rdfcore/rdfms-rdf-names-use/test-037.rdf"" , true , ""http://www.w3.org/2000/10/rdf-tests/rdfcore/rdfms-rdf-names-use/test-037.nt"" , false ) ; test2 . addTest ( test138 ) ; Test test139 = test1 . createPositiveTest ( ""http://www.w3.org/2000/10/rdf-tests/rdfcore/rdfms-rdf-names-use/Manifest.rdf#test-036"" , ""http://www.w3.org/2000/10/rdf-tests/rdfcore/rdfms-rdf-names-use/test-036.rdf"" , true , ""http://www.w3.org/2000/10/rdf-tests/rdfcore/rdfms-rdf-names-use/test-036.nt"" , false ) ; test2 . addTest ( test139 ) ; Test test140 = test1 . createPositiveTest ( ""http://www.w3.org/2000/10/rdf-tests/rdfcore/rdfms-rdf-names-use/Manifest.rdf#test-035"" , ""http://www.w3.org/2000/10/rdf-tests/rdfcore/rdfms-rdf-names-use/test-035.rdf"" , true , ""http://www.w3.org/2000/10/rdf-tests/rdfcore/rdfms-rdf-names-use/test-035.nt"" , false ) ; test2 . addTest ( test140 ) ; Test test141 = test1 . createNegativeTest ( ""http://www.w3.org/2000/10/rdf-tests/rdfcore/rdfms-syntax-incomplete/Manifest.rdf#error003"" , ""http://www.w3.org/2000/10/rdf-tests/rdfcore/rdfms-syntax-incomplete/error003.rdf"" , true , null ) ; test2 . addTest ( test141 ) ; Test test142 = test1 . createNegativeTest ( ""http://www.w3.org/2000/10/rdf-tests/rdfcore/rdfms-syntax-incomplete/Manifest.rdf#error002"" , ""http://www.w3.org/2000/10/rdf-tests/rdfcore/rdfms-syntax-incomplete/error002.rdf"" , true , null ) ; test2 . addTest ( test142 ) ; Test test143 = test1 . createPositiveTest ( ""http://www.w3.org/2000/10/rdf-tests/rdfcore/rdfms-difference-between-ID-and-about/Manifest.rdf#test2"" , ""http://www.w3.org/2000/10/rdf-tests/rdfcore/rdfms-difference-between-ID-and-about/test2.rdf"" , true , ""http://www.w3.org/2000/10/rdf-tests/rdfcore/rdfms-difference-between-ID-and-about/test2.nt"" , false ) ; test2 . addTest ( test143 ) ; Test test144 = test1 . createPositiveTest ( ""http://www.w3.org/2000/10/rdf-tests/rdfcore/rdfms-rdf-names-use/Manifest.rdf#test-008"" , ""http://www.w3.org/2000/10/rdf-tests/rdfcore/rdfms-rdf-names-use/test-008.rdf"" , true , ""http://www.w3.org/2000/10/rdf-tests/rdfcore/rdfms-rdf-names-use/test-008.nt"" , false ) ; test2 . addTest ( test144 ) ; Test test145 = test1 . createPositiveTest ( ""http://www.w3.org/2000/10/rdf-tests/rdfcore/rdfms-rdf-names-use/Manifest.rdf#test-009"" , ""http://www.w3.org/2000/10/rdf-tests/rdfcore/rdfms-rdf-names-use/test-009.rdf"" , true , ""http://www.w3.org/2000/10/rdf-tests/rdfcore/rdfms-rdf-names-use/test-009.nt"" , false ) ; test2 . addTest ( test145 ) ; Test test146 = test1 . createPositiveTest ( ""http://www.w3.org/2000/10/rdf-tests/rdfcore/rdfms-rdf-names-use/Manifest.rdf#test-032"" , ""http://www.w3.org/2000/10/rdf-tests/rdfcore/rdfms-rdf-names-use/test-032.rdf"" , true , ""http://www.w3.org/2000/10/rdf-tests/rdfcore/rdfms-rdf-names-use/test-032.nt"" , false ) ; test2 . addTest ( test146 ) ; Test test147 = test1 . createPositiveTest ( ""http://www.w3.org/2000/10/rdf-tests/rdfcore/rdfms-rdf-names-use/Manifest.rdf#test-031"" , ""http://www.w3.org/2000/10/rdf-tests/rdfcore/rdfms-rdf-names-use/test-031.rdf"" , true , ""http://www.w3.org/2000/10/rdf-tests/rdfcore/rdfms-rdf-names-use/test-031.nt"" , false ) ; test2 . addTest ( test147 ) ; Test test148 = test1 . createPositiveTest ( ""http://www.w3.org/2000/10/rdf-tests/rdfcore/rdf-ns-prefix-confusion/Manifest.rdf#test0001"" , ""http://www.w3.org/2000/10/rdf-tests/rdfcore/rdf-ns-prefix-confusion/test0001.rdf"" , true , ""http://www.w3.org/2000/10/rdf-tests/rdfcore/rdf-ns-prefix-confusion/test0001.nt"" , false ) ; test2 . addTest ( test148 ) ; Test test149 = test1 . createNegativeTest ( ""http://www.w3.org/2000/10/rdf-tests/rdfcore/rdfms-rdf-names-use/Manifest.rdf#error-008"" , ""http://www.w3.org/2000/10/rdf-tests/rdfcore/rdfms-rdf-names-use/error-008.rdf"" , true , new int [ ] { 204 , } ) ; test2 . addTest ( test149 ) ; Test test150 = test1 . createNegativeTest ( ""http://www.w3.org/2000/10/rdf-tests/rdfcore/rdfms-rdf-names-use/Manifest.rdf#error-009"" , ""http://www.w3.org/2000/10/rdf-tests/rdfcore/rdfms-rdf-names-use/error-009.rdf"" , true , new int [ ] { 205 , } ) ; test2 . addTest ( test150 ) ; Test test151 = test1 . createPositiveTest ( ""http://www.w3.org/2000/10/rdf-tests/rdfcore/xmlbase/Manifest.rdf#test006"" , ""http://www.w3.org/2000/10/rdf-tests/rdfcore/xmlbase/test006.rdf"" , true , ""http://www.w3.org/2000/10/rdf-tests/rdfcore/xmlbase/test006.nt"" , false ) ; test2 . addTest ( test151 ) ; Test test152 = test1 . createPositiveTest ( ""http://www.w3.org/2000/10/rdf-tests/rdfcore/rdfms-uri-substructure/Manifest.rdf#test001"" , ""http://www.w3.org/2000/10/rdf-tests/rdfcore/rdfms-uri-substructure/test001.rdf"" , true , ""http://www.w3.org/2000/10/rdf-tests/rdfcore/rdfms-uri-substructure/test001.nt"" , false ) ; test2 . addTest ( test152 ) ; Test test153 = test1 . createNegativeTest ( ""http://www.w3.org/2000/10/rdf-tests/rdfcore/rdfms-empty-property-elements/Manifest.rdf#error003"" , ""http://www.w3.org/2000/10/rdf-tests/rdfcore/rdfms-empty-property-elements/error003.rdf"" , true , new int [ ] { 201 , } ) ; test2 . addTest ( test153 ) ; Test test154 = test1 . createNegativeTest ( ""http://www.w3.org/2000/10/rdf-tests/rdfcore/rdfms-rdf-names-use/Manifest.rdf#error-002"" , ""http://www.w3.org/2000/10/rdf-tests/rdfcore/rdfms-rdf-names-use/error-002.rdf"" , true , new int [ ] { 205 , } ) ; test2 . addTest ( test154 ) ; Test test155 = test1 . createNegativeTest ( ""http://www.w3.org/2000/10/rdf-tests/rdfcore/rdfms-rdf-names-use/Manifest.rdf#error-003"" , ""http://www.w3.org/2000/10/rdf-tests/rdfcore/rdfms-rdf-names-use/error-003.rdf"" , true , new int [ ] { 205 , } ) ; test2 . addTest ( test155 ) ; Test test156 = test1 . createPositiveTest ( ""http://www.w3.org/2000/10/rdf-tests/rdfcore/xmlbase/Manifest.rdf#test013"" , ""http://www.w3.org/2000/10/rdf-tests/rdfcore/xmlbase/test013.rdf"" , true , ""http://www.w3.org/2000/10/rdf-tests/rdfcore/xmlbase/test013.nt"" , false ) ; test2 . addTest ( test156 ) ; Test test157 = test1 . createPositiveTest ( ""http://www.w3.org/2000/10/rdf-tests/rdfcore/rdfms-rdf-names-use/Manifest.rdf#test-022"" , ""http://www.w3.org/2000/10/rdf-tests/rdfcore/rdfms-rdf-names-use/test-022.rdf"" , true , ""http://www.w3.org/2000/10/rdf-tests/rdfcore/rdfms-rdf-names-use/test-022.nt"" , false ) ; test2 . addTest ( test157 ) ; Test test158 = test1 . createPositiveTest ( ""http://www.w3.org/2000/10/rdf-tests/rdfcore/rdfms-rdf-names-use/Manifest.rdf#test-023"" , ""http://www.w3.org/2000/10/rdf-tests/rdfcore/rdfms-rdf-names-use/test-023.rdf"" , true , ""http://www.w3.org/2000/10/rdf-tests/rdfcore/rdfms-rdf-names-use/test-023.nt"" , false ) ; test2 . addTest ( test158 ) ; Test test159 = test1 . createPositiveTest ( ""http://www.w3.org/2000/10/rdf-tests/rdfcore/rdfms-rdf-names-use/Manifest.rdf#test-004"" , ""http://www.w3.org/2000/10/rdf-tests/rdfcore/rdfms-rdf-names-use/test-004.rdf"" , true , ""http://www.w3.org/2000/10/rdf-tests/rdfcore/rdfms-rdf-names-use/test-004.nt"" , false ) ; test2 . addTest ( test159 ) ; Test test160 = test1 . createPositiveTest ( ""http://www.w3.org/2000/10/rdf-tests/rdfcore/rdfms-rdf-names-use/Manifest.rdf#test-005"" , ""http://www.w3.org/2000/10/rdf-tests/rdfcore/rdfms-rdf-names-use/test-005.rdf"" , true , ""http://www.w3.org/2000/10/rdf-tests/rdfcore/rdfms-rdf-names-use/test-005.nt"" , false ) ; test2 . addTest ( test160 ) ; Test test161 = test1 . createPositiveTest ( ""http://www.w3.org/2000/10/rdf-tests/rdfcore/rdfms-not-id-and-resource-attr/Manifest.rdf#test002"" , ""http://www.w3.org/2000/10/rdf-tests/rdfcore/rdfms-not-id-and-resource-attr/test002.rdf"" , true , ""http://www.w3.org/2000/10/rdf-tests/rdfcore/rdfms-not-id-and-resource-attr/test002.nt"" , false ) ; test2 . addTest ( test161 ) ; Test test162 = test1 . createPositiveTest ( ""http://www.w3.org/2000/10/rdf-tests/rdfcore/rdfms-empty-property-elements/Manifest.rdf#test014"" , ""http://www.w3.org/2000/10/rdf-tests/rdfcore/rdfms-empty-property-elements/test014.rdf"" , true , ""http://www.w3.org/2000/10/rdf-tests/rdfcore/rdfms-empty-property-elements/test014.nt"" , false ) ; test2 . addTest ( test162 ) ; Test test163 = test1 . createPositiveTest ( ""http://www.w3.org/2000/10/rdf-tests/rdfcore/rdfms-empty-property-elements/Manifest.rdf#test015"" , ""http://www.w3.org/2000/10/rdf-tests/rdfcore/rdfms-empty-property-elements/test015.rdf"" , true , ""http://www.w3.org/2000/10/rdf-tests/rdfcore/rdfms-empty-property-elements/test015.nt"" , false ) ; test2 . addTest ( test163 ) ; Test test164 = test1 . createPositiveTest ( ""http://www.w3.org/2000/10/rdf-tests/rdfcore/rdf-charmod-uris/Manifest.rdf#test002"" , ""http://www.w3.org/2000/10/rdf-tests/rdfcore/rdf-charmod-uris/test002.rdf"" , true , ""http://www.w3.org/2000/10/rdf-tests/rdfcore/rdf-charmod-uris/test002.nt"" , false ) ; test2 . addTest ( test164 ) ; Test test165 = test1 . createPositiveTest ( ""http://www.w3.org/2000/10/rdf-tests/rdfcore/rdf-ns-prefix-confusion/Manifest.rdf#test0011"" , ""http://www.w3.org/2000/10/rdf-tests/rdfcore/rdf-ns-prefix-confusion/test0011.rdf"" , true , ""http://www.w3.org/2000/10/rdf-tests/rdfcore/rdf-ns-prefix-confusion/test0011.nt"" , false ) ; test2 . addTest ( test165 ) ; Test test166 = test1 . createPositiveTest ( ""http://www.w3.org/2000/10/rdf-tests/rdfcore/rdf-ns-prefix-confusion/Manifest.rdf#test0010"" , ""http://www.w3.org/2000/10/rdf-tests/rdfcore/rdf-ns-prefix-confusion/test0010.rdf"" , true , ""http://www.w3.org/2000/10/rdf-tests/rdfcore/rdf-ns-prefix-confusion/test0010.nt"" , false ) ; test2 . addTest ( test166 ) ; Test test167 = test1 . createPositiveTest ( ""http://www.w3.org/2000/10/rdf-tests/rdfcore/rdfms-rdf-names-use/Manifest.rdf#test-012"" , ""http://www.w3.org/2000/10/rdf-tests/rdfcore/rdfms-rdf-names-use/test-012.rdf"" , true , ""http://www.w3.org/2000/10/rdf-tests/rdfcore/rdfms-rdf-names-use/test-012.nt"" , false ) ; test2 . addTest ( test167 ) ; Test test168 = test1 . createPositiveTest ( ""http://www.w3.org/2000/10/rdf-tests/rdfcore/rdfms-rdf-names-use/Manifest.rdf#test-011"" , ""http://www.w3.org/2000/10/rdf-tests/rdfcore/rdfms-rdf-names-use/test-011.rdf"" , true , ""http://www.w3.org/2000/10/rdf-tests/rdfcore/rdfms-rdf-names-use/test-011.nt"" , false ) ; test2 . addTest ( test168 ) ; test1 . addTest ( test2 ) ; TestSuite test169 = new TestSuite ( ""PENDING"" ) ; Test test170 = test1 . createPositiveTest ( ""http://www.w3.org/2000/10/rdf-tests/rdfcore/rdfms-empty-property-elements/Manifest.rdf#test016"" , ""http://www.w3.org/2000/10/rdf-tests/rdfcore/rdfms-empty-property-elements/test016.rdf"" , true , ""http://www.w3.org/2000/10/rdf-tests/rdfcore/rdfms-empty-property-elements/test016.nt"" , false ) ; test169 . addTest ( test170 ) ; Test test171 = test1 . createPositiveTest ( ""http://www.w3.org/2000/10/rdf-tests/rdfcore/rdfms-empty-property-elements/Manifest.rdf#test017"" , ""http://www.w3.org/2000/10/rdf-tests/rdfcore/rdfms-empty-property-elements/test017.rdf"" , true , ""http://www.w3.org/2000/10/rdf-tests/rdfcore/rdfms-empty-property-elements/test017.nt"" , false ) ; test169 . addTest ( test171 ) ; Test test172 = test1 . createPositiveTest ( ""http://www.w3.org/2000/10/rdf-tests/rdfcore/rdfms-difference-between-ID-and-about/Manifest.rdf#test3"" , ""http://www.w3.org/2000/10/rdf-tests/rdfcore/rdfms-difference-between-ID-and-about/test3.rdf"" , true , ""http://www.w3.org/2000/10/rdf-tests/rdfcore/rdfms-difference-between-ID-and-about/test3.nt"" , false ) ; test169 . addTest ( test172 ) ; test1 . addTest ( test169 ) ; test0 . addTest ( test1 ) ; WGTestSuite test175 = new org . apache . jena . rdfxml . xmlinput . WGTestSuite ( new InputStreamFactoryTests ( IRIFactory . iriImplementation ( ) . create ( ""http://jcarroll.hpl.hp.com/arp-tests/"" ) , ""arp"" ) , ""ARP Tests"" , false ) ; TestSuite test176 = new TestSuite ( ""ARP"" ) ; Test test177 = test175 . createPositiveTest ( ""http://jcarroll.hpl.hp.com/arp-tests/xml-literals/reported3"" , ""http://jcarroll.hpl.hp.com/arp-tests/xml-literals/reported3.rdf"" , true , ""http://jcarroll.hpl.hp.com/arp-tests/xml-literals/reported3.nt"" , false ) ; test176 . addTest ( test177 ) ; Test test177x = test175 . createPositiveTest ( ""http://jcarroll.hpl.hp.com/arp-tests/xml-literals/html"" , ""http://jcarroll.hpl.hp.com/arp-tests/xml-literals/html.rdf"" , true , ""http://jcarroll.hpl.hp.com/arp-tests/xml-literals/html.nt"" , false ) ; test176 . addTest ( test177x ) ; Test test178 = test175 . createWarningTest ( ""http://jcarroll.hpl.hp.com/arp-tests/rdf-nnn/67_6"" , ""http://jcarroll.hpl.hp.com/arp-tests/rdf-nnn/bad-bug67_6.rdf"" , true , ""http://jcarroll.hpl.hp.com/arp-tests/rdf-nnn/bad-bug67_6.nt"" , false , new int [ ] { 103 , } ) ; test176 . addTest ( test178 ) ; Test test179 = test175 . createWarningTest ( ""http://jcarroll.hpl.hp.com/arp-tests/rdf-nnn/67_5"" , ""http://jcarroll.hpl.hp.com/arp-tests/rdf-nnn/bad-bug67_5.rdf"" , true , ""http://jcarroll.hpl.hp.com/arp-tests/rdf-nnn/bad-bug67_5.nt"" , false , new int [ ] { 103 , } ) ; test176 . addTest ( test179 ) ; Test test180 = test175 . createPositiveTest ( ""http://jcarroll.hpl.hp.com/arp-tests/comments/test10"" , ""http://jcarroll.hpl.hp.com/arp-tests/comments/test10.rdf"" , true , ""http://jcarroll.hpl.hp.com/arp-tests/comments/test1X.nt"" , false ) ; test176 . addTest ( test180 ) ; Test test181 = test175 . createWarningTest ( ""http://jcarroll.hpl.hp.com/arp-tests/rdf-nnn/67_7"" , ""http://jcarroll.hpl.hp.com/arp-tests/rdf-nnn/bad-bug67_7.rdf"" , true , ""http://jcarroll.hpl.hp.com/arp-tests/rdf-nnn/bad-bug67_7.nt"" , false , new int [ ] { 113 , } ) ; test176 . addTest ( test181 ) ; Test test182 = test175 . createWarningTest ( ""http://jcarroll.hpl.hp.com/arp-tests/rdf-nnn/67_8"" , ""http://jcarroll.hpl.hp.com/arp-tests/rdf-nnn/bad-bug67_8.rdf"" , true , ""http://jcarroll.hpl.hp.com/arp-tests/rdf-nnn/bad-bug67_8.nt"" , false , new int [ ] { 103 , 113 , } ) ; test176 . addTest ( test182 ) ; Test test183 = test175 . createPositiveTest ( ""http://jcarroll.hpl.hp.com/arp-tests/comments/test01"" , ""http://jcarroll.hpl.hp.com/arp-tests/comments/test01.rdf"" , true , ""http://jcarroll.hpl.hp.com/arp-tests/comments/test0X.nt"" , false ) ; test176 . addTest ( test183 ) ; Test test184 = test175 . createWarningTest ( ""http://jcarroll.hpl.hp.com/arp-tests/parsetype/bug68"" , ""http://jcarroll.hpl.hp.com/arp-tests/parsetype/bug68_0.rdf"" , true , ""http://jcarroll.hpl.hp.com/arp-tests/parsetype/bug68_0.nt"" , false , new int [ ] { 106 , } ) ; test176 . addTest ( test184 ) ; Test test185 = test175 . createPositiveTest ( ""http://jcarroll.hpl.hp.com/arp-tests/i18n/bug73a"" , ""http://jcarroll.hpl.hp.com/arp-tests/i18n/eq-bug73_0.rdf"" , true , ""http://jcarroll.hpl.hp.com/arp-tests/i18n/eq-bug73_1.rdf"" , true ) ; test176 . addTest ( test185 ) ; Test test186 = test175 . createPositiveTest ( ""http://jcarroll.hpl.hp.com/arp-tests/comments/test12"" , ""http://jcarroll.hpl.hp.com/arp-tests/comments/test12.rdf"" , true , ""http://jcarroll.hpl.hp.com/arp-tests/comments/test1X.nt"" , false ) ; test176 . addTest ( test186 ) ; Test test187 = test175 . createPositiveTest ( ""http://jcarroll.hpl.hp.com/arp-tests/comments/test11"" , ""http://jcarroll.hpl.hp.com/arp-tests/comments/test11.rdf"" , true , ""http://jcarroll.hpl.hp.com/arp-tests/comments/test1X.nt"" , false ) ; test176 . addTest ( test187 ) ; Test test188 = test175 . createNegativeTest ( ""http://jcarroll.hpl.hp.com/arp-tests/qname-in-ID/bug74"" , ""http://jcarroll.hpl.hp.com/arp-tests/qname-in-ID/bug74_0.rdf"" , true , new int [ ] { 108 , } ) ; test176 . addTest ( test188 ) ; Test test189 = test175 . createNegativeTest ( ""http://jcarroll.hpl.hp.com/arp-tests/relative-namespaces/50_0"" , ""http://jcarroll.hpl.hp.com/arp-tests/relative-namespaces/bad-bug50_0.rdf"" , true , new int [ ] { 109 , 136 , } ) ; test176 . addTest ( test189 ) ; Test test190 = test175 . createPositiveTest ( ""http://jcarroll.hpl.hp.com/arp-tests/rfc2396-issue/bug51"" , ""http://jcarroll.hpl.hp.com/arp-tests/rfc2396-issue/bug51_0.rdf"" , true , ""http://jcarroll.hpl.hp.com/arp-tests/rfc2396-issue/bug51_0.nt"" , false ) ; test176 . addTest ( test190 ) ; Test test191 = test175 . createPositiveTest ( ""http://jcarroll.hpl.hp.com/arp-tests/comments/test03"" , ""http://jcarroll.hpl.hp.com/arp-tests/comments/test03.rdf"" , true , ""http://jcarroll.hpl.hp.com/arp-tests/comments/test0X.nt"" , false ) ; test176 . addTest ( test191 ) ; Test test192 = test175 . createPositiveTest ( ""http://jcarroll.hpl.hp.com/arp-tests/comments/test02"" , ""http://jcarroll.hpl.hp.com/arp-tests/comments/test02.rdf"" , true , ""http://jcarroll.hpl.hp.com/arp-tests/comments/test0X.nt"" , false ) ; test176 . addTest ( test192 ) ; Test test193 = test175 . createNegativeTest ( ""http://jcarroll.hpl.hp.com/arp-tests/xmlns/bad01"" , ""http://jcarroll.hpl.hp.com/arp-tests/xmlns/bad01.rdf"" , true , new int [ ] { 124 , 107 , } ) ; test176 . addTest ( test193 ) ; Test tProp = test175 . createNegativeTest ( ""http://jcarroll.hpl.hp.com/arp-tests/unqualified/property"" , ""http://jcarroll.hpl.hp.com/arp-tests/unqualified/property.rdf"" , true , new int [ ] { 104 , 136 } ) ; test176 . addTest ( tProp ) ; Test tAttr = test175 . createNegativeTest ( ""http://jcarroll.hpl.hp.com/arp-tests/unqualified/attribute"" , ""http://jcarroll.hpl.hp.com/arp-tests/unqualified/attribute.rdf"" , true , new int [ ] { 102 , 136 } ) ; test176 . addTest ( tAttr ) ; Test tType = test175 . createNegativeTest ( ""http://jcarroll.hpl.hp.com/arp-tests/unqualified/typedNode"" , ""http://jcarroll.hpl.hp.com/arp-tests/unqualified/typedNode.rdf"" , true , new int [ ] { 104 , 136 } ) ; test176 . addTest ( tType ) ; Test tRelative = test175 . createNegativeTest ( ""http://jcarroll.hpl.hp.com/arp-tests/unqualified/relative-namespace"" , ""http://jcarroll.hpl.hp.com/arp-tests/unqualified/relative-namespace.rdf"" , true , new int [ ] { 109 , 136 } ) ; test176 . addTest ( tRelative ) ; Test test194 = test175 . createPositiveTest ( ""http://jcarroll.hpl.hp.com/arp-tests/comments/test09"" , ""http://jcarroll.hpl.hp.com/arp-tests/comments/test09.rdf"" , true , ""http://jcarroll.hpl.hp.com/arp-tests/comments/test0X.nt"" , false ) ; test176 . addTest ( test194 ) ; Test test195 = test175 . createPositiveTest ( ""http://jcarroll.hpl.hp.com/arp-tests/comments/test08"" , ""http://jcarroll.hpl.hp.com/arp-tests/comments/test08.rdf"" , true , ""http://jcarroll.hpl.hp.com/arp-tests/comments/test0X.nt"" , false ) ; test176 . addTest ( test195 ) ; Test test196 = test175 . createPositiveTest ( ""http://jcarroll.hpl.hp.com/arp-tests/comments/test13"" , ""http://jcarroll.hpl.hp.com/arp-tests/comments/test13.rdf"" , true , ""http://jcarroll.hpl.hp.com/arp-tests/comments/test1X.nt"" , false ) ; test176 . addTest ( test196 ) ; Test test197 = test175 . createPositiveTest ( ""http://jcarroll.hpl.hp.com/arp-tests/i18n/bug73b"" , ""http://jcarroll.hpl.hp.com/arp-tests/i18n/eq-bug73_0.rdf"" , true , ""http://jcarroll.hpl.hp.com/arp-tests/i18n/eq-bug73_2.rdf"" , true ) ; test176 . addTest ( test197 ) ; Test test198 = test175 . createPositiveTest ( ""http://jcarroll.hpl.hp.com/arp-tests/comments/test05"" , ""http://jcarroll.hpl.hp.com/arp-tests/comments/test05.rdf"" , true , ""http://jcarroll.hpl.hp.com/arp-tests/comments/test0X.nt"" , false ) ; test176 . addTest ( test198 ) ; Test test199 = test175 . createPositiveTest ( ""http://jcarroll.hpl.hp.com/arp-tests/comments/test04"" , ""http://jcarroll.hpl.hp.com/arp-tests/comments/test04.rdf"" , true , ""http://jcarroll.hpl.hp.com/arp-tests/comments/test0X.nt"" , false ) ; test176 . addTest ( test199 ) ; Test test200 = test175 . createPositiveTest ( ""http://jcarroll.hpl.hp.com/arp-tests/rfc2396-issue/fileURI"" , ""http://jcarroll.hpl.hp.com/arp-tests/rfc2396-issue/fileURI.rdf"" , true , ""http://jcarroll.hpl.hp.com/arp-tests/rfc2396-issue/fileURI.nt"" , false ) ; test176 . addTest ( test200 ) ; Test test201 = test175 . createPositiveTest ( ""http://jcarroll.hpl.hp.com/arp-tests/comments/test07"" , ""http://jcarroll.hpl.hp.com/arp-tests/comments/test07.rdf"" , true , ""http://jcarroll.hpl.hp.com/arp-tests/comments/test0X.nt"" , false ) ; test176 . addTest ( test201 ) ; Test test202 = test175 . createPositiveTest ( ""http://jcarroll.hpl.hp.com/arp-tests/comments/test06"" , ""http://jcarroll.hpl.hp.com/arp-tests/comments/test06.rdf"" , true , ""http://jcarroll.hpl.hp.com/arp-tests/comments/test0X.nt"" , false ) ; test176 . addTest ( test202 ) ; Test test203 = test175 . createPositiveTest ( ""http://jcarroll.hpl.hp.com/arp-tests/xml-literals/reported1"" , ""http://jcarroll.hpl.hp.com/arp-tests/xml-literals/reported1.rdf"" , true , ""http://jcarroll.hpl.hp.com/arp-tests/xml-literals/reported1.nt"" , false ) ; test176 . addTest ( test203 ) ; Test test204 = test175 . createPositiveTest ( ""http://jcarroll.hpl.hp.com/arp-tests/xml-literals/reported2"" , ""http://jcarroll.hpl.hp.com/arp-tests/xml-literals/reported2.rdf"" , true , ""http://jcarroll.hpl.hp.com/arp-tests/xml-literals/reported2.nt"" , false ) ; test176 . addTest ( test204 ) ; Test test205 = test175 . createPositiveTest ( ""http://jcarroll.hpl.hp.com/arp-tests/xmlns/test01"" , ""http://jcarroll.hpl.hp.com/arp-tests/xmlns/test01.rdf"" , true , ""http://jcarroll.hpl.hp.com/arp-tests/xmlns/test0X.nt"" , false ) ; test176 . addTest ( test205 ) ; Test test206 = test175 . createPositiveTest ( ""http://jcarroll.hpl.hp.com/arp-tests/i18n/t9000"" , ""http://jcarroll.hpl.hp.com/arp-tests/i18n/t9000.rdf"" , true , ""http://jcarroll.hpl.hp.com/arp-tests/i18n/t9000.nt"" , false ) ; test176 . addTest ( test206 ) ; Test test207 = test175 . createPositiveTest ( ""http://jcarroll.hpl.hp.com/arp-tests/xmlns/test03"" , ""http://jcarroll.hpl.hp.com/arp-tests/xmlns/test03.rdf"" , true , ""http://jcarroll.hpl.hp.com/arp-tests/xmlns/test0X.nt"" , false ) ; test176 . addTest ( test207 ) ; Test test208 = test175 . createPositiveTest ( ""http://jcarroll.hpl.hp.com/arp-tests/xmlns/test02"" , ""http://jcarroll.hpl.hp.com/arp-tests/xmlns/test02.rdf"" , true , ""http://jcarroll.hpl.hp.com/arp-tests/xmlns/test0X.nt"" , false ) ; test176 . addTest ( test208 ) ; Test test209 = test175 . createWarningTest ( ""http://jcarroll.hpl.hp.com/arp-tests/rdf-nnn/67_0"" , ""http://jcarroll.hpl.hp.com/arp-tests/rdf-nnn/bad-bug67_0.rdf"" , true , ""http://jcarroll.hpl.hp.com/arp-tests/rdf-nnn/bad-bug67_0.nt"" , false , new int [ ] { 103 , } ) ; test176 . addTest ( test209 ) ; Test test210 = test175 . createWarningTest ( ""http://jcarroll.hpl.hp.com/arp-tests/rdf-nnn/67_9"" , ""http://jcarroll.hpl.hp.com/arp-tests/rdf-nnn/bad-bug67_9.rdf"" , true , ""http://jcarroll.hpl.hp.com/arp-tests/rdf-nnn/bad-bug67_9.nt"" , false , new int [ ] { 103 , 113 , } ) ; test176 . addTest ( test210 ) ; test175 . addTest ( test176 ) ; test0 . addTest ( test175 ) ; WGTestSuite test211 = new org . apache . jena . rdfxml . xmlinput . NTripleTestSuite ( new InputStreamFactoryTests ( IRIFactory . iriImplementation ( ) . create ( ""http://www.w3.org/2000/10/rdf-tests/rdfcore/"" ) , ""wg"" ) , ""NTriple WG Tests"" , false ) ; TestSuite test212 = new TestSuite ( ""APPROVED"" ) ; Test test213 = test211 . createPositiveTest ( ""http://www.w3.org/2000/10/rdf-tests/rdfcore/rdfms-rdf-names-use/Manifest.rdf#test-024"" , ""http://www.w3.org/2000/10/rdf-tests/rdfcore/rdfms-rdf-names-use/test-024.rdf"" , true , ""http://www.w3.org/2000/10/rdf-tests/rdfcore/rdfms-rdf-names-use/test-024.nt"" , false ) ; test212 . addTest ( test213 ) ; Test test214 = test211 . createPositiveTest ( ""http://www.w3.org/2000/10/rdf-tests/rdfcore/rdfms-rdf-names-use/Manifest.rdf#test-025"" , ""http://www.w3.org/2000/10/rdf-tests/rdfcore/rdfms-rdf-names-use/test-025.rdf"" , true , ""http://www.w3.org/2000/10/rdf-tests/rdfcore/rdfms-rdf-names-use/test-025.nt"" , false ) ; test212 . addTest ( test214 ) ; Test test215 = test211 . createPositiveTest ( ""http://www.w3.org/2000/10/rdf-tests/rdfcore/rdfms-empty-property-elements/Manifest.rdf#test003"" , ""http://www.w3.org/2000/10/rdf-tests/rdfcore/rdfms-empty-property-elements/test003.rdf"" , true , ""http://www.w3.org/2000/10/rdf-tests/rdfcore/rdfms-empty-property-elements/test003.nt"" , false ) ; test212 . addTest ( test215 ) ; Test test216 = test211 . createPositiveTest ( ""http://www.w3.org/2000/10/rdf-tests/rdfcore/rdfms-empty-property-elements/Manifest.rdf#test004"" , ""http://www.w3.org/2000/10/rdf-tests/rdfcore/rdfms-empty-property-elements/test004.rdf"" , true , ""http://www.w3.org/2000/10/rdf-tests/rdfcore/rdfms-empty-property-elements/test004.nt"" , false ) ; test212 . addTest ( test216 ) ; Test test217 = test211 . createNegativeTest ( ""http://www.w3.org/2000/10/rdf-tests/rdfcore/rdfms-rdf-names-use/Manifest.rdf#error-019"" , ""http://www.w3.org/2000/10/rdf-tests/rdfcore/rdfms-rdf-names-use/error-019.rdf"" , true , new int [ ] { 205 , } ) ; test212 . addTest ( test217 ) ; Test test218 = test211 . createPositiveTest ( ""http://www.w3.org/2000/10/rdf-tests/rdfcore/rdfms-rdf-names-use/Manifest.rdf#test-017"" , ""http://www.w3.org/2000/10/rdf-tests/rdfcore/rdfms-rdf-names-use/test-017.rdf"" , true , ""http://www.w3.org/2000/10/rdf-tests/rdfcore/rdfms-rdf-names-use/test-017.nt"" , false ) ; test212 . addTest ( test218 ) ; Test test219 = test211 . createPositiveTest ( ""http://www.w3.org/2000/10/rdf-tests/rdfcore/rdfms-rdf-names-use/Manifest.rdf#test-018"" , ""http://www.w3.org/2000/10/rdf-tests/rdfcore/rdfms-rdf-names-use/test-018.rdf"" , true , ""http://www.w3.org/2000/10/rdf-tests/rdfcore/rdfms-rdf-names-use/test-018.nt"" , false ) ; test212 . addTest ( test219 ) ; Test test220 = test211 . createPositiveTest ( ""http://www.w3.org/2000/10/rdf-tests/rdfcore/rdf-element-not-mandatory/Manifest.rdf#test001"" , ""http://www.w3.org/2000/10/rdf-tests/rdfcore/rdf-element-not-mandatory/test001.rdf"" , true , ""http://www.w3.org/2000/10/rdf-tests/rdfcore/rdf-element-not-mandatory/test001.nt"" , false ) ; test212 . addTest ( test220 ) ; Test test221 = test211 . createPositiveTest ( ""http://www.w3.org/2000/10/rdf-tests/rdfcore/datatypes/Manifest.rdf#test001"" , ""http://www.w3.org/2000/10/rdf-tests/rdfcore/datatypes/test001.rdf"" , true , ""http://www.w3.org/2000/10/rdf-tests/rdfcore/datatypes/test001.nt"" , false ) ; test212 . addTest ( test221 ) ; Test test222 = test211 . createPositiveTest ( ""http://www.w3.org/2000/10/rdf-tests/rdfcore/rdfms-xmllang/Manifest.rdf#test005"" , ""http://www.w3.org/2000/10/rdf-tests/rdfcore/rdfms-xmllang/test005.rdf"" , true , ""http://www.w3.org/2000/10/rdf-tests/rdfcore/rdfms-xmllang/test005.nt"" , false ) ; test212 . addTest ( test222 ) ; Test test223 = test211 . createPositiveTest ( ""http://www.w3.org/2000/10/rdf-tests/rdfcore/rdfms-xmllang/Manifest.rdf#test006"" , ""http://www.w3.org/2000/10/rdf-tests/rdfcore/rdfms-xmllang/test006.rdf"" , true , ""http://www.w3.org/2000/10/rdf-tests/rdfcore/rdfms-xmllang/test006.nt"" , false ) ; test212 . addTest ( test223 ) ; Test test224 = test211 . createNegativeTest ( ""http://www.w3.org/2000/10/rdf-tests/rdfcore/rdfms-rdf-names-use/Manifest.rdf#error-001"" , ""http://www.w3.org/2000/10/rdf-tests/rdfcore/rdfms-rdf-names-use/error-001.rdf"" , true , new int [ ] { 205 , } ) ; test212 . addTest ( test224 ) ; Test test225 = test211 . createPositiveTest ( ""http://www.w3.org/2000/10/rdf-tests/rdfcore/xmlbase/Manifest.rdf#test011"" , ""http://www.w3.org/2000/10/rdf-tests/rdfcore/xmlbase/test011.rdf"" , true , ""http://www.w3.org/2000/10/rdf-tests/rdfcore/xmlbase/test011.nt"" , false ) ; test212 . addTest ( test225 ) ; Test test226 = test211 . createPositiveTest ( ""http://www.w3.org/2000/10/rdf-tests/rdfcore/xmlbase/Manifest.rdf#test010"" , ""http://www.w3.org/2000/10/rdf-tests/rdfcore/xmlbase/test010.rdf"" , true , ""http://www.w3.org/2000/10/rdf-tests/rdfcore/xmlbase/test010.nt"" , false ) ; test212 . addTest ( test226 ) ; Test test227 = test211 . createPositiveTest ( ""http://www.w3.org/2000/10/rdf-tests/rdfcore/rdf-ns-prefix-confusion/Manifest.rdf#test0013"" , ""http://www.w3.org/2000/10/rdf-tests/rdfcore/rdf-ns-prefix-confusion/test0013.rdf"" , true , ""http://www.w3.org/2000/10/rdf-tests/rdfcore/rdf-ns-prefix-confusion/test0013.nt"" , false ) ; test212 . addTest ( test227 ) ; Test test228 = test211 . createPositiveTest ( ""http://www.w3.org/2000/10/rdf-tests/rdfcore/rdf-ns-prefix-confusion/Manifest.rdf#test0012"" , ""http://www.w3.org/2000/10/rdf-tests/rdfcore/rdf-ns-prefix-confusion/test0012.rdf"" , true , ""http://www.w3.org/2000/10/rdf-tests/rdfcore/rdf-ns-prefix-confusion/test0012.nt"" , false ) ; test212 . addTest ( test228 ) ; Test test229 = test211 . createPositiveTest ( ""http://www.w3.org/2000/10/rdf-tests/rdfcore/unrecognised-xml-attributes/Manifest.rdf#test002"" , ""http://www.w3.org/2000/10/rdf-tests/rdfcore/unrecognised-xml-attributes/test002.rdf"" , true , ""http://www.w3.org/2000/10/rdf-tests/rdfcore/unrecognised-xml-attributes/test002.nt"" , false ) ; test212 . addTest ( test229 ) ; Test test230 = test211 . createPositiveTest ( ""http://www.w3.org/2000/10/rdf-tests/rdfcore/unrecognised-xml-attributes/Manifest.rdf#test001"" , ""http://www.w3.org/2000/10/rdf-tests/rdfcore/unrecognised-xml-attributes/test001.rdf"" , true , ""http://www.w3.org/2000/10/rdf-tests/rdfcore/unrecognised-xml-attributes/test001.nt"" , false ) ; test212 . addTest ( test230 ) ; Test test231 = test211 . createPositiveTest ( ""http://www.w3.org/2000/10/rdf-tests/rdfcore/xmlbase/Manifest.rdf#test002"" , ""http://www.w3.org/2000/10/rdf-tests/rdfcore/xmlbase/test002.rdf"" , true , ""http://www.w3.org/2000/10/rdf-tests/rdfcore/xmlbase/test002.nt"" , false ) ; test212 . addTest ( test231 ) ; Test test232 = test211 . createPositiveTest ( ""http://www.w3.org/2000/10/rdf-tests/rdfcore/xmlbase/Manifest.rdf#test001"" , ""http://www.w3.org/2000/10/rdf-tests/rdfcore/xmlbase/test001.rdf"" , true , ""http://www.w3.org/2000/10/rdf-tests/rdfcore/xmlbase/test001.nt"" , false ) ; test212 . addTest ( test232 ) ; Test test233 = test211 . createPositiveTest ( ""http://www.w3.org/2000/10/rdf-tests/rdfcore/rdfs-domain-and-range/Manifest.rdf#test002"" , ""http://www.w3.org/2000/10/rdf-tests/rdfcore/rdfs-domain-and-range/test002.rdf"" , true , ""http://www.w3.org/2000/10/rdf-tests/rdfcore/rdfs-domain-and-range/test002.nt"" , false ) ; test212 . addTest ( test233 ) ; Test test234 = test211 . createPositiveTest ( ""http://www.w3.org/2000/10/rdf-tests/rdfcore/rdfs-domain-and-range/Manifest.rdf#test001"" , ""http://www.w3.org/2000/10/rdf-tests/rdfcore/rdfs-domain-and-range/test001.rdf"" , true , ""http://www.w3.org/2000/10/rdf-tests/rdfcore/rdfs-domain-and-range/test001.nt"" , false ) ; test212 . addTest ( test234 ) ; Test test235 = test211 . createPositiveTest ( ""http://www.w3.org/2000/10/rdf-tests/rdfcore/rdfms-xml-literal-namespaces/Manifest.rdf#test001"" , ""http://www.w3.org/2000/10/rdf-tests/rdfcore/rdfms-xml-literal-namespaces/test001.rdf"" , true , ""http://www.w3.org/2000/10/rdf-tests/rdfcore/rdfms-xml-literal-namespaces/test001.nt"" , false ) ; test212 . addTest ( test235 ) ; Test test236 = test211 . createPositiveTest ( ""http://www.w3.org/2000/10/rdf-tests/rdfcore/xmlbase/Manifest.rdf#test009"" , ""http://www.w3.org/2000/10/rdf-tests/rdfcore/xmlbase/test009.rdf"" , true , ""http://www.w3.org/2000/10/rdf-tests/rdfcore/xmlbase/test009.nt"" , false ) ; test212 . addTest ( test236 ) ; Test test237 = test211 . createNegativeTest ( ""http://www.w3.org/2000/10/rdf-tests/rdfcore/rdfms-rdf-names-use/Manifest.rdf#error-004"" , ""http://www.w3.org/2000/10/rdf-tests/rdfcore/rdfms-rdf-names-use/error-004.rdf"" , true , new int [ ] { 205 , } ) ; test212 . addTest ( test237 ) ; Test test238 = test211 . createNegativeTest ( ""http://www.w3.org/2000/10/rdf-tests/rdfcore/rdfms-rdf-names-use/Manifest.rdf#error-005"" , ""http://www.w3.org/2000/10/rdf-tests/rdfcore/rdfms-rdf-names-use/error-005.rdf"" , true , new int [ ] { 205 , } ) ; test212 . addTest ( test238 ) ; Test test239 = test211 . createPositiveTest ( ""http://www.w3.org/2000/10/rdf-tests/rdfcore/rdfms-rdf-names-use/Manifest.rdf#test-028"" , ""http://www.w3.org/2000/10/rdf-tests/rdfcore/rdfms-rdf-names-use/test-028.rdf"" , true , ""http://www.w3.org/2000/10/rdf-tests/rdfcore/rdfms-rdf-names-use/test-028.nt"" , false ) ; test212 . addTest ( test239 ) ; Test test240 = test211 . createPositiveTest ( ""http://www.w3.org/2000/10/rdf-tests/rdfcore/rdfms-rdf-names-use/Manifest.rdf#test-029"" , ""http://www.w3.org/2000/10/rdf-tests/rdfcore/rdfms-rdf-names-use/test-029.rdf"" , true , ""http://www.w3.org/2000/10/rdf-tests/rdfcore/rdfms-rdf-names-use/test-029.nt"" , false ) ; test212 . addTest ( test240 ) ; Test test241 = test211 . createPositiveTest ( ""http://www.w3.org/2000/10/rdf-tests/rdfcore/rdfms-empty-property-elements/Manifest.rdf#test012"" , ""http://www.w3.org/2000/10/rdf-tests/rdfcore/rdfms-empty-property-elements/test012.rdf"" , true , ""http://www.w3.org/2000/10/rdf-tests/rdfcore/rdfms-empty-property-elements/test012.nt"" , false ) ; test212 . addTest ( test241 ) ; Test test242 = test211 . createPositiveTest ( ""http://www.w3.org/2000/10/rdf-tests/rdfcore/rdfms-empty-property-elements/Manifest.rdf#test013"" , ""http://www.w3.org/2000/10/rdf-tests/rdfcore/rdfms-empty-property-elements/test013.rdf"" , true , ""http://www.w3.org/2000/10/rdf-tests/rdfcore/rdfms-empty-property-elements/test013.nt"" , false ) ; test212 . addTest ( test242 ) ; Test test243 = test211 . createPositiveTest ( ""http://www.w3.org/2000/10/rdf-tests/rdfcore/rdf-containers-syntax-vs-schema/Manifest.rdf#test002"" , ""http://www.w3.org/2000/10/rdf-tests/rdfcore/rdf-containers-syntax-vs-schema/test002.rdf"" , true , ""http://www.w3.org/2000/10/rdf-tests/rdfcore/rdf-containers-syntax-vs-schema/test002.nt"" , false ) ; test212 . addTest ( test243 ) ; Test test244 = test211 . createPositiveTest ( ""http://www.w3.org/2000/10/rdf-tests/rdfcore/rdf-containers-syntax-vs-schema/Manifest.rdf#test003"" , ""http://www.w3.org/2000/10/rdf-tests/rdfcore/rdf-containers-syntax-vs-schema/test003.rdf"" , true , ""http://www.w3.org/2000/10/rdf-tests/rdfcore/rdf-containers-syntax-vs-schema/test003.nt"" , false ) ; test212 . addTest ( test244 ) ; Test test245 = test211 . createPositiveTest ( ""http://www.w3.org/2000/10/rdf-tests/rdfcore/rdf-ns-prefix-confusion/Manifest.rdf#test0006"" , ""http://www.w3.org/2000/10/rdf-tests/rdfcore/rdf-ns-prefix-confusion/test0006.rdf"" , true , ""http://www.w3.org/2000/10/rdf-tests/rdfcore/rdf-ns-prefix-confusion/test0006.nt"" , false ) ; test212 . addTest ( test245 ) ; Test test246 = test211 . createPositiveTest ( ""http://www.w3.org/2000/10/rdf-tests/rdfcore/rdf-ns-prefix-confusion/Manifest.rdf#test0005"" , ""http://www.w3.org/2000/10/rdf-tests/rdfcore/rdf-ns-prefix-confusion/test0005.rdf"" , true , ""http://www.w3.org/2000/10/rdf-tests/rdfcore/rdf-ns-prefix-confusion/test0005.nt"" , false ) ; test212 . addTest ( test246 ) ; Test test247 = test211 . createPositiveTest ( ""http://www.w3.org/2000/10/rdf-tests/rdfcore/rdfms-reification-required/Manifest.rdf#test001"" , ""http://www.w3.org/2000/10/rdf-tests/rdfcore/rdfms-reification-required/test001.rdf"" , true , ""http://www.w3.org/2000/10/rdf-tests/rdfcore/rdfms-reification-required/test001.nt"" , false ) ; test212 . addTest ( test247 ) ; Test test248 = test211 . createPositiveTest ( ""http://www.w3.org/2000/10/rdf-tests/rdfcore/rdfms-rdf-names-use/Manifest.rdf#test-021"" , ""http://www.w3.org/2000/10/rdf-tests/rdfcore/rdfms-rdf-names-use/test-021.rdf"" , true , ""http://www.w3.org/2000/10/rdf-tests/rdfcore/rdfms-rdf-names-use/test-021.nt"" , false ) ; test212 . addTest ( test248 ) ; Test test249 = test211 . createPositiveTest ( ""http://www.w3.org/2000/10/rdf-tests/rdfcore/rdfms-rdf-names-use/Manifest.rdf#test-020"" , ""http://www.w3.org/2000/10/rdf-tests/rdfcore/rdfms-rdf-names-use/test-020.rdf"" , true , ""http://www.w3.org/2000/10/rdf-tests/rdfcore/rdfms-rdf-names-use/test-020.nt"" , false ) ; test212 . addTest ( test249 ) ; Test test250 = test211 . createPositiveTest ( ""http://www.w3.org/2000/10/rdf-tests/rdfcore/rdfms-empty-property-elements/Manifest.rdf#test008"" , ""http://www.w3.org/2000/10/rdf-tests/rdfcore/rdfms-empty-property-elements/test008.rdf"" , true , ""http://www.w3.org/2000/10/rdf-tests/rdfcore/rdfms-empty-property-elements/test008.nt"" , false ) ; test212 . addTest ( test250 ) ; Test test251 = test211 . createPositiveTest ( ""http://www.w3.org/2000/10/rdf-tests/rdfcore/rdfms-empty-property-elements/Manifest.rdf#test007"" , ""http://www.w3.org/2000/10/rdf-tests/rdfcore/rdfms-empty-property-elements/test007.rdf"" , true , ""http://www.w3.org/2000/10/rdf-tests/rdfcore/rdfms-empty-property-elements/test007.nt"" , false ) ; test212 . addTest ( test251 ) ; Test test252 = test211 . createPositiveTest ( ""http://www.w3.org/2000/10/rdf-tests/rdfcore/rdf-containers-syntax-vs-schema/Manifest.rdf#test006"" , ""http://www.w3.org/2000/10/rdf-tests/rdfcore/rdf-containers-syntax-vs-schema/test006.rdf"" , true , ""http://www.w3.org/2000/10/rdf-tests/rdfcore/rdf-containers-syntax-vs-schema/test006.nt"" , false ) ; test212 . addTest ( test252 ) ; Test test253 = test211 . createNegativeTest ( ""http://www.w3.org/2000/10/rdf-tests/rdfcore/rdfms-rdf-names-use/Manifest.rdf#error-016"" , ""http://www.w3.org/2000/10/rdf-tests/rdfcore/rdfms-rdf-names-use/error-016.rdf"" , true , new int [ ] { 205 , } ) ; test212 . addTest ( test253 ) ; Test test254 = test211 . createPositiveTest ( ""http://www.w3.org/2000/10/rdf-tests/rdfcore/rdf-containers-syntax-vs-schema/Manifest.rdf#test007"" , ""http://www.w3.org/2000/10/rdf-tests/rdfcore/rdf-containers-syntax-vs-schema/test007.rdf"" , true , ""http://www.w3.org/2000/10/rdf-tests/rdfcore/rdf-containers-syntax-vs-schema/test007.nt"" , false ) ; test212 . addTest ( test254 ) ; Test test255 = test211 . createNegativeTest ( ""http://www.w3.org/2000/10/rdf-tests/rdfcore/rdfms-rdf-names-use/Manifest.rdf#error-015"" , ""http://www.w3.org/2000/10/rdf-tests/rdfcore/rdfms-rdf-names-use/error-015.rdf"" , true , new int [ ] { 205 , } ) ; test212 . addTest ( test255 ) ; Test test256 = test211 . createNegativeTest ( ""http://www.w3.org/2000/10/rdf-tests/rdfcore/rdfms-syntax-incomplete/Manifest.rdf#error005"" , ""http://www.w3.org/2000/10/rdf-tests/rdfcore/rdfms-syntax-incomplete/error005.rdf"" , true , null ) ; test212 . addTest ( test256 ) ; Test test257 = test211 . createNegativeTest ( ""http://www.w3.org/2000/10/rdf-tests/rdfcore/rdfms-syntax-incomplete/Manifest.rdf#error004"" , ""http://www.w3.org/2000/10/rdf-tests/rdfcore/rdfms-syntax-incomplete/error004.rdf"" , true , null ) ; test212 . addTest ( test257 ) ; Test test258 = test211 . createPositiveTest ( ""http://www.w3.org/2000/10/rdf-tests/rdfcore/rdf-ns-prefix-confusion/Manifest.rdf#test0003"" , ""http://www.w3.org/2000/10/rdf-tests/rdfcore/rdf-ns-prefix-confusion/test0003.rdf"" , true , ""http://www.w3.org/2000/10/rdf-tests/rdfcore/rdf-ns-prefix-confusion/test0003.nt"" , false ) ; test212 . addTest ( test258 ) ; Test test259 = test211 . createPositiveTest ( ""http://www.w3.org/2000/10/rdf-tests/rdfcore/rdf-ns-prefix-confusion/Manifest.rdf#test0004"" , ""http://www.w3.org/2000/10/rdf-tests/rdfcore/rdf-ns-prefix-confusion/test0004.rdf"" , true , ""http://www.w3.org/2000/10/rdf-tests/rdfcore/rdf-ns-prefix-confusion/test0004.nt"" , false ) ; test212 . addTest ( test259 ) ; Test test260 = test211 . createPositiveTest ( ""http://www.w3.org/2000/10/rdf-tests/rdfcore/rdfms-identity-anon-resources/Manifest.rdf#test005"" , ""http://www.w3.org/2000/10/rdf-tests/rdfcore/rdfms-identity-anon-resources/test005.rdf"" , true , ""http://www.w3.org/2000/10/rdf-tests/rdfcore/rdfms-identity-anon-resources/test005.nt"" , false ) ; test212 . addTest ( test260 ) ; Test test261 = test211 . createPositiveTest ( ""http://www.w3.org/2000/10/rdf-tests/rdfcore/xmlbase/Manifest.rdf#test014"" , ""http://www.w3.org/2000/10/rdf-tests/rdfcore/xmlbase/test014.rdf"" , true , ""http://www.w3.org/2000/10/rdf-tests/rdfcore/xmlbase/test014.nt"" , false ) ; test212 . addTest ( test261 ) ; Test test262 = test211 . createPositiveTest ( ""http://www.w3.org/2000/10/rdf-tests/rdfcore/rdf-ns-prefix-confusion/Manifest.rdf#test0009"" , ""http://www.w3.org/2000/10/rdf-tests/rdfcore/rdf-ns-prefix-confusion/test0009.rdf"" , true , ""http://www.w3.org/2000/10/rdf-tests/rdfcore/rdf-ns-prefix-confusion/test0009.nt"" , false ) ; test212 . addTest ( test262 ) ; Test test263 = test211 . createNegativeTest ( ""http://www.w3.org/2000/10/rdf-tests/rdfcore/rdfms-rdf-id/Manifest.rdf#error004"" , ""http://www.w3.org/2000/10/rdf-tests/rdfcore/rdfms-rdf-id/error004.rdf"" , true , null ) ; test212 . addTest ( test263 ) ; Test test264 = test211 . createNegativeTest ( ""http://www.w3.org/2000/10/rdf-tests/rdfcore/rdfms-rdf-id/Manifest.rdf#error005"" , ""http://www.w3.org/2000/10/rdf-tests/rdfcore/rdfms-rdf-id/error005.rdf"" , true , null ) ; test212 . addTest ( test264 ) ; Test test265 = test211 . createNegativeTest ( ""http://www.w3.org/2000/10/rdf-tests/rdfcore/rdfms-rdf-id/Manifest.rdf#error007"" , ""http://www.w3.org/2000/10/rdf-tests/rdfcore/rdfms-rdf-id/error007.rdf"" , true , null ) ; test212 . addTest ( test265 ) ; Test test266 = test211 . createNegativeTest ( ""http://www.w3.org/2000/10/rdf-tests/rdfcore/rdfms-rdf-id/Manifest.rdf#error006"" , ""http://www.w3.org/2000/10/rdf-tests/rdfcore/rdfms-rdf-id/error006.rdf"" , true , null ) ; test212 . addTest ( test266 ) ; Test test267 = test211 . createPositiveTest ( ""http://www.w3.org/2000/10/rdf-tests/rdfcore/amp-in-url/Manifest.rdf#test001"" , ""http://www.w3.org/2000/10/rdf-tests/rdfcore/amp-in-url/test001.rdf"" , true , ""http://www.w3.org/2000/10/rdf-tests/rdfcore/amp-in-url/test001.nt"" , false ) ; test212 . addTest ( test267 ) ; Test test268 = test211 . createPositiveTest ( ""http://www.w3.org/2000/10/rdf-tests/rdfcore/rdfms-syntax-incomplete/Manifest.rdf#test001"" , ""http://www.w3.org/2000/10/rdf-tests/rdfcore/rdfms-syntax-incomplete/test001.rdf"" , true , ""http://www.w3.org/2000/10/rdf-tests/rdfcore/rdfms-syntax-incomplete/test001.nt"" , false ) ; test212 . addTest ( test268 ) ; Test test269 = test211 . createNegativeTest ( ""http://www.w3.org/2000/10/rdf-tests/rdfcore/rdfms-abouteach/Manifest.rdf#error002"" , ""http://www.w3.org/2000/10/rdf-tests/rdfcore/rdfms-abouteach/error002.rdf"" , true , new int [ ] { 206 , } ) ; test212 . addTest ( test269 ) ; Test test270 = test211 . createNegativeTest ( ""http://www.w3.org/2000/10/rdf-tests/rdfcore/rdfms-rdf-id/Manifest.rdf#error002"" , ""http://www.w3.org/2000/10/rdf-tests/rdfcore/rdfms-rdf-id/error002.rdf"" , true , null ) ; test212 . addTest ( test270 ) ; Test test271 = test211 . createPositiveTest ( ""http://www.w3.org/2000/10/rdf-tests/rdfcore/rdf-containers-syntax-vs-schema/Manifest.rdf#test004"" , ""http://www.w3.org/2000/10/rdf-tests/rdfcore/rdf-containers-syntax-vs-schema/test004.rdf"" , true , ""http://www.w3.org/2000/10/rdf-tests/rdfcore/rdf-containers-syntax-vs-schema/test004.nt"" , false ) ; test212 . addTest ( test271 ) ; Test test272 = test211 . createNegativeTest ( ""http://www.w3.org/2000/10/rdf-tests/rdfcore/rdfms-rdf-id/Manifest.rdf#error003"" , ""http://www.w3.org/2000/10/rdf-tests/rdfcore/rdfms-rdf-id/error003.rdf"" , true , null ) ; test212 . addTest ( test272 ) ; Test test273 = test211 . createPositiveTest ( ""http://www.w3.org/2000/10/rdf-tests/rdfcore/datatypes/Manifest.rdf#test002"" , ""http://www.w3.org/2000/10/rdf-tests/rdfcore/datatypes/test002.rdf"" , true , ""http://www.w3.org/2000/10/rdf-tests/rdfcore/datatypes/test002.nt"" , false ) ; test212 . addTest ( test273 ) ; Test test274 = test211 . createPositiveTest ( ""http://www.w3.org/2000/10/rdf-tests/rdfcore/xmlbase/Manifest.rdf#test004"" , ""http://www.w3.org/2000/10/rdf-tests/rdfcore/xmlbase/test004.rdf"" , true , ""http://www.w3.org/2000/10/rdf-tests/rdfcore/xmlbase/test004.nt"" , false ) ; test212 . addTest ( test274 ) ; Test test275 = test211 . createPositiveTest ( ""http://www.w3.org/2000/10/rdf-tests/rdfcore/xmlbase/Manifest.rdf#test003"" , ""http://www.w3.org/2000/10/rdf-tests/rdfcore/xmlbase/test003.rdf"" , true , ""http://www.w3.org/2000/10/rdf-tests/rdfcore/xmlbase/test003.nt"" , false ) ; test212 . addTest ( test275 ) ; Test test276 = test211 . createNegativeTest ( ""http://www.w3.org/2000/10/rdf-tests/rdfcore/rdfms-difference-between-ID-and-about/Manifest.rdf#error1"" , ""http://www.w3.org/2000/10/rdf-tests/rdfcore/rdfms-difference-between-ID-and-about/error1.rdf"" , true , new int [ ] { 105 , } ) ; test212 . addTest ( test276 ) ; Test test277 = test211 . createPositiveTest ( ""http://www.w3.org/2000/10/rdf-tests/rdfcore/rdfms-rdf-names-use/Manifest.rdf#test-030"" , ""http://www.w3.org/2000/10/rdf-tests/rdfcore/rdfms-rdf-names-use/test-030.rdf"" , true , ""http://www.w3.org/2000/10/rdf-tests/rdfcore/rdfms-rdf-names-use/test-030.nt"" , false ) ; test212 . addTest ( test277 ) ; Test test278 = test211 . createPositiveTest ( ""http://www.w3.org/2000/10/rdf-tests/rdfcore/rdfms-identity-anon-resources/Manifest.rdf#test001"" , ""http://www.w3.org/2000/10/rdf-tests/rdfcore/rdfms-identity-anon-resources/test001.rdf"" , true , ""http://www.w3.org/2000/10/rdf-tests/rdfcore/rdfms-identity-anon-resources/test001.nt"" , false ) ; test212 . addTest ( test278 ) ; Test test279 = test211 . createPositiveTest ( ""http://www.w3.org/2000/10/rdf-tests/rdfcore/rdfms-identity-anon-resources/Manifest.rdf#test002"" , ""http://www.w3.org/2000/10/rdf-tests/rdfcore/rdfms-identity-anon-resources/test002.rdf"" , true , ""http://www.w3.org/2000/10/rdf-tests/rdfcore/rdfms-identity-anon-resources/test002.nt"" , false ) ; test212 . addTest ( test279 ) ; Test test280 = test211 . createPositiveTest ( ""http://www.w3.org/2000/10/rdf-tests/rdfcore/rdfms-syntax-incomplete/Manifest.rdf#test004"" , ""http://www.w3.org/2000/10/rdf-tests/rdfcore/rdfms-syntax-incomplete/test004.rdf"" , true , ""http://www.w3.org/2000/10/rdf-tests/rdfcore/rdfms-syntax-incomplete/test004.nt"" , false ) ; test212 . addTest ( test280 ) ; Test test281 = test211 . createWarningTest ( ""http://www.w3.org/2000/10/rdf-tests/rdfcore/rdfms-rdf-names-use/Manifest.rdf#warn-001"" , ""http://www.w3.org/2000/10/rdf-tests/rdfcore/rdfms-rdf-names-use/warn-001.rdf"" , true , ""http://www.w3.org/2000/10/rdf-tests/rdfcore/rdfms-rdf-names-use/warn-001.nt"" , false , null ) ; test212 . addTest ( test281 ) ; Test test282 = test211 . createPositiveTest ( ""http://www.w3.org/2000/10/rdf-tests/rdfcore/xml-canon/Manifest.rdf#test001"" , ""http://www.w3.org/2000/10/rdf-tests/rdfcore/xml-canon/test001.rdf"" , true , ""http://www.w3.org/2000/10/rdf-tests/rdfcore/xml-canon/test001.nt"" , false ) ; test212 . addTest ( test282 ) ; Test test283 = test211 . createNegativeTest ( ""http://www.w3.org/2000/10/rdf-tests/rdfcore/rdfms-abouteach/Manifest.rdf#error001"" , ""http://www.w3.org/2000/10/rdf-tests/rdfcore/rdfms-abouteach/error001.rdf"" , true , new int [ ] { 206 , } ) ; test212 . addTest ( test283 ) ; Test test284 = test211 . createPositiveTest ( ""http://www.w3.org/2000/10/rdf-tests/rdfcore/rdfms-not-id-and-resource-attr/Manifest.rdf#test001"" , ""http://www.w3.org/2000/10/rdf-tests/rdfcore/rdfms-not-id-and-resource-attr/test001.rdf"" , true , ""http://www.w3.org/2000/10/rdf-tests/rdfcore/rdfms-not-id-and-resource-attr/test001.nt"" , false ) ; test212 . addTest ( test284 ) ; Test test285 = test211 . createPositiveTest ( ""http://www.w3.org/2000/10/rdf-tests/rdfcore/rdfms-para196/Manifest.rdf#test001"" , ""http://www.w3.org/2000/10/rdf-tests/rdfcore/rdfms-para196/test001.rdf"" , true , ""http://www.w3.org/2000/10/rdf-tests/rdfcore/rdfms-para196/test001.nt"" , false ) ; test212 . addTest ( test285 ) ; Test test286 = test211 . createPositiveTest ( ""http://www.w3.org/2000/10/rdf-tests/rdfcore/rdfms-rdf-names-use/Manifest.rdf#test-006"" , ""http://www.w3.org/2000/10/rdf-tests/rdfcore/rdfms-rdf-names-use/test-006.rdf"" , true , ""http://www.w3.org/2000/10/rdf-tests/rdfcore/rdfms-rdf-names-use/test-006.nt"" , false ) ; test212 . addTest ( test286 ) ; Test test287 = test211 . createPositiveTest ( ""http://www.w3.org/2000/10/rdf-tests/rdfcore/rdfms-rdf-names-use/Manifest.rdf#test-007"" , ""http://www.w3.org/2000/10/rdf-tests/rdfcore/rdfms-rdf-names-use/test-007.rdf"" , true , ""http://www.w3.org/2000/10/rdf-tests/rdfcore/rdfms-rdf-names-use/test-007.nt"" , false ) ; test212 . addTest ( test287 ) ; Test test288 = test211 . createNegativeTest ( ""http://www.w3.org/2000/10/rdf-tests/rdfcore/rdf-containers-syntax-vs-schema/Manifest.rdf#error002"" , ""http://www.w3.org/2000/10/rdf-tests/rdfcore/rdf-containers-syntax-vs-schema/error002.rdf"" , true , new int [ ] { 204 , } ) ; test212 . addTest ( test288 ) ; Test test289 = test211 . createPositiveTest ( ""http://www.w3.org/2000/10/rdf-tests/rdfcore/rdfms-not-id-and-resource-attr/Manifest.rdf#test005"" , ""http://www.w3.org/2000/10/rdf-tests/rdfcore/rdfms-not-id-and-resource-attr/test005.rdf"" , true , ""http://www.w3.org/2000/10/rdf-tests/rdfcore/rdfms-not-id-and-resource-attr/test005.nt"" , false ) ; test212 . addTest ( test289 ) ; Test test290 = test211 . createPositiveTest ( ""http://www.w3.org/2000/10/rdf-tests/rdfcore/rdfms-not-id-and-resource-attr/Manifest.rdf#test004"" , ""http://www.w3.org/2000/10/rdf-tests/rdfcore/rdfms-not-id-and-resource-attr/test004.rdf"" , true , ""http://www.w3.org/2000/10/rdf-tests/rdfcore/rdfms-not-id-and-resource-attr/test004.nt"" , false ) ; test212 . addTest ( test290 ) ; Test test291 = test211 . createPositiveTest ( ""http://www.w3.org/2000/10/rdf-tests/rdfcore/rdf-charmod-uris/Manifest.rdf#test001"" , ""http://www.w3.org/2000/10/rdf-tests/rdfcore/rdf-charmod-uris/test001.rdf"" , true , ""http://www.w3.org/2000/10/rdf-tests/rdfcore/rdf-charmod-uris/test001.nt"" , false ) ; test212 . addTest ( test291 ) ; Test test292 = test211 . createPositiveTest ( ""http://www.w3.org/2000/10/rdf-tests/rdfcore/rdfms-rdf-names-use/Manifest.rdf#test-002"" , ""http://www.w3.org/2000/10/rdf-tests/rdfcore/rdfms-rdf-names-use/test-002.rdf"" , true , ""http://www.w3.org/2000/10/rdf-tests/rdfcore/rdfms-rdf-names-use/test-002.nt"" , false ) ; test212 . addTest ( test292 ) ; Test test293 = test211 . createPositiveTest ( ""http://www.w3.org/2000/10/rdf-tests/rdfcore/rdfms-duplicate-member-props/Manifest.rdf#test001"" , ""http://www.w3.org/2000/10/rdf-tests/rdfcore/rdfms-duplicate-member-props/test001.rdf"" , true , ""http://www.w3.org/2000/10/rdf-tests/rdfcore/rdfms-duplicate-member-props/test001.nt"" , false ) ; test212 . addTest ( test293 ) ; Test test294 = test211 . createPositiveTest ( ""http://www.w3.org/2000/10/rdf-tests/rdfcore/rdfms-rdf-names-use/Manifest.rdf#test-003"" , ""http://www.w3.org/2000/10/rdf-tests/rdfcore/rdfms-rdf-names-use/test-003.rdf"" , true , ""http://www.w3.org/2000/10/rdf-tests/rdfcore/rdfms-rdf-names-use/test-003.nt"" , false ) ; test212 . addTest ( test294 ) ; Test test295 = test211 . createPositiveTest ( ""http://www.w3.org/2000/10/rdf-tests/rdfcore/rdfms-seq-representation/Manifest.rdf#test001"" , ""http://www.w3.org/2000/10/rdf-tests/rdfcore/rdfms-seq-representation/test001.rdf"" , true , ""http://www.w3.org/2000/10/rdf-tests/rdfcore/rdfms-seq-representation/test001.nt"" , false ) ; test212 . addTest ( test295 ) ; Test test296 = test211 . createPositiveTest ( ""http://www.w3.org/2000/10/rdf-tests/rdfcore/rdf-containers-syntax-vs-schema/Manifest.rdf#test001"" , ""http://www.w3.org/2000/10/rdf-tests/rdfcore/rdf-containers-syntax-vs-schema/test001.rdf"" , true , ""http://www.w3.org/2000/10/rdf-tests/rdfcore/rdf-containers-syntax-vs-schema/test001.nt"" , false ) ; test212 . addTest ( test296 ) ; Test test297 = test211 . createNegativeTest ( ""http://www.w3.org/2000/10/rdf-tests/rdfcore/rdfms-rdf-names-use/Manifest.rdf#error-020"" , ""http://www.w3.org/2000/10/rdf-tests/rdfcore/rdfms-rdf-names-use/error-020.rdf"" , true , new int [ ] { 205 , } ) ; test212 . addTest ( test297 ) ; Test test298 = test211 . createPositiveTest ( ""http://www.w3.org/2000/10/rdf-tests/rdfcore/rdfms-rdf-names-use/Manifest.rdf#test-015"" , ""http://www.w3.org/2000/10/rdf-tests/rdfcore/rdfms-rdf-names-use/test-015.rdf"" , true , ""http://www.w3.org/2000/10/rdf-tests/rdfcore/rdfms-rdf-names-use/test-015.nt"" , false ) ; test212 . addTest ( test298 ) ; Test test299 = test211 . createPositiveTest ( ""http://www.w3.org/2000/10/rdf-tests/rdfcore/rdfms-rdf-names-use/Manifest.rdf#test-016"" , ""http://www.w3.org/2000/10/rdf-tests/rdfcore/rdfms-rdf-names-use/test-016.rdf"" , true , ""http://www.w3.org/2000/10/rdf-tests/rdfcore/rdfms-rdf-names-use/test-016.nt"" , false ) ; test212 . addTest ( test299 ) ; Test test300 = test211 . createPositiveTest ( ""http://www.w3.org/2000/10/rdf-tests/rdfcore/rdfms-difference-between-ID-and-about/Manifest.rdf#test1"" , ""http://www.w3.org/2000/10/rdf-tests/rdfcore/rdfms-difference-between-ID-and-about/test1.rdf"" , true , ""http://www.w3.org/2000/10/rdf-tests/rdfcore/rdfms-difference-between-ID-and-about/test1.nt"" , false ) ; test212 . addTest ( test300 ) ; Test test301 = test211 . createPositiveTest ( ""http://www.w3.org/2000/10/rdf-tests/rdfcore/xmlbase/Manifest.rdf#test007"" , ""http://www.w3.org/2000/10/rdf-tests/rdfcore/xmlbase/test007.rdf"" , true , ""http://www.w3.org/2000/10/rdf-tests/rdfcore/xmlbase/test007.nt"" , false ) ; test212 . addTest ( test301 ) ; Test test302 = test211 . createPositiveTest ( ""http://www.w3.org/2000/10/rdf-tests/rdfcore/xmlbase/Manifest.rdf#test008"" , ""http://www.w3.org/2000/10/rdf-tests/rdfcore/xmlbase/test008.rdf"" , true , ""http://www.w3.org/2000/10/rdf-tests/rdfcore/xmlbase/test008.nt"" , false ) ; test212 . addTest ( test302 ) ; Test test303 = test211 . createPositiveTest ( ""http://www.w3.org/2000/10/rdf-tests/rdfcore/rdfms-empty-property-elements/Manifest.rdf#test005"" , ""http://www.w3.org/2000/10/rdf-tests/rdfcore/rdfms-empty-property-elements/test005.rdf"" , true , ""http://www.w3.org/2000/10/rdf-tests/rdfcore/rdfms-empty-property-elements/test005.nt"" , false ) ; test212 . addTest ( test303 ) ; Test test304 = test211 . createPositiveTest ( ""http://www.w3.org/2000/10/rdf-tests/rdfcore/rdfms-empty-property-elements/Manifest.rdf#test006"" , ""http://www.w3.org/2000/10/rdf-tests/rdfcore/rdfms-empty-property-elements/test006.rdf"" , true , ""http://www.w3.org/2000/10/rdf-tests/rdfcore/rdfms-empty-property-elements/test006.nt"" , false ) ; test212 . addTest ( test304 ) ; Test test305 = test211 . createNegativeTest ( ""http://www.w3.org/2000/10/rdf-tests/rdfcore/rdfms-rdf-id/Manifest.rdf#error001"" , ""http://www.w3.org/2000/10/rdf-tests/rdfcore/rdfms-rdf-id/error001.rdf"" , true , null ) ; test212 . addTest ( test305 ) ; Test test306 = test211 . createPositiveTest ( ""http://www.w3.org/2000/10/rdf-tests/rdfcore/rdfms-rdf-names-use/Manifest.rdf#test-010"" , ""http://www.w3.org/2000/10/rdf-tests/rdfcore/rdfms-rdf-names-use/test-010.rdf"" , true , ""http://www.w3.org/2000/10/rdf-tests/rdfcore/rdfms-rdf-names-use/test-010.nt"" , false ) ; test212 . addTest ( test306 ) ; Test test307 = test211 . createPositiveTest ( ""http://www.w3.org/2000/10/rdf-tests/rdfcore/rdfms-xmllang/Manifest.rdf#test003"" , ""http://www.w3.org/2000/10/rdf-tests/rdfcore/rdfms-xmllang/test003.rdf"" , true , ""http://www.w3.org/2000/10/rdf-tests/rdfcore/rdfms-xmllang/test003.nt"" , false ) ; test212 . addTest ( test307 ) ; Test test308 = test211 . createPositiveTest ( ""http://www.w3.org/2000/10/rdf-tests/rdfcore/rdfms-xmllang/Manifest.rdf#test004"" , ""http://www.w3.org/2000/10/rdf-tests/rdfcore/rdfms-xmllang/test004.rdf"" , true , ""http://www.w3.org/2000/10/rdf-tests/rdfcore/rdfms-xmllang/test004.nt"" , false ) ; test212 . addTest ( test308 ) ; Test test309 = test211 . createNegativeTest ( ""http://www.w3.org/2000/10/rdf-tests/rdfcore/rdfms-empty-property-elements/Manifest.rdf#error001"" , ""http://www.w3.org/2000/10/rdf-tests/rdfcore/rdfms-empty-property-elements/error001.rdf"" , true , new int [ ] { 201 , } ) ; test212 . addTest ( test309 ) ; Test test310 = test211 . createNegativeTest ( ""http://www.w3.org/2000/10/rdf-tests/rdfcore/rdfms-empty-property-elements/Manifest.rdf#error002"" , ""http://www.w3.org/2000/10/rdf-tests/rdfcore/rdfms-empty-property-elements/error002.rdf"" , true , new int [ ] { 201 , } ) ; test212 . addTest ( test310 ) ; Test test311 = test211 . createPositiveTest ( ""http://www.w3.org/2000/10/rdf-tests/rdfcore/rdfms-rdf-names-use/Manifest.rdf#test-013"" , ""http://www.w3.org/2000/10/rdf-tests/rdfcore/rdfms-rdf-names-use/test-013.rdf"" , true , ""http://www.w3.org/2000/10/rdf-tests/rdfcore/rdfms-rdf-names-use/test-013.nt"" , false ) ; test212 . addTest ( test311 ) ; Test test312 = test211 . createPositiveTest ( ""http://www.w3.org/2000/10/rdf-tests/rdfcore/rdfms-rdf-names-use/Manifest.rdf#test-014"" , ""http://www.w3.org/2000/10/rdf-tests/rdfcore/rdfms-rdf-names-use/test-014.rdf"" , true , ""http://www.w3.org/2000/10/rdf-tests/rdfcore/rdfms-rdf-names-use/test-014.nt"" , false ) ; test212 . addTest ( test312 ) ; Test test313 = test211 . createPositiveTest ( ""http://www.w3.org/2000/10/rdf-tests/rdfcore/rdfms-rdf-names-use/Manifest.rdf#test-001"" , ""http://www.w3.org/2000/10/rdf-tests/rdfcore/rdfms-rdf-names-use/test-001.rdf"" , true , ""http://www.w3.org/2000/10/rdf-tests/rdfcore/rdfms-rdf-names-use/test-001.nt"" , false ) ; test212 . addTest ( test313 ) ; Test test314 = test211 . createPositiveTest ( ""http://www.w3.org/2000/10/rdf-tests/rdfcore/rdf-charmod-literals/Manifest.rdf#test001"" , ""http://www.w3.org/2000/10/rdf-tests/rdfcore/rdf-charmod-literals/test001.rdf"" , true , ""http://www.w3.org/2000/10/rdf-tests/rdfcore/rdf-charmod-literals/test001.nt"" , false ) ; test212 . addTest ( test314 ) ; Test test315 = test211 . createNegativeTest ( ""http://www.w3.org/2000/10/rdf-tests/rdfcore/rdfms-rdf-names-use/Manifest.rdf#error-007"" , ""http://www.w3.org/2000/10/rdf-tests/rdfcore/rdfms-rdf-names-use/error-007.rdf"" , true , new int [ ] { 205 , } ) ; test212 . addTest ( test315 ) ; Test test316 = test211 . createNegativeTest ( ""http://www.w3.org/2000/10/rdf-tests/rdfcore/rdfms-rdf-names-use/Manifest.rdf#error-006"" , ""http://www.w3.org/2000/10/rdf-tests/rdfcore/rdfms-rdf-names-use/error-006.rdf"" , true , new int [ ] { 205 , } ) ; test212 . addTest ( test316 ) ; Test test317 = test211 . createWarningTest ( ""http://www.w3.org/2000/10/rdf-tests/rdfcore/rdfms-rdf-names-use/Manifest.rdf#warn-003"" , ""http://www.w3.org/2000/10/rdf-tests/rdfcore/rdfms-rdf-names-use/warn-003.rdf"" , true , ""http://www.w3.org/2000/10/rdf-tests/rdfcore/rdfms-rdf-names-use/warn-003.nt"" , false , null ) ; test212 . addTest ( test317 ) ; Test test318 = test211 . createWarningTest ( ""http://www.w3.org/2000/10/rdf-tests/rdfcore/rdfms-rdf-names-use/Manifest.rdf#warn-002"" , ""http://www.w3.org/2000/10/rdf-tests/rdfcore/rdfms-rdf-names-use/warn-002.rdf"" , true , ""http://www.w3.org/2000/10/rdf-tests/rdfcore/rdfms-rdf-names-use/warn-002.nt"" , false , null ) ; test212 . addTest ( test318 ) ; Test test319 = test211 . createNegativeTest ( ""http://www.w3.org/2000/10/rdf-tests/rdfcore/rdfms-rdf-names-use/Manifest.rdf#error-014"" , ""http://www.w3.org/2000/10/rdf-tests/rdfcore/rdfms-rdf-names-use/error-014.rdf"" , true , new int [ ] { 205 , } ) ; test212 . addTest ( test319 ) ; Test test320 = test211 . createNegativeTest ( ""http://www.w3.org/2000/10/rdf-tests/rdfcore/rdfms-rdf-names-use/Manifest.rdf#error-013"" , ""http://www.w3.org/2000/10/rdf-tests/rdfcore/rdfms-rdf-names-use/error-013.rdf"" , true , new int [ ] { 205 , } ) ; test212 . addTest ( test320 ) ; Test test321 = test211 . createPositiveTest ( ""http://www.w3.org/2000/10/rdf-tests/rdfcore/rdfms-identity-anon-resources/Manifest.rdf#test003"" , ""http://www.w3.org/2000/10/rdf-tests/rdfcore/rdfms-identity-anon-resources/test003.rdf"" , true , ""http://www.w3.org/2000/10/rdf-tests/rdfcore/rdfms-identity-anon-resources/test003.nt"" , false ) ; test212 . addTest ( test321 ) ; Test test322 = test211 . createPositiveTest ( ""http://www.w3.org/2000/10/rdf-tests/rdfcore/rdfms-identity-anon-resources/Manifest.rdf#test004"" , ""http://www.w3.org/2000/10/rdf-tests/rdfcore/rdfms-identity-anon-resources/test004.rdf"" , true , ""http://www.w3.org/2000/10/rdf-tests/rdfcore/rdfms-identity-anon-resources/test004.nt"" , false ) ; test212 . addTest ( test322 ) ; Test test323 = test211 . createNegativeTest ( ""http://www.w3.org/2000/10/rdf-tests/rdfcore/rdfms-rdf-names-use/Manifest.rdf#error-017"" , ""http://www.w3.org/2000/10/rdf-tests/rdfcore/rdfms-rdf-names-use/error-017.rdf"" , true , new int [ ] { 205 , } ) ; test212 . addTest ( test323 ) ; Test test324 = test211 . createNegativeTest ( ""http://www.w3.org/2000/10/rdf-tests/rdfcore/rdfms-rdf-names-use/Manifest.rdf#error-018"" , ""http://www.w3.org/2000/10/rdf-tests/rdfcore/rdfms-rdf-names-use/error-018.rdf"" , true , new int [ ] { 205 , } ) ; test212 . addTest ( test324 ) ; Test test325 = test211 . createPositiveTest ( ""http://www.w3.org/2000/10/rdf-tests/rdfcore/rdfms-empty-property-elements/Manifest.rdf#test009"" , ""http://www.w3.org/2000/10/rdf-tests/rdfcore/rdfms-empty-property-elements/test009.rdf"" , true , ""http://www.w3.org/2000/10/rdf-tests/rdfcore/rdfms-empty-property-elements/test009.nt"" , false ) ; test212 . addTest ( test325 ) ; Test test326 = test211 . createPositiveTest ( ""http://www.w3.org/2000/10/rdf-tests/rdfcore/rdfms-xml-literal-namespaces/Manifest.rdf#test002"" , ""http://www.w3.org/2000/10/rdf-tests/rdfcore/rdfms-xml-literal-namespaces/test002.rdf"" , true , ""http://www.w3.org/2000/10/rdf-tests/rdfcore/rdfms-xml-literal-namespaces/test002.nt"" , false ) ; test212 . addTest ( test326 ) ; Test test327 = test211 . createPositiveTest ( ""http://www.w3.org/2000/10/rdf-tests/rdfcore/rdfms-xmllang/Manifest.rdf#test001"" , ""http://www.w3.org/2000/10/rdf-tests/rdfcore/rdfms-xmllang/test001.rdf"" , true , ""http://www.w3.org/2000/10/rdf-tests/rdfcore/rdfms-xmllang/test001.nt"" , false ) ; test212 . addTest ( test327 ) ; Test test328 = test211 . createPositiveTest ( ""http://www.w3.org/2000/10/rdf-tests/rdfcore/rdfms-xmllang/Manifest.rdf#test002"" , ""http://www.w3.org/2000/10/rdf-tests/rdfcore/rdfms-xmllang/test002.rdf"" , true , ""http://www.w3.org/2000/10/rdf-tests/rdfcore/rdfms-xmllang/test002.nt"" , false ) ; test212 . addTest ( test328 ) ; Test test329 = test211 . createNegativeTest ( ""http://www.w3.org/2000/10/rdf-tests/rdfcore/rdfms-syntax-incomplete/Manifest.rdf#error006"" , ""http://www.w3.org/2000/10/rdf-tests/rdfcore/rdfms-syntax-incomplete/error006.rdf"" , true , null ) ; test212 . addTest ( test329 ) ; Test test330 = test211 . createPositiveTest ( ""http://www.w3.org/2000/10/rdf-tests/rdfcore/rdf-containers-syntax-vs-schema/Manifest.rdf#test008"" , ""http://www.w3.org/2000/10/rdf-tests/rdfcore/rdf-containers-syntax-vs-schema/test008.rdf"" , true , ""http://www.w3.org/2000/10/rdf-tests/rdfcore/rdf-containers-syntax-vs-schema/test008.nt"" , false ) ; test212 . addTest ( test330 ) ; Test test331 = test211 . createPositiveTest ( ""http://www.w3.org/2000/10/rdf-tests/rdfcore/rdfms-rdf-names-use/Manifest.rdf#test-026"" , ""http://www.w3.org/2000/10/rdf-tests/rdfcore/rdfms-rdf-names-use/test-026.rdf"" , true , ""http://www.w3.org/2000/10/rdf-tests/rdfcore/rdfms-rdf-names-use/test-026.nt"" , false ) ; test212 . addTest ( test331 ) ; Test test332 = test211 . createPositiveTest ( ""http://www.w3.org/2000/10/rdf-tests/rdfcore/rdfms-rdf-names-use/Manifest.rdf#test-027"" , ""http://www.w3.org/2000/10/rdf-tests/rdfcore/rdfms-rdf-names-use/test-027.rdf"" , true , ""http://www.w3.org/2000/10/rdf-tests/rdfcore/rdfms-rdf-names-use/test-027.nt"" , false ) ; test212 . addTest ( test332 ) ; Test test333 = test211 . createNegativeTest ( ""http://www.w3.org/2000/10/rdf-tests/rdfcore/rdfms-rdf-names-use/Manifest.rdf#error-010"" , ""http://www.w3.org/2000/10/rdf-tests/rdfcore/rdfms-rdf-names-use/error-010.rdf"" , true , new int [ ] { 205 , } ) ; test212 . addTest ( test333 ) ; Test test334 = test211 . createPositiveTest ( ""http://www.w3.org/2000/10/rdf-tests/rdfcore/rdfms-empty-property-elements/Manifest.rdf#test011"" , ""http://www.w3.org/2000/10/rdf-tests/rdfcore/rdfms-empty-property-elements/test011.rdf"" , true , ""http://www.w3.org/2000/10/rdf-tests/rdfcore/rdfms-empty-property-elements/test011.nt"" , false ) ; test212 . addTest ( test334 ) ; Test test335 = test211 . createPositiveTest ( ""http://www.w3.org/2000/10/rdf-tests/rdfcore/rdfms-empty-property-elements/Manifest.rdf#test010"" , ""http://www.w3.org/2000/10/rdf-tests/rdfcore/rdfms-empty-property-elements/test010.rdf"" , true , ""http://www.w3.org/2000/10/rdf-tests/rdfcore/rdfms-empty-property-elements/test010.nt"" , false ) ; test212 . addTest ( test335 ) ; Test test336 = test211 . createPositiveTest ( ""http://www.w3.org/2000/10/rdf-tests/rdfcore/rdfms-rdf-names-use/Manifest.rdf#test-019"" , ""http://www.w3.org/2000/10/rdf-tests/rdfcore/rdfms-rdf-names-use/test-019.rdf"" , true , ""http://www.w3.org/2000/10/rdf-tests/rdfcore/rdfms-rdf-names-use/test-019.nt"" , false ) ; test212 . addTest ( test336 ) ; Test test337 = test211 . createPositiveTest ( ""http://www.w3.org/2000/10/rdf-tests/rdfcore/rdfms-empty-property-elements/Manifest.rdf#test001"" , ""http://www.w3.org/2000/10/rdf-tests/rdfcore/rdfms-empty-property-elements/test001.rdf"" , true , ""http://www.w3.org/2000/10/rdf-tests/rdfcore/rdfms-empty-property-elements/test001.nt"" , false ) ; test212 . addTest ( test337 ) ; Test test338 = test211 . createPositiveTest ( ""http://www.w3.org/2000/10/rdf-tests/rdfcore/rdfms-empty-property-elements/Manifest.rdf#test002"" , ""http://www.w3.org/2000/10/rdf-tests/rdfcore/rdfms-empty-property-elements/test002.rdf"" , true , ""http://www.w3.org/2000/10/rdf-tests/rdfcore/rdfms-empty-property-elements/test002.nt"" , false ) ; test212 . addTest ( test338 ) ; Test test339 = test211 . createPositiveTest ( ""http://www.w3.org/2000/10/rdf-tests/rdfcore/rdf-ns-prefix-confusion/Manifest.rdf#test0014"" , ""http://www.w3.org/2000/10/rdf-tests/rdfcore/rdf-ns-prefix-confusion/test0014.rdf"" , true , ""http://www.w3.org/2000/10/rdf-tests/rdfcore/rdf-ns-prefix-confusion/test0014.nt"" , false ) ; test212 . addTest ( test339 ) ; Test test340 = test211 . createNegativeTest ( ""http://www.w3.org/2000/10/rdf-tests/rdfcore/rdf-containers-syntax-vs-schema/Manifest.rdf#error001"" , ""http://www.w3.org/2000/10/rdf-tests/rdfcore/rdf-containers-syntax-vs-schema/error001.rdf"" , true , new int [ ] { 206 , } ) ; test212 . addTest ( test340 ) ; Test test341 = test211 . createPositiveTest ( ""http://www.w3.org/2000/10/rdf-tests/rdfcore/rdfms-syntax-incomplete/Manifest.rdf#test003"" , ""http://www.w3.org/2000/10/rdf-tests/rdfcore/rdfms-syntax-incomplete/test003.rdf"" , true , ""http://www.w3.org/2000/10/rdf-tests/rdfcore/rdfms-syntax-incomplete/test003.nt"" , false ) ; test212 . addTest ( test341 ) ; Test test342 = test211 . createPositiveTest ( ""http://www.w3.org/2000/10/rdf-tests/rdfcore/rdfms-syntax-incomplete/Manifest.rdf#test002"" , ""http://www.w3.org/2000/10/rdf-tests/rdfcore/rdfms-syntax-incomplete/test002.rdf"" , true , ""http://www.w3.org/2000/10/rdf-tests/rdfcore/rdfms-syntax-incomplete/test002.nt"" , false ) ; test212 . addTest ( test342 ) ; Test test343 = test211 . createNegativeTest ( ""http://www.w3.org/2000/10/rdf-tests/rdfcore/rdfms-rdf-names-use/Manifest.rdf#error-012"" , ""http://www.w3.org/2000/10/rdf-tests/rdfcore/rdfms-rdf-names-use/error-012.rdf"" , true , new int [ ] { 205 , } ) ; test212 . addTest ( test343 ) ; Test test344 = test211 . createNegativeTest ( ""http://www.w3.org/2000/10/rdf-tests/rdfcore/rdfms-rdf-names-use/Manifest.rdf#error-011"" , ""http://www.w3.org/2000/10/rdf-tests/rdfcore/rdfms-rdf-names-use/error-011.rdf"" , true , new int [ ] { 205 , } ) ; test212 . addTest ( test344 ) ; Test test345 = test211 . createNegativeTest ( ""http://www.w3.org/2000/10/rdf-tests/rdfcore/rdfms-syntax-incomplete/Manifest.rdf#error001"" , ""http://www.w3.org/2000/10/rdf-tests/rdfcore/rdfms-syntax-incomplete/error001.rdf"" , true , null ) ; test212 . addTest ( test345 ) ; Test test346 = test211 . createPositiveTest ( ""http://www.w3.org/2000/10/rdf-tests/rdfcore/rdfms-rdf-names-use/Manifest.rdf#test-034"" , ""http://www.w3.org/2000/10/rdf-tests/rdfcore/rdfms-rdf-names-use/test-034.rdf"" , true , ""http://www.w3.org/2000/10/rdf-tests/rdfcore/rdfms-rdf-names-use/test-034.nt"" , false ) ; test212 . addTest ( test346 ) ; Test test347 = test211 . createPositiveTest ( ""http://www.w3.org/2000/10/rdf-tests/rdfcore/rdfms-rdf-names-use/Manifest.rdf#test-033"" , ""http://www.w3.org/2000/10/rdf-tests/rdfcore/rdfms-rdf-names-use/test-033.rdf"" , true , ""http://www.w3.org/2000/10/rdf-tests/rdfcore/rdfms-rdf-names-use/test-033.nt"" , false ) ; test212 . addTest ( test347 ) ; Test test348 = test211 . createPositiveTest ( ""http://www.w3.org/2000/10/rdf-tests/rdfcore/rdfms-rdf-names-use/Manifest.rdf#test-037"" , ""http://www.w3.org/2000/10/rdf-tests/rdfcore/rdfms-rdf-names-use/test-037.rdf"" , true , ""http://www.w3.org/2000/10/rdf-tests/rdfcore/rdfms-rdf-names-use/test-037.nt"" , false ) ; test212 . addTest ( test348 ) ; Test test349 = test211 . createPositiveTest ( ""http://www.w3.org/2000/10/rdf-tests/rdfcore/rdfms-rdf-names-use/Manifest.rdf#test-036"" , ""http://www.w3.org/2000/10/rdf-tests/rdfcore/rdfms-rdf-names-use/test-036.rdf"" , true , ""http://www.w3.org/2000/10/rdf-tests/rdfcore/rdfms-rdf-names-use/test-036.nt"" , false ) ; test212 . addTest ( test349 ) ; Test test350 = test211 . createPositiveTest ( ""http://www.w3.org/2000/10/rdf-tests/rdfcore/rdfms-rdf-names-use/Manifest.rdf#test-035"" , ""http://www.w3.org/2000/10/rdf-tests/rdfcore/rdfms-rdf-names-use/test-035.rdf"" , true , ""http://www.w3.org/2000/10/rdf-tests/rdfcore/rdfms-rdf-names-use/test-035.nt"" , false ) ; test212 . addTest ( test350 ) ; Test test351 = test211 . createNegativeTest ( ""http://www.w3.org/2000/10/rdf-tests/rdfcore/rdfms-syntax-incomplete/Manifest.rdf#error003"" , ""http://www.w3.org/2000/10/rdf-tests/rdfcore/rdfms-syntax-incomplete/error003.rdf"" , true , null ) ; test212 . addTest ( test351 ) ; Test test352 = test211 . createNegativeTest ( ""http://www.w3.org/2000/10/rdf-tests/rdfcore/rdfms-syntax-incomplete/Manifest.rdf#error002"" , ""http://www.w3.org/2000/10/rdf-tests/rdfcore/rdfms-syntax-incomplete/error002.rdf"" , true , null ) ; test212 . addTest ( test352 ) ; Test test353 = test211 . createPositiveTest ( ""http://www.w3.org/2000/10/rdf-tests/rdfcore/rdfms-difference-between-ID-and-about/Manifest.rdf#test2"" , ""http://www.w3.org/2000/10/rdf-tests/rdfcore/rdfms-difference-between-ID-and-about/test2.rdf"" , true , ""http://www.w3.org/2000/10/rdf-tests/rdfcore/rdfms-difference-between-ID-and-about/test2.nt"" , false ) ; test212 . addTest ( test353 ) ; Test test354 = test211 . createPositiveTest ( ""http://www.w3.org/2000/10/rdf-tests/rdfcore/rdfms-rdf-names-use/Manifest.rdf#test-008"" , ""http://www.w3.org/2000/10/rdf-tests/rdfcore/rdfms-rdf-names-use/test-008.rdf"" , true , ""http://www.w3.org/2000/10/rdf-tests/rdfcore/rdfms-rdf-names-use/test-008.nt"" , false ) ; test212 . addTest ( test354 ) ; Test test355 = test211 . createPositiveTest ( ""http://www.w3.org/2000/10/rdf-tests/rdfcore/rdfms-rdf-names-use/Manifest.rdf#test-009"" , ""http://www.w3.org/2000/10/rdf-tests/rdfcore/rdfms-rdf-names-use/test-009.rdf"" , true , ""http://www.w3.org/2000/10/rdf-tests/rdfcore/rdfms-rdf-names-use/test-009.nt"" , false ) ; test212 . addTest ( test355 ) ; Test test356 = test211 . createPositiveTest ( ""http://www.w3.org/2000/10/rdf-tests/rdfcore/rdfms-rdf-names-use/Manifest.rdf#test-032"" , ""http://www.w3.org/2000/10/rdf-tests/rdfcore/rdfms-rdf-names-use/test-032.rdf"" , true , ""http://www.w3.org/2000/10/rdf-tests/rdfcore/rdfms-rdf-names-use/test-032.nt"" , false ) ; test212 . addTest ( test356 ) ; Test test357 = test211 . createPositiveTest ( ""http://www.w3.org/2000/10/rdf-tests/rdfcore/rdfms-rdf-names-use/Manifest.rdf#test-031"" , ""http://www.w3.org/2000/10/rdf-tests/rdfcore/rdfms-rdf-names-use/test-031.rdf"" , true , ""http://www.w3.org/2000/10/rdf-tests/rdfcore/rdfms-rdf-names-use/test-031.nt"" , false ) ; test212 . addTest ( test357 ) ; Test test358 = test211 . createPositiveTest ( ""http://www.w3.org/2000/10/rdf-tests/rdfcore/rdf-ns-prefix-confusion/Manifest.rdf#test0001"" , ""http://www.w3.org/2000/10/rdf-tests/rdfcore/rdf-ns-prefix-confusion/test0001.rdf"" , true , ""http://www.w3.org/2000/10/rdf-tests/rdfcore/rdf-ns-prefix-confusion/test0001.nt"" , false ) ; test212 . addTest ( test358 ) ; Test test359 = test211 . createNegativeTest ( ""http://www.w3.org/2000/10/rdf-tests/rdfcore/rdfms-rdf-names-use/Manifest.rdf#error-008"" , ""http://www.w3.org/2000/10/rdf-tests/rdfcore/rdfms-rdf-names-use/error-008.rdf"" , true , new int [ ] { 204 , } ) ; test212 . addTest ( test359 ) ; Test test360 = test211 . createNegativeTest ( ""http://www.w3.org/2000/10/rdf-tests/rdfcore/rdfms-rdf-names-use/Manifest.rdf#error-009"" , ""http://www.w3.org/2000/10/rdf-tests/rdfcore/rdfms-rdf-names-use/error-009.rdf"" , true , new int [ ] { 205 , } ) ; test212 . addTest ( test360 ) ; Test test361 = test211 . createPositiveTest ( ""http://www.w3.org/2000/10/rdf-tests/rdfcore/xmlbase/Manifest.rdf#test006"" , ""http://www.w3.org/2000/10/rdf-tests/rdfcore/xmlbase/test006.rdf"" , true , ""http://www.w3.org/2000/10/rdf-tests/rdfcore/xmlbase/test006.nt"" , false ) ; test212 . addTest ( test361 ) ; Test test362 = test211 . createPositiveTest ( ""http://www.w3.org/2000/10/rdf-tests/rdfcore/rdfms-uri-substructure/Manifest.rdf#test001"" , ""http://www.w3.org/2000/10/rdf-tests/rdfcore/rdfms-uri-substructure/test001.rdf"" , true , ""http://www.w3.org/2000/10/rdf-tests/rdfcore/rdfms-uri-substructure/test001.nt"" , false ) ; test212 . addTest ( test362 ) ; Test test363 = test211 . createNegativeTest ( ""http://www.w3.org/2000/10/rdf-tests/rdfcore/rdfms-empty-property-elements/Manifest.rdf#error003"" , ""http://www.w3.org/2000/10/rdf-tests/rdfcore/rdfms-empty-property-elements/error003.rdf"" , true , new int [ ] { 201 , } ) ; test212 . addTest ( test363 ) ; Test test364 = test211 . createNegativeTest ( ""http://www.w3.org/2000/10/rdf-tests/rdfcore/rdfms-rdf-names-use/Manifest.rdf#error-002"" , ""http://www.w3.org/2000/10/rdf-tests/rdfcore/rdfms-rdf-names-use/error-002.rdf"" , true , new int [ ] { 205 , } ) ; test212 . addTest ( test364 ) ; Test test365 = test211 . createNegativeTest ( ""http://www.w3.org/2000/10/rdf-tests/rdfcore/rdfms-rdf-names-use/Manifest.rdf#error-003"" , ""http://www.w3.org/2000/10/rdf-tests/rdfcore/rdfms-rdf-names-use/error-003.rdf"" , true , new int [ ] { 205 , } ) ; test212 . addTest ( test365 ) ; Test test366 = test211 . createPositiveTest ( ""http://www.w3.org/2000/10/rdf-tests/rdfcore/xmlbase/Manifest.rdf#test013"" , ""http://www.w3.org/2000/10/rdf-tests/rdfcore/xmlbase/test013.rdf"" , true , ""http://www.w3.org/2000/10/rdf-tests/rdfcore/xmlbase/test013.nt"" , false ) ; test212 . addTest ( test366 ) ; Test test367 = test211 . createPositiveTest ( ""http://www.w3.org/2000/10/rdf-tests/rdfcore/rdfms-rdf-names-use/Manifest.rdf#test-022"" , ""http://www.w3.org/2000/10/rdf-tests/rdfcore/rdfms-rdf-names-use/test-022.rdf"" , true , ""http://www.w3.org/2000/10/rdf-tests/rdfcore/rdfms-rdf-names-use/test-022.nt"" , false ) ; test212 . addTest ( test367 ) ; Test test368 = test211 . createPositiveTest ( ""http://www.w3.org/2000/10/rdf-tests/rdfcore/rdfms-rdf-names-use/Manifest.rdf#test-023"" , ""http://www.w3.org/2000/10/rdf-tests/rdfcore/rdfms-rdf-names-use/test-023.rdf"" , true , ""http://www.w3.org/2000/10/rdf-tests/rdfcore/rdfms-rdf-names-use/test-023.nt"" , false ) ; test212 . addTest ( test368 ) ; Test test369 = test211 . createPositiveTest ( ""http://www.w3.org/2000/10/rdf-tests/rdfcore/rdfms-rdf-names-use/Manifest.rdf#test-004"" , ""http://www.w3.org/2000/10/rdf-tests/rdfcore/rdfms-rdf-names-use/test-004.rdf"" , true , ""http://www.w3.org/2000/10/rdf-tests/rdfcore/rdfms-rdf-names-use/test-004.nt"" , false ) ; test212 . addTest ( test369 ) ; Test test370 = test211 . createPositiveTest ( ""http://www.w3.org/2000/10/rdf-tests/rdfcore/rdfms-rdf-names-use/Manifest.rdf#test-005"" , ""http://www.w3.org/2000/10/rdf-tests/rdfcore/rdfms-rdf-names-use/test-005.rdf"" , true , ""http://www.w3.org/2000/10/rdf-tests/rdfcore/rdfms-rdf-names-use/test-005.nt"" , false ) ; test212 . addTest ( test370 ) ; Test test371 = test211 . createPositiveTest ( ""http://www.w3.org/2000/10/rdf-tests/rdfcore/rdfms-not-id-and-resource-attr/Manifest.rdf#test002"" , ""http://www.w3.org/2000/10/rdf-tests/rdfcore/rdfms-not-id-and-resource-attr/test002.rdf"" , true , ""http://www.w3.org/2000/10/rdf-tests/rdfcore/rdfms-not-id-and-resource-attr/test002.nt"" , false ) ; test212 . addTest ( test371 ) ; Test test372 = test211 . createPositiveTest ( ""http://www.w3.org/2000/10/rdf-tests/rdfcore/rdfms-empty-property-elements/Manifest.rdf#test014"" , ""http://www.w3.org/2000/10/rdf-tests/rdfcore/rdfms-empty-property-elements/test014.rdf"" , true , ""http://www.w3.org/2000/10/rdf-tests/rdfcore/rdfms-empty-property-elements/test014.nt"" , false ) ; test212 . addTest ( test372 ) ; Test test373 = test211 . createPositiveTest ( ""http://www.w3.org/2000/10/rdf-tests/rdfcore/rdfms-empty-property-elements/Manifest.rdf#test015"" , ""http://www.w3.org/2000/10/rdf-tests/rdfcore/rdfms-empty-property-elements/test015.rdf"" , true , ""http://www.w3.org/2000/10/rdf-tests/rdfcore/rdfms-empty-property-elements/test015.nt"" , false ) ; test212 . addTest ( test373 ) ; Test test374 = test211 . createPositiveTest ( ""http://www.w3.org/2000/10/rdf-tests/rdfcore/rdf-charmod-uris/Manifest.rdf#test002"" , ""http://www.w3.org/2000/10/rdf-tests/rdfcore/rdf-charmod-uris/test002.rdf"" , true , ""http://www.w3.org/2000/10/rdf-tests/rdfcore/rdf-charmod-uris/test002.nt"" , false ) ; test212 . addTest ( test374 ) ; Test test375 = test211 . createPositiveTest ( ""http://www.w3.org/2000/10/rdf-tests/rdfcore/rdf-ns-prefix-confusion/Manifest.rdf#test0011"" , ""http://www.w3.org/2000/10/rdf-tests/rdfcore/rdf-ns-prefix-confusion/test0011.rdf"" , true , ""http://www.w3.org/2000/10/rdf-tests/rdfcore/rdf-ns-prefix-confusion/test0011.nt"" , false ) ; test212 . addTest ( test375 ) ; Test test376 = test211 . createPositiveTest ( ""http://www.w3.org/2000/10/rdf-tests/rdfcore/rdf-ns-prefix-confusion/Manifest.rdf#test0010"" , ""http://www.w3.org/2000/10/rdf-tests/rdfcore/rdf-ns-prefix-confusion/test0010.rdf"" , true , ""http://www.w3.org/2000/10/rdf-tests/rdfcore/rdf-ns-prefix-confusion/test0010.nt"" , false ) ; test212 . addTest ( test376 ) ; Test test377 = test211 . createPositiveTest ( ""http://www.w3.org/2000/10/rdf-tests/rdfcore/rdfms-rdf-names-use/Manifest.rdf#test-012"" , ""http://www.w3.org/2000/10/rdf-tests/rdfcore/rdfms-rdf-names-use/test-012.rdf"" , true , ""http://www.w3.org/2000/10/rdf-tests/rdfcore/rdfms-rdf-names-use/test-012.nt"" , false ) ; test212 . addTest ( test377 ) ; Test test378 = test211 . createPositiveTest ( ""http://www.w3.org/2000/10/rdf-tests/rdfcore/rdfms-rdf-names-use/Manifest.rdf#test-011"" , ""http://www.w3.org/2000/10/rdf-tests/rdfcore/rdfms-rdf-names-use/test-011.rdf"" , true , ""http://www.w3.org/2000/10/rdf-tests/rdfcore/rdfms-rdf-names-use/test-011.nt"" , false ) ; test212 . addTest ( test378 ) ; test211 . addTest ( test212 ) ; TestSuite test379 = new TestSuite ( ""PENDING"" ) ; Test test380 = test211 . createPositiveTest ( ""http://www.w3.org/2000/10/rdf-tests/rdfcore/rdfms-empty-property-elements/Manifest.rdf#test016"" , ""http://www.w3.org/2000/10/rdf-tests/rdfcore/rdfms-empty-property-elements/test016.rdf"" , true , ""http://www.w3.org/2000/10/rdf-tests/rdfcore/rdfms-empty-property-elements/test016.nt"" , false ) ; test379 . addTest ( test380 ) ; Test test381 = test211 . createPositiveTest ( ""http://www.w3.org/2000/10/rdf-tests/rdfcore/rdfms-empty-property-elements/Manifest.rdf#test017"" , ""http://www.w3.org/2000/10/rdf-tests/rdfcore/rdfms-empty-property-elements/test017.rdf"" , true , ""http://www.w3.org/2000/10/rdf-tests/rdfcore/rdfms-empty-property-elements/test017.nt"" , false ) ; test379 . addTest ( test381 ) ; Test test382 = test211 . createPositiveTest ( ""http://www.w3.org/2000/10/rdf-tests/rdfcore/rdfms-difference-between-ID-and-about/Manifest.rdf#test3"" , ""http://www.w3.org/2000/10/rdf-tests/rdfcore/rdfms-difference-between-ID-and-about/test3.rdf"" , true , ""http://www.w3.org/2000/10/rdf-tests/rdfcore/rdfms-difference-between-ID-and-about/test3.nt"" , false ) ; test379 . addTest ( test382 ) ; test211 . addTest ( test379 ) ; test0 . addTest ( test211 ) ; return test0 ; }",Smelly
" static String add_escapes ( String str ) { StringBuffer retval = new StringBuffer ( ) ; char ch ; for ( int i = 0 ; i < str . length ( ) ; i ++ ) { switch ( str . charAt ( i ) ) { case 0 : continue ; case '\b' : retval . append ( ""\\b"" ) ; continue ; case '\t' : retval . append ( ""\\t"" ) ; continue ; case '\n' : retval . append ( ""\\n"" ) ; continue ; case '\f' : retval . append ( ""\\f"" ) ; continue ; case '\r' : retval . append ( ""\\r"" ) ; continue ; case '\""' : retval . append ( ""\\\"""" ) ; continue ; case '\'' : retval . append ( ""\\\'"" ) ; continue ; case '\\' : retval . append ( ""\\\\"" ) ; continue ; default : if ( ( ch = str . charAt ( i ) ) < 0x20 || ch > 0x7e ) { String s = ""0000"" + Integer . toString ( ch , 16 ) ; retval . append ( ""\\u"" + s . substring ( s . length ( ) - 4 , s . length ( ) ) ) ; } else { retval . append ( ch ) ; } continue ; } } return retval . toString ( ) ; }",Smelly
" private static void drainStep ( final Vertex vertex , final Step < Object , Object > step , final TraverserSet < Object > activeTraversers , final TraverserSet < Object > haltedTraversers , final Memory memory , final boolean returnHaltedTraversers , final HaltedTraverserStrategy haltedTraverserStrategy ) { GraphComputing . atMaster ( step , false ) ; if ( step instanceof Barrier ) { if ( step instanceof Bypassing ) ( ( Bypassing ) step ) . setBypass ( true ) ; if ( step instanceof LocalBarrier ) { final LocalBarrier < Object > barrier = ( LocalBarrier < Object > ) step ; final TraverserSet < Object > localBarrierTraversers = vertex . < TraverserSet < Object > > property ( TraversalVertexProgram . ACTIVE_TRAVERSERS ) . orElse ( new TraverserSet < > ( ) ) ; vertex . property ( TraversalVertexProgram . ACTIVE_TRAVERSERS , localBarrierTraversers ) ; while ( barrier . hasNextBarrier ( ) ) { final TraverserSet < Object > barrierSet = barrier . nextBarrier ( ) ; IteratorUtils . removeOnNext ( barrierSet . iterator ( ) ) . forEachRemaining ( traverser -> { traverser . addLabels ( step . getLabels ( ) ) ; if ( traverser . isHalted ( ) && ( returnHaltedTraversers || ( ! ( traverser . get ( ) instanceof Element ) && ! ( traverser . get ( ) instanceof Property ) ) || Host . getHostingVertex ( traverser . get ( ) ) . equals ( vertex ) ) ) { if ( returnHaltedTraversers ) memory . add ( TraversalVertexProgram . HALTED_TRAVERSERS , new TraverserSet < > ( haltedTraverserStrategy . halt ( traverser ) ) ) ; else haltedTraversers . add ( traverser . detach ( ) ) ; } else localBarrierTraversers . add ( traverser . detach ( ) ) ; } ) ; } memory . add ( TraversalVertexProgram . MUTATED_MEMORY_KEYS , new HashSet < > ( Collections . singleton ( step . getId ( ) ) ) ) ; } else { final Barrier barrier = ( Barrier ) step ; while ( barrier . hasNextBarrier ( ) ) { memory . add ( step . getId ( ) , barrier . nextBarrier ( ) ) ; } memory . add ( TraversalVertexProgram . MUTATED_MEMORY_KEYS , new HashSet < > ( Collections . singleton ( step . getId ( ) ) ) ) ; } } else { step . forEachRemaining ( traverser -> { if ( traverser . isHalted ( ) && ( ( returnHaltedTraversers || ReferenceFactory . class == haltedTraverserStrategy . getHaltedTraverserFactory ( ) ) && ( ! ( traverser . get ( ) instanceof Element ) && ! ( traverser . get ( ) instanceof Property ) ) || Host . getHostingVertex ( traverser . get ( ) ) . equals ( vertex ) ) ) { if ( returnHaltedTraversers ) memory . add ( TraversalVertexProgram . HALTED_TRAVERSERS , new TraverserSet < > ( haltedTraverserStrategy . halt ( traverser ) ) ) ; else haltedTraversers . add ( traverser . detach ( ) ) ; } else { activeTraversers . add ( traverser ) ; } } ) ; } }",Smelly
" public Map < TupleTag < ? > , PValue > expand ( ) { return Collections . singletonMap ( tag , pCollection ) ; }",No
" public void postAddRSGroup ( ObserverContext < MasterCoprocessorEnvironment > ctx , String name ) throws IOException { }",No
" public String eval ( ) { return ""ftremblay@gmail.com"" ; }",No
" protected void setRealm ( String realm , KrbCredInfoContainer krbCredInfoContainer ) { krbCredInfoContainer . getKrbCredInfo ( ) . setpRealm ( realm ) ; krbCredInfoContainer . setGrammarEndAllowed ( true ) ; }",No
" public String toString ( ) { IndentedLineBuffer out = new IndentedLineBuffer ( ) ; SerializationContext sCxt = SSE . sCxt ( SSE . getPrefixMapString ( ) ) ; boolean first = true ; for ( Triple t : triples ) { if ( ! first ) out . print ( ""\n"" ) ; else first = false ; out . print ( ""("" ) ; WriterNode . outputPlain ( out , t , sCxt ) ; out . print ( "")"" ) ; } out . flush ( ) ; return out . toString ( ) ; }",No
" public void testDenyToMany ( ) { Gallery gallery = ( Gallery ) context . newObject ( ""Gallery"" ) ; gallery . setGalleryName ( ""A Name"" ) ; Painting painting = ( Painting ) context . newObject ( ""Painting"" ) ; painting . setPaintingTitle ( ""A Title"" ) ; gallery . addToPaintingArray ( painting ) ; context . commitChanges ( ) ; try { context . deleteObjects ( gallery ) ; fail ( ""Should have thrown an exception"" ) ; } catch ( Exception e ) { } context . commitChanges ( ) ; }",No
" public String getBeanName ( ) { return ""checkbox"" ; }",No
 public static void main ( String [ ] args ) { ExampleUtils . showExampleFrame ( new Display ( ) ) ; },Smelly
" public void looseMarshal ( OpenWireFormat wireFormat , Object o , DataOutput dataOut ) throws IOException { RemoveInfo info = ( RemoveInfo ) o ; super . looseMarshal ( wireFormat , o , dataOut ) ; looseMarshalCachedObject ( wireFormat , ( DataStructure ) info . getObjectId ( ) , dataOut ) ; looseMarshalLong ( wireFormat , info . getLastDeliveredSequenceId ( ) , dataOut ) ; }",No
 protected abstract boolean showTagBody ( String p ) ;,No
 public void setLeafB1Data ( String leafB1Data ) { this . leafB1Data = leafB1Data ; },No
" public void testZNRecordSizeLimitUseZNRecordStreamingSerializer ( ) { String className = TestUtil . getTestName ( ) ; System . out . println ( ""START testZNRecordSizeLimitUseZNRecordStreamingSerializer at "" + new Date ( System . currentTimeMillis ( ) ) ) ; ZNRecordStreamingSerializer serializer = new ZNRecordStreamingSerializer ( ) ; String root = className ; byte [ ] buf = new byte [ 1024 ] ; for ( int i = 0 ; i < 1024 ; i ++ ) { buf [ i ] = 'a' ; } String bufStr = new String ( buf ) ; final ZNRecord smallRecord = new ZNRecord ( ""normalsize"" ) ; smallRecord . getSimpleFields ( ) . clear ( ) ; for ( int i = 0 ; i < 900 ; i ++ ) { smallRecord . setSimpleField ( i + """" , bufStr ) ; } String path1 = ""/"" + root + ""/test1"" ; _zkclient . createPersistent ( path1 , true ) ; _zkclient . writeData ( path1 , smallRecord ) ; ZNRecord record = _zkclient . readData ( path1 ) ; Assert . assertTrue ( serializer . serialize ( record ) . length > 900 * 1024 ) ; final ZNRecord largeRecord = new ZNRecord ( ""oversize"" ) ; largeRecord . getSimpleFields ( ) . clear ( ) ; for ( int i = 0 ; i < 1024 ; i ++ ) { largeRecord . setSimpleField ( i + """" , bufStr ) ; } String path2 = ""/"" + root + ""/test2"" ; _zkclient . createPersistent ( path2 , true ) ; try { _zkclient . writeData ( path2 , largeRecord ) ; Assert . fail ( ""Should fail because data size is larger than 1M"" ) ; } catch ( HelixException e ) { } record = _zkclient . readData ( path2 ) ; Assert . assertNull ( record ) ; record = _zkclient . readData ( path1 ) ; try { _zkclient . writeData ( path1 , largeRecord ) ; Assert . fail ( ""Should fail because data size is larger than 1M"" ) ; } catch ( HelixException e ) { } ZNRecord recordNew = _zkclient . readData ( path1 ) ; byte [ ] arr = serializer . serialize ( record ) ; byte [ ] arrNew = serializer . serialize ( recordNew ) ; Assert . assertTrue ( Arrays . equals ( arr , arrNew ) ) ; ZKHelixAdmin admin = new ZKHelixAdmin ( _zkclient ) ; admin . addCluster ( className , true ) ; InstanceConfig instanceConfig = new InstanceConfig ( ""localhost_12918"" ) ; admin . addInstance ( className , instanceConfig ) ; ZKHelixDataAccessor accessor = new ZKHelixDataAccessor ( className , new ZkBaseDataAccessor < ZNRecord > ( _zkclient ) ) ; Builder keyBuilder = accessor . keyBuilder ( ) ; IdealState idealState = new IdealState ( ""currentState"" ) ; idealState . setStateModelDefId ( StateModelDefId . from ( ""MasterSlave"" ) ) ; idealState . setRebalanceMode ( RebalanceMode . SEMI_AUTO ) ; idealState . setNumPartitions ( 10 ) ; for ( int i = 0 ; i < 1024 ; i ++ ) { idealState . getRecord ( ) . setSimpleField ( i + """" , bufStr ) ; } boolean succeed = accessor . setProperty ( keyBuilder . idealStates ( ""TestDB_1"" ) , idealState ) ; Assert . assertFalse ( succeed ) ; HelixProperty property = accessor . getProperty ( keyBuilder . idealStates ( ""TestDB_1"" ) ) ; Assert . assertNull ( property ) ; idealState . getRecord ( ) . getSimpleFields ( ) . clear ( ) ; idealState . setStateModelDefId ( StateModelDefId . from ( ""MasterSlave"" ) ) ; idealState . setRebalanceMode ( RebalanceMode . SEMI_AUTO ) ; idealState . setNumPartitions ( 10 ) ; for ( int i = 0 ; i < 900 ; i ++ ) { idealState . getRecord ( ) . setSimpleField ( i + """" , bufStr ) ; } succeed = accessor . setProperty ( keyBuilder . idealStates ( ""TestDB_2"" ) , idealState ) ; Assert . assertTrue ( succeed ) ; record = accessor . getProperty ( keyBuilder . idealStates ( ""TestDB_2"" ) ) . getRecord ( ) ; Assert . assertTrue ( serializer . serialize ( record ) . length > 900 * 1024 ) ; idealState . getRecord ( ) . getSimpleFields ( ) . clear ( ) ; idealState . setStateModelDefId ( StateModelDefId . from ( ""MasterSlave"" ) ) ; idealState . setRebalanceMode ( RebalanceMode . SEMI_AUTO ) ; idealState . setNumPartitions ( 10 ) ; for ( int i = 900 ; i < 1024 ; i ++ ) { idealState . getRecord ( ) . setSimpleField ( i + """" , bufStr ) ; } succeed = accessor . updateProperty ( keyBuilder . idealStates ( ""TestDB_2"" ) , idealState ) ; Assert . assertFalse ( succeed ) ; recordNew = accessor . getProperty ( keyBuilder . idealStates ( ""TestDB_2"" ) ) . getRecord ( ) ; arr = serializer . serialize ( record ) ; arrNew = serializer . serialize ( recordNew ) ; Assert . assertTrue ( Arrays . equals ( arr , arrNew ) ) ; System . out . println ( ""END testZNRecordSizeLimitUseZNRecordStreamingSerializer at "" + new Date ( System . currentTimeMillis ( ) ) ) ; }",Smelly
 Ensembleable < T > withUnhandledErrorListener ( UnhandledErrorListener listener ) ;,No
" public static void main ( String [ ] args ) throws InterruptedException , ExecutionException { int port = Integer . parseInt ( args [ 0 ] ) ; HttpProxyExample proxy = new HttpProxyExample ( HBaseConfiguration . create ( ) , port ) ; proxy . start ( ) ; proxy . join ( ) ; }",No
" public void read ( org . apache . thrift . protocol . TProtocol prot , Partition struct ) throws org . apache . thrift . TException { TTupleProtocol iprot = ( TTupleProtocol ) prot ; BitSet incoming = iprot . readBitSet ( 8 ) ; if ( incoming . get ( 0 ) ) { { org . apache . thrift . protocol . TList _list219 = new org . apache . thrift . protocol . TList ( org . apache . thrift . protocol . TType . STRING , iprot . readI32 ( ) ) ; struct . values = new ArrayList < String > ( _list219 . size ) ; for ( int _i220 = 0 ; _i220 < _list219 . size ; ++ _i220 ) { String _elem221 ; _elem221 = iprot . readString ( ) ; struct . values . add ( _elem221 ) ; } } struct . setValuesIsSet ( true ) ; } if ( incoming . get ( 1 ) ) { struct . dbName = iprot . readString ( ) ; struct . setDbNameIsSet ( true ) ; } if ( incoming . get ( 2 ) ) { struct . tableName = iprot . readString ( ) ; struct . setTableNameIsSet ( true ) ; } if ( incoming . get ( 3 ) ) { struct . createTime = iprot . readI32 ( ) ; struct . setCreateTimeIsSet ( true ) ; } if ( incoming . get ( 4 ) ) { struct . lastAccessTime = iprot . readI32 ( ) ; struct . setLastAccessTimeIsSet ( true ) ; } if ( incoming . get ( 5 ) ) { struct . sd = new StorageDescriptor ( ) ; struct . sd . read ( iprot ) ; struct . setSdIsSet ( true ) ; } if ( incoming . get ( 6 ) ) { { org . apache . thrift . protocol . TMap _map222 = new org . apache . thrift . protocol . TMap ( org . apache . thrift . protocol . TType . STRING , org . apache . thrift . protocol . TType . STRING , iprot . readI32 ( ) ) ; struct . parameters = new HashMap < String , String > ( 2 * _map222 . size ) ; for ( int _i223 = 0 ; _i223 < _map222 . size ; ++ _i223 ) { String _key224 ; String _val225 ; _key224 = iprot . readString ( ) ; _val225 = iprot . readString ( ) ; struct . parameters . put ( _key224 , _val225 ) ; } } struct . setParametersIsSet ( true ) ; } if ( incoming . get ( 7 ) ) { struct . privileges = new PrincipalPrivilegeSet ( ) ; struct . privileges . read ( iprot ) ; struct . setPrivilegesIsSet ( true ) ; } }",Smelly
 private static < S extends org . apache . thrift . scheme . IScheme > S scheme ( org . apache . thrift . protocol . TProtocol proto ) { return ( org . apache . thrift . scheme . StandardScheme . class . equals ( proto . getScheme ( ) ) ? STANDARD_SCHEME_FACTORY : TUPLE_SCHEME_FACTORY ) . getScheme ( ) ; },Smelly
" public static void addAreas ( AbstractLayoutManager parentLM , PositionIterator parentIter , LayoutContext layoutContext ) { LayoutManager childLM ; LayoutContext lc = LayoutContext . offspringOf ( layoutContext ) ; LayoutManager firstLM = null ; LayoutManager lastLM = null ; Position firstPos = null ; Position lastPos = null ; if ( parentLM != null ) { parentLM . addId ( ) ; } LinkedList < Position > positionList = new LinkedList < Position > ( ) ; Position pos ; while ( parentIter . hasNext ( ) ) { pos = parentIter . next ( ) ; if ( pos == null ) { continue ; } if ( pos . getIndex ( ) >= 0 ) { if ( firstPos == null ) { firstPos = pos ; } lastPos = pos ; } if ( pos instanceof NonLeafPosition ) { positionList . add ( pos . getPosition ( ) ) ; lastLM = ( pos . getPosition ( ) . getLM ( ) ) ; if ( firstLM == null ) { firstLM = lastLM ; } } else if ( pos instanceof SpaceHandlingBreakPosition ) { positionList . add ( pos ) ; } else { } } if ( firstPos == null ) { return ; } if ( parentLM != null ) { parentLM . registerMarkers ( true , parentLM . isFirst ( firstPos ) , parentLM . isLast ( lastPos ) ) ; } PositionIterator childPosIter = new PositionIterator ( positionList . listIterator ( ) ) ; while ( ( childLM = childPosIter . getNextChildLM ( ) ) != null ) { lc . setFlags ( LayoutContext . FIRST_AREA , childLM == firstLM ) ; lc . setFlags ( LayoutContext . LAST_AREA , childLM == lastLM ) ; lc . setSpaceAdjust ( layoutContext . getSpaceAdjust ( ) ) ; lc . setSpaceBefore ( ( childLM == firstLM ? layoutContext . getSpaceBefore ( ) : 0 ) ) ; lc . setSpaceAfter ( layoutContext . getSpaceAfter ( ) ) ; lc . setStackLimitBP ( layoutContext . getStackLimitBP ( ) ) ; childLM . addAreas ( childPosIter , lc ) ; } if ( parentLM != null ) { parentLM . registerMarkers ( false , parentLM . isFirst ( firstPos ) , parentLM . isLast ( lastPos ) ) ; } }",Smelly
 public String next ( ) { return iter . next ( ) ; },No
" public void read ( org . apache . thrift . protocol . TProtocol prot , Message struct ) throws org . apache . thrift . TException { TTupleProtocol iprot = ( TTupleProtocol ) prot ; struct . event = iprot . readBinary ( ) ; struct . setEventIsSet ( true ) ; struct . messageId = iprot . readString ( ) ; struct . setMessageIdIsSet ( true ) ; struct . messageType = org . apache . airavata . model . messaging . event . MessageType . findByValue ( iprot . readI32 ( ) ) ; struct . setMessageTypeIsSet ( true ) ; BitSet incoming = iprot . readBitSet ( 2 ) ; if ( incoming . get ( 0 ) ) { struct . updatedTime = iprot . readI64 ( ) ; struct . setUpdatedTimeIsSet ( true ) ; } if ( incoming . get ( 1 ) ) { struct . messageLevel = org . apache . airavata . model . messaging . event . MessageLevel . findByValue ( iprot . readI32 ( ) ) ; struct . setMessageLevelIsSet ( true ) ; } }",No
" public void read ( org . apache . thrift . protocol . TProtocol prot , getFollowing_result struct ) throws org . apache . thrift . TException { TTupleProtocol iprot = ( TTupleProtocol ) prot ; BitSet incoming = iprot . readBitSet ( 1 ) ; if ( incoming . get ( 0 ) ) { struct . success = new Key ( ) ; struct . success . read ( iprot ) ; struct . setSuccessIsSet ( true ) ; } }",Smelly
" public void read ( org . apache . thrift . protocol . TProtocol prot , PartitionsByExprRequest struct ) throws org . apache . thrift . TException { TTupleProtocol iprot = ( TTupleProtocol ) prot ; struct . dbName = iprot . readString ( ) ; struct . setDbNameIsSet ( true ) ; struct . tblName = iprot . readString ( ) ; struct . setTblNameIsSet ( true ) ; struct . expr = iprot . readBinary ( ) ; struct . setExprIsSet ( true ) ; BitSet incoming = iprot . readBitSet ( 2 ) ; if ( incoming . get ( 0 ) ) { struct . defaultPartitionName = iprot . readString ( ) ; struct . setDefaultPartitionNameIsSet ( true ) ; } if ( incoming . get ( 1 ) ) { struct . maxParts = iprot . readI16 ( ) ; struct . setMaxPartsIsSet ( true ) ; } }",Smelly
" public void readFields ( DataInput dataInput ) throws IOException { extendedDataOutput = WritableUtils . readExtendedDataOutput ( dataInput , getConf ( ) ) ; }",No
 public void run ( ) { for ( int i = 0 ; i < count ; i ++ ) { test . run ( ) ; } },No
 public abstract void addKid ( PDFObject kid ) ;,No
" public void read ( org . apache . thrift . protocol . TProtocol prot , TGetDelegationTokenReq struct ) throws org . apache . thrift . TException { TTupleProtocol iprot = ( TTupleProtocol ) prot ; struct . sessionHandle = new TSessionHandle ( ) ; struct . sessionHandle . read ( iprot ) ; struct . setSessionHandleIsSet ( true ) ; struct . owner = iprot . readString ( ) ; struct . setOwnerIsSet ( true ) ; struct . renewer = iprot . readString ( ) ; struct . setRenewerIsSet ( true ) ; }",Smelly
 public String getJavaType ( String pathType ) { return pathType ; },No
" public void testVertexStateConversion ( ) { for ( VertexState state : VertexState . values ( ) ) { DAGProtos . VertexStatusStateProto stateProto = VertexStatusBuilder . getProtoState ( state ) ; VertexStatus . State clientState = VertexStatus . getState ( stateProto ) ; Assert . assertEquals ( state . name ( ) , clientState . name ( ) ) ; } }",No
" public Query makeLuceneQueryFieldNoBoost ( String fieldName , BasicQueryFactory qf ) { List luceneSubQueries = makeLuceneSubQueriesField ( fieldName , qf ) ; BooleanQuery bq = new BooleanQuery ( ) ; bq . add ( ( Query ) luceneSubQueries . get ( 0 ) , BooleanClause . Occur . MUST ) ; SrndBooleanQuery . addQueriesToBoolean ( bq , luceneSubQueries . subList ( 1 , luceneSubQueries . size ( ) ) , BooleanClause . Occur . MUST_NOT ) ; return bq ; }",No
" public void read ( org . apache . thrift . protocol . TProtocol prot , Complex struct ) throws org . apache . thrift . TException { TTupleProtocol iprot = ( TTupleProtocol ) prot ; BitSet incoming = iprot . readBitSet ( 6 ) ; if ( incoming . get ( 0 ) ) { struct . aint = iprot . readI32 ( ) ; struct . setAintIsSet ( true ) ; } if ( incoming . get ( 1 ) ) { struct . aString = iprot . readString ( ) ; struct . setAStringIsSet ( true ) ; } if ( incoming . get ( 2 ) ) { { org . apache . thrift . protocol . TList _list21 = new org . apache . thrift . protocol . TList ( org . apache . thrift . protocol . TType . I32 , iprot . readI32 ( ) ) ; struct . lint = new ArrayList < Integer > ( _list21 . size ) ; for ( int _i22 = 0 ; _i22 < _list21 . size ; ++ _i22 ) { int _elem23 ; _elem23 = iprot . readI32 ( ) ; struct . lint . add ( _elem23 ) ; } } struct . setLintIsSet ( true ) ; } if ( incoming . get ( 3 ) ) { { org . apache . thrift . protocol . TList _list24 = new org . apache . thrift . protocol . TList ( org . apache . thrift . protocol . TType . STRING , iprot . readI32 ( ) ) ; struct . lString = new ArrayList < String > ( _list24 . size ) ; for ( int _i25 = 0 ; _i25 < _list24 . size ; ++ _i25 ) { String _elem26 ; _elem26 = iprot . readString ( ) ; struct . lString . add ( _elem26 ) ; } } struct . setLStringIsSet ( true ) ; } if ( incoming . get ( 4 ) ) { { org . apache . thrift . protocol . TList _list27 = new org . apache . thrift . protocol . TList ( org . apache . thrift . protocol . TType . STRUCT , iprot . readI32 ( ) ) ; struct . lintString = new ArrayList < IntString > ( _list27 . size ) ; for ( int _i28 = 0 ; _i28 < _list27 . size ; ++ _i28 ) { IntString _elem29 ; _elem29 = new IntString ( ) ; _elem29 . read ( iprot ) ; struct . lintString . add ( _elem29 ) ; } } struct . setLintStringIsSet ( true ) ; } if ( incoming . get ( 5 ) ) { { org . apache . thrift . protocol . TMap _map30 = new org . apache . thrift . protocol . TMap ( org . apache . thrift . protocol . TType . STRING , org . apache . thrift . protocol . TType . STRING , iprot . readI32 ( ) ) ; struct . mStringString = new HashMap < String , String > ( 2 * _map30 . size ) ; for ( int _i31 = 0 ; _i31 < _map30 . size ; ++ _i31 ) { String _key32 ; String _val33 ; _key32 = iprot . readString ( ) ; _val33 = iprot . readString ( ) ; struct . mStringString . put ( _key32 , _val33 ) ; } } struct . setMStringStringIsSet ( true ) ; } }",Smelly
 protected Class getExceptionClass ( ) { return ExpiredCredentialsException . class ; },No
 public Scope getNodeScope ( ) { return nodeScope ; },No
" public void read ( org . apache . thrift . protocol . TProtocol prot , GcCycleStats struct ) throws org . apache . thrift . TException { TTupleProtocol iprot = ( TTupleProtocol ) prot ; BitSet incoming = iprot . readBitSet ( 6 ) ; if ( incoming . get ( 0 ) ) { struct . started = iprot . readI64 ( ) ; struct . setStartedIsSet ( true ) ; } if ( incoming . get ( 1 ) ) { struct . finished = iprot . readI64 ( ) ; struct . setFinishedIsSet ( true ) ; } if ( incoming . get ( 2 ) ) { struct . candidates = iprot . readI64 ( ) ; struct . setCandidatesIsSet ( true ) ; } if ( incoming . get ( 3 ) ) { struct . inUse = iprot . readI64 ( ) ; struct . setInUseIsSet ( true ) ; } if ( incoming . get ( 4 ) ) { struct . deleted = iprot . readI64 ( ) ; struct . setDeletedIsSet ( true ) ; } if ( incoming . get ( 5 ) ) { struct . errors = iprot . readI64 ( ) ; struct . setErrorsIsSet ( true ) ; } }",Smelly
" public void init ( final FilterConfig filterConfig ) { if ( filterConfig . getInitParameter ( INTERNAL_PROXIES_PARAMETER ) != null ) { config . setAllowedInternalProxies ( filterConfig . getInitParameter ( INTERNAL_PROXIES_PARAMETER ) ) ; } if ( filterConfig . getInitParameter ( PROTOCOL_HEADER_PARAMETER ) != null ) { config . setProtocolHeader ( filterConfig . getInitParameter ( PROTOCOL_HEADER_PARAMETER ) ) ; } if ( filterConfig . getInitParameter ( PROTOCOL_HEADER_SSL_VALUE_PARAMETER ) != null ) { config . setProtocolHeaderSslValue ( filterConfig . getInitParameter ( PROTOCOL_HEADER_SSL_VALUE_PARAMETER ) ) ; } if ( filterConfig . getInitParameter ( PROXIES_HEADER_PARAMETER ) != null ) { config . setProxiesHeader ( filterConfig . getInitParameter ( PROXIES_HEADER_PARAMETER ) ) ; } if ( filterConfig . getInitParameter ( REMOTE_IP_HEADER_PARAMETER ) != null ) { config . setRemoteIPHeader ( filterConfig . getInitParameter ( REMOTE_IP_HEADER_PARAMETER ) ) ; } if ( filterConfig . getInitParameter ( TRUSTED_PROXIES_PARAMETER ) != null ) { config . setTrustedProxies ( filterConfig . getInitParameter ( TRUSTED_PROXIES_PARAMETER ) ) ; } if ( filterConfig . getInitParameter ( HTTP_SERVER_PORT_PARAMETER ) != null ) { try { config . setHttpServerPort ( Integer . parseInt ( filterConfig . getInitParameter ( HTTP_SERVER_PORT_PARAMETER ) ) ) ; } catch ( NumberFormatException e ) { throw new NumberFormatException ( ""Illegal "" + HTTP_SERVER_PORT_PARAMETER + "" : "" + e . getMessage ( ) ) ; } } if ( filterConfig . getInitParameter ( HTTPS_SERVER_PORT_PARAMETER ) != null ) { try { config . setHttpsServerPort ( Integer . parseInt ( filterConfig . getInitParameter ( HTTPS_SERVER_PORT_PARAMETER ) ) ) ; } catch ( NumberFormatException e ) { throw new NumberFormatException ( ""Illegal "" + HTTPS_SERVER_PORT_PARAMETER + "" : "" + e . getMessage ( ) ) ; } } }",No
" public void read ( org . apache . thrift . protocol . TProtocol prot , Gateway struct ) throws org . apache . thrift . TException { TTupleProtocol iprot = ( TTupleProtocol ) prot ; struct . gatewayId = iprot . readString ( ) ; struct . setGatewayIdIsSet ( true ) ; struct . gatewayApprovalStatus = org . apache . airavata . model . workspace . GatewayApprovalStatus . findByValue ( iprot . readI32 ( ) ) ; struct . setGatewayApprovalStatusIsSet ( true ) ; BitSet incoming = iprot . readBitSet ( 12 ) ; if ( incoming . get ( 0 ) ) { struct . gatewayName = iprot . readString ( ) ; struct . setGatewayNameIsSet ( true ) ; } if ( incoming . get ( 1 ) ) { struct . domain = iprot . readString ( ) ; struct . setDomainIsSet ( true ) ; } if ( incoming . get ( 2 ) ) { struct . emailAddress = iprot . readString ( ) ; struct . setEmailAddressIsSet ( true ) ; } if ( incoming . get ( 3 ) ) { struct . gatewayAcronym = iprot . readString ( ) ; struct . setGatewayAcronymIsSet ( true ) ; } if ( incoming . get ( 4 ) ) { struct . gatewayURL = iprot . readString ( ) ; struct . setGatewayURLIsSet ( true ) ; } if ( incoming . get ( 5 ) ) { struct . gatewayPublicAbstract = iprot . readString ( ) ; struct . setGatewayPublicAbstractIsSet ( true ) ; } if ( incoming . get ( 6 ) ) { struct . reviewProposalDescription = iprot . readString ( ) ; struct . setReviewProposalDescriptionIsSet ( true ) ; } if ( incoming . get ( 7 ) ) { struct . gatewayAdminFirstName = iprot . readString ( ) ; struct . setGatewayAdminFirstNameIsSet ( true ) ; } if ( incoming . get ( 8 ) ) { struct . gatewayAdminLastName = iprot . readString ( ) ; struct . setGatewayAdminLastNameIsSet ( true ) ; } if ( incoming . get ( 9 ) ) { struct . gatewayAdminEmail = iprot . readString ( ) ; struct . setGatewayAdminEmailIsSet ( true ) ; } if ( incoming . get ( 10 ) ) { struct . identityServerUserName = iprot . readString ( ) ; struct . setIdentityServerUserNameIsSet ( true ) ; } if ( incoming . get ( 11 ) ) { struct . identityServerPasswordToken = iprot . readString ( ) ; struct . setIdentityServerPasswordTokenIsSet ( true ) ; } }",Smelly
" public Object invoke ( Object proxy , Method method , Object [ ] args ) throws Throwable { if ( method . getName ( ) . equals ( ""hashCode"" ) ) { return FakeBundleRevision . this . hashCode ( ) ; } else if ( method . getName ( ) . equals ( ""equals"" ) ) { return proxy == args [ 0 ] ; } else if ( method . getName ( ) . equals ( ""toString"" ) ) { return bundle . getSymbolicName ( ) + ""/"" + bundle . getVersion ( ) ; } else if ( method . getName ( ) . equals ( ""adapt"" ) ) { if ( args . length == 1 && args [ 0 ] == BundleRevision . class ) { return FakeBundleRevision . this ; } else if ( args . length == 1 && args [ 0 ] == BundleStartLevel . class ) { return FakeBundleRevision . this ; } } else if ( method . getName ( ) . equals ( ""getHeaders"" ) ) { return headers ; } else if ( method . getName ( ) . equals ( ""getBundleId"" ) ) { return bundleId ; } else if ( method . getName ( ) . equals ( ""getLocation"" ) ) { return location ; } else if ( method . getName ( ) . equals ( ""getSymbolicName"" ) ) { String name = headers . get ( Constants . BUNDLE_SYMBOLICNAME ) ; int idx = name . indexOf ( ';' ) ; if ( idx > 0 ) { name = name . substring ( 0 , idx ) . trim ( ) ; } return name ; } else if ( method . getName ( ) . equals ( ""getVersion"" ) ) { return new Version ( headers . get ( Constants . BUNDLE_VERSION ) ) ; } else if ( method . getName ( ) . equals ( ""getState"" ) ) { return Bundle . ACTIVE ; } else if ( method . getName ( ) . equals ( ""getLastModified"" ) ) { return 0l ; } return null ; }",Smelly
 void log ( AuditLogEntry entry ) ;,No
" public void read ( org . apache . thrift . protocol . TProtocol prot , getChildDataProducts_result struct ) throws org . apache . thrift . TException { TTupleProtocol iprot = ( TTupleProtocol ) prot ; BitSet incoming = iprot . readBitSet ( 5 ) ; if ( incoming . get ( 0 ) ) { { org . apache . thrift . protocol . TList _list283 = new org . apache . thrift . protocol . TList ( org . apache . thrift . protocol . TType . STRUCT , iprot . readI32 ( ) ) ; struct . success = new ArrayList < org . apache . airavata . model . data . replica . DataProductModel > ( _list283 . size ) ; org . apache . airavata . model . data . replica . DataProductModel _elem284 ; for ( int _i285 = 0 ; _i285 < _list283 . size ; ++ _i285 ) { _elem284 = new org . apache . airavata . model . data . replica . DataProductModel ( ) ; _elem284 . read ( iprot ) ; struct . success . add ( _elem284 ) ; } } struct . setSuccessIsSet ( true ) ; } if ( incoming . get ( 1 ) ) { struct . ire = new org . apache . airavata . model . error . InvalidRequestException ( ) ; struct . ire . read ( iprot ) ; struct . setIreIsSet ( true ) ; } if ( incoming . get ( 2 ) ) { struct . ace = new org . apache . airavata . model . error . AiravataClientException ( ) ; struct . ace . read ( iprot ) ; struct . setAceIsSet ( true ) ; } if ( incoming . get ( 3 ) ) { struct . ase = new org . apache . airavata . model . error . AiravataSystemException ( ) ; struct . ase . read ( iprot ) ; struct . setAseIsSet ( true ) ; } if ( incoming . get ( 4 ) ) { struct . ae = new org . apache . airavata . model . error . AuthorizationException ( ) ; struct . ae . read ( iprot ) ; struct . setAeIsSet ( true ) ; } }",Smelly
" public String guid ( ) { return ""123"" ; }",No
 public AjaxRequestAttributes setSerializeRecursively ( final boolean serializeRecursively ) { this . serializeRecursively = serializeRecursively ; return this ; },No
 private static < S extends org . apache . thrift . scheme . IScheme > S scheme ( org . apache . thrift . protocol . TProtocol proto ) { return ( org . apache . thrift . scheme . StandardScheme . class . equals ( proto . getScheme ( ) ) ? STANDARD_SCHEME_FACTORY : TUPLE_SCHEME_FACTORY ) . getScheme ( ) ; },Smelly
" public static void main ( String [ ] args ) throws SocketException , IOException { if ( args . length != 2 && args . length != 3 && args . length != 5 ) { System . out . println ( ""Usage: MessageThreading <hostname> <groupname> [<article specifier> [<user> <password>]]"" ) ; return ; } String hostname = args [ 0 ] ; String newsgroup = args [ 1 ] ; String articleSpec = args . length >= 3 ? args [ 2 ] : null ; NNTPClient client = new NNTPClient ( ) ; client . addProtocolCommandListener ( new PrintCommandListener ( new PrintWriter ( System . out ) , true ) ) ; client . connect ( hostname ) ; if ( args . length == 5 ) { String user = args [ 3 ] ; String password = args [ 4 ] ; if ( ! client . authenticate ( user , password ) ) { System . out . println ( ""Authentication failed for user "" + user + ""!"" ) ; System . exit ( 1 ) ; } } NewsgroupInfo group = new NewsgroupInfo ( ) ; client . selectNewsgroup ( newsgroup , group ) ; BufferedReader br ; String line ; if ( articleSpec != null ) { br = ( BufferedReader ) client . retrieveArticleHeader ( articleSpec ) ; } else { long articleNum = group . getLastArticleLong ( ) ; br = client . retrieveArticleHeader ( articleNum ) ; } if ( br != null ) { while ( ( line = br . readLine ( ) ) != null ) { System . out . println ( line ) ; } br . close ( ) ; } if ( articleSpec != null ) { br = ( BufferedReader ) client . retrieveArticleBody ( articleSpec ) ; } else { long articleNum = group . getLastArticleLong ( ) ; br = client . retrieveArticleBody ( articleNum ) ; } if ( br != null ) { while ( ( line = br . readLine ( ) ) != null ) { System . out . println ( line ) ; } br . close ( ) ; } }",Smelly
" public void read ( org . apache . thrift . protocol . TProtocol prot , getFollowing_result struct ) throws org . apache . thrift . TException { TTupleProtocol iprot = ( TTupleProtocol ) prot ; BitSet incoming = iprot . readBitSet ( 1 ) ; if ( incoming . get ( 0 ) ) { struct . success = new Key ( ) ; struct . success . read ( iprot ) ; struct . setSuccessIsSet ( true ) ; } }",Smelly
" public void interpret ( String token , String value ) throws InterpretException { int dotPosition = token . indexOf ( DOT ) ; if ( dotPosition == - 1 ) { throw new InterpretException ( gatewayResources . unsupportedPropertyTokenError ( token ) ) ; } String providerRole = token . substring ( 0 , dotPosition ) ; if ( providerRole != null && providerRole . isEmpty ( ) ) { providerRole = null ; } String nextToken = token . substring ( dotPosition + 1 ) ; dotPosition = nextToken . indexOf ( DOT ) ; if ( dotPosition == - 1 ) { throw new InterpretException ( gatewayResources . unsupportedPropertyTokenError ( token ) ) ; } String providerName = nextToken . substring ( 0 , dotPosition ) ; if ( providerName != null && providerName . isEmpty ( ) ) { providerName = null ; } nextToken = nextToken . substring ( dotPosition + 1 ) ; Provider provider = topology . getProvider ( providerRole , providerName ) ; if ( provider == null ) { provider = new Provider ( ) ; provider . setName ( providerName ) ; provider . setRole ( providerRole ) ; topology . addProvider ( provider ) ; } if ( PROVIDER_ENABLED . equalsIgnoreCase ( nextToken ) ) { provider . setEnabled ( Boolean . valueOf ( value ) ) ; } else { dotPosition = nextToken . indexOf ( DOT ) ; if ( dotPosition != - 1 ) { String aggregator = nextToken . substring ( 0 , dotPosition ) ; nextToken = nextToken . substring ( dotPosition + 1 ) ; if ( AGGREGATOR_PARAM . equalsIgnoreCase ( aggregator ) ) { new ProviderParameterPropertyInterpreter ( provider ) . interpret ( nextToken , value ) ; } else { throw new InterpretException ( gatewayResources . unsupportedPropertyTokenError ( token ) ) ; } } else { throw new InterpretException ( gatewayResources . unsupportedPropertyTokenError ( token ) ) ; } } }",Smelly
" public void testPatchBuilderWithJsonArrayInitialData ( ) { JsonArrayBuilder arrayBuilder = Json . createArrayBuilder ( ) ; arrayBuilder . add ( Json . createObjectBuilder ( ) . add ( ""op"" , JsonPatch . Operation . ADD . operationName ( ) ) . add ( ""path"" , ""/add/an/object"" ) . add ( ""value"" , ""someValue"" ) . build ( ) ) ; arrayBuilder . add ( Json . createObjectBuilder ( ) . add ( ""op"" , JsonPatch . Operation . TEST . operationName ( ) ) . add ( ""path"" , ""/test/someObject"" ) . add ( ""value"" , ""someValue"" ) . build ( ) ) ; JsonArray initialPatchData = arrayBuilder . build ( ) ; JsonPatchBuilder jsonPatchBuilder = Json . createPatchBuilder ( initialPatchData ) ; jsonPatchBuilder . move ( ""/move/me/to"" , ""/move/me/from"" ) ; JsonPatch jsonPatch = jsonPatchBuilder . build ( ) ; Assert . assertNotNull ( jsonPatch ) ; }",No
 void afterParsed ( Class < ? > clazz ) ;,No
" private ColumnPageDecoder createDecoderLegacy ( ValueEncoderMeta metadata , String compressor , boolean fullVectorFill ) { if ( null == metadata ) { throw new RuntimeException ( ""internal error"" ) ; } SimpleStatsResult stats = PrimitivePageStatsCollector . newInstance ( metadata ) ; TableSpec . ColumnSpec spec = TableSpec . ColumnSpec . newInstanceLegacy ( ""legacy"" , stats . getDataType ( ) , ColumnType . MEASURE ) ; DataType dataType = DataType . getDataType ( metadata . getType ( ) ) ; if ( dataType == DataTypes . BYTE || dataType == DataTypes . SHORT || dataType == DataTypes . INT || dataType == DataTypes . LONG ) { ColumnPageCodec codec = DefaultEncodingFactory . selectCodecByAlgorithmForIntegral ( stats , false , spec ) ; if ( codec instanceof AdaptiveIntegralCodec ) { AdaptiveIntegralCodec adaptiveCodec = ( AdaptiveIntegralCodec ) codec ; ColumnPageEncoderMeta meta = new ColumnPageEncoderMeta ( spec , adaptiveCodec . getTargetDataType ( ) , stats , compressor ) ; meta . setFillCompleteVector ( fullVectorFill ) ; return codec . createDecoder ( meta ) ; } else if ( codec instanceof AdaptiveDeltaIntegralCodec ) { AdaptiveDeltaIntegralCodec adaptiveCodec = ( AdaptiveDeltaIntegralCodec ) codec ; ColumnPageEncoderMeta meta = new ColumnPageEncoderMeta ( spec , adaptiveCodec . getTargetDataType ( ) , stats , compressor ) ; meta . setFillCompleteVector ( fullVectorFill ) ; return codec . createDecoder ( meta ) ; } else if ( codec instanceof DirectCompressCodec ) { ColumnPageEncoderMeta meta = new ColumnPageEncoderMeta ( spec , DataType . getDataType ( metadata . getType ( ) ) , stats , compressor ) ; meta . setFillCompleteVector ( fullVectorFill ) ; return codec . createDecoder ( meta ) ; } else { throw new RuntimeException ( ""internal error"" ) ; } } else if ( dataType == DataTypes . FLOAT || dataType == DataTypes . DOUBLE ) { ColumnPageCodec codec = DefaultEncodingFactory . selectCodecByAlgorithmForFloating ( stats , false , spec ) ; if ( codec instanceof AdaptiveFloatingCodec ) { AdaptiveFloatingCodec adaptiveCodec = ( AdaptiveFloatingCodec ) codec ; ColumnPageEncoderMeta meta = new ColumnPageEncoderMeta ( spec , adaptiveCodec . getTargetDataType ( ) , stats , compressor ) ; meta . setFillCompleteVector ( fullVectorFill ) ; return codec . createDecoder ( meta ) ; } else if ( codec instanceof DirectCompressCodec ) { ColumnPageEncoderMeta meta = new ColumnPageEncoderMeta ( spec , DataType . getDataType ( metadata . getType ( ) ) , stats , compressor ) ; meta . setFillCompleteVector ( fullVectorFill ) ; return codec . createDecoder ( meta ) ; } else if ( codec instanceof AdaptiveDeltaFloatingCodec ) { AdaptiveDeltaFloatingCodec adaptiveCodec = ( AdaptiveDeltaFloatingCodec ) codec ; ColumnPageEncoderMeta meta = new ColumnPageEncoderMeta ( spec , adaptiveCodec . getTargetDataType ( ) , stats , compressor ) ; meta . setFillCompleteVector ( fullVectorFill ) ; return codec . createDecoder ( meta ) ; } else { throw new RuntimeException ( ""internal error"" ) ; } } else if ( DataTypes . isDecimal ( dataType ) || dataType == DataTypes . BYTE_ARRAY ) { ColumnPageEncoderMeta meta = new ColumnPageEncoderMeta ( spec , stats . getDataType ( ) , stats , compressor ) ; meta . setFillCompleteVector ( fullVectorFill ) ; return new DirectCompressCodec ( stats . getDataType ( ) ) . createDecoder ( meta ) ; } else { throw new RuntimeException ( ""unsupported data type: "" + stats . getDataType ( ) ) ; } }",Smelly
 private static < S extends org . apache . thrift . scheme . IScheme > S scheme ( org . apache . thrift . protocol . TProtocol proto ) { return ( org . apache . thrift . scheme . StandardScheme . class . equals ( proto . getScheme ( ) ) ? STANDARD_SCHEME_FACTORY : TUPLE_SCHEME_FACTORY ) . getScheme ( ) ; },Smelly
" public void read ( org . apache . thrift . protocol . TProtocol prot , show_compact_result struct ) throws org . apache . thrift . TException { TTupleProtocol iprot = ( TTupleProtocol ) prot ; BitSet incoming = iprot . readBitSet ( 1 ) ; if ( incoming . get ( 0 ) ) { struct . success = new ShowCompactResponse ( ) ; struct . success . read ( iprot ) ; struct . setSuccessIsSet ( true ) ; } }",Smelly
 public static String generateUniqueId ( ) { return UUID . randomUUID ( ) . toString ( ) ; },No
" public void runAction ( Map < String , Object > context ) { ModelForm parentModel = modelForm . getParentModelForm ( ) ; switch ( kind ) { case ACTIONS : parentModel . runFormActions ( context ) ; break ; case ROW_ACTIONS : ModelFormAction . runSubActions ( parentModel . rowActions , context ) ; break ; } }",Smelly
 public void assertMessagesDividedAmongConsumers ( ) { assertEachConsumerReceivedAtLeastXMessages ( ( messageCount * producerCount ) / consumerCount ) ; assertEachConsumerReceivedAtMostXMessages ( ( ( messageCount * producerCount ) / consumerCount ) + 1 ) ; },No
" public static < T > T get ( ByteBuf pBody , Parser < T > parser ) throws RpcException { try { ByteBufInputStream is = new ByteBufInputStream ( pBody ) ; return parser . parseFrom ( is ) ; } catch ( InvalidProtocolBufferException e ) { throw new RpcException ( String . format ( ""Failure while decoding message with parser of type. %s"" , parser . getClass ( ) . getCanonicalName ( ) ) , e ) ; } }",Smelly
 private static < S extends org . apache . thrift . scheme . IScheme > S scheme ( org . apache . thrift . protocol . TProtocol proto ) { return ( org . apache . thrift . scheme . StandardScheme . class . equals ( proto . getScheme ( ) ) ? STANDARD_SCHEME_FACTORY : TUPLE_SCHEME_FACTORY ) . getScheme ( ) ; },Smelly
" public void run ( ) { MultiScanSession session = ( MultiScanSession ) server . getSession ( scanID ) ; String oldThreadName = Thread . currentThread ( ) . getName ( ) ; try { if ( isCancelled ( ) || session == null ) return ; TableConfiguration acuTableConf = server . getTableConfiguration ( session . threadPoolExtent ) ; long maxResultsSize = acuTableConf . getMemoryInBytes ( Property . TABLE_SCAN_MAXMEM ) ; runState . set ( ScanRunState . RUNNING ) ; Thread . currentThread ( ) . setName ( ""Client: "" + session . client + "" User: "" + session . getUser ( ) + "" Start: "" + session . startTime + "" Table: "" ) ; long bytesAdded = 0 ; long maxScanTime = 4000 ; long startTime = System . currentTimeMillis ( ) ; List < KVEntry > results = new ArrayList < > ( ) ; Map < KeyExtent , List < Range > > failures = new HashMap < > ( ) ; List < KeyExtent > fullScans = new ArrayList < > ( ) ; KeyExtent partScan = null ; Key partNextKey = null ; boolean partNextKeyInclusive = false ; Iterator < Entry < KeyExtent , List < Range > > > iter = session . queries . entrySet ( ) . iterator ( ) ; while ( iter . hasNext ( ) && bytesAdded < maxResultsSize && ( System . currentTimeMillis ( ) - startTime ) < maxScanTime ) { Entry < KeyExtent , List < Range > > entry = iter . next ( ) ; iter . remove ( ) ; Tablet tablet = server . getOnlineTablet ( entry . getKey ( ) ) ; if ( tablet == null ) { failures . put ( entry . getKey ( ) , entry . getValue ( ) ) ; continue ; } Thread . currentThread ( ) . setName ( ""Client: "" + session . client + "" User: "" + session . getUser ( ) + "" Start: "" + session . startTime + "" Tablet: "" + entry . getKey ( ) . toString ( ) ) ; LookupResult lookupResult ; try { if ( isCancelled ( ) ) interruptFlag . set ( true ) ; lookupResult = tablet . lookup ( entry . getValue ( ) , session . columnSet , session . auths , results , maxResultsSize - bytesAdded , session . ssiList , session . ssio , interruptFlag ) ; interruptFlag . set ( false ) ; } catch ( IOException e ) { log . warn ( ""lookup failed for tablet "" + entry . getKey ( ) , e ) ; throw new RuntimeException ( e ) ; } bytesAdded += lookupResult . bytesAdded ; if ( lookupResult . unfinishedRanges . size ( ) > 0 ) { if ( lookupResult . closed ) { failures . put ( entry . getKey ( ) , lookupResult . unfinishedRanges ) ; } else { session . queries . put ( entry . getKey ( ) , lookupResult . unfinishedRanges ) ; partScan = entry . getKey ( ) ; partNextKey = lookupResult . unfinishedRanges . get ( 0 ) . getStartKey ( ) ; partNextKeyInclusive = lookupResult . unfinishedRanges . get ( 0 ) . isStartKeyInclusive ( ) ; } } else { fullScans . add ( entry . getKey ( ) ) ; } } long finishTime = System . currentTimeMillis ( ) ; session . totalLookupTime += ( finishTime - startTime ) ; session . numEntries += results . size ( ) ; List < TKeyValue > retResults = new ArrayList < > ( ) ; for ( KVEntry entry : results ) retResults . add ( new TKeyValue ( entry . getKey ( ) . toThrift ( ) , ByteBuffer . wrap ( entry . getValue ( ) . get ( ) ) ) ) ; Map < TKeyExtent , List < TRange > > retFailures = Translator . translate ( failures , Translators . KET , new Translator . ListTranslator < > ( Translators . RT ) ) ; List < TKeyExtent > retFullScans = Translator . translate ( fullScans , Translators . KET ) ; TKeyExtent retPartScan = null ; TKey retPartNextKey = null ; if ( partScan != null ) { retPartScan = partScan . toThrift ( ) ; retPartNextKey = partNextKey . toThrift ( ) ; } addResult ( new MultiScanResult ( retResults , retFailures , retFullScans , retPartScan , retPartNextKey , partNextKeyInclusive , session . queries . size ( ) != 0 ) ) ; } catch ( IterationInterruptedException iie ) { if ( ! isCancelled ( ) ) { log . warn ( ""Iteration interrupted, when scan not cancelled"" , iie ) ; addResult ( iie ) ; } } catch ( Throwable e ) { log . warn ( ""exception while doing multi-scan "" , e ) ; addResult ( e ) ; } finally { Thread . currentThread ( ) . setName ( oldThreadName ) ; runState . set ( ScanRunState . FINISHED ) ; } }",Smelly
" public void execute ( ) throws MojoExecutionException { try { if ( protocCommand == null || protocCommand . trim ( ) . isEmpty ( ) ) { protocCommand = ""protoc"" ; } List < String > command = new ArrayList < String > ( ) ; command . add ( protocCommand ) ; command . add ( ""--version"" ) ; Exec exec = new Exec ( this ) ; List < String > out = new ArrayList < String > ( ) ; if ( exec . run ( command , out ) == 127 ) { getLog ( ) . error ( ""protoc, not found at: "" + protocCommand ) ; throw new MojoExecutionException ( ""protoc failure"" ) ; } else { if ( out . isEmpty ( ) ) { getLog ( ) . error ( ""stdout: "" + out ) ; throw new MojoExecutionException ( ""'protoc --version' did not return a version"" ) ; } else { if ( ! out . get ( 0 ) . endsWith ( protocVersion ) ) { throw new MojoExecutionException ( ""protoc version is '"" + out . get ( 0 ) + ""', expected version is '"" + protocVersion + ""'"" ) ; } } } if ( ! output . mkdirs ( ) ) { if ( ! output . exists ( ) ) { throw new MojoExecutionException ( ""Could not create directory: "" + output ) ; } } command = new ArrayList < String > ( ) ; command . add ( protocCommand ) ; command . add ( ""--java_out="" + output . getCanonicalPath ( ) ) ; if ( imports != null ) { for ( File i : imports ) { command . add ( ""-I"" + i . getCanonicalPath ( ) ) ; } } for ( File f : FileSetUtils . convertFileSetToFiles ( source ) ) { command . add ( f . getCanonicalPath ( ) ) ; } exec = new Exec ( this ) ; out = new ArrayList < String > ( ) ; if ( exec . run ( command , out ) != 0 ) { getLog ( ) . error ( ""protoc compiler error"" ) ; for ( String s : out ) { getLog ( ) . error ( s ) ; } throw new MojoExecutionException ( ""protoc failure"" ) ; } } catch ( Throwable ex ) { throw new MojoExecutionException ( ex . toString ( ) , ex ) ; } project . addCompileSourceRoot ( output . getAbsolutePath ( ) ) ; }",Smelly
" public Map < String , Object > run ( Map < String , Object > args , String crawlId ) throws Exception { Map < String , Object > results = new HashMap < > ( ) ; Path linkdb ; if ( args . containsKey ( Nutch . ARG_LINKDB ) ) { Object path = args . get ( Nutch . ARG_LINKDB ) ; if ( path instanceof Path ) { linkdb = ( Path ) path ; } else { linkdb = new Path ( path . toString ( ) ) ; } } else { linkdb = new Path ( crawlId + ""/linkdb"" ) ; } ArrayList < Path > segs = new ArrayList < > ( ) ; boolean filter = true ; boolean normalize = true ; boolean force = false ; if ( args . containsKey ( ""noNormalize"" ) ) { normalize = false ; } if ( args . containsKey ( ""noFilter"" ) ) { filter = false ; } if ( args . containsKey ( ""force"" ) ) { force = true ; } Path segmentsDir ; if ( args . containsKey ( Nutch . ARG_SEGMENTDIR ) ) { Object segDir = args . get ( Nutch . ARG_SEGMENTDIR ) ; if ( segDir instanceof Path ) { segmentsDir = ( Path ) segDir ; } else { segmentsDir = new Path ( segDir . toString ( ) ) ; } FileSystem fs = segmentsDir . getFileSystem ( getConf ( ) ) ; FileStatus [ ] paths = fs . listStatus ( segmentsDir , HadoopFSUtil . getPassDirectoriesFilter ( fs ) ) ; segs . addAll ( Arrays . asList ( HadoopFSUtil . getPaths ( paths ) ) ) ; } else if ( args . containsKey ( Nutch . ARG_SEGMENTS ) ) { Object segments = args . get ( Nutch . ARG_SEGMENTS ) ; ArrayList < String > segmentList = new ArrayList < > ( ) ; if ( segments instanceof ArrayList ) { segmentList = ( ArrayList < String > ) segments ; } else if ( segments instanceof Path ) { segmentList . add ( segments . toString ( ) ) ; } for ( String segment : segmentList ) { segs . add ( new Path ( segment ) ) ; } } else { String segmentDir = crawlId + ""/segments"" ; File dir = new File ( segmentDir ) ; File [ ] segmentsList = dir . listFiles ( ) ; Arrays . sort ( segmentsList , ( f1 , f2 ) -> { if ( f1 . lastModified ( ) > f2 . lastModified ( ) ) return - 1 ; else return 0 ; } ) ; segs . add ( new Path ( segmentsList [ 0 ] . getPath ( ) ) ) ; } try { invert ( linkdb , segs . toArray ( new Path [ segs . size ( ) ] ) , normalize , filter , force ) ; results . put ( Nutch . VAL_RESULT , Integer . toString ( 0 ) ) ; return results ; } catch ( Exception e ) { LOG . error ( ""LinkDb: {}"" , StringUtils . stringifyException ( e ) ) ; results . put ( Nutch . VAL_RESULT , Integer . toString ( - 1 ) ) ; return results ; } }",Smelly
 public Set < String > getOutboundRequestExcludeHeaders ( ) { return REQUEST_EXCLUDE_HEADERS ; },No
 public Expr copy ( Expr expr ) { return new E_IsURI ( expr ) ; },No
 public Session getSession ( ) { return sessionFactory . getCurrentSession ( ) ; },No
 public void verifyDeterministic ( ) { },No
" public void materialize ( RelNode queryRel , RelOptTable starRelOptTable ) { this . queryRel = queryRel ; this . starRelOptTable = starRelOptTable ; assert starRelOptTable . unwrap ( StarTable . class ) != null ; }",No
" public void read ( org . apache . thrift . protocol . TProtocol prot , getChildDataProducts_result struct ) throws org . apache . thrift . TException { TTupleProtocol iprot = ( TTupleProtocol ) prot ; BitSet incoming = iprot . readBitSet ( 5 ) ; if ( incoming . get ( 0 ) ) { { org . apache . thrift . protocol . TList _list283 = new org . apache . thrift . protocol . TList ( org . apache . thrift . protocol . TType . STRUCT , iprot . readI32 ( ) ) ; struct . success = new ArrayList < org . apache . airavata . model . data . replica . DataProductModel > ( _list283 . size ) ; org . apache . airavata . model . data . replica . DataProductModel _elem284 ; for ( int _i285 = 0 ; _i285 < _list283 . size ; ++ _i285 ) { _elem284 = new org . apache . airavata . model . data . replica . DataProductModel ( ) ; _elem284 . read ( iprot ) ; struct . success . add ( _elem284 ) ; } } struct . setSuccessIsSet ( true ) ; } if ( incoming . get ( 1 ) ) { struct . ire = new org . apache . airavata . model . error . InvalidRequestException ( ) ; struct . ire . read ( iprot ) ; struct . setIreIsSet ( true ) ; } if ( incoming . get ( 2 ) ) { struct . ace = new org . apache . airavata . model . error . AiravataClientException ( ) ; struct . ace . read ( iprot ) ; struct . setAceIsSet ( true ) ; } if ( incoming . get ( 3 ) ) { struct . ase = new org . apache . airavata . model . error . AiravataSystemException ( ) ; struct . ase . read ( iprot ) ; struct . setAseIsSet ( true ) ; } if ( incoming . get ( 4 ) ) { struct . ae = new org . apache . airavata . model . error . AuthorizationException ( ) ; struct . ae . read ( iprot ) ; struct . setAeIsSet ( true ) ; } }",Smelly
" public static Token newToken ( int ofKind ) { return newToken ( ofKind , null ) ; }",No
 public abstract void readExternal ( ObjectInput in ) throws IOException ;,No
" public void read ( org . apache . thrift . protocol . TProtocol prot , ResourceJobManager struct ) throws org . apache . thrift . TException { TTupleProtocol iprot = ( TTupleProtocol ) prot ; struct . resourceJobManagerId = iprot . readString ( ) ; struct . setResourceJobManagerIdIsSet ( true ) ; struct . resourceJobManagerType = org . apache . airavata . model . appcatalog . computeresource . ResourceJobManagerType . findByValue ( iprot . readI32 ( ) ) ; struct . setResourceJobManagerTypeIsSet ( true ) ; BitSet incoming = iprot . readBitSet ( 4 ) ; if ( incoming . get ( 0 ) ) { struct . pushMonitoringEndpoint = iprot . readString ( ) ; struct . setPushMonitoringEndpointIsSet ( true ) ; } if ( incoming . get ( 1 ) ) { struct . jobManagerBinPath = iprot . readString ( ) ; struct . setJobManagerBinPathIsSet ( true ) ; } if ( incoming . get ( 2 ) ) { { org . apache . thrift . protocol . TMap _map12 = new org . apache . thrift . protocol . TMap ( org . apache . thrift . protocol . TType . I32 , org . apache . thrift . protocol . TType . STRING , iprot . readI32 ( ) ) ; struct . jobManagerCommands = new HashMap < JobManagerCommand , String > ( 2 * _map12 . size ) ; JobManagerCommand _key13 ; String _val14 ; for ( int _i15 = 0 ; _i15 < _map12 . size ; ++ _i15 ) { _key13 = org . apache . airavata . model . appcatalog . computeresource . JobManagerCommand . findByValue ( iprot . readI32 ( ) ) ; _val14 = iprot . readString ( ) ; struct . jobManagerCommands . put ( _key13 , _val14 ) ; } } struct . setJobManagerCommandsIsSet ( true ) ; } if ( incoming . get ( 3 ) ) { { org . apache . thrift . protocol . TMap _map16 = new org . apache . thrift . protocol . TMap ( org . apache . thrift . protocol . TType . I32 , org . apache . thrift . protocol . TType . STRING , iprot . readI32 ( ) ) ; struct . parallelismPrefix = new HashMap < org . apache . airavata . model . parallelism . ApplicationParallelismType , String > ( 2 * _map16 . size ) ; org . apache . airavata . model . parallelism . ApplicationParallelismType _key17 ; String _val18 ; for ( int _i19 = 0 ; _i19 < _map16 . size ; ++ _i19 ) { _key17 = org . apache . airavata . model . parallelism . ApplicationParallelismType . findByValue ( iprot . readI32 ( ) ) ; _val18 = iprot . readString ( ) ; struct . parallelismPrefix . put ( _key17 , _val18 ) ; } } struct . setParallelismPrefixIsSet ( true ) ; } }",Smelly
 public void setPath ( String path ) { this . path = path ; },No
 public abstract NameContext getNameContext ( ) ;,No
" public void postAnalyze ( HiveSemanticAnalyzerHookContext context , List < Task < ? extends Serializable > > rootTasks ) throws SemanticException { if ( rootTasks . size ( ) == 0 ) { return ; } CreateTableDesc desc = ( ( DDLTask ) rootTasks . get ( rootTasks . size ( ) - 1 ) ) . getWork ( ) . getCreateTblDesc ( ) ; if ( desc == null ) { return ; } Map < String , String > tblProps = desc . getTblProps ( ) ; if ( tblProps == null ) { tblProps = new HashMap < String , String > ( ) ; } String storageHandler = desc . getStorageHandler ( ) ; if ( StringUtils . isEmpty ( storageHandler ) ) { } else { try { HiveStorageHandler storageHandlerInst = HCatUtil . getStorageHandler ( context . getConf ( ) , desc . getStorageHandler ( ) , desc . getSerName ( ) , desc . getInputFormat ( ) , desc . getOutputFormat ( ) ) ; } catch ( IOException e ) { throw new SemanticException ( e ) ; } } if ( desc != null ) { try { Table table = context . getHive ( ) . newTable ( desc . getTableName ( ) ) ; if ( desc . getLocation ( ) != null ) { table . setDataLocation ( new Path ( desc . getLocation ( ) ) ) ; } if ( desc . getStorageHandler ( ) != null ) { table . setProperty ( org . apache . hadoop . hive . metastore . api . hive_metastoreConstants . META_TABLE_STORAGE , desc . getStorageHandler ( ) ) ; } for ( Map . Entry < String , String > prop : tblProps . entrySet ( ) ) { table . setProperty ( prop . getKey ( ) , prop . getValue ( ) ) ; } for ( Map . Entry < String , String > prop : desc . getSerdeProps ( ) . entrySet ( ) ) { table . setSerdeParam ( prop . getKey ( ) , prop . getValue ( ) ) ; } if ( HiveConf . getBoolVar ( context . getConf ( ) , HiveConf . ConfVars . HIVE_AUTHORIZATION_ENABLED ) ) { authorize ( table , Privilege . CREATE ) ; } } catch ( HiveException ex ) { throw new SemanticException ( ex ) ; } } desc . setTblProps ( tblProps ) ; context . getConf ( ) . set ( HCatConstants . HCAT_CREATE_TBL_NAME , tableName ) ; }",Smelly
" private boolean seekToAvailableEntry ( PeekingIterator < Map . Entry < KENCODED , VENCODED > > iterator ) { if ( iterator != null ) { while ( iterator . hasNext ( ) ) { Map . Entry < KENCODED , VENCODED > entry = iterator . peek ( ) ; if ( ! providedKeys . contains ( entry . getKey ( ) ) ) { if ( isTombstoneValue ( entry . getValue ( ) ) ) { providedKeys . add ( entry . getKey ( ) ) ; } else { return true ; } } iterator . next ( ) ; } } return false ; }",No
 private static < S extends org . apache . thrift . scheme . IScheme > S scheme ( org . apache . thrift . protocol . TProtocol proto ) { return ( org . apache . thrift . scheme . StandardScheme . class . equals ( proto . getScheme ( ) ) ? STANDARD_SCHEME_FACTORY : TUPLE_SCHEME_FACTORY ) . getScheme ( ) ; },Smelly
 public int hashCode ( ) { return name . hashCode ( ) ; },No
" public void read ( org . apache . thrift . protocol . TProtocol prot , getChildDataProducts_result struct ) throws org . apache . thrift . TException { TTupleProtocol iprot = ( TTupleProtocol ) prot ; BitSet incoming = iprot . readBitSet ( 5 ) ; if ( incoming . get ( 0 ) ) { { org . apache . thrift . protocol . TList _list283 = new org . apache . thrift . protocol . TList ( org . apache . thrift . protocol . TType . STRUCT , iprot . readI32 ( ) ) ; struct . success = new ArrayList < org . apache . airavata . model . data . replica . DataProductModel > ( _list283 . size ) ; org . apache . airavata . model . data . replica . DataProductModel _elem284 ; for ( int _i285 = 0 ; _i285 < _list283 . size ; ++ _i285 ) { _elem284 = new org . apache . airavata . model . data . replica . DataProductModel ( ) ; _elem284 . read ( iprot ) ; struct . success . add ( _elem284 ) ; } } struct . setSuccessIsSet ( true ) ; } if ( incoming . get ( 1 ) ) { struct . ire = new org . apache . airavata . model . error . InvalidRequestException ( ) ; struct . ire . read ( iprot ) ; struct . setIreIsSet ( true ) ; } if ( incoming . get ( 2 ) ) { struct . ace = new org . apache . airavata . model . error . AiravataClientException ( ) ; struct . ace . read ( iprot ) ; struct . setAceIsSet ( true ) ; } if ( incoming . get ( 3 ) ) { struct . ase = new org . apache . airavata . model . error . AiravataSystemException ( ) ; struct . ase . read ( iprot ) ; struct . setAseIsSet ( true ) ; } if ( incoming . get ( 4 ) ) { struct . ae = new org . apache . airavata . model . error . AuthorizationException ( ) ; struct . ae . read ( iprot ) ; struct . setAeIsSet ( true ) ; } }",Smelly
 private Object readResolve ( ) { return DataTypes . FLOAT ; },No
" public void read ( org . apache . thrift . protocol . TProtocol prot , JobSubmissionInterface struct ) throws org . apache . thrift . TException { TTupleProtocol iprot = ( TTupleProtocol ) prot ; struct . jobSubmissionInterfaceId = iprot . readString ( ) ; struct . setJobSubmissionInterfaceIdIsSet ( true ) ; struct . jobSubmissionProtocol = org . apache . airavata . model . appcatalog . computeresource . JobSubmissionProtocol . findByValue ( iprot . readI32 ( ) ) ; struct . setJobSubmissionProtocolIsSet ( true ) ; struct . priorityOrder = iprot . readI32 ( ) ; struct . setPriorityOrderIsSet ( true ) ; }",Smelly
" public void read ( org . apache . thrift . protocol . TProtocol prot , show_compact_result struct ) throws org . apache . thrift . TException { TTupleProtocol iprot = ( TTupleProtocol ) prot ; BitSet incoming = iprot . readBitSet ( 1 ) ; if ( incoming . get ( 0 ) ) { struct . success = new ShowCompactResponse ( ) ; struct . success . read ( iprot ) ; struct . setSuccessIsSet ( true ) ; } }",Smelly
" public void read ( org . apache . thrift . protocol . TProtocol prot , getChildDataProducts_result struct ) throws org . apache . thrift . TException { TTupleProtocol iprot = ( TTupleProtocol ) prot ; BitSet incoming = iprot . readBitSet ( 5 ) ; if ( incoming . get ( 0 ) ) { { org . apache . thrift . protocol . TList _list283 = new org . apache . thrift . protocol . TList ( org . apache . thrift . protocol . TType . STRUCT , iprot . readI32 ( ) ) ; struct . success = new ArrayList < org . apache . airavata . model . data . replica . DataProductModel > ( _list283 . size ) ; org . apache . airavata . model . data . replica . DataProductModel _elem284 ; for ( int _i285 = 0 ; _i285 < _list283 . size ; ++ _i285 ) { _elem284 = new org . apache . airavata . model . data . replica . DataProductModel ( ) ; _elem284 . read ( iprot ) ; struct . success . add ( _elem284 ) ; } } struct . setSuccessIsSet ( true ) ; } if ( incoming . get ( 1 ) ) { struct . ire = new org . apache . airavata . model . error . InvalidRequestException ( ) ; struct . ire . read ( iprot ) ; struct . setIreIsSet ( true ) ; } if ( incoming . get ( 2 ) ) { struct . ace = new org . apache . airavata . model . error . AiravataClientException ( ) ; struct . ace . read ( iprot ) ; struct . setAceIsSet ( true ) ; } if ( incoming . get ( 3 ) ) { struct . ase = new org . apache . airavata . model . error . AiravataSystemException ( ) ; struct . ase . read ( iprot ) ; struct . setAseIsSet ( true ) ; } if ( incoming . get ( 4 ) ) { struct . ae = new org . apache . airavata . model . error . AuthorizationException ( ) ; struct . ae . read ( iprot ) ; struct . setAeIsSet ( true ) ; } }",Smelly
" public void testValidateJmxMetrics ( ) throws MetricsValidationFailureException { JmxMetricsAccessor jmxMetricsAccessor = mock ( JmxMetricsAccessor . class ) ; Map < String , Long > values = new HashMap < > ( ) ; values . put ( ""samza-container-0"" , 100L ) ; when ( jmxMetricsAccessor . getCounterValues ( SamzaContainerMetrics . class . getName ( ) , ""commit-calls"" ) ) . thenReturn ( values ) ; validator . validate ( jmxMetricsAccessor ) ; values . put ( ""samza-container-0"" , - 1L ) ; exception . expect ( MetricsValidationFailureException . class ) ; validator . validate ( jmxMetricsAccessor ) ; }",No
" protected void setRealm ( String realm , ChangePasswdDataContainer container ) { container . getChngPwdData ( ) . setTargRealm ( realm ) ; container . setGrammarEndAllowed ( true ) ; }",No
" public static void main ( String [ ] args ) { if ( args . length != 13 ) { System . err . println ( ""Usage: DefineJob <description> <connection_name> <output_name> <type> <start_method> <hopcount_method> <recrawl_interval> <expiration_interval> <reseed_interval> <job_priority> <hop_filters> <filespec_xml> <outputspec_xml>"" ) ; System . err . println ( ""<type> is one of: continuous or specified"" ) ; System . err . println ( ""<start_method> is one of: windowbegin, windowinside, disable"" ) ; System . err . println ( ""<hopcount_method> is one of: accurate, nodelete, neverdelete"" ) ; System . err . println ( ""<recrawl_interval> is the default document recrawl interval in minutes"" ) ; System . err . println ( ""<expiration_interval> is the default document expiration interval in minutes"" ) ; System . err . println ( ""<reseed_interval> is the default document reseed interval in minutes"" ) ; System . err . println ( ""<job_priority> is the job priority (and integer between 0 and 10)"" ) ; System . err . println ( ""<hop_filters> is a comma-separated list of tuples, of the form 'linktype=maxhops'"" ) ; System . err . println ( ""<filespec_xml> is the document specification XML, its form dependent on the connection type"" ) ; System . err . println ( ""<outputspec_xml> is the output specification XML, its form dependent on the output connection type"" ) ; System . exit ( - 1 ) ; } String description = args [ 0 ] ; String connectionName = args [ 1 ] ; String outputConnectionName = args [ 2 ] ; String typeString = args [ 3 ] ; String startString = args [ 4 ] ; String hopcountString = args [ 5 ] ; String recrawlInterval = args [ 6 ] ; String expirationInterval = args [ 7 ] ; String reseedInterval = args [ 8 ] ; String jobPriority = args [ 9 ] ; String hopFilters = args [ 10 ] ; String filespecXML = args [ 11 ] ; String outputspecXML = args [ 12 ] ; try { ManifoldCF . initializeEnvironment ( ) ; IThreadContext tc = ThreadContextFactory . make ( ) ; IJobManager jobManager = JobManagerFactory . make ( tc ) ; IJobDescription desc = jobManager . createJob ( ) ; desc . setDescription ( description ) ; desc . setConnectionName ( connectionName ) ; desc . setOutputConnectionName ( outputConnectionName ) ; if ( typeString . equals ( ""continuous"" ) ) desc . setType ( IJobDescription . TYPE_CONTINUOUS ) ; else if ( typeString . equals ( ""specified"" ) ) desc . setType ( IJobDescription . TYPE_SPECIFIED ) ; else throw new ManifoldCFException ( ""Unknown type: '"" + typeString + ""'"" ) ; if ( startString . equals ( ""windowbegin"" ) ) desc . setStartMethod ( IJobDescription . START_WINDOWBEGIN ) ; else if ( startString . equals ( ""windowinside"" ) ) desc . setStartMethod ( IJobDescription . START_WINDOWINSIDE ) ; else if ( startString . equals ( ""disable"" ) ) desc . setStartMethod ( IJobDescription . START_DISABLE ) ; else throw new ManifoldCFException ( ""Unknown start method: '"" + startString + ""'"" ) ; if ( hopcountString . equals ( ""accurate"" ) ) desc . setHopcountMode ( IJobDescription . HOPCOUNT_ACCURATE ) ; else if ( hopcountString . equals ( ""nodelete"" ) ) desc . setHopcountMode ( IJobDescription . HOPCOUNT_NODELETE ) ; else if ( hopcountString . equals ( ""neverdelete"" ) ) desc . setHopcountMode ( IJobDescription . HOPCOUNT_NEVERDELETE ) ; else throw new ManifoldCFException ( ""Unknown hopcount mode: '"" + hopcountString + ""'"" ) ; if ( recrawlInterval . length ( ) > 0 ) desc . setInterval ( new Long ( recrawlInterval ) ) ; if ( expirationInterval . length ( ) > 0 ) desc . setExpiration ( new Long ( expirationInterval ) ) ; if ( reseedInterval . length ( ) > 0 ) desc . setReseedInterval ( new Long ( reseedInterval ) ) ; desc . setPriority ( Integer . parseInt ( jobPriority ) ) ; String [ ] hopFilterSet = hopFilters . split ( "","" ) ; int i = 0 ; while ( i < hopFilterSet . length ) { String hopFilter = hopFilterSet [ i ++ ] ; if ( hopFilter != null && hopFilter . length ( ) > 0 ) { String [ ] stuff = hopFilter . trim ( ) . split ( ""="" ) ; if ( stuff != null && stuff . length == 2 ) desc . addHopCountFilter ( stuff [ 0 ] , ( ( stuff [ 1 ] . length ( ) > 0 ) ? new Long ( stuff [ 1 ] ) : null ) ) ; } } desc . getSpecification ( ) . fromXML ( filespecXML ) ; if ( outputspecXML . length ( ) > 0 ) desc . getOutputSpecification ( ) . fromXML ( outputspecXML ) ; jobManager . save ( desc ) ; System . out . print ( desc . getID ( ) . toString ( ) ) ; } catch ( Exception e ) { e . printStackTrace ( ) ; System . exit ( - 2 ) ; } }",Smelly
" public void read ( org . apache . thrift . protocol . TProtocol prot , Complex struct ) throws org . apache . thrift . TException { TTupleProtocol iprot = ( TTupleProtocol ) prot ; BitSet incoming = iprot . readBitSet ( 6 ) ; if ( incoming . get ( 0 ) ) { struct . aint = iprot . readI32 ( ) ; struct . setAintIsSet ( true ) ; } if ( incoming . get ( 1 ) ) { struct . aString = iprot . readString ( ) ; struct . setAStringIsSet ( true ) ; } if ( incoming . get ( 2 ) ) { { org . apache . thrift . protocol . TList _list21 = new org . apache . thrift . protocol . TList ( org . apache . thrift . protocol . TType . I32 , iprot . readI32 ( ) ) ; struct . lint = new ArrayList < Integer > ( _list21 . size ) ; for ( int _i22 = 0 ; _i22 < _list21 . size ; ++ _i22 ) { int _elem23 ; _elem23 = iprot . readI32 ( ) ; struct . lint . add ( _elem23 ) ; } } struct . setLintIsSet ( true ) ; } if ( incoming . get ( 3 ) ) { { org . apache . thrift . protocol . TList _list24 = new org . apache . thrift . protocol . TList ( org . apache . thrift . protocol . TType . STRING , iprot . readI32 ( ) ) ; struct . lString = new ArrayList < String > ( _list24 . size ) ; for ( int _i25 = 0 ; _i25 < _list24 . size ; ++ _i25 ) { String _elem26 ; _elem26 = iprot . readString ( ) ; struct . lString . add ( _elem26 ) ; } } struct . setLStringIsSet ( true ) ; } if ( incoming . get ( 4 ) ) { { org . apache . thrift . protocol . TList _list27 = new org . apache . thrift . protocol . TList ( org . apache . thrift . protocol . TType . STRUCT , iprot . readI32 ( ) ) ; struct . lintString = new ArrayList < IntString > ( _list27 . size ) ; for ( int _i28 = 0 ; _i28 < _list27 . size ; ++ _i28 ) { IntString _elem29 ; _elem29 = new IntString ( ) ; _elem29 . read ( iprot ) ; struct . lintString . add ( _elem29 ) ; } } struct . setLintStringIsSet ( true ) ; } if ( incoming . get ( 5 ) ) { { org . apache . thrift . protocol . TMap _map30 = new org . apache . thrift . protocol . TMap ( org . apache . thrift . protocol . TType . STRING , org . apache . thrift . protocol . TType . STRING , iprot . readI32 ( ) ) ; struct . mStringString = new HashMap < String , String > ( 2 * _map30 . size ) ; for ( int _i31 = 0 ; _i31 < _map30 . size ; ++ _i31 ) { String _key32 ; String _val33 ; _key32 = iprot . readString ( ) ; _val33 = iprot . readString ( ) ; struct . mStringString . put ( _key32 , _val33 ) ; } } struct . setMStringStringIsSet ( true ) ; } }",Smelly
" protected Object doExecute ( Bundle bundle ) throws Exception { if ( bundleService . isDynamicImport ( bundle ) ) { System . out . printf ( ""Disabling dynamic imports on bundle %s%n"" , bundle ) ; bundleService . disableDynamicImports ( bundle ) ; } else { System . out . printf ( ""Enabling dynamic imports on bundle %s%n"" , bundle ) ; bundleService . enableDynamicImports ( bundle ) ; } return null ; }",No
" public void read ( org . apache . thrift . protocol . TProtocol prot , show_compact_result struct ) throws org . apache . thrift . TException { TTupleProtocol iprot = ( TTupleProtocol ) prot ; BitSet incoming = iprot . readBitSet ( 1 ) ; if ( incoming . get ( 0 ) ) { struct . success = new ShowCompactResponse ( ) ; struct . success . read ( iprot ) ; struct . setSuccessIsSet ( true ) ; } }",Smelly
 private static < S extends org . apache . thrift . scheme . IScheme > S scheme ( org . apache . thrift . protocol . TProtocol proto ) { return ( org . apache . thrift . scheme . StandardScheme . class . equals ( proto . getScheme ( ) ) ? STANDARD_SCHEME_FACTORY : TUPLE_SCHEME_FACTORY ) . getScheme ( ) ; },Smelly
" private void addAuditResource ( String serviceType ) { if ( LOG . isDebugEnabled ( ) ) { LOG . debug ( ""==> addAuditResource(Service Type: "" + serviceType ) ; } URL url = null ; try { url = RangerLegacyConfigBuilder . getAuditConfig ( serviceType ) ; if ( url != null ) { addResource ( url ) ; if ( LOG . isDebugEnabled ( ) ) { LOG . debug ( ""==> addAuditResource() URL"" + url . getPath ( ) ) ; } } } catch ( Throwable t ) { LOG . warn ( "" Unable to find Audit Config for "" + serviceType + "" Auditing not enabled !"" ) ; if ( LOG . isDebugEnabled ( ) ) { LOG . debug ( "" Unable to find Audit Config for "" + serviceType + "" Auditing not enabled !"" + t ) ; } } if ( LOG . isDebugEnabled ( ) ) { LOG . debug ( ""<== addAuditResource(Service Type: "" + serviceType + "")"" ) ; } }",No
" public static Configuration getConfigurationFromFiles ( final String configFiles ) { final Configuration hiveConfig = new HiveConf ( ) ; if ( StringUtils . isNotBlank ( configFiles ) ) { for ( final String configFile : configFiles . split ( "","" ) ) { hiveConfig . addResource ( new Path ( configFile . trim ( ) ) ) ; } } return hiveConfig ; }",Smelly
" public void read ( org . apache . thrift . protocol . TProtocol prot , TaskOutputChangeEvent struct ) throws org . apache . thrift . TException { TTupleProtocol iprot = ( TTupleProtocol ) prot ; { org . apache . thrift . protocol . TList _list5 = new org . apache . thrift . protocol . TList ( org . apache . thrift . protocol . TType . STRUCT , iprot . readI32 ( ) ) ; struct . output = new ArrayList < org . apache . airavata . model . application . io . OutputDataObjectType > ( _list5 . size ) ; org . apache . airavata . model . application . io . OutputDataObjectType _elem6 ; for ( int _i7 = 0 ; _i7 < _list5 . size ; ++ _i7 ) { _elem6 = new org . apache . airavata . model . application . io . OutputDataObjectType ( ) ; _elem6 . read ( iprot ) ; struct . output . add ( _elem6 ) ; } } struct . setOutputIsSet ( true ) ; struct . taskIdentity = new TaskIdentifier ( ) ; struct . taskIdentity . read ( iprot ) ; struct . setTaskIdentityIsSet ( true ) ; }",Smelly
" public static Map < String , Object > checkAssocPermission ( DispatchContext dctx , Map < String , ? extends Object > context ) { Map < String , Object > results = FastMap . newInstance ( ) ; Delegator delegator = dctx . getDelegator ( ) ; LocalDispatcher dispatcher = dctx . getDispatcher ( ) ; Boolean bDisplayFailCond = ( Boolean ) context . get ( ""displayFailCond"" ) ; String contentIdFrom = ( String ) context . get ( ""contentIdFrom"" ) ; String contentIdTo = ( String ) context . get ( ""contentIdTo"" ) ; GenericValue userLogin = ( GenericValue ) context . get ( ""userLogin"" ) ; String entityAction = ( String ) context . get ( ""entityOperation"" ) ; Locale locale = ( Locale ) context . get ( ""locale"" ) ; if ( entityAction == null ) entityAction = ""_ADMIN"" ; String permissionStatus = null ; GenericValue contentTo = null ; GenericValue contentFrom = null ; try { contentTo = delegator . findOne ( ""Content"" , UtilMisc . toMap ( ""contentId"" , contentIdTo ) , true ) ; contentFrom = delegator . findOne ( ""Content"" , UtilMisc . toMap ( ""contentId"" , contentIdFrom ) , true ) ; } catch ( GenericEntityException e ) { return ServiceUtil . returnError ( UtilProperties . getMessage ( resource , ""ContentContentToOrFromErrorRetriving"" , locale ) ) ; } if ( contentTo == null || contentFrom == null ) { return ServiceUtil . returnError ( UtilProperties . getMessage ( resource , ""ContentContentToOrFromIsNull"" , UtilMisc . toMap ( ""contentTo"" , contentTo , ""contentFrom"" , contentFrom ) , locale ) ) ; } Map < String , Object > permResults = FastMap . newInstance ( ) ; List < String > relatedPurposes = EntityPermissionChecker . getRelatedPurposes ( contentFrom , null ) ; List < String > relatedPurposesTo = EntityPermissionChecker . getRelatedPurposes ( contentTo , relatedPurposes ) ; Map < String , Object > serviceInMap = FastMap . newInstance ( ) ; serviceInMap . put ( ""userLogin"" , userLogin ) ; serviceInMap . put ( ""targetOperationList"" , UtilMisc . toList ( ""CONTENT_LINK_TO"" ) ) ; serviceInMap . put ( ""contentPurposeList"" , relatedPurposesTo ) ; serviceInMap . put ( ""currentContent"" , contentTo ) ; serviceInMap . put ( ""displayFailCond"" , bDisplayFailCond ) ; try { permResults = dispatcher . runSync ( ""checkContentPermission"" , serviceInMap ) ; } catch ( GenericServiceException e ) { Debug . logError ( e , ""Problem checking permissions"" , ""ContentServices"" ) ; } permissionStatus = ( String ) permResults . get ( ""permissionStatus"" ) ; if ( permissionStatus == null || ! permissionStatus . equals ( ""granted"" ) ) { if ( bDisplayFailCond != null && bDisplayFailCond . booleanValue ( ) ) { String errMsg = ( String ) permResults . get ( ModelService . ERROR_MESSAGE ) ; results . put ( ModelService . ERROR_MESSAGE , errMsg ) ; } return results ; } serviceInMap . put ( ""currentContent"" , contentFrom ) ; serviceInMap . put ( ""targetOperationList"" , UtilMisc . toList ( ""CONTENT_LINK_FROM"" ) ) ; serviceInMap . put ( ""contentPurposeList"" , relatedPurposes ) ; try { permResults = dispatcher . runSync ( ""checkContentPermission"" , serviceInMap ) ; } catch ( GenericServiceException e ) { Debug . logError ( e , ""Problem checking permissions"" , ""ContentServices"" ) ; } permissionStatus = ( String ) permResults . get ( ""permissionStatus"" ) ; if ( permissionStatus != null && permissionStatus . equals ( ""granted"" ) ) { results . put ( ""permissionStatus"" , ""granted"" ) ; } else { if ( bDisplayFailCond != null && bDisplayFailCond . booleanValue ( ) ) { String errMsg = ( String ) permResults . get ( ModelService . ERROR_MESSAGE ) ; results . put ( ModelService . ERROR_MESSAGE , errMsg ) ; } } return results ; }",Smelly
" public void testNumberHashNumberRangePutGetDeleteGetSuccess ( ) { final TestRunner putRunner = TestRunners . newTestRunner ( PutDynamoDB . class ) ; putRunner . setProperty ( AbstractWriteDynamoDBProcessor . CREDENTIALS_FILE , CREDENTIALS_FILE ) ; putRunner . setProperty ( AbstractWriteDynamoDBProcessor . REGION , REGION ) ; putRunner . setProperty ( AbstractWriteDynamoDBProcessor . TABLE , numberHashNumberRangeTableName ) ; putRunner . setProperty ( AbstractWriteDynamoDBProcessor . HASH_KEY_NAME , ""hashN"" ) ; putRunner . setProperty ( AbstractWriteDynamoDBProcessor . RANGE_KEY_NAME , ""rangeN"" ) ; putRunner . setProperty ( AbstractWriteDynamoDBProcessor . HASH_KEY_VALUE_TYPE , AbstractWriteDynamoDBProcessor . ALLOWABLE_VALUE_NUMBER ) ; putRunner . setProperty ( AbstractWriteDynamoDBProcessor . RANGE_KEY_VALUE_TYPE , AbstractWriteDynamoDBProcessor . ALLOWABLE_VALUE_NUMBER ) ; putRunner . setProperty ( AbstractWriteDynamoDBProcessor . HASH_KEY_VALUE , ""40"" ) ; putRunner . setProperty ( AbstractWriteDynamoDBProcessor . RANGE_KEY_VALUE , ""50"" ) ; putRunner . setProperty ( AbstractWriteDynamoDBProcessor . JSON_DOCUMENT , ""document"" ) ; String document = ""{\""40\"":\""50\""}"" ; putRunner . enqueue ( document . getBytes ( ) ) ; putRunner . run ( 1 ) ; putRunner . assertAllFlowFilesTransferred ( AbstractWriteDynamoDBProcessor . REL_SUCCESS , 1 ) ; List < MockFlowFile > flowFiles = putRunner . getFlowFilesForRelationship ( AbstractWriteDynamoDBProcessor . REL_SUCCESS ) ; for ( MockFlowFile flowFile : flowFiles ) { assertEquals ( document , new String ( flowFile . toByteArray ( ) ) ) ; } final TestRunner getRunner = TestRunners . newTestRunner ( GetDynamoDB . class ) ; getRunner . setProperty ( AbstractDynamoDBProcessor . CREDENTIALS_FILE , CREDENTIALS_FILE ) ; getRunner . setProperty ( AbstractDynamoDBProcessor . REGION , REGION ) ; getRunner . setProperty ( AbstractDynamoDBProcessor . TABLE , numberHashNumberRangeTableName ) ; getRunner . setProperty ( AbstractDynamoDBProcessor . HASH_KEY_NAME , ""hashN"" ) ; getRunner . setProperty ( AbstractDynamoDBProcessor . RANGE_KEY_NAME , ""rangeN"" ) ; getRunner . setProperty ( AbstractDynamoDBProcessor . HASH_KEY_VALUE , ""40"" ) ; getRunner . setProperty ( AbstractDynamoDBProcessor . RANGE_KEY_VALUE , ""50"" ) ; getRunner . setProperty ( AbstractWriteDynamoDBProcessor . HASH_KEY_VALUE_TYPE , AbstractWriteDynamoDBProcessor . ALLOWABLE_VALUE_NUMBER ) ; getRunner . setProperty ( AbstractWriteDynamoDBProcessor . RANGE_KEY_VALUE_TYPE , AbstractWriteDynamoDBProcessor . ALLOWABLE_VALUE_NUMBER ) ; getRunner . setProperty ( AbstractDynamoDBProcessor . JSON_DOCUMENT , ""document"" ) ; getRunner . enqueue ( new byte [ ] { } ) ; getRunner . run ( 1 ) ; getRunner . assertAllFlowFilesTransferred ( AbstractDynamoDBProcessor . REL_SUCCESS , 1 ) ; flowFiles = getRunner . getFlowFilesForRelationship ( AbstractDynamoDBProcessor . REL_SUCCESS ) ; for ( MockFlowFile flowFile : flowFiles ) { assertEquals ( document , new String ( flowFile . toByteArray ( ) ) ) ; } final TestRunner deleteRunner = TestRunners . newTestRunner ( DeleteDynamoDB . class ) ; deleteRunner . setProperty ( DeleteDynamoDB . CREDENTIALS_FILE , CREDENTIALS_FILE ) ; deleteRunner . setProperty ( DeleteDynamoDB . REGION , REGION ) ; deleteRunner . setProperty ( DeleteDynamoDB . TABLE , numberHashNumberRangeTableName ) ; deleteRunner . setProperty ( DeleteDynamoDB . HASH_KEY_NAME , ""hashN"" ) ; deleteRunner . setProperty ( DeleteDynamoDB . RANGE_KEY_NAME , ""rangeN"" ) ; deleteRunner . setProperty ( DeleteDynamoDB . HASH_KEY_VALUE , ""40"" ) ; deleteRunner . setProperty ( DeleteDynamoDB . RANGE_KEY_VALUE , ""50"" ) ; deleteRunner . setProperty ( AbstractWriteDynamoDBProcessor . HASH_KEY_VALUE_TYPE , AbstractWriteDynamoDBProcessor . ALLOWABLE_VALUE_NUMBER ) ; deleteRunner . setProperty ( AbstractWriteDynamoDBProcessor . RANGE_KEY_VALUE_TYPE , AbstractWriteDynamoDBProcessor . ALLOWABLE_VALUE_NUMBER ) ; deleteRunner . enqueue ( new byte [ ] { } ) ; deleteRunner . run ( 1 ) ; deleteRunner . assertAllFlowFilesTransferred ( DeleteDynamoDB . REL_SUCCESS , 1 ) ; flowFiles = deleteRunner . getFlowFilesForRelationship ( DeleteDynamoDB . REL_SUCCESS ) ; for ( MockFlowFile flowFile : flowFiles ) { System . out . println ( flowFile . getAttributes ( ) ) ; assertEquals ( """" , new String ( flowFile . toByteArray ( ) ) ) ; } final TestRunner getRunnerAfterDelete = TestRunners . newTestRunner ( GetDynamoDB . class ) ; getRunnerAfterDelete . setProperty ( AbstractDynamoDBProcessor . CREDENTIALS_FILE , CREDENTIALS_FILE ) ; getRunnerAfterDelete . setProperty ( AbstractDynamoDBProcessor . REGION , REGION ) ; getRunnerAfterDelete . setProperty ( AbstractDynamoDBProcessor . TABLE , numberHashNumberRangeTableName ) ; getRunnerAfterDelete . setProperty ( AbstractDynamoDBProcessor . HASH_KEY_NAME , ""hashN"" ) ; getRunnerAfterDelete . setProperty ( AbstractDynamoDBProcessor . RANGE_KEY_NAME , ""rangeN"" ) ; getRunnerAfterDelete . setProperty ( AbstractDynamoDBProcessor . HASH_KEY_VALUE , ""40"" ) ; getRunnerAfterDelete . setProperty ( AbstractDynamoDBProcessor . RANGE_KEY_VALUE , ""50"" ) ; getRunnerAfterDelete . setProperty ( AbstractDynamoDBProcessor . JSON_DOCUMENT , ""document"" ) ; getRunnerAfterDelete . setProperty ( AbstractWriteDynamoDBProcessor . HASH_KEY_VALUE_TYPE , AbstractWriteDynamoDBProcessor . ALLOWABLE_VALUE_NUMBER ) ; getRunnerAfterDelete . setProperty ( AbstractWriteDynamoDBProcessor . RANGE_KEY_VALUE_TYPE , AbstractWriteDynamoDBProcessor . ALLOWABLE_VALUE_NUMBER ) ; getRunnerAfterDelete . enqueue ( new byte [ ] { } ) ; getRunnerAfterDelete . run ( 1 ) ; getRunnerAfterDelete . assertAllFlowFilesTransferred ( GetDynamoDB . REL_NOT_FOUND , 1 ) ; flowFiles = getRunnerAfterDelete . getFlowFilesForRelationship ( GetDynamoDB . REL_NOT_FOUND ) ; for ( MockFlowFile flowFile : flowFiles ) { String error = flowFile . getAttribute ( AbstractDynamoDBProcessor . DYNAMODB_KEY_ERROR_NOT_FOUND ) ; assertTrue ( error . startsWith ( AbstractDynamoDBProcessor . DYNAMODB_KEY_ERROR_NOT_FOUND_MESSAGE ) ) ; } }",Smelly
" public void read ( org . apache . thrift . protocol . TProtocol prot , getChildDataProducts_result struct ) throws org . apache . thrift . TException { TTupleProtocol iprot = ( TTupleProtocol ) prot ; BitSet incoming = iprot . readBitSet ( 5 ) ; if ( incoming . get ( 0 ) ) { { org . apache . thrift . protocol . TList _list283 = new org . apache . thrift . protocol . TList ( org . apache . thrift . protocol . TType . STRUCT , iprot . readI32 ( ) ) ; struct . success = new ArrayList < org . apache . airavata . model . data . replica . DataProductModel > ( _list283 . size ) ; org . apache . airavata . model . data . replica . DataProductModel _elem284 ; for ( int _i285 = 0 ; _i285 < _list283 . size ; ++ _i285 ) { _elem284 = new org . apache . airavata . model . data . replica . DataProductModel ( ) ; _elem284 . read ( iprot ) ; struct . success . add ( _elem284 ) ; } } struct . setSuccessIsSet ( true ) ; } if ( incoming . get ( 1 ) ) { struct . ire = new org . apache . airavata . model . error . InvalidRequestException ( ) ; struct . ire . read ( iprot ) ; struct . setIreIsSet ( true ) ; } if ( incoming . get ( 2 ) ) { struct . ace = new org . apache . airavata . model . error . AiravataClientException ( ) ; struct . ace . read ( iprot ) ; struct . setAceIsSet ( true ) ; } if ( incoming . get ( 3 ) ) { struct . ase = new org . apache . airavata . model . error . AiravataSystemException ( ) ; struct . ase . read ( iprot ) ; struct . setAseIsSet ( true ) ; } if ( incoming . get ( 4 ) ) { struct . ae = new org . apache . airavata . model . error . AuthorizationException ( ) ; struct . ae . read ( iprot ) ; struct . setAeIsSet ( true ) ; } }",Smelly
" public StructureTreeElement startReferencedNode ( String name , Attributes attributes , StructureTreeElement parent ) { return startNode ( name , attributes , parent ) ; }",No
 public byte getTag ( ) { return 67 ; },No
" protected String add_escapes ( String str ) { StringBuffer retval = new StringBuffer ( ) ; char ch ; for ( int i = 0 ; i < str . length ( ) ; i ++ ) { switch ( str . charAt ( i ) ) { case 0 : continue ; case '\b' : retval . append ( ""\\b"" ) ; continue ; case '\t' : retval . append ( ""\\t"" ) ; continue ; case '\n' : retval . append ( ""\\n"" ) ; continue ; case '\f' : retval . append ( ""\\f"" ) ; continue ; case '\r' : retval . append ( ""\\r"" ) ; continue ; case '\""' : retval . append ( ""\\\"""" ) ; continue ; case '\'' : retval . append ( ""\\\'"" ) ; continue ; case '\\' : retval . append ( ""\\\\"" ) ; continue ; default : if ( ( ch = str . charAt ( i ) ) < 0x20 || ch > 0x7e ) { String s = ""0000"" + Integer . toString ( ch , 16 ) ; retval . append ( ""\\u"" + s . substring ( s . length ( ) - 4 , s . length ( ) ) ) ; } else { retval . append ( ch ) ; } continue ; } } return retval . toString ( ) ; }",Smelly
 public String getDescriptiveName ( ) { return this . getConvertor ( ) . getTypeClass ( ) . getName ( ) ; },No
 public void setBreakingField ( String breakingField ) { this . breakingField = breakingField ; },No
" public void read ( org . apache . thrift . protocol . TProtocol prot , Test struct ) throws org . apache . thrift . TException { TTupleProtocol iprot = ( TTupleProtocol ) prot ; BitSet incoming = iprot . readBitSet ( 16 ) ; if ( incoming . get ( 0 ) ) { struct . boolField = iprot . readBool ( ) ; struct . setBoolFieldIsSet ( true ) ; } if ( incoming . get ( 1 ) ) { struct . byteField = iprot . readByte ( ) ; struct . setByteFieldIsSet ( true ) ; } if ( incoming . get ( 2 ) ) { struct . byteOptionalField = iprot . readByte ( ) ; struct . setByteOptionalFieldIsSet ( true ) ; } if ( incoming . get ( 3 ) ) { struct . i16Field = iprot . readI16 ( ) ; struct . setI16FieldIsSet ( true ) ; } if ( incoming . get ( 4 ) ) { struct . i16OptionalField = iprot . readI16 ( ) ; struct . setI16OptionalFieldIsSet ( true ) ; } if ( incoming . get ( 5 ) ) { struct . i32Field = iprot . readI32 ( ) ; struct . setI32FieldIsSet ( true ) ; } if ( incoming . get ( 6 ) ) { struct . i64Field = iprot . readI64 ( ) ; struct . setI64FieldIsSet ( true ) ; } if ( incoming . get ( 7 ) ) { struct . doubleField = iprot . readDouble ( ) ; struct . setDoubleFieldIsSet ( true ) ; } if ( incoming . get ( 8 ) ) { struct . stringField = iprot . readString ( ) ; struct . setStringFieldIsSet ( true ) ; } if ( incoming . get ( 9 ) ) { struct . binaryField = iprot . readBinary ( ) ; struct . setBinaryFieldIsSet ( true ) ; } if ( incoming . get ( 10 ) ) { { org . apache . thrift . protocol . TMap _map16 = new org . apache . thrift . protocol . TMap ( org . apache . thrift . protocol . TType . STRING , org . apache . thrift . protocol . TType . I32 , iprot . readI32 ( ) ) ; struct . mapField = new HashMap < > ( 2 * _map16 . size ) ; for ( int _i17 = 0 ; _i17 < _map16 . size ; ++ _i17 ) { String _key18 ; int _val19 ; _key18 = iprot . readString ( ) ; _val19 = iprot . readI32 ( ) ; struct . mapField . put ( _key18 , _val19 ) ; } } struct . setMapFieldIsSet ( true ) ; } if ( incoming . get ( 11 ) ) { { org . apache . thrift . protocol . TList _list20 = new org . apache . thrift . protocol . TList ( org . apache . thrift . protocol . TType . I32 , iprot . readI32 ( ) ) ; struct . listField = new ArrayList < > ( _list20 . size ) ; for ( int _i21 = 0 ; _i21 < _list20 . size ; ++ _i21 ) { int _elem22 ; _elem22 = iprot . readI32 ( ) ; struct . listField . add ( _elem22 ) ; } } struct . setListFieldIsSet ( true ) ; } if ( incoming . get ( 12 ) ) { { org . apache . thrift . protocol . TSet _set23 = new org . apache . thrift . protocol . TSet ( org . apache . thrift . protocol . TType . I32 , iprot . readI32 ( ) ) ; struct . setField = new HashSet < > ( 2 * _set23 . size ) ; for ( int _i24 = 0 ; _i24 < _set23 . size ; ++ _i24 ) { int _elem25 ; _elem25 = iprot . readI32 ( ) ; struct . setField . add ( _elem25 ) ; } } struct . setSetFieldIsSet ( true ) ; } if ( incoming . get ( 13 ) ) { struct . enumField = E . findByValue ( iprot . readI32 ( ) ) ; struct . setEnumFieldIsSet ( true ) ; } if ( incoming . get ( 14 ) ) { struct . structField = new Nested ( ) ; struct . structField . read ( iprot ) ; struct . setStructFieldIsSet ( true ) ; } if ( incoming . get ( 15 ) ) { struct . fooOrBar = new FooOrBar ( ) ; struct . fooOrBar . read ( iprot ) ; struct . setFooOrBarIsSet ( true ) ; } }",Smelly
 private static < S extends org . apache . thrift . scheme . IScheme > S scheme ( org . apache . thrift . protocol . TProtocol proto ) { return ( org . apache . thrift . scheme . StandardScheme . class . equals ( proto . getScheme ( ) ) ? STANDARD_SCHEME_FACTORY : TUPLE_SCHEME_FACTORY ) . getScheme ( ) ; },Smelly
" public HiveClient getClient ( ) { HiveClient result = mock ( HiveClient . class ) ; if ( ClientResult . RETURN_OK . equals ( this . result ) ) { List < String > fetchResult = new ArrayList < String > ( 1 ) ; fetchResult . add ( ""test result"" ) ; try { when ( result . fetchN ( anyInt ( ) ) ) . thenReturn ( fetchResult ) ; } catch ( HiveServerException e ) { } catch ( Exception e ) { } } else if ( ClientResult . RETURN_SERVER_EXCEPTION . equals ( this . result ) ) { HiveServerException exception = new HiveServerException ( ""test HiveServerException"" , 10 , ""sql state"" ) ; try { when ( result . fetchN ( anyInt ( ) ) ) . thenThrow ( exception ) ; when ( result . fetchN ( anyInt ( ) ) ) . thenThrow ( exception ) ; } catch ( TException e ) { ; } return result ; } else if ( ClientResult . RETURN_T_EXCEPTION . equals ( this . result ) ) { TException exception = new TException ( ""test TException"" ) ; try { doThrow ( exception ) . when ( result ) . clean ( ) ; when ( result . fetchN ( anyInt ( ) ) ) . thenThrow ( exception ) ; } catch ( TException e ) { e . printStackTrace ( ) ; } return result ; } return result ; }",No
" public void read ( org . apache . thrift . protocol . TProtocol prot , getActiveLogs_result struct ) throws org . apache . thrift . TException { TTupleProtocol iprot = ( TTupleProtocol ) prot ; BitSet incoming = iprot . readBitSet ( 1 ) ; if ( incoming . get ( 0 ) ) { { org . apache . thrift . protocol . TList _list327 = new org . apache . thrift . protocol . TList ( org . apache . thrift . protocol . TType . STRING , iprot . readI32 ( ) ) ; struct . success = new ArrayList < String > ( _list327 . size ) ; for ( int _i328 = 0 ; _i328 < _list327 . size ; ++ _i328 ) { String _elem329 ; _elem329 = iprot . readString ( ) ; struct . success . add ( _elem329 ) ; } } struct . setSuccessIsSet ( true ) ; } }",Smelly
" private long determineCleanupInterval ( NiFiProperties properties ) { long cleanupInterval = MIN_CLEANUP_INTERVAL_MILLIS ; String archiveCleanupFrequency = properties . getProperty ( NiFiProperties . CONTENT_ARCHIVE_CLEANUP_FREQUENCY ) ; if ( archiveCleanupFrequency != null ) { try { cleanupInterval = FormatUtils . getTimeDuration ( archiveCleanupFrequency . trim ( ) , TimeUnit . MILLISECONDS ) ; } catch ( Exception e ) { throw new RuntimeException ( ""Invalid value set for property "" + NiFiProperties . CONTENT_ARCHIVE_CLEANUP_FREQUENCY ) ; } if ( cleanupInterval < MIN_CLEANUP_INTERVAL_MILLIS ) { LOG . warn ( ""The value of "" + NiFiProperties . CONTENT_ARCHIVE_CLEANUP_FREQUENCY + "" property is set to '"" + archiveCleanupFrequency + ""' which is "" + ""below the allowed minimum of 1 second (1000 milliseconds). Minimum value of 1 sec will be used as scheduling interval for archive cleanup task."" ) ; cleanupInterval = MIN_CLEANUP_INTERVAL_MILLIS ; } } return cleanupInterval ; }",Smelly
 private static < S extends org . apache . thrift . scheme . IScheme > S scheme ( org . apache . thrift . protocol . TProtocol proto ) { return ( org . apache . thrift . scheme . StandardScheme . class . equals ( proto . getScheme ( ) ) ? STANDARD_SCHEME_FACTORY : TUPLE_SCHEME_FACTORY ) . getScheme ( ) ; },Smelly
" private String attemptsPostTableInit ( ) { return ""var asInitVals = new Array();\n"" + ""$('tfoot input').keyup( function () \n{"" + ""  attemptsDataTable.fnFilter( this.value, $('tfoot input').index(this) );\n"" + ""} );\n"" + ""$('tfoot input').each( function (i) {\n"" + ""  asInitVals[i] = this.value;\n"" + ""} );\n"" + ""$('tfoot input').focus( function () {\n"" + ""  if ( this.className == 'search_init' )\n"" + ""  {\n"" + ""    this.className = '';\n"" + ""    this.value = '';\n"" + ""  }\n"" + ""} );\n"" + ""$('tfoot input').blur( function (i) {\n"" + ""  if ( this.value == '' )\n"" + ""  {\n"" + ""    this.className = 'search_init';\n"" + ""    this.value = asInitVals[$('tfoot input').index(this)];\n"" + ""  }\n"" + ""} );\n"" ; }",Smelly
" public void read ( org . apache . thrift . protocol . TProtocol prot , show_compact_result struct ) throws org . apache . thrift . TException { TTupleProtocol iprot = ( TTupleProtocol ) prot ; BitSet incoming = iprot . readBitSet ( 1 ) ; if ( incoming . get ( 0 ) ) { struct . success = new ShowCompactResponse ( ) ; struct . success . read ( iprot ) ; struct . setSuccessIsSet ( true ) ; } }",Smelly
 public void setMapsIdColumns ( List < Column > cols ) { _mapsIdCols = cols ; },No
" public void read ( org . apache . thrift . protocol . TProtocol prot , ComputeResourceDescription struct ) throws org . apache . thrift . TException { TTupleProtocol iprot = ( TTupleProtocol ) prot ; struct . computeResourceId = iprot . readString ( ) ; struct . setComputeResourceIdIsSet ( true ) ; struct . hostName = iprot . readString ( ) ; struct . setHostNameIsSet ( true ) ; BitSet incoming = iprot . readBitSet ( 12 ) ; if ( incoming . get ( 0 ) ) { { org . apache . thrift . protocol . TList _list67 = new org . apache . thrift . protocol . TList ( org . apache . thrift . protocol . TType . STRING , iprot . readI32 ( ) ) ; struct . hostAliases = new ArrayList < String > ( _list67 . size ) ; String _elem68 ; for ( int _i69 = 0 ; _i69 < _list67 . size ; ++ _i69 ) { _elem68 = iprot . readString ( ) ; struct . hostAliases . add ( _elem68 ) ; } } struct . setHostAliasesIsSet ( true ) ; } if ( incoming . get ( 1 ) ) { { org . apache . thrift . protocol . TList _list70 = new org . apache . thrift . protocol . TList ( org . apache . thrift . protocol . TType . STRING , iprot . readI32 ( ) ) ; struct . ipAddresses = new ArrayList < String > ( _list70 . size ) ; String _elem71 ; for ( int _i72 = 0 ; _i72 < _list70 . size ; ++ _i72 ) { _elem71 = iprot . readString ( ) ; struct . ipAddresses . add ( _elem71 ) ; } } struct . setIpAddressesIsSet ( true ) ; } if ( incoming . get ( 2 ) ) { struct . resourceDescription = iprot . readString ( ) ; struct . setResourceDescriptionIsSet ( true ) ; } if ( incoming . get ( 3 ) ) { struct . enabled = iprot . readBool ( ) ; struct . setEnabledIsSet ( true ) ; } if ( incoming . get ( 4 ) ) { { org . apache . thrift . protocol . TList _list73 = new org . apache . thrift . protocol . TList ( org . apache . thrift . protocol . TType . STRUCT , iprot . readI32 ( ) ) ; struct . batchQueues = new ArrayList < BatchQueue > ( _list73 . size ) ; BatchQueue _elem74 ; for ( int _i75 = 0 ; _i75 < _list73 . size ; ++ _i75 ) { _elem74 = new BatchQueue ( ) ; _elem74 . read ( iprot ) ; struct . batchQueues . add ( _elem74 ) ; } } struct . setBatchQueuesIsSet ( true ) ; } if ( incoming . get ( 5 ) ) { { org . apache . thrift . protocol . TMap _map76 = new org . apache . thrift . protocol . TMap ( org . apache . thrift . protocol . TType . I32 , org . apache . thrift . protocol . TType . STRING , iprot . readI32 ( ) ) ; struct . fileSystems = new HashMap < FileSystems , String > ( 2 * _map76 . size ) ; FileSystems _key77 ; String _val78 ; for ( int _i79 = 0 ; _i79 < _map76 . size ; ++ _i79 ) { _key77 = org . apache . airavata . model . appcatalog . computeresource . FileSystems . findByValue ( iprot . readI32 ( ) ) ; _val78 = iprot . readString ( ) ; struct . fileSystems . put ( _key77 , _val78 ) ; } } struct . setFileSystemsIsSet ( true ) ; } if ( incoming . get ( 6 ) ) { { org . apache . thrift . protocol . TList _list80 = new org . apache . thrift . protocol . TList ( org . apache . thrift . protocol . TType . STRUCT , iprot . readI32 ( ) ) ; struct . jobSubmissionInterfaces = new ArrayList < JobSubmissionInterface > ( _list80 . size ) ; JobSubmissionInterface _elem81 ; for ( int _i82 = 0 ; _i82 < _list80 . size ; ++ _i82 ) { _elem81 = new JobSubmissionInterface ( ) ; _elem81 . read ( iprot ) ; struct . jobSubmissionInterfaces . add ( _elem81 ) ; } } struct . setJobSubmissionInterfacesIsSet ( true ) ; } if ( incoming . get ( 7 ) ) { { org . apache . thrift . protocol . TList _list83 = new org . apache . thrift . protocol . TList ( org . apache . thrift . protocol . TType . STRUCT , iprot . readI32 ( ) ) ; struct . dataMovementInterfaces = new ArrayList < org . apache . airavata . model . data . movement . DataMovementInterface > ( _list83 . size ) ; org . apache . airavata . model . data . movement . DataMovementInterface _elem84 ; for ( int _i85 = 0 ; _i85 < _list83 . size ; ++ _i85 ) { _elem84 = new org . apache . airavata . model . data . movement . DataMovementInterface ( ) ; _elem84 . read ( iprot ) ; struct . dataMovementInterfaces . add ( _elem84 ) ; } } struct . setDataMovementInterfacesIsSet ( true ) ; } if ( incoming . get ( 8 ) ) { struct . maxMemoryPerNode = iprot . readI32 ( ) ; struct . setMaxMemoryPerNodeIsSet ( true ) ; } if ( incoming . get ( 9 ) ) { struct . gatewayUsageReporting = iprot . readBool ( ) ; struct . setGatewayUsageReportingIsSet ( true ) ; } if ( incoming . get ( 10 ) ) { struct . gatewayUsageModuleLoadCommand = iprot . readString ( ) ; struct . setGatewayUsageModuleLoadCommandIsSet ( true ) ; } if ( incoming . get ( 11 ) ) { struct . gatewayUsageExecutable = iprot . readString ( ) ; struct . setGatewayUsageExecutableIsSet ( true ) ; } }",Smelly
 private static < S extends org . apache . thrift . scheme . IScheme > S scheme ( org . apache . thrift . protocol . TProtocol proto ) { return ( org . apache . thrift . scheme . StandardScheme . class . equals ( proto . getScheme ( ) ) ? STANDARD_SCHEME_FACTORY : TUPLE_SCHEME_FACTORY ) . getScheme ( ) ; },Smelly
 private static < S extends org . apache . thrift . scheme . IScheme > S scheme ( org . apache . thrift . protocol . TProtocol proto ) { return ( org . apache . thrift . scheme . StandardScheme . class . equals ( proto . getScheme ( ) ) ? STANDARD_SCHEME_FACTORY : TUPLE_SCHEME_FACTORY ) . getScheme ( ) ; },Smelly
" public void read ( org . apache . thrift . protocol . TProtocol prot , IterInfo struct ) throws org . apache . thrift . TException { TTupleProtocol iprot = ( TTupleProtocol ) prot ; BitSet incoming = iprot . readBitSet ( 3 ) ; if ( incoming . get ( 0 ) ) { struct . priority = iprot . readI32 ( ) ; struct . setPriorityIsSet ( true ) ; } if ( incoming . get ( 1 ) ) { struct . className = iprot . readString ( ) ; struct . setClassNameIsSet ( true ) ; } if ( incoming . get ( 2 ) ) { struct . iterName = iprot . readString ( ) ; struct . setIterNameIsSet ( true ) ; } }",Smelly
" public void ignoreNested ( ) { final To to = new To ( ) ; to . name = ""to"" ; final Person from = new Person ( ) ; from . name = ""myname"" ; from . street = ""blastreet 1"" ; from . description = ""gets ignored"" ; to . person = from ; to . persons = singletonList ( from ) ; final Jsonb jsonb = JsonbProvider . provider ( ) . create ( ) . build ( ) ; assertEquals ( ""{\""name\"":\""to\"",\""person\"":{\""name\"":\""myname\""},\""persons\"":[{\""name\"":\""myname\""}]}"" , jsonb . toJson ( to ) ) ; }",No
" public boolean dropVertex ( Vertex < I , V , E > vertex ) { return false ; }",No
" public String [ ] getContext ( Parse [ ] constituents , int index ) { List < String > features = new ArrayList < > ( 100 ) ; int ps = constituents . length ; Collection < Parse > punct2s = null ; Collection < Parse > punct_2s = null ; Parse p_2 = null ; if ( index - 2 >= 0 ) { p_2 = constituents [ index - 2 ] ; } Parse p_1 = null ; if ( index - 1 >= 0 ) { p_1 = constituents [ index - 1 ] ; punct_2s = p_1 . getPreviousPunctuationSet ( ) ; } Parse p0 = constituents [ index ] ; Collection < Parse > punct_1s = p0 . getPreviousPunctuationSet ( ) ; Collection < Parse > punct1s = p0 . getNextPunctuationSet ( ) ; Parse p1 = null ; if ( index + 1 < ps ) { p1 = constituents [ index + 1 ] ; punct2s = p1 . getNextPunctuationSet ( ) ; } Parse p2 = null ; if ( index + 2 < ps ) { p2 = constituents [ index + 2 ] ; } boolean u_2 = true ; boolean u_1 = true ; boolean u0 = true ; boolean u1 = true ; boolean u2 = true ; boolean b_2_1 = true ; boolean b_10 = true ; boolean b01 = true ; boolean b12 = true ; boolean t_2_10 = true ; boolean t_101 = true ; boolean t012 = true ; if ( dict != null ) { if ( p_2 != null ) { unigram [ 0 ] = p_2 . getHead ( ) . getCoveredText ( ) ; u_2 = dict . contains ( new StringList ( unigram ) ) ; } if ( p2 != null ) { unigram [ 0 ] = p2 . getHead ( ) . getCoveredText ( ) ; u2 = dict . contains ( new StringList ( unigram ) ) ; } unigram [ 0 ] = p0 . getHead ( ) . getCoveredText ( ) ; u0 = dict . contains ( new StringList ( unigram ) ) ; if ( p_2 != null && p_1 != null ) { bigram [ 0 ] = p_2 . getHead ( ) . getCoveredText ( ) ; bigram [ 1 ] = p_1 . getHead ( ) . getCoveredText ( ) ; b_2_1 = dict . contains ( new StringList ( bigram ) ) ; trigram [ 0 ] = p_2 . getHead ( ) . getCoveredText ( ) ; trigram [ 1 ] = p_1 . getHead ( ) . getCoveredText ( ) ; trigram [ 2 ] = p0 . getHead ( ) . getCoveredText ( ) ; t_2_10 = dict . contains ( new StringList ( trigram ) ) ; } if ( p_1 != null && p1 != null ) { trigram [ 0 ] = p_1 . getHead ( ) . getCoveredText ( ) ; trigram [ 1 ] = p0 . getHead ( ) . getCoveredText ( ) ; trigram [ 2 ] = p1 . getHead ( ) . getCoveredText ( ) ; t_101 = dict . contains ( new StringList ( trigram ) ) ; } if ( p_1 != null ) { unigram [ 0 ] = p_1 . getHead ( ) . getCoveredText ( ) ; u_1 = dict . contains ( new StringList ( unigram ) ) ; b_2_1 = b_2_1 && u_1 & u_2 ; t_2_10 = t_2_10 && u_1 & u_2 & u0 ; t_101 = t_101 && u_1 & u0 && u1 ; bigram [ 0 ] = p_1 . getHead ( ) . getCoveredText ( ) ; bigram [ 1 ] = p0 . getHead ( ) . getCoveredText ( ) ; b_10 = dict . contains ( new StringList ( bigram ) ) && u_1 && u0 ; } if ( p1 != null && p2 != null ) { bigram [ 0 ] = p1 . getHead ( ) . getCoveredText ( ) ; bigram [ 1 ] = p2 . getHead ( ) . getCoveredText ( ) ; b12 = dict . contains ( new StringList ( bigram ) ) ; trigram [ 0 ] = p0 . getHead ( ) . getCoveredText ( ) ; trigram [ 1 ] = p1 . getHead ( ) . getCoveredText ( ) ; trigram [ 2 ] = p2 . getHead ( ) . getCoveredText ( ) ; t012 = dict . contains ( new StringList ( trigram ) ) ; } if ( p1 != null ) { unigram [ 0 ] = p1 . getHead ( ) . getCoveredText ( ) ; u1 = dict . contains ( new StringList ( unigram ) ) ; b12 = b12 && u1 && u2 ; t012 = t012 && u1 && u2 && u0 ; t_101 = t_101 && u0 && u_1 && u1 ; bigram [ 0 ] = p0 . getHead ( ) . getCoveredText ( ) ; bigram [ 1 ] = p1 . getHead ( ) . getCoveredText ( ) ; b01 = dict . contains ( new StringList ( bigram ) ) ; b01 = b01 && u0 && u1 ; } } String consp_2 = cons ( p_2 , - 2 ) ; String consp_1 = cons ( p_1 , - 1 ) ; String consp0 = cons ( p0 , 0 ) ; String consp1 = cons ( p1 , 1 ) ; String consp2 = cons ( p2 , 2 ) ; String consbop_2 = consbo ( p_2 , - 2 ) ; String consbop_1 = consbo ( p_1 , - 1 ) ; String consbop0 = consbo ( p0 , 0 ) ; String consbop1 = consbo ( p1 , 1 ) ; String consbop2 = consbo ( p2 , 2 ) ; Cons c_2 = new Cons ( consp_2 , consbop_2 , - 2 , u_2 ) ; Cons c_1 = new Cons ( consp_1 , consbop_1 , - 1 , u_1 ) ; Cons c0 = new Cons ( consp0 , consbop0 , 0 , u0 ) ; Cons c1 = new Cons ( consp1 , consbop1 , 1 , u1 ) ; Cons c2 = new Cons ( consp2 , consbop2 , 2 , u2 ) ; features . add ( ""default"" ) ; if ( u0 ) features . add ( consp0 ) ; features . add ( consbop0 ) ; if ( u_2 ) features . add ( consp_2 ) ; features . add ( consbop_2 ) ; if ( u_1 ) features . add ( consp_1 ) ; features . add ( consbop_1 ) ; if ( u1 ) features . add ( consp1 ) ; features . add ( consbop1 ) ; if ( u2 ) features . add ( consp2 ) ; features . add ( consbop2 ) ; cons2 ( features , c0 , c1 , punct1s , b01 ) ; cons2 ( features , c_1 , c0 , punct_1s , b_10 ) ; cons3 ( features , c0 , c1 , c2 , punct1s , punct2s , t012 , b01 , b12 ) ; cons3 ( features , c_2 , c_1 , c0 , punct_2s , punct_1s , t_2_10 , b_2_1 , b_10 ) ; cons3 ( features , c_1 , c0 , c1 , punct_1s , punct1s , t_101 , b_10 , b01 ) ; String p0Tag = p0 . getType ( ) ; if ( p0Tag . equals ( ""-RRB-"" ) ) { for ( int pi = index - 1 ; pi >= 0 ; pi -- ) { Parse p = constituents [ pi ] ; if ( p . getType ( ) . equals ( ""-LRB-"" ) ) { features . add ( ""bracketsmatch"" ) ; break ; } if ( p . getLabel ( ) . startsWith ( Parser . START ) ) { break ; } } } if ( p0Tag . equals ( ""-RCB-"" ) ) { for ( int pi = index - 1 ; pi >= 0 ; pi -- ) { Parse p = constituents [ pi ] ; if ( p . getType ( ) . equals ( ""-LCB-"" ) ) { features . add ( ""bracketsmatch"" ) ; break ; } if ( p . getLabel ( ) . startsWith ( Parser . START ) ) { break ; } } } if ( p0Tag . equals ( ""''"" ) ) { for ( int pi = index - 1 ; pi >= 0 ; pi -- ) { Parse p = constituents [ pi ] ; if ( p . getType ( ) . equals ( ""``"" ) ) { features . add ( ""quotesmatch"" ) ; break ; } if ( p . getLabel ( ) . startsWith ( Parser . START ) ) { break ; } } } if ( p0Tag . equals ( ""'"" ) ) { for ( int pi = index - 1 ; pi >= 0 ; pi -- ) { Parse p = constituents [ pi ] ; if ( p . getType ( ) . equals ( ""`"" ) ) { features . add ( ""quotesmatch"" ) ; break ; } if ( p . getLabel ( ) . startsWith ( Parser . START ) ) { break ; } } } if ( p0Tag . equals ( "","" ) ) { for ( int pi = index - 1 ; pi >= 0 ; pi -- ) { Parse p = constituents [ pi ] ; if ( p . getType ( ) . equals ( "","" ) ) { features . add ( ""iscomma"" ) ; break ; } if ( p . getLabel ( ) . startsWith ( Parser . START ) ) { break ; } } } if ( p0Tag . equals ( ""."" ) && index == ps - 1 ) { for ( int pi = index - 1 ; pi >= 0 ; pi -- ) { Parse p = constituents [ pi ] ; if ( p . getLabel ( ) . startsWith ( Parser . START ) ) { if ( pi == 0 ) { features . add ( ""endofsentence"" ) ; } break ; } } } return features . toArray ( new String [ features . size ( ) ] ) ; }",Smelly
" public void read ( org . apache . thrift . protocol . TProtocol prot , checkNamespaceClass_result struct ) throws org . apache . thrift . TException { TTupleProtocol iprot = ( TTupleProtocol ) prot ; BitSet incoming = iprot . readBitSet ( 3 ) ; if ( incoming . get ( 0 ) ) { struct . success = iprot . readBool ( ) ; struct . setSuccessIsSet ( true ) ; } if ( incoming . get ( 1 ) ) { struct . sec = new ThriftSecurityException ( ) ; struct . sec . read ( iprot ) ; struct . setSecIsSet ( true ) ; } if ( incoming . get ( 2 ) ) { struct . tope = new ThriftTableOperationException ( ) ; struct . tope . read ( iprot ) ; struct . setTopeIsSet ( true ) ; } }",No
" public void read ( org . apache . thrift . protocol . TProtocol prot , getChildDataProducts_result struct ) throws org . apache . thrift . TException { TTupleProtocol iprot = ( TTupleProtocol ) prot ; BitSet incoming = iprot . readBitSet ( 5 ) ; if ( incoming . get ( 0 ) ) { { org . apache . thrift . protocol . TList _list283 = new org . apache . thrift . protocol . TList ( org . apache . thrift . protocol . TType . STRUCT , iprot . readI32 ( ) ) ; struct . success = new ArrayList < org . apache . airavata . model . data . replica . DataProductModel > ( _list283 . size ) ; org . apache . airavata . model . data . replica . DataProductModel _elem284 ; for ( int _i285 = 0 ; _i285 < _list283 . size ; ++ _i285 ) { _elem284 = new org . apache . airavata . model . data . replica . DataProductModel ( ) ; _elem284 . read ( iprot ) ; struct . success . add ( _elem284 ) ; } } struct . setSuccessIsSet ( true ) ; } if ( incoming . get ( 1 ) ) { struct . ire = new org . apache . airavata . model . error . InvalidRequestException ( ) ; struct . ire . read ( iprot ) ; struct . setIreIsSet ( true ) ; } if ( incoming . get ( 2 ) ) { struct . ace = new org . apache . airavata . model . error . AiravataClientException ( ) ; struct . ace . read ( iprot ) ; struct . setAceIsSet ( true ) ; } if ( incoming . get ( 3 ) ) { struct . ase = new org . apache . airavata . model . error . AiravataSystemException ( ) ; struct . ase . read ( iprot ) ; struct . setAseIsSet ( true ) ; } if ( incoming . get ( 4 ) ) { struct . ae = new org . apache . airavata . model . error . AuthorizationException ( ) ; struct . ae . read ( iprot ) ; struct . setAeIsSet ( true ) ; } }",Smelly
" public void read ( org . apache . thrift . protocol . TProtocol prot , TFetchResultsReq struct ) throws org . apache . thrift . TException { TTupleProtocol iprot = ( TTupleProtocol ) prot ; struct . operationHandle = new TOperationHandle ( ) ; struct . operationHandle . read ( iprot ) ; struct . setOperationHandleIsSet ( true ) ; struct . orientation = TFetchOrientation . findByValue ( iprot . readI32 ( ) ) ; struct . setOrientationIsSet ( true ) ; struct . maxRows = iprot . readI64 ( ) ; struct . setMaxRowsIsSet ( true ) ; }",Smelly
" public void handle ( Callback [ ] callbacks ) throws IOException , UnsupportedCallbackException { for ( int i = 0 ; i < callbacks . length ; i ++ ) { if ( callbacks [ i ] instanceof PasswordCallback ) { PasswordCallback pc = ( PasswordCallback ) callbacks [ i ] ; if ( pc . getPrompt ( ) . contains ( principal ) ) { pc . setPassword ( password . toCharArray ( ) ) ; break ; } } } }",No
 public void setCommand ( String command ) { this . command = command ; },No
" public void read ( org . apache . thrift . protocol . TProtocol prot , getChildDataProducts_result struct ) throws org . apache . thrift . TException { TTupleProtocol iprot = ( TTupleProtocol ) prot ; BitSet incoming = iprot . readBitSet ( 5 ) ; if ( incoming . get ( 0 ) ) { { org . apache . thrift . protocol . TList _list283 = new org . apache . thrift . protocol . TList ( org . apache . thrift . protocol . TType . STRUCT , iprot . readI32 ( ) ) ; struct . success = new ArrayList < org . apache . airavata . model . data . replica . DataProductModel > ( _list283 . size ) ; org . apache . airavata . model . data . replica . DataProductModel _elem284 ; for ( int _i285 = 0 ; _i285 < _list283 . size ; ++ _i285 ) { _elem284 = new org . apache . airavata . model . data . replica . DataProductModel ( ) ; _elem284 . read ( iprot ) ; struct . success . add ( _elem284 ) ; } } struct . setSuccessIsSet ( true ) ; } if ( incoming . get ( 1 ) ) { struct . ire = new org . apache . airavata . model . error . InvalidRequestException ( ) ; struct . ire . read ( iprot ) ; struct . setIreIsSet ( true ) ; } if ( incoming . get ( 2 ) ) { struct . ace = new org . apache . airavata . model . error . AiravataClientException ( ) ; struct . ace . read ( iprot ) ; struct . setAceIsSet ( true ) ; } if ( incoming . get ( 3 ) ) { struct . ase = new org . apache . airavata . model . error . AiravataSystemException ( ) ; struct . ase . read ( iprot ) ; struct . setAseIsSet ( true ) ; } if ( incoming . get ( 4 ) ) { struct . ae = new org . apache . airavata . model . error . AuthorizationException ( ) ; struct . ae . read ( iprot ) ; struct . setAeIsSet ( true ) ; } }",Smelly
" protected void readState ( ObjectInputStream in ) throws IOException , ClassNotFoundException { super . readState ( in ) ; this . toDependent = in . readObject ( ) ; }",No
" public void runAsyncFailure ( ) throws Exception { final String testMessage = ""this is just a test"" ; CompletionStage < Void > sideEffectFuture = MoreFutures . runAsync ( ( ) -> { throw new IllegalStateException ( testMessage ) ; } ) ; thrown . expect ( ExecutionException . class ) ; thrown . expectCause ( isA ( IllegalStateException . class ) ) ; thrown . expectMessage ( testMessage ) ; MoreFutures . get ( sideEffectFuture ) ; }",No
" public void read ( org . apache . thrift . protocol . TProtocol prot , getChildDataProducts_result struct ) throws org . apache . thrift . TException { TTupleProtocol iprot = ( TTupleProtocol ) prot ; BitSet incoming = iprot . readBitSet ( 5 ) ; if ( incoming . get ( 0 ) ) { { org . apache . thrift . protocol . TList _list283 = new org . apache . thrift . protocol . TList ( org . apache . thrift . protocol . TType . STRUCT , iprot . readI32 ( ) ) ; struct . success = new ArrayList < org . apache . airavata . model . data . replica . DataProductModel > ( _list283 . size ) ; org . apache . airavata . model . data . replica . DataProductModel _elem284 ; for ( int _i285 = 0 ; _i285 < _list283 . size ; ++ _i285 ) { _elem284 = new org . apache . airavata . model . data . replica . DataProductModel ( ) ; _elem284 . read ( iprot ) ; struct . success . add ( _elem284 ) ; } } struct . setSuccessIsSet ( true ) ; } if ( incoming . get ( 1 ) ) { struct . ire = new org . apache . airavata . model . error . InvalidRequestException ( ) ; struct . ire . read ( iprot ) ; struct . setIreIsSet ( true ) ; } if ( incoming . get ( 2 ) ) { struct . ace = new org . apache . airavata . model . error . AiravataClientException ( ) ; struct . ace . read ( iprot ) ; struct . setAceIsSet ( true ) ; } if ( incoming . get ( 3 ) ) { struct . ase = new org . apache . airavata . model . error . AiravataSystemException ( ) ; struct . ase . read ( iprot ) ; struct . setAseIsSet ( true ) ; } if ( incoming . get ( 4 ) ) { struct . ae = new org . apache . airavata . model . error . AuthorizationException ( ) ; struct . ae . read ( iprot ) ; struct . setAeIsSet ( true ) ; } }",Smelly
 public boolean process ( byte value ) throws Exception { return delimiter != value ; },No
" public void read ( org . apache . thrift . protocol . TProtocol prot , ScanResult struct ) throws org . apache . thrift . TException { TTupleProtocol iprot = ( TTupleProtocol ) prot ; BitSet incoming = iprot . readBitSet ( 2 ) ; if ( incoming . get ( 0 ) ) { { org . apache . thrift . protocol . TList _list13 = new org . apache . thrift . protocol . TList ( org . apache . thrift . protocol . TType . STRUCT , iprot . readI32 ( ) ) ; struct . results = new ArrayList < KeyValue > ( _list13 . size ) ; for ( int _i14 = 0 ; _i14 < _list13 . size ; ++ _i14 ) { KeyValue _elem15 ; _elem15 = new KeyValue ( ) ; _elem15 . read ( iprot ) ; struct . results . add ( _elem15 ) ; } } struct . setResultsIsSet ( true ) ; } if ( incoming . get ( 1 ) ) { struct . more = iprot . readBool ( ) ; struct . setMoreIsSet ( true ) ; } }",Smelly
" public void read ( org . apache . thrift . protocol . TProtocol prot , getActiveLogs_result struct ) throws org . apache . thrift . TException { TTupleProtocol iprot = ( TTupleProtocol ) prot ; BitSet incoming = iprot . readBitSet ( 1 ) ; if ( incoming . get ( 0 ) ) { { org . apache . thrift . protocol . TList _list327 = new org . apache . thrift . protocol . TList ( org . apache . thrift . protocol . TType . STRING , iprot . readI32 ( ) ) ; struct . success = new ArrayList < String > ( _list327 . size ) ; for ( int _i328 = 0 ; _i328 < _list327 . size ; ++ _i328 ) { String _elem329 ; _elem329 = iprot . readString ( ) ; struct . success . add ( _elem329 ) ; } } struct . setSuccessIsSet ( true ) ; } }",Smelly
 protected NodeState getConfigurationNodeState ( ) { return configurationNodeState ; },No
" public void read ( org . apache . thrift . protocol . TProtocol prot , getChildDataProducts_result struct ) throws org . apache . thrift . TException { TTupleProtocol iprot = ( TTupleProtocol ) prot ; BitSet incoming = iprot . readBitSet ( 5 ) ; if ( incoming . get ( 0 ) ) { { org . apache . thrift . protocol . TList _list283 = new org . apache . thrift . protocol . TList ( org . apache . thrift . protocol . TType . STRUCT , iprot . readI32 ( ) ) ; struct . success = new ArrayList < org . apache . airavata . model . data . replica . DataProductModel > ( _list283 . size ) ; org . apache . airavata . model . data . replica . DataProductModel _elem284 ; for ( int _i285 = 0 ; _i285 < _list283 . size ; ++ _i285 ) { _elem284 = new org . apache . airavata . model . data . replica . DataProductModel ( ) ; _elem284 . read ( iprot ) ; struct . success . add ( _elem284 ) ; } } struct . setSuccessIsSet ( true ) ; } if ( incoming . get ( 1 ) ) { struct . ire = new org . apache . airavata . model . error . InvalidRequestException ( ) ; struct . ire . read ( iprot ) ; struct . setIreIsSet ( true ) ; } if ( incoming . get ( 2 ) ) { struct . ace = new org . apache . airavata . model . error . AiravataClientException ( ) ; struct . ace . read ( iprot ) ; struct . setAceIsSet ( true ) ; } if ( incoming . get ( 3 ) ) { struct . ase = new org . apache . airavata . model . error . AiravataSystemException ( ) ; struct . ase . read ( iprot ) ; struct . setAseIsSet ( true ) ; } if ( incoming . get ( 4 ) ) { struct . ae = new org . apache . airavata . model . error . AuthorizationException ( ) ; struct . ae . read ( iprot ) ; struct . setAeIsSet ( true ) ; } }",Smelly
 private void dumpAttribute ( Attribute attribute ) throws IOException { out . writeShort ( attribute . attribute_name_index ) ; out . writeInt ( attribute . attribute_length ) ; switch ( attribute . attribute_tag ) { case Constants . ATTRIBUTE_SourceFile : out . writeShort ( ( ( Attribute_SourceFile ) attribute ) . sourcefile_index ) ; break ; case Constants . ATTRIBUTE_ConstantValue : out . writeShort ( ( ( Attribute_ConstantValue ) attribute ) . constant_value_index ) ; break ; case Constants . ATTRIBUTE_Code : Attribute_Code code = ( Attribute_Code ) attribute ; byte [ ] [ ] operands ; out . writeShort ( code . max_stack ) ; out . writeShort ( code . max_locals ) ; out . writeInt ( code . code_length ) ; Attribute_Code . Opcode op ; for ( int i = 0 ; i < code . codes . length ; i ++ ) { op = code . codes [ i ] ; out . writeByte ( op . opcode ) ; operands = op . operands ; if ( operands != null && operands . length != 0 ) { for ( int j = 0 ; j < operands . length ; j ++ ) { if ( operands [ j ] != null ) { out . write ( operands [ j ] ) ; } } } } out . writeShort ( code . exception_table_length ) ; Attribute_Code . ExceptionTableItem exc ; for ( int i = 0 ; i < code . exception_table_length ; i ++ ) { exc = code . exception_table [ i ] ; out . writeShort ( exc . start_pc ) ; out . writeShort ( exc . end_pc ) ; out . writeShort ( exc . handler_pc ) ; out . writeShort ( exc . catch_type ) ; } out . writeShort ( code . attributes_count ) ; for ( int i = 0 ; i < code . attributes_count ; i ++ ) { dumpAttribute ( code . attributes [ i ] ) ; } break ; case Constants . ATTRIBUTE_Exceptions : Attribute_Exceptions excep = ( Attribute_Exceptions ) attribute ; out . writeShort ( excep . number_of_exceptions ) ; for ( int i = 0 ; i < excep . number_of_exceptions ; i ++ ) { out . writeShort ( excep . exception_index_table [ i ] ) ; } break ; case Constants . ATTRIBUTE_InnerClasses : Attribute_InnerClasses innerClasses = ( Attribute_InnerClasses ) attribute ; Attribute_InnerClasses . InnerClass cla ; out . writeShort ( innerClasses . number_of_classes ) ; for ( int i = 0 ; i < innerClasses . number_of_classes ; i ++ ) { cla = innerClasses . innerClasses [ i ] ; out . writeShort ( cla . inner_class_info_index ) ; out . writeShort ( cla . outer_class_info_index ) ; out . writeShort ( cla . inner_name_index ) ; out . writeShort ( cla . inner_class_access_flags ) ; } break ; case Constants . ATTRIBUTE_Deprecated : case Constants . ATTRIBUTE_Synthetic : break ; case Constants . ATTRIBUTE_LineNumberTable : break ; case Constants . ATTRIBUTE_LocalVariableTable : Attribute_LocalVariableTable lvt = ( Attribute_LocalVariableTable ) attribute ; Attribute_LocalVariableTable . LocalVariable lv ; out . writeShort ( lvt . local_variable_table_length ) ; for ( int i = 0 ; i < lvt . local_variable_table_length ; i ++ ) { lv = lvt . local_variable_table [ i ] ; out . writeShort ( lv . start_pc ) ; out . writeShort ( lv . length ) ; out . writeShort ( lv . name_index ) ; out . writeShort ( lv . descriptor_index ) ; out . writeShort ( lv . index ) ; } break ; } },Smelly
" public void read ( org . apache . thrift . protocol . TProtocol prot , show_compact_result struct ) throws org . apache . thrift . TException { TTupleProtocol iprot = ( TTupleProtocol ) prot ; BitSet incoming = iprot . readBitSet ( 1 ) ; if ( incoming . get ( 0 ) ) { struct . success = new ShowCompactResponse ( ) ; struct . success . read ( iprot ) ; struct . setSuccessIsSet ( true ) ; } }",Smelly
" public com . google . protobuf . ExtensionRegistry assignDescriptors ( com . google . protobuf . Descriptors . FileDescriptor root ) { descriptor = root ; internal_static_CreateTableRequest_descriptor = getDescriptor ( ) . getMessageTypes ( ) . get ( 0 ) ; internal_static_CreateTableRequest_fieldAccessorTable = new com . google . protobuf . GeneratedMessage . FieldAccessorTable ( internal_static_CreateTableRequest_descriptor , new java . lang . String [ ] { ""TableName"" , ""ColumnFamilies"" , } ) ; internal_static_CreateTableResponse_descriptor = getDescriptor ( ) . getMessageTypes ( ) . get ( 1 ) ; internal_static_CreateTableResponse_fieldAccessorTable = new com . google . protobuf . GeneratedMessage . FieldAccessorTable ( internal_static_CreateTableResponse_descriptor , new java . lang . String [ ] { } ) ; internal_static_DropTableRequest_descriptor = getDescriptor ( ) . getMessageTypes ( ) . get ( 2 ) ; internal_static_DropTableRequest_fieldAccessorTable = new com . google . protobuf . GeneratedMessage . FieldAccessorTable ( internal_static_DropTableRequest_descriptor , new java . lang . String [ ] { ""TableName"" , } ) ; internal_static_DropTableResponse_descriptor = getDescriptor ( ) . getMessageTypes ( ) . get ( 3 ) ; internal_static_DropTableResponse_fieldAccessorTable = new com . google . protobuf . GeneratedMessage . FieldAccessorTable ( internal_static_DropTableResponse_descriptor , new java . lang . String [ ] { } ) ; internal_static_BeginWriteTransactionRequest_descriptor = getDescriptor ( ) . getMessageTypes ( ) . get ( 4 ) ; internal_static_BeginWriteTransactionRequest_fieldAccessorTable = new com . google . protobuf . GeneratedMessage . FieldAccessorTable ( internal_static_BeginWriteTransactionRequest_descriptor , new java . lang . String [ ] { ""TableName"" , ""KeepAlive"" , ""ColumnFamilies"" , } ) ; internal_static_BeginWriteTransactionResponse_descriptor = getDescriptor ( ) . getMessageTypes ( ) . get ( 5 ) ; internal_static_BeginWriteTransactionResponse_fieldAccessorTable = new com . google . protobuf . GeneratedMessage . FieldAccessorTable ( internal_static_BeginWriteTransactionResponse_descriptor , new java . lang . String [ ] { ""Transaction"" , } ) ; internal_static_CommitWriteTransactionRequest_descriptor = getDescriptor ( ) . getMessageTypes ( ) . get ( 6 ) ; internal_static_CommitWriteTransactionRequest_fieldAccessorTable = new com . google . protobuf . GeneratedMessage . FieldAccessorTable ( internal_static_CommitWriteTransactionRequest_descriptor , new java . lang . String [ ] { ""Transaction"" , } ) ; internal_static_CommitWriteTransactionResponse_descriptor = getDescriptor ( ) . getMessageTypes ( ) . get ( 7 ) ; internal_static_CommitWriteTransactionResponse_fieldAccessorTable = new com . google . protobuf . GeneratedMessage . FieldAccessorTable ( internal_static_CommitWriteTransactionResponse_descriptor , new java . lang . String [ ] { } ) ; internal_static_AbortWriteTransactionRequest_descriptor = getDescriptor ( ) . getMessageTypes ( ) . get ( 8 ) ; internal_static_AbortWriteTransactionRequest_fieldAccessorTable = new com . google . protobuf . GeneratedMessage . FieldAccessorTable ( internal_static_AbortWriteTransactionRequest_descriptor , new java . lang . String [ ] { ""Transaction"" , } ) ; internal_static_AbortWriteTransactionResponse_descriptor = getDescriptor ( ) . getMessageTypes ( ) . get ( 9 ) ; internal_static_AbortWriteTransactionResponse_fieldAccessorTable = new com . google . protobuf . GeneratedMessage . FieldAccessorTable ( internal_static_AbortWriteTransactionResponse_descriptor , new java . lang . String [ ] { } ) ; internal_static_GetAbortedWriteTransactionsRequest_descriptor = getDescriptor ( ) . getMessageTypes ( ) . get ( 10 ) ; internal_static_GetAbortedWriteTransactionsRequest_fieldAccessorTable = new com . google . protobuf . GeneratedMessage . FieldAccessorTable ( internal_static_GetAbortedWriteTransactionsRequest_descriptor , new java . lang . String [ ] { ""TableName"" , ""ColumnFamily"" , } ) ; internal_static_GetAbortedWriteTransactionsResponse_descriptor = getDescriptor ( ) . getMessageTypes ( ) . get ( 11 ) ; internal_static_GetAbortedWriteTransactionsResponse_fieldAccessorTable = new com . google . protobuf . GeneratedMessage . FieldAccessorTable ( internal_static_GetAbortedWriteTransactionsResponse_descriptor , new java . lang . String [ ] { ""FamilyRevisions"" , } ) ; internal_static_CreateSnapshotRequest_descriptor = getDescriptor ( ) . getMessageTypes ( ) . get ( 12 ) ; internal_static_CreateSnapshotRequest_fieldAccessorTable = new com . google . protobuf . GeneratedMessage . FieldAccessorTable ( internal_static_CreateSnapshotRequest_descriptor , new java . lang . String [ ] { ""TableName"" , ""Revision"" , } ) ; internal_static_CreateSnapshotResponse_descriptor = getDescriptor ( ) . getMessageTypes ( ) . get ( 13 ) ; internal_static_CreateSnapshotResponse_fieldAccessorTable = new com . google . protobuf . GeneratedMessage . FieldAccessorTable ( internal_static_CreateSnapshotResponse_descriptor , new java . lang . String [ ] { ""TableSnapshot"" , } ) ; internal_static_KeepAliveTransactionRequest_descriptor = getDescriptor ( ) . getMessageTypes ( ) . get ( 14 ) ; internal_static_KeepAliveTransactionRequest_fieldAccessorTable = new com . google . protobuf . GeneratedMessage . FieldAccessorTable ( internal_static_KeepAliveTransactionRequest_descriptor , new java . lang . String [ ] { ""Transaction"" , } ) ; internal_static_KeepAliveTransactionResponse_descriptor = getDescriptor ( ) . getMessageTypes ( ) . get ( 15 ) ; internal_static_KeepAliveTransactionResponse_fieldAccessorTable = new com . google . protobuf . GeneratedMessage . FieldAccessorTable ( internal_static_KeepAliveTransactionResponse_descriptor , new java . lang . String [ ] { } ) ; internal_static_FamilyRevision_descriptor = getDescriptor ( ) . getMessageTypes ( ) . get ( 16 ) ; internal_static_FamilyRevision_fieldAccessorTable = new com . google . protobuf . GeneratedMessage . FieldAccessorTable ( internal_static_FamilyRevision_descriptor , new java . lang . String [ ] { ""Revision"" , ""Timestamp"" , } ) ; internal_static_Transaction_descriptor = getDescriptor ( ) . getMessageTypes ( ) . get ( 17 ) ; internal_static_Transaction_fieldAccessorTable = new com . google . protobuf . GeneratedMessage . FieldAccessorTable ( internal_static_Transaction_descriptor , new java . lang . String [ ] { ""TableName"" , ""TimeStamp"" , ""KeepAlive"" , ""Revision"" , ""ColumnFamilies"" , } ) ; internal_static_TableSnapshot_descriptor = getDescriptor ( ) . getMessageTypes ( ) . get ( 18 ) ; internal_static_TableSnapshot_fieldAccessorTable = new com . google . protobuf . GeneratedMessage . FieldAccessorTable ( internal_static_TableSnapshot_descriptor , new java . lang . String [ ] { ""TableName"" , ""LatestRevision"" , ""ColumnFamilyRevision"" , } ) ; internal_static_TableSnapshot_ColumnFamilyRevision_descriptor = internal_static_TableSnapshot_descriptor . getNestedTypes ( ) . get ( 0 ) ; internal_static_TableSnapshot_ColumnFamilyRevision_fieldAccessorTable = new com . google . protobuf . GeneratedMessage . FieldAccessorTable ( internal_static_TableSnapshot_ColumnFamilyRevision_descriptor , new java . lang . String [ ] { ""Key"" , ""Value"" , } ) ; return null ; }",No
" private Expression normalize ( SqlTypeName typeName , Expression e ) { switch ( typeName ) { case TIME : return Expressions . call ( BuiltInMethod . FLOOR_MOD . method , e , Expressions . constant ( DateTimeUtils . MILLIS_PER_DAY ) ) ; default : return e ; } }",Smelly
" public void read ( org . apache . thrift . protocol . TProtocol prot , SCPDataMovement struct ) throws org . apache . thrift . TException { TTupleProtocol iprot = ( TTupleProtocol ) prot ; struct . dataMovementInterfaceId = iprot . readString ( ) ; struct . setDataMovementInterfaceIdIsSet ( true ) ; struct . securityProtocol = org . apache . airavata . model . data . movement . SecurityProtocol . findByValue ( iprot . readI32 ( ) ) ; struct . setSecurityProtocolIsSet ( true ) ; BitSet incoming = iprot . readBitSet ( 2 ) ; if ( incoming . get ( 0 ) ) { struct . alternativeSCPHostName = iprot . readString ( ) ; struct . setAlternativeSCPHostNameIsSet ( true ) ; } if ( incoming . get ( 1 ) ) { struct . sshPort = iprot . readI32 ( ) ; struct . setSshPortIsSet ( true ) ; } }",Smelly
" public boolean isValid ( final PlainAttrValue object , final ConstraintValidatorContext context ) { boolean isValid ; if ( object == null ) { isValid = true ; } else { int nonNullVales = 0 ; if ( object . getBooleanValue ( ) != null ) { nonNullVales ++ ; } if ( object . getDateValue ( ) != null ) { nonNullVales ++ ; } if ( object . getDoubleValue ( ) != null ) { nonNullVales ++ ; } if ( object . getLongValue ( ) != null ) { nonNullVales ++ ; } if ( object . getBinaryValue ( ) != null ) { nonNullVales ++ ; } if ( object . getStringValue ( ) != null ) { nonNullVales ++ ; } isValid = nonNullVales == 1 ; if ( ! isValid ) { LOG . error ( ""More than one non-null value for "" + object ) ; context . disableDefaultConstraintViolation ( ) ; context . buildConstraintViolationWithTemplate ( getTemplate ( EntityViolationType . MoreThanOneNonNull , ""More than one non-null value found"" ) ) . addPropertyNode ( object . getClass ( ) . getSimpleName ( ) . replaceAll ( ""\\n"" , "" "" ) ) . addConstraintViolation ( ) ; } else if ( object instanceof PlainAttrUniqueValue ) { PlainSchema uniqueValueSchema = ( ( PlainAttrUniqueValue ) object ) . getSchema ( ) ; PlainSchema attrSchema = object . getAttr ( ) . getSchema ( ) ; isValid = uniqueValueSchema . equals ( attrSchema ) ; if ( ! isValid ) { LOG . error ( ""Unique value schema for "" + object . getClass ( ) . getSimpleName ( ) + ""["" + object . getKey ( ) + ""]"" + "" is "" + uniqueValueSchema + "", while owning attribute schema is "" + attrSchema ) ; context . disableDefaultConstraintViolation ( ) ; context . buildConstraintViolationWithTemplate ( getTemplate ( EntityViolationType . InvalidPlainAttr , ""Unique value schema is "" + uniqueValueSchema + "", while owning attribute schema is "" + attrSchema ) ) . addPropertyNode ( ""schema"" ) . addConstraintViolation ( ) ; } } } return isValid ; }",Smelly
 public void setNestConfig ( TestClass5 nestConfig ) { this . nestConfig = nestConfig ; },No
 private int getResponseCode ( ResponseStyle style ) { int code ; if ( style == ResponseStyle . BACK_CHANNEL ) { code = HttpURLConnection . HTTP_OK ; } else if ( style == ResponseStyle . BACK_CHANNEL_ERROR ) { code = HttpURLConnection . HTTP_BAD_REQUEST ; } else { code = HttpURLConnection . HTTP_ACCEPTED ; } return code ; },No
" public void read ( org . apache . thrift . protocol . TProtocol prot , getFollowing_result struct ) throws org . apache . thrift . TException { TTupleProtocol iprot = ( TTupleProtocol ) prot ; BitSet incoming = iprot . readBitSet ( 1 ) ; if ( incoming . get ( 0 ) ) { struct . success = new Key ( ) ; struct . success . read ( iprot ) ; struct . setSuccessIsSet ( true ) ; } }",Smelly
" public void read ( org . apache . thrift . protocol . TProtocol prot , getChildDataProducts_result struct ) throws org . apache . thrift . TException { TTupleProtocol iprot = ( TTupleProtocol ) prot ; BitSet incoming = iprot . readBitSet ( 5 ) ; if ( incoming . get ( 0 ) ) { { org . apache . thrift . protocol . TList _list283 = new org . apache . thrift . protocol . TList ( org . apache . thrift . protocol . TType . STRUCT , iprot . readI32 ( ) ) ; struct . success = new ArrayList < org . apache . airavata . model . data . replica . DataProductModel > ( _list283 . size ) ; org . apache . airavata . model . data . replica . DataProductModel _elem284 ; for ( int _i285 = 0 ; _i285 < _list283 . size ; ++ _i285 ) { _elem284 = new org . apache . airavata . model . data . replica . DataProductModel ( ) ; _elem284 . read ( iprot ) ; struct . success . add ( _elem284 ) ; } } struct . setSuccessIsSet ( true ) ; } if ( incoming . get ( 1 ) ) { struct . ire = new org . apache . airavata . model . error . InvalidRequestException ( ) ; struct . ire . read ( iprot ) ; struct . setIreIsSet ( true ) ; } if ( incoming . get ( 2 ) ) { struct . ace = new org . apache . airavata . model . error . AiravataClientException ( ) ; struct . ace . read ( iprot ) ; struct . setAceIsSet ( true ) ; } if ( incoming . get ( 3 ) ) { struct . ase = new org . apache . airavata . model . error . AiravataSystemException ( ) ; struct . ase . read ( iprot ) ; struct . setAseIsSet ( true ) ; } if ( incoming . get ( 4 ) ) { struct . ae = new org . apache . airavata . model . error . AuthorizationException ( ) ; struct . ae . read ( iprot ) ; struct . setAeIsSet ( true ) ; } }",Smelly
" public void fromGoodConfig ( ) { ExpiringCredentialRefreshConfig expiringCredentialRefreshConfig = new ExpiringCredentialRefreshConfig ( new ConfigDef ( ) . withClientSaslSupport ( ) . parse ( Collections . emptyMap ( ) ) , true ) ; assertEquals ( Double . valueOf ( SaslConfigs . DEFAULT_LOGIN_REFRESH_WINDOW_FACTOR ) , Double . valueOf ( expiringCredentialRefreshConfig . loginRefreshWindowFactor ( ) ) ) ; assertEquals ( Double . valueOf ( SaslConfigs . DEFAULT_LOGIN_REFRESH_WINDOW_JITTER ) , Double . valueOf ( expiringCredentialRefreshConfig . loginRefreshWindowJitter ( ) ) ) ; assertEquals ( Short . valueOf ( SaslConfigs . DEFAULT_LOGIN_REFRESH_MIN_PERIOD_SECONDS ) , Short . valueOf ( expiringCredentialRefreshConfig . loginRefreshMinPeriodSeconds ( ) ) ) ; assertEquals ( Short . valueOf ( SaslConfigs . DEFAULT_LOGIN_REFRESH_BUFFER_SECONDS ) , Short . valueOf ( expiringCredentialRefreshConfig . loginRefreshBufferSeconds ( ) ) ) ; assertTrue ( expiringCredentialRefreshConfig . loginRefreshReloginAllowedBeforeLogout ( ) ) ; }",No
 public Schema getSchema ( ) { return schema ; },Smelly
" public void read ( org . apache . thrift . protocol . TProtocol prot , getFollowing_result struct ) throws org . apache . thrift . TException { TTupleProtocol iprot = ( TTupleProtocol ) prot ; BitSet incoming = iprot . readBitSet ( 1 ) ; if ( incoming . get ( 0 ) ) { struct . success = new Key ( ) ; struct . success . read ( iprot ) ; struct . setSuccessIsSet ( true ) ; } }",Smelly
 protected boolean skip ( Object event ) { return false ; },No
 public byte [ ] bytes ( ) { return EMPTY ; },No
" public void read ( org . apache . thrift . protocol . TProtocol prot , getChildDataProducts_result struct ) throws org . apache . thrift . TException { TTupleProtocol iprot = ( TTupleProtocol ) prot ; BitSet incoming = iprot . readBitSet ( 5 ) ; if ( incoming . get ( 0 ) ) { { org . apache . thrift . protocol . TList _list283 = new org . apache . thrift . protocol . TList ( org . apache . thrift . protocol . TType . STRUCT , iprot . readI32 ( ) ) ; struct . success = new ArrayList < org . apache . airavata . model . data . replica . DataProductModel > ( _list283 . size ) ; org . apache . airavata . model . data . replica . DataProductModel _elem284 ; for ( int _i285 = 0 ; _i285 < _list283 . size ; ++ _i285 ) { _elem284 = new org . apache . airavata . model . data . replica . DataProductModel ( ) ; _elem284 . read ( iprot ) ; struct . success . add ( _elem284 ) ; } } struct . setSuccessIsSet ( true ) ; } if ( incoming . get ( 1 ) ) { struct . ire = new org . apache . airavata . model . error . InvalidRequestException ( ) ; struct . ire . read ( iprot ) ; struct . setIreIsSet ( true ) ; } if ( incoming . get ( 2 ) ) { struct . ace = new org . apache . airavata . model . error . AiravataClientException ( ) ; struct . ace . read ( iprot ) ; struct . setAceIsSet ( true ) ; } if ( incoming . get ( 3 ) ) { struct . ase = new org . apache . airavata . model . error . AiravataSystemException ( ) ; struct . ase . read ( iprot ) ; struct . setAseIsSet ( true ) ; } if ( incoming . get ( 4 ) ) { struct . ae = new org . apache . airavata . model . error . AuthorizationException ( ) ; struct . ae . read ( iprot ) ; struct . setAeIsSet ( true ) ; } }",Smelly
" public void read ( org . apache . thrift . protocol . TProtocol prot , getFollowing_result struct ) throws org . apache . thrift . TException { TTupleProtocol iprot = ( TTupleProtocol ) prot ; BitSet incoming = iprot . readBitSet ( 1 ) ; if ( incoming . get ( 0 ) ) { struct . success = new Key ( ) ; struct . success . read ( iprot ) ; struct . setSuccessIsSet ( true ) ; } }",Smelly
" public void read ( org . apache . thrift . protocol . TProtocol prot , RemoteInterpreterResult struct ) throws org . apache . thrift . TException { TTupleProtocol iprot = ( TTupleProtocol ) prot ; BitSet incoming = iprot . readBitSet ( 4 ) ; if ( incoming . get ( 0 ) ) { struct . code = iprot . readString ( ) ; struct . setCodeIsSet ( true ) ; } if ( incoming . get ( 1 ) ) { { org . apache . thrift . protocol . TList _list5 = new org . apache . thrift . protocol . TList ( org . apache . thrift . protocol . TType . STRUCT , iprot . readI32 ( ) ) ; struct . msg = new ArrayList < RemoteInterpreterResultMessage > ( _list5 . size ) ; RemoteInterpreterResultMessage _elem6 ; for ( int _i7 = 0 ; _i7 < _list5 . size ; ++ _i7 ) { _elem6 = new RemoteInterpreterResultMessage ( ) ; _elem6 . read ( iprot ) ; struct . msg . add ( _elem6 ) ; } } struct . setMsgIsSet ( true ) ; } if ( incoming . get ( 2 ) ) { struct . config = iprot . readString ( ) ; struct . setConfigIsSet ( true ) ; } if ( incoming . get ( 3 ) ) { struct . gui = iprot . readString ( ) ; struct . setGuiIsSet ( true ) ; } }",Smelly
 public boolean equals ( Object o ) { if ( o instanceof JXCacheKey ) { JXCacheKey jxck = ( JXCacheKey ) o ; return this . templateUri . equals ( jxck . templateUri ) && this . templateKey . equals ( jxck . templateKey ) ; } return false ; },Smelly
" public static Object [ ] copyToStandardObject ( Object [ ] o , ObjectInspector [ ] oi , ObjectInspectorCopyOption objectInspectorOption ) { Object [ ] out = new Object [ o . length ] ; for ( int i = 0 ; i < oi . length ; i ++ ) { out [ i ] = ObjectInspectorUtils . copyToStandardObject ( o [ i ] , oi [ i ] , objectInspectorOption ) ; } return out ; }",No
" public void read ( org . apache . thrift . protocol . TProtocol prot , show_compact_result struct ) throws org . apache . thrift . TException { TTupleProtocol iprot = ( TTupleProtocol ) prot ; BitSet incoming = iprot . readBitSet ( 1 ) ; if ( incoming . get ( 0 ) ) { struct . success = new ShowCompactResponse ( ) ; struct . success . read ( iprot ) ; struct . setSuccessIsSet ( true ) ; } }",Smelly
" public void read ( org . apache . thrift . protocol . TProtocol prot , getFollowing_result struct ) throws org . apache . thrift . TException { TTupleProtocol iprot = ( TTupleProtocol ) prot ; BitSet incoming = iprot . readBitSet ( 1 ) ; if ( incoming . get ( 0 ) ) { struct . success = new Key ( ) ; struct . success . read ( iprot ) ; struct . setSuccessIsSet ( true ) ; } }",Smelly
" public void testReadFromOneDN ( ) throws Exception { BlockReaderTestUtil util = new BlockReaderTestUtil ( 1 , new HdfsConfiguration ( ) ) ; final Path testFile = new Path ( ""/testConnCache.dat"" ) ; byte authenticData [ ] = util . writeFile ( testFile , FILE_SIZE / 1024 ) ; DFSClient client = new DFSClient ( new InetSocketAddress ( ""localhost"" , util . getCluster ( ) . getNameNodePort ( ) ) , util . getConf ( ) ) ; DFSInputStream in = Mockito . spy ( client . open ( testFile . toString ( ) ) ) ; LOG . info ( ""opened "" + testFile . toString ( ) ) ; byte [ ] dataBuf = new byte [ BLOCK_SIZE ] ; MockGetBlockReader answer = new MockGetBlockReader ( ) ; Mockito . doAnswer ( answer ) . when ( in ) . getBlockReader ( ( InetSocketAddress ) Matchers . anyObject ( ) , ( DatanodeInfo ) Matchers . anyObject ( ) , Matchers . anyString ( ) , ( ExtendedBlock ) Matchers . anyObject ( ) , ( Token < BlockTokenIdentifier > ) Matchers . anyObject ( ) , Matchers . anyLong ( ) , Matchers . anyLong ( ) , Matchers . anyInt ( ) , Matchers . anyBoolean ( ) , Matchers . anyString ( ) ) ; pread ( in , 0 , dataBuf , 0 , dataBuf . length , authenticData ) ; pread ( in , FILE_SIZE - dataBuf . length , dataBuf , 0 , dataBuf . length , authenticData ) ; pread ( in , 1024 , dataBuf , 0 , dataBuf . length , authenticData ) ; pread ( in , - 1 , dataBuf , 0 , dataBuf . length , authenticData ) ; pread ( in , 64 , dataBuf , 0 , dataBuf . length / 2 , authenticData ) ; in . close ( ) ; }",No
 Object encode ( Object source ) throws EncoderException ;,No
 VariableReference getIndexed ( Variable index ) throws ScriptException ;,No
" public static void main ( String [ ] args ) throws Exception { final Arguments arguments = new Arguments ( ) ; JCommander jc = new JCommander ( arguments ) ; jc . setProgramName ( ""pulsar-perf read"" ) ; try { jc . parse ( args ) ; } catch ( ParameterException e ) { System . out . println ( e . getMessage ( ) ) ; jc . usage ( ) ; System . exit ( - 1 ) ; } if ( arguments . help ) { jc . usage ( ) ; System . exit ( - 1 ) ; } if ( arguments . topic . size ( ) != 1 ) { System . out . println ( ""Only one topic name is allowed"" ) ; jc . usage ( ) ; System . exit ( - 1 ) ; } if ( arguments . confFile != null ) { Properties prop = new Properties ( System . getProperties ( ) ) ; prop . load ( new FileInputStream ( arguments . confFile ) ) ; if ( arguments . serviceURL == null ) { arguments . serviceURL = prop . getProperty ( ""brokerServiceUrl"" ) ; } if ( arguments . serviceURL == null ) { arguments . serviceURL = prop . getProperty ( ""webServiceUrl"" ) ; } if ( arguments . serviceURL == null ) { arguments . serviceURL = prop . getProperty ( ""serviceUrl"" , ""http://localhost:8080/"" ) ; } if ( arguments . authPluginClassName == null ) { arguments . authPluginClassName = prop . getProperty ( ""authPlugin"" , null ) ; } if ( arguments . authParams == null ) { arguments . authParams = prop . getProperty ( ""authParams"" , null ) ; } if ( arguments . useTls == false ) { arguments . useTls = Boolean . parseBoolean ( prop . getProperty ( ""useTls"" ) ) ; } if ( isBlank ( arguments . tlsTrustCertsFilePath ) ) { arguments . tlsTrustCertsFilePath = prop . getProperty ( ""tlsTrustCertsFilePath"" , """" ) ; } } ObjectMapper m = new ObjectMapper ( ) ; ObjectWriter w = m . writerWithDefaultPrettyPrinter ( ) ; log . info ( ""Starting Pulsar performance reader with config: {}"" , w . writeValueAsString ( arguments ) ) ; final TopicName prefixTopicName = TopicName . get ( arguments . topic . get ( 0 ) ) ; final RateLimiter limiter = arguments . rate > 0 ? RateLimiter . create ( arguments . rate ) : null ; ReaderListener < byte [ ] > listener = ( reader , msg ) -> { messagesReceived . increment ( ) ; bytesReceived . add ( msg . getData ( ) . length ) ; if ( limiter != null ) { limiter . acquire ( ) ; } } ; ClientBuilder clientBuilder = PulsarClient . builder ( ) . serviceUrl ( arguments . serviceURL ) . connectionsPerBroker ( arguments . maxConnections ) . statsInterval ( arguments . statsIntervalSeconds , TimeUnit . SECONDS ) . ioThreads ( Runtime . getRuntime ( ) . availableProcessors ( ) ) . enableTls ( arguments . useTls ) . tlsTrustCertsFilePath ( arguments . tlsTrustCertsFilePath ) ; if ( isNotBlank ( arguments . authPluginClassName ) ) { clientBuilder . authentication ( arguments . authPluginClassName , arguments . authParams ) ; } PulsarClient pulsarClient = clientBuilder . build ( ) ; List < CompletableFuture < Reader < byte [ ] > > > futures = Lists . newArrayList ( ) ; MessageId startMessageId ; if ( ""earliest"" . equals ( arguments . startMessageId ) ) { startMessageId = MessageId . earliest ; } else if ( ""latest"" . equals ( arguments . startMessageId ) ) { startMessageId = MessageId . latest ; } else { String [ ] parts = arguments . startMessageId . split ( "":"" ) ; startMessageId = new MessageIdImpl ( Long . parseLong ( parts [ 0 ] ) , Long . parseLong ( parts [ 1 ] ) , - 1 ) ; } ReaderBuilder < byte [ ] > readerBuilder = pulsarClient . newReader ( ) . readerListener ( listener ) . receiverQueueSize ( arguments . receiverQueueSize ) . startMessageId ( startMessageId ) ; for ( int i = 0 ; i < arguments . numTopics ; i ++ ) { final TopicName topicName = ( arguments . numTopics == 1 ) ? prefixTopicName : TopicName . get ( String . format ( ""%s-%d"" , prefixTopicName , i ) ) ; futures . add ( readerBuilder . clone ( ) . topic ( topicName . toString ( ) ) . createAsync ( ) ) ; } FutureUtil . waitForAll ( futures ) . get ( ) ; log . info ( ""Start reading from {} topics"" , arguments . numTopics ) ; long oldTime = System . nanoTime ( ) ; while ( true ) { try { Thread . sleep ( 10000 ) ; } catch ( InterruptedException e ) { break ; } long now = System . nanoTime ( ) ; double elapsed = ( now - oldTime ) / 1e9 ; double rate = messagesReceived . sumThenReset ( ) / elapsed ; double throughput = bytesReceived . sumThenReset ( ) / elapsed * 8 / 1024 / 1024 ; log . info ( ""Read throughput: {}  msg/s -- {} Mbit/s"" , dec . format ( rate ) , dec . format ( throughput ) ) ; oldTime = now ; } pulsarClient . close ( ) ; }",Smelly
" public Map < String , Object > actualCall ( ) throws Exception { return svc . validateConfig ( ) ; }",No
 public PersistenceManager getPersistenceManager ( ) { return null ; },No
" public void read ( org . apache . thrift . protocol . TProtocol prot , checkNamespaceClass_result struct ) throws org . apache . thrift . TException { TTupleProtocol iprot = ( TTupleProtocol ) prot ; BitSet incoming = iprot . readBitSet ( 3 ) ; if ( incoming . get ( 0 ) ) { struct . success = iprot . readBool ( ) ; struct . setSuccessIsSet ( true ) ; } if ( incoming . get ( 1 ) ) { struct . sec = new ThriftSecurityException ( ) ; struct . sec . read ( iprot ) ; struct . setSecIsSet ( true ) ; } if ( incoming . get ( 2 ) ) { struct . tope = new ThriftTableOperationException ( ) ; struct . tope . read ( iprot ) ; struct . setTopeIsSet ( true ) ; } }",Smelly
" public void read ( org . apache . thrift . protocol . TProtocol prot , show_compact_result struct ) throws org . apache . thrift . TException { TTupleProtocol iprot = ( TTupleProtocol ) prot ; BitSet incoming = iprot . readBitSet ( 1 ) ; if ( incoming . get ( 0 ) ) { struct . success = new ShowCompactResponse ( ) ; struct . success . read ( iprot ) ; struct . setSuccessIsSet ( true ) ; } }",Smelly
" public void testPerf ( ) throws Exception { Configuration conf = new Configuration ( ) ; TezSharedExecutor sharedExecutor = new TezSharedExecutor ( conf ) ; LogicalIOProcessorRuntimeTask task = createLogicalTask ( conf , new TestUmbilical ( ) , ""dag"" , ""vertex"" , sharedExecutor ) ; task . initialize ( ) ; task . run ( ) ; task . close ( ) ; sharedExecutor . shutdownNow ( ) ; }",No
" public void read ( org . apache . thrift . protocol . TProtocol prot , getFollowing_result struct ) throws org . apache . thrift . TException { TTupleProtocol iprot = ( TTupleProtocol ) prot ; BitSet incoming = iprot . readBitSet ( 1 ) ; if ( incoming . get ( 0 ) ) { struct . success = new Key ( ) ; struct . success . read ( iprot ) ; struct . setSuccessIsSet ( true ) ; } }",Smelly
" public static void main ( String [ ] args ) { ArgumentParser parser = argParser ( ) ; if ( args . length == 0 ) { parser . printHelp ( ) ; Exit . exit ( 0 ) ; } try { final VerifiableProducer producer = createFromArgs ( parser , args ) ; final long startMs = System . currentTimeMillis ( ) ; ThroughputThrottler throttler = new ThroughputThrottler ( producer . throughput , startMs ) ; Runtime . getRuntime ( ) . addShutdownHook ( new Thread ( ( ) -> { producer . stopProducing = true ; producer . close ( ) ; long stopMs = System . currentTimeMillis ( ) ; double avgThroughput = 1000 * ( ( producer . numAcked ) / ( double ) ( stopMs - startMs ) ) ; producer . printJson ( new ToolData ( producer . numSent , producer . numAcked , producer . throughput , avgThroughput ) ) ; } ) ) ; producer . run ( throttler ) ; } catch ( ArgumentParserException e ) { parser . handleError ( e ) ; Exit . exit ( 1 ) ; } }",No
" public void read ( org . apache . thrift . protocol . TProtocol prot , show_compact_result struct ) throws org . apache . thrift . TException { TTupleProtocol iprot = ( TTupleProtocol ) prot ; BitSet incoming = iprot . readBitSet ( 1 ) ; if ( incoming . get ( 0 ) ) { struct . success = new ShowCompactResponse ( ) ; struct . success . read ( iprot ) ; struct . setSuccessIsSet ( true ) ; } }",Smelly
" public void looseMarshal ( OpenWireFormat wireFormat , Object o , DataOutput dataOut ) throws IOException { super . looseMarshal ( wireFormat , o , dataOut ) ; }",No
 protected boolean isValueType ( final ReferenceStrength type ) { return this . valueType == type ; },No
" public void run ( ) { try { long now = System . currentTimeMillis ( ) ; while ( ConnectCountTest . this . run ) { if ( ( System . currentTimeMillis ( ) - now ) >= ConnectCountTest . this . complete ) break ; long start = System . nanoTime ( ) ; Connection con = null ; try { if ( async ) { Future < Connection > cf = ( ( DataSourceProxy ) d ) . getConnectionAsync ( ) ; con = cf . get ( ) ; } else { con = d . getConnection ( ) ; } long delta = System . nanoTime ( ) - start ; totalwait += delta ; maxwait = Math . max ( delta , maxwait ) ; minwait = Math . min ( delta , minwait ) ; nroffetch ++ ; if ( query != null ) { Statement st = con . createStatement ( ) ; ResultSet rs = st . executeQuery ( query ) ; while ( rs . next ( ) ) { } rs . close ( ) ; st . close ( ) ; } try { if ( ConnectCountTest . this . sleep > 0 ) sleep ( ConnectCountTest . this . sleep ) ; } catch ( InterruptedException x ) { interrupted ( ) ; } } finally { long cstart = System . nanoTime ( ) ; if ( con != null ) try { con . close ( ) ; } catch ( Exception x ) { x . printStackTrace ( ) ; } long cdelta = System . nanoTime ( ) - cstart ; totalcmax += cdelta ; cmax = Math . max ( cdelta , cmax ) ; } totalruntime += ( System . nanoTime ( ) - start ) ; } } catch ( Exception x ) { x . printStackTrace ( ) ; } finally { ConnectCountTest . this . latch . countDown ( ) ; } if ( System . getProperty ( ""print-thread-stats"" ) != null ) { System . out . println ( ""["" + getName ( ) + ""] "" + ""\n\tMax time to retrieve connection:"" + maxwait / 1000000f + "" ms."" + ""\n\tTotal time to retrieve connection:"" + totalwait / 1000000f + "" ms."" + ""\n\tAverage time to retrieve connection:"" + totalwait / 1000000f / nroffetch + "" ms."" + ""\n\tMax time to close connection:"" + cmax / 1000000f + "" ms."" + ""\n\tTotal time to close connection:"" + totalcmax / 1000000f + "" ms."" + ""\n\tAverage time to close connection:"" + totalcmax / 1000000f / nroffetch + "" ms."" + ""\n\tRun time:"" + totalruntime / 1000000f + "" ms."" + ""\n\tNr of fetch:"" + nroffetch ) ; } }",Smelly
" public void read ( org . apache . thrift . protocol . TProtocol prot , StorageDescriptor struct ) throws org . apache . thrift . TException { TTupleProtocol iprot = ( TTupleProtocol ) prot ; BitSet incoming = iprot . readBitSet ( 12 ) ; if ( incoming . get ( 0 ) ) { { org . apache . thrift . protocol . TList _list177 = new org . apache . thrift . protocol . TList ( org . apache . thrift . protocol . TType . STRUCT , iprot . readI32 ( ) ) ; struct . cols = new ArrayList < FieldSchema > ( _list177 . size ) ; for ( int _i178 = 0 ; _i178 < _list177 . size ; ++ _i178 ) { FieldSchema _elem179 ; _elem179 = new FieldSchema ( ) ; _elem179 . read ( iprot ) ; struct . cols . add ( _elem179 ) ; } } struct . setColsIsSet ( true ) ; } if ( incoming . get ( 1 ) ) { struct . location = iprot . readString ( ) ; struct . setLocationIsSet ( true ) ; } if ( incoming . get ( 2 ) ) { struct . inputFormat = iprot . readString ( ) ; struct . setInputFormatIsSet ( true ) ; } if ( incoming . get ( 3 ) ) { struct . outputFormat = iprot . readString ( ) ; struct . setOutputFormatIsSet ( true ) ; } if ( incoming . get ( 4 ) ) { struct . compressed = iprot . readBool ( ) ; struct . setCompressedIsSet ( true ) ; } if ( incoming . get ( 5 ) ) { struct . numBuckets = iprot . readI32 ( ) ; struct . setNumBucketsIsSet ( true ) ; } if ( incoming . get ( 6 ) ) { struct . serdeInfo = new SerDeInfo ( ) ; struct . serdeInfo . read ( iprot ) ; struct . setSerdeInfoIsSet ( true ) ; } if ( incoming . get ( 7 ) ) { { org . apache . thrift . protocol . TList _list180 = new org . apache . thrift . protocol . TList ( org . apache . thrift . protocol . TType . STRING , iprot . readI32 ( ) ) ; struct . bucketCols = new ArrayList < String > ( _list180 . size ) ; for ( int _i181 = 0 ; _i181 < _list180 . size ; ++ _i181 ) { String _elem182 ; _elem182 = iprot . readString ( ) ; struct . bucketCols . add ( _elem182 ) ; } } struct . setBucketColsIsSet ( true ) ; } if ( incoming . get ( 8 ) ) { { org . apache . thrift . protocol . TList _list183 = new org . apache . thrift . protocol . TList ( org . apache . thrift . protocol . TType . STRUCT , iprot . readI32 ( ) ) ; struct . sortCols = new ArrayList < Order > ( _list183 . size ) ; for ( int _i184 = 0 ; _i184 < _list183 . size ; ++ _i184 ) { Order _elem185 ; _elem185 = new Order ( ) ; _elem185 . read ( iprot ) ; struct . sortCols . add ( _elem185 ) ; } } struct . setSortColsIsSet ( true ) ; } if ( incoming . get ( 9 ) ) { { org . apache . thrift . protocol . TMap _map186 = new org . apache . thrift . protocol . TMap ( org . apache . thrift . protocol . TType . STRING , org . apache . thrift . protocol . TType . STRING , iprot . readI32 ( ) ) ; struct . parameters = new HashMap < String , String > ( 2 * _map186 . size ) ; for ( int _i187 = 0 ; _i187 < _map186 . size ; ++ _i187 ) { String _key188 ; String _val189 ; _key188 = iprot . readString ( ) ; _val189 = iprot . readString ( ) ; struct . parameters . put ( _key188 , _val189 ) ; } } struct . setParametersIsSet ( true ) ; } if ( incoming . get ( 10 ) ) { struct . skewedInfo = new SkewedInfo ( ) ; struct . skewedInfo . read ( iprot ) ; struct . setSkewedInfoIsSet ( true ) ; } if ( incoming . get ( 11 ) ) { struct . storedAsSubDirectories = iprot . readBool ( ) ; struct . setStoredAsSubDirectoriesIsSet ( true ) ; } }",Smelly
 public DOMSource bareNoParam ( ) { return null ; },No
" public void read ( org . apache . thrift . protocol . TProtocol prot , getChildDataProducts_result struct ) throws org . apache . thrift . TException { TTupleProtocol iprot = ( TTupleProtocol ) prot ; BitSet incoming = iprot . readBitSet ( 5 ) ; if ( incoming . get ( 0 ) ) { { org . apache . thrift . protocol . TList _list283 = new org . apache . thrift . protocol . TList ( org . apache . thrift . protocol . TType . STRUCT , iprot . readI32 ( ) ) ; struct . success = new ArrayList < org . apache . airavata . model . data . replica . DataProductModel > ( _list283 . size ) ; org . apache . airavata . model . data . replica . DataProductModel _elem284 ; for ( int _i285 = 0 ; _i285 < _list283 . size ; ++ _i285 ) { _elem284 = new org . apache . airavata . model . data . replica . DataProductModel ( ) ; _elem284 . read ( iprot ) ; struct . success . add ( _elem284 ) ; } } struct . setSuccessIsSet ( true ) ; } if ( incoming . get ( 1 ) ) { struct . ire = new org . apache . airavata . model . error . InvalidRequestException ( ) ; struct . ire . read ( iprot ) ; struct . setIreIsSet ( true ) ; } if ( incoming . get ( 2 ) ) { struct . ace = new org . apache . airavata . model . error . AiravataClientException ( ) ; struct . ace . read ( iprot ) ; struct . setAceIsSet ( true ) ; } if ( incoming . get ( 3 ) ) { struct . ase = new org . apache . airavata . model . error . AiravataSystemException ( ) ; struct . ase . read ( iprot ) ; struct . setAseIsSet ( true ) ; } if ( incoming . get ( 4 ) ) { struct . ae = new org . apache . airavata . model . error . AuthorizationException ( ) ; struct . ae . read ( iprot ) ; struct . setAeIsSet ( true ) ; } }",Smelly
" protected boolean compare ( final Object lhs , final Object rhs ) { return lhs != null && rhs != null && ( ( lhs == rhs ) || ( lhs . equals ( rhs ) ) || lhs . toString ( ) . equals ( rhs . toString ( ) ) ) ; }",No
" public void read ( org . apache . thrift . protocol . TProtocol prot , show_compact_result struct ) throws org . apache . thrift . TException { TTupleProtocol iprot = ( TTupleProtocol ) prot ; BitSet incoming = iprot . readBitSet ( 1 ) ; if ( incoming . get ( 0 ) ) { struct . success = new ShowCompactResponse ( ) ; struct . success . read ( iprot ) ; struct . setSuccessIsSet ( true ) ; } }",Smelly
 public void processArgs ( CmdArgModule cmdLine ) { verbose = cmdLine . contains ( argDeclVerbose ) || cmdLine . contains ( argDeclDebug ) ; quiet = cmdLine . contains ( argDeclQuiet ) ; help = cmdLine . contains ( argDeclHelp ) ; if ( help ) helpFunction . run ( ) ; },No
" protected String [ ] getConnectorClasses ( ) { return new String [ ] { ""org.apache.manifoldcf.crawler.connectors.filesystem.FileConnector"" } ; }",No
" public void testAgentExecWithNormalExit ( ) throws Exception { Agent agent = createAgent ( Scheduler . SYSTEM ) ; SampleTaskSpec spec = new SampleTaskSpec ( 0 , 120000 , Collections . singletonMap ( ""node01"" , 1L ) , """" ) ; TaskSpec rebasedSpec = agent . rebaseTaskSpecTime ( spec ) ; testExec ( agent , String . format ( ""Waiting for completion of task:%s%n"" , JsonUtil . toPrettyJsonString ( rebasedSpec ) ) + String . format ( ""Task succeeded with status \""halted\""%n"" ) , true , rebasedSpec ) ; agent . beginShutdown ( ) ; agent . waitForShutdown ( ) ; }",No
" public void testDisableSomeButtons ( ) throws Exception { List left = new ArrayList ( ) ; left . add ( ""Left2"" ) ; List right = new ArrayList ( ) ; right . add ( ""Right2"" ) ; List leftVal = new ArrayList ( ) ; leftVal . add ( ""Left1"" ) ; leftVal . add ( ""Left2"" ) ; leftVal . add ( ""Left3"" ) ; List rightVal = new ArrayList ( ) ; rightVal . add ( ""Right1"" ) ; rightVal . add ( ""Right2"" ) ; rightVal . add ( ""Right3"" ) ; TestAction testaction = ( TestAction ) action ; testaction . setCollection ( left ) ; testaction . setList2 ( right ) ; testaction . setCollection2 ( leftVal ) ; testaction . setList3 ( rightVal ) ; OptionTransferSelectTag tag = new OptionTransferSelectTag ( ) ; tag . setPageContext ( pageContext ) ; tag . setName ( ""collection"" ) ; tag . setId ( ""id"" ) ; tag . setList ( ""collection2"" ) ; tag . setSize ( ""20"" ) ; tag . setMultiple ( ""true"" ) ; tag . setEmptyOption ( ""true"" ) ; tag . setDoubleName ( ""list2"" ) ; tag . setDoubleList ( ""list3"" ) ; tag . setDoubleId ( ""doubleId"" ) ; tag . setDoubleSize ( ""20"" ) ; tag . setMultiple ( ""true"" ) ; tag . setDoubleEmptyOption ( ""true"" ) ; tag . setAllowAddAllToLeft ( ""false"" ) ; tag . setAllowAddAllToRight ( ""false"" ) ; tag . setAllowAddToLeft ( ""true"" ) ; tag . setAllowAddToRight ( ""true"" ) ; tag . setAllowSelectAll ( ""false"" ) ; tag . setAddAllToLeftLabel ( ""All Left"" ) ; tag . setAddAllToRightLabel ( ""All Right"" ) ; tag . setAddToLeftLabel ( ""Left"" ) ; tag . setAddToRightLabel ( ""Right"" ) ; tag . setSelectAllLabel ( ""Select All"" ) ; tag . setLeftTitle ( ""Title Left"" ) ; tag . setRightTitle ( ""Title Right"" ) ; tag . setButtonCssClass ( ""buttonCssClass"" ) ; tag . setButtonCssStyle ( ""buttonCssStyle"" ) ; tag . setHeaderKey ( ""Header Key"" ) ; tag . setHeaderValue ( ""Header Value"" ) ; tag . setDoubleHeaderKey ( ""Double Header Key"" ) ; tag . setDoubleHeaderValue ( ""Double Header Value"" ) ; tag . setAddToLeftOnclick ( ""alert('Moving Left')"" ) ; tag . setAddToRightOnclick ( ""alert('Moving Right')"" ) ; tag . doStartTag ( ) ; tag . doEndTag ( ) ; verify ( OptionTransferSelectTagTest . class . getResource ( ""optiontransferselect-7.txt"" ) ) ; }",Smelly
 private static < S extends org . apache . thrift . scheme . IScheme > S scheme ( org . apache . thrift . protocol . TProtocol proto ) { return ( org . apache . thrift . scheme . StandardScheme . class . equals ( proto . getScheme ( ) ) ? STANDARD_SCHEME_FACTORY : TUPLE_SCHEME_FACTORY ) . getScheme ( ) ; },No
" void allocateDataBuffer ( ) { if ( data == null ) { data = ByteBuffer . allocate ( this . size ) ; data . putInt ( 0 , this . getId ( ) ) ; } }",No
" public void read ( org . apache . thrift . protocol . TProtocol prot , BatchScanOptions struct ) throws org . apache . thrift . TException { TTupleProtocol iprot = ( TTupleProtocol ) prot ; BitSet incoming = iprot . readBitSet ( 5 ) ; if ( incoming . get ( 0 ) ) { { org . apache . thrift . protocol . TSet _set70 = new org . apache . thrift . protocol . TSet ( org . apache . thrift . protocol . TType . STRING , iprot . readI32 ( ) ) ; struct . authorizations = new HashSet < ByteBuffer > ( 2 * _set70 . size ) ; for ( int _i71 = 0 ; _i71 < _set70 . size ; ++ _i71 ) { ByteBuffer _elem72 ; _elem72 = iprot . readBinary ( ) ; struct . authorizations . add ( _elem72 ) ; } } struct . setAuthorizationsIsSet ( true ) ; } if ( incoming . get ( 1 ) ) { { org . apache . thrift . protocol . TList _list73 = new org . apache . thrift . protocol . TList ( org . apache . thrift . protocol . TType . STRUCT , iprot . readI32 ( ) ) ; struct . ranges = new ArrayList < Range > ( _list73 . size ) ; for ( int _i74 = 0 ; _i74 < _list73 . size ; ++ _i74 ) { Range _elem75 ; _elem75 = new Range ( ) ; _elem75 . read ( iprot ) ; struct . ranges . add ( _elem75 ) ; } } struct . setRangesIsSet ( true ) ; } if ( incoming . get ( 2 ) ) { { org . apache . thrift . protocol . TList _list76 = new org . apache . thrift . protocol . TList ( org . apache . thrift . protocol . TType . STRUCT , iprot . readI32 ( ) ) ; struct . columns = new ArrayList < ScanColumn > ( _list76 . size ) ; for ( int _i77 = 0 ; _i77 < _list76 . size ; ++ _i77 ) { ScanColumn _elem78 ; _elem78 = new ScanColumn ( ) ; _elem78 . read ( iprot ) ; struct . columns . add ( _elem78 ) ; } } struct . setColumnsIsSet ( true ) ; } if ( incoming . get ( 3 ) ) { { org . apache . thrift . protocol . TList _list79 = new org . apache . thrift . protocol . TList ( org . apache . thrift . protocol . TType . STRUCT , iprot . readI32 ( ) ) ; struct . iterators = new ArrayList < IteratorSetting > ( _list79 . size ) ; for ( int _i80 = 0 ; _i80 < _list79 . size ; ++ _i80 ) { IteratorSetting _elem81 ; _elem81 = new IteratorSetting ( ) ; _elem81 . read ( iprot ) ; struct . iterators . add ( _elem81 ) ; } } struct . setIteratorsIsSet ( true ) ; } if ( incoming . get ( 4 ) ) { struct . threads = iprot . readI32 ( ) ; struct . setThreadsIsSet ( true ) ; } }",Smelly
" public static void transform ( InputStream styleSheet , InputStream xml , Writer out ) throws TransformerConfigurationException , TransformerException { TransformerFactory tFactory = TransformerFactory . newInstance ( ) ; Transformer transformer = tFactory . newTransformer ( new StreamSource ( styleSheet ) ) ; transformer . transform ( new StreamSource ( xml ) , new StreamResult ( out ) ) ; }",No
" public int hashCode ( ) { return Objects . hash ( compareFn , listCoder , maximumSize ) ; }",No
" public void read ( org . apache . thrift . protocol . TProtocol prot , getFollowing_result struct ) throws org . apache . thrift . TException { TTupleProtocol iprot = ( TTupleProtocol ) prot ; BitSet incoming = iprot . readBitSet ( 1 ) ; if ( incoming . get ( 0 ) ) { struct . success = new Key ( ) ; struct . success . read ( iprot ) ; struct . setSuccessIsSet ( true ) ; } }",Smelly
" public void read ( org . apache . thrift . protocol . TProtocol prot , getChildDataProducts_result struct ) throws org . apache . thrift . TException { TTupleProtocol iprot = ( TTupleProtocol ) prot ; BitSet incoming = iprot . readBitSet ( 5 ) ; if ( incoming . get ( 0 ) ) { { org . apache . thrift . protocol . TList _list283 = new org . apache . thrift . protocol . TList ( org . apache . thrift . protocol . TType . STRUCT , iprot . readI32 ( ) ) ; struct . success = new ArrayList < org . apache . airavata . model . data . replica . DataProductModel > ( _list283 . size ) ; org . apache . airavata . model . data . replica . DataProductModel _elem284 ; for ( int _i285 = 0 ; _i285 < _list283 . size ; ++ _i285 ) { _elem284 = new org . apache . airavata . model . data . replica . DataProductModel ( ) ; _elem284 . read ( iprot ) ; struct . success . add ( _elem284 ) ; } } struct . setSuccessIsSet ( true ) ; } if ( incoming . get ( 1 ) ) { struct . ire = new org . apache . airavata . model . error . InvalidRequestException ( ) ; struct . ire . read ( iprot ) ; struct . setIreIsSet ( true ) ; } if ( incoming . get ( 2 ) ) { struct . ace = new org . apache . airavata . model . error . AiravataClientException ( ) ; struct . ace . read ( iprot ) ; struct . setAceIsSet ( true ) ; } if ( incoming . get ( 3 ) ) { struct . ase = new org . apache . airavata . model . error . AiravataSystemException ( ) ; struct . ase . read ( iprot ) ; struct . setAseIsSet ( true ) ; } if ( incoming . get ( 4 ) ) { struct . ae = new org . apache . airavata . model . error . AuthorizationException ( ) ; struct . ae . read ( iprot ) ; struct . setAeIsSet ( true ) ; } }",No
" public List < Object > getWrapperParts ( Object o ) throws Fault { try { Object wrapperObject = getWrapperObject ( o ) ; List < Object > ret = new ArrayList < Object > ( getMethods . length ) ; for ( int x = 0 ; x < getMethods . length ; x ++ ) { if ( getMethods [ x ] != null ) { ret . add ( getValue ( getMethods [ x ] , wrapperObject ) ) ; } else if ( fields [ x ] != null ) { ret . add ( fields [ x ] . get ( wrapperObject ) ) ; } else { ret . add ( null ) ; } } return ret ; } catch ( Exception ex ) { if ( ex . getCause ( ) == null ) { throw new Fault ( ex ) ; } throw new Fault ( ex . getCause ( ) ) ; } }",No
 void close ( ) { },No
 void withoutScope ( ) ;,No
" public void removeNamespace ( String namespaceId ) throws KeeperException , InterruptedException { ZooReaderWriter . getInstance ( ) . recursiveDelete ( ZooUtil . getRoot ( instance ) + Constants . ZNAMESPACES + ""/"" + namespaceId , NodeMissingPolicy . SKIP ) ; }",Smelly
 public void dispose ( IoSession arg0 ) throws Exception { },No
" private void waitOnPids ( List < Long > pids ) { TEST_UTIL . waitFor ( 60000 , ( ) -> pids . stream ( ) . allMatch ( procExec :: isFinished ) ) ; }",No
" public void commitLogical ( CommittedBundle < ? > bundle , MetricUpdates updates ) { for ( MetricUpdate < Long > counter : updates . counterUpdates ( ) ) { counters . get ( counter . getKey ( ) ) . commitLogical ( bundle , counter . getUpdate ( ) ) ; } for ( MetricUpdate < DistributionData > distribution : updates . distributionUpdates ( ) ) { distributions . get ( distribution . getKey ( ) ) . commitLogical ( bundle , distribution . getUpdate ( ) ) ; } for ( MetricUpdate < GaugeData > gauge : updates . gaugeUpdates ( ) ) { gauges . get ( gauge . getKey ( ) ) . commitLogical ( bundle , gauge . getUpdate ( ) ) ; } }",No
" public void read ( org . apache . thrift . protocol . TProtocol prot , StorageDescriptor struct ) throws org . apache . thrift . TException { TTupleProtocol iprot = ( TTupleProtocol ) prot ; BitSet incoming = iprot . readBitSet ( 12 ) ; if ( incoming . get ( 0 ) ) { { org . apache . thrift . protocol . TList _list177 = new org . apache . thrift . protocol . TList ( org . apache . thrift . protocol . TType . STRUCT , iprot . readI32 ( ) ) ; struct . cols = new ArrayList < FieldSchema > ( _list177 . size ) ; for ( int _i178 = 0 ; _i178 < _list177 . size ; ++ _i178 ) { FieldSchema _elem179 ; _elem179 = new FieldSchema ( ) ; _elem179 . read ( iprot ) ; struct . cols . add ( _elem179 ) ; } } struct . setColsIsSet ( true ) ; } if ( incoming . get ( 1 ) ) { struct . location = iprot . readString ( ) ; struct . setLocationIsSet ( true ) ; } if ( incoming . get ( 2 ) ) { struct . inputFormat = iprot . readString ( ) ; struct . setInputFormatIsSet ( true ) ; } if ( incoming . get ( 3 ) ) { struct . outputFormat = iprot . readString ( ) ; struct . setOutputFormatIsSet ( true ) ; } if ( incoming . get ( 4 ) ) { struct . compressed = iprot . readBool ( ) ; struct . setCompressedIsSet ( true ) ; } if ( incoming . get ( 5 ) ) { struct . numBuckets = iprot . readI32 ( ) ; struct . setNumBucketsIsSet ( true ) ; } if ( incoming . get ( 6 ) ) { struct . serdeInfo = new SerDeInfo ( ) ; struct . serdeInfo . read ( iprot ) ; struct . setSerdeInfoIsSet ( true ) ; } if ( incoming . get ( 7 ) ) { { org . apache . thrift . protocol . TList _list180 = new org . apache . thrift . protocol . TList ( org . apache . thrift . protocol . TType . STRING , iprot . readI32 ( ) ) ; struct . bucketCols = new ArrayList < String > ( _list180 . size ) ; for ( int _i181 = 0 ; _i181 < _list180 . size ; ++ _i181 ) { String _elem182 ; _elem182 = iprot . readString ( ) ; struct . bucketCols . add ( _elem182 ) ; } } struct . setBucketColsIsSet ( true ) ; } if ( incoming . get ( 8 ) ) { { org . apache . thrift . protocol . TList _list183 = new org . apache . thrift . protocol . TList ( org . apache . thrift . protocol . TType . STRUCT , iprot . readI32 ( ) ) ; struct . sortCols = new ArrayList < Order > ( _list183 . size ) ; for ( int _i184 = 0 ; _i184 < _list183 . size ; ++ _i184 ) { Order _elem185 ; _elem185 = new Order ( ) ; _elem185 . read ( iprot ) ; struct . sortCols . add ( _elem185 ) ; } } struct . setSortColsIsSet ( true ) ; } if ( incoming . get ( 9 ) ) { { org . apache . thrift . protocol . TMap _map186 = new org . apache . thrift . protocol . TMap ( org . apache . thrift . protocol . TType . STRING , org . apache . thrift . protocol . TType . STRING , iprot . readI32 ( ) ) ; struct . parameters = new HashMap < String , String > ( 2 * _map186 . size ) ; for ( int _i187 = 0 ; _i187 < _map186 . size ; ++ _i187 ) { String _key188 ; String _val189 ; _key188 = iprot . readString ( ) ; _val189 = iprot . readString ( ) ; struct . parameters . put ( _key188 , _val189 ) ; } } struct . setParametersIsSet ( true ) ; } if ( incoming . get ( 10 ) ) { struct . skewedInfo = new SkewedInfo ( ) ; struct . skewedInfo . read ( iprot ) ; struct . setSkewedInfoIsSet ( true ) ; } if ( incoming . get ( 11 ) ) { struct . storedAsSubDirectories = iprot . readBool ( ) ; struct . setStoredAsSubDirectoriesIsSet ( true ) ; } }",No
" public void read ( org . apache . thrift . protocol . TProtocol prot , getChildDataProducts_result struct ) throws org . apache . thrift . TException { TTupleProtocol iprot = ( TTupleProtocol ) prot ; BitSet incoming = iprot . readBitSet ( 5 ) ; if ( incoming . get ( 0 ) ) { { org . apache . thrift . protocol . TList _list283 = new org . apache . thrift . protocol . TList ( org . apache . thrift . protocol . TType . STRUCT , iprot . readI32 ( ) ) ; struct . success = new ArrayList < org . apache . airavata . model . data . replica . DataProductModel > ( _list283 . size ) ; org . apache . airavata . model . data . replica . DataProductModel _elem284 ; for ( int _i285 = 0 ; _i285 < _list283 . size ; ++ _i285 ) { _elem284 = new org . apache . airavata . model . data . replica . DataProductModel ( ) ; _elem284 . read ( iprot ) ; struct . success . add ( _elem284 ) ; } } struct . setSuccessIsSet ( true ) ; } if ( incoming . get ( 1 ) ) { struct . ire = new org . apache . airavata . model . error . InvalidRequestException ( ) ; struct . ire . read ( iprot ) ; struct . setIreIsSet ( true ) ; } if ( incoming . get ( 2 ) ) { struct . ace = new org . apache . airavata . model . error . AiravataClientException ( ) ; struct . ace . read ( iprot ) ; struct . setAceIsSet ( true ) ; } if ( incoming . get ( 3 ) ) { struct . ase = new org . apache . airavata . model . error . AiravataSystemException ( ) ; struct . ase . read ( iprot ) ; struct . setAseIsSet ( true ) ; } if ( incoming . get ( 4 ) ) { struct . ae = new org . apache . airavata . model . error . AuthorizationException ( ) ; struct . ae . read ( iprot ) ; struct . setAeIsSet ( true ) ; } }",Smelly
 public boolean isTemporary ( ) { return isTemporary . booleanValue ( ) ; },No
 public void close ( ) throws IOException { },No
" public void read ( org . apache . thrift . protocol . TProtocol prot , getChildDataProducts_result struct ) throws org . apache . thrift . TException { TTupleProtocol iprot = ( TTupleProtocol ) prot ; BitSet incoming = iprot . readBitSet ( 5 ) ; if ( incoming . get ( 0 ) ) { { org . apache . thrift . protocol . TList _list283 = new org . apache . thrift . protocol . TList ( org . apache . thrift . protocol . TType . STRUCT , iprot . readI32 ( ) ) ; struct . success = new ArrayList < org . apache . airavata . model . data . replica . DataProductModel > ( _list283 . size ) ; org . apache . airavata . model . data . replica . DataProductModel _elem284 ; for ( int _i285 = 0 ; _i285 < _list283 . size ; ++ _i285 ) { _elem284 = new org . apache . airavata . model . data . replica . DataProductModel ( ) ; _elem284 . read ( iprot ) ; struct . success . add ( _elem284 ) ; } } struct . setSuccessIsSet ( true ) ; } if ( incoming . get ( 1 ) ) { struct . ire = new org . apache . airavata . model . error . InvalidRequestException ( ) ; struct . ire . read ( iprot ) ; struct . setIreIsSet ( true ) ; } if ( incoming . get ( 2 ) ) { struct . ace = new org . apache . airavata . model . error . AiravataClientException ( ) ; struct . ace . read ( iprot ) ; struct . setAceIsSet ( true ) ; } if ( incoming . get ( 3 ) ) { struct . ase = new org . apache . airavata . model . error . AiravataSystemException ( ) ; struct . ase . read ( iprot ) ; struct . setAseIsSet ( true ) ; } if ( incoming . get ( 4 ) ) { struct . ae = new org . apache . airavata . model . error . AuthorizationException ( ) ; struct . ae . read ( iprot ) ; struct . setAeIsSet ( true ) ; } }",Smelly
 private static < S extends org . apache . thrift . scheme . IScheme > S scheme ( org . apache . thrift . protocol . TProtocol proto ) { return ( org . apache . thrift . scheme . StandardScheme . class . equals ( proto . getScheme ( ) ) ? STANDARD_SCHEME_FACTORY : TUPLE_SCHEME_FACTORY ) . getScheme ( ) ; },Smelly
 public Schema getSchema ( ) { return schema ; },No
" public void read ( org . apache . thrift . protocol . TProtocol prot , getActiveLogs_result struct ) throws org . apache . thrift . TException { TTupleProtocol iprot = ( TTupleProtocol ) prot ; BitSet incoming = iprot . readBitSet ( 1 ) ; if ( incoming . get ( 0 ) ) { { org . apache . thrift . protocol . TList _list327 = new org . apache . thrift . protocol . TList ( org . apache . thrift . protocol . TType . STRING , iprot . readI32 ( ) ) ; struct . success = new ArrayList < String > ( _list327 . size ) ; for ( int _i328 = 0 ; _i328 < _list327 . size ; ++ _i328 ) { String _elem329 ; _elem329 = iprot . readString ( ) ; struct . success . add ( _elem329 ) ; } } struct . setSuccessIsSet ( true ) ; } }",Smelly
" public void read ( org . apache . thrift . protocol . TProtocol prot , ActiveCompaction struct ) throws org . apache . thrift . TException { TTupleProtocol iprot = ( TTupleProtocol ) prot ; BitSet incoming = iprot . readBitSet ( 10 ) ; if ( incoming . get ( 0 ) ) { struct . extent = new KeyExtent ( ) ; struct . extent . read ( iprot ) ; struct . setExtentIsSet ( true ) ; } if ( incoming . get ( 1 ) ) { struct . age = iprot . readI64 ( ) ; struct . setAgeIsSet ( true ) ; } if ( incoming . get ( 2 ) ) { { org . apache . thrift . protocol . TList _list148 = new org . apache . thrift . protocol . TList ( org . apache . thrift . protocol . TType . STRING , iprot . readI32 ( ) ) ; struct . inputFiles = new ArrayList < String > ( _list148 . size ) ; for ( int _i149 = 0 ; _i149 < _list148 . size ; ++ _i149 ) { String _elem150 ; _elem150 = iprot . readString ( ) ; struct . inputFiles . add ( _elem150 ) ; } } struct . setInputFilesIsSet ( true ) ; } if ( incoming . get ( 3 ) ) { struct . outputFile = iprot . readString ( ) ; struct . setOutputFileIsSet ( true ) ; } if ( incoming . get ( 4 ) ) { struct . type = CompactionType . findByValue ( iprot . readI32 ( ) ) ; struct . setTypeIsSet ( true ) ; } if ( incoming . get ( 5 ) ) { struct . reason = CompactionReason . findByValue ( iprot . readI32 ( ) ) ; struct . setReasonIsSet ( true ) ; } if ( incoming . get ( 6 ) ) { struct . localityGroup = iprot . readString ( ) ; struct . setLocalityGroupIsSet ( true ) ; } if ( incoming . get ( 7 ) ) { struct . entriesRead = iprot . readI64 ( ) ; struct . setEntriesReadIsSet ( true ) ; } if ( incoming . get ( 8 ) ) { struct . entriesWritten = iprot . readI64 ( ) ; struct . setEntriesWrittenIsSet ( true ) ; } if ( incoming . get ( 9 ) ) { { org . apache . thrift . protocol . TList _list151 = new org . apache . thrift . protocol . TList ( org . apache . thrift . protocol . TType . STRUCT , iprot . readI32 ( ) ) ; struct . iterators = new ArrayList < IteratorSetting > ( _list151 . size ) ; for ( int _i152 = 0 ; _i152 < _list151 . size ; ++ _i152 ) { IteratorSetting _elem153 ; _elem153 = new IteratorSetting ( ) ; _elem153 . read ( iprot ) ; struct . iterators . add ( _elem153 ) ; } } struct . setIteratorsIsSet ( true ) ; } }",Smelly
" public void read ( org . apache . thrift . protocol . TProtocol prot , FieldSchema struct ) throws org . apache . thrift . TException { TTupleProtocol iprot = ( TTupleProtocol ) prot ; BitSet incoming = iprot . readBitSet ( 3 ) ; if ( incoming . get ( 0 ) ) { struct . name = iprot . readString ( ) ; struct . setNameIsSet ( true ) ; } if ( incoming . get ( 1 ) ) { struct . type = iprot . readString ( ) ; struct . setTypeIsSet ( true ) ; } if ( incoming . get ( 2 ) ) { struct . comment = iprot . readString ( ) ; struct . setCommentIsSet ( true ) ; } }",Smelly
 private static < S extends org . apache . thrift . scheme . IScheme > S scheme ( org . apache . thrift . protocol . TProtocol proto ) { return ( org . apache . thrift . scheme . StandardScheme . class . equals ( proto . getScheme ( ) ) ? STANDARD_SCHEME_FACTORY : TUPLE_SCHEME_FACTORY ) . getScheme ( ) ; },Smelly
 protected BrokerService createBroker ( ) throws Exception { BrokerService answer = new BrokerService ( ) ; answer . setPersistent ( false ) ; answer . addConnector ( getBrokerURL ( ) ) ; return answer ; },No
 public NodeTypeProvider getNodeTypeProvider ( ) { return null ; },No
" public synchronized Object [ ] toParameterArray ( StoreQuery q , Map userParams ) { Object [ ] array = new Object [ userParams . size ( ) ] ; Set < Map . Entry < Object , Object > > userSet = userParams . entrySet ( ) ; for ( Map . Entry < Object , Object > userEntry : userSet ) { int idx = ( ( Integer ) userEntry . getKey ( ) ) . intValue ( ) ; array [ idx ] = userEntry . getValue ( ) ; } return array ; }",Smelly
" public void read ( org . apache . thrift . protocol . TProtocol prot , getChildDataProducts_result struct ) throws org . apache . thrift . TException { TTupleProtocol iprot = ( TTupleProtocol ) prot ; BitSet incoming = iprot . readBitSet ( 5 ) ; if ( incoming . get ( 0 ) ) { { org . apache . thrift . protocol . TList _list283 = new org . apache . thrift . protocol . TList ( org . apache . thrift . protocol . TType . STRUCT , iprot . readI32 ( ) ) ; struct . success = new ArrayList < org . apache . airavata . model . data . replica . DataProductModel > ( _list283 . size ) ; org . apache . airavata . model . data . replica . DataProductModel _elem284 ; for ( int _i285 = 0 ; _i285 < _list283 . size ; ++ _i285 ) { _elem284 = new org . apache . airavata . model . data . replica . DataProductModel ( ) ; _elem284 . read ( iprot ) ; struct . success . add ( _elem284 ) ; } } struct . setSuccessIsSet ( true ) ; } if ( incoming . get ( 1 ) ) { struct . ire = new org . apache . airavata . model . error . InvalidRequestException ( ) ; struct . ire . read ( iprot ) ; struct . setIreIsSet ( true ) ; } if ( incoming . get ( 2 ) ) { struct . ace = new org . apache . airavata . model . error . AiravataClientException ( ) ; struct . ace . read ( iprot ) ; struct . setAceIsSet ( true ) ; } if ( incoming . get ( 3 ) ) { struct . ase = new org . apache . airavata . model . error . AiravataSystemException ( ) ; struct . ase . read ( iprot ) ; struct . setAseIsSet ( true ) ; } if ( incoming . get ( 4 ) ) { struct . ae = new org . apache . airavata . model . error . AuthorizationException ( ) ; struct . ae . read ( iprot ) ; struct . setAeIsSet ( true ) ; } }",Smelly
" private void setQuotaAndVerifyForRegionReplication ( int region , int replicatedRegion , SpaceViolationPolicy policy ) throws Exception { TableName tn = helper . createTableWithRegions ( TEST_UTIL . getAdmin ( ) , NamespaceDescriptor . DEFAULT_NAMESPACE_NAME_STR , region , replicatedRegion ) ; helper . setQuotaLimit ( tn , policy , 5L ) ; helper . writeData ( tn , 5L * SpaceQuotaHelperForTests . ONE_MEGABYTE ) ; Put p = new Put ( Bytes . toBytes ( ""to_reject"" ) ) ; p . addColumn ( Bytes . toBytes ( SpaceQuotaHelperForTests . F1 ) , Bytes . toBytes ( ""to"" ) , Bytes . toBytes ( ""reject"" ) ) ; helper . verifyViolation ( policy , tn , p ) ; }",No
" private void setCarbonEnum ( ) throws Exception { for ( HiveStorageFormat format : HiveStorageFormat . values ( ) ) { if ( format . name ( ) . equals ( ""CARBON"" ) ) { return ; } } Constructor < ? > [ ] declaredConstructors = HiveStorageFormat . class . getDeclaredConstructors ( ) ; declaredConstructors [ 0 ] . setAccessible ( true ) ; Field constructorAccessorField = Constructor . class . getDeclaredField ( ""constructorAccessor"" ) ; constructorAccessorField . setAccessible ( true ) ; ConstructorAccessor ca = ( ConstructorAccessor ) constructorAccessorField . get ( declaredConstructors [ 0 ] ) ; if ( ca == null ) { Method acquireConstructorAccessorMethod = Constructor . class . getDeclaredMethod ( ""acquireConstructorAccessor"" ) ; acquireConstructorAccessorMethod . setAccessible ( true ) ; ca = ( ConstructorAccessor ) acquireConstructorAccessorMethod . invoke ( declaredConstructors [ 0 ] ) ; } Object instance = ca . newInstance ( new Object [ ] { ""CARBON"" , HiveStorageFormat . values ( ) . length , """" , CarbonTableInputFormat . class . getName ( ) , CarbonTableOutputFormat . class . getName ( ) , new DataSize ( 256.0D , DataSize . Unit . MEGABYTE ) } ) ; Field values = HiveStorageFormat . class . getDeclaredField ( ""$VALUES"" ) ; values . setAccessible ( true ) ; Field modifiersField = Field . class . getDeclaredField ( ""modifiers"" ) ; modifiersField . setAccessible ( true ) ; modifiersField . setInt ( values , values . getModifiers ( ) & ~ Modifier . FINAL ) ; HiveStorageFormat [ ] hiveStorageFormats = new HiveStorageFormat [ HiveStorageFormat . values ( ) . length + 1 ] ; HiveStorageFormat [ ] src = ( HiveStorageFormat [ ] ) values . get ( null ) ; System . arraycopy ( src , 0 , hiveStorageFormats , 0 , src . length ) ; hiveStorageFormats [ src . length ] = ( HiveStorageFormat ) instance ; values . set ( null , hiveStorageFormats ) ; }",Smelly
" public void decompress ( ByteBuffer input , int compressedSize , ByteBuffer output , int uncompressedSize ) throws IOException { if ( codecName == CompressionCodecName . GZIP ) { GzipCodec codec = new GzipCodec ( ) ; DirectDecompressor directDecompressor = codec . createDirectDecompressor ( ) ; if ( directDecompressor != null ) { logger . debug ( ""Using GZIP direct decompressor."" ) ; directDecompressor . decompress ( input , output ) ; } else { logger . debug ( ""Using GZIP (in)direct decompressor."" ) ; Decompressor decompressor = codec . createDecompressor ( ) ; decompressor . reset ( ) ; byte [ ] inputBytes = new byte [ compressedSize ] ; input . position ( 0 ) ; input . get ( inputBytes ) ; decompressor . setInput ( inputBytes , 0 , inputBytes . length ) ; byte [ ] outputBytes = new byte [ uncompressedSize ] ; decompressor . decompress ( outputBytes , 0 , uncompressedSize ) ; output . clear ( ) ; output . put ( outputBytes ) ; } } else if ( codecName == CompressionCodecName . SNAPPY ) { output . clear ( ) ; int size = Snappy . uncompress ( input , output ) ; output . limit ( size ) ; } else { CodecFactory . BytesDecompressor decompressor = codecFactory . getDecompressor ( parentColumnReader . columnChunkMetaData . getCodec ( ) ) ; decompressor . decompress ( input , compressedSize , output , uncompressedSize ) ; } }",Smelly
" public void read ( org . apache . thrift . protocol . TProtocol prot , checkNamespaceClass_result struct ) throws org . apache . thrift . TException { TTupleProtocol iprot = ( TTupleProtocol ) prot ; BitSet incoming = iprot . readBitSet ( 3 ) ; if ( incoming . get ( 0 ) ) { struct . success = iprot . readBool ( ) ; struct . setSuccessIsSet ( true ) ; } if ( incoming . get ( 1 ) ) { struct . sec = new ThriftSecurityException ( ) ; struct . sec . read ( iprot ) ; struct . setSecIsSet ( true ) ; } if ( incoming . get ( 2 ) ) { struct . tope = new ThriftTableOperationException ( ) ; struct . tope . read ( iprot ) ; struct . setTopeIsSet ( true ) ; } }",Smelly
" public static void main ( String [ ] args ) throws Exception { OpcodeLoader loader = new OpcodeLoader ( ) ; OpcodeInfo [ ] ops = loader . loadOpcodes ( ) ; OpcodeInfo op ; for ( int i = 0 ; i < ops . length ; i ++ ) { if ( ops [ i ] != null ) { op = ops [ i ] ; prt ( ""<p><span class='InstructionTitle'>Name</span> : "" + op . opname + ""</p>"" ) ; prt ( ""<p><span class='InstructionTitle'>Opcode</span> : "" + ( op . opcode & 0xFF ) + ""(0x"" + Integer . toHexString ( ( op . opcode & 0xFF ) ) + "")</p>"" ) ; prt ( ""<p><span class='InstructionTitle'>Operation</span> : </p>"" ) ; prt ( ""<p>"" + pr ( op . operation ) + ""</p>"" ) ; prt ( ""<p><span class='InstructionTitle'>Format</span> : </p>"" ) ; prt ( ""<p>"" + pr ( op . format ) + ""</p>"" ) ; prt ( ""<p><span class='InstructionTitle'>Operand Stack</span> : </p>"" ) ; prt ( ""<p>"" + op . operandStack + ""</p>"" ) ; prt ( ""<p><span class='InstructionTitle'>Description</span> :</p>"" ) ; prt ( ""<p>"" + pr ( op . description ) + ""</p>"" ) ; if ( op . linkingExceptions != null && op . linkingExceptions . trim ( ) . length ( ) != 0 ) { prt ( ""<p><span class='InstructionTitle'>Linking Exceptions</span> : </p>"" ) ; prt ( ""<p>"" + pr ( op . linkingExceptions ) + ""</p>"" ) ; } if ( op . runtimeExceptions . trim ( ) . length ( ) != 0 ) { prt ( ""<p><span class='InstructionTitle'>Runtime Exceptions</span> : </p>"" ) ; prt ( ""<p>"" + pr ( op . runtimeExceptions ) + ""</p>"" ) ; } if ( op . notes . trim ( ) . length ( ) != 0 ) { prt ( "" <p><span class='InstructionTitle'>Notes</span> : </p>"" ) ; prt ( ""<p>"" + pr ( op . notes ) + ""</p>"" ) ; } prt ( ""<br>"" ) ; prt ( ""<hr>"" ) ; } } }",Smelly
 public SqlModality getModality ( ) { return modality ; },No
" private void throwNotImplementedException ( String method ) throws HiveAuthzPluginException { throw new HiveAuthzPluginException ( method + ""() not implemented in Ranger HiveAuthorizer"" ) ; }",No
" public void read ( org . apache . thrift . protocol . TProtocol prot , TKeyExtent struct ) throws org . apache . thrift . TException { TTupleProtocol iprot = ( TTupleProtocol ) prot ; BitSet incoming = iprot . readBitSet ( 3 ) ; if ( incoming . get ( 0 ) ) { struct . table = iprot . readBinary ( ) ; struct . setTableIsSet ( true ) ; } if ( incoming . get ( 1 ) ) { struct . endRow = iprot . readBinary ( ) ; struct . setEndRowIsSet ( true ) ; } if ( incoming . get ( 2 ) ) { struct . prevEndRow = iprot . readBinary ( ) ; struct . setPrevEndRowIsSet ( true ) ; } }",Smelly
" protected String getUrl ( String _url , String host , String _port , String _db ) { String db = ( _db == null ) ? DEFAULT_DB_NAME : _db ; int idx = _url . indexOf ( ';' ) ; String suffix = idx > - 1 ? _url . substring ( idx ) : """" ; return String . format ( ""jdbc:derby:%s%s"" , db , suffix ) ; }",No
" public static void main ( String [ ] args ) throws Exception { System . exit ( ToolRunner . run ( HBaseConfiguration . create ( ) , new CompactionTool ( ) , args ) ) ; }",No
 public Permission resolvePermission ( String permissionString ) { return new IsisPermission ( permissionString ) ; },No
" public void addRuleInstances ( Digester digester ) { digester . addObjectCreate ( prefix + ""Manager"" , null , ""className"" ) ; digester . addSetProperties ( prefix + ""Manager"" ) ; digester . addSetNext ( prefix + ""Manager"" , ""setManagerTemplate"" , ""org.apache.catalina.ha.ClusterManager"" ) ; digester . addObjectCreate ( prefix + ""Channel"" , null , ""className"" ) ; digester . addSetProperties ( prefix + ""Channel"" ) ; digester . addSetNext ( prefix + ""Channel"" , ""setChannel"" , ""org.apache.catalina.tribes.Channel"" ) ; String channelPrefix = prefix + ""Channel/"" ; { digester . addObjectCreate ( channelPrefix + ""Membership"" , null , ""className"" ) ; digester . addSetProperties ( channelPrefix + ""Membership"" ) ; digester . addSetNext ( channelPrefix + ""Membership"" , ""setMembershipService"" , ""org.apache.catalina.tribes.MembershipService"" ) ; digester . addObjectCreate ( channelPrefix + ""Sender"" , null , ""className"" ) ; digester . addSetProperties ( channelPrefix + ""Sender"" ) ; digester . addSetNext ( channelPrefix + ""Sender"" , ""setChannelSender"" , ""org.apache.catalina.tribes.ChannelSender"" ) ; digester . addObjectCreate ( channelPrefix + ""Sender/Transport"" , null , ""className"" ) ; digester . addSetProperties ( channelPrefix + ""Sender/Transport"" ) ; digester . addSetNext ( channelPrefix + ""Sender/Transport"" , ""setTransport"" , ""org.apache.catalina.tribes.transport.MultiPointSender"" ) ; digester . addObjectCreate ( channelPrefix + ""Receiver"" , null , ""className"" ) ; digester . addSetProperties ( channelPrefix + ""Receiver"" ) ; digester . addSetNext ( channelPrefix + ""Receiver"" , ""setChannelReceiver"" , ""org.apache.catalina.tribes.ChannelReceiver"" ) ; digester . addObjectCreate ( channelPrefix + ""Interceptor"" , null , ""className"" ) ; digester . addSetProperties ( channelPrefix + ""Interceptor"" ) ; digester . addSetNext ( channelPrefix + ""Interceptor"" , ""addInterceptor"" , ""org.apache.catalina.tribes.ChannelInterceptor"" ) ; digester . addObjectCreate ( channelPrefix + ""Interceptor/Member"" , null , ""className"" ) ; digester . addSetProperties ( channelPrefix + ""Interceptor/Member"" ) ; digester . addSetNext ( channelPrefix + ""Interceptor/Member"" , ""addStaticMember"" , ""org.apache.catalina.tribes.Member"" ) ; } digester . addObjectCreate ( prefix + ""Valve"" , null , ""className"" ) ; digester . addSetProperties ( prefix + ""Valve"" ) ; digester . addSetNext ( prefix + ""Valve"" , ""addValve"" , ""org.apache.catalina.Valve"" ) ; digester . addObjectCreate ( prefix + ""Deployer"" , null , ""className"" ) ; digester . addSetProperties ( prefix + ""Deployer"" ) ; digester . addSetNext ( prefix + ""Deployer"" , ""setClusterDeployer"" , ""org.apache.catalina.ha.ClusterDeployer"" ) ; digester . addObjectCreate ( prefix + ""Listener"" , null , ""className"" ) ; digester . addSetProperties ( prefix + ""Listener"" ) ; digester . addSetNext ( prefix + ""Listener"" , ""addLifecycleListener"" , ""org.apache.catalina.LifecycleListener"" ) ; digester . addObjectCreate ( prefix + ""ClusterListener"" , null , ""className"" ) ; digester . addSetProperties ( prefix + ""ClusterListener"" ) ; digester . addSetNext ( prefix + ""ClusterListener"" , ""addClusterListener"" , ""org.apache.catalina.ha.ClusterListener"" ) ; }",Smelly
 public void onMatch ( RelOptRuleCall call ) { SingleRel single = call . rel ( 0 ) ; call . transformTo ( call . builder ( ) . push ( single ) . empty ( ) . build ( ) ) ; },No
 public void after ( ) { tester . destroy ( ) ; },No
" private void createModernSourceRepository ( ) throws Exception { ArtifactRepositoryFactory factory = plexusSisuBridge . lookup ( ArtifactRepositoryFactory . class ) ; ArtifactRepositoryLayout layout = plexusSisuBridge . lookup ( ArtifactRepositoryLayout . class , ""default"" ) ; File sourceBase = getTestFile ( ""src/test/source-modern-repository"" ) ; sourceRepository = factory . createArtifactRepository ( ""source"" , sourceBase . toURL ( ) . toString ( ) , layout , null , null ) ; }",No
" private void parseMethodSignature ( Method method , ArrayList attributes ) throws ParsingException , GrammerException { int acc = 0 ; String methodName , retType ; StringBuffer para = new StringBuffer ( 15 ) ; while ( scanner . tokenType ( ) == AccessFlag ) { acc = acc | Util . getAccessFlag_Method ( scanner . token ( ) ) ; scanner . nextToken ( ) ; } retType = scanner . token ( ) ; scanner . nextToken ( ) ; methodName = scanner . token ( ) ; scanner . nextToken ( ) ; if ( scanner . tokenType ( ) != SBracket_Left ) { exception ( scanner , ""'('.expected.here"" ) ; } scanner . nextToken ( ) ; if ( scanner . tokenType ( ) == SBracket_Right ) { para . append ( """" ) ; } else { while ( scanner . tokenType ( ) != EOF && scanner . tokenType ( ) != SBracket_Right ) { para = para . append ( scanner . token ( ) ) ; if ( scanner . nextToken ( ) == Comma ) { para . append ( ',' ) ; scanner . nextToken ( ) ; } } if ( scanner . tokenType ( ) != SBracket_Right ) { throw new ParsingException ( scanner . getOffset ( ) , ""')'.expected.here"" ) ; } } retType = Util . toInnerType ( retType ) ; method . descriptor_index = cpl . addUtf8 ( ""("" + Util . toInnerParameterTypes ( para . toString ( ) ) + "")"" + retType ) ; method . name_index = cpl . addUtf8 ( methodName ) ; method . access_flags = acc ; scanner . nextToken ( ) ; if ( ""throws"" . equals ( scanner . token ( ) ) == true ) { IntegerArray thr = new IntegerArray ( 4 ) ; while ( scanner . tokenType ( ) != Bracket_Left && scanner . tokenType ( ) != EOF ) { scanner . nextToken ( ) ; thr . add ( cpl . addClass ( scanner . token ( ) ) ) ; scanner . nextToken ( ) ; if ( scanner . tokenType ( ) != Bracket_Left && scanner . tokenType ( ) != Comma ) { exception ( scanner , ""invalid.throw.clause"" ) ; } } Attribute att = new Attribute_Exceptions ( 2 + 2 * thr . getAll ( ) . length , thr . getAll ( ) . length , thr . getAll ( ) ) ; att . attribute_name_index = cpl . addUtf8 ( ""Exceptions"" ) ; attributes . add ( att ) ; } else if ( scanner . tokenType ( ) == Bracket_Left ) { } else { exception ( scanner , ""'{'.expected.here"" ) ; } scanner . nextToken ( ) ; }",Smelly
 public KafkaFuture < List < DelegationToken > > delegationTokens ( ) { return delegationTokens ; },No
" public void read ( org . apache . thrift . protocol . TProtocol prot , checkNamespaceClass_result struct ) throws org . apache . thrift . TException { TTupleProtocol iprot = ( TTupleProtocol ) prot ; BitSet incoming = iprot . readBitSet ( 3 ) ; if ( incoming . get ( 0 ) ) { struct . success = iprot . readBool ( ) ; struct . setSuccessIsSet ( true ) ; } if ( incoming . get ( 1 ) ) { struct . sec = new ThriftSecurityException ( ) ; struct . sec . read ( iprot ) ; struct . setSecIsSet ( true ) ; } if ( incoming . get ( 2 ) ) { struct . tope = new ThriftTableOperationException ( ) ; struct . tope . read ( iprot ) ; struct . setTopeIsSet ( true ) ; } }",Smelly
" public void read ( org . apache . thrift . protocol . TProtocol prot , show_compact_result struct ) throws org . apache . thrift . TException { TTupleProtocol iprot = ( TTupleProtocol ) prot ; BitSet incoming = iprot . readBitSet ( 1 ) ; if ( incoming . get ( 0 ) ) { struct . success = new ShowCompactResponse ( ) ; struct . success . read ( iprot ) ; struct . setSuccessIsSet ( true ) ; } }",Smelly
" public void doTag ( TagPluginContext ctxt ) { boolean hasContext , hasVar , hasScope , hasVarReader , hasCharEncoding ; hasContext = ctxt . isAttributeSpecified ( ""context"" ) ; hasVar = ctxt . isAttributeSpecified ( ""var"" ) ; hasScope = ctxt . isAttributeSpecified ( ""scope"" ) ; hasVarReader = ctxt . isAttributeSpecified ( ""varReader"" ) ; hasCharEncoding = ctxt . isAttributeSpecified ( ""charEncoding"" ) ; String urlName = ctxt . getTemporaryVariableName ( ) ; String contextName = ctxt . getTemporaryVariableName ( ) ; String iauName = ctxt . getTemporaryVariableName ( ) ; String urlObjName = ctxt . getTemporaryVariableName ( ) ; String ucName = ctxt . getTemporaryVariableName ( ) ; String inputStreamName = ctxt . getTemporaryVariableName ( ) ; String tempReaderName = ctxt . getTemporaryVariableName ( ) ; String tempReaderName2 = ctxt . getTemporaryVariableName ( ) ; String charSetName = ctxt . getTemporaryVariableName ( ) ; String charEncodingName = ctxt . getTemporaryVariableName ( ) ; String contentTypeName = ctxt . getTemporaryVariableName ( ) ; String varReaderName = ctxt . getTemporaryVariableName ( ) ; String servletContextName = ctxt . getTemporaryVariableName ( ) ; String servletPathName = ctxt . getTemporaryVariableName ( ) ; String requestDispatcherName = ctxt . getTemporaryVariableName ( ) ; String irwName = ctxt . getTemporaryVariableName ( ) ; String brName = ctxt . getTemporaryVariableName ( ) ; String sbName = ctxt . getTemporaryVariableName ( ) ; String tempStringName = ctxt . getTemporaryVariableName ( ) ; ctxt . generateJavaSource ( ""boolean "" + iauName + "";"" ) ; ctxt . generateJavaSource ( ""String "" + urlName + "" = "" ) ; ctxt . generateAttribute ( ""url"" ) ; ctxt . generateJavaSource ( "";"" ) ; ctxt . generateJavaSource ( ""if("" + urlName + "" == null || "" + urlName + "".equals(\""\"")){"" ) ; ctxt . generateJavaSource ( ""    throw new JspTagException(\""The \\\""url\\\"" attribute "" + ""illegally evaluated to \\\""null\\\"" or \\\""\\\"" in &lt;import&gt;\"");"" ) ; ctxt . generateJavaSource ( ""}"" ) ; ctxt . generateJavaSource ( iauName + "" = "" + ""org.apache.jasper.tagplugins.jstl.Util.isAbsoluteUrl("" + urlName + "");"" ) ; if ( hasContext ) { ctxt . generateJavaSource ( ""String "" + contextName + "" = "" ) ; ctxt . generateAttribute ( ""context"" ) ; ctxt . generateJavaSource ( "";"" ) ; ctxt . generateJavaSource ( ""if((!"" + contextName + "".startsWith(\""/\"")) "" + ""|| (!"" + urlName + "".startsWith(\""/\""))){"" ) ; ctxt . generateJavaSource ( ""    throw new JspTagException"" + ""(\""In URL tags, when the \\\""context\\\"" attribute is specified, "" + ""values of both \\\""context\\\"" and \\\""url\\\"" must start with \\\""/\\\"".\"");"" ) ; ctxt . generateJavaSource ( ""}"" ) ; } ctxt . generateJavaSource ( ""String "" + charSetName + "" = null;"" ) ; if ( hasCharEncoding ) { ctxt . generateJavaSource ( ""String "" + charEncodingName + "" = "" ) ; ctxt . generateAttribute ( ""charEncoding"" ) ; ctxt . generateJavaSource ( "";"" ) ; ctxt . generateJavaSource ( ""if(null != "" + charEncodingName + "" "" + ""&& !"" + charEncodingName + "".equals(\""\"")){"" ) ; ctxt . generateJavaSource ( ""    "" + charSetName + "" = "" + charEncodingName + "";"" ) ; ctxt . generateJavaSource ( ""}"" ) ; } ctxt . generateJavaSource ( ""if(!"" + iauName + ""){"" ) ; ctxt . generateJavaSource ( ""    if(!"" + urlName + "".startsWith(\""/\"")){"" ) ; ctxt . generateJavaSource ( ""        String "" + servletPathName + "" = "" + ""((HttpServletRequest)pageContext.getRequest()).getServletPath();"" ) ; ctxt . generateJavaSource ( ""        "" + urlName + "" = "" + servletPathName + "".substring(0,"" + servletPathName + "".lastIndexOf('/')) + '/' + "" + urlName + "";"" ) ; ctxt . generateJavaSource ( ""    }"" ) ; ctxt . generateJavaSource ( ""}"" ) ; if ( hasVarReader ) { ctxt . generateJavaSource ( ""String "" + varReaderName + "" = "" ) ; ctxt . generateAttribute ( ""varReader"" ) ; ctxt . generateJavaSource ( "";"" ) ; ctxt . generateJavaSource ( ""if("" + iauName + ""){"" ) ; ctxt . generateJavaSource ( ""    java.net.URL "" + urlObjName + "" = new java.net.URL("" + urlName + "");"" ) ; ctxt . generateJavaSource ( ""    java.net.URLConnection "" + ucName + "" = "" + urlObjName + "".openConnection();"" ) ; ctxt . generateJavaSource ( ""    java.io.InputStream "" + inputStreamName + "" = "" + ucName + "".getInputStream();"" ) ; ctxt . generateJavaSource ( ""    if("" + charSetName + "" == null){"" ) ; ctxt . generateJavaSource ( ""        String "" + contentTypeName + "" = "" + ucName + "".getContentType();"" ) ; ctxt . generateJavaSource ( ""        if(null != "" + contentTypeName + ""){"" ) ; ctxt . generateJavaSource ( ""            "" + charSetName + "" = "" + ""org.apache.jasper.tagplugins.jstl.Util.getContentTypeAttribute("" + contentTypeName + "", \""charset\"");"" ) ; ctxt . generateJavaSource ( ""            if("" + charSetName + "" == null) "" + charSetName + "" = org.apache.jasper.tagplugins.jstl.Util.DEFAULT_ENCODING;"" ) ; ctxt . generateJavaSource ( ""        }else{"" ) ; ctxt . generateJavaSource ( ""            "" + charSetName + "" = org.apache.jasper.tagplugins.jstl.Util.DEFAULT_ENCODING;"" ) ; ctxt . generateJavaSource ( ""        }"" ) ; ctxt . generateJavaSource ( ""    }"" ) ; if ( ! hasCharEncoding ) { ctxt . generateJavaSource ( ""    String "" + contentTypeName + "" = "" + ucName + "".getContentType();"" ) ; } ctxt . generateJavaSource ( ""    java.io.Reader "" + tempReaderName + "" = null;"" ) ; ctxt . generateJavaSource ( ""    try{"" ) ; ctxt . generateJavaSource ( ""        "" + tempReaderName + "" = new java.io.InputStreamReader("" + inputStreamName + "", "" + charSetName + "");"" ) ; ctxt . generateJavaSource ( ""    }catch(Exception ex){"" ) ; ctxt . generateJavaSource ( ""        "" + tempReaderName + "" = new java.io.InputStreamReader("" + inputStreamName + "", org.apache.jasper.tagplugins.jstl.Util.DEFAULT_ENCODING);"" ) ; ctxt . generateJavaSource ( ""    }"" ) ; ctxt . generateJavaSource ( ""    if("" + ucName + "" instanceof java.net.HttpURLConnection){"" ) ; ctxt . generateJavaSource ( ""        int status = ((java.net.HttpURLConnection) "" + ucName + "").getResponseCode();"" ) ; ctxt . generateJavaSource ( ""        if(status < 200 || status > 299){"" ) ; ctxt . generateJavaSource ( ""            throw new JspTagException(status + \"" \"" + "" + urlName + "");"" ) ; ctxt . generateJavaSource ( ""        }"" ) ; ctxt . generateJavaSource ( ""    }"" ) ; ctxt . generateJavaSource ( ""    pageContext.setAttribute("" + varReaderName + "", "" + tempReaderName + "");"" ) ; ctxt . generateJavaSource ( ""}else{"" ) ; ctxt . generateJavaSource ( ""    if (!(pageContext.getRequest() instanceof HttpServletRequest  "" + ""&& pageContext.getResponse() instanceof HttpServletResponse)){"" ) ; ctxt . generateJavaSource ( ""        throw new JspTagException(\""Relative &lt;import&gt; from non-HTTP request not allowed\"");"" ) ; ctxt . generateJavaSource ( ""    }"" ) ; ctxt . generateJavaSource ( ""    ServletContext "" + servletContextName + "" = null;"" ) ; if ( hasContext ) { ctxt . generateJavaSource ( ""    if(null != "" + contextName + ""){"" ) ; ctxt . generateJavaSource ( ""        "" + servletContextName + "" = pageContext.getServletContext().getContext("" + contextName + "");"" ) ; ctxt . generateJavaSource ( ""    }else{"" ) ; ctxt . generateJavaSource ( ""        "" + servletContextName + "" = pageContext.getServletContext();"" ) ; ctxt . generateJavaSource ( ""    }"" ) ; } else { ctxt . generateJavaSource ( ""    "" + servletContextName + "" = pageContext.getServletContext();"" ) ; } ctxt . generateJavaSource ( ""    if("" + servletContextName + "" == null){"" ) ; if ( hasContext ) { ctxt . generateJavaSource ( ""        throw new JspTagException(\""Unable to get RequestDispatcher for Context: \\\"" \""+"" + contextName + ""+\"" \\\"" and URL: \\\"" \"" +"" + urlName + ""+ \"" \\\"". Verify values and/or enable cross context access.\"");"" ) ; } else { ctxt . generateJavaSource ( ""        throw new JspTagException(\""Unable to get RequestDispatcher for  URL: \\\"" \"" +"" + urlName + ""+ \"" \\\"". Verify values and/or enable cross context access.\"");"" ) ; } ctxt . generateJavaSource ( ""    }"" ) ; ctxt . generateJavaSource ( ""    RequestDispatcher "" + requestDispatcherName + "" = "" + servletContextName + "".getRequestDispatcher(org.apache.jasper.tagplugins.jstl.Util.stripSession("" + urlName + ""));"" ) ; ctxt . generateJavaSource ( ""    if("" + requestDispatcherName + "" == null) throw new JspTagException(org.apache.jasper.tagplugins.jstl.Util.stripSession("" + urlName + ""));"" ) ; ctxt . generateJavaSource ( ""    org.apache.jasper.tagplugins.jstl.Util.ImportResponseWrapper "" + irwName + "" = new org.apache.jasper.tagplugins.jstl.Util.ImportResponseWrapper((HttpServletResponse) pageContext.getResponse());"" ) ; ctxt . generateJavaSource ( ""    if("" + charSetName + "" == null){"" ) ; ctxt . generateJavaSource ( ""        "" + charSetName + "" = org.apache.jasper.tagplugins.jstl.Util.DEFAULT_ENCODING;"" ) ; ctxt . generateJavaSource ( ""    }"" ) ; ctxt . generateJavaSource ( ""    "" + irwName + "".setCharEncoding("" + charSetName + "");"" ) ; ctxt . generateJavaSource ( ""    try{"" ) ; ctxt . generateJavaSource ( ""        "" + requestDispatcherName + "".include(pageContext.getRequest(), "" + irwName + "");"" ) ; ctxt . generateJavaSource ( ""    }catch(java.io.IOException ex){"" ) ; ctxt . generateJavaSource ( ""        throw new JspException(ex);"" ) ; ctxt . generateJavaSource ( ""    }catch(RuntimeException ex){"" ) ; ctxt . generateJavaSource ( ""        throw new JspException(ex);"" ) ; ctxt . generateJavaSource ( ""    }catch(ServletException ex){"" ) ; ctxt . generateJavaSource ( ""        Throwable rc = ex.getRootCause();"" ) ; ctxt . generateJavaSource ( ""        if (rc == null)"" ) ; ctxt . generateJavaSource ( ""            throw new JspException(ex);"" ) ; ctxt . generateJavaSource ( ""        else"" ) ; ctxt . generateJavaSource ( ""            throw new JspException(rc);"" ) ; ctxt . generateJavaSource ( ""    }"" ) ; ctxt . generateJavaSource ( ""    if("" + irwName + "".getStatus() < 200 || "" + irwName + "".getStatus() > 299){"" ) ; ctxt . generateJavaSource ( ""        throw new JspTagException("" + irwName + "".getStatus()+\"" \"" + org.apache.jasper.tagplugins.jstl.Util.stripSession("" + urlName + ""));"" ) ; ctxt . generateJavaSource ( ""    }"" ) ; ctxt . generateJavaSource ( ""    java.io.Reader "" + tempReaderName + "" = new java.io.StringReader("" + irwName + "".getString());"" ) ; ctxt . generateJavaSource ( ""    pageContext.setAttribute("" + varReaderName + "", "" + tempReaderName + "");"" ) ; ctxt . generateJavaSource ( ""}"" ) ; ctxt . generateBody ( ) ; ctxt . generateJavaSource ( ""java.io.Reader "" + tempReaderName2 + "" = (java.io.Reader)pageContext.getAttribute("" + varReaderName + "");"" ) ; ctxt . generateJavaSource ( ""if("" + tempReaderName2 + "" != null) "" + tempReaderName2 + "".close();"" ) ; ctxt . generateJavaSource ( ""pageContext.removeAttribute("" + varReaderName + "",1);"" ) ; } else { ctxt . generateJavaSource ( ""pageContext.setAttribute(\""url_without_param\"","" + urlName + "");"" ) ; ctxt . generateBody ( ) ; ctxt . generateJavaSource ( urlName + "" = (String)pageContext.getAttribute(\""url_without_param\"");"" ) ; ctxt . generateJavaSource ( ""pageContext.removeAttribute(\""url_without_param\"");"" ) ; String strScope = ""page"" ; if ( hasScope ) { strScope = ctxt . getConstantAttribute ( ""scope"" ) ; } int iScope = Util . getScope ( strScope ) ; ctxt . generateJavaSource ( ""String "" + tempStringName + "" = null;"" ) ; ctxt . generateJavaSource ( ""if("" + iauName + ""){"" ) ; ctxt . generateJavaSource ( ""    java.net.URL "" + urlObjName + "" = new java.net.URL("" + urlName + "");"" ) ; ctxt . generateJavaSource ( ""    java.net.URLConnection "" + ucName + "" = "" + urlObjName + "".openConnection();"" ) ; ctxt . generateJavaSource ( ""    java.io.InputStream "" + inputStreamName + "" = "" + ucName + "".getInputStream();"" ) ; ctxt . generateJavaSource ( ""    java.io.Reader "" + tempReaderName + "" = null;"" ) ; ctxt . generateJavaSource ( ""    if("" + charSetName + "" == null){"" ) ; ctxt . generateJavaSource ( ""        String "" + contentTypeName + "" = "" + ucName + "".getContentType();"" ) ; ctxt . generateJavaSource ( ""        if(null != "" + contentTypeName + ""){"" ) ; ctxt . generateJavaSource ( ""            "" + charSetName + "" = "" + ""org.apache.jasper.tagplugins.jstl.Util.getContentTypeAttribute("" + contentTypeName + "", \""charset\"");"" ) ; ctxt . generateJavaSource ( ""            if("" + charSetName + "" == null) "" + charSetName + "" = org.apache.jasper.tagplugins.jstl.Util.DEFAULT_ENCODING;"" ) ; ctxt . generateJavaSource ( ""        }else{"" ) ; ctxt . generateJavaSource ( ""            "" + charSetName + "" = org.apache.jasper.tagplugins.jstl.Util.DEFAULT_ENCODING;"" ) ; ctxt . generateJavaSource ( ""        }"" ) ; ctxt . generateJavaSource ( ""    }"" ) ; ctxt . generateJavaSource ( ""    try{"" ) ; ctxt . generateJavaSource ( ""        "" + tempReaderName + "" = new java.io.InputStreamReader("" + inputStreamName + "","" + charSetName + "");"" ) ; ctxt . generateJavaSource ( ""    }catch(Exception ex){"" ) ; ctxt . generateJavaSource ( ""        "" + tempReaderName + "" = new java.io.InputStreamReader("" + inputStreamName + "",org.apache.jasper.tagplugins.jstl.Util.DEFAULT_ENCODING);"" ) ; ctxt . generateJavaSource ( ""    }"" ) ; ctxt . generateJavaSource ( ""    if("" + ucName + "" instanceof java.net.HttpURLConnection){"" ) ; ctxt . generateJavaSource ( ""        int status = ((java.net.HttpURLConnection) "" + ucName + "").getResponseCode();"" ) ; ctxt . generateJavaSource ( ""        if(status < 200 || status > 299){"" ) ; ctxt . generateJavaSource ( ""            throw new JspTagException(status + \"" \"" + "" + urlName + "");"" ) ; ctxt . generateJavaSource ( ""        }"" ) ; ctxt . generateJavaSource ( ""    }"" ) ; ctxt . generateJavaSource ( ""    java.io.BufferedReader "" + brName + "" =  new java.io.BufferedReader("" + tempReaderName + "");"" ) ; ctxt . generateJavaSource ( ""    StringBuilder "" + sbName + "" = new StringBuilder();"" ) ; String index = ctxt . getTemporaryVariableName ( ) ; ctxt . generateJavaSource ( ""    int "" + index + "";"" ) ; ctxt . generateJavaSource ( ""    while(("" + index + "" = "" + brName + "".read()) != -1) "" + sbName + "".append((char)"" + index + "");"" ) ; ctxt . generateJavaSource ( ""    "" + tempStringName + "" = "" + sbName + "".toString();"" ) ; ctxt . generateJavaSource ( ""}else{"" ) ; ctxt . generateJavaSource ( ""    if (!(pageContext.getRequest() instanceof HttpServletRequest  "" + ""&& pageContext.getResponse() instanceof HttpServletResponse)){"" ) ; ctxt . generateJavaSource ( ""        throw new JspTagException(\""Relative &lt;import&gt; from non-HTTP request not allowed\"");"" ) ; ctxt . generateJavaSource ( ""    }"" ) ; ctxt . generateJavaSource ( ""    ServletContext "" + servletContextName + "" = null;"" ) ; if ( hasContext ) { ctxt . generateJavaSource ( ""    if(null != "" + contextName + ""){"" ) ; ctxt . generateJavaSource ( ""        "" + servletContextName + "" = pageContext.getServletContext().getContext("" + contextName + "");"" ) ; ctxt . generateJavaSource ( ""    }else{"" ) ; ctxt . generateJavaSource ( ""        "" + servletContextName + "" = pageContext.getServletContext();"" ) ; ctxt . generateJavaSource ( ""    }"" ) ; } else { ctxt . generateJavaSource ( ""    "" + servletContextName + "" = pageContext.getServletContext();"" ) ; } ctxt . generateJavaSource ( ""    if("" + servletContextName + "" == null){"" ) ; if ( hasContext ) { ctxt . generateJavaSource ( ""        throw new JspTagException(\""Unable to get RequestDispatcher for Context: \\\"" \"" +"" + contextName + ""+ \"" \\\"" and URL: \\\"" \"" +"" + urlName + ""+ \"" \\\"". Verify values and/or enable cross context access.\"");"" ) ; } else { ctxt . generateJavaSource ( ""        throw new JspTagException(\""Unable to get RequestDispatcher for URL: \\\"" \"" +"" + urlName + ""+ \"" \\\"". Verify values and/or enable cross context access.\"");"" ) ; } ctxt . generateJavaSource ( ""    }"" ) ; ctxt . generateJavaSource ( ""    RequestDispatcher "" + requestDispatcherName + "" = "" + servletContextName + "".getRequestDispatcher(org.apache.jasper.tagplugins.jstl.Util.stripSession("" + urlName + ""));"" ) ; ctxt . generateJavaSource ( ""    if("" + requestDispatcherName + "" == null) throw new JspTagException(org.apache.jasper.tagplugins.jstl.Util.stripSession("" + urlName + ""));"" ) ; ctxt . generateJavaSource ( ""    org.apache.jasper.tagplugins.jstl.Util.ImportResponseWrapper "" + irwName + "" = new org.apache.jasper.tagplugins.jstl.Util.ImportResponseWrapper((HttpServletResponse) pageContext.getResponse());"" ) ; ctxt . generateJavaSource ( ""    if("" + charSetName + "" == null){"" ) ; ctxt . generateJavaSource ( ""        "" + charSetName + "" = org.apache.jasper.tagplugins.jstl.Util.DEFAULT_ENCODING;"" ) ; ctxt . generateJavaSource ( ""    }"" ) ; ctxt . generateJavaSource ( ""    "" + irwName + "".setCharEncoding("" + charSetName + "");"" ) ; ctxt . generateJavaSource ( ""    try{"" ) ; ctxt . generateJavaSource ( ""        "" + requestDispatcherName + "".include(pageContext.getRequest(), "" + irwName + "");"" ) ; ctxt . generateJavaSource ( ""    }catch(java.io.IOException ex){"" ) ; ctxt . generateJavaSource ( ""        throw new JspException(ex);"" ) ; ctxt . generateJavaSource ( ""    }catch(RuntimeException ex){"" ) ; ctxt . generateJavaSource ( ""        throw new JspException(ex);"" ) ; ctxt . generateJavaSource ( ""    }catch(ServletException ex){"" ) ; ctxt . generateJavaSource ( ""        Throwable rc = ex.getRootCause();"" ) ; ctxt . generateJavaSource ( ""        if (rc == null)"" ) ; ctxt . generateJavaSource ( ""            throw new JspException(ex);"" ) ; ctxt . generateJavaSource ( ""        else"" ) ; ctxt . generateJavaSource ( ""            throw new JspException(rc);"" ) ; ctxt . generateJavaSource ( ""    }"" ) ; ctxt . generateJavaSource ( ""    if("" + irwName + "".getStatus() < 200 || "" + irwName + "".getStatus() > 299){"" ) ; ctxt . generateJavaSource ( ""        throw new JspTagException("" + irwName + "".getStatus()+\"" \"" + org.apache.jasper.tagplugins.jstl.Util.stripSession("" + urlName + ""));"" ) ; ctxt . generateJavaSource ( ""    }"" ) ; ctxt . generateJavaSource ( ""    "" + tempStringName + "" = "" + irwName + "".getString();"" ) ; ctxt . generateJavaSource ( ""}"" ) ; if ( hasVar ) { String strVar = ctxt . getConstantAttribute ( ""var"" ) ; ctxt . generateJavaSource ( ""pageContext.setAttribute(\"""" + strVar + ""\"","" + tempStringName + "","" + iScope + "");"" ) ; } else { ctxt . generateJavaSource ( ""pageContext.getOut().print("" + tempStringName + "");"" ) ; } } }",Smelly
" public void testGetFileAsInputStream ( ) throws Exception { Configuration props = ApplicationProperties . get ( ""test.properties"" ) ; InputStream inStr = null ; try { inStr = ApplicationProperties . getFileAsInputStream ( props , ""jaas.properties.file"" , null ) ; assertNotNull ( inStr ) ; } finally { if ( inStr != null ) { inStr . close ( ) ; } } props . setProperty ( ""jaas.properties.file"" , ""src/test/resources/atlas-jaas.properties"" ) ; try { inStr = ApplicationProperties . getFileAsInputStream ( props , ""jaas.properties.file"" , null ) ; assertNotNull ( inStr ) ; } finally { if ( inStr != null ) { inStr . close ( ) ; } } try { inStr = ApplicationProperties . getFileAsInputStream ( props , ""property.not.specified.in.config"" , ""atlas-jaas.properties"" ) ; assertNotNull ( inStr ) ; } finally { if ( inStr != null ) { inStr . close ( ) ; } } try { inStr = ApplicationProperties . getFileAsInputStream ( props , ""property.not.specified.in.config"" , ""src/test/resources/atlas-jaas.properties"" ) ; assertNotNull ( inStr ) ; } finally { if ( inStr != null ) { inStr . close ( ) ; } } String originalConfDirSetting = System . setProperty ( ApplicationProperties . ATLAS_CONFIGURATION_DIRECTORY_PROPERTY , ""src/test/resources"" ) ; try { inStr = ApplicationProperties . getFileAsInputStream ( props , ""property.not.specified.in.config"" , ""atlas-jaas.properties"" ) ; assertNotNull ( inStr ) ; } finally { if ( inStr != null ) { inStr . close ( ) ; } if ( originalConfDirSetting != null ) { System . setProperty ( ApplicationProperties . ATLAS_CONFIGURATION_DIRECTORY_PROPERTY , originalConfDirSetting ) ; } else { System . clearProperty ( ApplicationProperties . ATLAS_CONFIGURATION_DIRECTORY_PROPERTY ) ; } } try { inStr = ApplicationProperties . getFileAsInputStream ( props , ""property.not.specified.in.config"" , null ) ; fail ( ""Expected "" + AtlasException . class . getSimpleName ( ) + "" but none thrown"" ) ; } catch ( AtlasException e ) { } finally { if ( inStr != null ) { inStr . close ( ) ; } } props . setProperty ( ""jaas.properties.file"" , ""does_not_exist.txt"" ) ; try { inStr = ApplicationProperties . getFileAsInputStream ( props , ""jaas.properties.file"" , null ) ; fail ( ""Expected "" + AtlasException . class . getSimpleName ( ) + "" but none thrown"" ) ; } catch ( AtlasException e ) { } finally { if ( inStr != null ) { inStr . close ( ) ; } } }",Smelly
 public boolean isOffPeakHour ( int targetHour ) { if ( startHour <= endHour ) { return startHour <= targetHour && targetHour < endHour ; } return targetHour < endHour || startHour <= targetHour ; },No
" public void read ( org . apache . thrift . protocol . TProtocol prot , show_compact_result struct ) throws org . apache . thrift . TException { TTupleProtocol iprot = ( TTupleProtocol ) prot ; BitSet incoming = iprot . readBitSet ( 1 ) ; if ( incoming . get ( 0 ) ) { struct . success = new ShowCompactResponse ( ) ; struct . success . read ( iprot ) ; struct . setSuccessIsSet ( true ) ; } }",Smelly
" public void read ( org . apache . thrift . protocol . TProtocol prot , cancelProcess_result struct ) throws org . apache . thrift . TException { TTupleProtocol iprot = ( TTupleProtocol ) prot ; BitSet incoming = iprot . readBitSet ( 1 ) ; if ( incoming . get ( 0 ) ) { struct . success = iprot . readBool ( ) ; struct . setSuccessIsSet ( true ) ; } }",Smelly
 public boolean shouldClientThrottle ( short version ) { return version >= 4 ; },No
" public void looseMarshal ( OpenWireFormat wireFormat , Object o , DataOutput dataOut ) throws IOException { super . looseMarshal ( wireFormat , o , dataOut ) ; }",No
 private static < S extends org . apache . thrift . scheme . IScheme > S scheme ( org . apache . thrift . protocol . TProtocol proto ) { return ( org . apache . thrift . scheme . StandardScheme . class . equals ( proto . getScheme ( ) ) ? STANDARD_SCHEME_FACTORY : TUPLE_SCHEME_FACTORY ) . getScheme ( ) ; },Smelly
 public void setValue ( String value ) { this . value = value ; },No
" public void run ( ) { try { IThreadContext threadContext = ThreadContextFactory . make ( ) ; IJobManager jobManager = JobManagerFactory . make ( threadContext ) ; IRepositoryConnectionManager connectionManager = RepositoryConnectionManagerFactory . make ( threadContext ) ; while ( true ) { if ( Thread . currentThread ( ) . isInterrupted ( ) ) break ; try { long currentTime = System . currentTimeMillis ( ) ; if ( Logging . threads . isDebugEnabled ( ) ) Logging . threads . debug ( ""Job start thread - checking for jobs to start at "" + new Long ( currentTime ) . toString ( ) ) ; ArrayList unwaitJobs = new ArrayList ( ) ; jobManager . startJobs ( currentTime , unwaitJobs ) ; int k = 0 ; while ( k < unwaitJobs . size ( ) ) { Long jobID = ( Long ) unwaitJobs . get ( k ++ ) ; IJobDescription desc = jobManager . load ( jobID ) ; connectionManager . recordHistory ( desc . getConnectionName ( ) , null , connectionManager . ACTIVITY_JOBUNWAIT , null , desc . getID ( ) . toString ( ) + ""("" + desc . getDescription ( ) + "")"" , null , null , null ) ; } ArrayList waitJobs = new ArrayList ( ) ; jobManager . waitJobs ( currentTime , waitJobs ) ; k = 0 ; while ( k < waitJobs . size ( ) ) { Long jobID = ( Long ) waitJobs . get ( k ++ ) ; IJobDescription desc = jobManager . load ( jobID ) ; connectionManager . recordHistory ( desc . getConnectionName ( ) , null , connectionManager . ACTIVITY_JOBWAIT , null , desc . getID ( ) . toString ( ) + ""("" + desc . getDescription ( ) + "")"" , null , null , null ) ; } ManifoldCF . sleep ( 10000L ) ; } catch ( ManifoldCFException e ) { if ( e . getErrorCode ( ) == ManifoldCFException . INTERRUPTED ) break ; if ( e . getErrorCode ( ) == ManifoldCFException . DATABASE_CONNECTION_ERROR ) { Logging . threads . error ( ""Job start thread aborting and restarting due to database connection reset: "" + e . getMessage ( ) , e ) ; try { ManifoldCF . sleep ( 10000L ) ; } catch ( InterruptedException se ) { break ; } continue ; } Logging . threads . error ( ""Exception tossed: "" + e . getMessage ( ) , e ) ; if ( e . getErrorCode ( ) == ManifoldCFException . SETUP_ERROR ) { System . exit ( 1 ) ; } } catch ( InterruptedException e ) { break ; } catch ( OutOfMemoryError e ) { System . err . println ( ""agents process ran out of memory - shutting down"" ) ; e . printStackTrace ( System . err ) ; System . exit ( - 200 ) ; } catch ( Throwable e ) { Logging . threads . fatal ( ""Error tossed: "" + e . getMessage ( ) , e ) ; } } } catch ( Throwable e ) { System . err . println ( ""agents process could not start - shutting down"" ) ; Logging . threads . fatal ( ""JobStartThread initialization error tossed: "" + e . getMessage ( ) , e ) ; System . exit ( - 300 ) ; } }",Smelly
" public static boolean matches ( final Type type , final MapperConverter adapter ) { Type convertType = null ; if ( ConverterAdapter . class . isInstance ( adapter ) ) { final Converter delegate = ConverterAdapter . class . cast ( adapter ) . getConverter ( ) ; if ( Converter . TypeAccess . class . isInstance ( delegate ) ) { convertType = Converter . TypeAccess . class . cast ( delegate ) . type ( ) ; } else { for ( final Type pt : delegate . getClass ( ) . getGenericInterfaces ( ) ) { if ( ParameterizedType . class . isInstance ( pt ) && ParameterizedType . class . cast ( pt ) . getRawType ( ) == Converter . class ) { convertType = ParameterizedType . class . cast ( pt ) . getActualTypeArguments ( ) [ 0 ] ; break ; } } } } else if ( TypeAwareAdapter . class . isInstance ( adapter ) ) { convertType = TypeAwareAdapter . class . cast ( adapter ) . getFrom ( ) ; } if ( convertType == null ) { return true ; } if ( ParameterizedType . class . isInstance ( type ) ) { final ParameterizedType parameterizedType = ParameterizedType . class . cast ( type ) ; final Type rawType = parameterizedType . getRawType ( ) ; if ( Class . class . isInstance ( rawType ) ) { final Class < ? > clazz = Class . class . cast ( rawType ) ; if ( Collection . class . isAssignableFrom ( clazz ) && parameterizedType . getActualTypeArguments ( ) . length == 1 ) { final Type argType = parameterizedType . getActualTypeArguments ( ) [ 0 ] ; if ( Class . class . isInstance ( argType ) && Class . class . isInstance ( convertType ) ) { return ! Class . class . cast ( convertType ) . isAssignableFrom ( Class . class . cast ( argType ) ) ; } } else if ( Map . class . isAssignableFrom ( clazz ) && parameterizedType . getActualTypeArguments ( ) . length == 2 ) { final Type argType = parameterizedType . getActualTypeArguments ( ) [ 1 ] ; if ( Class . class . isInstance ( argType ) && Class . class . isInstance ( convertType ) ) { return ! Class . class . cast ( convertType ) . isAssignableFrom ( Class . class . cast ( argType ) ) ; } } return true ; } } if ( Class . class . isInstance ( type ) ) { final Class < ? > clazz = Class . class . cast ( type ) ; if ( clazz . isArray ( ) ) { return ! Class . class . cast ( convertType ) . isAssignableFrom ( clazz . getComponentType ( ) ) ; } } return true ; }",Smelly
" public ConsumersManager build ( Node node , Map < String , String > runtimeAttributes , ArrayBlockingQueue < FileResource > queue ) { ConsumersManager manager = super . build ( node , runtimeAttributes , queue ) ; boolean hangOnInit = runtimeAttributes . containsKey ( ""hangOnInit"" ) ; boolean hangOnShutdown = runtimeAttributes . containsKey ( ""hangOnShutdown"" ) ; return new MockConsumersManager ( manager , hangOnInit , hangOnShutdown ) ; }",No
" public com . google . protobuf . ExtensionRegistry assignDescriptors ( com . google . protobuf . Descriptors . FileDescriptor root ) { descriptor = root ; internal_static_exec_shared_UserCredentials_descriptor = getDescriptor ( ) . getMessageTypes ( ) . get ( 0 ) ; internal_static_exec_shared_UserCredentials_fieldAccessorTable = new com . google . protobuf . GeneratedMessage . FieldAccessorTable ( internal_static_exec_shared_UserCredentials_descriptor , new java . lang . String [ ] { ""UserName"" , } ) ; internal_static_exec_shared_QueryId_descriptor = getDescriptor ( ) . getMessageTypes ( ) . get ( 1 ) ; internal_static_exec_shared_QueryId_fieldAccessorTable = new com . google . protobuf . GeneratedMessage . FieldAccessorTable ( internal_static_exec_shared_QueryId_descriptor , new java . lang . String [ ] { ""Part1"" , ""Part2"" , } ) ; internal_static_exec_shared_DrillPBError_descriptor = getDescriptor ( ) . getMessageTypes ( ) . get ( 2 ) ; internal_static_exec_shared_DrillPBError_fieldAccessorTable = new com . google . protobuf . GeneratedMessage . FieldAccessorTable ( internal_static_exec_shared_DrillPBError_descriptor , new java . lang . String [ ] { ""ErrorId"" , ""Endpoint"" , ""ErrorType"" , ""Message"" , ""Exception"" , ""ParsingError"" , } ) ; internal_static_exec_shared_ExceptionWrapper_descriptor = getDescriptor ( ) . getMessageTypes ( ) . get ( 3 ) ; internal_static_exec_shared_ExceptionWrapper_fieldAccessorTable = new com . google . protobuf . GeneratedMessage . FieldAccessorTable ( internal_static_exec_shared_ExceptionWrapper_descriptor , new java . lang . String [ ] { ""ExceptionClass"" , ""Message"" , ""StackTrace"" , ""Cause"" , } ) ; internal_static_exec_shared_StackTraceElementWrapper_descriptor = getDescriptor ( ) . getMessageTypes ( ) . get ( 4 ) ; internal_static_exec_shared_StackTraceElementWrapper_fieldAccessorTable = new com . google . protobuf . GeneratedMessage . FieldAccessorTable ( internal_static_exec_shared_StackTraceElementWrapper_descriptor , new java . lang . String [ ] { ""ClassName"" , ""FileName"" , ""LineNumber"" , ""MethodName"" , ""IsNativeMethod"" , } ) ; internal_static_exec_shared_ParsingError_descriptor = getDescriptor ( ) . getMessageTypes ( ) . get ( 5 ) ; internal_static_exec_shared_ParsingError_fieldAccessorTable = new com . google . protobuf . GeneratedMessage . FieldAccessorTable ( internal_static_exec_shared_ParsingError_descriptor , new java . lang . String [ ] { ""StartColumn"" , ""StartRow"" , ""EndColumn"" , ""EndRow"" , } ) ; internal_static_exec_shared_RecordBatchDef_descriptor = getDescriptor ( ) . getMessageTypes ( ) . get ( 6 ) ; internal_static_exec_shared_RecordBatchDef_fieldAccessorTable = new com . google . protobuf . GeneratedMessage . FieldAccessorTable ( internal_static_exec_shared_RecordBatchDef_descriptor , new java . lang . String [ ] { ""RecordCount"" , ""Field"" , ""CarriesTwoByteSelectionVector"" , } ) ; internal_static_exec_shared_NamePart_descriptor = getDescriptor ( ) . getMessageTypes ( ) . get ( 7 ) ; internal_static_exec_shared_NamePart_fieldAccessorTable = new com . google . protobuf . GeneratedMessage . FieldAccessorTable ( internal_static_exec_shared_NamePart_descriptor , new java . lang . String [ ] { ""Type"" , ""Name"" , ""Child"" , } ) ; internal_static_exec_shared_SerializedField_descriptor = getDescriptor ( ) . getMessageTypes ( ) . get ( 8 ) ; internal_static_exec_shared_SerializedField_fieldAccessorTable = new com . google . protobuf . GeneratedMessage . FieldAccessorTable ( internal_static_exec_shared_SerializedField_descriptor , new java . lang . String [ ] { ""MajorType"" , ""NamePart"" , ""Child"" , ""ValueCount"" , ""VarByteLength"" , ""BufferLength"" , } ) ; internal_static_exec_shared_NodeStatus_descriptor = getDescriptor ( ) . getMessageTypes ( ) . get ( 9 ) ; internal_static_exec_shared_NodeStatus_fieldAccessorTable = new com . google . protobuf . GeneratedMessage . FieldAccessorTable ( internal_static_exec_shared_NodeStatus_descriptor , new java . lang . String [ ] { ""NodeId"" , ""MemoryFootprint"" , } ) ; internal_static_exec_shared_QueryResult_descriptor = getDescriptor ( ) . getMessageTypes ( ) . get ( 10 ) ; internal_static_exec_shared_QueryResult_fieldAccessorTable = new com . google . protobuf . GeneratedMessage . FieldAccessorTable ( internal_static_exec_shared_QueryResult_descriptor , new java . lang . String [ ] { ""QueryState"" , ""QueryId"" , ""Error"" , } ) ; internal_static_exec_shared_QueryData_descriptor = getDescriptor ( ) . getMessageTypes ( ) . get ( 11 ) ; internal_static_exec_shared_QueryData_fieldAccessorTable = new com . google . protobuf . GeneratedMessage . FieldAccessorTable ( internal_static_exec_shared_QueryData_descriptor , new java . lang . String [ ] { ""QueryId"" , ""RowCount"" , ""Def"" , } ) ; internal_static_exec_shared_QueryInfo_descriptor = getDescriptor ( ) . getMessageTypes ( ) . get ( 12 ) ; internal_static_exec_shared_QueryInfo_fieldAccessorTable = new com . google . protobuf . GeneratedMessage . FieldAccessorTable ( internal_static_exec_shared_QueryInfo_descriptor , new java . lang . String [ ] { ""Query"" , ""Start"" , ""State"" , ""User"" , ""Foreman"" , ""OptionsJson"" , } ) ; internal_static_exec_shared_QueryProfile_descriptor = getDescriptor ( ) . getMessageTypes ( ) . get ( 13 ) ; internal_static_exec_shared_QueryProfile_fieldAccessorTable = new com . google . protobuf . GeneratedMessage . FieldAccessorTable ( internal_static_exec_shared_QueryProfile_descriptor , new java . lang . String [ ] { ""Id"" , ""Type"" , ""Start"" , ""End"" , ""Query"" , ""Plan"" , ""Foreman"" , ""State"" , ""TotalFragments"" , ""FinishedFragments"" , ""FragmentProfile"" , ""User"" , ""Error"" , ""VerboseError"" , ""ErrorId"" , ""ErrorNode"" , ""OptionsJson"" , ""PlanEnd"" , ""QueueWaitEnd"" , } ) ; internal_static_exec_shared_MajorFragmentProfile_descriptor = getDescriptor ( ) . getMessageTypes ( ) . get ( 14 ) ; internal_static_exec_shared_MajorFragmentProfile_fieldAccessorTable = new com . google . protobuf . GeneratedMessage . FieldAccessorTable ( internal_static_exec_shared_MajorFragmentProfile_descriptor , new java . lang . String [ ] { ""MajorFragmentId"" , ""MinorFragmentProfile"" , } ) ; internal_static_exec_shared_MinorFragmentProfile_descriptor = getDescriptor ( ) . getMessageTypes ( ) . get ( 15 ) ; internal_static_exec_shared_MinorFragmentProfile_fieldAccessorTable = new com . google . protobuf . GeneratedMessage . FieldAccessorTable ( internal_static_exec_shared_MinorFragmentProfile_descriptor , new java . lang . String [ ] { ""State"" , ""Error"" , ""MinorFragmentId"" , ""OperatorProfile"" , ""StartTime"" , ""EndTime"" , ""MemoryUsed"" , ""MaxMemoryUsed"" , ""Endpoint"" , ""LastUpdate"" , ""LastProgress"" , } ) ; internal_static_exec_shared_OperatorProfile_descriptor = getDescriptor ( ) . getMessageTypes ( ) . get ( 16 ) ; internal_static_exec_shared_OperatorProfile_fieldAccessorTable = new com . google . protobuf . GeneratedMessage . FieldAccessorTable ( internal_static_exec_shared_OperatorProfile_descriptor , new java . lang . String [ ] { ""InputProfile"" , ""OperatorId"" , ""OperatorType"" , ""SetupNanos"" , ""ProcessNanos"" , ""PeakLocalMemoryAllocated"" , ""Metric"" , ""WaitNanos"" , } ) ; internal_static_exec_shared_StreamProfile_descriptor = getDescriptor ( ) . getMessageTypes ( ) . get ( 17 ) ; internal_static_exec_shared_StreamProfile_fieldAccessorTable = new com . google . protobuf . GeneratedMessage . FieldAccessorTable ( internal_static_exec_shared_StreamProfile_descriptor , new java . lang . String [ ] { ""Records"" , ""Batches"" , ""Schemas"" , } ) ; internal_static_exec_shared_MetricValue_descriptor = getDescriptor ( ) . getMessageTypes ( ) . get ( 18 ) ; internal_static_exec_shared_MetricValue_fieldAccessorTable = new com . google . protobuf . GeneratedMessage . FieldAccessorTable ( internal_static_exec_shared_MetricValue_descriptor , new java . lang . String [ ] { ""MetricId"" , ""LongValue"" , ""DoubleValue"" , } ) ; internal_static_exec_shared_Registry_descriptor = getDescriptor ( ) . getMessageTypes ( ) . get ( 19 ) ; internal_static_exec_shared_Registry_fieldAccessorTable = new com . google . protobuf . GeneratedMessage . FieldAccessorTable ( internal_static_exec_shared_Registry_descriptor , new java . lang . String [ ] { ""Jar"" , } ) ; internal_static_exec_shared_Jar_descriptor = getDescriptor ( ) . getMessageTypes ( ) . get ( 20 ) ; internal_static_exec_shared_Jar_fieldAccessorTable = new com . google . protobuf . GeneratedMessage . FieldAccessorTable ( internal_static_exec_shared_Jar_descriptor , new java . lang . String [ ] { ""Name"" , ""FunctionSignature"" , } ) ; internal_static_exec_shared_SaslMessage_descriptor = getDescriptor ( ) . getMessageTypes ( ) . get ( 21 ) ; internal_static_exec_shared_SaslMessage_fieldAccessorTable = new com . google . protobuf . GeneratedMessage . FieldAccessorTable ( internal_static_exec_shared_SaslMessage_descriptor , new java . lang . String [ ] { ""Mechanism"" , ""Data"" , ""Status"" , } ) ; return null ; }",No
 private static < S extends org . apache . thrift . scheme . IScheme > S scheme ( org . apache . thrift . protocol . TProtocol proto ) { return ( org . apache . thrift . scheme . StandardScheme . class . equals ( proto . getScheme ( ) ) ? STANDARD_SCHEME_FACTORY : TUPLE_SCHEME_FACTORY ) . getScheme ( ) ; },Smelly
" public void read ( org . apache . thrift . protocol . TProtocol prot , getChildDataProducts_result struct ) throws org . apache . thrift . TException { TTupleProtocol iprot = ( TTupleProtocol ) prot ; BitSet incoming = iprot . readBitSet ( 5 ) ; if ( incoming . get ( 0 ) ) { { org . apache . thrift . protocol . TList _list283 = new org . apache . thrift . protocol . TList ( org . apache . thrift . protocol . TType . STRUCT , iprot . readI32 ( ) ) ; struct . success = new ArrayList < org . apache . airavata . model . data . replica . DataProductModel > ( _list283 . size ) ; org . apache . airavata . model . data . replica . DataProductModel _elem284 ; for ( int _i285 = 0 ; _i285 < _list283 . size ; ++ _i285 ) { _elem284 = new org . apache . airavata . model . data . replica . DataProductModel ( ) ; _elem284 . read ( iprot ) ; struct . success . add ( _elem284 ) ; } } struct . setSuccessIsSet ( true ) ; } if ( incoming . get ( 1 ) ) { struct . ire = new org . apache . airavata . model . error . InvalidRequestException ( ) ; struct . ire . read ( iprot ) ; struct . setIreIsSet ( true ) ; } if ( incoming . get ( 2 ) ) { struct . ace = new org . apache . airavata . model . error . AiravataClientException ( ) ; struct . ace . read ( iprot ) ; struct . setAceIsSet ( true ) ; } if ( incoming . get ( 3 ) ) { struct . ase = new org . apache . airavata . model . error . AiravataSystemException ( ) ; struct . ase . read ( iprot ) ; struct . setAseIsSet ( true ) ; } if ( incoming . get ( 4 ) ) { struct . ae = new org . apache . airavata . model . error . AuthorizationException ( ) ; struct . ae . read ( iprot ) ; struct . setAeIsSet ( true ) ; } }",Smelly
" public static String parseViewableString ( String s ) { int len = s . length ( ) ; StringBuffer buf = new StringBuffer ( len ) ; char c ; int ti ; for ( int i = 0 ; i < len ; i ++ ) { c = s . charAt ( i ) ; if ( c == '\\' ) { i ++ ; if ( i < len ) { switch ( s . charAt ( ( i ) ) ) { case 'b' : buf . append ( '\b' ) ; break ; case 't' : buf . append ( '\t' ) ; break ; case 'n' : buf . append ( '\n' ) ; break ; case 'f' : buf . append ( '\f' ) ; break ; case 'r' : buf . append ( '\r' ) ; break ; case '""' : buf . append ( '\""' ) ; break ; case '\\' : buf . append ( '\\' ) ; break ; case 'u' : ti = 0 ; i ++ ; c = s . charAt ( i ) ; ti = Numbers [ ( int ) c ] < < 12 ; i ++ ; c = s . charAt ( i ) ; ti = ti | ( Numbers [ ( int ) c ] < < 8 ) ; i ++ ; c = s . charAt ( i ) ; ti = ti | ( Numbers [ ( int ) c ] < < 4 ) ; i ++ ; c = s . charAt ( i ) ; ti = ti | Numbers [ ( int ) c ] ; buf . append ( ( char ) ti ) ; } } } else { buf . append ( c ) ; } } return buf . toString ( ) ; }",Smelly
 private static < S extends org . apache . thrift . scheme . IScheme > S scheme ( org . apache . thrift . protocol . TProtocol proto ) { return ( org . apache . thrift . scheme . StandardScheme . class . equals ( proto . getScheme ( ) ) ? STANDARD_SCHEME_FACTORY : TUPLE_SCHEME_FACTORY ) . getScheme ( ) ; },Smelly
" private static void writeChars ( DataOutput out , String s , int start , int length ) throws IOException { final int end = start + length ; for ( int i = start ; i < end ; i ++ ) { int code = s . charAt ( i ) ; if ( code <= 0x7F ) { out . writeByte ( ( byte ) code ) ; } else if ( code <= 0x07FF ) { out . writeByte ( ( byte ) ( 0xC0 | ( ( code > > 6 ) & 0x1F ) ) ) ; out . writeByte ( ( byte ) ( 0x80 | code & 0x3F ) ) ; } else { out . writeByte ( ( byte ) ( 0xE0 | ( ( code > > 12 ) & 0X0F ) ) ) ; out . writeByte ( ( byte ) ( 0x80 | ( ( code > > 6 ) & 0x3F ) ) ) ; out . writeByte ( ( byte ) ( 0x80 | ( code & 0x3F ) ) ) ; } } }",No
" public void read ( org . apache . thrift . protocol . TProtocol prot , TaskModel struct ) throws org . apache . thrift . TException { TTupleProtocol iprot = ( TTupleProtocol ) prot ; struct . taskId = iprot . readString ( ) ; struct . setTaskIdIsSet ( true ) ; struct . taskType = org . apache . airavata . model . task . TaskTypes . findByValue ( iprot . readI32 ( ) ) ; struct . setTaskTypeIsSet ( true ) ; struct . parentProcessId = iprot . readString ( ) ; struct . setParentProcessIdIsSet ( true ) ; struct . creationTime = iprot . readI64 ( ) ; struct . setCreationTimeIsSet ( true ) ; struct . lastUpdateTime = iprot . readI64 ( ) ; struct . setLastUpdateTimeIsSet ( true ) ; struct . taskStatus = new org . apache . airavata . model . status . TaskStatus ( ) ; struct . taskStatus . read ( iprot ) ; struct . setTaskStatusIsSet ( true ) ; BitSet incoming = iprot . readBitSet ( 4 ) ; if ( incoming . get ( 0 ) ) { struct . taskDetail = iprot . readString ( ) ; struct . setTaskDetailIsSet ( true ) ; } if ( incoming . get ( 1 ) ) { struct . subTaskModel = iprot . readBinary ( ) ; struct . setSubTaskModelIsSet ( true ) ; } if ( incoming . get ( 2 ) ) { struct . taskError = new org . apache . airavata . model . commons . ErrorModel ( ) ; struct . taskError . read ( iprot ) ; struct . setTaskErrorIsSet ( true ) ; } if ( incoming . get ( 3 ) ) { { org . apache . thrift . protocol . TList _list5 = new org . apache . thrift . protocol . TList ( org . apache . thrift . protocol . TType . STRUCT , iprot . readI32 ( ) ) ; struct . jobs = new ArrayList < org . apache . airavata . model . job . JobModel > ( _list5 . size ) ; org . apache . airavata . model . job . JobModel _elem6 ; for ( int _i7 = 0 ; _i7 < _list5 . size ; ++ _i7 ) { _elem6 = new org . apache . airavata . model . job . JobModel ( ) ; _elem6 . read ( iprot ) ; struct . jobs . add ( _elem6 ) ; } } struct . setJobsIsSet ( true ) ; } }",No
" public void read ( org . apache . thrift . protocol . TProtocol prot , show_compact_result struct ) throws org . apache . thrift . TException { TTupleProtocol iprot = ( TTupleProtocol ) prot ; BitSet incoming = iprot . readBitSet ( 1 ) ; if ( incoming . get ( 0 ) ) { struct . success = new ShowCompactResponse ( ) ; struct . success . read ( iprot ) ; struct . setSuccessIsSet ( true ) ; } }",Smelly
" public void read ( org . apache . thrift . protocol . TProtocol prot , getChildDataProducts_result struct ) throws org . apache . thrift . TException { TTupleProtocol iprot = ( TTupleProtocol ) prot ; BitSet incoming = iprot . readBitSet ( 5 ) ; if ( incoming . get ( 0 ) ) { { org . apache . thrift . protocol . TList _list283 = new org . apache . thrift . protocol . TList ( org . apache . thrift . protocol . TType . STRUCT , iprot . readI32 ( ) ) ; struct . success = new ArrayList < org . apache . airavata . model . data . replica . DataProductModel > ( _list283 . size ) ; org . apache . airavata . model . data . replica . DataProductModel _elem284 ; for ( int _i285 = 0 ; _i285 < _list283 . size ; ++ _i285 ) { _elem284 = new org . apache . airavata . model . data . replica . DataProductModel ( ) ; _elem284 . read ( iprot ) ; struct . success . add ( _elem284 ) ; } } struct . setSuccessIsSet ( true ) ; } if ( incoming . get ( 1 ) ) { struct . ire = new org . apache . airavata . model . error . InvalidRequestException ( ) ; struct . ire . read ( iprot ) ; struct . setIreIsSet ( true ) ; } if ( incoming . get ( 2 ) ) { struct . ace = new org . apache . airavata . model . error . AiravataClientException ( ) ; struct . ace . read ( iprot ) ; struct . setAceIsSet ( true ) ; } if ( incoming . get ( 3 ) ) { struct . ase = new org . apache . airavata . model . error . AiravataSystemException ( ) ; struct . ase . read ( iprot ) ; struct . setAseIsSet ( true ) ; } if ( incoming . get ( 4 ) ) { struct . ae = new org . apache . airavata . model . error . AuthorizationException ( ) ; struct . ae . read ( iprot ) ; struct . setAeIsSet ( true ) ; } }",Smelly
" public void read ( org . apache . thrift . protocol . TProtocol prot , getChildDataProducts_result struct ) throws org . apache . thrift . TException { TTupleProtocol iprot = ( TTupleProtocol ) prot ; BitSet incoming = iprot . readBitSet ( 5 ) ; if ( incoming . get ( 0 ) ) { { org . apache . thrift . protocol . TList _list283 = new org . apache . thrift . protocol . TList ( org . apache . thrift . protocol . TType . STRUCT , iprot . readI32 ( ) ) ; struct . success = new ArrayList < org . apache . airavata . model . data . replica . DataProductModel > ( _list283 . size ) ; org . apache . airavata . model . data . replica . DataProductModel _elem284 ; for ( int _i285 = 0 ; _i285 < _list283 . size ; ++ _i285 ) { _elem284 = new org . apache . airavata . model . data . replica . DataProductModel ( ) ; _elem284 . read ( iprot ) ; struct . success . add ( _elem284 ) ; } } struct . setSuccessIsSet ( true ) ; } if ( incoming . get ( 1 ) ) { struct . ire = new org . apache . airavata . model . error . InvalidRequestException ( ) ; struct . ire . read ( iprot ) ; struct . setIreIsSet ( true ) ; } if ( incoming . get ( 2 ) ) { struct . ace = new org . apache . airavata . model . error . AiravataClientException ( ) ; struct . ace . read ( iprot ) ; struct . setAceIsSet ( true ) ; } if ( incoming . get ( 3 ) ) { struct . ase = new org . apache . airavata . model . error . AiravataSystemException ( ) ; struct . ase . read ( iprot ) ; struct . setAseIsSet ( true ) ; } if ( incoming . get ( 4 ) ) { struct . ae = new org . apache . airavata . model . error . AuthorizationException ( ) ; struct . ae . read ( iprot ) ; struct . setAeIsSet ( true ) ; } }",Smelly
" public void read ( org . apache . thrift . protocol . TProtocol prot , getChildDataProducts_result struct ) throws org . apache . thrift . TException { TTupleProtocol iprot = ( TTupleProtocol ) prot ; BitSet incoming = iprot . readBitSet ( 5 ) ; if ( incoming . get ( 0 ) ) { { org . apache . thrift . protocol . TList _list283 = new org . apache . thrift . protocol . TList ( org . apache . thrift . protocol . TType . STRUCT , iprot . readI32 ( ) ) ; struct . success = new ArrayList < org . apache . airavata . model . data . replica . DataProductModel > ( _list283 . size ) ; org . apache . airavata . model . data . replica . DataProductModel _elem284 ; for ( int _i285 = 0 ; _i285 < _list283 . size ; ++ _i285 ) { _elem284 = new org . apache . airavata . model . data . replica . DataProductModel ( ) ; _elem284 . read ( iprot ) ; struct . success . add ( _elem284 ) ; } } struct . setSuccessIsSet ( true ) ; } if ( incoming . get ( 1 ) ) { struct . ire = new org . apache . airavata . model . error . InvalidRequestException ( ) ; struct . ire . read ( iprot ) ; struct . setIreIsSet ( true ) ; } if ( incoming . get ( 2 ) ) { struct . ace = new org . apache . airavata . model . error . AiravataClientException ( ) ; struct . ace . read ( iprot ) ; struct . setAceIsSet ( true ) ; } if ( incoming . get ( 3 ) ) { struct . ase = new org . apache . airavata . model . error . AiravataSystemException ( ) ; struct . ase . read ( iprot ) ; struct . setAseIsSet ( true ) ; } if ( incoming . get ( 4 ) ) { struct . ae = new org . apache . airavata . model . error . AuthorizationException ( ) ; struct . ae . read ( iprot ) ; struct . setAeIsSet ( true ) ; } }",Smelly
" public void testFixedDefaultValueDrop ( ) { Schema md5 = SchemaBuilder . builder ( ) . fixed ( ""MD5"" ) . size ( 16 ) ; Schema frec = SchemaBuilder . builder ( ) . record ( ""test"" ) . fields ( ) . name ( ""hash"" ) . type ( md5 ) . withDefault ( new byte [ 16 ] ) . endRecord ( ) ; Schema . Field field = frec . getField ( ""hash"" ) ; Assert . assertNotNull ( field . defaultVal ( ) ) ; Assert . assertArrayEquals ( new byte [ 16 ] , ( byte [ ] ) field . defaultVal ( ) ) ; }",No
 public void setCharacterEncoding ( java . lang . String s ) { },No
 protected boolean hasBusProperty ( ) { return true ; },No
 private static < S extends org . apache . thrift . scheme . IScheme > S scheme ( org . apache . thrift . protocol . TProtocol proto ) { return ( org . apache . thrift . scheme . StandardScheme . class . equals ( proto . getScheme ( ) ) ? STANDARD_SCHEME_FACTORY : TUPLE_SCHEME_FACTORY ) . getScheme ( ) ; },No
" static String add_escapes ( String str ) { StringBuffer retval = new StringBuffer ( ) ; char ch ; for ( int i = 0 ; i < str . length ( ) ; i ++ ) { switch ( str . charAt ( i ) ) { case 0 : continue ; case '\b' : retval . append ( ""\\b"" ) ; continue ; case '\t' : retval . append ( ""\\t"" ) ; continue ; case '\n' : retval . append ( ""\\n"" ) ; continue ; case '\f' : retval . append ( ""\\f"" ) ; continue ; case '\r' : retval . append ( ""\\r"" ) ; continue ; case '\""' : retval . append ( ""\\\"""" ) ; continue ; case '\'' : retval . append ( ""\\\'"" ) ; continue ; case '\\' : retval . append ( ""\\\\"" ) ; continue ; default : if ( ( ch = str . charAt ( i ) ) < 0x20 || ch > 0x7e ) { String s = ""0000"" + Integer . toString ( ch , 16 ) ; retval . append ( ""\\u"" + s . substring ( s . length ( ) - 4 , s . length ( ) ) ) ; } else { retval . append ( ch ) ; } continue ; } } return retval . toString ( ) ; }",Smelly
" protected void readState ( ObjectInputStream in ) throws IOException , ClassNotFoundException { super . readState ( in ) ; this . salary = ( Float ) in . readObject ( ) ; this . addresses = in . readObject ( ) ; this . toDepartment = in . readObject ( ) ; }",No
" public void read ( org . apache . thrift . protocol . TProtocol prot , Compacting struct ) throws org . apache . thrift . TException { TTupleProtocol iprot = ( TTupleProtocol ) prot ; BitSet incoming = iprot . readBitSet ( 2 ) ; if ( incoming . get ( 0 ) ) { struct . running = iprot . readI32 ( ) ; struct . setRunningIsSet ( true ) ; } if ( incoming . get ( 1 ) ) { struct . queued = iprot . readI32 ( ) ; struct . setQueuedIsSet ( true ) ; } }",No
" public void read ( org . apache . thrift . protocol . TProtocol prot , getFollowing_result struct ) throws org . apache . thrift . TException { TTupleProtocol iprot = ( TTupleProtocol ) prot ; BitSet incoming = iprot . readBitSet ( 1 ) ; if ( incoming . get ( 0 ) ) { struct . success = new Key ( ) ; struct . success . read ( iprot ) ; struct . setSuccessIsSet ( true ) ; } }",Smelly
 public String getXpath ( ) { return xpath ; },No
 public void close ( ) { ctx . close ( ) ; },Smelly
" public void read ( org . apache . thrift . protocol . TProtocol prot , getChildDataProducts_result struct ) throws org . apache . thrift . TException { TTupleProtocol iprot = ( TTupleProtocol ) prot ; BitSet incoming = iprot . readBitSet ( 5 ) ; if ( incoming . get ( 0 ) ) { { org . apache . thrift . protocol . TList _list283 = new org . apache . thrift . protocol . TList ( org . apache . thrift . protocol . TType . STRUCT , iprot . readI32 ( ) ) ; struct . success = new ArrayList < org . apache . airavata . model . data . replica . DataProductModel > ( _list283 . size ) ; org . apache . airavata . model . data . replica . DataProductModel _elem284 ; for ( int _i285 = 0 ; _i285 < _list283 . size ; ++ _i285 ) { _elem284 = new org . apache . airavata . model . data . replica . DataProductModel ( ) ; _elem284 . read ( iprot ) ; struct . success . add ( _elem284 ) ; } } struct . setSuccessIsSet ( true ) ; } if ( incoming . get ( 1 ) ) { struct . ire = new org . apache . airavata . model . error . InvalidRequestException ( ) ; struct . ire . read ( iprot ) ; struct . setIreIsSet ( true ) ; } if ( incoming . get ( 2 ) ) { struct . ace = new org . apache . airavata . model . error . AiravataClientException ( ) ; struct . ace . read ( iprot ) ; struct . setAceIsSet ( true ) ; } if ( incoming . get ( 3 ) ) { struct . ase = new org . apache . airavata . model . error . AiravataSystemException ( ) ; struct . ase . read ( iprot ) ; struct . setAseIsSet ( true ) ; } if ( incoming . get ( 4 ) ) { struct . ae = new org . apache . airavata . model . error . AuthorizationException ( ) ; struct . ae . read ( iprot ) ; struct . setAeIsSet ( true ) ; } }",No
" public void testTopics ( ) throws Exception { for ( Map . Entry < TopicName , PulsarRecordCursor > entry : pulsarRecordCursors . entrySet ( ) ) { log . info ( ""!------ topic %s ------!"" , entry . getKey ( ) ) ; setup ( ) ; PulsarRecordCursor pulsarRecordCursor = entry . getValue ( ) ; TopicName topicName = entry . getKey ( ) ; int count = 0 ; while ( pulsarRecordCursor . advanceNextPosition ( ) ) { List < String > columnsSeen = new LinkedList < > ( ) ; for ( int i = 0 ; i < fooColumnHandles . size ( ) ; i ++ ) { if ( pulsarRecordCursor . isNull ( i ) ) { columnsSeen . add ( fooColumnHandles . get ( i ) . getName ( ) ) ; } else { if ( fooColumnHandles . get ( i ) . getName ( ) . equals ( ""field1"" ) ) { assertEquals ( pulsarRecordCursor . getLong ( i ) , ( ( Integer ) fooFunctions . get ( ""field1"" ) . apply ( count ) ) . longValue ( ) ) ; columnsSeen . add ( fooColumnHandles . get ( i ) . getName ( ) ) ; } else if ( fooColumnHandles . get ( i ) . getName ( ) . equals ( ""field2"" ) ) { assertEquals ( pulsarRecordCursor . getSlice ( i ) . getBytes ( ) , ( ( String ) fooFunctions . get ( ""field2"" ) . apply ( count ) ) . getBytes ( ) ) ; columnsSeen . add ( fooColumnHandles . get ( i ) . getName ( ) ) ; } else if ( fooColumnHandles . get ( i ) . getName ( ) . equals ( ""field3"" ) ) { assertEquals ( pulsarRecordCursor . getLong ( i ) , Float . floatToIntBits ( ( ( Float ) fooFunctions . get ( ""field3"" ) . apply ( count ) ) . floatValue ( ) ) ) ; columnsSeen . add ( fooColumnHandles . get ( i ) . getName ( ) ) ; } else if ( fooColumnHandles . get ( i ) . getName ( ) . equals ( ""field4"" ) ) { assertEquals ( pulsarRecordCursor . getDouble ( i ) , ( ( Double ) fooFunctions . get ( ""field4"" ) . apply ( count ) ) . doubleValue ( ) ) ; columnsSeen . add ( fooColumnHandles . get ( i ) . getName ( ) ) ; } else if ( fooColumnHandles . get ( i ) . getName ( ) . equals ( ""field5"" ) ) { assertEquals ( pulsarRecordCursor . getBoolean ( i ) , ( ( Boolean ) fooFunctions . get ( ""field5"" ) . apply ( count ) ) . booleanValue ( ) ) ; columnsSeen . add ( fooColumnHandles . get ( i ) . getName ( ) ) ; } else if ( fooColumnHandles . get ( i ) . getName ( ) . equals ( ""field6"" ) ) { assertEquals ( pulsarRecordCursor . getLong ( i ) , ( ( Long ) fooFunctions . get ( ""field6"" ) . apply ( count ) ) . longValue ( ) ) ; columnsSeen . add ( fooColumnHandles . get ( i ) . getName ( ) ) ; } else if ( fooColumnHandles . get ( i ) . getName ( ) . equals ( ""timestamp"" ) ) { pulsarRecordCursor . getLong ( i ) ; columnsSeen . add ( fooColumnHandles . get ( i ) . getName ( ) ) ; } else if ( fooColumnHandles . get ( i ) . getName ( ) . equals ( ""time"" ) ) { pulsarRecordCursor . getLong ( i ) ; columnsSeen . add ( fooColumnHandles . get ( i ) . getName ( ) ) ; } else if ( fooColumnHandles . get ( i ) . getName ( ) . equals ( ""date"" ) ) { pulsarRecordCursor . getLong ( i ) ; columnsSeen . add ( fooColumnHandles . get ( i ) . getName ( ) ) ; } else if ( fooColumnHandles . get ( i ) . getName ( ) . equals ( ""bar.field1"" ) ) { assertEquals ( pulsarRecordCursor . getLong ( i ) , ( ( Integer ) fooFunctions . get ( ""bar.field1"" ) . apply ( count ) ) . longValue ( ) ) ; columnsSeen . add ( fooColumnHandles . get ( i ) . getName ( ) ) ; } else if ( fooColumnHandles . get ( i ) . getName ( ) . equals ( ""bar.field2"" ) ) { assertEquals ( pulsarRecordCursor . getSlice ( i ) . getBytes ( ) , ( ( String ) fooFunctions . get ( ""bar.field2"" ) . apply ( count ) ) . getBytes ( ) ) ; columnsSeen . add ( fooColumnHandles . get ( i ) . getName ( ) ) ; } else if ( fooColumnHandles . get ( i ) . getName ( ) . equals ( ""bar.field3"" ) ) { assertEquals ( pulsarRecordCursor . getLong ( i ) , Float . floatToIntBits ( ( ( Float ) fooFunctions . get ( ""bar.field3"" ) . apply ( count ) ) . floatValue ( ) ) ) ; columnsSeen . add ( fooColumnHandles . get ( i ) . getName ( ) ) ; } else if ( fooColumnHandles . get ( i ) . getName ( ) . equals ( ""bar.test.field4"" ) ) { assertEquals ( pulsarRecordCursor . getDouble ( i ) , ( ( Double ) fooFunctions . get ( ""bar.test.field4"" ) . apply ( count ) ) . doubleValue ( ) ) ; columnsSeen . add ( fooColumnHandles . get ( i ) . getName ( ) ) ; } else if ( fooColumnHandles . get ( i ) . getName ( ) . equals ( ""bar.test.field5"" ) ) { assertEquals ( pulsarRecordCursor . getBoolean ( i ) , ( ( Boolean ) fooFunctions . get ( ""bar.test.field5"" ) . apply ( count ) ) . booleanValue ( ) ) ; columnsSeen . add ( fooColumnHandles . get ( i ) . getName ( ) ) ; } else if ( fooColumnHandles . get ( i ) . getName ( ) . equals ( ""bar.test.field6"" ) ) { assertEquals ( pulsarRecordCursor . getLong ( i ) , ( ( Long ) fooFunctions . get ( ""bar.test.field6"" ) . apply ( count ) ) . longValue ( ) ) ; columnsSeen . add ( fooColumnHandles . get ( i ) . getName ( ) ) ; } else if ( fooColumnHandles . get ( i ) . getName ( ) . equals ( ""bar.test.foobar.field1"" ) ) { assertEquals ( pulsarRecordCursor . getLong ( i ) , ( ( Integer ) fooFunctions . get ( ""bar.test.foobar.field1"" ) . apply ( count ) ) . longValue ( ) ) ; columnsSeen . add ( fooColumnHandles . get ( i ) . getName ( ) ) ; } else if ( fooColumnHandles . get ( i ) . getName ( ) . equals ( ""bar.test2.field4"" ) ) { assertEquals ( pulsarRecordCursor . getDouble ( i ) , ( ( Double ) fooFunctions . get ( ""bar.test2.field4"" ) . apply ( count ) ) . doubleValue ( ) ) ; columnsSeen . add ( fooColumnHandles . get ( i ) . getName ( ) ) ; } else if ( fooColumnHandles . get ( i ) . getName ( ) . equals ( ""bar.test2.field5"" ) ) { assertEquals ( pulsarRecordCursor . getBoolean ( i ) , ( ( Boolean ) fooFunctions . get ( ""bar.test2.field5"" ) . apply ( count ) ) . booleanValue ( ) ) ; columnsSeen . add ( fooColumnHandles . get ( i ) . getName ( ) ) ; } else if ( fooColumnHandles . get ( i ) . getName ( ) . equals ( ""bar.test2.field6"" ) ) { assertEquals ( pulsarRecordCursor . getLong ( i ) , ( ( Long ) fooFunctions . get ( ""bar.test2.field6"" ) . apply ( count ) ) . longValue ( ) ) ; columnsSeen . add ( fooColumnHandles . get ( i ) . getName ( ) ) ; } else if ( fooColumnHandles . get ( i ) . getName ( ) . equals ( ""bar.test2.foobar.field1"" ) ) { assertEquals ( pulsarRecordCursor . getLong ( i ) , ( ( Integer ) fooFunctions . get ( ""bar.test2.foobar.field1"" ) . apply ( count ) ) . longValue ( ) ) ; columnsSeen . add ( fooColumnHandles . get ( i ) . getName ( ) ) ; } else if ( fooColumnHandles . get ( i ) . getName ( ) . equals ( ""field7"" ) ) { assertEquals ( pulsarRecordCursor . getSlice ( i ) . getBytes ( ) , fooFunctions . get ( ""field7"" ) . apply ( count ) . toString ( ) . getBytes ( ) ) ; columnsSeen . add ( fooColumnHandles . get ( i ) . getName ( ) ) ; } else { if ( PulsarInternalColumn . getInternalFieldsMap ( ) . containsKey ( fooColumnHandles . get ( i ) . getName ( ) ) ) { columnsSeen . add ( fooColumnHandles . get ( i ) . getName ( ) ) ; } } } } assertEquals ( columnsSeen . size ( ) , fooColumnHandles . size ( ) ) ; count ++ ; } assertEquals ( count , topicsToNumEntries . get ( topicName . getSchemaName ( ) ) . longValue ( ) ) ; assertEquals ( pulsarRecordCursor . getCompletedBytes ( ) , completedBytes ) ; cleanup ( ) ; pulsarRecordCursor . close ( ) ; } }",Smelly
 private ISearch getSearchInput ( ) { if ( getInput ( ) instanceof ISearch ) { return ( ISearch ) getInput ( ) ; } else { return null ; } },No
" public void read ( org . apache . thrift . protocol . TProtocol prot , getFollowing_result struct ) throws org . apache . thrift . TException { TTupleProtocol iprot = ( TTupleProtocol ) prot ; BitSet incoming = iprot . readBitSet ( 1 ) ; if ( incoming . get ( 0 ) ) { struct . success = new Key ( ) ; struct . success . read ( iprot ) ; struct . setSuccessIsSet ( true ) ; } }",Smelly
" public void read ( org . apache . thrift . protocol . TProtocol prot , getActiveLogs_result struct ) throws org . apache . thrift . TException { TTupleProtocol iprot = ( TTupleProtocol ) prot ; BitSet incoming = iprot . readBitSet ( 1 ) ; if ( incoming . get ( 0 ) ) { { org . apache . thrift . protocol . TList _list327 = new org . apache . thrift . protocol . TList ( org . apache . thrift . protocol . TType . STRING , iprot . readI32 ( ) ) ; struct . success = new ArrayList < String > ( _list327 . size ) ; for ( int _i328 = 0 ; _i328 < _list327 . size ; ++ _i328 ) { String _elem329 ; _elem329 = iprot . readString ( ) ; struct . success . add ( _elem329 ) ; } } struct . setSuccessIsSet ( true ) ; } }",Smelly
" public void read ( org . apache . thrift . protocol . TProtocol prot , onReceivedZeppelinResource_result struct ) throws org . apache . thrift . TException { TTupleProtocol iprot = ( TTupleProtocol ) prot ; }",Smelly
" public void read ( org . apache . thrift . protocol . TProtocol prot , Message struct ) throws org . apache . thrift . TException { TTupleProtocol iprot = ( TTupleProtocol ) prot ; struct . event = iprot . readBinary ( ) ; struct . setEventIsSet ( true ) ; struct . messageId = iprot . readString ( ) ; struct . setMessageIdIsSet ( true ) ; struct . messageType = org . apache . airavata . model . messaging . event . MessageType . findByValue ( iprot . readI32 ( ) ) ; struct . setMessageTypeIsSet ( true ) ; BitSet incoming = iprot . readBitSet ( 2 ) ; if ( incoming . get ( 0 ) ) { struct . updatedTime = iprot . readI64 ( ) ; struct . setUpdatedTimeIsSet ( true ) ; } if ( incoming . get ( 1 ) ) { struct . messageLevel = org . apache . airavata . model . messaging . event . MessageLevel . findByValue ( iprot . readI32 ( ) ) ; struct . setMessageLevelIsSet ( true ) ; } }",Smelly
 public CheckSumType cksumType ( ) { return CheckSumType . RSA_MD4 ; },No
 void postStore ( Object parameter ) throws Exception ;,No
" public boolean shouldIgnoreField ( String name ) { return name . startsWith ( ""has"" ) ; }",No
 private static < S extends org . apache . thrift . scheme . IScheme > S scheme ( org . apache . thrift . protocol . TProtocol proto ) { return ( org . apache . thrift . scheme . StandardScheme . class . equals ( proto . getScheme ( ) ) ? STANDARD_SCHEME_FACTORY : TUPLE_SCHEME_FACTORY ) . getScheme ( ) ; },Smelly
 public Timeout getPartitionsAutoUpdateTimeout ( ) { return partitionsAutoUpdateTimeout ; },Smelly
 private static < S extends org . apache . thrift . scheme . IScheme > S scheme ( org . apache . thrift . protocol . TProtocol proto ) { return ( org . apache . thrift . scheme . StandardScheme . class . equals ( proto . getScheme ( ) ) ? STANDARD_SCHEME_FACTORY : TUPLE_SCHEME_FACTORY ) . getScheme ( ) ; },Smelly
 public static void main ( String [ ] args ) throws Exception { int ret = processCommandLineArgs ( args ) ; System . exit ( ret ) ; },Smelly
" public void read ( org . apache . thrift . protocol . TProtocol prot , LOCALSubmission struct ) throws org . apache . thrift . TException { TTupleProtocol iprot = ( TTupleProtocol ) prot ; struct . jobSubmissionInterfaceId = iprot . readString ( ) ; struct . setJobSubmissionInterfaceIdIsSet ( true ) ; struct . resourceJobManager = new ResourceJobManager ( ) ; struct . resourceJobManager . read ( iprot ) ; struct . setResourceJobManagerIsSet ( true ) ; BitSet incoming = iprot . readBitSet ( 1 ) ; if ( incoming . get ( 0 ) ) { struct . securityProtocol = org . apache . airavata . model . data . movement . SecurityProtocol . findByValue ( iprot . readI32 ( ) ) ; struct . setSecurityProtocolIsSet ( true ) ; } }",Smelly
" protected List refreshTicksHorizontal ( Graphics2D g2 , Rectangle2D dataArea , RectangleEdge edge ) { List result = new java . util . ArrayList ( ) ; Font tickLabelFont = getTickLabelFont ( ) ; g2 . setFont ( tickLabelFont ) ; if ( isAutoTickUnitSelection ( ) ) { selectAutoTickUnit ( g2 , dataArea , edge ) ; } DateTickUnit unit = getTickUnit ( ) ; Date tickDate = calculateLowestVisibleTickValue ( unit ) ; Date upperDate = getMaximumDate ( ) ; while ( tickDate . before ( upperDate ) ) { tickDate = correctTickDateForPosition ( tickDate , unit , this . tickMarkPosition ) ; long lowestTickTime = tickDate . getTime ( ) ; long distance = unit . addToDate ( tickDate , this . timeZone ) . getTime ( ) - lowestTickTime ; int minorTickSpaces = getMinorTickCount ( ) ; if ( minorTickSpaces <= 0 ) { minorTickSpaces = unit . getMinorTickCount ( ) ; } for ( int minorTick = 1 ; minorTick < minorTickSpaces ; minorTick ++ ) { long minorTickTime = lowestTickTime - distance * minorTick / minorTickSpaces ; if ( minorTickTime > 0 && getRange ( ) . contains ( minorTickTime ) && ( ! isHiddenValue ( minorTickTime ) ) ) { result . add ( new DateTick ( TickType . MINOR , new Date ( minorTickTime ) , """" , TextAnchor . TOP_CENTER , TextAnchor . CENTER , 0.0 ) ) ; } } if ( ! isHiddenValue ( tickDate . getTime ( ) ) ) { String tickLabel ; DateFormat formatter = getDateFormatOverride ( ) ; if ( formatter != null ) { tickLabel = formatter . format ( tickDate ) ; } else { tickLabel = this . tickUnit . dateToString ( tickDate ) ; } TextAnchor anchor = null ; TextAnchor rotationAnchor = null ; double angle = 0.0 ; if ( isVerticalTickLabels ( ) ) { anchor = TextAnchor . CENTER_RIGHT ; rotationAnchor = TextAnchor . CENTER_RIGHT ; if ( edge == RectangleEdge . TOP ) { angle = Math . PI / 2.0 ; } else { angle = - Math . PI / 2.0 ; } } else { if ( edge == RectangleEdge . TOP ) { anchor = TextAnchor . BOTTOM_CENTER ; rotationAnchor = TextAnchor . BOTTOM_CENTER ; } else { anchor = TextAnchor . TOP_CENTER ; rotationAnchor = TextAnchor . TOP_CENTER ; } } Tick tick = new DateTick ( tickDate , tickLabel , anchor , rotationAnchor , angle ) ; result . add ( tick ) ; long currentTickTime = tickDate . getTime ( ) ; tickDate = unit . addToDate ( tickDate , this . timeZone ) ; long nextTickTime = tickDate . getTime ( ) ; for ( int minorTick = 1 ; minorTick < minorTickSpaces ; minorTick ++ ) { long minorTickTime = currentTickTime + ( nextTickTime - currentTickTime ) * minorTick / minorTickSpaces ; if ( getRange ( ) . contains ( minorTickTime ) && ( ! isHiddenValue ( minorTickTime ) ) ) { result . add ( new DateTick ( TickType . MINOR , new Date ( minorTickTime ) , """" , TextAnchor . TOP_CENTER , TextAnchor . CENTER , 0.0 ) ) ; } } } else { tickDate = unit . rollDate ( tickDate , this . timeZone ) ; continue ; } } return result ; }",Smelly
 Object getInvocationHandler ( ) ;,No
" public Validator getValidator ( QName qName ) throws WSSecurityException { String key = null ; if ( WSSecurityEngine . SAML_TOKEN . equals ( qName ) ) { key = SecurityConstants . SAML1_TOKEN_VALIDATOR ; } else if ( WSSecurityEngine . SAML2_TOKEN . equals ( qName ) ) { key = SecurityConstants . SAML2_TOKEN_VALIDATOR ; } else if ( WSSecurityEngine . USERNAME_TOKEN . equals ( qName ) ) { key = SecurityConstants . USERNAME_TOKEN_VALIDATOR ; } else if ( WSSecurityEngine . SIGNATURE . equals ( qName ) ) { key = SecurityConstants . SIGNATURE_TOKEN_VALIDATOR ; } else if ( WSSecurityEngine . TIMESTAMP . equals ( qName ) ) { key = SecurityConstants . TIMESTAMP_TOKEN_VALIDATOR ; } else if ( WSSecurityEngine . BINARY_TOKEN . equals ( qName ) ) { key = SecurityConstants . BST_TOKEN_VALIDATOR ; } else if ( WSSecurityEngine . SECURITY_CONTEXT_TOKEN_05_02 . equals ( qName ) || WSSecurityEngine . SECURITY_CONTEXT_TOKEN_05_12 . equals ( qName ) ) { key = SecurityConstants . SCT_TOKEN_VALIDATOR ; } if ( key != null ) { Object o = ( ( SoapMessage ) this . getMsgContext ( ) ) . getContextualProperty ( key ) ; try { if ( o instanceof Validator ) { return ( Validator ) o ; } else if ( o instanceof Class ) { return ( Validator ) ( ( Class < ? > ) o ) . newInstance ( ) ; } else if ( o instanceof String ) { return ( Validator ) ClassLoaderUtils . loadClass ( o . toString ( ) , WSS4JInInterceptor . class ) . newInstance ( ) ; } } catch ( RuntimeException t ) { throw t ; } catch ( Throwable t ) { throw new WSSecurityException ( t . getMessage ( ) , t ) ; } } return super . getValidator ( qName ) ; }",Smelly
" static String buildNavPath ( UriHelper helper , EdmEntityType rootType , LinkedList < UriResourceNavigation > navigations , boolean includeLastPredicates ) throws SerializerException { if ( navigations . isEmpty ( ) ) { return null ; } StringBuilder sb = new StringBuilder ( ) ; boolean containsTarget = false ; EdmEntityType type = rootType ; for ( UriResourceNavigation nav : navigations ) { String name = nav . getProperty ( ) . getName ( ) ; EdmNavigationProperty property = type . getNavigationProperty ( name ) ; if ( property . containsTarget ( ) ) { containsTarget = true ; } type = nav . getProperty ( ) . getType ( ) ; } if ( containsTarget ) { for ( int i = 0 ; i < navigations . size ( ) ; i ++ ) { UriResourceNavigation nav = navigations . get ( i ) ; if ( i > 0 ) { sb . append ( ""/"" ) ; } sb . append ( nav . getProperty ( ) . getName ( ) ) ; boolean skipKeys = false ; if ( navigations . size ( ) == i + 1 && ! includeLastPredicates ) { skipKeys = true ; } if ( ! skipKeys && ! nav . getKeyPredicates ( ) . isEmpty ( ) ) { sb . append ( ""("" ) ; sb . append ( helper . buildContextURLKeyPredicate ( nav . getKeyPredicates ( ) ) ) ; sb . append ( "")"" ) ; } if ( nav . getTypeFilterOnCollection ( ) != null ) { sb . append ( ""/"" ) . append ( nav . getTypeFilterOnCollection ( ) . getFullQualifiedName ( ) . getFullQualifiedNameAsString ( ) ) ; } else if ( nav . getTypeFilterOnEntry ( ) != null ) { sb . append ( ""/"" ) . append ( nav . getTypeFilterOnEntry ( ) . getFullQualifiedName ( ) . getFullQualifiedNameAsString ( ) ) ; } } } return sb . toString ( ) ; }",No
" public void read ( org . apache . thrift . protocol . TProtocol prot , show_compact_result struct ) throws org . apache . thrift . TException { TTupleProtocol iprot = ( TTupleProtocol ) prot ; BitSet incoming = iprot . readBitSet ( 1 ) ; if ( incoming . get ( 0 ) ) { struct . success = new ShowCompactResponse ( ) ; struct . success . read ( iprot ) ; struct . setSuccessIsSet ( true ) ; } }",Smelly
" public void read ( org . apache . thrift . protocol . TProtocol prot , JobStatus struct ) throws org . apache . thrift . TException { TTupleProtocol iprot = ( TTupleProtocol ) prot ; struct . jobState = org . apache . airavata . model . status . JobState . findByValue ( iprot . readI32 ( ) ) ; struct . setJobStateIsSet ( true ) ; BitSet incoming = iprot . readBitSet ( 2 ) ; if ( incoming . get ( 0 ) ) { struct . timeOfStateChange = iprot . readI64 ( ) ; struct . setTimeOfStateChangeIsSet ( true ) ; } if ( incoming . get ( 1 ) ) { struct . reason = iprot . readString ( ) ; struct . setReasonIsSet ( true ) ; } }",Smelly
" public void testArrayIndexOutOfBounds ( ) { ParentProcedure proc = new ParentProcedure ( ) ; long procId = procExec . submitProcedure ( proc ) ; long noopProcId = - 1L ; for ( int i = 0 ; i < Long . SIZE - 2 ; i ++ ) { noopProcId = procExec . submitProcedure ( new NoopProcedure < > ( ) ) ; } final long lastNoopProcId = noopProcId ; UTIL . waitFor ( 30000 , ( ) -> procExec . isFinished ( lastNoopProcId ) ) ; proc . latch . countDown ( ) ; UTIL . waitFor ( 10000 , ( ) -> procExec . isFinished ( procId ) ) ; }",No
" public void nonConflictingRemovePropertyWithBranch2 ( ) { String rev = mk . commit ( ""/"" , ""+\""foo\"":{\""prop1\"":\""value\"", \""prop2\"":\""value\""}"" , null , null ) ; String branchRev = mk . branch ( rev ) ; mk . commit ( ""/foo"" , ""^\""prop2\"":null"" , rev , null ) ; branchRev = mk . commit ( ""/foo"" , ""^\""prop1\"":\""bar\"""" , branchRev , null ) ; mk . merge ( branchRev , null ) ; }",No
 public Builder clearAuthResponse ( ) { authResponse_ = org . apache . pulsar . common . api . proto . PulsarApi . CommandAuthResponse . getDefaultInstance ( ) ; bitField1_ = ( bitField1_ & ~ 0x00000010 ) ; return this ; },No
" public void read ( org . apache . thrift . protocol . TProtocol prot , getChildDataProducts_result struct ) throws org . apache . thrift . TException { TTupleProtocol iprot = ( TTupleProtocol ) prot ; BitSet incoming = iprot . readBitSet ( 5 ) ; if ( incoming . get ( 0 ) ) { { org . apache . thrift . protocol . TList _list283 = new org . apache . thrift . protocol . TList ( org . apache . thrift . protocol . TType . STRUCT , iprot . readI32 ( ) ) ; struct . success = new ArrayList < org . apache . airavata . model . data . replica . DataProductModel > ( _list283 . size ) ; org . apache . airavata . model . data . replica . DataProductModel _elem284 ; for ( int _i285 = 0 ; _i285 < _list283 . size ; ++ _i285 ) { _elem284 = new org . apache . airavata . model . data . replica . DataProductModel ( ) ; _elem284 . read ( iprot ) ; struct . success . add ( _elem284 ) ; } } struct . setSuccessIsSet ( true ) ; } if ( incoming . get ( 1 ) ) { struct . ire = new org . apache . airavata . model . error . InvalidRequestException ( ) ; struct . ire . read ( iprot ) ; struct . setIreIsSet ( true ) ; } if ( incoming . get ( 2 ) ) { struct . ace = new org . apache . airavata . model . error . AiravataClientException ( ) ; struct . ace . read ( iprot ) ; struct . setAceIsSet ( true ) ; } if ( incoming . get ( 3 ) ) { struct . ase = new org . apache . airavata . model . error . AiravataSystemException ( ) ; struct . ase . read ( iprot ) ; struct . setAseIsSet ( true ) ; } if ( incoming . get ( 4 ) ) { struct . ae = new org . apache . airavata . model . error . AuthorizationException ( ) ; struct . ae . read ( iprot ) ; struct . setAeIsSet ( true ) ; } }",Smelly
" public void read ( org . apache . thrift . protocol . TProtocol prot , show_compact_result struct ) throws org . apache . thrift . TException { TTupleProtocol iprot = ( TTupleProtocol ) prot ; BitSet incoming = iprot . readBitSet ( 1 ) ; if ( incoming . get ( 0 ) ) { struct . success = new ShowCompactResponse ( ) ; struct . success . read ( iprot ) ; struct . setSuccessIsSet ( true ) ; } }",Smelly
" public void read ( org . apache . thrift . protocol . TProtocol prot , getChildDataProducts_result struct ) throws org . apache . thrift . TException { TTupleProtocol iprot = ( TTupleProtocol ) prot ; BitSet incoming = iprot . readBitSet ( 5 ) ; if ( incoming . get ( 0 ) ) { { org . apache . thrift . protocol . TList _list283 = new org . apache . thrift . protocol . TList ( org . apache . thrift . protocol . TType . STRUCT , iprot . readI32 ( ) ) ; struct . success = new ArrayList < org . apache . airavata . model . data . replica . DataProductModel > ( _list283 . size ) ; org . apache . airavata . model . data . replica . DataProductModel _elem284 ; for ( int _i285 = 0 ; _i285 < _list283 . size ; ++ _i285 ) { _elem284 = new org . apache . airavata . model . data . replica . DataProductModel ( ) ; _elem284 . read ( iprot ) ; struct . success . add ( _elem284 ) ; } } struct . setSuccessIsSet ( true ) ; } if ( incoming . get ( 1 ) ) { struct . ire = new org . apache . airavata . model . error . InvalidRequestException ( ) ; struct . ire . read ( iprot ) ; struct . setIreIsSet ( true ) ; } if ( incoming . get ( 2 ) ) { struct . ace = new org . apache . airavata . model . error . AiravataClientException ( ) ; struct . ace . read ( iprot ) ; struct . setAceIsSet ( true ) ; } if ( incoming . get ( 3 ) ) { struct . ase = new org . apache . airavata . model . error . AiravataSystemException ( ) ; struct . ase . read ( iprot ) ; struct . setAseIsSet ( true ) ; } if ( incoming . get ( 4 ) ) { struct . ae = new org . apache . airavata . model . error . AuthorizationException ( ) ; struct . ae . read ( iprot ) ; struct . setAeIsSet ( true ) ; } }",Smelly
 public Chapter getChapter ( ) { return new Chapter ( 1 ) ; },No
" public static boolean checkParenthesis ( String str ) { boolean result = true ; if ( str != null ) { int open = 0 ; int closed = 0 ; int i = 0 ; while ( ( i = str . indexOf ( '(' , i ) ) >= 0 ) { i ++ ; open ++ ; } i = 0 ; while ( ( i = str . indexOf ( ')' , i ) ) >= 0 ) { i ++ ; closed ++ ; } result = open == closed ; } return result ; }",No
 public String getKey ( ) { return id ; },No
" public void read ( org . apache . thrift . protocol . TProtocol prot , TaskStatusChangeEvent struct ) throws org . apache . thrift . TException { TTupleProtocol iprot = ( TTupleProtocol ) prot ; struct . state = org . apache . airavata . model . status . TaskState . findByValue ( iprot . readI32 ( ) ) ; struct . setStateIsSet ( true ) ; struct . taskIdentity = new TaskIdentifier ( ) ; struct . taskIdentity . read ( iprot ) ; struct . setTaskIdentityIsSet ( true ) ; }",No
" protected String getLanguageName ( ) { return ""groovy"" ; }",No
" protected Pair < BigDecimal [ ] , BigDecimal [ ] > computeRule ( int numberOfPoints ) throws DimensionMismatchException { if ( numberOfPoints == 1 ) { return new Pair < BigDecimal [ ] , BigDecimal [ ] > ( new BigDecimal [ ] { BigDecimal . ZERO } , new BigDecimal [ ] { two } ) ; } final BigDecimal [ ] previousPoints = getRuleInternal ( numberOfPoints - 1 ) . getFirst ( ) ; final BigDecimal [ ] points = new BigDecimal [ numberOfPoints ] ; final BigDecimal [ ] weights = new BigDecimal [ numberOfPoints ] ; final int iMax = numberOfPoints / 2 ; for ( int i = 0 ; i < iMax ; i ++ ) { BigDecimal a = ( i == 0 ) ? minusOne : previousPoints [ i - 1 ] ; BigDecimal b = ( iMax == 1 ) ? BigDecimal . ONE : previousPoints [ i ] ; BigDecimal pma = BigDecimal . ONE ; BigDecimal pa = a ; BigDecimal pmb = BigDecimal . ONE ; BigDecimal pb = b ; for ( int j = 1 ; j < numberOfPoints ; j ++ ) { final BigDecimal b_two_j_p_1 = new BigDecimal ( 2 * j + 1 , mContext ) ; final BigDecimal b_j = new BigDecimal ( j , mContext ) ; final BigDecimal b_j_p_1 = new BigDecimal ( j + 1 , mContext ) ; BigDecimal tmp1 = a . multiply ( b_two_j_p_1 , mContext ) ; tmp1 = pa . multiply ( tmp1 , mContext ) ; BigDecimal tmp2 = pma . multiply ( b_j , mContext ) ; BigDecimal ppa = tmp1 . subtract ( tmp2 , mContext ) ; ppa = ppa . divide ( b_j_p_1 , mContext ) ; tmp1 = b . multiply ( b_two_j_p_1 , mContext ) ; tmp1 = pb . multiply ( tmp1 , mContext ) ; tmp2 = pmb . multiply ( b_j , mContext ) ; BigDecimal ppb = tmp1 . subtract ( tmp2 , mContext ) ; ppb = ppb . divide ( b_j_p_1 , mContext ) ; pma = pa ; pa = ppa ; pmb = pb ; pb = ppb ; } BigDecimal c = a . add ( b , mContext ) . multiply ( oneHalf , mContext ) ; BigDecimal pmc = BigDecimal . ONE ; BigDecimal pc = c ; boolean done = false ; while ( ! done ) { BigDecimal tmp1 = b . subtract ( a , mContext ) ; BigDecimal tmp2 = c . ulp ( ) . multiply ( BigDecimal . TEN , mContext ) ; done = tmp1 . compareTo ( tmp2 ) <= 0 ; pmc = BigDecimal . ONE ; pc = c ; for ( int j = 1 ; j < numberOfPoints ; j ++ ) { final BigDecimal b_two_j_p_1 = new BigDecimal ( 2 * j + 1 , mContext ) ; final BigDecimal b_j = new BigDecimal ( j , mContext ) ; final BigDecimal b_j_p_1 = new BigDecimal ( j + 1 , mContext ) ; tmp1 = c . multiply ( b_two_j_p_1 , mContext ) ; tmp1 = pc . multiply ( tmp1 , mContext ) ; tmp2 = pmc . multiply ( b_j , mContext ) ; BigDecimal ppc = tmp1 . subtract ( tmp2 , mContext ) ; ppc = ppc . divide ( b_j_p_1 , mContext ) ; pmc = pc ; pc = ppc ; } if ( ! done ) { if ( pa . signum ( ) * pc . signum ( ) <= 0 ) { b = c ; pmb = pmc ; pb = pc ; } else { a = c ; pma = pmc ; pa = pc ; } c = a . add ( b , mContext ) . multiply ( oneHalf , mContext ) ; } } final BigDecimal nP = new BigDecimal ( numberOfPoints , mContext ) ; BigDecimal tmp1 = pmc . subtract ( c . multiply ( pc , mContext ) , mContext ) ; tmp1 = tmp1 . multiply ( nP ) ; tmp1 = tmp1 . pow ( 2 , mContext ) ; BigDecimal tmp2 = c . pow ( 2 , mContext ) ; tmp2 = BigDecimal . ONE . subtract ( tmp2 , mContext ) ; tmp2 = tmp2 . multiply ( two , mContext ) ; tmp2 = tmp2 . divide ( tmp1 , mContext ) ; points [ i ] = c ; weights [ i ] = tmp2 ; final int idx = numberOfPoints - i - 1 ; points [ idx ] = c . negate ( mContext ) ; weights [ idx ] = tmp2 ; } if ( numberOfPoints % 2 != 0 ) { BigDecimal pmc = BigDecimal . ONE ; for ( int j = 1 ; j < numberOfPoints ; j += 2 ) { final BigDecimal b_j = new BigDecimal ( j , mContext ) ; final BigDecimal b_j_p_1 = new BigDecimal ( j + 1 , mContext ) ; pmc = pmc . multiply ( b_j , mContext ) ; pmc = pmc . divide ( b_j_p_1 , mContext ) ; pmc = pmc . negate ( mContext ) ; } final BigDecimal nP = new BigDecimal ( numberOfPoints , mContext ) ; BigDecimal tmp1 = pmc . multiply ( nP , mContext ) ; tmp1 = tmp1 . pow ( 2 , mContext ) ; BigDecimal tmp2 = two . divide ( tmp1 , mContext ) ; points [ iMax ] = BigDecimal . ZERO ; weights [ iMax ] = tmp2 ; } return new Pair < BigDecimal [ ] , BigDecimal [ ] > ( points , weights ) ; }",Smelly
" public void read ( org . apache . thrift . protocol . TProtocol prot , getFollowing_result struct ) throws org . apache . thrift . TException { TTupleProtocol iprot = ( TTupleProtocol ) prot ; BitSet incoming = iprot . readBitSet ( 1 ) ; if ( incoming . get ( 0 ) ) { struct . success = new Key ( ) ; struct . success . read ( iprot ) ; struct . setSuccessIsSet ( true ) ; } }",Smelly
 private static < S extends org . apache . thrift . scheme . IScheme > S scheme ( org . apache . thrift . protocol . TProtocol proto ) { return ( org . apache . thrift . scheme . StandardScheme . class . equals ( proto . getScheme ( ) ) ? STANDARD_SCHEME_FACTORY : TUPLE_SCHEME_FACTORY ) . getScheme ( ) ; },Smelly
 public abstract boolean visit ( Subplan < ? > node ) ;,No
" public void read ( org . apache . thrift . protocol . TProtocol prot , checkNamespaceClass_result struct ) throws org . apache . thrift . TException { TTupleProtocol iprot = ( TTupleProtocol ) prot ; BitSet incoming = iprot . readBitSet ( 3 ) ; if ( incoming . get ( 0 ) ) { struct . success = iprot . readBool ( ) ; struct . setSuccessIsSet ( true ) ; } if ( incoming . get ( 1 ) ) { struct . sec = new ThriftSecurityException ( ) ; struct . sec . read ( iprot ) ; struct . setSecIsSet ( true ) ; } if ( incoming . get ( 2 ) ) { struct . tope = new ThriftTableOperationException ( ) ; struct . tope . read ( iprot ) ; struct . setTopeIsSet ( true ) ; } }",Smelly
" public RelWriter explainTerms ( RelWriter pw ) { super . explainTerms ( pw ) ; pw . itemIf ( ""offset"" , offset , offset != null ) ; pw . itemIf ( ""fetch"" , fetch , fetch != null ) ; return pw ; }",No
" public void dump ( Writer writer ) throws IOException { if ( xml instanceof SaxBuffer ) { writer . write ( ""[XMLizable] Begin nested SaxBuffer\n"" ) ; ( ( SaxBuffer ) xml ) . dump ( writer ) ; writer . write ( ""[XMLizable] End nested SaxBuffer\n"" ) ; } else { writer . write ( ""[XMLizable] xml="" + xml + ""\n"" ) ; } }",No
" public void read ( org . apache . thrift . protocol . TProtocol prot , getChildDataProducts_result struct ) throws org . apache . thrift . TException { TTupleProtocol iprot = ( TTupleProtocol ) prot ; BitSet incoming = iprot . readBitSet ( 5 ) ; if ( incoming . get ( 0 ) ) { { org . apache . thrift . protocol . TList _list283 = new org . apache . thrift . protocol . TList ( org . apache . thrift . protocol . TType . STRUCT , iprot . readI32 ( ) ) ; struct . success = new ArrayList < org . apache . airavata . model . data . replica . DataProductModel > ( _list283 . size ) ; org . apache . airavata . model . data . replica . DataProductModel _elem284 ; for ( int _i285 = 0 ; _i285 < _list283 . size ; ++ _i285 ) { _elem284 = new org . apache . airavata . model . data . replica . DataProductModel ( ) ; _elem284 . read ( iprot ) ; struct . success . add ( _elem284 ) ; } } struct . setSuccessIsSet ( true ) ; } if ( incoming . get ( 1 ) ) { struct . ire = new org . apache . airavata . model . error . InvalidRequestException ( ) ; struct . ire . read ( iprot ) ; struct . setIreIsSet ( true ) ; } if ( incoming . get ( 2 ) ) { struct . ace = new org . apache . airavata . model . error . AiravataClientException ( ) ; struct . ace . read ( iprot ) ; struct . setAceIsSet ( true ) ; } if ( incoming . get ( 3 ) ) { struct . ase = new org . apache . airavata . model . error . AiravataSystemException ( ) ; struct . ase . read ( iprot ) ; struct . setAseIsSet ( true ) ; } if ( incoming . get ( 4 ) ) { struct . ae = new org . apache . airavata . model . error . AuthorizationException ( ) ; struct . ae . read ( iprot ) ; struct . setAeIsSet ( true ) ; } }",Smelly
" public static Map < String , Object > exportVCard ( DispatchContext dctx , Map < String , ? extends Object > context ) { Delegator delegator = dctx . getDelegator ( ) ; String partyId = ( String ) context . get ( ""partyId"" ) ; Locale locale = ( Locale ) context . get ( ""locale"" ) ; File file = null ; try { ContactModelFactory cmf = Pim . getContactModelFactory ( ) ; Contact contact = cmf . createContact ( ) ; PersonalIdentity pid = cmf . createPersonalIdentity ( ) ; String fullName = PartyHelper . getPartyName ( delegator , partyId , false ) ; String [ ] name = fullName . split ( ""\\s"" ) ; pid . setFirstname ( name [ 0 ] ) ; pid . setLastname ( name [ 1 ] ) ; contact . setPersonalIdentity ( pid ) ; GenericValue postalAddress = PartyWorker . findPartyLatestPostalAddress ( partyId , delegator ) ; Address address = cmf . createAddress ( ) ; address . setStreet ( postalAddress . getString ( ""address1"" ) ) ; address . setCity ( postalAddress . getString ( ""city"" ) ) ; address . setPostalCode ( postalAddress . getString ( ""postalCode"" ) ) ; GenericValue state = postalAddress . getRelatedOne ( ""StateProvinceGeo"" , false ) ; if ( UtilValidate . isNotEmpty ( state ) ) { address . setRegion ( state . getString ( ""geoName"" ) ) ; } GenericValue countryGeo = postalAddress . getRelatedOne ( ""CountryGeo"" , false ) ; if ( UtilValidate . isNotEmpty ( countryGeo ) ) { String country = postalAddress . getRelatedOne ( ""CountryGeo"" , false ) . getString ( ""geoName"" ) ; address . setCountry ( country ) ; address . setWork ( true ) ; } contact . addAddress ( address ) ; Communications communication = cmf . createCommunications ( ) ; contact . setCommunications ( communication ) ; PhoneNumber number = cmf . createPhoneNumber ( ) ; GenericValue telecomNumber = PartyWorker . findPartyLatestTelecomNumber ( partyId , delegator ) ; if ( UtilValidate . isNotEmpty ( telecomNumber ) ) { number . setNumber ( telecomNumber . getString ( ""areaCode"" ) + telecomNumber . getString ( ""contactNumber"" ) ) ; number . setWork ( true ) ; communication . addPhoneNumber ( number ) ; } EmailAddress email = cmf . createEmailAddress ( ) ; GenericValue emailAddress = PartyWorker . findPartyLatestContactMech ( partyId , ""EMAIL_ADDRESS"" , delegator ) ; if ( UtilValidate . isNotEmpty ( emailAddress . getString ( ""infoString"" ) ) ) { email . setAddress ( emailAddress . getString ( ""infoString"" ) ) ; communication . addEmailAddress ( email ) ; } ContactIOFactory ciof = Pim . getContactIOFactory ( ) ; ContactMarshaller marshaller = ciof . createContactMarshaller ( ) ; String saveToDirectory = UtilProperties . getPropertyValue ( ""sfa.properties"" , ""save.outgoing.directory"" , """" ) ; if ( UtilValidate . isEmpty ( saveToDirectory ) ) { saveToDirectory = System . getProperty ( ""ofbiz.home"" ) ; } String saveToFilename = fullName + "".vcf"" ; file = FileUtil . getFile ( saveToDirectory + ""/"" + saveToFilename ) ; FileOutputStream outputStream = new FileOutputStream ( file ) ; marshaller . marshallContact ( outputStream , contact ) ; outputStream . close ( ) ; } catch ( FileNotFoundException e ) { Debug . logError ( e , module ) ; return ServiceUtil . returnError ( UtilProperties . getMessage ( resourceError , ""SfaExportVCardErrorOpeningFile"" , UtilMisc . toMap ( ""errorString"" , file . getAbsolutePath ( ) ) , locale ) ) ; } catch ( IOException e ) { Debug . logError ( e , module ) ; return ServiceUtil . returnError ( UtilProperties . getMessage ( resourceError , ""SfaExportVCardErrorWritingFile"" , UtilMisc . toMap ( ""errorString"" , file . getAbsolutePath ( ) ) , locale ) ) ; } catch ( GenericEntityException e ) { return ServiceUtil . returnError ( UtilProperties . getMessage ( resourceError , ""SfaExportVCardError"" , UtilMisc . toMap ( ""errorString"" , e . getMessage ( ) ) , locale ) ) ; } return ServiceUtil . returnSuccess ( ) ; }",Smelly
" protected String [ ] getConnectorClasses ( ) { return new String [ ] { ""org.apache.manifoldcf.crawler.connectors.wiki.WikiConnector"" } ; }",No
" public void read ( org . apache . thrift . protocol . TProtocol prot , show_compact_result struct ) throws org . apache . thrift . TException { TTupleProtocol iprot = ( TTupleProtocol ) prot ; BitSet incoming = iprot . readBitSet ( 1 ) ; if ( incoming . get ( 0 ) ) { struct . success = new ShowCompactResponse ( ) ; struct . success . read ( iprot ) ; struct . setSuccessIsSet ( true ) ; } }",Smelly
 public int hashCode ( ) { return super . hashCode ( ) ^ this . traversals . hashCode ( ) ; },No
" public void statusJobAnyWithoutPermission ( ) { String user = YUWEN ; String job = getRandomJobName ( ) ; AuthorizationEngine . statusJob ( user , job ) ; }",No
" public void pathRestrictions ( ) throws Exception { FilterImpl f = new FilterImpl ( null , null ) ; assertEquals ( ""/"" , f . getPath ( ) ) ; assertEquals ( Filter . PathRestriction . NO_RESTRICTION , f . getPathRestriction ( ) ) ; f . restrictPath ( ""/test"" , Filter . PathRestriction . ALL_CHILDREN ) ; f . restrictPath ( ""/test2"" , Filter . PathRestriction . ALL_CHILDREN ) ; assertTrue ( f . isAlwaysFalse ( ) ) ; f = new FilterImpl ( null , null ) ; f . restrictPath ( ""/test"" , Filter . PathRestriction . ALL_CHILDREN ) ; assertEquals ( ""/test"" , f . getPath ( ) ) ; assertEquals ( Filter . PathRestriction . ALL_CHILDREN , f . getPathRestriction ( ) ) ; f . restrictPath ( ""/test/x"" , Filter . PathRestriction . DIRECT_CHILDREN ) ; assertEquals ( ""/test/x"" , f . getPath ( ) ) ; assertEquals ( Filter . PathRestriction . DIRECT_CHILDREN , f . getPathRestriction ( ) ) ; f . restrictPath ( ""/test/x/y"" , Filter . PathRestriction . PARENT ) ; assertEquals ( ""/test/x/y"" , f . getPath ( ) ) ; assertEquals ( Filter . PathRestriction . PARENT , f . getPathRestriction ( ) ) ; f = new FilterImpl ( null , null ) ; f . restrictPath ( ""/test"" , Filter . PathRestriction . DIRECT_CHILDREN ) ; f . restrictPath ( ""/test/x/y"" , Filter . PathRestriction . PARENT ) ; assertEquals ( ""/test/x/y"" , f . getPath ( ) ) ; assertEquals ( Filter . PathRestriction . PARENT , f . getPathRestriction ( ) ) ; f . restrictPath ( ""/test/y"" , Filter . PathRestriction . DIRECT_CHILDREN ) ; assertTrue ( f . isAlwaysFalse ( ) ) ; f = new FilterImpl ( null , null ) ; f . restrictPath ( ""/test/x/y"" , Filter . PathRestriction . PARENT ) ; f . restrictPath ( ""/test/x"" , Filter . PathRestriction . EXACT ) ; assertEquals ( ""/test/x"" , f . getPath ( ) ) ; assertEquals ( Filter . PathRestriction . EXACT , f . getPathRestriction ( ) ) ; f . restrictPath ( ""/test/y"" , Filter . PathRestriction . EXACT ) ; assertTrue ( f . isAlwaysFalse ( ) ) ; f = new FilterImpl ( null , null ) ; f . restrictPath ( ""/test"" , Filter . PathRestriction . ALL_CHILDREN ) ; f . restrictPath ( ""/test"" , Filter . PathRestriction . PARENT ) ; assertTrue ( f . isAlwaysFalse ( ) ) ; f = new FilterImpl ( null , null ) ; f . restrictPath ( ""/test/x"" , Filter . PathRestriction . PARENT ) ; f . restrictPath ( ""/test"" , Filter . PathRestriction . ALL_CHILDREN ) ; assertEquals ( ""/test/x"" , f . getPath ( ) ) ; assertEquals ( Filter . PathRestriction . PARENT , f . getPathRestriction ( ) ) ; f . restrictPath ( ""/test/x"" , Filter . PathRestriction . ALL_CHILDREN ) ; assertTrue ( f . isAlwaysFalse ( ) ) ; f = new FilterImpl ( null , null ) ; f . restrictPath ( ""/test"" , Filter . PathRestriction . ALL_CHILDREN ) ; f . restrictPath ( ""/test"" , Filter . PathRestriction . EXACT ) ; assertTrue ( f . isAlwaysFalse ( ) ) ; f = new FilterImpl ( null , null ) ; f . restrictPath ( ""/test"" , Filter . PathRestriction . DIRECT_CHILDREN ) ; f . restrictPath ( ""/test/x"" , Filter . PathRestriction . EXACT ) ; assertEquals ( ""/test/x"" , f . getPath ( ) ) ; assertEquals ( Filter . PathRestriction . EXACT , f . getPathRestriction ( ) ) ; f = new FilterImpl ( null , null ) ; f . restrictPath ( ""/test"" , Filter . PathRestriction . DIRECT_CHILDREN ) ; f . restrictPath ( ""/test/x/y"" , Filter . PathRestriction . EXACT ) ; assertTrue ( f . isAlwaysFalse ( ) ) ; f = new FilterImpl ( null , null ) ; f . restrictPath ( ""/test/x"" , Filter . PathRestriction . PARENT ) ; f . restrictPath ( ""/"" , Filter . PathRestriction . ALL_CHILDREN ) ; assertEquals ( ""/test/x"" , f . getPath ( ) ) ; assertEquals ( Filter . PathRestriction . PARENT , f . getPathRestriction ( ) ) ; f . restrictPath ( ""/test/y"" , Filter . PathRestriction . EXACT ) ; assertTrue ( f . isAlwaysFalse ( ) ) ; f = new FilterImpl ( null , null ) ; f . restrictPath ( ""/test"" , Filter . PathRestriction . DIRECT_CHILDREN ) ; assertEquals ( ""/test"" , f . getPath ( ) ) ; assertEquals ( Filter . PathRestriction . DIRECT_CHILDREN , f . getPathRestriction ( ) ) ; f . restrictPath ( ""/"" , Filter . PathRestriction . ALL_CHILDREN ) ; assertEquals ( ""/test"" , f . getPath ( ) ) ; assertEquals ( Filter . PathRestriction . DIRECT_CHILDREN , f . getPathRestriction ( ) ) ; f . restrictPath ( ""/test"" , Filter . PathRestriction . ALL_CHILDREN ) ; assertEquals ( ""/test"" , f . getPath ( ) ) ; assertEquals ( Filter . PathRestriction . DIRECT_CHILDREN , f . getPathRestriction ( ) ) ; f . restrictPath ( ""/test/x/y"" , Filter . PathRestriction . PARENT ) ; assertEquals ( ""/test/x/y"" , f . getPath ( ) ) ; assertEquals ( Filter . PathRestriction . PARENT , f . getPathRestriction ( ) ) ; f . restrictPath ( ""/test2"" , Filter . PathRestriction . ALL_CHILDREN ) ; assertTrue ( f . isAlwaysFalse ( ) ) ; f = new FilterImpl ( null , null ) ; f . restrictPath ( ""/test/x"" , Filter . PathRestriction . EXACT ) ; assertEquals ( ""/test/x"" , f . getPath ( ) ) ; assertEquals ( Filter . PathRestriction . EXACT , f . getPathRestriction ( ) ) ; f . restrictPath ( ""/test"" , Filter . PathRestriction . ALL_CHILDREN ) ; f . restrictPath ( ""/test"" , Filter . PathRestriction . DIRECT_CHILDREN ) ; f . restrictPath ( ""/test/x/y"" , Filter . PathRestriction . PARENT ) ; f . restrictPath ( ""/test/y"" , Filter . PathRestriction . DIRECT_CHILDREN ) ; assertTrue ( f . isAlwaysFalse ( ) ) ; f = new FilterImpl ( null , null ) ; f . restrictPath ( ""/test/x/y"" , Filter . PathRestriction . PARENT ) ; assertEquals ( ""/test/x/y"" , f . getPath ( ) ) ; assertEquals ( Filter . PathRestriction . PARENT , f . getPathRestriction ( ) ) ; f . restrictPath ( ""/test/x"" , Filter . PathRestriction . PARENT ) ; assertEquals ( ""/test/x"" , f . getPath ( ) ) ; assertEquals ( Filter . PathRestriction . PARENT , f . getPathRestriction ( ) ) ; f . restrictPath ( ""/test"" , Filter . PathRestriction . ALL_CHILDREN ) ; assertEquals ( ""/test/x"" , f . getPath ( ) ) ; assertEquals ( Filter . PathRestriction . PARENT , f . getPathRestriction ( ) ) ; f . restrictPath ( ""/test"" , Filter . PathRestriction . DIRECT_CHILDREN ) ; assertEquals ( ""/test/x"" , f . getPath ( ) ) ; assertEquals ( Filter . PathRestriction . PARENT , f . getPathRestriction ( ) ) ; f . restrictPath ( ""/test/x"" , Filter . PathRestriction . PARENT ) ; assertEquals ( ""/test/x"" , f . getPath ( ) ) ; assertEquals ( Filter . PathRestriction . PARENT , f . getPathRestriction ( ) ) ; f . restrictPath ( ""/test"" , Filter . PathRestriction . PARENT ) ; assertEquals ( ""/test"" , f . getPath ( ) ) ; assertEquals ( Filter . PathRestriction . PARENT , f . getPathRestriction ( ) ) ; f . restrictPath ( ""/test2"" , Filter . PathRestriction . EXACT ) ; assertTrue ( f . isAlwaysFalse ( ) ) ; }",Smelly
" public void runAction ( Map < String , Object > context ) { Object valueObject = valueNameAcsr . get ( context ) ; if ( valueObject == null ) { Debug . logVerbose ( ""Value not found with name: "" + valueNameAcsr + "", not getting related..."" , module ) ; return ; } if ( ! ( valueObject instanceof GenericValue ) ) { String errMsg = ""Env variable for value-name "" + valueNameAcsr . toString ( ) + "" is not a GenericValue object; for the relation-name: "" + relationName + ""]"" ; Debug . logError ( errMsg , module ) ; throw new IllegalArgumentException ( errMsg ) ; } GenericValue value = ( GenericValue ) valueObject ; List < String > orderByNames = null ; if ( ! orderByListAcsr . isEmpty ( ) ) { orderByNames = orderByListAcsr . get ( context ) ; } Map < String , Object > constraintMap = null ; if ( ! mapAcsr . isEmpty ( ) ) { constraintMap = mapAcsr . get ( context ) ; } try { listNameAcsr . put ( context , value . getRelated ( relationName , constraintMap , orderByNames , useCache ) ) ; } catch ( GenericEntityException e ) { String errMsg = ""Problem getting related from entity with name "" + value . getEntityName ( ) + "" for the relation-name: "" + relationName + "": "" + e . getMessage ( ) ; Debug . logError ( e , errMsg , module ) ; throw new IllegalArgumentException ( errMsg ) ; } }",Smelly
 public void testIsInclude ( ) throws Exception { },No
" public void read ( org . apache . thrift . protocol . TProtocol prot , getChildDataProducts_result struct ) throws org . apache . thrift . TException { TTupleProtocol iprot = ( TTupleProtocol ) prot ; BitSet incoming = iprot . readBitSet ( 5 ) ; if ( incoming . get ( 0 ) ) { { org . apache . thrift . protocol . TList _list283 = new org . apache . thrift . protocol . TList ( org . apache . thrift . protocol . TType . STRUCT , iprot . readI32 ( ) ) ; struct . success = new ArrayList < org . apache . airavata . model . data . replica . DataProductModel > ( _list283 . size ) ; org . apache . airavata . model . data . replica . DataProductModel _elem284 ; for ( int _i285 = 0 ; _i285 < _list283 . size ; ++ _i285 ) { _elem284 = new org . apache . airavata . model . data . replica . DataProductModel ( ) ; _elem284 . read ( iprot ) ; struct . success . add ( _elem284 ) ; } } struct . setSuccessIsSet ( true ) ; } if ( incoming . get ( 1 ) ) { struct . ire = new org . apache . airavata . model . error . InvalidRequestException ( ) ; struct . ire . read ( iprot ) ; struct . setIreIsSet ( true ) ; } if ( incoming . get ( 2 ) ) { struct . ace = new org . apache . airavata . model . error . AiravataClientException ( ) ; struct . ace . read ( iprot ) ; struct . setAceIsSet ( true ) ; } if ( incoming . get ( 3 ) ) { struct . ase = new org . apache . airavata . model . error . AiravataSystemException ( ) ; struct . ase . read ( iprot ) ; struct . setAseIsSet ( true ) ; } if ( incoming . get ( 4 ) ) { struct . ae = new org . apache . airavata . model . error . AuthorizationException ( ) ; struct . ae . read ( iprot ) ; struct . setAeIsSet ( true ) ; } }",Smelly
" public void read ( org . apache . thrift . protocol . TProtocol prot , ExperimentSummaryModel struct ) throws org . apache . thrift . TException { TTupleProtocol iprot = ( TTupleProtocol ) prot ; struct . experimentId = iprot . readString ( ) ; struct . setExperimentIdIsSet ( true ) ; struct . projectId = iprot . readString ( ) ; struct . setProjectIdIsSet ( true ) ; struct . gatewayId = iprot . readString ( ) ; struct . setGatewayIdIsSet ( true ) ; struct . userName = iprot . readString ( ) ; struct . setUserNameIsSet ( true ) ; struct . name = iprot . readString ( ) ; struct . setNameIsSet ( true ) ; BitSet incoming = iprot . readBitSet ( 6 ) ; if ( incoming . get ( 0 ) ) { struct . creationTime = iprot . readI64 ( ) ; struct . setCreationTimeIsSet ( true ) ; } if ( incoming . get ( 1 ) ) { struct . description = iprot . readString ( ) ; struct . setDescriptionIsSet ( true ) ; } if ( incoming . get ( 2 ) ) { struct . executionId = iprot . readString ( ) ; struct . setExecutionIdIsSet ( true ) ; } if ( incoming . get ( 3 ) ) { struct . resourceHostId = iprot . readString ( ) ; struct . setResourceHostIdIsSet ( true ) ; } if ( incoming . get ( 4 ) ) { struct . experimentStatus = iprot . readString ( ) ; struct . setExperimentStatusIsSet ( true ) ; } if ( incoming . get ( 5 ) ) { struct . statusUpdateTime = iprot . readI64 ( ) ; struct . setStatusUpdateTimeIsSet ( true ) ; } }",Smelly
" public void read ( org . apache . thrift . protocol . TProtocol prot , PartitionsByExprResult struct ) throws org . apache . thrift . TException { TTupleProtocol iprot = ( TTupleProtocol ) prot ; { org . apache . thrift . protocol . TList _list277 = new org . apache . thrift . protocol . TList ( org . apache . thrift . protocol . TType . STRUCT , iprot . readI32 ( ) ) ; struct . partitions = new ArrayList < Partition > ( _list277 . size ) ; for ( int _i278 = 0 ; _i278 < _list277 . size ; ++ _i278 ) { Partition _elem279 ; _elem279 = new Partition ( ) ; _elem279 . read ( iprot ) ; struct . partitions . add ( _elem279 ) ; } } struct . setPartitionsIsSet ( true ) ; struct . hasUnknownPartitions = iprot . readBool ( ) ; struct . setHasUnknownPartitionsIsSet ( true ) ; }",Smelly
" public void read ( org . apache . thrift . protocol . TProtocol prot , show_compact_result struct ) throws org . apache . thrift . TException { TTupleProtocol iprot = ( TTupleProtocol ) prot ; BitSet incoming = iprot . readBitSet ( 1 ) ; if ( incoming . get ( 0 ) ) { struct . success = new ShowCompactResponse ( ) ; struct . success . read ( iprot ) ; struct . setSuccessIsSet ( true ) ; } }",Smelly
" public void read ( org . apache . thrift . protocol . TProtocol prot , getStatus_result struct ) throws org . apache . thrift . TException { TTupleProtocol iprot = ( TTupleProtocol ) prot ; BitSet incoming = iprot . readBitSet ( 2 ) ; if ( incoming . get ( 0 ) ) { struct . success = new GCStatus ( ) ; struct . success . read ( iprot ) ; struct . setSuccessIsSet ( true ) ; } if ( incoming . get ( 1 ) ) { struct . sec = new org . apache . accumulo . core . client . impl . thrift . ThriftSecurityException ( ) ; struct . sec . read ( iprot ) ; struct . setSecIsSet ( true ) ; } }",No
" public void read ( org . apache . thrift . protocol . TProtocol prot , checkNamespaceClass_result struct ) throws org . apache . thrift . TException { TTupleProtocol iprot = ( TTupleProtocol ) prot ; BitSet incoming = iprot . readBitSet ( 3 ) ; if ( incoming . get ( 0 ) ) { struct . success = iprot . readBool ( ) ; struct . setSuccessIsSet ( true ) ; } if ( incoming . get ( 1 ) ) { struct . sec = new ThriftSecurityException ( ) ; struct . sec . read ( iprot ) ; struct . setSecIsSet ( true ) ; } if ( incoming . get ( 2 ) ) { struct . tope = new ThriftTableOperationException ( ) ; struct . tope . read ( iprot ) ; struct . setTopeIsSet ( true ) ; } }",Smelly
" public void read ( org . apache . thrift . protocol . TProtocol prot , show_compact_result struct ) throws org . apache . thrift . TException { TTupleProtocol iprot = ( TTupleProtocol ) prot ; BitSet incoming = iprot . readBitSet ( 1 ) ; if ( incoming . get ( 0 ) ) { struct . success = new ShowCompactResponse ( ) ; struct . success . read ( iprot ) ; struct . setSuccessIsSet ( true ) ; } }",Smelly
" public void read ( org . apache . thrift . protocol . TProtocol prot , getChildDataProducts_result struct ) throws org . apache . thrift . TException { TTupleProtocol iprot = ( TTupleProtocol ) prot ; BitSet incoming = iprot . readBitSet ( 5 ) ; if ( incoming . get ( 0 ) ) { { org . apache . thrift . protocol . TList _list283 = new org . apache . thrift . protocol . TList ( org . apache . thrift . protocol . TType . STRUCT , iprot . readI32 ( ) ) ; struct . success = new ArrayList < org . apache . airavata . model . data . replica . DataProductModel > ( _list283 . size ) ; org . apache . airavata . model . data . replica . DataProductModel _elem284 ; for ( int _i285 = 0 ; _i285 < _list283 . size ; ++ _i285 ) { _elem284 = new org . apache . airavata . model . data . replica . DataProductModel ( ) ; _elem284 . read ( iprot ) ; struct . success . add ( _elem284 ) ; } } struct . setSuccessIsSet ( true ) ; } if ( incoming . get ( 1 ) ) { struct . ire = new org . apache . airavata . model . error . InvalidRequestException ( ) ; struct . ire . read ( iprot ) ; struct . setIreIsSet ( true ) ; } if ( incoming . get ( 2 ) ) { struct . ace = new org . apache . airavata . model . error . AiravataClientException ( ) ; struct . ace . read ( iprot ) ; struct . setAceIsSet ( true ) ; } if ( incoming . get ( 3 ) ) { struct . ase = new org . apache . airavata . model . error . AiravataSystemException ( ) ; struct . ase . read ( iprot ) ; struct . setAseIsSet ( true ) ; } if ( incoming . get ( 4 ) ) { struct . ae = new org . apache . airavata . model . error . AuthorizationException ( ) ; struct . ae . read ( iprot ) ; struct . setAeIsSet ( true ) ; } }",Smelly
 DavSession getSession ( ) ;,No
" public void read ( org . apache . thrift . protocol . TProtocol prot , TabletStats struct ) throws org . apache . thrift . TException { TTupleProtocol iprot = ( TTupleProtocol ) prot ; BitSet incoming = iprot . readBitSet ( 8 ) ; if ( incoming . get ( 0 ) ) { struct . extent = new org . apache . accumulo . core . data . thrift . TKeyExtent ( ) ; struct . extent . read ( iprot ) ; struct . setExtentIsSet ( true ) ; } if ( incoming . get ( 1 ) ) { struct . majors = new ActionStats ( ) ; struct . majors . read ( iprot ) ; struct . setMajorsIsSet ( true ) ; } if ( incoming . get ( 2 ) ) { struct . minors = new ActionStats ( ) ; struct . minors . read ( iprot ) ; struct . setMinorsIsSet ( true ) ; } if ( incoming . get ( 3 ) ) { struct . splits = new ActionStats ( ) ; struct . splits . read ( iprot ) ; struct . setSplitsIsSet ( true ) ; } if ( incoming . get ( 4 ) ) { struct . numEntries = iprot . readI64 ( ) ; struct . setNumEntriesIsSet ( true ) ; } if ( incoming . get ( 5 ) ) { struct . ingestRate = iprot . readDouble ( ) ; struct . setIngestRateIsSet ( true ) ; } if ( incoming . get ( 6 ) ) { struct . queryRate = iprot . readDouble ( ) ; struct . setQueryRateIsSet ( true ) ; } if ( incoming . get ( 7 ) ) { struct . splitCreationTime = iprot . readI64 ( ) ; struct . setSplitCreationTimeIsSet ( true ) ; } }",Smelly
 private static < S extends org . apache . thrift . scheme . IScheme > S scheme ( org . apache . thrift . protocol . TProtocol proto ) { return ( org . apache . thrift . scheme . StandardScheme . class . equals ( proto . getScheme ( ) ) ? STANDARD_SCHEME_FACTORY : TUPLE_SCHEME_FACTORY ) . getScheme ( ) ; },Smelly
 public void setNumber ( int number ) { _number = number ; },No
 private static < S extends org . apache . thrift . scheme . IScheme > S scheme ( org . apache . thrift . protocol . TProtocol proto ) { return ( org . apache . thrift . scheme . StandardScheme . class . equals ( proto . getScheme ( ) ) ? STANDARD_SCHEME_FACTORY : TUPLE_SCHEME_FACTORY ) . getScheme ( ) ; },Smelly
 private static long getStartTime ( ) { if ( startTime == 0 ) { synchronized ( PatternParser . class ) { try { startTime = ManagementFactory . getRuntimeMXBean ( ) . getStartTime ( ) ; } catch ( Throwable t ) { startTime = System . currentTimeMillis ( ) ; } } } return startTime ; },No
" public void read ( org . apache . thrift . protocol . TProtocol prot , getActiveLogs_result struct ) throws org . apache . thrift . TException { TTupleProtocol iprot = ( TTupleProtocol ) prot ; BitSet incoming = iprot . readBitSet ( 1 ) ; if ( incoming . get ( 0 ) ) { { org . apache . thrift . protocol . TList _list327 = new org . apache . thrift . protocol . TList ( org . apache . thrift . protocol . TType . STRING , iprot . readI32 ( ) ) ; struct . success = new ArrayList < String > ( _list327 . size ) ; for ( int _i328 = 0 ; _i328 < _list327 . size ; ++ _i328 ) { String _elem329 ; _elem329 = iprot . readString ( ) ; struct . success . add ( _elem329 ) ; } } struct . setSuccessIsSet ( true ) ; } }",Smelly
" public Comparable getObject ( ) { int hashPos = provider . getSort ( ) . getProperty ( ) . indexOf ( '#' ) ; SchemaType schemaType = null ; final String schema ; if ( hashPos == - 1 ) { schema = provider . getSort ( ) . getProperty ( ) ; } else { String [ ] splitted = provider . getSort ( ) . getProperty ( ) . split ( ""#"" ) ; try { schemaType = SchemaType . valueOf ( splitted [ 0 ] ) ; } catch ( IllegalArgumentException e ) { } schema = provider . getSort ( ) . getProperty ( ) . substring ( hashPos + 1 ) ; } final AttrTO attr ; if ( schemaType == null ) { attr = this . anyTO . getPlainAttr ( schema ) ; } else { switch ( schemaType ) { case PLAIN : default : attr = this . anyTO . getPlainAttr ( schema ) ; break ; case DERIVED : attr = this . anyTO . getDerAttr ( schema ) ; break ; case VIRTUAL : attr = this . anyTO . getVirAttr ( schema ) ; break ; } } Comparable result = null ; List < String > values = attr == null ? null : attr . getValues ( ) ; if ( values != null && ! values . isEmpty ( ) ) { result = values . iterator ( ) . next ( ) ; } return result ; }",Smelly
 public void setRootEntityData ( String rootEntityData ) { this . rootEntityData = rootEntityData ; },No
" public boolean validatePolicy ( AssertionInfoMap aim , Message message , List < WSSecurityEngineResult > results , List < WSSecurityEngineResult > signedResults , List < WSSecurityEngineResult > encryptedResults ) { Collection < AssertionInfo > ais = aim . get ( SP12Constants . ENDORSING_ENCRYPTED_SUPPORTING_TOKENS ) ; if ( ais == null || ais . isEmpty ( ) ) { return true ; } setMessage ( message ) ; setResults ( results ) ; setSignedResults ( signedResults ) ; setEncryptedResults ( encryptedResults ) ; for ( AssertionInfo ai : ais ) { SupportingToken binding = ( SupportingToken ) ai . getAssertion ( ) ; if ( SPConstants . SupportTokenType . SUPPORTING_TOKEN_ENDORSING_ENCRYPTED != binding . getTokenType ( ) ) { continue ; } ai . setAsserted ( true ) ; setSignedParts ( binding . getSignedParts ( ) ) ; setEncryptedParts ( binding . getEncryptedParts ( ) ) ; setSignedElements ( binding . getSignedElements ( ) ) ; setEncryptedElements ( binding . getEncryptedElements ( ) ) ; List < Token > tokens = binding . getTokens ( ) ; for ( Token token : tokens ) { if ( ! isTokenRequired ( token , message ) ) { continue ; } boolean derived = token . isDerivedKeys ( ) ; setDerived ( derived ) ; boolean processingFailed = false ; if ( token instanceof KerberosToken ) { if ( ! processKerberosTokens ( ) ) { processingFailed = true ; } } else if ( token instanceof X509Token ) { if ( ! processX509Tokens ( ) ) { processingFailed = true ; } } else if ( token instanceof KeyValueToken ) { if ( ! processKeyValueTokens ( ) ) { processingFailed = true ; } } else if ( token instanceof UsernameToken ) { if ( ! processUsernameTokens ( ) ) { processingFailed = true ; } } else if ( token instanceof SecurityContextToken ) { if ( ! processSCTokens ( ) ) { processingFailed = true ; } } else if ( token instanceof SamlToken ) { if ( ! processSAMLTokens ( ) ) { processingFailed = true ; } } else if ( ! ( token instanceof IssuedToken ) ) { processingFailed = true ; } if ( processingFailed ) { ai . setNotAsserted ( ""The received token does not match the endorsing encrypted "" + ""supporting token requirement"" ) ; return false ; } } } return true ; }",Smelly
" Method resolveViewMethod ( Bean < ? > component , Method declaredMethod ) ;",No
" protected void populateObject ( Object object ) throws Exception { super . populateObject ( object ) ; Message info = ( Message ) object ; info . setProducerId ( createProducerId ( ""ProducerId:1"" ) ) ; info . setDestination ( createActiveMQDestination ( ""Destination:2"" ) ) ; info . setTransactionId ( createTransactionId ( ""TransactionId:3"" ) ) ; info . setOriginalDestination ( createActiveMQDestination ( ""OriginalDestination:4"" ) ) ; info . setMessageId ( createMessageId ( ""MessageId:5"" ) ) ; info . setOriginalTransactionId ( createTransactionId ( ""OriginalTransactionId:6"" ) ) ; info . setGroupID ( ""GroupID:7"" ) ; info . setGroupSequence ( 1 ) ; info . setCorrelationId ( ""CorrelationId:8"" ) ; info . setPersistent ( true ) ; info . setExpiration ( 1 ) ; info . setPriority ( ( byte ) 1 ) ; info . setReplyTo ( createActiveMQDestination ( ""ReplyTo:9"" ) ) ; info . setTimestamp ( 2 ) ; info . setType ( ""Type:10"" ) ; { byte data [ ] = ""Content:11"" . getBytes ( ) ; info . setContent ( new org . apache . activemq . util . ByteSequence ( data , 0 , data . length ) ) ; } { byte data [ ] = ""MarshalledProperties:12"" . getBytes ( ) ; info . setMarshalledProperties ( new org . apache . activemq . util . ByteSequence ( data , 0 , data . length ) ) ; } info . setDataStructure ( createDataStructure ( ""DataStructure:13"" ) ) ; info . setTargetConsumerId ( createConsumerId ( ""TargetConsumerId:14"" ) ) ; info . setCompressed ( false ) ; info . setRedeliveryCounter ( 2 ) ; { BrokerId value [ ] = new BrokerId [ 2 ] ; for ( int i = 0 ; i < 2 ; i ++ ) { value [ i ] = createBrokerId ( ""BrokerPath:15"" ) ; } info . setBrokerPath ( value ) ; } info . setArrival ( 3 ) ; info . setUserID ( ""UserID:16"" ) ; info . setRecievedByDFBridge ( true ) ; info . setDroppable ( false ) ; { BrokerId value [ ] = new BrokerId [ 2 ] ; for ( int i = 0 ; i < 2 ; i ++ ) { value [ i ] = createBrokerId ( ""Cluster:17"" ) ; } info . setCluster ( value ) ; } info . setBrokerInTime ( 4 ) ; info . setBrokerOutTime ( 5 ) ; }",Smelly
" private void doRun ( ) { if ( socket . getSocket ( ) == null ) { return ; } SocketState state = handler . process ( socket , status ) ; if ( state == Handler . SocketState . CLOSED ) { closeSocket ( socket . getSocket ( ) . longValue ( ) ) ; socket . socket = null ; } else if ( state == Handler . SocketState . LONG ) { socket . access ( ) ; if ( socket . async ) { waitingRequests . add ( socket ) ; } } else if ( state == Handler . SocketState . ASYNC_END ) { socket . access ( ) ; SocketProcessor proc = new SocketProcessor ( socket , SocketStatus . OPEN_READ ) ; getExecutor ( ) . execute ( proc ) ; } }",Smelly
 public boolean equals ( Object obj ) { if ( obj == this ) { return true ; } if ( obj instanceof PropertyId ) { return super . equals ( ( PropertyId ) obj ) ; } return false ; },No
" public final void onMessage ( T message , boolean last ) { if ( params . length == 1 && params [ 0 ] instanceof DecodeException ) { ( ( WsSession ) session ) . getLocal ( ) . onError ( session , ( DecodeException ) params [ 0 ] ) ; return ; } Object [ ] parameters = params . clone ( ) ; if ( indexBoolean != - 1 ) { parameters [ indexBoolean ] = Boolean . valueOf ( last ) ; } if ( indexSession != - 1 ) { parameters [ indexSession ] = session ; } if ( convert ) { parameters [ indexPayload ] = ( ( ByteBuffer ) message ) . array ( ) ; } else { parameters [ indexPayload ] = message ; } Object result = null ; try { result = method . invoke ( pojo , parameters ) ; } catch ( IllegalAccessException e ) { handlePojoMethodException ( e ) ; } catch ( InvocationTargetException e ) { handlePojoMethodException ( e ) ; } processResult ( result ) ; }",No
" public T receive ( ) throws NetworkException , InterruptedException { LOG . entering ( ""BroadcastReceiver"" , ""receive"" , this ) ; LOG . fine ( ""I am "" + this ) ; if ( init . compareAndSet ( false , true ) ) { LOG . fine ( this + "" Communication group initializing"" ) ; commGroupClient . initialize ( ) ; LOG . fine ( this + "" Communication group initialized"" ) ; } final T retVal ; LOG . fine ( this + "" Waiting to receive broadcast"" ) ; final byte [ ] data ; try { data = topology . recvFromParent ( ReefNetworkGroupCommProtos . GroupCommMessage . Type . Broadcast ) ; if ( data == null ) { LOG . fine ( this + "" Received null. Perhaps one of my ancestors is dead."" ) ; retVal = null ; } else { LOG . finest ( ""Using "" + dataCodec . getClass ( ) . getSimpleName ( ) + "" as codec"" ) ; retVal = dataCodec . decode ( data ) ; LOG . finest ( ""Decoded msg successfully"" ) ; LOG . finest ( this + "" Sending to children."" ) ; } topology . sendToChildren ( data , ReefNetworkGroupCommProtos . GroupCommMessage . Type . Broadcast ) ; } catch ( final ParentDeadException e ) { throw new RuntimeException ( ""ParentDeadException"" , e ) ; } LOG . exiting ( ""BroadcastReceiver"" , ""receive"" , this ) ; return retVal ; }",No
 private static < S extends org . apache . thrift . scheme . IScheme > S scheme ( org . apache . thrift . protocol . TProtocol proto ) { return ( org . apache . thrift . scheme . StandardScheme . class . equals ( proto . getScheme ( ) ) ? STANDARD_SCHEME_FACTORY : TUPLE_SCHEME_FACTORY ) . getScheme ( ) ; },Smelly
" public String toString ( ) { String str = ""VXTrxLog={"" ; str += super . toString ( ) ; str += ""objectClassType={"" + objectClassType + ""} "" ; str += ""objectId={"" + objectId + ""} "" ; str += ""parentObjectId={"" + parentObjectId + ""} "" ; str += ""parentObjectClassType={"" + parentObjectClassType + ""} "" ; str += ""parentObjectName={"" + parentObjectName + ""} "" ; str += ""objectName={"" + objectName + ""} "" ; str += ""attributeName={"" + attributeName + ""} "" ; str += ""previousValue={"" + previousValue + ""} "" ; str += ""newValue={"" + newValue + ""} "" ; str += ""transactionId={"" + transactionId + ""} "" ; str += ""action={"" + action + ""} "" ; str += ""sessionId={"" + sessionId + ""} "" ; str += ""requestId={"" + requestId + ""} "" ; str += ""sessionType={"" + sessionType + ""} "" ; str += ""}"" ; return str ; }",No
 boolean isExternal ( ) ;,No
" public void putMapKeyValue ( ) { CommonDtoUtils . putMapKeyValue ( null , ""someKey"" , ""someValue"" ) ; final MapDto mapDto = new MapDto ( ) ; CommonDtoUtils . putMapKeyValue ( mapDto , ""someKey"" , ""someValue"" ) ; Assert . assertThat ( CommonDtoUtils . getMapValue ( mapDto , ""someKey"" ) , is ( ""someValue"" ) ) ; }",No
" protected void onBeforeRender ( ) { onBeforeRenderOrder . append ( ""|"" ) ; onBeforeRenderOrder . append ( getId ( ) ) ; super . onBeforeRender ( ) ; }",No
" public void read ( org . apache . thrift . protocol . TProtocol prot , ActiveCompaction struct ) throws org . apache . thrift . TException { TTupleProtocol iprot = ( TTupleProtocol ) prot ; BitSet incoming = iprot . readBitSet ( 11 ) ; if ( incoming . get ( 0 ) ) { struct . extent = new org . apache . accumulo . core . data . thrift . TKeyExtent ( ) ; struct . extent . read ( iprot ) ; struct . setExtentIsSet ( true ) ; } if ( incoming . get ( 1 ) ) { struct . age = iprot . readI64 ( ) ; struct . setAgeIsSet ( true ) ; } if ( incoming . get ( 2 ) ) { { org . apache . thrift . protocol . TList _list74 = new org . apache . thrift . protocol . TList ( org . apache . thrift . protocol . TType . STRING , iprot . readI32 ( ) ) ; struct . inputFiles = new ArrayList < String > ( _list74 . size ) ; for ( int _i75 = 0 ; _i75 < _list74 . size ; ++ _i75 ) { String _elem76 ; _elem76 = iprot . readString ( ) ; struct . inputFiles . add ( _elem76 ) ; } } struct . setInputFilesIsSet ( true ) ; } if ( incoming . get ( 3 ) ) { struct . outputFile = iprot . readString ( ) ; struct . setOutputFileIsSet ( true ) ; } if ( incoming . get ( 4 ) ) { struct . type = CompactionType . findByValue ( iprot . readI32 ( ) ) ; struct . setTypeIsSet ( true ) ; } if ( incoming . get ( 5 ) ) { struct . reason = CompactionReason . findByValue ( iprot . readI32 ( ) ) ; struct . setReasonIsSet ( true ) ; } if ( incoming . get ( 6 ) ) { struct . localityGroup = iprot . readString ( ) ; struct . setLocalityGroupIsSet ( true ) ; } if ( incoming . get ( 7 ) ) { struct . entriesRead = iprot . readI64 ( ) ; struct . setEntriesReadIsSet ( true ) ; } if ( incoming . get ( 8 ) ) { struct . entriesWritten = iprot . readI64 ( ) ; struct . setEntriesWrittenIsSet ( true ) ; } if ( incoming . get ( 9 ) ) { { org . apache . thrift . protocol . TList _list77 = new org . apache . thrift . protocol . TList ( org . apache . thrift . protocol . TType . STRUCT , iprot . readI32 ( ) ) ; struct . ssiList = new ArrayList < org . apache . accumulo . core . data . thrift . IterInfo > ( _list77 . size ) ; for ( int _i78 = 0 ; _i78 < _list77 . size ; ++ _i78 ) { org . apache . accumulo . core . data . thrift . IterInfo _elem79 ; _elem79 = new org . apache . accumulo . core . data . thrift . IterInfo ( ) ; _elem79 . read ( iprot ) ; struct . ssiList . add ( _elem79 ) ; } } struct . setSsiListIsSet ( true ) ; } if ( incoming . get ( 10 ) ) { { org . apache . thrift . protocol . TMap _map80 = new org . apache . thrift . protocol . TMap ( org . apache . thrift . protocol . TType . STRING , org . apache . thrift . protocol . TType . MAP , iprot . readI32 ( ) ) ; struct . ssio = new HashMap < String , Map < String , String > > ( 2 * _map80 . size ) ; for ( int _i81 = 0 ; _i81 < _map80 . size ; ++ _i81 ) { String _key82 ; Map < String , String > _val83 ; _key82 = iprot . readString ( ) ; { org . apache . thrift . protocol . TMap _map84 = new org . apache . thrift . protocol . TMap ( org . apache . thrift . protocol . TType . STRING , org . apache . thrift . protocol . TType . STRING , iprot . readI32 ( ) ) ; _val83 = new HashMap < String , String > ( 2 * _map84 . size ) ; for ( int _i85 = 0 ; _i85 < _map84 . size ; ++ _i85 ) { String _key86 ; String _val87 ; _key86 = iprot . readString ( ) ; _val87 = iprot . readString ( ) ; _val83 . put ( _key86 , _val87 ) ; } } struct . ssio . put ( _key82 , _val83 ) ; } } struct . setSsioIsSet ( true ) ; } }",Smelly
" protected void populateObject ( Object object ) throws Exception { super . populateObject ( object ) ; PartialCommand info = ( PartialCommand ) object ; info . setCommandId ( 1 ) ; info . setData ( ""Data:1"" . getBytes ( ) ) ; }",No
" public void runJSONScanPopFragment ( ) throws Exception { try ( final RemoteServiceSet serviceSet = RemoteServiceSet . getLocalServiceSet ( ) ; final Drillbit bit = new Drillbit ( CONFIG , serviceSet ) ; final DrillClient client = new DrillClient ( CONFIG , serviceSet . getCoordinator ( ) ) ) { bit . run ( ) ; client . connect ( ) ; final List < QueryDataBatch > results = client . runQuery ( QueryType . PHYSICAL , Files . toString ( FileUtils . getResourceAsFile ( ""/physical_json_scan_test1.json"" ) , Charsets . UTF_8 ) . replace ( ""#{TEST_FILE}"" , FileUtils . getResourceAsFile ( ""/scan_json_test_1.json"" ) . toURI ( ) . toString ( ) ) ) ; final RecordBatchLoader batchLoader = new RecordBatchLoader ( RootAllocatorFactory . newRoot ( CONFIG ) ) ; int recordCount = 0 ; for ( int i = 0 ; i < results . size ( ) ; ++ i ) { final QueryDataBatch batch = results . get ( i ) ; if ( i == 0 ) { assertTrue ( batch . hasData ( ) ) ; } else { assertFalse ( batch . hasData ( ) ) ; batch . release ( ) ; continue ; } assertTrue ( batchLoader . load ( batch . getHeader ( ) . getDef ( ) , batch . getData ( ) ) ) ; boolean firstColumn = true ; System . out . println ( ""\n\n========NEW SCHEMA=========\n\n"" ) ; for ( final VectorWrapper < ? > v : batchLoader ) { if ( firstColumn ) { firstColumn = false ; } else { System . out . print ( ""\t"" ) ; } System . out . print ( v . getField ( ) . getPath ( ) ) ; System . out . print ( ""["" ) ; System . out . print ( v . getField ( ) . getType ( ) . getMinorType ( ) ) ; System . out . print ( ""]"" ) ; } System . out . println ( ) ; for ( int r = 0 ; r < batchLoader . getRecordCount ( ) ; r ++ ) { boolean first = true ; recordCount ++ ; for ( final VectorWrapper < ? > v : batchLoader ) { if ( first ) { first = false ; } else { System . out . print ( ""\t"" ) ; } final ValueVector . Accessor accessor = v . getValueVector ( ) . getAccessor ( ) ; System . out . print ( accessor . getObject ( r ) ) ; } if ( ! first ) { System . out . println ( ) ; } } batchLoader . clear ( ) ; batch . release ( ) ; } assertEquals ( 2 , recordCount ) ; } }",Smelly
" public MutableRel clone ( ) { return MutableTableModify . of ( rowType , input . clone ( ) , table , catalogReader , operation , updateColumnList , sourceExpressionList , flattened ) ; }",No
" public int evaluate ( Boolean b ) { if ( b ) { return 1 ; } else { throw new RuntimeException ( ""UDFTestErrorOnFalse got b=false"" ) ; } }",No
" public String toString ( ) { return String . format ( ""ExecBean(stdout=%s, stderr=%s, exitcode=%s)"" , stdout , stderr , exitcode ) ; }",No
" public void validateCall ( SqlCall call , SqlValidator validator , SqlValidatorScope scope , SqlValidatorScope operandScope ) { validator . validateWith ( ( SqlWith ) call , scope ) ; }",No
 private static < S extends org . apache . thrift . scheme . IScheme > S scheme ( org . apache . thrift . protocol . TProtocol proto ) { return ( org . apache . thrift . scheme . StandardScheme . class . equals ( proto . getScheme ( ) ) ? STANDARD_SCHEME_FACTORY : TUPLE_SCHEME_FACTORY ) . getScheme ( ) ; },Smelly
" private void parseMajorOrMinor ( ) throws GrammerException , ParsingException { String s ; while ( scanner . tokenType ( ) == Attribute ) { s = scanner . token ( ) ; if ( s . indexOf ( Constants . ATTRIBUTE_NAME_MAJOR_VERSION ) != - 1 ) { try { javaClass . major_version = parseInteger ( s . substring ( s . indexOf ( ':' ) + 1 , s . lastIndexOf ( ']' ) ) . trim ( ) ) ; } catch ( NumberFormatException ne ) { exception ( scanner , ""invalid.major.version.definition"" ) ; } } else if ( s . indexOf ( Constants . ATTRIBUTE_NAME_MINOR_VERSION ) != - 1 ) { try { javaClass . minor_version = parseInteger ( s . substring ( s . indexOf ( ':' ) + 1 , s . lastIndexOf ( ']' ) ) . trim ( ) ) ; } catch ( NumberFormatException ne ) { exception ( scanner , ""invalid.minor.version.definition"" ) ; } } else { exception ( scanner , ""unexpected.attribute.here"" ) ; } scanner . nextToken ( ) ; } }",Smelly
" public com . google . protobuf . ExtensionRegistry assignDescriptors ( com . google . protobuf . Descriptors . FileDescriptor root ) { descriptor = root ; internal_static_org_apache_hadoop_hive_ql_io_orc_IntegerStatistics_descriptor = getDescriptor ( ) . getMessageTypes ( ) . get ( 0 ) ; internal_static_org_apache_hadoop_hive_ql_io_orc_IntegerStatistics_fieldAccessorTable = new com . google . protobuf . GeneratedMessage . FieldAccessorTable ( internal_static_org_apache_hadoop_hive_ql_io_orc_IntegerStatistics_descriptor , new java . lang . String [ ] { ""Minimum"" , ""Maximum"" , ""Sum"" , } ) ; internal_static_org_apache_hadoop_hive_ql_io_orc_DoubleStatistics_descriptor = getDescriptor ( ) . getMessageTypes ( ) . get ( 1 ) ; internal_static_org_apache_hadoop_hive_ql_io_orc_DoubleStatistics_fieldAccessorTable = new com . google . protobuf . GeneratedMessage . FieldAccessorTable ( internal_static_org_apache_hadoop_hive_ql_io_orc_DoubleStatistics_descriptor , new java . lang . String [ ] { ""Minimum"" , ""Maximum"" , ""Sum"" , } ) ; internal_static_org_apache_hadoop_hive_ql_io_orc_StringStatistics_descriptor = getDescriptor ( ) . getMessageTypes ( ) . get ( 2 ) ; internal_static_org_apache_hadoop_hive_ql_io_orc_StringStatistics_fieldAccessorTable = new com . google . protobuf . GeneratedMessage . FieldAccessorTable ( internal_static_org_apache_hadoop_hive_ql_io_orc_StringStatistics_descriptor , new java . lang . String [ ] { ""Minimum"" , ""Maximum"" , ""Sum"" , } ) ; internal_static_org_apache_hadoop_hive_ql_io_orc_BucketStatistics_descriptor = getDescriptor ( ) . getMessageTypes ( ) . get ( 3 ) ; internal_static_org_apache_hadoop_hive_ql_io_orc_BucketStatistics_fieldAccessorTable = new com . google . protobuf . GeneratedMessage . FieldAccessorTable ( internal_static_org_apache_hadoop_hive_ql_io_orc_BucketStatistics_descriptor , new java . lang . String [ ] { ""Count"" , } ) ; internal_static_org_apache_hadoop_hive_ql_io_orc_DecimalStatistics_descriptor = getDescriptor ( ) . getMessageTypes ( ) . get ( 4 ) ; internal_static_org_apache_hadoop_hive_ql_io_orc_DecimalStatistics_fieldAccessorTable = new com . google . protobuf . GeneratedMessage . FieldAccessorTable ( internal_static_org_apache_hadoop_hive_ql_io_orc_DecimalStatistics_descriptor , new java . lang . String [ ] { ""Minimum"" , ""Maximum"" , ""Sum"" , } ) ; internal_static_org_apache_hadoop_hive_ql_io_orc_DateStatistics_descriptor = getDescriptor ( ) . getMessageTypes ( ) . get ( 5 ) ; internal_static_org_apache_hadoop_hive_ql_io_orc_DateStatistics_fieldAccessorTable = new com . google . protobuf . GeneratedMessage . FieldAccessorTable ( internal_static_org_apache_hadoop_hive_ql_io_orc_DateStatistics_descriptor , new java . lang . String [ ] { ""Minimum"" , ""Maximum"" , } ) ; internal_static_org_apache_hadoop_hive_ql_io_orc_BinaryStatistics_descriptor = getDescriptor ( ) . getMessageTypes ( ) . get ( 6 ) ; internal_static_org_apache_hadoop_hive_ql_io_orc_BinaryStatistics_fieldAccessorTable = new com . google . protobuf . GeneratedMessage . FieldAccessorTable ( internal_static_org_apache_hadoop_hive_ql_io_orc_BinaryStatistics_descriptor , new java . lang . String [ ] { ""Sum"" , } ) ; internal_static_org_apache_hadoop_hive_ql_io_orc_ColumnStatistics_descriptor = getDescriptor ( ) . getMessageTypes ( ) . get ( 7 ) ; internal_static_org_apache_hadoop_hive_ql_io_orc_ColumnStatistics_fieldAccessorTable = new com . google . protobuf . GeneratedMessage . FieldAccessorTable ( internal_static_org_apache_hadoop_hive_ql_io_orc_ColumnStatistics_descriptor , new java . lang . String [ ] { ""NumberOfValues"" , ""IntStatistics"" , ""DoubleStatistics"" , ""StringStatistics"" , ""BucketStatistics"" , ""DecimalStatistics"" , ""DateStatistics"" , ""BinaryStatistics"" , } ) ; internal_static_org_apache_hadoop_hive_ql_io_orc_RowIndexEntry_descriptor = getDescriptor ( ) . getMessageTypes ( ) . get ( 8 ) ; internal_static_org_apache_hadoop_hive_ql_io_orc_RowIndexEntry_fieldAccessorTable = new com . google . protobuf . GeneratedMessage . FieldAccessorTable ( internal_static_org_apache_hadoop_hive_ql_io_orc_RowIndexEntry_descriptor , new java . lang . String [ ] { ""Positions"" , ""Statistics"" , } ) ; internal_static_org_apache_hadoop_hive_ql_io_orc_RowIndex_descriptor = getDescriptor ( ) . getMessageTypes ( ) . get ( 9 ) ; internal_static_org_apache_hadoop_hive_ql_io_orc_RowIndex_fieldAccessorTable = new com . google . protobuf . GeneratedMessage . FieldAccessorTable ( internal_static_org_apache_hadoop_hive_ql_io_orc_RowIndex_descriptor , new java . lang . String [ ] { ""Entry"" , } ) ; internal_static_org_apache_hadoop_hive_ql_io_orc_Stream_descriptor = getDescriptor ( ) . getMessageTypes ( ) . get ( 10 ) ; internal_static_org_apache_hadoop_hive_ql_io_orc_Stream_fieldAccessorTable = new com . google . protobuf . GeneratedMessage . FieldAccessorTable ( internal_static_org_apache_hadoop_hive_ql_io_orc_Stream_descriptor , new java . lang . String [ ] { ""Kind"" , ""Column"" , ""Length"" , } ) ; internal_static_org_apache_hadoop_hive_ql_io_orc_ColumnEncoding_descriptor = getDescriptor ( ) . getMessageTypes ( ) . get ( 11 ) ; internal_static_org_apache_hadoop_hive_ql_io_orc_ColumnEncoding_fieldAccessorTable = new com . google . protobuf . GeneratedMessage . FieldAccessorTable ( internal_static_org_apache_hadoop_hive_ql_io_orc_ColumnEncoding_descriptor , new java . lang . String [ ] { ""Kind"" , ""DictionarySize"" , } ) ; internal_static_org_apache_hadoop_hive_ql_io_orc_StripeFooter_descriptor = getDescriptor ( ) . getMessageTypes ( ) . get ( 12 ) ; internal_static_org_apache_hadoop_hive_ql_io_orc_StripeFooter_fieldAccessorTable = new com . google . protobuf . GeneratedMessage . FieldAccessorTable ( internal_static_org_apache_hadoop_hive_ql_io_orc_StripeFooter_descriptor , new java . lang . String [ ] { ""Streams"" , ""Columns"" , } ) ; internal_static_org_apache_hadoop_hive_ql_io_orc_Type_descriptor = getDescriptor ( ) . getMessageTypes ( ) . get ( 13 ) ; internal_static_org_apache_hadoop_hive_ql_io_orc_Type_fieldAccessorTable = new com . google . protobuf . GeneratedMessage . FieldAccessorTable ( internal_static_org_apache_hadoop_hive_ql_io_orc_Type_descriptor , new java . lang . String [ ] { ""Kind"" , ""Subtypes"" , ""FieldNames"" , ""MaximumLength"" , ""Precision"" , ""Scale"" , } ) ; internal_static_org_apache_hadoop_hive_ql_io_orc_StripeInformation_descriptor = getDescriptor ( ) . getMessageTypes ( ) . get ( 14 ) ; internal_static_org_apache_hadoop_hive_ql_io_orc_StripeInformation_fieldAccessorTable = new com . google . protobuf . GeneratedMessage . FieldAccessorTable ( internal_static_org_apache_hadoop_hive_ql_io_orc_StripeInformation_descriptor , new java . lang . String [ ] { ""Offset"" , ""IndexLength"" , ""DataLength"" , ""FooterLength"" , ""NumberOfRows"" , } ) ; internal_static_org_apache_hadoop_hive_ql_io_orc_UserMetadataItem_descriptor = getDescriptor ( ) . getMessageTypes ( ) . get ( 15 ) ; internal_static_org_apache_hadoop_hive_ql_io_orc_UserMetadataItem_fieldAccessorTable = new com . google . protobuf . GeneratedMessage . FieldAccessorTable ( internal_static_org_apache_hadoop_hive_ql_io_orc_UserMetadataItem_descriptor , new java . lang . String [ ] { ""Name"" , ""Value"" , } ) ; internal_static_org_apache_hadoop_hive_ql_io_orc_StripeStatistics_descriptor = getDescriptor ( ) . getMessageTypes ( ) . get ( 16 ) ; internal_static_org_apache_hadoop_hive_ql_io_orc_StripeStatistics_fieldAccessorTable = new com . google . protobuf . GeneratedMessage . FieldAccessorTable ( internal_static_org_apache_hadoop_hive_ql_io_orc_StripeStatistics_descriptor , new java . lang . String [ ] { ""ColStats"" , } ) ; internal_static_org_apache_hadoop_hive_ql_io_orc_Metadata_descriptor = getDescriptor ( ) . getMessageTypes ( ) . get ( 17 ) ; internal_static_org_apache_hadoop_hive_ql_io_orc_Metadata_fieldAccessorTable = new com . google . protobuf . GeneratedMessage . FieldAccessorTable ( internal_static_org_apache_hadoop_hive_ql_io_orc_Metadata_descriptor , new java . lang . String [ ] { ""StripeStats"" , } ) ; internal_static_org_apache_hadoop_hive_ql_io_orc_Footer_descriptor = getDescriptor ( ) . getMessageTypes ( ) . get ( 18 ) ; internal_static_org_apache_hadoop_hive_ql_io_orc_Footer_fieldAccessorTable = new com . google . protobuf . GeneratedMessage . FieldAccessorTable ( internal_static_org_apache_hadoop_hive_ql_io_orc_Footer_descriptor , new java . lang . String [ ] { ""HeaderLength"" , ""ContentLength"" , ""Stripes"" , ""Types"" , ""Metadata"" , ""NumberOfRows"" , ""Statistics"" , ""RowIndexStride"" , } ) ; internal_static_org_apache_hadoop_hive_ql_io_orc_PostScript_descriptor = getDescriptor ( ) . getMessageTypes ( ) . get ( 19 ) ; internal_static_org_apache_hadoop_hive_ql_io_orc_PostScript_fieldAccessorTable = new com . google . protobuf . GeneratedMessage . FieldAccessorTable ( internal_static_org_apache_hadoop_hive_ql_io_orc_PostScript_descriptor , new java . lang . String [ ] { ""FooterLength"" , ""Compression"" , ""CompressionBlockSize"" , ""Version"" , ""MetadataLength"" , ""Magic"" , } ) ; return null ; }",No
 public long getTrailerHitCount ( ) { return this . cacheStats != null ? this . cacheStats . getTrailerHitCount ( ) : 0L ; },Smelly
" public void read ( org . apache . thrift . protocol . TProtocol prot , getChildDataProducts_result struct ) throws org . apache . thrift . TException { TTupleProtocol iprot = ( TTupleProtocol ) prot ; BitSet incoming = iprot . readBitSet ( 5 ) ; if ( incoming . get ( 0 ) ) { { org . apache . thrift . protocol . TList _list283 = new org . apache . thrift . protocol . TList ( org . apache . thrift . protocol . TType . STRUCT , iprot . readI32 ( ) ) ; struct . success = new ArrayList < org . apache . airavata . model . data . replica . DataProductModel > ( _list283 . size ) ; org . apache . airavata . model . data . replica . DataProductModel _elem284 ; for ( int _i285 = 0 ; _i285 < _list283 . size ; ++ _i285 ) { _elem284 = new org . apache . airavata . model . data . replica . DataProductModel ( ) ; _elem284 . read ( iprot ) ; struct . success . add ( _elem284 ) ; } } struct . setSuccessIsSet ( true ) ; } if ( incoming . get ( 1 ) ) { struct . ire = new org . apache . airavata . model . error . InvalidRequestException ( ) ; struct . ire . read ( iprot ) ; struct . setIreIsSet ( true ) ; } if ( incoming . get ( 2 ) ) { struct . ace = new org . apache . airavata . model . error . AiravataClientException ( ) ; struct . ace . read ( iprot ) ; struct . setAceIsSet ( true ) ; } if ( incoming . get ( 3 ) ) { struct . ase = new org . apache . airavata . model . error . AiravataSystemException ( ) ; struct . ase . read ( iprot ) ; struct . setAseIsSet ( true ) ; } if ( incoming . get ( 4 ) ) { struct . ae = new org . apache . airavata . model . error . AuthorizationException ( ) ; struct . ae . read ( iprot ) ; struct . setAeIsSet ( true ) ; } }",Smelly
" public void read ( org . apache . thrift . protocol . TProtocol prot , show_compact_result struct ) throws org . apache . thrift . TException { TTupleProtocol iprot = ( TTupleProtocol ) prot ; BitSet incoming = iprot . readBitSet ( 1 ) ; if ( incoming . get ( 0 ) ) { struct . success = new ShowCompactResponse ( ) ; struct . success . read ( iprot ) ; struct . setSuccessIsSet ( true ) ; } }",Smelly
" public String toString ( ) { return ""AdsAddDeviceNotificationResponse{"" + ""result="" + result + "", notificationHandle="" + notificationHandle + ""} "" + super . toString ( ) ; }",No
" protected SpatialMatch getSpatialMatch ( Double latitude , Double longitude , int limit ) { SpatialMatch match = new SpatialMatch ( SpatialQuery . ctx . getWorldBounds ( ) . getMinY ( ) , longitude , SpatialQuery . ctx . getWorldBounds ( ) . getMaxY ( ) , SpatialQuery . ctx . getWorldBounds ( ) . getMaxX ( ) , limit , getSpatialOperation ( ) ) ; return match ; }",No
 public VersionedFlowStatus getStatus ( ) { return status ; },No
" public abstract void dagComplete ( TezDAGID dag , JobTokenSecretManager jobTokenSecretManager ) ;",No
 public abstract int getBlockEntryBytesCount ( ) ;,No
" public static void ensureAllClassesLoaded ( Bundle bundle ) throws ClassNotFoundException { BundleWiring wiring = bundle . adapt ( BundleWiring . class ) ; if ( wiring != null ) { for ( String path : wiring . listResources ( ""/"" , ""*.class"" , BundleWiring . LISTRESOURCES_RECURSE ) ) { String className = path . substring ( 0 , path . length ( ) - "".class"" . length ( ) ) ; className = className . replace ( '/' , '.' ) ; bundle . loadClass ( className ) ; } } }",No
" public void onEvent ( PreEventContext context ) throws MetaException , NoSuchObjectException , InvalidOperationException { notifyList . add ( context ) ; }",No
" public void read ( org . apache . thrift . protocol . TProtocol prot , finishFateOperation_result struct ) throws org . apache . thrift . TException { TTupleProtocol iprot = ( TTupleProtocol ) prot ; BitSet incoming = iprot . readBitSet ( 1 ) ; if ( incoming . get ( 0 ) ) { struct . sec = new org . apache . accumulo . core . client . impl . thrift . ThriftSecurityException ( ) ; struct . sec . read ( iprot ) ; struct . setSecIsSet ( true ) ; } }",Smelly
" public void read ( org . apache . thrift . protocol . TProtocol prot , getChildDataProducts_result struct ) throws org . apache . thrift . TException { TTupleProtocol iprot = ( TTupleProtocol ) prot ; BitSet incoming = iprot . readBitSet ( 5 ) ; if ( incoming . get ( 0 ) ) { { org . apache . thrift . protocol . TList _list283 = new org . apache . thrift . protocol . TList ( org . apache . thrift . protocol . TType . STRUCT , iprot . readI32 ( ) ) ; struct . success = new ArrayList < org . apache . airavata . model . data . replica . DataProductModel > ( _list283 . size ) ; org . apache . airavata . model . data . replica . DataProductModel _elem284 ; for ( int _i285 = 0 ; _i285 < _list283 . size ; ++ _i285 ) { _elem284 = new org . apache . airavata . model . data . replica . DataProductModel ( ) ; _elem284 . read ( iprot ) ; struct . success . add ( _elem284 ) ; } } struct . setSuccessIsSet ( true ) ; } if ( incoming . get ( 1 ) ) { struct . ire = new org . apache . airavata . model . error . InvalidRequestException ( ) ; struct . ire . read ( iprot ) ; struct . setIreIsSet ( true ) ; } if ( incoming . get ( 2 ) ) { struct . ace = new org . apache . airavata . model . error . AiravataClientException ( ) ; struct . ace . read ( iprot ) ; struct . setAceIsSet ( true ) ; } if ( incoming . get ( 3 ) ) { struct . ase = new org . apache . airavata . model . error . AiravataSystemException ( ) ; struct . ase . read ( iprot ) ; struct . setAseIsSet ( true ) ; } if ( incoming . get ( 4 ) ) { struct . ae = new org . apache . airavata . model . error . AuthorizationException ( ) ; struct . ae . read ( iprot ) ; struct . setAeIsSet ( true ) ; } }",Smelly
" public Serde < byte [ ] > getSerde ( String name , Config config ) { return new ByteSerde ( ) ; }",No
 private boolean seekable ( BeamRelNode relNode ) { if ( relNode instanceof BeamIOSourceRel ) { BeamIOSourceRel srcRel = ( BeamIOSourceRel ) relNode ; BeamSqlTable sourceTable = srcRel . getBeamSqlTable ( ) ; if ( sourceTable instanceof BeamSqlSeekableTable ) { return true ; } } return false ; },Smelly
" public static Map < String , Object > renderContentPdf ( DispatchContext dctx , Map < String , ? extends Object > context ) { LocalDispatcher dispatcher = dctx . getDispatcher ( ) ; Map < String , Object > results = ServiceUtil . returnSuccess ( ) ; String dataResourceId = null ; Locale locale = ( Locale ) context . get ( ""locale"" ) ; String rootDir = ( String ) context . get ( ""rootDir"" ) ; String webSiteId = ( String ) context . get ( ""webSiteId"" ) ; String https = ( String ) context . get ( ""https"" ) ; Delegator delegator = dctx . getDelegator ( ) ; String contentId = ( String ) context . get ( ""contentId"" ) ; String contentRevisionSeqId = ( String ) context . get ( ""contentRevisionSeqId"" ) ; String oooHost = ( String ) context . get ( ""oooHost"" ) ; String oooPort = ( String ) context . get ( ""oooPort"" ) ; GenericValue userLogin = ( GenericValue ) context . get ( ""userLogin"" ) ; try { Document document = new Document ( ) ; document . setPageSize ( PageSize . LETTER ) ; document . open ( ) ; GenericValue dataResource = null ; if ( UtilValidate . isEmpty ( contentRevisionSeqId ) ) { GenericValue content = delegator . findOne ( ""Content"" , UtilMisc . toMap ( ""contentId"" , contentId ) , true ) ; dataResourceId = content . getString ( ""dataResourceId"" ) ; Debug . logInfo ( ""SCVH(0b)- dataResourceId:"" + dataResourceId , module ) ; dataResource = delegator . findOne ( ""DataResource"" , UtilMisc . toMap ( ""dataResourceId"" , dataResourceId ) , false ) ; } else { GenericValue contentRevisionItem = delegator . findOne ( ""ContentRevisionItem"" , UtilMisc . toMap ( ""contentId"" , contentId , ""itemContentId"" , contentId , ""contentRevisionSeqId"" , contentRevisionSeqId ) , true ) ; if ( contentRevisionItem == null ) { throw new ViewHandlerException ( ""ContentRevisionItem record not found for contentId="" + contentId + "", contentRevisionSeqId="" + contentRevisionSeqId + "", itemContentId="" + contentId ) ; } Debug . logInfo ( ""SCVH(1)- contentRevisionItem:"" + contentRevisionItem , module ) ; Debug . logInfo ( ""SCVH(2)-contentId="" + contentId + "", contentRevisionSeqId="" + contentRevisionSeqId + "", itemContentId="" + contentId , module ) ; dataResourceId = contentRevisionItem . getString ( ""newDataResourceId"" ) ; Debug . logInfo ( ""SCVH(3)- dataResourceId:"" + dataResourceId , module ) ; dataResource = delegator . findOne ( ""DataResource"" , UtilMisc . toMap ( ""dataResourceId"" , dataResourceId ) , false ) ; } String inputMimeType = null ; if ( dataResource != null ) { inputMimeType = dataResource . getString ( ""mimeTypeId"" ) ; } byte [ ] inputByteArray = null ; if ( inputMimeType != null && inputMimeType . equals ( ""application/pdf"" ) ) { ByteBuffer byteBuffer = DataResourceWorker . getContentAsByteBuffer ( delegator , dataResourceId , https , webSiteId , locale , rootDir ) ; inputByteArray = byteBuffer . array ( ) ; } else if ( inputMimeType != null && inputMimeType . equals ( ""text/html"" ) ) { ByteBuffer byteBuffer = DataResourceWorker . getContentAsByteBuffer ( delegator , dataResourceId , https , webSiteId , locale , rootDir ) ; inputByteArray = byteBuffer . array ( ) ; String s = new String ( inputByteArray ) ; Debug . logInfo ( ""text/html string:"" + s , module ) ; } else if ( inputMimeType != null && inputMimeType . equals ( ""application/vnd.ofbiz.survey.response"" ) ) { String surveyResponseId = dataResource . getString ( ""relatedDetailId"" ) ; String surveyId = null ; String acroFormContentId = null ; GenericValue surveyResponse = null ; if ( UtilValidate . isNotEmpty ( surveyResponseId ) ) { surveyResponse = delegator . findOne ( ""SurveyResponse"" , UtilMisc . toMap ( ""surveyResponseId"" , surveyResponseId ) , false ) ; if ( surveyResponse != null ) { surveyId = surveyResponse . getString ( ""surveyId"" ) ; } } if ( UtilValidate . isNotEmpty ( surveyId ) ) { GenericValue survey = delegator . findOne ( ""Survey"" , UtilMisc . toMap ( ""surveyId"" , surveyId ) , false ) ; if ( survey != null ) { acroFormContentId = survey . getString ( ""acroFormContentId"" ) ; if ( UtilValidate . isNotEmpty ( acroFormContentId ) ) { } } } if ( surveyResponse != null ) { if ( UtilValidate . isEmpty ( acroFormContentId ) ) { Map < String , Object > survey2PdfResults = dispatcher . runSync ( ""buildPdfFromSurveyResponse"" , UtilMisc . toMap ( ""surveyResponseId"" , surveyResponseId ) ) ; if ( ServiceUtil . isError ( survey2PdfResults ) ) { return ServiceUtil . returnError ( UtilProperties . getMessage ( resource , ""ContentSurveyErrorBuildingPDF"" , locale ) , null , null , survey2PdfResults ) ; } ByteBuffer outByteBuffer = ( ByteBuffer ) survey2PdfResults . get ( ""outByteBuffer"" ) ; inputByteArray = outByteBuffer . array ( ) ; } else { Map < String , Object > survey2AcroFieldResults = dispatcher . runSync ( ""setAcroFieldsFromSurveyResponse"" , UtilMisc . toMap ( ""surveyResponseId"" , surveyResponseId ) ) ; if ( ServiceUtil . isError ( survey2AcroFieldResults ) ) { return ServiceUtil . returnError ( UtilProperties . getMessage ( resource , ""ContentSurveyErrorSettingAcroFields"" , locale ) , null , null , survey2AcroFieldResults ) ; } ByteBuffer outByteBuffer = ( ByteBuffer ) survey2AcroFieldResults . get ( ""outByteBuffer"" ) ; inputByteArray = outByteBuffer . array ( ) ; } } } else { ByteBuffer inByteBuffer = DataResourceWorker . getContentAsByteBuffer ( delegator , dataResourceId , https , webSiteId , locale , rootDir ) ; Map < String , Object > convertInMap = UtilMisc . < String , Object > toMap ( ""userLogin"" , userLogin , ""inByteBuffer"" , inByteBuffer , ""inputMimeType"" , inputMimeType , ""outputMimeType"" , ""application/pdf"" ) ; if ( UtilValidate . isNotEmpty ( oooHost ) ) convertInMap . put ( ""oooHost"" , oooHost ) ; if ( UtilValidate . isNotEmpty ( oooPort ) ) convertInMap . put ( ""oooPort"" , oooPort ) ; Map < String , Object > convertResult = dispatcher . runSync ( ""convertDocumentByteBuffer"" , convertInMap ) ; if ( ServiceUtil . isError ( convertResult ) ) { return ServiceUtil . returnError ( UtilProperties . getMessage ( resource , ""ContentConvertingDocumentByteBuffer"" , locale ) , null , null , convertResult ) ; } ByteBuffer outByteBuffer = ( ByteBuffer ) convertResult . get ( ""outByteBuffer"" ) ; inputByteArray = outByteBuffer . array ( ) ; } ByteBuffer outByteBuffer = ByteBuffer . wrap ( inputByteArray ) ; results . put ( ""outByteBuffer"" , outByteBuffer ) ; } catch ( GenericEntityException e ) { return ServiceUtil . returnError ( e . toString ( ) ) ; } catch ( IOException e ) { Debug . logError ( e , ""Error in PDF generation: "" , module ) ; return ServiceUtil . returnError ( e . toString ( ) ) ; } catch ( Exception e ) { Debug . logError ( e , ""Error in PDF generation: "" , module ) ; return ServiceUtil . returnError ( e . toString ( ) ) ; } return results ; }",Smelly
" public void read ( org . apache . thrift . protocol . TProtocol prot , RenewDelegationToken_result struct ) throws org . apache . thrift . TException { TTupleProtocol iprot = ( TTupleProtocol ) prot ; BitSet incoming = iprot . readBitSet ( 1 ) ; if ( incoming . get ( 0 ) ) { struct . success = new TRenewDelegationTokenResp ( ) ; struct . success . read ( iprot ) ; struct . setSuccessIsSet ( true ) ; } }",No
" public void read ( org . apache . thrift . protocol . TProtocol prot , drainReplicationTable_result struct ) throws org . apache . thrift . TException { TTupleProtocol iprot = ( TTupleProtocol ) prot ; BitSet incoming = iprot . readBitSet ( 1 ) ; if ( incoming . get ( 0 ) ) { struct . success = iprot . readBool ( ) ; struct . setSuccessIsSet ( true ) ; } }",Smelly
 public KafkaFuture < Long > expiryTimestamp ( ) { return expiryTimestamp ; },No
 protected SimpleDateFormat newSimpleDateFormatUsingDateTimePattern ( ) { return new SimpleDateFormat ( dateTimePattern ) ; },No
 public void readFields ( DataInput input ) throws IOException { id = input . readInt ( ) ; },No
" static String add_escapes ( String str ) { StringBuffer retval = new StringBuffer ( ) ; char ch ; for ( int i = 0 ; i < str . length ( ) ; i ++ ) { switch ( str . charAt ( i ) ) { case 0 : continue ; case '\b' : retval . append ( ""\\b"" ) ; continue ; case '\t' : retval . append ( ""\\t"" ) ; continue ; case '\n' : retval . append ( ""\\n"" ) ; continue ; case '\f' : retval . append ( ""\\f"" ) ; continue ; case '\r' : retval . append ( ""\\r"" ) ; continue ; case '\""' : retval . append ( ""\\\"""" ) ; continue ; case '\'' : retval . append ( ""\\\'"" ) ; continue ; case '\\' : retval . append ( ""\\\\"" ) ; continue ; default : if ( ( ch = str . charAt ( i ) ) < 0x20 || ch > 0x7e ) { String s = ""0000"" + Integer . toString ( ch , 16 ) ; retval . append ( ""\\u"" + s . substring ( s . length ( ) - 4 , s . length ( ) ) ) ; } else { retval . append ( ch ) ; } continue ; } } return retval . toString ( ) ; }",Smelly
" public void addFont ( int fontReference , AFPFont font , int size , int orientation ) throws MaximumSizeExceededException { FontDefinition fontDefinition = new FontDefinition ( ) ; fontDefinition . fontReferenceKey = BinaryUtils . convert ( fontReference ) [ 0 ] ; switch ( orientation ) { case 90 : fontDefinition . orientation = 0x2D ; break ; case 180 : fontDefinition . orientation = 0x5A ; break ; case 270 : fontDefinition . orientation = ( byte ) 0x87 ; break ; default : fontDefinition . orientation = 0x00 ; break ; } try { if ( font instanceof RasterFont ) { RasterFont raster = ( RasterFont ) font ; CharacterSet cs = raster . getCharacterSet ( size ) ; if ( cs == null ) { String msg = ""Character set not found for font "" + font . getFontName ( ) + "" with point size "" + size ; LOG . error ( msg ) ; throw new FontRuntimeException ( msg ) ; } fontDefinition . characterSet = cs . getNameBytes ( ) ; if ( fontDefinition . characterSet . length != 8 ) { throw new IllegalArgumentException ( ""The character set "" + new String ( fontDefinition . characterSet , AFPConstants . EBCIDIC_ENCODING ) + "" must have a fixed length of 8 characters."" ) ; } fontDefinition . codePage = cs . getCodePage ( ) . getBytes ( AFPConstants . EBCIDIC_ENCODING ) ; if ( fontDefinition . codePage . length != 8 ) { throw new IllegalArgumentException ( ""The code page "" + new String ( fontDefinition . codePage , AFPConstants . EBCIDIC_ENCODING ) + "" must have a fixed length of 8 characters."" ) ; } } else if ( font instanceof OutlineFont ) { OutlineFont outline = ( OutlineFont ) font ; CharacterSet cs = outline . getCharacterSet ( ) ; fontDefinition . characterSet = cs . getNameBytes ( ) ; fontDefinition . scale = 20 * size / 1000 ; fontDefinition . codePage = cs . getCodePage ( ) . getBytes ( AFPConstants . EBCIDIC_ENCODING ) ; if ( fontDefinition . codePage . length != 8 ) { throw new IllegalArgumentException ( ""The code page "" + new String ( fontDefinition . codePage , AFPConstants . EBCIDIC_ENCODING ) + "" must have a fixed length of 8 characters."" ) ; } } else if ( font instanceof DoubleByteFont ) { DoubleByteFont outline = ( DoubleByteFont ) font ; CharacterSet cs = outline . getCharacterSet ( ) ; fontDefinition . characterSet = cs . getNameBytes ( ) ; fontDefinition . scale = 20 * size / 1000 ; fontDefinition . codePage = cs . getCodePage ( ) . getBytes ( AFPConstants . EBCIDIC_ENCODING ) ; if ( fontDefinition . codePage . length != 8 ) { throw new IllegalArgumentException ( ""The code page "" + new String ( fontDefinition . codePage , AFPConstants . EBCIDIC_ENCODING ) + "" must have a fixed length of 8 characters."" ) ; } } else { String msg = ""Font of type "" + font . getClass ( ) . getName ( ) + "" not recognized."" ; LOG . error ( msg ) ; throw new FontRuntimeException ( msg ) ; } if ( fontList . size ( ) > 253 ) { throw new MaximumSizeExceededException ( ) ; } else { fontList . add ( fontDefinition ) ; } } catch ( UnsupportedEncodingException ex ) { throw new FontRuntimeException ( ""Failed to create font "" + "" due to a UnsupportedEncodingException"" , ex ) ; } }",Smelly
" public void read ( org . apache . thrift . protocol . TProtocol prot , getFollowing_result struct ) throws org . apache . thrift . TException { TTupleProtocol iprot = ( TTupleProtocol ) prot ; BitSet incoming = iprot . readBitSet ( 1 ) ; if ( incoming . get ( 0 ) ) { struct . success = new Key ( ) ; struct . success . read ( iprot ) ; struct . setSuccessIsSet ( true ) ; } }",Smelly
" private static int [ ] toKeyIndex ( int start , int end ) { int [ ] keyIndex = new int [ end - start ] ; for ( int i = 0 ; i < keyIndex . length ; i ++ ) { keyIndex [ i ] = start + i ; } return keyIndex ; }",Smelly
 public void close ( ) { },No
" public void doSave ( Widget frmModel , JXPathContext jxpc ) { jxpc . removePath ( ""."" ) ; }",No
 Class < ? > getStorageInterface ( ) ;,No
" public void testDbcp369 ( ) { final ArrayList < SharedPoolDataSource > dataSources = new ArrayList < > ( ) ; for ( int j = 0 ; j < 10000 ; j ++ ) { final SharedPoolDataSource dataSource = new SharedPoolDataSource ( ) ; dataSources . add ( dataSource ) ; } final Thread t1 = new Thread ( new Runnable ( ) { @ Override public void run ( ) { for ( final SharedPoolDataSource dataSource : dataSources ) { dataSource . setDataSourceName ( ""a"" ) ; } } } ) ; final Thread t2 = new Thread ( new Runnable ( ) { @ Override public void run ( ) { for ( final SharedPoolDataSource dataSource : dataSources ) { try { dataSource . close ( ) ; } catch ( final Exception e ) { } } } } ) ; t1 . start ( ) ; t2 . start ( ) ; try { t1 . join ( ) ; t2 . join ( ) ; } catch ( final InterruptedException ie ) { } }",No
 public JavaClass parseClass ( File classFile ) throws IOException { JavaClass ret = null ; try { FileInputStream fsin = new FileInputStream ( classFile ) ; in = new DataInputStream ( fsin ) ; readMagic ( ) ; readVersion ( ) ; readConstant_Pool_Count ( ) ; readConstantPool ( ) ; readAccess_flags ( ) ; readThis_class ( ) ; readSuper_class ( ) ; readInterfaces ( ) ; readFields ( ) ; readMethods ( ) ; readAttributes ( ) ; ret = new JavaClass ( ) ; ret . magic = magic ; ret . minor_version = minor_Version ; ret . major_version = major_Version ; ret . constant_pool_count = constant_Pool_Count ; ret . constantPool = constantPool ; ret . access_flags = access_flags ; ret . this_class = this_class ; ret . super_class = super_class ; ret . interfaces_count = interfaces_count ; ret . interfaces = interfaces ; ret . fields_count = fields_count ; ret . fields = fields ; ret . methods_count = methods_count ; ret . methods = methods ; ret . attributes_count = attributes_count ; ret . attributes = attributes ; } finally { try { in . close ( ) ; } catch ( Exception e ) { } } return ret ; },Smelly
 public String getProcessGroupIdentifier ( ) { return innerValidationContext . getProcessGroupIdentifier ( ) ; },No
 public Schema getSchema ( ) { return schema ; },No
" public void decode ( IoSession session , IoBuffer buffer , ProtocolDecoderOutput out ) throws Exception { byte [ ] tempBuffer = ( byte [ ] ) session . getAttribute ( ""tempBuffer"" ) ; Integer bufferPosition = ( Integer ) session . getAttribute ( ""bufferPosition"" ) ; Integer bufferDataLength = ( Integer ) session . getAttribute ( ""bufferDataLength"" ) ; if ( tempBuffer == null ) { tempBuffer = new byte [ SoapTcpOutputStream . CHUNK_SIZE ] ; bufferDataLength = buffer . limit ( ) ; for ( bufferPosition = Integer . valueOf ( 0 ) ; bufferPosition < bufferDataLength ; bufferPosition ++ ) { tempBuffer [ bufferPosition ] = buffer . get ( ) ; } session . setAttribute ( ""tempBuffer"" , tempBuffer ) ; session . setAttribute ( ""bufferPosition"" , bufferPosition ) ; session . setAttribute ( ""bufferDataLength"" , bufferDataLength ) ; } else { bufferDataLength += buffer . limit ( ) ; for ( ; bufferPosition < bufferDataLength ; bufferPosition ++ ) { tempBuffer [ bufferPosition ] = buffer . get ( ) ; } } SoapTcpSessionState sessionState = ( SoapTcpSessionState ) session . getAttribute ( ""sessionState"" ) ; if ( sessionState != null && sessionState . getStateId ( ) == SoapTcpSessionState . SOAP_TCP_SESSION_STATE_NEW ) { if ( bufferPosition == 16 ) { out . write ( IoBuffer . wrap ( tempBuffer , 0 , bufferPosition ) ) ; bufferPosition = 0 ; bufferDataLength = 0 ; session . setAttribute ( ""bufferPosition"" , bufferPosition ) ; session . setAttribute ( ""bufferDataLength"" , bufferDataLength ) ; return ; } else { return ; } } InputStream inStream = new ByteArrayInputStream ( tempBuffer , 0 , bufferDataLength ) ; try { SoapTcpFrame frame = SoapTcpUtils . readMessageFrame ( inStream ) ; List < SoapTcpChannel > channels = ( List < SoapTcpChannel > ) session . getAttribute ( ""channels"" ) ; for ( SoapTcpChannel channel : channels ) { if ( channel . getChannelId ( ) == frame . getChannelId ( ) ) { switch ( frame . getHeader ( ) . getFrameType ( ) ) { case SoapTcpFrameHeader . SINGLE_FRAME_MESSAGE : case SoapTcpFrameHeader . ERROR_MESSAGE : case SoapTcpFrameHeader . NULL_MESSAGE : SoapTcpMessage singleFrameMessage = SoapTcpMessage . createSoapTcpMessage ( frame ) ; out . write ( singleFrameMessage ) ; bufferPosition = 0 ; bufferDataLength = 0 ; break ; case SoapTcpFrameHeader . MESSAGE_START_CHUNK : case SoapTcpFrameHeader . MESSAGE_CHUNK : channel . addFrame ( frame ) ; bufferPosition = 0 ; bufferDataLength = 0 ; break ; case SoapTcpFrameHeader . MESSAGE_END_CHUNK : List < SoapTcpFrame > frames = channel . getFrames ( ) ; SoapTcpMessage multiFrameMessage = SoapTcpMessage . createSoapTcpMessage ( frames ) ; multiFrameMessage . getFrames ( ) . add ( frame ) ; out . write ( multiFrameMessage ) ; bufferPosition = 0 ; bufferDataLength = 0 ; break ; default : return ; } } } } catch ( IOException ex ) { } finally { session . setAttribute ( ""bufferPosition"" , bufferPosition ) ; session . setAttribute ( ""bufferDataLength"" , bufferDataLength ) ; } }",Smelly
" public void testSchemaGeneration ( ) { JDBCConfiguration conf = new JDBCConfigurationImpl ( ) ; DBDictionary dict = conf . getDBDictionaryInstance ( ) ; MappingRepository repos = conf . getMappingRepositoryInstance ( ) ; repos . setStrategyInstaller ( new RefreshStrategyInstaller ( repos ) ) ; ClassMapping mapping = repos . getMapping ( Column . class , null , true ) ; Class cls ; if ( dict . getPreferredType ( JavaSQLTypes . CLOB ) == JavaSQLTypes . CLOB ) { if ( dict . maxEmbeddedClobSize > 0 ) { cls = mapping . getFieldMapping ( ""toClob"" ) . getStrategy ( ) . getClass ( ) ; assertTrue ( cls . getName ( ) , MaxEmbeddedClobFieldStrategy . class . isAssignableFrom ( cls ) ) ; } else { cls = mapping . getFieldMapping ( ""toClob"" ) . getHandler ( ) . getClass ( ) ; assertTrue ( cls . getName ( ) , ClobValueHandler . class . isAssignableFrom ( cls ) ) ; } } else assertTrue ( mapping . getFieldMapping ( ""toClob"" ) . getStrategy ( ) instanceof StringFieldStrategy ) ; cls = mapping . getFieldMapping ( ""toBlob"" ) . getHandler ( ) . getClass ( ) ; assertTrue ( cls . getName ( ) , BlobValueHandler . class . isAssignableFrom ( cls ) ) ; SchemaGroup schema = repos . getSchemaGroup ( ) ; Table table = schema . getSchemas ( ) [ 0 ] . getTables ( ) [ 0 ] ; Column [ ] cols = table . getColumns ( ) ; for ( int i = 0 ; i < cols . length ; i ++ ) { if ( cols [ i ] . getName ( ) . equalsIgnoreCase ( ""id"" ) || cols [ i ] . getName ( ) . equalsIgnoreCase ( ""versn"" ) || cols [ i ] . getName ( ) . equalsIgnoreCase ( ""typ"" ) ) continue ; if ( ""longToInt"" . equalsIgnoreCase ( cols [ i ] . getName ( ) ) ) assertEquals ( dict . getPreferredType ( JavaSQLTypes . INT ) , cols [ i ] . getType ( ) ) ; else if ( ""longToSQL"" . equalsIgnoreCase ( cols [ i ] . getName ( ) ) ) assertEquals ( ""varchar"" , cols [ i ] . getTypeName ( ) ) ; else if ( ""toClob"" . equalsIgnoreCase ( cols [ i ] . getName ( ) ) ) assertEquals ( dict . getPreferredType ( JavaSQLTypes . CLOB ) , cols [ i ] . getType ( ) ) ; else if ( ""toBlob"" . equalsIgnoreCase ( cols [ i ] . getName ( ) ) ) assertEquals ( dict . getPreferredType ( JavaSQLTypes . BLOB ) , cols [ i ] . getType ( ) ) ; else fail ( ""Unknown column:"" + cols [ i ] . getName ( ) ) ; } }",Smelly
" public static Map < String , Object > createJsLanguageFileMapping ( DispatchContext ctx , Map < String , ? > context ) { Map < String , Object > result = ServiceUtil . returnSuccess ( ) ; String encoding = ( String ) context . get ( ""encoding"" ) ; List < Locale > localeList = UtilMisc . availableLocales ( ) ; Map < String , Object > jQueryLocaleFile = FastMap . newInstance ( ) ; Map < String , String > dateJsLocaleFile = FastMap . newInstance ( ) ; Map < String , String > validationLocaleFile = FastMap . newInstance ( ) ; Map < String , String > dateTimePickerLocaleFile = FastMap . newInstance ( ) ; String componentRoot = ""component://images/webapp"" ; String jqueryUiLocaleRelPath = ""/images/jquery/ui/i18n/"" ; String dateJsLocaleRelPath = ""/images/jquery/plugins/datejs/"" ; String validateRelPath = ""/images/jquery/plugins/validate/localization/"" ; String dateTimePickerJsLocaleRelPath = ""/images/jquery/plugins/datetimepicker/localization/"" ; String jsFilePostFix = "".js"" ; String dateJsLocalePrefix = ""date-"" ; String validateLocalePrefix = ""messages_"" ; String jqueryUiLocalePrefix = ""jquery.ui.datepicker-"" ; String dateTimePickerPrefix = ""jquery-ui-timepicker-"" ; String defaultLocaleDateJs = ""en-US"" ; String defaultLocaleJquery = ""en"" ; for ( Locale locale : localeList ) { String displayCountry = locale . toString ( ) ; String modifiedDisplayCountry = null ; String modifiedDisplayCountryForValidation = null ; if ( displayCountry . contains ( ""_"" ) ) { modifiedDisplayCountry = displayCountry . replace ( ""_"" , ""-"" ) ; modifiedDisplayCountryForValidation = displayCountry ; } else { modifiedDisplayCountry = displayCountry ; } String strippedLocale = locale . getLanguage ( ) ; File file = null ; String fileUrl = null ; String fileName = componentRoot + dateJsLocaleRelPath + dateJsLocalePrefix + modifiedDisplayCountry + jsFilePostFix ; file = FileUtil . getFile ( fileName ) ; if ( file . exists ( ) ) { fileUrl = dateJsLocaleRelPath + dateJsLocalePrefix + modifiedDisplayCountry + jsFilePostFix ; } else { String tmpLocale = strippedLocale + ""-"" + strippedLocale . toUpperCase ( ) ; fileName = componentRoot + dateJsLocaleRelPath + dateJsLocalePrefix + tmpLocale + jsFilePostFix ; file = FileUtil . getFile ( fileName ) ; if ( file . exists ( ) ) { fileUrl = dateJsLocaleRelPath + dateJsLocalePrefix + tmpLocale + jsFilePostFix ; } else { fileUrl = dateJsLocaleRelPath + dateJsLocalePrefix + defaultLocaleDateJs + jsFilePostFix ; } } dateJsLocaleFile . put ( displayCountry , fileUrl ) ; if ( modifiedDisplayCountryForValidation != null ) { fileName = componentRoot + validateRelPath + validateLocalePrefix + modifiedDisplayCountryForValidation + jsFilePostFix ; file = FileUtil . getFile ( fileName ) ; if ( file . exists ( ) ) { fileUrl = validateRelPath + validateLocalePrefix + modifiedDisplayCountryForValidation + jsFilePostFix ; } else { fileName = componentRoot + validateRelPath + validateLocalePrefix + strippedLocale + jsFilePostFix ; file = FileUtil . getFile ( fileName ) ; if ( file . exists ( ) ) { fileUrl = validateRelPath + validateLocalePrefix + strippedLocale + jsFilePostFix ; } else { fileUrl = validateRelPath + validateLocalePrefix + defaultLocaleJquery + jsFilePostFix ; } } } else { fileName = componentRoot + validateRelPath + validateLocalePrefix + strippedLocale + jsFilePostFix ; file = FileUtil . getFile ( fileName ) ; if ( file . exists ( ) ) { fileUrl = validateRelPath + validateLocalePrefix + strippedLocale + jsFilePostFix ; } else { fileUrl = validateRelPath + validateLocalePrefix + defaultLocaleJquery + jsFilePostFix ; } } validationLocaleFile . put ( displayCountry , fileUrl ) ; fileName = componentRoot + jqueryUiLocaleRelPath + jqueryUiLocalePrefix + strippedLocale + jsFilePostFix ; file = FileUtil . getFile ( fileName ) ; if ( file . exists ( ) ) { fileUrl = jqueryUiLocaleRelPath + jqueryUiLocalePrefix + strippedLocale + jsFilePostFix ; } else { fileName = componentRoot + jqueryUiLocaleRelPath + jqueryUiLocalePrefix + modifiedDisplayCountry + jsFilePostFix ; file = FileUtil . getFile ( fileName ) ; if ( file . exists ( ) ) { fileUrl = jqueryUiLocaleRelPath + jqueryUiLocalePrefix + modifiedDisplayCountry + jsFilePostFix ; } else { fileUrl = jqueryUiLocaleRelPath + jqueryUiLocalePrefix + defaultLocaleJquery + jsFilePostFix ; } } jQueryLocaleFile . put ( displayCountry , fileUrl ) ; fileName = componentRoot + dateTimePickerJsLocaleRelPath + dateTimePickerPrefix + strippedLocale + jsFilePostFix ; file = FileUtil . getFile ( fileName ) ; if ( file . exists ( ) ) { fileUrl = dateTimePickerJsLocaleRelPath + dateTimePickerPrefix + strippedLocale + jsFilePostFix ; } else { fileName = componentRoot + dateTimePickerJsLocaleRelPath + dateTimePickerPrefix + modifiedDisplayCountry + jsFilePostFix ; file = FileUtil . getFile ( fileName ) ; if ( file . exists ( ) ) { fileUrl = dateTimePickerJsLocaleRelPath + dateTimePickerPrefix + modifiedDisplayCountry + jsFilePostFix ; } else { fileUrl = dateTimePickerJsLocaleRelPath + dateTimePickerPrefix + defaultLocaleJquery + jsFilePostFix ; } } dateTimePickerLocaleFile . put ( displayCountry , fileUrl ) ; } String template = ""framework/common/template/JsLanguageFilesMapping.ftl"" ; String output = ""framework/common/src/org/ofbiz/common/JsLanguageFilesMapping.java"" ; Map < String , Object > mapWrapper = new HashMap < String , Object > ( ) ; mapWrapper . put ( ""datejs"" , dateJsLocaleFile ) ; mapWrapper . put ( ""jquery"" , jQueryLocaleFile ) ; mapWrapper . put ( ""validation"" , validationLocaleFile ) ; mapWrapper . put ( ""dateTime"" , dateTimePickerLocaleFile ) ; Writer writer = new StringWriter ( ) ; try { FreeMarkerWorker . renderTemplateAtLocation ( template , mapWrapper , writer ) ; File file = new File ( output ) ; FileUtils . writeStringToFile ( file , writer . toString ( ) , encoding ) ; } catch ( Exception e ) { Debug . logError ( e , module ) ; return ServiceUtil . returnError ( ""The Outputfile could not be created: "" + e . getMessage ( ) ) ; } return result ; }",Smelly
" public void read ( org . apache . thrift . protocol . TProtocol prot , ExperimentModel struct ) throws org . apache . thrift . TException { TTupleProtocol iprot = ( TTupleProtocol ) prot ; struct . experimentId = iprot . readString ( ) ; struct . setExperimentIdIsSet ( true ) ; struct . projectId = iprot . readString ( ) ; struct . setProjectIdIsSet ( true ) ; struct . gatewayId = iprot . readString ( ) ; struct . setGatewayIdIsSet ( true ) ; struct . experimentType = org . apache . airavata . model . experiment . ExperimentType . findByValue ( iprot . readI32 ( ) ) ; struct . setExperimentTypeIsSet ( true ) ; struct . userName = iprot . readString ( ) ; struct . setUserNameIsSet ( true ) ; struct . experimentName = iprot . readString ( ) ; struct . setExperimentNameIsSet ( true ) ; BitSet incoming = iprot . readBitSet ( 13 ) ; if ( incoming . get ( 0 ) ) { struct . creationTime = iprot . readI64 ( ) ; struct . setCreationTimeIsSet ( true ) ; } if ( incoming . get ( 1 ) ) { struct . description = iprot . readString ( ) ; struct . setDescriptionIsSet ( true ) ; } if ( incoming . get ( 2 ) ) { struct . executionId = iprot . readString ( ) ; struct . setExecutionIdIsSet ( true ) ; } if ( incoming . get ( 3 ) ) { struct . gatewayExecutionId = iprot . readString ( ) ; struct . setGatewayExecutionIdIsSet ( true ) ; } if ( incoming . get ( 4 ) ) { struct . gatewayInstanceId = iprot . readString ( ) ; struct . setGatewayInstanceIdIsSet ( true ) ; } if ( incoming . get ( 5 ) ) { struct . enableEmailNotification = iprot . readBool ( ) ; struct . setEnableEmailNotificationIsSet ( true ) ; } if ( incoming . get ( 6 ) ) { { org . apache . thrift . protocol . TList _list25 = new org . apache . thrift . protocol . TList ( org . apache . thrift . protocol . TType . STRING , iprot . readI32 ( ) ) ; struct . emailAddresses = new ArrayList < String > ( _list25 . size ) ; String _elem26 ; for ( int _i27 = 0 ; _i27 < _list25 . size ; ++ _i27 ) { _elem26 = iprot . readString ( ) ; struct . emailAddresses . add ( _elem26 ) ; } } struct . setEmailAddressesIsSet ( true ) ; } if ( incoming . get ( 7 ) ) { struct . userConfigurationData = new UserConfigurationDataModel ( ) ; struct . userConfigurationData . read ( iprot ) ; struct . setUserConfigurationDataIsSet ( true ) ; } if ( incoming . get ( 8 ) ) { { org . apache . thrift . protocol . TList _list28 = new org . apache . thrift . protocol . TList ( org . apache . thrift . protocol . TType . STRUCT , iprot . readI32 ( ) ) ; struct . experimentInputs = new ArrayList < org . apache . airavata . model . application . io . InputDataObjectType > ( _list28 . size ) ; org . apache . airavata . model . application . io . InputDataObjectType _elem29 ; for ( int _i30 = 0 ; _i30 < _list28 . size ; ++ _i30 ) { _elem29 = new org . apache . airavata . model . application . io . InputDataObjectType ( ) ; _elem29 . read ( iprot ) ; struct . experimentInputs . add ( _elem29 ) ; } } struct . setExperimentInputsIsSet ( true ) ; } if ( incoming . get ( 9 ) ) { { org . apache . thrift . protocol . TList _list31 = new org . apache . thrift . protocol . TList ( org . apache . thrift . protocol . TType . STRUCT , iprot . readI32 ( ) ) ; struct . experimentOutputs = new ArrayList < org . apache . airavata . model . application . io . OutputDataObjectType > ( _list31 . size ) ; org . apache . airavata . model . application . io . OutputDataObjectType _elem32 ; for ( int _i33 = 0 ; _i33 < _list31 . size ; ++ _i33 ) { _elem32 = new org . apache . airavata . model . application . io . OutputDataObjectType ( ) ; _elem32 . read ( iprot ) ; struct . experimentOutputs . add ( _elem32 ) ; } } struct . setExperimentOutputsIsSet ( true ) ; } if ( incoming . get ( 10 ) ) { struct . experimentStatus = new org . apache . airavata . model . status . ExperimentStatus ( ) ; struct . experimentStatus . read ( iprot ) ; struct . setExperimentStatusIsSet ( true ) ; } if ( incoming . get ( 11 ) ) { { org . apache . thrift . protocol . TList _list34 = new org . apache . thrift . protocol . TList ( org . apache . thrift . protocol . TType . STRUCT , iprot . readI32 ( ) ) ; struct . errors = new ArrayList < org . apache . airavata . model . commons . ErrorModel > ( _list34 . size ) ; org . apache . airavata . model . commons . ErrorModel _elem35 ; for ( int _i36 = 0 ; _i36 < _list34 . size ; ++ _i36 ) { _elem35 = new org . apache . airavata . model . commons . ErrorModel ( ) ; _elem35 . read ( iprot ) ; struct . errors . add ( _elem35 ) ; } } struct . setErrorsIsSet ( true ) ; } if ( incoming . get ( 12 ) ) { { org . apache . thrift . protocol . TList _list37 = new org . apache . thrift . protocol . TList ( org . apache . thrift . protocol . TType . STRUCT , iprot . readI32 ( ) ) ; struct . processes = new ArrayList < org . apache . airavata . model . process . ProcessModel > ( _list37 . size ) ; org . apache . airavata . model . process . ProcessModel _elem38 ; for ( int _i39 = 0 ; _i39 < _list37 . size ; ++ _i39 ) { _elem38 = new org . apache . airavata . model . process . ProcessModel ( ) ; _elem38 . read ( iprot ) ; struct . processes . add ( _elem38 ) ; } } struct . setProcessesIsSet ( true ) ; } }",Smelly
" public void read ( org . apache . thrift . protocol . TProtocol prot , show_compact_result struct ) throws org . apache . thrift . TException { TTupleProtocol iprot = ( TTupleProtocol ) prot ; BitSet incoming = iprot . readBitSet ( 1 ) ; if ( incoming . get ( 0 ) ) { struct . success = new ShowCompactResponse ( ) ; struct . success . read ( iprot ) ; struct . setSuccessIsSet ( true ) ; } }",No
" public < T > AggregationFunction < T > createAggregationFunction ( Class < T > type ) { if ( type == Long . class ) { return ( AggregationFunction < T > ) new LongSumAgg ( ) ; } else if ( type == LongValue . class ) { return ( AggregationFunction < T > ) new LongValueSumAgg ( ) ; } else if ( type == Integer . class ) { return ( AggregationFunction < T > ) new IntSumAgg ( ) ; } else if ( type == IntValue . class ) { return ( AggregationFunction < T > ) new IntValueSumAgg ( ) ; } else if ( type == Double . class ) { return ( AggregationFunction < T > ) new DoubleSumAgg ( ) ; } else if ( type == DoubleValue . class ) { return ( AggregationFunction < T > ) new DoubleValueSumAgg ( ) ; } else if ( type == Float . class ) { return ( AggregationFunction < T > ) new FloatSumAgg ( ) ; } else if ( type == FloatValue . class ) { return ( AggregationFunction < T > ) new FloatValueSumAgg ( ) ; } else if ( type == Byte . class ) { return ( AggregationFunction < T > ) new ByteSumAgg ( ) ; } else if ( type == ByteValue . class ) { return ( AggregationFunction < T > ) new ByteValueSumAgg ( ) ; } else if ( type == Short . class ) { return ( AggregationFunction < T > ) new ShortSumAgg ( ) ; } else if ( type == ShortValue . class ) { return ( AggregationFunction < T > ) new ShortValueSumAgg ( ) ; } else { throw new UnsupportedAggregationTypeException ( ""The type "" + type . getName ( ) + "" is currently not supported for built-in sum aggregations."" ) ; } }",Smelly
" public void read ( org . apache . thrift . protocol . TProtocol prot , show_compact_result struct ) throws org . apache . thrift . TException { TTupleProtocol iprot = ( TTupleProtocol ) prot ; BitSet incoming = iprot . readBitSet ( 1 ) ; if ( incoming . get ( 0 ) ) { struct . success = new ShowCompactResponse ( ) ; struct . success . read ( iprot ) ; struct . setSuccessIsSet ( true ) ; } }",Smelly
 abstract public void test ( Thread runnable ) throws InterruptedException ;,No
" public void regionFromZone ( ) throws Exception { assertEquals ( ""us-central1"" , GcpTempLocationFactory . getRegionFromZone ( ""us-central1-a"" ) ) ; assertEquals ( ""asia-east"" , GcpTempLocationFactory . getRegionFromZone ( ""asia-east-a"" ) ) ; }",No
" public void testHappyPathSelfOpZkCacheBaseDataAccessor ( ) throws Exception { String className = TestHelper . getTestClassName ( ) ; String methodName = TestHelper . getTestMethodName ( ) ; String clusterName = className + ""_"" + methodName ; System . out . println ( ""START "" + clusterName + "" at "" + new Date ( System . currentTimeMillis ( ) ) ) ; String curStatePath = PropertyPathConfig . getPath ( PropertyType . CURRENTSTATES , clusterName , ""localhost_8901"" ) ; String extViewPath = PropertyPathConfig . getPath ( PropertyType . EXTERNALVIEW , clusterName ) ; ZkBaseDataAccessor < ZNRecord > baseAccessor = new ZkBaseDataAccessor < ZNRecord > ( _zkclient ) ; baseAccessor . create ( curStatePath , null , AccessOption . PERSISTENT ) ; List < String > zkCacheInitPaths = Arrays . asList ( curStatePath , extViewPath ) ; ZkCacheBaseDataAccessor < ZNRecord > accessor = new ZkCacheBaseDataAccessor < ZNRecord > ( baseAccessor , null , null , zkCacheInitPaths ) ; boolean ret = TestHelper . verifyZkCache ( zkCacheInitPaths , accessor . _zkCache . _cache , _zkclient , true ) ; Assert . assertTrue ( ret , ""zkCache doesn't match data on Zk"" ) ; List < String > paths = new ArrayList < String > ( ) ; List < ZNRecord > records = new ArrayList < ZNRecord > ( ) ; for ( int i = 0 ; i < 10 ; i ++ ) { String path = PropertyPathConfig . getPath ( PropertyType . CURRENTSTATES , clusterName , ""localhost_8901"" , ""session_0"" , ""TestDB"" + i ) ; ZNRecord record = new ZNRecord ( ""TestDB"" + i ) ; paths . add ( path ) ; records . add ( record ) ; } boolean [ ] success = accessor . createChildren ( paths , records , AccessOption . PERSISTENT ) ; for ( int i = 0 ; i < 10 ; i ++ ) { Assert . assertTrue ( success [ i ] , ""Should succeed in create: "" + paths . get ( i ) ) ; } ret = TestHelper . verifyZkCache ( zkCacheInitPaths , accessor . _zkCache . _cache , _zkclient , false ) ; Assert . assertTrue ( ret , ""zkCache doesn't match data on Zk"" ) ; List < DataUpdater < ZNRecord > > updaters = new ArrayList < DataUpdater < ZNRecord > > ( ) ; for ( int j = 0 ; j < 10 ; j ++ ) { paths . clear ( ) ; updaters . clear ( ) ; for ( int i = 0 ; i < 10 ; i ++ ) { String path = curStatePath + ""/session_0/TestDB"" + i ; ZNRecord newRecord = new ZNRecord ( ""TestDB"" + i ) ; newRecord . setSimpleField ( """" + j , """" + j ) ; DataUpdater < ZNRecord > updater = new ZNRecordUpdater ( newRecord ) ; paths . add ( path ) ; updaters . add ( updater ) ; } success = accessor . updateChildren ( paths , updaters , AccessOption . PERSISTENT ) ; for ( int i = 0 ; i < 10 ; i ++ ) { Assert . assertTrue ( success [ i ] , ""Should succeed in update: "" + paths . get ( i ) ) ; } } ret = TestHelper . verifyZkCache ( zkCacheInitPaths , zkCacheInitPaths , accessor . _zkCache . _cache , _zkclient , true ) ; Assert . assertTrue ( ret , ""zkCache doesn't match data on Zk"" ) ; paths . clear ( ) ; records . clear ( ) ; for ( int j = 0 ; j < 10 ; j ++ ) { for ( int i = 0 ; i < 10 ; i ++ ) { String path = PropertyPathConfig . getPath ( PropertyType . EXTERNALVIEW , clusterName , ""TestDB"" + i ) ; ZNRecord record = new ZNRecord ( ""TestDB"" + i ) ; record . setSimpleField ( ""setKey"" , """" + j ) ; paths . add ( path ) ; records . add ( record ) ; } success = accessor . setChildren ( paths , records , AccessOption . PERSISTENT ) ; for ( int i = 0 ; i < 10 ; i ++ ) { Assert . assertTrue ( success [ i ] , ""Should succeed in set: "" + paths . get ( i ) ) ; } } ret = TestHelper . verifyZkCache ( zkCacheInitPaths , accessor . _zkCache . _cache , _zkclient , true ) ; Assert . assertTrue ( ret , ""zkCache doesn't match data on Zk"" ) ; paths . clear ( ) ; records . clear ( ) ; for ( int i = 0 ; i < 10 ; i ++ ) { String path = extViewPath + ""/TestDB"" + i ; paths . add ( path ) ; } records = accessor . get ( paths , null , 0 ) ; for ( int i = 0 ; i < 10 ; i ++ ) { Assert . assertEquals ( records . get ( i ) . getId ( ) , ""TestDB"" + i ) ; } records . clear ( ) ; records = accessor . getChildren ( extViewPath , null , 0 ) ; for ( int i = 0 ; i < 10 ; i ++ ) { Assert . assertEquals ( records . get ( i ) . getId ( ) , ""TestDB"" + i ) ; } paths . clear ( ) ; for ( int i = 0 ; i < 10 ; i ++ ) { String path = curStatePath + ""/session_0/TestDB"" + i ; paths . add ( path ) ; } success = accessor . exists ( paths , 0 ) ; for ( int i = 0 ; i < 10 ; i ++ ) { Assert . assertTrue ( success [ i ] , ""Should exits: "" + paths . get ( i ) ) ; } System . out . println ( ""END "" + clusterName + "" at "" + new Date ( System . currentTimeMillis ( ) ) ) ; }",Smelly
" protected Query [ ] prepareQueries ( ) throws Exception { String words [ ] ; ArrayList w = new ArrayList ( ) ; StringTokenizer st = new StringTokenizer ( SimpleDocMaker . DOC_TEXT ) ; while ( st . hasMoreTokens ( ) && w . size ( ) < 100 ) { w . add ( st . nextToken ( ) ) ; } words = ( String [ ] ) w . toArray ( new String [ 0 ] ) ; ArrayList queries = new ArrayList ( ) ; for ( int slop = 0 ; slop < 8 ; slop ++ ) { for ( int qlen = 2 ; qlen < 6 ; qlen ++ ) { for ( int wd = 0 ; wd < words . length - qlen - slop ; wd ++ ) { int remainedSlop = slop ; PhraseQuery q = new PhraseQuery ( ) ; q . setSlop ( slop ) ; int wind = wd ; for ( int i = 0 ; i < qlen ; i ++ ) { q . add ( new Term ( BasicDocMaker . BODY_FIELD , words [ wind ++ ] ) ) ; if ( remainedSlop > 0 ) { remainedSlop -- ; wind ++ ; } } queries . add ( q ) ; remainedSlop = slop ; q = new PhraseQuery ( ) ; q . setSlop ( slop + 2 * qlen ) ; wind = wd + qlen + remainedSlop - 1 ; for ( int i = 0 ; i < qlen ; i ++ ) { q . add ( new Term ( BasicDocMaker . BODY_FIELD , words [ wind -- ] ) ) ; if ( remainedSlop > 0 ) { remainedSlop -- ; wind -- ; } } queries . add ( q ) ; } } } return ( Query [ ] ) queries . toArray ( new Query [ 0 ] ) ; }",Smelly
 public long getLastModifiedAt ( Configuration configuration ) { return - 1 ; },No
" protected NodeTable createEmptyNodeTable ( ) { StoreParams params = StoreParamsBuilder . create ( ) . nodeId2NodeCacheSize ( - 1 ) . node2NodeIdCacheSize ( - 1 ) . nodeMissCacheSize ( - 1 ) . build ( ) ; return BuildTestLib . makeNodeTableBase ( Location . mem ( ) , ""test"" , params ) ; }",No
" static String add_escapes ( String str ) { StringBuffer retval = new StringBuffer ( ) ; char ch ; for ( int i = 0 ; i < str . length ( ) ; i ++ ) { switch ( str . charAt ( i ) ) { case 0 : continue ; case '\b' : retval . append ( ""\\b"" ) ; continue ; case '\t' : retval . append ( ""\\t"" ) ; continue ; case '\n' : retval . append ( ""\\n"" ) ; continue ; case '\f' : retval . append ( ""\\f"" ) ; continue ; case '\r' : retval . append ( ""\\r"" ) ; continue ; case '\""' : retval . append ( ""\\\"""" ) ; continue ; case '\'' : retval . append ( ""\\\'"" ) ; continue ; case '\\' : retval . append ( ""\\\\"" ) ; continue ; default : if ( ( ch = str . charAt ( i ) ) < 0x20 || ch > 0x7e ) { String s = ""0000"" + Integer . toString ( ch , 16 ) ; retval . append ( ""\\u"" + s . substring ( s . length ( ) - 4 , s . length ( ) ) ) ; } else { retval . append ( ch ) ; } continue ; } } return retval . toString ( ) ; }",Smelly
" public void addEditDirectoryPurge ( String daysOlder , String retentionCount , String description , boolean success ) { setFieldValue ( ""daysOlder"" , daysOlder ) ; setFieldValue ( ""retentionCount"" , retentionCount ) ; setFieldValue ( ""description"" , description ) ; submit ( ) ; if ( success ) { assertGeneralPurgePage ( ) ; } else { assertAddEditDirectoryPurgePage ( ) ; } }",No
 public void close ( ) throws IOException { if ( chunk != null ) chunk . close ( ) ; },No
" public void read ( org . apache . thrift . protocol . TProtocol prot , getChildDataProducts_result struct ) throws org . apache . thrift . TException { TTupleProtocol iprot = ( TTupleProtocol ) prot ; BitSet incoming = iprot . readBitSet ( 5 ) ; if ( incoming . get ( 0 ) ) { { org . apache . thrift . protocol . TList _list283 = new org . apache . thrift . protocol . TList ( org . apache . thrift . protocol . TType . STRUCT , iprot . readI32 ( ) ) ; struct . success = new ArrayList < org . apache . airavata . model . data . replica . DataProductModel > ( _list283 . size ) ; org . apache . airavata . model . data . replica . DataProductModel _elem284 ; for ( int _i285 = 0 ; _i285 < _list283 . size ; ++ _i285 ) { _elem284 = new org . apache . airavata . model . data . replica . DataProductModel ( ) ; _elem284 . read ( iprot ) ; struct . success . add ( _elem284 ) ; } } struct . setSuccessIsSet ( true ) ; } if ( incoming . get ( 1 ) ) { struct . ire = new org . apache . airavata . model . error . InvalidRequestException ( ) ; struct . ire . read ( iprot ) ; struct . setIreIsSet ( true ) ; } if ( incoming . get ( 2 ) ) { struct . ace = new org . apache . airavata . model . error . AiravataClientException ( ) ; struct . ace . read ( iprot ) ; struct . setAceIsSet ( true ) ; } if ( incoming . get ( 3 ) ) { struct . ase = new org . apache . airavata . model . error . AiravataSystemException ( ) ; struct . ase . read ( iprot ) ; struct . setAseIsSet ( true ) ; } if ( incoming . get ( 4 ) ) { struct . ae = new org . apache . airavata . model . error . AuthorizationException ( ) ; struct . ae . read ( iprot ) ; struct . setAeIsSet ( true ) ; } }",No
" public IResourceStream getMarkupResourceStream ( MarkupContainer container , Class < ? > containerClass ) { return new StringResourceStream ( ""<html><body></body></html>"" ) ; }",No
" public void read ( org . apache . thrift . protocol . TProtocol prot , checkNamespaceClass_result struct ) throws org . apache . thrift . TException { TTupleProtocol iprot = ( TTupleProtocol ) prot ; BitSet incoming = iprot . readBitSet ( 3 ) ; if ( incoming . get ( 0 ) ) { struct . success = iprot . readBool ( ) ; struct . setSuccessIsSet ( true ) ; } if ( incoming . get ( 1 ) ) { struct . sec = new ThriftSecurityException ( ) ; struct . sec . read ( iprot ) ; struct . setSecIsSet ( true ) ; } if ( incoming . get ( 2 ) ) { struct . tope = new ThriftTableOperationException ( ) ; struct . tope . read ( iprot ) ; struct . setTopeIsSet ( true ) ; } }",Smelly
" public void read ( org . apache . thrift . protocol . TProtocol prot , RenewDelegationToken_result struct ) throws org . apache . thrift . TException { TTupleProtocol iprot = ( TTupleProtocol ) prot ; BitSet incoming = iprot . readBitSet ( 1 ) ; if ( incoming . get ( 0 ) ) { struct . success = new TRenewDelegationTokenResp ( ) ; struct . success . read ( iprot ) ; struct . setSuccessIsSet ( true ) ; } }",No
 public ResourceRequestEvent build ( ) { return new ResourceRequestEventImpl ( this ) ; },No
" public void read ( org . apache . thrift . protocol . TProtocol prot , getChildDataProducts_result struct ) throws org . apache . thrift . TException { TTupleProtocol iprot = ( TTupleProtocol ) prot ; BitSet incoming = iprot . readBitSet ( 5 ) ; if ( incoming . get ( 0 ) ) { { org . apache . thrift . protocol . TList _list283 = new org . apache . thrift . protocol . TList ( org . apache . thrift . protocol . TType . STRUCT , iprot . readI32 ( ) ) ; struct . success = new ArrayList < org . apache . airavata . model . data . replica . DataProductModel > ( _list283 . size ) ; org . apache . airavata . model . data . replica . DataProductModel _elem284 ; for ( int _i285 = 0 ; _i285 < _list283 . size ; ++ _i285 ) { _elem284 = new org . apache . airavata . model . data . replica . DataProductModel ( ) ; _elem284 . read ( iprot ) ; struct . success . add ( _elem284 ) ; } } struct . setSuccessIsSet ( true ) ; } if ( incoming . get ( 1 ) ) { struct . ire = new org . apache . airavata . model . error . InvalidRequestException ( ) ; struct . ire . read ( iprot ) ; struct . setIreIsSet ( true ) ; } if ( incoming . get ( 2 ) ) { struct . ace = new org . apache . airavata . model . error . AiravataClientException ( ) ; struct . ace . read ( iprot ) ; struct . setAceIsSet ( true ) ; } if ( incoming . get ( 3 ) ) { struct . ase = new org . apache . airavata . model . error . AiravataSystemException ( ) ; struct . ase . read ( iprot ) ; struct . setAseIsSet ( true ) ; } if ( incoming . get ( 4 ) ) { struct . ae = new org . apache . airavata . model . error . AuthorizationException ( ) ; struct . ae . read ( iprot ) ; struct . setAeIsSet ( true ) ; } }",Smelly
 public Object getValueAndReset ( ) { ConcurrentMap metrics = getMetrics ( ) ; resetMetrics ( ) ; return metrics ; },No
" public void read ( org . apache . thrift . protocol . TProtocol prot , getChildDataProducts_result struct ) throws org . apache . thrift . TException { TTupleProtocol iprot = ( TTupleProtocol ) prot ; BitSet incoming = iprot . readBitSet ( 5 ) ; if ( incoming . get ( 0 ) ) { { org . apache . thrift . protocol . TList _list283 = new org . apache . thrift . protocol . TList ( org . apache . thrift . protocol . TType . STRUCT , iprot . readI32 ( ) ) ; struct . success = new ArrayList < org . apache . airavata . model . data . replica . DataProductModel > ( _list283 . size ) ; org . apache . airavata . model . data . replica . DataProductModel _elem284 ; for ( int _i285 = 0 ; _i285 < _list283 . size ; ++ _i285 ) { _elem284 = new org . apache . airavata . model . data . replica . DataProductModel ( ) ; _elem284 . read ( iprot ) ; struct . success . add ( _elem284 ) ; } } struct . setSuccessIsSet ( true ) ; } if ( incoming . get ( 1 ) ) { struct . ire = new org . apache . airavata . model . error . InvalidRequestException ( ) ; struct . ire . read ( iprot ) ; struct . setIreIsSet ( true ) ; } if ( incoming . get ( 2 ) ) { struct . ace = new org . apache . airavata . model . error . AiravataClientException ( ) ; struct . ace . read ( iprot ) ; struct . setAceIsSet ( true ) ; } if ( incoming . get ( 3 ) ) { struct . ase = new org . apache . airavata . model . error . AiravataSystemException ( ) ; struct . ase . read ( iprot ) ; struct . setAseIsSet ( true ) ; } if ( incoming . get ( 4 ) ) { struct . ae = new org . apache . airavata . model . error . AuthorizationException ( ) ; struct . ae . read ( iprot ) ; struct . setAeIsSet ( true ) ; } }",Smelly
" public void read ( org . apache . thrift . protocol . TProtocol prot , show_compact_result struct ) throws org . apache . thrift . TException { TTupleProtocol iprot = ( TTupleProtocol ) prot ; BitSet incoming = iprot . readBitSet ( 1 ) ; if ( incoming . get ( 0 ) ) { struct . success = new ShowCompactResponse ( ) ; struct . success . read ( iprot ) ; struct . setSuccessIsSet ( true ) ; } }",Smelly
" public void process ( JCas jcas ) throws AnalysisEngineProcessException { CAS cas = jcas . getCas ( ) ; String documentText = cas . getDocumentText ( ) ; BufferedReader br = new BufferedReader ( new StringReader ( documentText ) ) ; Type lineType = cas . getTypeSystem ( ) . getType ( TYPE_LINE ) ; Type wsLineType = cas . getTypeSystem ( ) . getType ( TYPE_WSLINE ) ; Type emptyLineType = cas . getTypeSystem ( ) . getType ( TYPE_EMPTYLINE ) ; Type paragraphType = cas . getTypeSystem ( ) . getType ( TYPE_PARAGRAPH ) ; int offsetTillNow = 0 ; int paragraphBegin = - 1 ; int lastLineEnd = 0 ; boolean lastWasEmpty = true ; String eachLine = null ; try { while ( ( eachLine = br . readLine ( ) ) != null ) { boolean wsLine = StringUtils . isBlank ( eachLine ) ; if ( ! wsLine && StringUtils . isBlank ( eachLine . trim ( ) . replaceAll ( ""\u00A0|\u202F|\uFEFF|\u2007|\u180E"" , """" ) ) ) { wsLine = true ; } boolean emptyLine = StringUtils . isEmpty ( eachLine ) ; int offsetAfterLine = offsetTillNow + eachLine . length ( ) ; int nlLength = 1 ; if ( documentText . length ( ) >= offsetAfterLine + 2 ) { String substring = documentText . substring ( offsetAfterLine , offsetAfterLine + 2 ) ; if ( substring . equals ( ""\r\n"" ) ) { nlLength = 2 ; } } if ( lastWasEmpty && ! wsLine ) { paragraphBegin = offsetTillNow ; } if ( wsLine && emptyLine ) { AnnotationFS newEmptyLineFS = cas . createAnnotation ( emptyLineType , offsetTillNow , offsetTillNow + nlLength ) ; cas . addFsToIndexes ( newEmptyLineFS ) ; } else if ( wsLine && ! emptyLine ) { AnnotationFS newWSLineFS = cas . createAnnotation ( wsLineType , offsetTillNow , offsetTillNow + eachLine . length ( ) ) ; cas . addFsToIndexes ( newWSLineFS ) ; } else if ( ! emptyLine ) { AnnotationFS newLineFS = cas . createAnnotation ( lineType , offsetTillNow , offsetTillNow + eachLine . length ( ) ) ; cas . addFsToIndexes ( newLineFS ) ; lastWasEmpty = false ; lastLineEnd = offsetTillNow + eachLine . length ( ) ; } if ( wsLine && ! lastWasEmpty && lastLineEnd != 0 ) { AnnotationFS newParaFS = cas . createAnnotation ( paragraphType , paragraphBegin , lastLineEnd ) ; cas . addFsToIndexes ( newParaFS ) ; } else if ( offsetAfterLine + nlLength == documentText . length ( ) ) { AnnotationFS newParaFS = cas . createAnnotation ( paragraphType , paragraphBegin , offsetAfterLine ) ; cas . addFsToIndexes ( newParaFS ) ; } else if ( offsetAfterLine == documentText . length ( ) ) { AnnotationFS newParaFS = cas . createAnnotation ( paragraphType , paragraphBegin , offsetAfterLine ) ; cas . addFsToIndexes ( newParaFS ) ; } if ( wsLine ) { lastWasEmpty = true ; } offsetTillNow = offsetTillNow + eachLine . length ( ) + nlLength ; } } catch ( IOException e ) { throw new AnalysisEngineProcessException ( e ) ; } }",Smelly
 public static NodeProcessor getMultiGroupByProc ( ) { return new MultiGroupByInferrer ( ) ; },Smelly
 public String name ( ) { return FUNCTION_NAME ; },No
" protected void exec ( ) { Op op = modAlgebra . getOp ( ) ; if ( op == null ) { System . err . println ( ""No query expression to execute"" ) ; throw new TerminationException ( 9 ) ; } Dataset dataset = modDataset . getDataset ( ) ; if ( dataset == null ) dataset = DatasetFactory . createGeneral ( ) ; modTime . startTimer ( ) ; DatasetGraph dsg = dataset . asDatasetGraph ( ) ; if ( printOp || printPlan ) { if ( printOp ) { divider ( ) ; IndentedWriter out = new IndentedWriter ( System . out , true ) ; op . output ( out ) ; out . flush ( ) ; } if ( printPlan ) { QueryIterator qIter = Algebra . exec ( op , dsg ) ; Plan plan = new PlanOp ( op , null , qIter ) ; divider ( ) ; IndentedWriter out = new IndentedWriter ( System . out , false ) ; plan . output ( out ) ; out . flush ( ) ; } } QueryExecUtils . execute ( op , dsg , modResults . getResultsFormat ( ) ) ; long time = modTime . endTimer ( ) ; if ( modTime . timingEnabled ( ) ) System . out . println ( ""Time: "" + modTime . timeStr ( time ) ) ; }",No
" public String getRValue ( ) { if ( ! this . value . isEmpty ( ) ) { return ""\"""" . concat ( this . value ) . concat ( ""\"""" ) ; } return this . envName ; }",No
" public void write ( Config config ) throws IOException { PrintWriter out = null ; if ( config . configName == null || config . configName . isEmpty ( ) ) { throw new RuntimeException ( ""Config Name is null or empty"" ) ; } try { File file = new File ( config . configName + "".html"" ) ; out = new PrintWriter ( new OutputStreamWriter ( new FileOutputStream ( file ) , ""UTF-8"" ) ) ; out . println ( ""<?xml version=\""1.0\"" encoding=\""ISO-8859-1\"" standalone=\""no\"" ?>"" ) ; out . println ( ""<!DOCTYPE html PUBLIC \""-//W3C//DTD XHTML 1.0 Strict//EN\"""" ) ; out . println ( ""    \""http://www.w3.org/TR/xhtml1/DTD/xhtml1-strict.dtd\"">"" ) ; out . println ( ""<html xmlns=\""http://www.w3.org/1999/xhtml\"">"" ) ; out . println ( ""<head>"" ) ; out . println ( ""<meta http-equiv=\""Content-Type\"" content=\""text/html; charset=ISO-8859-1\"" />"" ) ; out . println ( ""<title>"" + config . configName + ""</title>"" ) ; out . println ( ""</head>"" ) ; out . println ( ""<style>"" ) ; out . println ( ""table"" ) ; out . println ( ""{"" ) ; out . println ( ""  background-color: #000;"" ) ; out . println ( ""  border-spacing: 1px;"" ) ; out . println ( ""  margin: 0 auto 0 auto;"" ) ; out . println ( ""}"" ) ; out . println ( ""th"" ) ; out . println ( ""{"" ) ; out . println ( ""  background-color: #fff;"" ) ; out . println ( ""  padding: 5px;"" ) ; out . println ( ""  margin: 1px;"" ) ; out . println ( ""}"" ) ; out . println ( ""td"" ) ; out . println ( ""{"" ) ; out . println ( ""  background-color: #fff;"" ) ; out . println ( ""  padding: 2px;"" ) ; out . println ( ""}"" ) ; out . println ( ""table, th, td {"" ) ; out . println ( ""  border: 1px solid black;"" ) ; out . println ( ""}"" ) ; out . println ( ""tr.tr_private td"" ) ; out . println ( ""{"" ) ; out . println ( ""  background-color: #FF4500;"" ) ; out . println ( ""  padding: 2px;"" ) ; out . println ( ""}"" ) ; out . println ( ""tr.tr_evolve_unstable td"" ) ; out . println ( ""{"" ) ; out . println ( ""  background-color: #FFFFE0;"" ) ; out . println ( ""  padding: 2px;"" ) ; out . println ( ""}"" ) ; out . println ( ""th.th_private"" ) ; out . println ( ""{"" ) ; out . println ( ""  background-color: #FF4500;"" ) ; out . println ( ""}"" ) ; out . println ( ""th.th_evolve_unstable"" ) ; out . println ( ""{"" ) ; out . println ( ""  background-color: #FFFFE0;"" ) ; out . println ( ""}"" ) ; out . println ( ""</style>"" ) ; out . println ( ""<body>"" ) ; out . println ( ""<div id=\""wrapper\"">"" ) ; out . println ( ""<div id=\""container\"">"" ) ; out . println ( ""<h1>"" + config . configName + ""</h1>"" ) ; out . println ( ""<hr />"" ) ; out . println ( ""<table>"" ) ; out . println ( ""<tr>"" ) ; out . println ( ""<th>"" + ""Property Name"" + ""</th>"" ) ; out . println ( ""<th>"" + ""Default Value"" + ""</th>"" ) ; out . println ( ""<th>"" + ""Description"" + ""</th>"" ) ; out . println ( ""<th>"" + ""Type"" + ""</th>"" ) ; out . println ( ""<th class=\""th_private\"">"" + ""Is Private?"" + ""</th>"" ) ; out . println ( ""<th class=\""th_evolve_unstable\"">"" + ""Is Unstable?"" + ""</th>"" ) ; out . println ( ""<th class=\""th_evolve_unstable\"">"" + ""Is Evolving?"" + ""</th>"" ) ; out . println ( ""</tr>"" ) ; for ( ConfigProperty configProperty : config . configProperties . values ( ) ) { if ( ! isValidConfigProperty ( configProperty ) ) { continue ; } String altClass = """" ; if ( configProperty . isPrivate ) { altClass = ""class=\""tr_private\"""" ; } else if ( configProperty . isEvolving || configProperty . isUnstable ) { altClass = ""class=\""tr_evolve_unstable\"""" ; } out . println ( ""<tr "" + altClass + "">"" ) ; out . println ( ""<td>"" + configProperty . propertyName + ""</td>"" ) ; out . println ( ""<td>"" + configProperty . defaultValue + ""</td>"" ) ; out . println ( ""<td>"" + configProperty . description + ""</td>"" ) ; out . println ( ""<td>"" + configProperty . type + ""</td>"" ) ; out . println ( ""<td class=\"""" + ( configProperty . isPrivate ? ""td_private_true"" : ""td_private_false"" ) + ""\"">"" + configProperty . isPrivate + ""</td>"" ) ; out . println ( ""<td class=\"""" + ( configProperty . isEvolving ? ""td_evolve_true"" : ""td_evolve_false"" ) + ""\"">"" + configProperty . isEvolving + ""</td>"" ) ; out . println ( ""<td class=\"""" + ( configProperty . isUnstable ? ""td_unstable_true"" : ""td_unstable_false"" ) + ""\"">"" + configProperty . isUnstable + ""</td>"" ) ; out . println ( ""</tr>"" ) ; } out . println ( ""</table>"" ) ; out . println ( ""</div>"" ) ; out . println ( ""</div>"" ) ; out . println ( ""</body>"" ) ; out . println ( ""</html>"" ) ; } finally { if ( out != null ) { out . close ( ) ; } } }",Smelly
" public void read ( org . apache . thrift . protocol . TProtocol prot , show_compact_result struct ) throws org . apache . thrift . TException { TTupleProtocol iprot = ( TTupleProtocol ) prot ; BitSet incoming = iprot . readBitSet ( 1 ) ; if ( incoming . get ( 0 ) ) { struct . success = new ShowCompactResponse ( ) ; struct . success . read ( iprot ) ; struct . setSuccessIsSet ( true ) ; } }",Smelly
" public void read ( org . apache . thrift . protocol . TProtocol prot , getChildDataProducts_result struct ) throws org . apache . thrift . TException { TTupleProtocol iprot = ( TTupleProtocol ) prot ; BitSet incoming = iprot . readBitSet ( 5 ) ; if ( incoming . get ( 0 ) ) { { org . apache . thrift . protocol . TList _list283 = new org . apache . thrift . protocol . TList ( org . apache . thrift . protocol . TType . STRUCT , iprot . readI32 ( ) ) ; struct . success = new ArrayList < org . apache . airavata . model . data . replica . DataProductModel > ( _list283 . size ) ; org . apache . airavata . model . data . replica . DataProductModel _elem284 ; for ( int _i285 = 0 ; _i285 < _list283 . size ; ++ _i285 ) { _elem284 = new org . apache . airavata . model . data . replica . DataProductModel ( ) ; _elem284 . read ( iprot ) ; struct . success . add ( _elem284 ) ; } } struct . setSuccessIsSet ( true ) ; } if ( incoming . get ( 1 ) ) { struct . ire = new org . apache . airavata . model . error . InvalidRequestException ( ) ; struct . ire . read ( iprot ) ; struct . setIreIsSet ( true ) ; } if ( incoming . get ( 2 ) ) { struct . ace = new org . apache . airavata . model . error . AiravataClientException ( ) ; struct . ace . read ( iprot ) ; struct . setAceIsSet ( true ) ; } if ( incoming . get ( 3 ) ) { struct . ase = new org . apache . airavata . model . error . AiravataSystemException ( ) ; struct . ase . read ( iprot ) ; struct . setAseIsSet ( true ) ; } if ( incoming . get ( 4 ) ) { struct . ae = new org . apache . airavata . model . error . AuthorizationException ( ) ; struct . ae . read ( iprot ) ; struct . setAeIsSet ( true ) ; } }",Smelly
 void setUpdatedBy ( String updatedBy ) ;,No
" protected void load ( StructInstance instance , int colPos , Object val ) { instance . maps [ colPos ] = ( ImmutableMap ) val ; }",No
 protected String getValue ( StringValue value ) { return value . getValue ( ) ; },No
" void set ( int colIndex , Object value ) ;",No
 private static < S extends org . apache . thrift . scheme . IScheme > S scheme ( org . apache . thrift . protocol . TProtocol proto ) { return ( org . apache . thrift . scheme . StandardScheme . class . equals ( proto . getScheme ( ) ) ? STANDARD_SCHEME_FACTORY : TUPLE_SCHEME_FACTORY ) . getScheme ( ) ; },Smelly
 public void testCountWords ( ) throws Exception { PCollection < String > input = p . apply ( Create . of ( WORDS ) . withCoder ( StringUtf8Coder . of ( ) ) ) ; PCollection < String > output = input . apply ( new CountWords ( ) ) . apply ( MapElements . via ( new FormatAsTextFn ( ) ) ) ; PAssert . that ( output ) . containsInAnyOrder ( COUNTS_ARRAY ) ; p . run ( ) . waitUntilFinish ( ) ; },No
" public void read ( org . apache . thrift . protocol . TProtocol prot , getChildDataProducts_result struct ) throws org . apache . thrift . TException { TTupleProtocol iprot = ( TTupleProtocol ) prot ; BitSet incoming = iprot . readBitSet ( 5 ) ; if ( incoming . get ( 0 ) ) { { org . apache . thrift . protocol . TList _list283 = new org . apache . thrift . protocol . TList ( org . apache . thrift . protocol . TType . STRUCT , iprot . readI32 ( ) ) ; struct . success = new ArrayList < org . apache . airavata . model . data . replica . DataProductModel > ( _list283 . size ) ; org . apache . airavata . model . data . replica . DataProductModel _elem284 ; for ( int _i285 = 0 ; _i285 < _list283 . size ; ++ _i285 ) { _elem284 = new org . apache . airavata . model . data . replica . DataProductModel ( ) ; _elem284 . read ( iprot ) ; struct . success . add ( _elem284 ) ; } } struct . setSuccessIsSet ( true ) ; } if ( incoming . get ( 1 ) ) { struct . ire = new org . apache . airavata . model . error . InvalidRequestException ( ) ; struct . ire . read ( iprot ) ; struct . setIreIsSet ( true ) ; } if ( incoming . get ( 2 ) ) { struct . ace = new org . apache . airavata . model . error . AiravataClientException ( ) ; struct . ace . read ( iprot ) ; struct . setAceIsSet ( true ) ; } if ( incoming . get ( 3 ) ) { struct . ase = new org . apache . airavata . model . error . AiravataSystemException ( ) ; struct . ase . read ( iprot ) ; struct . setAseIsSet ( true ) ; } if ( incoming . get ( 4 ) ) { struct . ae = new org . apache . airavata . model . error . AuthorizationException ( ) ; struct . ae . read ( iprot ) ; struct . setAeIsSet ( true ) ; } }",Smelly
" public void read ( org . apache . thrift . protocol . TProtocol prot , LongColumnStatsData struct ) throws org . apache . thrift . TException { TTupleProtocol iprot = ( TTupleProtocol ) prot ; struct . lowValue = iprot . readI64 ( ) ; struct . setLowValueIsSet ( true ) ; struct . highValue = iprot . readI64 ( ) ; struct . setHighValueIsSet ( true ) ; struct . numNulls = iprot . readI64 ( ) ; struct . setNumNullsIsSet ( true ) ; struct . numDVs = iprot . readI64 ( ) ; struct . setNumDVsIsSet ( true ) ; }",Smelly
 public Message retrieveFromContinuation ( HttpServletRequest request ) { return super . retrieveFromContinuation ( request ) ; },No
 AsyncPathable < AsyncStage < Void > > removingAll ( Watcher . WatcherType watcherType ) ;,No
" public void looseMarshal ( OpenWireFormat wireFormat , Object o , DataOutput dataOut ) throws IOException { LocalTransactionId info = ( LocalTransactionId ) o ; super . looseMarshal ( wireFormat , o , dataOut ) ; looseMarshalLong ( wireFormat , info . getValue ( ) , dataOut ) ; looseMarshalCachedObject ( wireFormat , ( DataStructure ) info . getConnectionId ( ) , dataOut ) ; }",No
" HiveAuthorizer createHiveAuthorizer ( HiveMetastoreClientFactory metastoreClientFactory , HiveConf conf , HiveAuthenticationProvider hiveAuthenticator ) throws HiveAuthzPluginException ;",No
 void setCompany ( Company _company ) ;,No
" public void read ( org . apache . thrift . protocol . TProtocol prot , getChildDataProducts_result struct ) throws org . apache . thrift . TException { TTupleProtocol iprot = ( TTupleProtocol ) prot ; BitSet incoming = iprot . readBitSet ( 5 ) ; if ( incoming . get ( 0 ) ) { { org . apache . thrift . protocol . TList _list283 = new org . apache . thrift . protocol . TList ( org . apache . thrift . protocol . TType . STRUCT , iprot . readI32 ( ) ) ; struct . success = new ArrayList < org . apache . airavata . model . data . replica . DataProductModel > ( _list283 . size ) ; org . apache . airavata . model . data . replica . DataProductModel _elem284 ; for ( int _i285 = 0 ; _i285 < _list283 . size ; ++ _i285 ) { _elem284 = new org . apache . airavata . model . data . replica . DataProductModel ( ) ; _elem284 . read ( iprot ) ; struct . success . add ( _elem284 ) ; } } struct . setSuccessIsSet ( true ) ; } if ( incoming . get ( 1 ) ) { struct . ire = new org . apache . airavata . model . error . InvalidRequestException ( ) ; struct . ire . read ( iprot ) ; struct . setIreIsSet ( true ) ; } if ( incoming . get ( 2 ) ) { struct . ace = new org . apache . airavata . model . error . AiravataClientException ( ) ; struct . ace . read ( iprot ) ; struct . setAceIsSet ( true ) ; } if ( incoming . get ( 3 ) ) { struct . ase = new org . apache . airavata . model . error . AiravataSystemException ( ) ; struct . ase . read ( iprot ) ; struct . setAseIsSet ( true ) ; } if ( incoming . get ( 4 ) ) { struct . ae = new org . apache . airavata . model . error . AuthorizationException ( ) ; struct . ae . read ( iprot ) ; struct . setAeIsSet ( true ) ; } }",Smelly
" private static String jss ( final int n , char c ) { char [ ] cc = new char [ n + 2 ] ; cc [ 0 ] = cc [ n + 1 ] = '""' ; for ( int i = 1 ; i < n + 1 ; i ++ ) { if ( c == 'Z' ) { c = 'a' ; } else if ( c == 'z' ) { c = '0' ; } else if ( c == '9' ) { c = 'A' ; } else { c ++ ; } cc [ i ] = c ; } return new String ( cc ) ; }",Smelly
" protected void readState ( ObjectInputStream in ) throws IOException , ClassNotFoundException { super . readState ( in ) ; this . byteArray = ( byte [ ] ) in . readObject ( ) ; this . byteWrapperArray = ( Byte [ ] ) in . readObject ( ) ; this . charArray = ( char [ ] ) in . readObject ( ) ; this . charWrapperArray = ( Character [ ] ) in . readObject ( ) ; }",No
" public void read ( org . apache . thrift . protocol . TProtocol prot , getChildDataProducts_result struct ) throws org . apache . thrift . TException { TTupleProtocol iprot = ( TTupleProtocol ) prot ; BitSet incoming = iprot . readBitSet ( 5 ) ; if ( incoming . get ( 0 ) ) { { org . apache . thrift . protocol . TList _list283 = new org . apache . thrift . protocol . TList ( org . apache . thrift . protocol . TType . STRUCT , iprot . readI32 ( ) ) ; struct . success = new ArrayList < org . apache . airavata . model . data . replica . DataProductModel > ( _list283 . size ) ; org . apache . airavata . model . data . replica . DataProductModel _elem284 ; for ( int _i285 = 0 ; _i285 < _list283 . size ; ++ _i285 ) { _elem284 = new org . apache . airavata . model . data . replica . DataProductModel ( ) ; _elem284 . read ( iprot ) ; struct . success . add ( _elem284 ) ; } } struct . setSuccessIsSet ( true ) ; } if ( incoming . get ( 1 ) ) { struct . ire = new org . apache . airavata . model . error . InvalidRequestException ( ) ; struct . ire . read ( iprot ) ; struct . setIreIsSet ( true ) ; } if ( incoming . get ( 2 ) ) { struct . ace = new org . apache . airavata . model . error . AiravataClientException ( ) ; struct . ace . read ( iprot ) ; struct . setAceIsSet ( true ) ; } if ( incoming . get ( 3 ) ) { struct . ase = new org . apache . airavata . model . error . AiravataSystemException ( ) ; struct . ase . read ( iprot ) ; struct . setAseIsSet ( true ) ; } if ( incoming . get ( 4 ) ) { struct . ae = new org . apache . airavata . model . error . AuthorizationException ( ) ; struct . ae . read ( iprot ) ; struct . setAeIsSet ( true ) ; } }",Smelly
" public void read ( org . apache . thrift . protocol . TProtocol prot , getChildDataProducts_result struct ) throws org . apache . thrift . TException { TTupleProtocol iprot = ( TTupleProtocol ) prot ; BitSet incoming = iprot . readBitSet ( 5 ) ; if ( incoming . get ( 0 ) ) { { org . apache . thrift . protocol . TList _list283 = new org . apache . thrift . protocol . TList ( org . apache . thrift . protocol . TType . STRUCT , iprot . readI32 ( ) ) ; struct . success = new ArrayList < org . apache . airavata . model . data . replica . DataProductModel > ( _list283 . size ) ; org . apache . airavata . model . data . replica . DataProductModel _elem284 ; for ( int _i285 = 0 ; _i285 < _list283 . size ; ++ _i285 ) { _elem284 = new org . apache . airavata . model . data . replica . DataProductModel ( ) ; _elem284 . read ( iprot ) ; struct . success . add ( _elem284 ) ; } } struct . setSuccessIsSet ( true ) ; } if ( incoming . get ( 1 ) ) { struct . ire = new org . apache . airavata . model . error . InvalidRequestException ( ) ; struct . ire . read ( iprot ) ; struct . setIreIsSet ( true ) ; } if ( incoming . get ( 2 ) ) { struct . ace = new org . apache . airavata . model . error . AiravataClientException ( ) ; struct . ace . read ( iprot ) ; struct . setAceIsSet ( true ) ; } if ( incoming . get ( 3 ) ) { struct . ase = new org . apache . airavata . model . error . AiravataSystemException ( ) ; struct . ase . read ( iprot ) ; struct . setAseIsSet ( true ) ; } if ( incoming . get ( 4 ) ) { struct . ae = new org . apache . airavata . model . error . AuthorizationException ( ) ; struct . ae . read ( iprot ) ; struct . setAeIsSet ( true ) ; } }",Smelly
" public void run ( ) { while ( true ) { if ( ! keepRunning ) { return ; } try { AllocateResponse response ; if ( savedException != null ) { LOG . error ( ""Stopping callback due to: "" , savedException ) ; handler . onError ( savedException ) ; return ; } try { response = responseQueue . take ( ) ; } catch ( InterruptedException ex ) { LOG . info ( ""Interrupted while waiting for queue"" , ex ) ; continue ; } if ( response . getAMCommand ( ) != null ) { switch ( response . getAMCommand ( ) ) { case AM_RESYNC : case AM_SHUTDOWN : handler . onShutdownRequest ( ) ; LOG . info ( ""Shutdown requested. Stopping callback."" ) ; return ; default : String msg = ""Unhandled value of RM AMCommand: "" + response . getAMCommand ( ) ; LOG . error ( msg ) ; throw new YarnRuntimeException ( msg ) ; } } List < NodeReport > updatedNodes = response . getUpdatedNodes ( ) ; if ( ! updatedNodes . isEmpty ( ) ) { handler . onNodesUpdated ( updatedNodes ) ; } List < ContainerStatus > completed = response . getCompletedContainersStatuses ( ) ; if ( ! completed . isEmpty ( ) ) { handler . onContainersCompleted ( completed ) ; } List < Container > allocated = response . getAllocatedContainers ( ) ; if ( ! allocated . isEmpty ( ) ) { handler . onContainersAllocated ( allocated ) ; } progress = handler . getProgress ( ) ; } catch ( Throwable ex ) { handler . onError ( ex ) ; throw new YarnRuntimeException ( ex ) ; } } }",No
" public void testGuidTypeNode ( ) throws IOException { String guid = ""a1b2c3d4-e5f6-a7b8-c9da-ebf001121314"" ; assertEquals ( guid , new GuidTypeNode ( testBinaryReaderBuilder . putGuid ( guid ) . build ( ) , chunkHeader , parent , - 1 ) . getValue ( ) ) ; }",No
" public int compare ( ArtifactMetadata o1 , ArtifactMetadata o2 ) { int result = new DefaultArtifactVersion ( o2 . getVersion ( ) ) . compareTo ( new DefaultArtifactVersion ( o1 . getVersion ( ) ) ) ; return result != 0 ? result : o1 . getId ( ) . compareTo ( o2 . getId ( ) ) ; }",No
" public < TKey > RecordWriter < TKey , TripleWritable > createTripleWriter ( Writer writer , Configuration config ) { return new NTriplesWriter < TKey > ( writer ) ; }",No
 public void dispatch ( final InteractionEvent interactionEvent ) { dispatchTypeSafe ( ( T ) interactionEvent ) ; },No
" public void read ( org . apache . thrift . protocol . TProtocol prot , getChildDataProducts_result struct ) throws org . apache . thrift . TException { TTupleProtocol iprot = ( TTupleProtocol ) prot ; BitSet incoming = iprot . readBitSet ( 5 ) ; if ( incoming . get ( 0 ) ) { { org . apache . thrift . protocol . TList _list283 = new org . apache . thrift . protocol . TList ( org . apache . thrift . protocol . TType . STRUCT , iprot . readI32 ( ) ) ; struct . success = new ArrayList < org . apache . airavata . model . data . replica . DataProductModel > ( _list283 . size ) ; org . apache . airavata . model . data . replica . DataProductModel _elem284 ; for ( int _i285 = 0 ; _i285 < _list283 . size ; ++ _i285 ) { _elem284 = new org . apache . airavata . model . data . replica . DataProductModel ( ) ; _elem284 . read ( iprot ) ; struct . success . add ( _elem284 ) ; } } struct . setSuccessIsSet ( true ) ; } if ( incoming . get ( 1 ) ) { struct . ire = new org . apache . airavata . model . error . InvalidRequestException ( ) ; struct . ire . read ( iprot ) ; struct . setIreIsSet ( true ) ; } if ( incoming . get ( 2 ) ) { struct . ace = new org . apache . airavata . model . error . AiravataClientException ( ) ; struct . ace . read ( iprot ) ; struct . setAceIsSet ( true ) ; } if ( incoming . get ( 3 ) ) { struct . ase = new org . apache . airavata . model . error . AiravataSystemException ( ) ; struct . ase . read ( iprot ) ; struct . setAseIsSet ( true ) ; } if ( incoming . get ( 4 ) ) { struct . ae = new org . apache . airavata . model . error . AuthorizationException ( ) ; struct . ae . read ( iprot ) ; struct . setAeIsSet ( true ) ; } }",Smelly
" public Object execute ( ) throws Exception { if ( level != null ) { int sbsl = bundleService . getSystemBundleThreshold ( ) ; if ( level < sbsl ) { if ( ! JaasHelper . currentUserHasRole ( BundleService . SYSTEM_BUNDLES_ROLE ) ) { throw new IllegalArgumentException ( ""Insufficient privileges"" ) ; } } } boolean r3warned = false ; List < Exception > exceptions = new ArrayList < > ( ) ; List < Bundle > bundles = new ArrayList < > ( ) ; for ( URI url : urls ) { try { Bundle bundle = bundleContext . installBundle ( url . toString ( ) , null ) ; if ( ! ""2"" . equals ( bundle . getHeaders ( ) . get ( Constants . BUNDLE_MANIFESTVERSION ) ) ) { if ( allowR3 ) { if ( ! r3warned ) { System . err . println ( ""WARNING: use of OSGi r3 bundles is discouraged"" ) ; r3warned = true ; } } else { bundle . uninstall ( ) ; throw new BundleException ( ""OSGi R3 bundle not supported"" ) ; } } bundles . add ( bundle ) ; } catch ( Exception e ) { exceptions . add ( new Exception ( ""Unable to install bundle "" + url + "": "" + e . toString ( ) , e ) ) ; } } if ( level != null ) { for ( Bundle bundle : bundles ) { try { bundle . adapt ( BundleStartLevel . class ) . setStartLevel ( level ) ; } catch ( Exception e ) { exceptions . add ( new Exception ( ""Unable to set bundle start level "" + bundle . getLocation ( ) + "": "" + e . toString ( ) , e ) ) ; } } } if ( start ) { for ( Bundle bundle : bundles ) { try { bundle . start ( ) ; } catch ( Exception e ) { exceptions . add ( new Exception ( ""Unable to start bundle "" + bundle . getLocation ( ) + "": "" + e . toString ( ) , e ) ) ; } } } if ( bundles . size ( ) == 1 ) { System . out . println ( ""Bundle ID: "" + bundles . get ( 0 ) . getBundleId ( ) ) ; } else { String msg = bundles . stream ( ) . map ( b -> Long . toString ( b . getBundleId ( ) ) ) . collect ( Collectors . joining ( "", "" , ""Bundle IDs: "" , """" ) ) ; System . out . println ( msg ) ; } MultiException . throwIf ( ""Error installing bundles"" , exceptions ) ; return null ; }",Smelly
 boolean isSelectedVersionKnown ( ) throws OverConstrainedVersionException ;,No
" private void printUsage ( ) { System . err . println ( ""Usage:\n"" + ""--------------------------\n"" + MobRefReporter . class . getName ( ) + "" output-dir tableName familyName"" ) ; System . err . println ( "" output-dir       Where to write output report."" ) ; System . err . println ( "" tableName        The table name"" ) ; System . err . println ( "" familyName       The column family name"" ) ; }",Smelly
" private void doMaxMessageSize ( String path , long size , boolean expectOpen ) throws Exception { Tomcat tomcat = getTomcatInstance ( ) ; Context ctx = tomcat . addContext ( """" , System . getProperty ( ""java.io.tmpdir"" ) ) ; ctx . addApplicationListener ( TesterEchoServer . Config . class . getName ( ) ) ; Tomcat . addServlet ( ctx , ""default"" , new DefaultServlet ( ) ) ; ctx . addServletMapping ( ""/"" , ""default"" ) ; tomcat . start ( ) ; WebSocketContainer wsContainer = ContainerProvider . getWebSocketContainer ( ) ; Session s = connectToEchoServer ( wsContainer , EndpointA . class , path ) ; StringBuilder msg = new StringBuilder ( ) ; for ( long i = 0 ; i < size ; i ++ ) { msg . append ( 'x' ) ; } s . getBasicRemote ( ) . sendText ( msg . toString ( ) ) ; boolean open = s . isOpen ( ) ; int count = 0 ; while ( open != expectOpen && count < 50 ) { Thread . sleep ( 100 ) ; count ++ ; open = s . isOpen ( ) ; } Assert . assertEquals ( Boolean . valueOf ( expectOpen ) , Boolean . valueOf ( s . isOpen ( ) ) ) ; }",No
 public Object getContainerResponse ( ) { return originalResponse . getContainerResponse ( ) ; },No
 public void initialize ( ) { },No
 public Integer getOid ( ) { return oid ; },No
 public String getName ( ) { return groupName ; },No
" public void runAction ( Map < String , Object > context ) { Object valueObject = valueNameAcsr . get ( context ) ; if ( valueObject == null ) { Debug . logVerbose ( ""Value not found with name: "" + valueNameAcsr + "", not getting related..."" , module ) ; return ; } if ( ! ( valueObject instanceof GenericValue ) ) { String errMsg = ""Env variable for value-name "" + valueNameAcsr . toString ( ) + "" is not a GenericValue object; for the relation-name: "" + relationName + ""]"" ; Debug . logError ( errMsg , module ) ; throw new IllegalArgumentException ( errMsg ) ; } GenericValue value = ( GenericValue ) valueObject ; List < String > orderByNames = null ; if ( ! orderByListAcsr . isEmpty ( ) ) { orderByNames = orderByListAcsr . get ( context ) ; } Map < String , Object > constraintMap = null ; if ( ! mapAcsr . isEmpty ( ) ) { constraintMap = mapAcsr . get ( context ) ; } try { listNameAcsr . put ( context , value . getRelated ( relationName , constraintMap , orderByNames , useCache ) ) ; } catch ( GenericEntityException e ) { String errMsg = ""Problem getting related from entity with name "" + value . getEntityName ( ) + "" for the relation-name: "" + relationName + "": "" + e . getMessage ( ) ; Debug . logError ( e , errMsg , module ) ; throw new IllegalArgumentException ( errMsg ) ; } }",Smelly
 public void setVersion ( int version ) { this . version = version ; },No
" public void read ( org . apache . thrift . protocol . TProtocol prot , getFollowing_result struct ) throws org . apache . thrift . TException { TTupleProtocol iprot = ( TTupleProtocol ) prot ; BitSet incoming = iprot . readBitSet ( 1 ) ; if ( incoming . get ( 0 ) ) { struct . success = new Key ( ) ; struct . success . read ( iprot ) ; struct . setSuccessIsSet ( true ) ; } }",Smelly
 public boolean select ( Metadata metadata ) { String v = metadata . get ( TikaCoreProperties . EMBEDDED_RESOURCE_TYPE ) ; if ( v != null && v . equals ( TikaCoreProperties . EmbeddedResourceType . INLINE . toString ( ) ) ) { return false ; } return true ; },No
" public void run ( ) { try { IThreadContext threadContext = ThreadContextFactory . make ( ) ; IRepositoryConnectionManager mgr = RepositoryConnectionManagerFactory . make ( threadContext ) ; IJobManager jobManager = JobManagerFactory . make ( threadContext ) ; Logging . threads . debug ( ""Set priority thread coming up"" ) ; HashMap jobDescriptionMap = new HashMap ( ) ; HashMap connectionMap = new HashMap ( ) ; while ( true ) { try { if ( Thread . currentThread ( ) . isInterrupted ( ) ) throw new ManifoldCFException ( ""Interrupted"" , ManifoldCFException . INTERRUPTED ) ; Logging . threads . debug ( ""Set priority thread woke up"" ) ; long currentTime = System . currentTimeMillis ( ) ; jobDescriptionMap . clear ( ) ; connectionMap . clear ( ) ; int processedCount = 0 ; while ( true ) { if ( Thread . currentThread ( ) . isInterrupted ( ) ) throw new ManifoldCFException ( ""Interrupted"" , ManifoldCFException . INTERRUPTED ) ; if ( processedCount >= cycleCount ) { Logging . threads . debug ( ""Done reprioritizing because exceeded cycle count"" ) ; break ; } DocumentDescription desc = blockingDocuments . getBlockingDocument ( ) ; if ( desc != null ) { ManifoldCF . writeDocumentPriorities ( threadContext , mgr , jobManager , new DocumentDescription [ ] { desc } , connectionMap , jobDescriptionMap , queueTracker , currentTime ) ; processedCount ++ ; continue ; } Logging . threads . debug ( ""Done reprioritizing because no more documents to reprioritize"" ) ; ManifoldCF . sleep ( 30000L ) ; break ; } } catch ( ManifoldCFException e ) { if ( e . getErrorCode ( ) == ManifoldCFException . INTERRUPTED ) break ; if ( e . getErrorCode ( ) == ManifoldCFException . DATABASE_CONNECTION_ERROR ) { Logging . threads . error ( ""Set priority thread aborting and restarting due to database connection reset: "" + e . getMessage ( ) , e ) ; try { ManifoldCF . sleep ( 10000L ) ; } catch ( InterruptedException se ) { break ; } continue ; } Logging . threads . error ( ""Exception tossed: "" + e . getMessage ( ) , e ) ; if ( e . getErrorCode ( ) == ManifoldCFException . SETUP_ERROR ) { System . exit ( 1 ) ; } } catch ( InterruptedException e ) { break ; } catch ( OutOfMemoryError e ) { System . err . println ( ""agents process ran out of memory - shutting down"" ) ; e . printStackTrace ( System . err ) ; System . exit ( - 200 ) ; } catch ( Throwable e ) { Logging . threads . fatal ( ""Error tossed: "" + e . getMessage ( ) , e ) ; } } } catch ( Throwable e ) { System . err . println ( ""agents process could not start - shutting down"" ) ; Logging . threads . fatal ( ""SetPriorityThread initialization error tossed: "" + e . getMessage ( ) , e ) ; System . exit ( - 300 ) ; } }",Smelly
 private PrincipalConfiguration getPrincipalConfiguration ( ) { return new PrincipalConfigurationImpl ( this ) ; },No
" protected String getPassword ( ServletRequest request ) { return WebUtils . getCleanParam ( request , getPasswordParam ( ) ) ; }",No
 public String [ ] getSupportedMimeTypes ( ) { return MIMES ; },No
" public void looseMarshal ( OpenWireFormat wireFormat , Object o , DataOutput dataOut ) throws IOException { LocalTransactionId info = ( LocalTransactionId ) o ; super . looseMarshal ( wireFormat , o , dataOut ) ; looseMarshalLong ( wireFormat , info . getValue ( ) , dataOut ) ; looseMarshalCachedObject ( wireFormat , ( DataStructure ) info . getConnectionId ( ) , dataOut ) ; }",No
 private SecurityContext createSecurityContext ( final Principal p ) { return new SecurityContext ( ) { public Principal getUserPrincipal ( ) { return p ; } public boolean isUserInRole ( String role ) { return false ; } } ; },Smelly
 public void setComponentState ( ComponentStateDTO componentState ) { this . componentState = componentState ; },No
" public void read ( org . apache . thrift . protocol . TProtocol prot , getFollowing_result struct ) throws org . apache . thrift . TException { TTupleProtocol iprot = ( TTupleProtocol ) prot ; BitSet incoming = iprot . readBitSet ( 1 ) ; if ( incoming . get ( 0 ) ) { struct . success = new Key ( ) ; struct . success . read ( iprot ) ; struct . setSuccessIsSet ( true ) ; } }",Smelly
 public Class coerceType ( final Class clazz ) { final Class type ; if ( ! ReferenceVertex . class . isAssignableFrom ( clazz ) && ! DetachedVertex . class . isAssignableFrom ( clazz ) && Vertex . class . isAssignableFrom ( clazz ) ) type = Vertex . class ; else if ( ! ReferenceEdge . class . isAssignableFrom ( clazz ) && ! DetachedEdge . class . isAssignableFrom ( clazz ) && Edge . class . isAssignableFrom ( clazz ) ) type = Edge . class ; else if ( ! ReferenceVertexProperty . class . isAssignableFrom ( clazz ) && ! DetachedVertexProperty . class . isAssignableFrom ( clazz ) && VertexProperty . class . isAssignableFrom ( clazz ) ) type = VertexProperty . class ; else if ( ! ReferenceProperty . class . isAssignableFrom ( clazz ) && ! DetachedProperty . class . isAssignableFrom ( clazz ) && ! DetachedVertexProperty . class . isAssignableFrom ( clazz ) && ! ReferenceVertexProperty . class . isAssignableFrom ( clazz ) && Property . class . isAssignableFrom ( clazz ) ) type = Property . class ; else if ( ! ReferencePath . class . isAssignableFrom ( clazz ) && ! DetachedPath . class . isAssignableFrom ( clazz ) && Path . class . isAssignableFrom ( clazz ) ) type = Path . class ; else if ( Lambda . class . isAssignableFrom ( clazz ) ) type = Lambda . class ; else if ( ByteBuffer . class . isAssignableFrom ( clazz ) ) type = ByteBuffer . class ; else if ( Class . class . isAssignableFrom ( clazz ) ) type = Class . class ; else if ( InetAddress . class . isAssignableFrom ( clazz ) ) type = InetAddress . class ; else if ( ConnectiveP . class . isAssignableFrom ( clazz ) ) type = P . class ; else if ( Metrics . class . isAssignableFrom ( clazz ) ) type = Metrics . class ; else if ( TraversalMetrics . class . isAssignableFrom ( clazz ) ) type = TraversalMetrics . class ; else type = clazz ; return type ; },Smelly
" public void read ( org . apache . thrift . protocol . TProtocol prot , getChildDataProducts_result struct ) throws org . apache . thrift . TException { TTupleProtocol iprot = ( TTupleProtocol ) prot ; BitSet incoming = iprot . readBitSet ( 5 ) ; if ( incoming . get ( 0 ) ) { { org . apache . thrift . protocol . TList _list283 = new org . apache . thrift . protocol . TList ( org . apache . thrift . protocol . TType . STRUCT , iprot . readI32 ( ) ) ; struct . success = new ArrayList < org . apache . airavata . model . data . replica . DataProductModel > ( _list283 . size ) ; org . apache . airavata . model . data . replica . DataProductModel _elem284 ; for ( int _i285 = 0 ; _i285 < _list283 . size ; ++ _i285 ) { _elem284 = new org . apache . airavata . model . data . replica . DataProductModel ( ) ; _elem284 . read ( iprot ) ; struct . success . add ( _elem284 ) ; } } struct . setSuccessIsSet ( true ) ; } if ( incoming . get ( 1 ) ) { struct . ire = new org . apache . airavata . model . error . InvalidRequestException ( ) ; struct . ire . read ( iprot ) ; struct . setIreIsSet ( true ) ; } if ( incoming . get ( 2 ) ) { struct . ace = new org . apache . airavata . model . error . AiravataClientException ( ) ; struct . ace . read ( iprot ) ; struct . setAceIsSet ( true ) ; } if ( incoming . get ( 3 ) ) { struct . ase = new org . apache . airavata . model . error . AiravataSystemException ( ) ; struct . ase . read ( iprot ) ; struct . setAseIsSet ( true ) ; } if ( incoming . get ( 4 ) ) { struct . ae = new org . apache . airavata . model . error . AuthorizationException ( ) ; struct . ae . read ( iprot ) ; struct . setAeIsSet ( true ) ; } }",Smelly
 private static < S extends org . apache . thrift . scheme . IScheme > S scheme ( org . apache . thrift . protocol . TProtocol proto ) { return ( org . apache . thrift . scheme . StandardScheme . class . equals ( proto . getScheme ( ) ) ? STANDARD_SCHEME_FACTORY : TUPLE_SCHEME_FACTORY ) . getScheme ( ) ; },No
" public void read ( org . apache . thrift . protocol . TProtocol prot , terminateExperiment_result struct ) throws org . apache . thrift . TException { TTupleProtocol iprot = ( TTupleProtocol ) prot ; BitSet incoming = iprot . readBitSet ( 1 ) ; if ( incoming . get ( 0 ) ) { struct . success = iprot . readBool ( ) ; struct . setSuccessIsSet ( true ) ; } }",Smelly
" public void read ( org . apache . thrift . protocol . TProtocol prot , getChildDataProducts_result struct ) throws org . apache . thrift . TException { TTupleProtocol iprot = ( TTupleProtocol ) prot ; BitSet incoming = iprot . readBitSet ( 5 ) ; if ( incoming . get ( 0 ) ) { { org . apache . thrift . protocol . TList _list283 = new org . apache . thrift . protocol . TList ( org . apache . thrift . protocol . TType . STRUCT , iprot . readI32 ( ) ) ; struct . success = new ArrayList < org . apache . airavata . model . data . replica . DataProductModel > ( _list283 . size ) ; org . apache . airavata . model . data . replica . DataProductModel _elem284 ; for ( int _i285 = 0 ; _i285 < _list283 . size ; ++ _i285 ) { _elem284 = new org . apache . airavata . model . data . replica . DataProductModel ( ) ; _elem284 . read ( iprot ) ; struct . success . add ( _elem284 ) ; } } struct . setSuccessIsSet ( true ) ; } if ( incoming . get ( 1 ) ) { struct . ire = new org . apache . airavata . model . error . InvalidRequestException ( ) ; struct . ire . read ( iprot ) ; struct . setIreIsSet ( true ) ; } if ( incoming . get ( 2 ) ) { struct . ace = new org . apache . airavata . model . error . AiravataClientException ( ) ; struct . ace . read ( iprot ) ; struct . setAceIsSet ( true ) ; } if ( incoming . get ( 3 ) ) { struct . ase = new org . apache . airavata . model . error . AiravataSystemException ( ) ; struct . ase . read ( iprot ) ; struct . setAseIsSet ( true ) ; } if ( incoming . get ( 4 ) ) { struct . ae = new org . apache . airavata . model . error . AuthorizationException ( ) ; struct . ae . read ( iprot ) ; struct . setAeIsSet ( true ) ; } }",Smelly
 private static < S extends org . apache . thrift . scheme . IScheme > S scheme ( org . apache . thrift . protocol . TProtocol proto ) { return ( org . apache . thrift . scheme . StandardScheme . class . equals ( proto . getScheme ( ) ) ? STANDARD_SCHEME_FACTORY : TUPLE_SCHEME_FACTORY ) . getScheme ( ) ; },Smelly
" public String getMessageBusTopicName ( String dbName , String tableName ) throws HCatException { try { return hmsClient . getTable ( dbName , tableName ) . getParameters ( ) . get ( HCatConstants . HCAT_MSGBUS_TOPIC_NAME ) ; } catch ( MetaException e ) { throw new HCatException ( ""MetaException while retrieving JMS Topic name."" , e ) ; } catch ( NoSuchObjectException e ) { throw new HCatException ( ""Could not find DB:"" + dbName + "" or Table:"" + tableName , e ) ; } catch ( TException e ) { throw new ConnectionFailureException ( ""TException while retrieving JMS Topic name."" , e ) ; } }",No
" public static void main ( String [ ] argv ) throws Exception { int res = ToolRunner . run ( new GetGroupsForTesting ( new YarnConfiguration ( ) ) , argv ) ; System . exit ( res ) ; }",No
" public Object execute ( ) throws Exception { File [ ] wrapperPaths = wrapperService . install ( name , displayName , description , startType , envs , includes ) ; String os = System . getProperty ( ""os.name"" , ""Unknown"" ) ; File wrapperConf = wrapperPaths [ 0 ] ; File serviceFile = wrapperPaths [ 1 ] ; File systemdFile = wrapperPaths [ 2 ] ; System . out . println ( """" ) ; System . out . println ( ""Setup complete.  You may wish to tweak the JVM properties in the wrapper configuration file:"" ) ; System . out . println ( ""\t"" + wrapperConf . getPath ( ) ) ; System . out . println ( ""before installing and starting the service."" ) ; System . out . println ( """" ) ; if ( os . startsWith ( ""Win"" ) ) { System . out . println ( """" ) ; System . out . println ( INTENSITY_BOLD + ""MS Windows system detected:"" + INTENSITY_NORMAL ) ; System . out . println ( ""To install the service, run: "" ) ; System . out . println ( ""  C:> "" + serviceFile . getPath ( ) + "" install"" ) ; System . out . println ( """" ) ; System . out . println ( ""Once installed, to start the service run: "" ) ; System . out . println ( ""  C:> net start \"""" + name + ""\"""" ) ; System . out . println ( """" ) ; System . out . println ( ""Once running, to stop the service run: "" ) ; System . out . println ( ""  C:> net stop \"""" + name + ""\"""" ) ; System . out . println ( """" ) ; System . out . println ( ""Once stopped, to remove the installed the service run: "" ) ; System . out . println ( ""  C:> "" + serviceFile . getPath ( ) + "" remove"" ) ; System . out . println ( """" ) ; } else if ( os . startsWith ( ""Mac OS X"" ) ) { System . out . println ( """" ) ; System . out . println ( INTENSITY_BOLD + ""Mac OS X system detected:"" + INTENSITY_NORMAL ) ; System . out . println ( ""to add bin/org.apache.karaf.KARAF as user service move this file into ~/Library/LaunchAgents/"" ) ; System . out . println ( ""> mv bin/org.apache.karaf.KARAF.plist ~/Library/LaunchAgents/"" ) ; System . out . println ( """" ) ; System . out . println ( ""to add org.apache.karaf.KARAF as system service move this into /Library/LaunchDaemons"" ) ; System . out . println ( ""> sudo mv bin/org.apache.karaf.KARAF.plist /Library/LaunchDaemons/"" ) ; System . out . println ( ""change owner and rights"" ) ; System . out . println ( ""> sudo chown root:wheel /Library/LaunchDaemons/org.apache.karaf.KARAF.plist"" ) ; System . out . println ( ""> sudo chmod u=rw,g=r,o=r /Library/LaunchDaemons/org.apache.karaf.KARAF.plist"" ) ; System . out . println ( """" ) ; System . out . println ( ""test your service"" ) ; System . out . println ( ""> launchctl load ~/Library/LaunchAgents/org.apache.karaf.KARAF.plist"" ) ; System . out . println ( ""> launchctl start org.apache.karaf.KARAF"" ) ; System . out . println ( ""> launchctl stop org.apache.karaf.KARAF"" ) ; System . out . println ( """" ) ; System . out . println ( ""after restart your session or system"" ) ; System . out . println ( ""you can use launchctl command to start and stop your service"" ) ; System . out . println ( """" ) ; System . out . println ( ""for removing the service call"" ) ; System . out . println ( ""> launchctl remove org.apache.karaf.KARAF"" ) ; System . out . println ( """" ) ; } else if ( os . startsWith ( ""Linux"" ) ) { File debianVersion = new File ( ""/etc/debian_version"" ) ; File redhatRelease = new File ( ""/etc/redhat-release"" ) ; if ( redhatRelease . exists ( ) ) { System . out . println ( """" ) ; System . out . println ( INTENSITY_BOLD + ""RedHat/Fedora/CentOS Linux system detected (SystemV):"" + INTENSITY_NORMAL ) ; System . out . println ( ""  To install the service:"" ) ; System . out . println ( ""    $ ln -s "" + serviceFile . getPath ( ) + "" /etc/init.d/"" ) ; System . out . println ( ""    $ chkconfig "" + serviceFile . getName ( ) + "" --add"" ) ; System . out . println ( """" ) ; System . out . println ( ""  To start the service when the machine is rebooted:"" ) ; System . out . println ( ""    $ chkconfig "" + serviceFile . getName ( ) + "" on"" ) ; System . out . println ( """" ) ; System . out . println ( ""  To disable starting the service when the machine is rebooted:"" ) ; System . out . println ( ""    $ chkconfig "" + serviceFile . getName ( ) + "" off"" ) ; System . out . println ( """" ) ; System . out . println ( ""  To start the service:"" ) ; System . out . println ( ""    $ service "" + serviceFile . getName ( ) + "" start"" ) ; System . out . println ( """" ) ; System . out . println ( ""  To stop the service:"" ) ; System . out . println ( ""    $ service "" + serviceFile . getName ( ) + "" stop"" ) ; System . out . println ( """" ) ; System . out . println ( ""  To uninstall the service :"" ) ; System . out . println ( ""    $ chkconfig "" + serviceFile . getName ( ) + "" --del"" ) ; System . out . println ( ""    $ rm /etc/init.d/"" + serviceFile . getName ( ) ) ; } else if ( debianVersion . exists ( ) ) { System . out . println ( """" ) ; System . out . println ( INTENSITY_BOLD + ""Ubuntu/Debian Linux system detected (SystemV):"" + INTENSITY_NORMAL ) ; System . out . println ( ""  To install the service:"" ) ; System . out . println ( ""    $ ln -s "" + serviceFile . getPath ( ) + "" /etc/init.d/"" ) ; System . out . println ( """" ) ; System . out . println ( ""  To start the service when the machine is rebooted:"" ) ; System . out . println ( ""    $ update-rc.d "" + serviceFile . getName ( ) + "" defaults"" ) ; System . out . println ( """" ) ; System . out . println ( ""  To disable starting the service when the machine is rebooted:"" ) ; System . out . println ( ""    $ update-rc.d -f "" + serviceFile . getName ( ) + "" remove"" ) ; System . out . println ( """" ) ; System . out . println ( ""  To start the service:"" ) ; System . out . println ( ""    $ /etc/init.d/"" + serviceFile . getName ( ) + "" start"" ) ; System . out . println ( """" ) ; System . out . println ( ""  To stop the service:"" ) ; System . out . println ( ""    $ /etc/init.d/"" + serviceFile . getName ( ) + "" stop"" ) ; System . out . println ( """" ) ; System . out . println ( ""  To uninstall the service :"" ) ; System . out . println ( ""    $ rm /etc/init.d/"" + serviceFile . getName ( ) ) ; } else { System . out . println ( """" ) ; System . out . println ( INTENSITY_BOLD + ""On Redhat/Fedora/CentOS Systems (SystemV):"" + INTENSITY_NORMAL ) ; System . out . println ( ""  To install the service:"" ) ; System . out . println ( ""    $ ln -s "" + serviceFile . getPath ( ) + "" /etc/init.d/"" ) ; System . out . println ( ""    $ chkconfig "" + serviceFile . getName ( ) + "" --add"" ) ; System . out . println ( """" ) ; System . out . println ( ""  To start the service when the machine is rebooted:"" ) ; System . out . println ( ""    $ chkconfig "" + serviceFile . getName ( ) + "" on"" ) ; System . out . println ( """" ) ; System . out . println ( ""  To disable starting the service when the machine is rebooted:"" ) ; System . out . println ( ""    $ chkconfig "" + serviceFile . getName ( ) + "" off"" ) ; System . out . println ( """" ) ; System . out . println ( ""  To start the service:"" ) ; System . out . println ( ""    $ service "" + serviceFile . getName ( ) + "" start"" ) ; System . out . println ( """" ) ; System . out . println ( ""  To stop the service:"" ) ; System . out . println ( ""    $ service "" + serviceFile . getName ( ) + "" stop"" ) ; System . out . println ( """" ) ; System . out . println ( ""  To uninstall the service :"" ) ; System . out . println ( ""    $ chkconfig "" + serviceFile . getName ( ) + "" --del"" ) ; System . out . println ( ""    $ rm /etc/init.d/"" + serviceFile . getName ( ) ) ; System . out . println ( """" ) ; System . out . println ( INTENSITY_BOLD + ""On Ubuntu/Debian Systems (SystemV):"" + INTENSITY_NORMAL ) ; System . out . println ( ""  To install the service:"" ) ; System . out . println ( ""    $ ln -s "" + serviceFile . getPath ( ) + "" /etc/init.d/"" ) ; System . out . println ( """" ) ; System . out . println ( ""  To start the service when the machine is rebooted:"" ) ; System . out . println ( ""    $ update-rc.d "" + serviceFile . getName ( ) + "" defaults"" ) ; System . out . println ( """" ) ; System . out . println ( ""  To disable starting the service when the machine is rebooted:"" ) ; System . out . println ( ""    $ update-rc.d -f "" + serviceFile . getName ( ) + "" remove"" ) ; System . out . println ( """" ) ; System . out . println ( ""  To start the service:"" ) ; System . out . println ( ""    $ /etc/init.d/"" + serviceFile . getName ( ) + "" start"" ) ; System . out . println ( """" ) ; System . out . println ( ""  To stop the service:"" ) ; System . out . println ( ""    $ /etc/init.d/"" + serviceFile . getName ( ) + "" stop"" ) ; System . out . println ( """" ) ; System . out . println ( ""  To uninstall the service :"" ) ; System . out . println ( ""    $ rm /etc/init.d/"" + serviceFile . getName ( ) ) ; } if ( systemdFile != null ) { System . out . println ( """" ) ; System . out . println ( INTENSITY_BOLD + ""For systemd compliant Linux: "" + INTENSITY_NORMAL ) ; System . out . println ( ""  To install the service (and enable at system boot):"" ) ; System . out . println ( ""   $ systemctl enable "" + systemdFile . getPath ( ) ) ; System . out . println ( """" ) ; System . out . println ( ""  To start the service:"" ) ; System . out . println ( ""   $ systemctl start "" + name ) ; System . out . println ( """" ) ; System . out . println ( ""  To stop the service:"" ) ; System . out . println ( ""   $ systemctl stop "" + name ) ; System . out . println ( """" ) ; System . out . println ( ""  To check the current service status:"" ) ; System . out . println ( ""   $ systemctl status "" + name ) ; System . out . println ( """" ) ; System . out . println ( ""  To see service activity journal:"" ) ; System . out . println ( ""   $ journalctl -u "" + name ) ; System . out . println ( """" ) ; System . out . println ( ""  To uninstall the service (and disable at system boot):"" ) ; System . out . println ( ""   $ systemctl disable "" + name ) ; } } else if ( os . startsWith ( ""Solaris"" ) || os . startsWith ( ""SunOS"" ) ) { System . out . println ( """" ) ; System . out . println ( INTENSITY_BOLD + ""Solaris/SunOS system detected :"" + INTENSITY_NORMAL ) ; System . out . println ( ""  To install the service (and enable at system boot):"" ) ; System . out . println ( ""    $ ln -s "" + serviceFile . getPath ( ) + "" /etc/init.d/"" ) ; System . out . println ( """" ) ; System . out . println ( ""  To start the service when the machine is rebooted for all multi-user run levels"" ) ; System . out . println ( ""  and stopped for the halt, single-user and reboot runlevels:"" ) ; System . out . println ( ""    $ ln -s /etc/init.d/"" + serviceFile . getName ( ) + "" /etc/rc0.d/K20"" + serviceFile . getName ( ) ) ; System . out . println ( ""    $ ln -s /etc/init.d/"" + serviceFile . getName ( ) + "" /etc/rc1.d/K20"" + serviceFile . getName ( ) ) ; System . out . println ( ""    $ ln -s /etc/init.d/"" + serviceFile . getName ( ) + "" /etc/rc2.d/S20"" + serviceFile . getName ( ) ) ; System . out . println ( ""    $ ln -s /etc/init.d/"" + serviceFile . getName ( ) + "" /etc/rc3.d/S20"" + serviceFile . getName ( ) ) ; System . out . println ( """" ) ; System . out . println ( ""    If your application makes use of other services, then you will need to make"" ) ; System . out . println ( ""    sure that your application is started after, and then shutdown before. This"" ) ; System . out . println ( ""    is done by controlling the startup/shutdown order by setting the right order"" ) ; System . out . println ( ""    value, which in this example it set to 20."" ) ; System . out . println ( """" ) ; System . out . println ( ""  To start the service:"" ) ; System . out . println ( ""    $ /etc/init.d/"" + serviceFile . getName ( ) + "" start"" ) ; System . out . println ( """" ) ; System . out . println ( ""  To stop the service:"" ) ; System . out . println ( ""    $ /etc/init.d/"" + serviceFile . getName ( ) + "" stop"" ) ; System . out . println ( """" ) ; System . out . println ( ""  To uninstall the service :"" ) ; System . out . println ( ""    $ rm /etc/init.d/"" + serviceFile . getName ( ) ) ; System . out . println ( ""    $ rm /etc/rc0.d/K20"" + serviceFile . getName ( ) ) ; System . out . println ( ""    $ rm /etc/rc1.d/K20"" + serviceFile . getName ( ) ) ; System . out . println ( ""    $ rm /etc/rc2.d/S20"" + serviceFile . getName ( ) ) ; System . out . println ( ""    $ rm /etc/rc3.d/S20"" + serviceFile . getName ( ) ) ; } else if ( os . startsWith ( ""AIX"" ) ) { System . out . println ( """" ) ; System . out . println ( INTENSITY_BOLD + ""AIX system detected :"" + INTENSITY_NORMAL ) ; System . out . println ( ""  To install the service (and enable at system boot):"" ) ; System . out . println ( ""    $ ln -s "" + serviceFile . getPath ( ) + "" /etc/rc.d/init.d/"" ) ; System . out . println ( """" ) ; System . out . println ( ""  To start the service when the machine is rebooted for all multi-user run levels"" ) ; System . out . println ( ""  and stopped for the halt, single-user and reboot runlevels:"" ) ; System . out . println ( ""    $ ln -s /etc/rc.d/init.d/"" + serviceFile . getName ( ) + "" /etc/rc2.d/K20"" + serviceFile . getName ( ) ) ; System . out . println ( ""    $ ln -s /etc/rc.d/init.d/"" + serviceFile . getName ( ) + "" /etc/rc2.d/S20"" + serviceFile . getName ( ) ) ; System . out . println ( """" ) ; System . out . println ( ""    If your application makes use of other services, then you will need to make"" ) ; System . out . println ( ""    sure that your application is started after, and then shutdown before. This"" ) ; System . out . println ( ""    is done by controlling the startup/shutdown order by setting the right order"" ) ; System . out . println ( ""    value, which in this example it set to 20."" ) ; System . out . println ( """" ) ; System . out . println ( ""  To start the service:"" ) ; System . out . println ( ""    $ /etc/rc.d/init.d/"" + serviceFile . getName ( ) + "" start"" ) ; System . out . println ( """" ) ; System . out . println ( ""  To stop the service:"" ) ; System . out . println ( ""    $ /etc/rc.d/init.d/"" + serviceFile . getName ( ) + "" stop"" ) ; System . out . println ( """" ) ; System . out . println ( ""  To uninstall the service :"" ) ; System . out . println ( ""    $ rm /etc/rc.d/init.d/"" + serviceFile . getName ( ) ) ; System . out . println ( ""    $ rm /etc/rc2.d/K20"" + serviceFile . getName ( ) ) ; System . out . println ( ""    $ rm /etc/rc2.d/S20"" + serviceFile . getName ( ) ) ; } else if ( os . startsWith ( ""HP-UX"" ) ) { System . out . println ( """" ) ; System . out . println ( INTENSITY_BOLD + ""HP-UX system detected :"" + INTENSITY_NORMAL ) ; System . out . println ( ""  To install the service (and enable at system boot):"" ) ; System . out . println ( ""    $ cp /sbin/init.d/template /sbin/init.d/"" + serviceFile . getName ( ) ) ; System . out . println ( ""    $ cat /sbin/init.d/"" + serviceFile . getName ( ) + "" | sed 's/<specific>/"" + serviceFile . getName ( ) + ""/g' | \\ "" ) ; System . out . println ( ""      awk '/# Execute the commands to/{print;print \""                set_return\"";next}1' | \\ "" ) ; System . out . println ( ""      sed 's/CONTROL_VARIABLE/CONTROL_VARIABLE_KARAF/g' | \\ "" ) ; System . out . println ( ""      sed 's@# Execute the commands to start your subsystem@        "" + serviceFile . getPath ( ) + "" start@g' | \\ "" ) ; System . out . println ( ""      sed 's@# Execute the commands to stop your subsystem@        "" + serviceFile . getPath ( ) + "" stop@g' | \\ "" ) ; System . out . println ( ""      sed 's/^[ \t]*.://g' > /sbin/init.d/"" + serviceFile . getName ( ) + "".tmp"" ) ; System . out . println ( ""    $ mv /sbin/init.d/"" + serviceFile . getName ( ) + "".tmp /sbin/init.d/"" + serviceFile . getName ( ) ) ; System . out . println ( ""    $ chmod +x /sbin/init.d/"" + serviceFile . getName ( ) ) ; System . out . println ( ""    $ rm -f /sbin/init.d/"" + serviceFile . getName ( ) + "".tmp"" ) ; System . out . println ( ""    $ echo CONTROL_VARIABLE_KARAF=1 > /etc/rc.config.d/"" + serviceFile . getName ( ) ) ; System . out . println ( """" ) ; System . out . println ( ""  To start the service when the machine is rebooted for multi-user run level"" ) ; System . out . println ( ""  and stopped for the halt, single-user and reboot runlevels:"" ) ; System . out . println ( ""    $ ln -s /sbin/init.d/"" + serviceFile . getName ( ) + "" /sbin/rc2.d/K20"" + serviceFile . getName ( ) ) ; System . out . println ( ""    $ ln -s /sbin/init.d/"" + serviceFile . getName ( ) + "" /sbin/rc3.d/S20"" + serviceFile . getName ( ) ) ; System . out . println ( """" ) ; System . out . println ( ""    If your application makes use of other services, then you will need to make"" ) ; System . out . println ( ""    sure that your application is started after, and then shutdown before. This"" ) ; System . out . println ( ""    is done by controlling the startup/shutdown order by setting the right order"" ) ; System . out . println ( ""    value, which in this example it set to 20."" ) ; System . out . println ( """" ) ; System . out . println ( ""  To start the service:"" ) ; System . out . println ( ""    $ /sbin/init.d/"" + serviceFile . getName ( ) + "" start"" ) ; System . out . println ( """" ) ; System . out . println ( ""  To stop the service:"" ) ; System . out . println ( ""    $ /sbin/init.d/"" + serviceFile . getName ( ) + "" stop"" ) ; System . out . println ( """" ) ; System . out . println ( ""  To uninstall the service :"" ) ; System . out . println ( ""    $ rm /sbin/init.d/"" + serviceFile . getName ( ) ) ; System . out . println ( ""    $ rm /sbin/rc2.d/K20"" + serviceFile . getName ( ) ) ; System . out . println ( ""    $ rm /sbin/rc3.d/S20"" + serviceFile . getName ( ) ) ; } return null ; }",Smelly
" protected void initialize ( JobConf job , String table ) throws IOException { Connection connection = ConnectionFactory . createConnection ( HBaseConfiguration . create ( job ) ) ; TableName tableName = TableName . valueOf ( table ) ; initializeTable ( connection , tableName ) ; byte [ ] [ ] inputColumns = new byte [ ] [ ] { Bytes . toBytes ( ""columnA"" ) , Bytes . toBytes ( ""columnB"" ) } ; setInputColumns ( inputColumns ) ; Filter exampleFilter = new RowFilter ( CompareOperator . EQUAL , new RegexStringComparator ( ""aa.*"" ) ) ; setRowFilter ( exampleFilter ) ; }",No
" protected String getStepName ( ) { return ""Json Input Processor"" ; }",No
" public boolean setRegex ( String regex ) { try { pattern = Pattern . compile ( regex ) ; return true ; } catch ( PatternSyntaxException pse ) { throw new IllegalArgumentException ( ""Unparseable regex supplied: "" + regex ) ; } }",No
" protected void populateObject ( Object object ) throws Exception { super . populateObject ( object ) ; ConnectionError info = ( ConnectionError ) object ; info . setException ( createThrowable ( ""Exception:1"" ) ) ; info . setConnectionId ( createConnectionId ( ""ConnectionId:2"" ) ) ; }",No
" public static void testVersionedWritable ( Writable before , Writable after ) throws Exception { DataOutputBuffer dob = new DataOutputBuffer ( ) ; before . write ( dob ) ; DataInputBuffer dib = new DataInputBuffer ( ) ; dib . reset ( dob . getData ( ) , dob . getLength ( ) ) ; try { after . readFields ( dib ) ; } catch ( VersionMismatchException vmme ) { System . out . println ( ""Good, we expected this:"" + vmme ) ; return ; } throw new Exception ( ""A Version Mismatch Didn't Happen!"" ) ; }",No
" public int compare ( TreeNode o1 , TreeNode o2 ) { List < String > o1Names = null ; List < String > o2Names = null ; if ( ( o1 instanceof AttributeTypeWrapper ) && ( o2 instanceof AttributeTypeWrapper ) ) { AttributeType at1 = ( ( AttributeTypeWrapper ) o1 ) . getAttributeType ( ) ; AttributeType at2 = ( ( AttributeTypeWrapper ) o2 ) . getAttributeType ( ) ; o1Names = at1 . getNames ( ) ; o2Names = at2 . getNames ( ) ; } else if ( ( o1 instanceof ObjectClassWrapper ) && ( o2 instanceof ObjectClassWrapper ) ) { ObjectClass oc1 = ( ( ObjectClassWrapper ) o1 ) . getObjectClass ( ) ; ObjectClass oc2 = ( ( ObjectClassWrapper ) o2 ) . getObjectClass ( ) ; o1Names = oc1 . getNames ( ) ; o2Names = oc2 . getNames ( ) ; } else if ( ( o1 instanceof AttributeTypeWrapper ) && ( o2 instanceof ObjectClassWrapper ) ) { AttributeType at = ( ( AttributeTypeWrapper ) o1 ) . getAttributeType ( ) ; ObjectClass oc = ( ( ObjectClassWrapper ) o2 ) . getObjectClass ( ) ; o1Names = at . getNames ( ) ; o2Names = oc . getNames ( ) ; } else if ( ( o1 instanceof ObjectClassWrapper ) && ( o2 instanceof AttributeTypeWrapper ) ) { ObjectClass oc = ( ( ObjectClassWrapper ) o1 ) . getObjectClass ( ) ; AttributeType at = ( ( AttributeTypeWrapper ) o2 ) . getAttributeType ( ) ; o1Names = oc . getNames ( ) ; o2Names = at . getNames ( ) ; } if ( ( o1Names != null ) && ( o2Names != null ) ) { if ( ( o1Names . size ( ) > 0 ) && ( o2Names . size ( ) > 0 ) ) { return o1Names . get ( 0 ) . compareToIgnoreCase ( o2Names . get ( 0 ) ) ; } else if ( ( o1Names . size ( ) == 0 ) && ( o2Names . size ( ) > 0 ) ) { return """" . compareToIgnoreCase ( o2Names . get ( 0 ) ) ; } else if ( ( o1Names . size ( ) > 0 ) && ( o2Names . size ( ) == 0 ) ) { return o1Names . get ( 0 ) . compareToIgnoreCase ( """" ) ; } } return o1 . toString ( ) . compareToIgnoreCase ( o2 . toString ( ) ) ; }",Smelly
" public void read ( org . apache . thrift . protocol . TProtocol prot , DoubleColumnStatsData struct ) throws org . apache . thrift . TException { TTupleProtocol iprot = ( TTupleProtocol ) prot ; struct . lowValue = iprot . readDouble ( ) ; struct . setLowValueIsSet ( true ) ; struct . highValue = iprot . readDouble ( ) ; struct . setHighValueIsSet ( true ) ; struct . numNulls = iprot . readI64 ( ) ; struct . setNumNullsIsSet ( true ) ; struct . numDVs = iprot . readI64 ( ) ; struct . setNumDVsIsSet ( true ) ; }",Smelly
" public void testSetExtension ( ) throws Exception { DefaultActionMapper mapper = new DefaultActionMapper ( ) ; mapper . setExtensions ( """" ) ; assertNull ( mapper . extensions ) ; mapper . setExtensions ( null ) ; assertNull ( mapper . extensions ) ; mapper . setExtensions ( "",xml"" ) ; assertEquals ( Arrays . asList ( """" , ""xml"" ) , mapper . extensions ) ; mapper . setExtensions ( ""html,xml,"" ) ; assertEquals ( Arrays . asList ( ""html"" , ""xml"" , """" ) , mapper . extensions ) ; mapper . setExtensions ( ""html,,xml"" ) ; assertEquals ( Arrays . asList ( ""html"" , """" , ""xml"" ) , mapper . extensions ) ; mapper . setExtensions ( ""xml"" ) ; assertEquals ( Arrays . asList ( ""xml"" ) , mapper . extensions ) ; mapper . setExtensions ( "","" ) ; assertEquals ( Arrays . asList ( """" ) , mapper . extensions ) ; }",No
 public int getAMPM ( ) { return calendar . get ( Calendar . AM_PM ) ; },No
" public void testHttpServerFileExtensions ( ) { assertEquals ( ""application/andrew-inset"" , tika . detect ( ""x.ez"" ) ) ; assertEquals ( ""application/applixware"" , tika . detect ( ""x.aw"" ) ) ; assertEquals ( ""application/atom+xml"" , tika . detect ( ""x.atom"" ) ) ; assertEquals ( ""application/atomcat+xml"" , tika . detect ( ""x.atomcat"" ) ) ; assertEquals ( ""application/atomsvc+xml"" , tika . detect ( ""x.atomsvc"" ) ) ; assertEquals ( ""application/ccxml+xml"" , tika . detect ( ""x.ccxml"" ) ) ; assertEquals ( ""application/cu-seeme"" , tika . detect ( ""x.cu"" ) ) ; assertEquals ( ""application/davmount+xml"" , tika . detect ( ""x.davmount"" ) ) ; assertEquals ( ""application/ecmascript"" , tika . detect ( ""x.ecma"" ) ) ; assertEquals ( ""application/emma+xml"" , tika . detect ( ""x.emma"" ) ) ; assertEquals ( ""application/epub+zip"" , tika . detect ( ""x.epub"" ) ) ; assertEquals ( ""application/font-tdpfr"" , tika . detect ( ""x.pfr"" ) ) ; assertEquals ( ""application/hyperstudio"" , tika . detect ( ""x.stk"" ) ) ; assertEquals ( ""application/java-archive"" , tika . detect ( ""x.jar"" ) ) ; assertEquals ( ""application/java-serialized-object"" , tika . detect ( ""x.ser"" ) ) ; assertEquals ( ""application/java-vm"" , tika . detect ( ""x.class"" ) ) ; assertEquals ( ""application/javascript"" , tika . detect ( ""x.js"" ) ) ; assertEquals ( ""application/json"" , tika . detect ( ""x.json"" ) ) ; assertEquals ( ""application/lost+xml"" , tika . detect ( ""x.lostxml"" ) ) ; assertEquals ( ""application/mac-binhex40"" , tika . detect ( ""x.hqx"" ) ) ; assertEquals ( ""application/mac-compactpro"" , tika . detect ( ""x.cpt"" ) ) ; assertEquals ( ""application/marc"" , tika . detect ( ""x.mrc"" ) ) ; assertEquals ( ""application/mathematica"" , tika . detect ( ""x.ma"" ) ) ; assertEquals ( ""application/mathematica"" , tika . detect ( ""x.nb"" ) ) ; assertEquals ( ""application/mathematica"" , tika . detect ( ""x.mb"" ) ) ; assertEquals ( ""application/mathml+xml"" , tika . detect ( ""x.mathml"" ) ) ; assertEquals ( ""application/mbox"" , tika . detect ( ""x.mbox"" ) ) ; assertEquals ( ""application/mediaservercontrol+xml"" , tika . detect ( ""x.mscml"" ) ) ; assertEquals ( ""application/mp4"" , tika . detect ( ""x.mp4s"" ) ) ; assertEquals ( ""application/msword"" , tika . detect ( ""x.doc"" ) ) ; assertEquals ( ""application/msword"" , tika . detect ( ""x.dot"" ) ) ; assertEquals ( ""application/mxf"" , tika . detect ( ""x.mxf"" ) ) ; assertEquals ( ""application/octet-stream"" , tika . detect ( ""x.bin"" ) ) ; assertEquals ( ""application/octet-stream"" , tika . detect ( ""x.dms"" ) ) ; assertEquals ( ""application/octet-stream"" , tika . detect ( ""x.lha"" ) ) ; assertEquals ( ""application/octet-stream"" , tika . detect ( ""x.lrf"" ) ) ; assertEquals ( ""application/octet-stream"" , tika . detect ( ""x.lzh"" ) ) ; assertEquals ( ""application/octet-stream"" , tika . detect ( ""x.so"" ) ) ; assertEquals ( ""application/x-iso9660-image"" , tika . detect ( ""x.iso"" ) ) ; assertEquals ( ""application/x-apple-diskimage"" , tika . detect ( ""x.dmg"" ) ) ; assertEquals ( ""application/octet-stream"" , tika . detect ( ""x.dist"" ) ) ; assertEquals ( ""application/octet-stream"" , tika . detect ( ""x.distz"" ) ) ; assertEquals ( ""application/octet-stream"" , tika . detect ( ""x.pkg"" ) ) ; assertEquals ( ""application/octet-stream"" , tika . detect ( ""x.bpk"" ) ) ; assertEquals ( ""application/octet-stream"" , tika . detect ( ""x.dump"" ) ) ; assertEquals ( ""application/octet-stream"" , tika . detect ( ""x.elc"" ) ) ; assertEquals ( ""application/octet-stream"" , tika . detect ( ""x.deploy"" ) ) ; assertEquals ( ""application/oda"" , tika . detect ( ""x.oda"" ) ) ; assertEquals ( ""application/oebps-package+xml"" , tika . detect ( ""x.opf"" ) ) ; assertEquals ( ""application/ogg"" , tika . detect ( ""x.ogx"" ) ) ; assertEquals ( ""application/onenote"" , tika . detect ( ""x.onetoc"" ) ) ; assertEquals ( ""application/onenote"" , tika . detect ( ""x.onetoc2"" ) ) ; assertEquals ( ""application/onenote"" , tika . detect ( ""x.onetmp"" ) ) ; assertEquals ( ""application/onenote"" , tika . detect ( ""x.onepkg"" ) ) ; assertEquals ( ""application/patch-ops-error+xml"" , tika . detect ( ""x.xer"" ) ) ; assertEquals ( ""application/pdf"" , tika . detect ( ""x.pdf"" ) ) ; assertEquals ( ""application/pgp-encrypted"" , tika . detect ( ""x.pgp"" ) ) ; assertEquals ( ""application/pgp-signature"" , tika . detect ( ""x.asc"" ) ) ; assertEquals ( ""application/pgp-signature"" , tika . detect ( ""x.sig"" ) ) ; assertEquals ( ""application/pics-rules"" , tika . detect ( ""x.prf"" ) ) ; assertEquals ( ""application/pkcs10"" , tika . detect ( ""x.p10"" ) ) ; assertEquals ( ""application/pkcs7-mime"" , tika . detect ( ""x.p7m"" ) ) ; assertEquals ( ""application/pkcs7-mime"" , tika . detect ( ""x.p7c"" ) ) ; assertEquals ( ""application/pkcs7-signature"" , tika . detect ( ""x.p7s"" ) ) ; assertEquals ( ""application/pkix-cert"" , tika . detect ( ""x.cer"" ) ) ; assertEquals ( ""application/pkix-crl"" , tika . detect ( ""x.crl"" ) ) ; assertEquals ( ""application/pkix-pkipath"" , tika . detect ( ""x.pkipath"" ) ) ; assertEquals ( ""application/pkixcmp"" , tika . detect ( ""x.pki"" ) ) ; assertEquals ( ""application/pls+xml"" , tika . detect ( ""x.pls"" ) ) ; assertEquals ( ""application/illustrator"" , tika . detect ( ""x.ai"" ) ) ; assertEquals ( ""application/postscript"" , tika . detect ( ""x.eps"" ) ) ; assertEquals ( ""application/postscript"" , tika . detect ( ""x.ps"" ) ) ; assertEquals ( ""application/prs.cww"" , tika . detect ( ""x.cww"" ) ) ; assertEquals ( ""application/rdf+xml"" , tika . detect ( ""x.rdf"" ) ) ; assertEquals ( ""application/reginfo+xml"" , tika . detect ( ""x.rif"" ) ) ; assertEquals ( ""application/relax-ng-compact-syntax"" , tika . detect ( ""x.rnc"" ) ) ; assertEquals ( ""application/resource-lists+xml"" , tika . detect ( ""x.rl"" ) ) ; assertEquals ( ""application/resource-lists-diff+xml"" , tika . detect ( ""x.rld"" ) ) ; assertEquals ( ""application/rls-services+xml"" , tika . detect ( ""x.rs"" ) ) ; assertEquals ( ""application/rsd+xml"" , tika . detect ( ""x.rsd"" ) ) ; assertEquals ( ""application/rss+xml"" , tika . detect ( ""x.rss"" ) ) ; assertEquals ( ""application/rtf"" , tika . detect ( ""x.rtf"" ) ) ; assertEquals ( ""application/sbml+xml"" , tika . detect ( ""x.sbml"" ) ) ; assertEquals ( ""application/scvp-cv-request"" , tika . detect ( ""x.scq"" ) ) ; assertEquals ( ""application/scvp-cv-response"" , tika . detect ( ""x.scs"" ) ) ; assertEquals ( ""application/scvp-vp-request"" , tika . detect ( ""x.spq"" ) ) ; assertEquals ( ""application/scvp-vp-response"" , tika . detect ( ""x.spp"" ) ) ; assertEquals ( ""application/sdp"" , tika . detect ( ""x.sdp"" ) ) ; assertEquals ( ""application/set-payment-initiation"" , tika . detect ( ""x.setpay"" ) ) ; assertEquals ( ""application/set-registration-initiation"" , tika . detect ( ""x.setreg"" ) ) ; assertEquals ( ""application/sldworks"" , tika . detect ( ""x.sldprt"" ) ) ; assertEquals ( ""application/sldworks"" , tika . detect ( ""x.sldasm"" ) ) ; assertEquals ( ""application/sldworks"" , tika . detect ( ""x.slddrw"" ) ) ; assertEquals ( ""application/shf+xml"" , tika . detect ( ""x.shf"" ) ) ; assertEquals ( ""application/smil+xml"" , tika . detect ( ""x.smi"" ) ) ; assertEquals ( ""application/smil+xml"" , tika . detect ( ""x.smil"" ) ) ; assertEquals ( ""application/sparql-query"" , tika . detect ( ""x.rq"" ) ) ; assertEquals ( ""application/sparql-results+xml"" , tika . detect ( ""x.srx"" ) ) ; assertEquals ( ""application/srgs"" , tika . detect ( ""x.gram"" ) ) ; assertEquals ( ""application/srgs+xml"" , tika . detect ( ""x.grxml"" ) ) ; assertEquals ( ""application/ssml+xml"" , tika . detect ( ""x.ssml"" ) ) ; assertEquals ( ""application/vnd.3gpp.pic-bw-large"" , tika . detect ( ""x.plb"" ) ) ; assertEquals ( ""application/vnd.3gpp.pic-bw-small"" , tika . detect ( ""x.psb"" ) ) ; assertEquals ( ""application/vnd.3gpp.pic-bw-var"" , tika . detect ( ""x.pvb"" ) ) ; assertEquals ( ""application/vnd.3gpp2.tcap"" , tika . detect ( ""x.tcap"" ) ) ; assertEquals ( ""application/vnd.3m.post-it-notes"" , tika . detect ( ""x.pwn"" ) ) ; assertEquals ( ""application/vnd.accpac.simply.aso"" , tika . detect ( ""x.aso"" ) ) ; assertEquals ( ""application/vnd.accpac.simply.imp"" , tika . detect ( ""x.imp"" ) ) ; assertEquals ( ""application/vnd.acucobol"" , tika . detect ( ""x.acu"" ) ) ; assertEquals ( ""application/vnd.acucorp"" , tika . detect ( ""x.atc"" ) ) ; assertEquals ( ""application/vnd.acucorp"" , tika . detect ( ""x.acutc"" ) ) ; assertEquals ( ""application/vnd.adobe.air-application-installer-package+zip"" , tika . detect ( ""x.air"" ) ) ; assertEquals ( ""application/vnd.adobe.xdp+xml"" , tika . detect ( ""x.xdp"" ) ) ; assertEquals ( ""application/vnd.adobe.xfdf"" , tika . detect ( ""x.xfdf"" ) ) ; assertEquals ( ""application/vnd.airzip.filesecure.azf"" , tika . detect ( ""x.azf"" ) ) ; assertEquals ( ""application/vnd.airzip.filesecure.azs"" , tika . detect ( ""x.azs"" ) ) ; assertEquals ( ""application/vnd.amazon.ebook"" , tika . detect ( ""x.azw"" ) ) ; assertEquals ( ""application/vnd.americandynamics.acc"" , tika . detect ( ""x.acc"" ) ) ; assertEquals ( ""application/vnd.amiga.ami"" , tika . detect ( ""x.ami"" ) ) ; assertEquals ( ""application/vnd.android.package-archive"" , tika . detect ( ""x.apk"" ) ) ; assertEquals ( ""application/vnd.anser-web-certificate-issue-initiation"" , tika . detect ( ""x.cii"" ) ) ; assertEquals ( ""application/vnd.anser-web-funds-transfer-initiation"" , tika . detect ( ""x.fti"" ) ) ; assertEquals ( ""application/vnd.antix.game-component"" , tika . detect ( ""x.atx"" ) ) ; assertEquals ( ""application/vnd.apple.installer+xml"" , tika . detect ( ""x.mpkg"" ) ) ; assertEquals ( ""application/vnd.arastra.swi"" , tika . detect ( ""x.swi"" ) ) ; assertEquals ( ""application/vnd.blueice.multipass"" , tika . detect ( ""x.mpm"" ) ) ; assertEquals ( ""application/vnd.bmi"" , tika . detect ( ""x.bmi"" ) ) ; assertEquals ( ""application/vnd.businessobjects"" , tika . detect ( ""x.rep"" ) ) ; assertEquals ( ""application/vnd.chemdraw+xml"" , tika . detect ( ""x.cdxml"" ) ) ; assertEquals ( ""application/vnd.chipnuts.karaoke-mmd"" , tika . detect ( ""x.mmd"" ) ) ; assertEquals ( ""application/vnd.cinderella"" , tika . detect ( ""x.cdy"" ) ) ; assertEquals ( ""application/vnd.claymore"" , tika . detect ( ""x.cla"" ) ) ; assertEquals ( ""application/vnd.clonk.c4group"" , tika . detect ( ""x.c4g"" ) ) ; assertEquals ( ""application/vnd.clonk.c4group"" , tika . detect ( ""x.c4d"" ) ) ; assertEquals ( ""application/vnd.clonk.c4group"" , tika . detect ( ""x.c4f"" ) ) ; assertEquals ( ""application/vnd.clonk.c4group"" , tika . detect ( ""x.c4p"" ) ) ; assertEquals ( ""application/vnd.clonk.c4group"" , tika . detect ( ""x.c4u"" ) ) ; assertEquals ( ""application/vnd.commonspace"" , tika . detect ( ""x.csp"" ) ) ; assertEquals ( ""application/vnd.contact.cmsg"" , tika . detect ( ""x.cdbcmsg"" ) ) ; assertEquals ( ""application/vnd.cosmocaller"" , tika . detect ( ""x.cmc"" ) ) ; assertEquals ( ""application/vnd.crick.clicker"" , tika . detect ( ""x.clkx"" ) ) ; assertEquals ( ""application/vnd.crick.clicker.keyboard"" , tika . detect ( ""x.clkk"" ) ) ; assertEquals ( ""application/vnd.crick.clicker.palette"" , tika . detect ( ""x.clkp"" ) ) ; assertEquals ( ""application/vnd.crick.clicker.template"" , tika . detect ( ""x.clkt"" ) ) ; assertEquals ( ""application/vnd.crick.clicker.wordbank"" , tika . detect ( ""x.clkw"" ) ) ; assertEquals ( ""application/vnd.criticaltools.wbs+xml"" , tika . detect ( ""x.wbs"" ) ) ; assertEquals ( ""application/vnd.ctc-posml"" , tika . detect ( ""x.pml"" ) ) ; assertEquals ( ""application/vnd.cups-ppd"" , tika . detect ( ""x.ppd"" ) ) ; assertEquals ( ""application/vnd.curl.car"" , tika . detect ( ""x.car"" ) ) ; assertEquals ( ""application/vnd.curl.pcurl"" , tika . detect ( ""x.pcurl"" ) ) ; assertEquals ( ""application/vnd.data-vision.rdz"" , tika . detect ( ""x.rdz"" ) ) ; assertEquals ( ""application/vnd.denovo.fcselayout-link"" , tika . detect ( ""x.fe_launch"" ) ) ; assertEquals ( ""application/vnd.dna"" , tika . detect ( ""x.dna"" ) ) ; assertEquals ( ""application/vnd.dolby.mlp"" , tika . detect ( ""x.mlp"" ) ) ; assertEquals ( ""application/vnd.dpgraph"" , tika . detect ( ""x.dpg"" ) ) ; assertEquals ( ""application/vnd.dreamfactory"" , tika . detect ( ""x.dfac"" ) ) ; assertEquals ( ""application/vnd.dynageo"" , tika . detect ( ""x.geo"" ) ) ; assertEquals ( ""application/vnd.ecowin.chart"" , tika . detect ( ""x.mag"" ) ) ; assertEquals ( ""application/vnd.enliven"" , tika . detect ( ""x.nml"" ) ) ; assertEquals ( ""application/vnd.epson.esf"" , tika . detect ( ""x.esf"" ) ) ; assertEquals ( ""application/vnd.epson.msf"" , tika . detect ( ""x.msf"" ) ) ; assertEquals ( ""application/vnd.epson.quickanime"" , tika . detect ( ""x.qam"" ) ) ; assertEquals ( ""application/vnd.epson.salt"" , tika . detect ( ""x.slt"" ) ) ; assertEquals ( ""application/vnd.epson.ssf"" , tika . detect ( ""x.ssf"" ) ) ; assertEquals ( ""application/vnd.eszigno3+xml"" , tika . detect ( ""x.es3"" ) ) ; assertEquals ( ""application/vnd.eszigno3+xml"" , tika . detect ( ""x.et3"" ) ) ; assertEquals ( ""application/vnd.ezpix-album"" , tika . detect ( ""x.ez2"" ) ) ; assertEquals ( ""application/vnd.ezpix-package"" , tika . detect ( ""x.ez3"" ) ) ; assertEquals ( ""application/vnd.fdf"" , tika . detect ( ""x.fdf"" ) ) ; assertEquals ( ""application/vnd.fdsn.mseed"" , tika . detect ( ""x.mseed"" ) ) ; assertEquals ( ""application/vnd.fdsn.seed"" , tika . detect ( ""x.seed"" ) ) ; assertEquals ( ""application/vnd.fdsn.seed"" , tika . detect ( ""x.dataless"" ) ) ; assertEquals ( ""application/vnd.flographit"" , tika . detect ( ""x.gph"" ) ) ; assertEquals ( ""application/vnd.fluxtime.clip"" , tika . detect ( ""x.ftc"" ) ) ; assertEquals ( ""application/vnd.framemaker"" , tika . detect ( ""x.fm"" ) ) ; assertEquals ( ""application/vnd.framemaker"" , tika . detect ( ""x.frame"" ) ) ; assertEquals ( ""application/vnd.framemaker"" , tika . detect ( ""x.maker"" ) ) ; assertEquals ( ""application/vnd.framemaker"" , tika . detect ( ""x.book"" ) ) ; assertEquals ( ""application/vnd.frogans.fnc"" , tika . detect ( ""x.fnc"" ) ) ; assertEquals ( ""application/vnd.frogans.ltf"" , tika . detect ( ""x.ltf"" ) ) ; assertEquals ( ""application/vnd.fsc.weblaunch"" , tika . detect ( ""x.fsc"" ) ) ; assertEquals ( ""application/vnd.fujitsu.oasys"" , tika . detect ( ""x.oas"" ) ) ; assertEquals ( ""application/vnd.fujitsu.oasys2"" , tika . detect ( ""x.oa2"" ) ) ; assertEquals ( ""application/vnd.fujitsu.oasys3"" , tika . detect ( ""x.oa3"" ) ) ; assertEquals ( ""application/vnd.fujitsu.oasysgp"" , tika . detect ( ""x.fg5"" ) ) ; assertEquals ( ""application/vnd.fujitsu.oasysprs"" , tika . detect ( ""x.bh2"" ) ) ; assertEquals ( ""application/vnd.fujixerox.ddd"" , tika . detect ( ""x.ddd"" ) ) ; assertEquals ( ""application/vnd.fujixerox.docuworks"" , tika . detect ( ""x.xdw"" ) ) ; assertEquals ( ""application/vnd.fujixerox.docuworks.binder"" , tika . detect ( ""x.xbd"" ) ) ; assertEquals ( ""application/vnd.fuzzysheet"" , tika . detect ( ""x.fzs"" ) ) ; assertEquals ( ""application/vnd.genomatix.tuxedo"" , tika . detect ( ""x.txd"" ) ) ; assertEquals ( ""application/vnd.geogebra.file"" , tika . detect ( ""x.ggb"" ) ) ; assertEquals ( ""application/vnd.geogebra.tool"" , tika . detect ( ""x.ggt"" ) ) ; assertEquals ( ""application/vnd.geometry-explorer"" , tika . detect ( ""x.gex"" ) ) ; assertEquals ( ""application/vnd.geometry-explorer"" , tika . detect ( ""x.gre"" ) ) ; assertEquals ( ""application/vnd.gmx"" , tika . detect ( ""x.gmx"" ) ) ; assertEquals ( ""application/vnd.google-earth.kml+xml"" , tika . detect ( ""x.kml"" ) ) ; assertEquals ( ""application/vnd.google-earth.kmz"" , tika . detect ( ""x.kmz"" ) ) ; assertEquals ( ""application/vnd.grafeq"" , tika . detect ( ""x.gqf"" ) ) ; assertEquals ( ""application/vnd.grafeq"" , tika . detect ( ""x.gqs"" ) ) ; assertEquals ( ""application/vnd.groove-account"" , tika . detect ( ""x.gac"" ) ) ; assertEquals ( ""application/vnd.groove-help"" , tika . detect ( ""x.ghf"" ) ) ; assertEquals ( ""application/vnd.groove-identity-message"" , tika . detect ( ""x.gim"" ) ) ; assertEquals ( ""application/vnd.groove-injector"" , tika . detect ( ""x.grv"" ) ) ; assertEquals ( ""application/vnd.groove-tool-message"" , tika . detect ( ""x.gtm"" ) ) ; assertEquals ( ""application/vnd.groove-tool-template"" , tika . detect ( ""x.tpl"" ) ) ; assertEquals ( ""application/vnd.groove-vcard"" , tika . detect ( ""x.vcg"" ) ) ; assertEquals ( ""application/vnd.handheld-entertainment+xml"" , tika . detect ( ""x.zmm"" ) ) ; assertEquals ( ""application/vnd.hbci"" , tika . detect ( ""x.hbci"" ) ) ; assertEquals ( ""application/vnd.hhe.lesson-player"" , tika . detect ( ""x.les"" ) ) ; assertEquals ( ""application/vnd.hp-hpgl"" , tika . detect ( ""x.hpgl"" ) ) ; assertEquals ( ""application/vnd.hp-hpid"" , tika . detect ( ""x.hpid"" ) ) ; assertEquals ( ""application/vnd.hp-hps"" , tika . detect ( ""x.hps"" ) ) ; assertEquals ( ""application/vnd.hp-jlyt"" , tika . detect ( ""x.jlt"" ) ) ; assertEquals ( ""application/vnd.hp-pcl"" , tika . detect ( ""x.pcl"" ) ) ; assertEquals ( ""application/vnd.hp-pclxl"" , tika . detect ( ""x.pclxl"" ) ) ; assertEquals ( ""application/vnd.hydrostatix.sof-data"" , tika . detect ( ""x.sfd-hdstx"" ) ) ; assertEquals ( ""application/vnd.hzn-3d-crossword"" , tika . detect ( ""x.x3d"" ) ) ; assertEquals ( ""application/vnd.ibm.minipay"" , tika . detect ( ""x.mpy"" ) ) ; assertEquals ( ""application/vnd.ibm.modcap"" , tika . detect ( ""x.afp"" ) ) ; assertEquals ( ""application/vnd.ibm.modcap"" , tika . detect ( ""x.listafp"" ) ) ; assertEquals ( ""application/vnd.ibm.modcap"" , tika . detect ( ""x.list3820"" ) ) ; assertEquals ( ""application/vnd.ibm.rights-management"" , tika . detect ( ""x.irm"" ) ) ; assertEquals ( ""application/vnd.ibm.secure-container"" , tika . detect ( ""x.sc"" ) ) ; assertEquals ( ""application/vnd.iccprofile"" , tika . detect ( ""x.icc"" ) ) ; assertEquals ( ""application/vnd.iccprofile"" , tika . detect ( ""x.icm"" ) ) ; assertEquals ( ""application/vnd.igloader"" , tika . detect ( ""x.igl"" ) ) ; assertEquals ( ""application/vnd.immervision-ivp"" , tika . detect ( ""x.ivp"" ) ) ; assertEquals ( ""application/vnd.immervision-ivu"" , tika . detect ( ""x.ivu"" ) ) ; assertEquals ( ""application/vnd.intercon.formnet"" , tika . detect ( ""x.xpw"" ) ) ; assertEquals ( ""application/vnd.intercon.formnet"" , tika . detect ( ""x.xpx"" ) ) ; assertEquals ( ""application/vnd.intu.qbo"" , tika . detect ( ""x.qbo"" ) ) ; assertEquals ( ""application/vnd.intu.qfx"" , tika . detect ( ""x.qfx"" ) ) ; assertEquals ( ""application/vnd.ipunplugged.rcprofile"" , tika . detect ( ""x.rcprofile"" ) ) ; assertEquals ( ""application/vnd.irepository.package+xml"" , tika . detect ( ""x.irp"" ) ) ; assertEquals ( ""application/vnd.is-xpr"" , tika . detect ( ""x.xpr"" ) ) ; assertEquals ( ""application/vnd.jam"" , tika . detect ( ""x.jam"" ) ) ; assertEquals ( ""application/vnd.jcp.javame.midlet-rms"" , tika . detect ( ""x.rms"" ) ) ; assertEquals ( ""application/vnd.jisp"" , tika . detect ( ""x.jisp"" ) ) ; assertEquals ( ""application/vnd.joost.joda-archive"" , tika . detect ( ""x.joda"" ) ) ; assertEquals ( ""application/vnd.kahootz"" , tika . detect ( ""x.ktz"" ) ) ; assertEquals ( ""application/vnd.kahootz"" , tika . detect ( ""x.ktr"" ) ) ; assertEquals ( ""application/vnd.kde.karbon"" , tika . detect ( ""x.karbon"" ) ) ; assertEquals ( ""application/vnd.kde.kchart"" , tika . detect ( ""x.chrt"" ) ) ; assertEquals ( ""application/vnd.kde.kformula"" , tika . detect ( ""x.kfo"" ) ) ; assertEquals ( ""application/vnd.kde.kivio"" , tika . detect ( ""x.flw"" ) ) ; assertEquals ( ""application/vnd.kde.kontour"" , tika . detect ( ""x.kon"" ) ) ; assertEquals ( ""application/vnd.kde.kpresenter"" , tika . detect ( ""x.kpr"" ) ) ; assertEquals ( ""application/vnd.kde.kpresenter"" , tika . detect ( ""x.kpt"" ) ) ; assertEquals ( ""application/vnd.kde.kspread"" , tika . detect ( ""x.ksp"" ) ) ; assertEquals ( ""application/vnd.kde.kword"" , tika . detect ( ""x.kwd"" ) ) ; assertEquals ( ""application/vnd.kde.kword"" , tika . detect ( ""x.kwt"" ) ) ; assertEquals ( ""application/vnd.kenameaapp"" , tika . detect ( ""x.htke"" ) ) ; assertEquals ( ""application/vnd.kidspiration"" , tika . detect ( ""x.kia"" ) ) ; assertEquals ( ""application/vnd.kinar"" , tika . detect ( ""x.kne"" ) ) ; assertEquals ( ""application/vnd.kinar"" , tika . detect ( ""x.knp"" ) ) ; assertEquals ( ""application/vnd.koan"" , tika . detect ( ""x.skp"" ) ) ; assertEquals ( ""application/vnd.koan"" , tika . detect ( ""x.skd"" ) ) ; assertEquals ( ""application/vnd.koan"" , tika . detect ( ""x.skt"" ) ) ; assertEquals ( ""application/vnd.koan"" , tika . detect ( ""x.skm"" ) ) ; assertEquals ( ""application/vnd.kodak-descriptor"" , tika . detect ( ""x.sse"" ) ) ; assertEquals ( ""application/vnd.llamagraphics.life-balance.desktop"" , tika . detect ( ""x.lbd"" ) ) ; assertEquals ( ""application/vnd.llamagraphics.life-balance.exchange+xml"" , tika . detect ( ""x.lbe"" ) ) ; assertEquals ( ""application/vnd.lotus-1-2-3"" , tika . detect ( ""x.123"" ) ) ; assertEquals ( ""application/vnd.lotus-approach"" , tika . detect ( ""x.apr"" ) ) ; assertEquals ( ""application/vnd.lotus-freelance"" , tika . detect ( ""x.pre"" ) ) ; assertEquals ( ""application/vnd.lotus-notes"" , tika . detect ( ""x.nsf"" ) ) ; assertEquals ( ""application/vnd.lotus-organizer"" , tika . detect ( ""x.org"" ) ) ; assertEquals ( ""text/x-scheme"" , tika . detect ( ""x.scm"" ) ) ; assertEquals ( ""application/vnd.lotus-wordpro"" , tika . detect ( ""x.lwp"" ) ) ; assertEquals ( ""application/vnd.macports.portpkg"" , tika . detect ( ""x.portpkg"" ) ) ; assertEquals ( ""application/vnd.mcd"" , tika . detect ( ""x.mcd"" ) ) ; assertEquals ( ""application/vnd.medcalcdata"" , tika . detect ( ""x.mc1"" ) ) ; assertEquals ( ""application/vnd.mediastation.cdkey"" , tika . detect ( ""x.cdkey"" ) ) ; assertEquals ( ""application/vnd.mfer"" , tika . detect ( ""x.mwf"" ) ) ; assertEquals ( ""application/vnd.mfmp"" , tika . detect ( ""x.mfm"" ) ) ; assertEquals ( ""application/vnd.micrografx.flo"" , tika . detect ( ""x.flo"" ) ) ; assertEquals ( ""application/vnd.micrografx.igx"" , tika . detect ( ""x.igx"" ) ) ; assertEquals ( ""application/vnd.mif"" , tika . detect ( ""x.mif"" ) ) ; assertEquals ( ""application/vnd.mobius.daf"" , tika . detect ( ""x.daf"" ) ) ; assertEquals ( ""application/vnd.mobius.dis"" , tika . detect ( ""x.dis"" ) ) ; assertEquals ( ""application/vnd.mobius.mbk"" , tika . detect ( ""x.mbk"" ) ) ; assertEquals ( ""application/vnd.mobius.mqy"" , tika . detect ( ""x.mqy"" ) ) ; assertEquals ( ""application/vnd.mobius.msl"" , tika . detect ( ""x.msl"" ) ) ; assertEquals ( ""application/vnd.mobius.plc"" , tika . detect ( ""x.plc"" ) ) ; assertEquals ( ""application/vnd.mobius.txf"" , tika . detect ( ""x.txf"" ) ) ; assertEquals ( ""application/vnd.mophun.application"" , tika . detect ( ""x.mpn"" ) ) ; assertEquals ( ""application/vnd.mophun.certificate"" , tika . detect ( ""x.mpc"" ) ) ; assertEquals ( ""application/vnd.mozilla.xul+xml"" , tika . detect ( ""x.xul"" ) ) ; assertEquals ( ""application/vnd.ms-artgalry"" , tika . detect ( ""x.cil"" ) ) ; assertEquals ( ""application/vnd.ms-cab-compressed"" , tika . detect ( ""x.cab"" ) ) ; assertEquals ( ""application/vnd.ms-excel"" , tika . detect ( ""x.xls"" ) ) ; assertEquals ( ""application/vnd.ms-excel"" , tika . detect ( ""x.xlm"" ) ) ; assertEquals ( ""application/vnd.ms-excel"" , tika . detect ( ""x.xla"" ) ) ; assertEquals ( ""application/vnd.ms-excel"" , tika . detect ( ""x.xlc"" ) ) ; assertEquals ( ""application/vnd.ms-excel"" , tika . detect ( ""x.xlt"" ) ) ; assertEquals ( ""application/vnd.ms-excel"" , tika . detect ( ""x.xlw"" ) ) ; assertEquals ( ""application/vnd.ms-excel.addin.macroenabled.12"" , tika . detect ( ""x.xlam"" ) ) ; assertEquals ( ""application/vnd.ms-excel.sheet.binary.macroenabled.12"" , tika . detect ( ""x.xlsb"" ) ) ; assertEquals ( ""application/vnd.ms-excel.sheet.macroenabled.12"" , tika . detect ( ""x.xlsm"" ) ) ; assertEquals ( ""application/vnd.ms-excel.template.macroenabled.12"" , tika . detect ( ""x.xltm"" ) ) ; assertEquals ( ""application/vnd.ms-fontobject"" , tika . detect ( ""x.eot"" ) ) ; assertEquals ( ""application/vnd.ms-htmlhelp"" , tika . detect ( ""x.chm"" ) ) ; assertEquals ( ""application/vnd.ms-ims"" , tika . detect ( ""x.ims"" ) ) ; assertEquals ( ""application/vnd.ms-lrm"" , tika . detect ( ""x.lrm"" ) ) ; assertEquals ( ""application/vnd.ms-pki.seccat"" , tika . detect ( ""x.cat"" ) ) ; assertEquals ( ""application/vnd.ms-pki.stl"" , tika . detect ( ""x.stl"" ) ) ; assertEquals ( ""application/vnd.ms-powerpoint"" , tika . detect ( ""x.ppt"" ) ) ; assertEquals ( ""application/vnd.ms-powerpoint"" , tika . detect ( ""x.pps"" ) ) ; assertEquals ( ""application/vnd.ms-powerpoint"" , tika . detect ( ""x.pot"" ) ) ; assertEquals ( ""application/vnd.ms-powerpoint.addin.macroenabled.12"" , tika . detect ( ""x.ppam"" ) ) ; assertEquals ( ""application/vnd.ms-powerpoint.presentation.macroenabled.12"" , tika . detect ( ""x.pptm"" ) ) ; assertEquals ( ""application/vnd.ms-powerpoint.slide.macroenabled.12"" , tika . detect ( ""x.sldm"" ) ) ; assertEquals ( ""application/vnd.ms-powerpoint.slideshow.macroenabled.12"" , tika . detect ( ""x.ppsm"" ) ) ; assertEquals ( ""application/vnd.ms-powerpoint.template.macroenabled.12"" , tika . detect ( ""x.potm"" ) ) ; assertEquals ( ""application/vnd.ms-project"" , tika . detect ( ""x.mpp"" ) ) ; assertEquals ( ""application/vnd.ms-project"" , tika . detect ( ""x.mpt"" ) ) ; assertEquals ( ""application/vnd.ms-word.document.macroenabled.12"" , tika . detect ( ""x.docm"" ) ) ; assertEquals ( ""application/vnd.ms-word.template.macroenabled.12"" , tika . detect ( ""x.dotm"" ) ) ; assertEquals ( ""application/vnd.ms-works"" , tika . detect ( ""x.wps"" ) ) ; assertEquals ( ""application/vnd.ms-works"" , tika . detect ( ""x.wks"" ) ) ; assertEquals ( ""application/vnd.ms-works"" , tika . detect ( ""x.wcm"" ) ) ; assertEquals ( ""application/vnd.ms-works"" , tika . detect ( ""x.wdb"" ) ) ; assertEquals ( ""application/vnd.ms-wpl"" , tika . detect ( ""x.wpl"" ) ) ; assertEquals ( ""application/vnd.ms-xpsdocument"" , tika . detect ( ""x.xps"" ) ) ; assertEquals ( ""application/vnd.mseq"" , tika . detect ( ""x.mseq"" ) ) ; assertEquals ( ""application/vnd.musician"" , tika . detect ( ""x.mus"" ) ) ; assertEquals ( ""application/vnd.muvee.style"" , tika . detect ( ""x.msty"" ) ) ; assertEquals ( ""application/vnd.neurolanguage.nlu"" , tika . detect ( ""x.nlu"" ) ) ; assertEquals ( ""application/vnd.noblenet-directory"" , tika . detect ( ""x.nnd"" ) ) ; assertEquals ( ""application/vnd.noblenet-sealer"" , tika . detect ( ""x.nns"" ) ) ; assertEquals ( ""application/vnd.noblenet-web"" , tika . detect ( ""x.nnw"" ) ) ; assertEquals ( ""application/vnd.nokia.n-gage.data"" , tika . detect ( ""x.ngdat"" ) ) ; assertEquals ( ""application/vnd.nokia.n-gage.symbian.install"" , tika . detect ( ""x.n-gage"" ) ) ; assertEquals ( ""application/vnd.nokia.radio-preset"" , tika . detect ( ""x.rpst"" ) ) ; assertEquals ( ""application/vnd.nokia.radio-presets"" , tika . detect ( ""x.rpss"" ) ) ; assertEquals ( ""application/vnd.novadigm.edm"" , tika . detect ( ""x.edm"" ) ) ; assertEquals ( ""application/vnd.novadigm.edx"" , tika . detect ( ""x.edx"" ) ) ; assertEquals ( ""application/vnd.novadigm.ext"" , tika . detect ( ""x.ext"" ) ) ; assertEquals ( ""application/vnd.oasis.opendocument.chart"" , tika . detect ( ""x.odc"" ) ) ; assertEquals ( ""application/vnd.oasis.opendocument.chart-template"" , tika . detect ( ""x.otc"" ) ) ; assertEquals ( ""application/vnd.oasis.opendocument.database"" , tika . detect ( ""x.odb"" ) ) ; assertEquals ( ""application/vnd.oasis.opendocument.formula"" , tika . detect ( ""x.odf"" ) ) ; assertEquals ( ""application/vnd.oasis.opendocument.formula-template"" , tika . detect ( ""x.odft"" ) ) ; assertEquals ( ""application/vnd.oasis.opendocument.graphics"" , tika . detect ( ""x.odg"" ) ) ; assertEquals ( ""application/vnd.oasis.opendocument.graphics-template"" , tika . detect ( ""x.otg"" ) ) ; assertEquals ( ""application/vnd.oasis.opendocument.image"" , tika . detect ( ""x.odi"" ) ) ; assertEquals ( ""application/vnd.oasis.opendocument.image-template"" , tika . detect ( ""x.oti"" ) ) ; assertEquals ( ""application/vnd.oasis.opendocument.presentation"" , tika . detect ( ""x.odp"" ) ) ; assertEquals ( ""application/vnd.oasis.opendocument.presentation-template"" , tika . detect ( ""x.otp"" ) ) ; assertEquals ( ""application/vnd.oasis.opendocument.spreadsheet"" , tika . detect ( ""x.ods"" ) ) ; assertEquals ( ""application/vnd.oasis.opendocument.spreadsheet-template"" , tika . detect ( ""x.ots"" ) ) ; assertEquals ( ""application/vnd.oasis.opendocument.text"" , tika . detect ( ""x.odt"" ) ) ; assertEquals ( ""application/vnd.oasis.opendocument.text-master"" , tika . detect ( ""x.otm"" ) ) ; assertEquals ( ""application/vnd.oasis.opendocument.text-template"" , tika . detect ( ""x.ott"" ) ) ; assertEquals ( ""application/vnd.oasis.opendocument.text-web"" , tika . detect ( ""x.oth"" ) ) ; assertEquals ( ""application/vnd.olpc-sugar"" , tika . detect ( ""x.xo"" ) ) ; assertEquals ( ""application/vnd.oma.dd2+xml"" , tika . detect ( ""x.dd2"" ) ) ; assertEquals ( ""application/vnd.openofficeorg.extension"" , tika . detect ( ""x.oxt"" ) ) ; assertEquals ( ""application/vnd.openxmlformats-officedocument.presentationml.presentation"" , tika . detect ( ""x.pptx"" ) ) ; assertEquals ( ""application/vnd.openxmlformats-officedocument.presentationml.slide"" , tika . detect ( ""x.sldx"" ) ) ; assertEquals ( ""application/vnd.openxmlformats-officedocument.presentationml.slideshow"" , tika . detect ( ""x.ppsx"" ) ) ; assertEquals ( ""application/vnd.openxmlformats-officedocument.presentationml.template"" , tika . detect ( ""x.potx"" ) ) ; assertEquals ( ""application/vnd.openxmlformats-officedocument.spreadsheetml.sheet"" , tika . detect ( ""x.xlsx"" ) ) ; assertEquals ( ""application/vnd.openxmlformats-officedocument.spreadsheetml.template"" , tika . detect ( ""x.xltx"" ) ) ; assertEquals ( ""application/vnd.openxmlformats-officedocument.wordprocessingml.document"" , tika . detect ( ""x.docx"" ) ) ; assertEquals ( ""application/vnd.openxmlformats-officedocument.wordprocessingml.template"" , tika . detect ( ""x.dotx"" ) ) ; assertEquals ( ""application/vnd.osgi.dp"" , tika . detect ( ""x.dp"" ) ) ; assertEquals ( ""chemical/x-pdb"" , tika . detect ( ""x.pdb"" ) ) ; assertEquals ( ""application/vnd.palm"" , tika . detect ( ""x.pqa"" ) ) ; assertEquals ( ""application/vnd.palm"" , tika . detect ( ""x.oprc"" ) ) ; assertEquals ( ""application/vnd.pg.format"" , tika . detect ( ""x.str"" ) ) ; assertEquals ( ""application/vnd.pg.osasli"" , tika . detect ( ""x.ei6"" ) ) ; assertEquals ( ""application/vnd.picsel"" , tika . detect ( ""x.efif"" ) ) ; assertEquals ( ""application/vnd.pocketlearn"" , tika . detect ( ""x.plf"" ) ) ; assertEquals ( ""application/vnd.powerbuilder6"" , tika . detect ( ""x.pbd"" ) ) ; assertEquals ( ""application/vnd.previewsystems.box"" , tika . detect ( ""x.box"" ) ) ; assertEquals ( ""application/vnd.proteus.magazine"" , tika . detect ( ""x.mgz"" ) ) ; assertEquals ( ""application/vnd.publishare-delta-tree"" , tika . detect ( ""x.qps"" ) ) ; assertEquals ( ""application/vnd.pvi.ptid1"" , tika . detect ( ""x.ptid"" ) ) ; assertEquals ( ""application/vnd.quark.quarkxpress"" , tika . detect ( ""x.qxd"" ) ) ; assertEquals ( ""application/vnd.quark.quarkxpress"" , tika . detect ( ""x.qxt"" ) ) ; assertEquals ( ""application/vnd.quark.quarkxpress"" , tika . detect ( ""x.qwd"" ) ) ; assertEquals ( ""application/vnd.quark.quarkxpress"" , tika . detect ( ""x.qwt"" ) ) ; assertEquals ( ""application/vnd.quark.quarkxpress"" , tika . detect ( ""x.qxl"" ) ) ; assertEquals ( ""application/vnd.quark.quarkxpress"" , tika . detect ( ""x.qxb"" ) ) ; assertEquals ( ""application/vnd.recordare.musicxml"" , tika . detect ( ""x.mxl"" ) ) ; assertEquals ( ""application/vnd.recordare.musicxml+xml"" , tika . detect ( ""x.musicxml"" ) ) ; assertEquals ( ""application/vnd.rim.cod"" , tika . detect ( ""x.cod"" ) ) ; assertEquals ( ""application/vnd.rn-realmedia"" , tika . detect ( ""x.rm"" ) ) ; assertEquals ( ""application/vnd.route66.link66+xml"" , tika . detect ( ""x.link66"" ) ) ; assertEquals ( ""application/vnd.seemail"" , tika . detect ( ""x.see"" ) ) ; assertEquals ( ""application/vnd.sema"" , tika . detect ( ""x.sema"" ) ) ; assertEquals ( ""application/vnd.semd"" , tika . detect ( ""x.semd"" ) ) ; assertEquals ( ""application/vnd.semf"" , tika . detect ( ""x.semf"" ) ) ; assertEquals ( ""application/vnd.shana.informed.formdata"" , tika . detect ( ""x.ifm"" ) ) ; assertEquals ( ""application/vnd.shana.informed.formtemplate"" , tika . detect ( ""x.itp"" ) ) ; assertEquals ( ""application/vnd.shana.informed.interchange"" , tika . detect ( ""x.iif"" ) ) ; assertEquals ( ""application/vnd.shana.informed.package"" , tika . detect ( ""x.ipk"" ) ) ; assertEquals ( ""application/vnd.simtech-mindmapper"" , tika . detect ( ""x.twd"" ) ) ; assertEquals ( ""application/vnd.simtech-mindmapper"" , tika . detect ( ""x.twds"" ) ) ; assertEquals ( ""application/vnd.smaf"" , tika . detect ( ""x.mmf"" ) ) ; assertEquals ( ""application/vnd.smart.teacher"" , tika . detect ( ""x.teacher"" ) ) ; assertEquals ( ""application/vnd.solent.sdkm+xml"" , tika . detect ( ""x.sdkm"" ) ) ; assertEquals ( ""application/vnd.solent.sdkm+xml"" , tika . detect ( ""x.sdkd"" ) ) ; assertEquals ( ""application/vnd.spotfire.dxp"" , tika . detect ( ""x.dxp"" ) ) ; assertEquals ( ""application/vnd.spotfire.sfs"" , tika . detect ( ""x.sfs"" ) ) ; assertEquals ( ""application/vnd.stardivision.calc"" , tika . detect ( ""x.sdc"" ) ) ; assertEquals ( ""application/vnd.stardivision.draw"" , tika . detect ( ""x.sda"" ) ) ; assertEquals ( ""application/vnd.stardivision.impress"" , tika . detect ( ""x.sdd"" ) ) ; assertEquals ( ""application/vnd.stardivision.math"" , tika . detect ( ""x.smf"" ) ) ; assertEquals ( ""application/vnd.stardivision.writer"" , tika . detect ( ""x.sdw"" ) ) ; assertEquals ( ""application/x-staroffice-template"" , tika . detect ( ""x.vor"" ) ) ; assertEquals ( ""application/vnd.stardivision.writer-global"" , tika . detect ( ""x.sgl"" ) ) ; assertEquals ( ""application/vnd.sun.xml.calc"" , tika . detect ( ""x.sxc"" ) ) ; assertEquals ( ""application/vnd.sun.xml.calc.template"" , tika . detect ( ""x.stc"" ) ) ; assertEquals ( ""application/vnd.sun.xml.draw"" , tika . detect ( ""x.sxd"" ) ) ; assertEquals ( ""application/vnd.sun.xml.draw.template"" , tika . detect ( ""x.std"" ) ) ; assertEquals ( ""application/vnd.sun.xml.impress"" , tika . detect ( ""x.sxi"" ) ) ; assertEquals ( ""application/vnd.sun.xml.impress.template"" , tika . detect ( ""x.sti"" ) ) ; assertEquals ( ""application/vnd.sun.xml.math"" , tika . detect ( ""x.sxm"" ) ) ; assertEquals ( ""application/vnd.sun.xml.writer"" , tika . detect ( ""x.sxw"" ) ) ; assertEquals ( ""application/vnd.sun.xml.writer.global"" , tika . detect ( ""x.sxg"" ) ) ; assertEquals ( ""application/vnd.sun.xml.writer.template"" , tika . detect ( ""x.stw"" ) ) ; assertEquals ( ""application/vnd.sus-calendar"" , tika . detect ( ""x.sus"" ) ) ; assertEquals ( ""application/vnd.sus-calendar"" , tika . detect ( ""x.susp"" ) ) ; assertEquals ( ""application/vnd.svd"" , tika . detect ( ""x.svd"" ) ) ; assertEquals ( ""application/vnd.symbian.install"" , tika . detect ( ""x.sis"" ) ) ; assertEquals ( ""application/vnd.symbian.install"" , tika . detect ( ""x.sisx"" ) ) ; assertEquals ( ""application/vnd.syncml+xml"" , tika . detect ( ""x.xsm"" ) ) ; assertEquals ( ""application/vnd.syncml.dm+wbxml"" , tika . detect ( ""x.bdm"" ) ) ; assertEquals ( ""application/vnd.syncml.dm+xml"" , tika . detect ( ""x.xdm"" ) ) ; assertEquals ( ""application/vnd.tao.intent-module-archive"" , tika . detect ( ""x.tao"" ) ) ; assertEquals ( ""application/vnd.tmobile-livetv"" , tika . detect ( ""x.tmo"" ) ) ; assertEquals ( ""application/vnd.trid.tpt"" , tika . detect ( ""x.tpt"" ) ) ; assertEquals ( ""application/vnd.triscape.mxs"" , tika . detect ( ""x.mxs"" ) ) ; assertEquals ( ""application/vnd.trueapp"" , tika . detect ( ""x.tra"" ) ) ; assertEquals ( ""application/vnd.ufdl"" , tika . detect ( ""x.ufd"" ) ) ; assertEquals ( ""application/vnd.ufdl"" , tika . detect ( ""x.ufdl"" ) ) ; assertEquals ( ""application/vnd.uiq.theme"" , tika . detect ( ""x.utz"" ) ) ; assertEquals ( ""application/vnd.umajin"" , tika . detect ( ""x.umj"" ) ) ; assertEquals ( ""application/vnd.unity"" , tika . detect ( ""x.unityweb"" ) ) ; assertEquals ( ""application/vnd.uoml+xml"" , tika . detect ( ""x.uoml"" ) ) ; assertEquals ( ""application/vnd.vcx"" , tika . detect ( ""x.vcx"" ) ) ; assertEquals ( ""application/vnd.visio"" , tika . detect ( ""x.vsd"" ) ) ; assertEquals ( ""application/vnd.visio"" , tika . detect ( ""x.vst"" ) ) ; assertEquals ( ""application/vnd.visio"" , tika . detect ( ""x.vss"" ) ) ; assertEquals ( ""application/vnd.visio"" , tika . detect ( ""x.vsw"" ) ) ; assertEquals ( ""application/vnd.visionary"" , tika . detect ( ""x.vis"" ) ) ; assertEquals ( ""application/vnd.vsf"" , tika . detect ( ""x.vsf"" ) ) ; assertEquals ( ""application/vnd.wap.wbxml"" , tika . detect ( ""x.wbxml"" ) ) ; assertEquals ( ""application/vnd.wap.wmlc"" , tika . detect ( ""x.wmlc"" ) ) ; assertEquals ( ""application/vnd.wap.wmlscriptc"" , tika . detect ( ""x.wmlsc"" ) ) ; assertEquals ( ""application/vnd.webturbo"" , tika . detect ( ""x.wtb"" ) ) ; assertEquals ( ""application/vnd.wordperfect"" , tika . detect ( ""x.wpd"" ) ) ; assertEquals ( ""application/vnd.wqd"" , tika . detect ( ""x.wqd"" ) ) ; assertEquals ( ""application/vnd.wt.stf"" , tika . detect ( ""x.stf"" ) ) ; assertEquals ( ""application/vnd.xara"" , tika . detect ( ""x.xar"" ) ) ; assertEquals ( ""application/vnd.xfdl"" , tika . detect ( ""x.xfdl"" ) ) ; assertEquals ( ""application/vnd.yamaha.hv-dic"" , tika . detect ( ""x.hvd"" ) ) ; assertEquals ( ""application/vnd.yamaha.hv-script"" , tika . detect ( ""x.hvs"" ) ) ; assertEquals ( ""application/vnd.yamaha.hv-voice"" , tika . detect ( ""x.hvp"" ) ) ; assertEquals ( ""application/vnd.yamaha.openscoreformat"" , tika . detect ( ""x.osf"" ) ) ; assertEquals ( ""application/vnd.yamaha.openscoreformat.osfpvg+xml"" , tika . detect ( ""x.osfpvg"" ) ) ; assertEquals ( ""application/vnd.yamaha.smaf-audio"" , tika . detect ( ""x.saf"" ) ) ; assertEquals ( ""application/vnd.yamaha.smaf-phrase"" , tika . detect ( ""x.spf"" ) ) ; assertEquals ( ""application/vnd.yellowriver-custom-menu"" , tika . detect ( ""x.cmp"" ) ) ; assertEquals ( ""application/vnd.zul"" , tika . detect ( ""x.zir"" ) ) ; assertEquals ( ""application/vnd.zul"" , tika . detect ( ""x.zirz"" ) ) ; assertEquals ( ""application/vnd.zzazz.deck+xml"" , tika . detect ( ""x.zaz"" ) ) ; assertEquals ( ""application/voicexml+xml"" , tika . detect ( ""x.vxml"" ) ) ; assertEquals ( ""application/winhlp"" , tika . detect ( ""x.hlp"" ) ) ; assertEquals ( ""application/wsdl+xml"" , tika . detect ( ""x.wsdl"" ) ) ; assertEquals ( ""application/wspolicy+xml"" , tika . detect ( ""x.wspolicy"" ) ) ; assertEquals ( ""application/x-abiword"" , tika . detect ( ""x.abw"" ) ) ; assertEquals ( ""application/x-ace-compressed"" , tika . detect ( ""x.ace"" ) ) ; assertEquals ( ""application/x-authorware-bin"" , tika . detect ( ""x.aab"" ) ) ; assertEquals ( ""application/x-authorware-bin"" , tika . detect ( ""x.x32"" ) ) ; assertEquals ( ""application/x-authorware-bin"" , tika . detect ( ""x.u32"" ) ) ; assertEquals ( ""application/x-authorware-bin"" , tika . detect ( ""x.vox"" ) ) ; assertEquals ( ""application/x-authorware-map"" , tika . detect ( ""x.aam"" ) ) ; assertEquals ( ""application/x-authorware-seg"" , tika . detect ( ""x.aas"" ) ) ; assertEquals ( ""application/x-bcpio"" , tika . detect ( ""x.bcpio"" ) ) ; assertEquals ( ""application/x-bittorrent"" , tika . detect ( ""x.torrent"" ) ) ; assertEquals ( ""application/x-bzip"" , tika . detect ( ""x.bz"" ) ) ; assertEquals ( ""application/x-bzip2"" , tika . detect ( ""x.bz2"" ) ) ; assertEquals ( ""application/x-bzip2"" , tika . detect ( ""x.boz"" ) ) ; assertEquals ( ""application/x-cdlink"" , tika . detect ( ""x.vcd"" ) ) ; assertEquals ( ""application/x-chat"" , tika . detect ( ""x.chat"" ) ) ; assertEquals ( ""application/x-chess-pgn"" , tika . detect ( ""x.pgn"" ) ) ; assertEquals ( ""application/x-cpio"" , tika . detect ( ""x.cpio"" ) ) ; assertEquals ( ""application/x-csh"" , tika . detect ( ""x.csh"" ) ) ; assertEquals ( ""application/x-debian-package"" , tika . detect ( ""x.deb"" ) ) ; assertEquals ( ""application/x-debian-package"" , tika . detect ( ""x.udeb"" ) ) ; assertEquals ( ""application/x-director"" , tika . detect ( ""x.dir"" ) ) ; assertEquals ( ""application/x-director"" , tika . detect ( ""x.dcr"" ) ) ; assertEquals ( ""application/x-director"" , tika . detect ( ""x.dxr"" ) ) ; assertEquals ( ""application/x-director"" , tika . detect ( ""x.cst"" ) ) ; assertEquals ( ""application/x-director"" , tika . detect ( ""x.cct"" ) ) ; assertEquals ( ""application/x-director"" , tika . detect ( ""x.cxt"" ) ) ; assertEquals ( ""application/x-director"" , tika . detect ( ""x.w3d"" ) ) ; assertEquals ( ""application/x-director"" , tika . detect ( ""x.fgd"" ) ) ; assertEquals ( ""application/x-director"" , tika . detect ( ""x.swa"" ) ) ; assertEquals ( ""application/x-doom"" , tika . detect ( ""x.wad"" ) ) ; assertEquals ( ""application/x-dtbncx+xml"" , tika . detect ( ""x.ncx"" ) ) ; assertEquals ( ""application/x-dtbook+xml"" , tika . detect ( ""x.dtb"" ) ) ; assertEquals ( ""application/x-dtbresource+xml"" , tika . detect ( ""x.res"" ) ) ; assertEquals ( ""application/x-dvi"" , tika . detect ( ""x.dvi"" ) ) ; assertEquals ( ""application/x-font-bdf"" , tika . detect ( ""x.bdf"" ) ) ; assertEquals ( ""application/x-font-ghostscript"" , tika . detect ( ""x.gsf"" ) ) ; assertEquals ( ""application/x-font-linux-psf"" , tika . detect ( ""x.psf"" ) ) ; assertEquals ( ""application/x-font-otf"" , tika . detect ( ""x.otf"" ) ) ; assertEquals ( ""application/x-font-pcf"" , tika . detect ( ""x.pcf"" ) ) ; assertEquals ( ""application/x-font-snf"" , tika . detect ( ""x.snf"" ) ) ; assertEquals ( ""application/x-font-ttf"" , tika . detect ( ""x.ttf"" ) ) ; assertEquals ( ""application/x-font-ttf"" , tika . detect ( ""x.ttc"" ) ) ; assertEquals ( ""application/x-font-type1"" , tika . detect ( ""x.pfa"" ) ) ; assertEquals ( ""application/x-font-type1"" , tika . detect ( ""x.pfb"" ) ) ; assertEquals ( ""application/x-font-printer-metric"" , tika . detect ( ""x.pfm"" ) ) ; assertEquals ( ""application/x-font-adobe-metric"" , tika . detect ( ""x.afm"" ) ) ; assertEquals ( ""application/x-futuresplash"" , tika . detect ( ""x.spl"" ) ) ; assertEquals ( ""application/x-gnumeric"" , tika . detect ( ""x.gnumeric"" ) ) ; assertEquals ( ""application/x-gtar"" , tika . detect ( ""x.gtar"" ) ) ; assertEquals ( ""application/x-hdf"" , tika . detect ( ""x.hdf"" ) ) ; assertEquals ( ""application/x-java-jnlp-file"" , tika . detect ( ""x.jnlp"" ) ) ; assertEquals ( ""application/x-latex"" , tika . detect ( ""x.latex"" ) ) ; assertEquals ( ""application/x-mobipocket-ebook"" , tika . detect ( ""x.prc"" ) ) ; assertEquals ( ""application/x-mobipocket-ebook"" , tika . detect ( ""x.mobi"" ) ) ; assertEquals ( ""application/x-ms-application"" , tika . detect ( ""x.application"" ) ) ; assertEquals ( ""application/x-ms-wmd"" , tika . detect ( ""x.wmd"" ) ) ; assertEquals ( ""application/x-ms-wmz"" , tika . detect ( ""x.wmz"" ) ) ; assertEquals ( ""application/x-ms-xbap"" , tika . detect ( ""x.xbap"" ) ) ; assertEquals ( ""application/x-msaccess"" , tika . detect ( ""x.mdb"" ) ) ; assertEquals ( ""application/x-msbinder"" , tika . detect ( ""x.obd"" ) ) ; assertEquals ( ""application/x-mscardfile"" , tika . detect ( ""x.crd"" ) ) ; assertEquals ( ""application/x-msclip"" , tika . detect ( ""x.clp"" ) ) ; assertEquals ( ""application/x-dosexec"" , tika . detect ( ""x.exe"" ) ) ; assertEquals ( ""application/x-msdownload"" , tika . detect ( ""x.dll"" ) ) ; assertEquals ( ""application/x-msdownload"" , tika . detect ( ""x.com"" ) ) ; assertEquals ( ""application/x-msdownload"" , tika . detect ( ""x.bat"" ) ) ; assertEquals ( ""application/x-msmediaview"" , tika . detect ( ""x.mvb"" ) ) ; assertEquals ( ""application/x-msmediaview"" , tika . detect ( ""x.m13"" ) ) ; assertEquals ( ""application/x-msmediaview"" , tika . detect ( ""x.m14"" ) ) ; assertEquals ( ""application/x-msmetafile"" , tika . detect ( ""x.wmf"" ) ) ; assertEquals ( ""application/x-msmoney"" , tika . detect ( ""x.mny"" ) ) ; assertEquals ( ""application/x-mspublisher"" , tika . detect ( ""x.pub"" ) ) ; assertEquals ( ""application/x-msschedule"" , tika . detect ( ""x.scd"" ) ) ; assertEquals ( ""application/x-msterminal"" , tika . detect ( ""x.trm"" ) ) ; assertEquals ( ""application/x-mswrite"" , tika . detect ( ""x.wri"" ) ) ; assertEquals ( ""application/x-netcdf"" , tika . detect ( ""x.nc"" ) ) ; assertEquals ( ""application/x-netcdf"" , tika . detect ( ""x.cdf"" ) ) ; assertEquals ( ""application/x-pkcs12"" , tika . detect ( ""x.p12"" ) ) ; assertEquals ( ""application/x-pkcs12"" , tika . detect ( ""x.pfx"" ) ) ; assertEquals ( ""application/x-pkcs7-certificates"" , tika . detect ( ""x.p7b"" ) ) ; assertEquals ( ""application/x-pkcs7-certificates"" , tika . detect ( ""x.spc"" ) ) ; assertEquals ( ""application/x-pkcs7-certreqresp"" , tika . detect ( ""x.p7r"" ) ) ; assertEquals ( ""application/x-rar-compressed"" , tika . detect ( ""x.rar"" ) ) ; assertEquals ( ""application/x-sh"" , tika . detect ( ""x.sh"" ) ) ; assertEquals ( ""application/x-shar"" , tika . detect ( ""x.shar"" ) ) ; assertEquals ( ""application/x-shockwave-flash"" , tika . detect ( ""x.swf"" ) ) ; assertEquals ( ""application/x-silverlight-app"" , tika . detect ( ""x.xap"" ) ) ; assertEquals ( ""application/x-stuffit"" , tika . detect ( ""x.sit"" ) ) ; assertEquals ( ""application/x-stuffitx"" , tika . detect ( ""x.sitx"" ) ) ; assertEquals ( ""application/x-sv4cpio"" , tika . detect ( ""x.sv4cpio"" ) ) ; assertEquals ( ""application/x-sv4crc"" , tika . detect ( ""x.sv4crc"" ) ) ; assertEquals ( ""application/x-tar"" , tika . detect ( ""x.tar"" ) ) ; assertEquals ( ""text/x-tcl"" , tika . detect ( ""x.tcl"" ) ) ; assertEquals ( ""application/x-tex"" , tika . detect ( ""x.tex"" ) ) ; assertEquals ( ""application/x-tex-tfm"" , tika . detect ( ""x.tfm"" ) ) ; assertEquals ( ""application/x-texinfo"" , tika . detect ( ""x.texinfo"" ) ) ; assertEquals ( ""application/x-texinfo"" , tika . detect ( ""x.texi"" ) ) ; assertEquals ( ""application/x-ustar"" , tika . detect ( ""x.ustar"" ) ) ; assertEquals ( ""application/x-wais-source"" , tika . detect ( ""x.src"" ) ) ; assertEquals ( ""application/x-x509-ca-cert"" , tika . detect ( ""x.der"" ) ) ; assertEquals ( ""application/x-x509-ca-cert"" , tika . detect ( ""x.crt"" ) ) ; assertEquals ( ""application/x-xfig"" , tika . detect ( ""x.fig"" ) ) ; assertEquals ( ""application/x-xpinstall"" , tika . detect ( ""x.xpi"" ) ) ; assertEquals ( ""application/xenc+xml"" , tika . detect ( ""x.xenc"" ) ) ; assertEquals ( ""application/xhtml+xml"" , tika . detect ( ""x.xhtml"" ) ) ; assertEquals ( ""application/xhtml+xml"" , tika . detect ( ""x.xht"" ) ) ; assertEquals ( ""application/xml"" , tika . detect ( ""x.xml"" ) ) ; assertEquals ( ""application/xml"" , tika . detect ( ""x.xsl"" ) ) ; assertEquals ( ""application/xml-dtd"" , tika . detect ( ""x.dtd"" ) ) ; assertEquals ( ""application/xop+xml"" , tika . detect ( ""x.xop"" ) ) ; assertEquals ( ""application/xslt+xml"" , tika . detect ( ""x.xslt"" ) ) ; assertEquals ( ""application/xspf+xml"" , tika . detect ( ""x.xspf"" ) ) ; assertEquals ( ""application/xv+xml"" , tika . detect ( ""x.mxml"" ) ) ; assertEquals ( ""application/xv+xml"" , tika . detect ( ""x.xhvml"" ) ) ; assertEquals ( ""application/xv+xml"" , tika . detect ( ""x.xvml"" ) ) ; assertEquals ( ""application/xv+xml"" , tika . detect ( ""x.xvm"" ) ) ; assertEquals ( ""application/zip"" , tika . detect ( ""x.zip"" ) ) ; assertEquals ( ""audio/adpcm"" , tika . detect ( ""x.adp"" ) ) ; assertEquals ( ""audio/basic"" , tika . detect ( ""x.au"" ) ) ; assertEquals ( ""audio/basic"" , tika . detect ( ""x.snd"" ) ) ; assertEquals ( ""audio/midi"" , tika . detect ( ""x.mid"" ) ) ; assertEquals ( ""audio/midi"" , tika . detect ( ""x.midi"" ) ) ; assertEquals ( ""audio/midi"" , tika . detect ( ""x.kar"" ) ) ; assertEquals ( ""audio/midi"" , tika . detect ( ""x.rmi"" ) ) ; assertEquals ( ""audio/mp4"" , tika . detect ( ""x.mp4a"" ) ) ; assertEquals ( ""audio/mpeg"" , tika . detect ( ""x.mpga"" ) ) ; assertEquals ( ""audio/mpeg"" , tika . detect ( ""x.mp2"" ) ) ; assertEquals ( ""audio/mpeg"" , tika . detect ( ""x.mp2a"" ) ) ; assertEquals ( ""audio/mpeg"" , tika . detect ( ""x.mp3"" ) ) ; assertEquals ( ""audio/mpeg"" , tika . detect ( ""x.m2a"" ) ) ; assertEquals ( ""audio/mpeg"" , tika . detect ( ""x.m3a"" ) ) ; assertEquals ( ""audio/ogg"" , tika . detect ( ""x.oga"" ) ) ; assertEquals ( ""audio/vnd.digital-winds"" , tika . detect ( ""x.eol"" ) ) ; assertEquals ( ""audio/vnd.dts"" , tika . detect ( ""x.dts"" ) ) ; assertEquals ( ""audio/vnd.dts.hd"" , tika . detect ( ""x.dtshd"" ) ) ; assertEquals ( ""audio/vnd.lucent.voice"" , tika . detect ( ""x.lvp"" ) ) ; assertEquals ( ""audio/vnd.ms-playready.media.pya"" , tika . detect ( ""x.pya"" ) ) ; assertEquals ( ""audio/vnd.nuera.ecelp4800"" , tika . detect ( ""x.ecelp4800"" ) ) ; assertEquals ( ""audio/vnd.nuera.ecelp7470"" , tika . detect ( ""x.ecelp7470"" ) ) ; assertEquals ( ""audio/vnd.nuera.ecelp9600"" , tika . detect ( ""x.ecelp9600"" ) ) ; assertEquals ( ""audio/x-aac"" , tika . detect ( ""x.aac"" ) ) ; assertEquals ( ""audio/x-aiff"" , tika . detect ( ""x.aif"" ) ) ; assertEquals ( ""audio/x-aiff"" , tika . detect ( ""x.aiff"" ) ) ; assertEquals ( ""audio/x-aiff"" , tika . detect ( ""x.aifc"" ) ) ; assertEquals ( ""audio/x-mpegurl"" , tika . detect ( ""x.m3u"" ) ) ; assertEquals ( ""audio/x-ms-wax"" , tika . detect ( ""x.wax"" ) ) ; assertEquals ( ""audio/x-ms-wma"" , tika . detect ( ""x.wma"" ) ) ; assertEquals ( ""audio/x-pn-realaudio"" , tika . detect ( ""x.ram"" ) ) ; assertEquals ( ""audio/x-pn-realaudio"" , tika . detect ( ""x.ra"" ) ) ; assertEquals ( ""audio/x-pn-realaudio-plugin"" , tika . detect ( ""x.rmp"" ) ) ; assertEquals ( ""audio/x-wav"" , tika . detect ( ""x.wav"" ) ) ; assertEquals ( ""chemical/x-cdx"" , tika . detect ( ""x.cdx"" ) ) ; assertEquals ( ""chemical/x-cif"" , tika . detect ( ""x.cif"" ) ) ; assertEquals ( ""chemical/x-cmdf"" , tika . detect ( ""x.cmdf"" ) ) ; assertEquals ( ""chemical/x-cml"" , tika . detect ( ""x.cml"" ) ) ; assertEquals ( ""chemical/x-csml"" , tika . detect ( ""x.csml"" ) ) ; assertEquals ( ""chemical/x-xyz"" , tika . detect ( ""x.xyz"" ) ) ; assertEquals ( ""image/x-ms-bmp"" , tika . detect ( ""x.bmp"" ) ) ; assertEquals ( ""image/cgm"" , tika . detect ( ""x.cgm"" ) ) ; assertEquals ( ""image/g3fax"" , tika . detect ( ""x.g3"" ) ) ; assertEquals ( ""image/gif"" , tika . detect ( ""x.gif"" ) ) ; assertEquals ( ""image/ief"" , tika . detect ( ""x.ief"" ) ) ; assertEquals ( ""image/jpeg"" , tika . detect ( ""x.jpeg"" ) ) ; assertEquals ( ""image/jpeg"" , tika . detect ( ""x.jpg"" ) ) ; assertEquals ( ""image/jpeg"" , tika . detect ( ""x.jpe"" ) ) ; assertEquals ( ""image/jpm"" , tika . detect ( ""x.jpm"" ) ) ; assertEquals ( ""image/jpm"" , tika . detect ( ""x.jpgm"" ) ) ; assertEquals ( ""image/png"" , tika . detect ( ""x.png"" ) ) ; assertEquals ( ""image/prs.btif"" , tika . detect ( ""x.btif"" ) ) ; assertEquals ( ""image/svg+xml"" , tika . detect ( ""x.svg"" ) ) ; assertEquals ( ""image/svg+xml"" , tika . detect ( ""x.svgz"" ) ) ; assertEquals ( ""image/tiff"" , tika . detect ( ""x.tiff"" ) ) ; assertEquals ( ""image/tiff"" , tika . detect ( ""x.tif"" ) ) ; assertEquals ( ""image/vnd.adobe.photoshop"" , tika . detect ( ""x.psd"" ) ) ; assertEquals ( ""image/vnd.djvu"" , tika . detect ( ""x.djvu"" ) ) ; assertEquals ( ""image/vnd.djvu"" , tika . detect ( ""x.djv"" ) ) ; assertEquals ( ""image/vnd.dwg"" , tika . detect ( ""x.dwg"" ) ) ; assertEquals ( ""image/vnd.dxf"" , tika . detect ( ""x.dxf"" ) ) ; assertEquals ( ""image/vnd.fastbidsheet"" , tika . detect ( ""x.fbs"" ) ) ; assertEquals ( ""image/vnd.fpx"" , tika . detect ( ""x.fpx"" ) ) ; assertEquals ( ""image/vnd.fst"" , tika . detect ( ""x.fst"" ) ) ; assertEquals ( ""image/vnd.fujixerox.edmics-mmr"" , tika . detect ( ""x.mmr"" ) ) ; assertEquals ( ""image/vnd.fujixerox.edmics-rlc"" , tika . detect ( ""x.rlc"" ) ) ; assertEquals ( ""image/vnd.ms-modi"" , tika . detect ( ""x.mdi"" ) ) ; assertEquals ( ""image/vnd.net-fpx"" , tika . detect ( ""x.npx"" ) ) ; assertEquals ( ""image/vnd.wap.wbmp"" , tika . detect ( ""x.wbmp"" ) ) ; assertEquals ( ""image/vnd.xiff"" , tika . detect ( ""x.xif"" ) ) ; assertEquals ( ""image/x-cmu-raster"" , tika . detect ( ""x.ras"" ) ) ; assertEquals ( ""image/x-cmx"" , tika . detect ( ""x.cmx"" ) ) ; assertEquals ( ""image/x-freehand"" , tika . detect ( ""x.fh"" ) ) ; assertEquals ( ""image/x-freehand"" , tika . detect ( ""x.fhc"" ) ) ; assertEquals ( ""image/x-freehand"" , tika . detect ( ""x.fh4"" ) ) ; assertEquals ( ""image/x-freehand"" , tika . detect ( ""x.fh5"" ) ) ; assertEquals ( ""image/x-freehand"" , tika . detect ( ""x.fh7"" ) ) ; assertEquals ( ""image/x-pcx"" , tika . detect ( ""x.pcx"" ) ) ; assertEquals ( ""image/x-pict"" , tika . detect ( ""x.pic"" ) ) ; assertEquals ( ""image/x-pict"" , tika . detect ( ""x.pct"" ) ) ; assertEquals ( ""image/x-portable-anymap"" , tika . detect ( ""x.pnm"" ) ) ; assertEquals ( ""image/x-portable-bitmap"" , tika . detect ( ""x.pbm"" ) ) ; assertEquals ( ""image/x-portable-graymap"" , tika . detect ( ""x.pgm"" ) ) ; assertEquals ( ""image/x-portable-pixmap"" , tika . detect ( ""x.ppm"" ) ) ; assertEquals ( ""image/x-rgb"" , tika . detect ( ""x.rgb"" ) ) ; assertEquals ( ""image/x-xbitmap"" , tika . detect ( ""x.xbm"" ) ) ; assertEquals ( ""image/x-xpixmap"" , tika . detect ( ""x.xpm"" ) ) ; assertEquals ( ""image/x-xwindowdump"" , tika . detect ( ""x.xwd"" ) ) ; assertEquals ( ""message/rfc822"" , tika . detect ( ""x.eml"" ) ) ; assertEquals ( ""message/rfc822"" , tika . detect ( ""x.mime"" ) ) ; assertEquals ( ""model/iges"" , tika . detect ( ""x.igs"" ) ) ; assertEquals ( ""model/iges"" , tika . detect ( ""x.iges"" ) ) ; assertEquals ( ""model/mesh"" , tika . detect ( ""x.msh"" ) ) ; assertEquals ( ""model/mesh"" , tika . detect ( ""x.mesh"" ) ) ; assertEquals ( ""model/mesh"" , tika . detect ( ""x.silo"" ) ) ; assertEquals ( ""model/vnd.dwf"" , tika . detect ( ""x.dwf"" ) ) ; assertEquals ( ""model/vnd.gdl"" , tika . detect ( ""x.gdl"" ) ) ; assertEquals ( ""model/vnd.gtw"" , tika . detect ( ""x.gtw"" ) ) ; assertEquals ( ""model/vnd.mts"" , tika . detect ( ""x.mts"" ) ) ; assertEquals ( ""model/vnd.vtu"" , tika . detect ( ""x.vtu"" ) ) ; assertEquals ( ""model/vrml"" , tika . detect ( ""x.wrl"" ) ) ; assertEquals ( ""model/vrml"" , tika . detect ( ""x.vrml"" ) ) ; assertEquals ( ""text/calendar"" , tika . detect ( ""x.ics"" ) ) ; assertEquals ( ""text/calendar"" , tika . detect ( ""x.ifb"" ) ) ; assertEquals ( ""text/css"" , tika . detect ( ""x.css"" ) ) ; assertEquals ( ""text/csv"" , tika . detect ( ""x.csv"" ) ) ; assertEquals ( ""text/html"" , tika . detect ( ""x.html"" ) ) ; assertEquals ( ""text/html"" , tika . detect ( ""x.htm"" ) ) ; assertEquals ( ""text/plain"" , tika . detect ( ""x.txt"" ) ) ; assertEquals ( ""text/plain"" , tika . detect ( ""x.text"" ) ) ; assertEquals ( ""text/plain"" , tika . detect ( ""x.conf"" ) ) ; assertEquals ( ""text/plain"" , tika . detect ( ""x.def"" ) ) ; assertEquals ( ""text/plain"" , tika . detect ( ""x.list"" ) ) ; assertEquals ( ""text/x-log"" , tika . detect ( ""x.log"" ) ) ; assertEquals ( ""text/plain"" , tika . detect ( ""x.in"" ) ) ; assertEquals ( ""text/prs.lines.tag"" , tika . detect ( ""x.dsc"" ) ) ; assertEquals ( ""text/richtext"" , tika . detect ( ""x.rtx"" ) ) ; assertEquals ( ""text/sgml"" , tika . detect ( ""x.sgml"" ) ) ; assertEquals ( ""text/sgml"" , tika . detect ( ""x.sgm"" ) ) ; assertEquals ( ""text/tab-separated-values"" , tika . detect ( ""x.tsv"" ) ) ; assertEquals ( ""text/troff"" , tika . detect ( ""x.t"" ) ) ; assertEquals ( ""text/troff"" , tika . detect ( ""x.tr"" ) ) ; assertEquals ( ""text/troff"" , tika . detect ( ""x.roff"" ) ) ; assertEquals ( ""text/troff"" , tika . detect ( ""x.man"" ) ) ; assertEquals ( ""text/troff"" , tika . detect ( ""x.me"" ) ) ; assertEquals ( ""text/troff"" , tika . detect ( ""x.ms"" ) ) ; assertEquals ( ""text/uri-list"" , tika . detect ( ""x.uri"" ) ) ; assertEquals ( ""text/uri-list"" , tika . detect ( ""x.uris"" ) ) ; assertEquals ( ""text/uri-list"" , tika . detect ( ""x.urls"" ) ) ; assertEquals ( ""text/vnd.curl"" , tika . detect ( ""x.curl"" ) ) ; assertEquals ( ""text/vnd.curl.dcurl"" , tika . detect ( ""x.dcurl"" ) ) ; assertEquals ( ""text/vnd.curl.scurl"" , tika . detect ( ""x.scurl"" ) ) ; assertEquals ( ""text/vnd.curl.mcurl"" , tika . detect ( ""x.mcurl"" ) ) ; assertEquals ( ""text/vnd.fly"" , tika . detect ( ""x.fly"" ) ) ; assertEquals ( ""text/vnd.fmi.flexstor"" , tika . detect ( ""x.flx"" ) ) ; assertEquals ( ""text/vnd.graphviz"" , tika . detect ( ""x.gv"" ) ) ; assertEquals ( ""text/vnd.in3d.3dml"" , tika . detect ( ""x.3dml"" ) ) ; assertEquals ( ""text/vnd.in3d.spot"" , tika . detect ( ""x.spot"" ) ) ; assertEquals ( ""text/vnd.sun.j2me.app-descriptor"" , tika . detect ( ""x.jad"" ) ) ; assertEquals ( ""text/vnd.wap.wml"" , tika . detect ( ""x.wml"" ) ) ; assertEquals ( ""text/vnd.wap.wmlscript"" , tika . detect ( ""x.wmls"" ) ) ; assertEquals ( ""text/x-assembly"" , tika . detect ( ""x.s"" ) ) ; assertEquals ( ""text/x-assembly"" , tika . detect ( ""x.asm"" ) ) ; assertEquals ( ""text/x-csrc"" , tika . detect ( ""x.c"" ) ) ; assertEquals ( ""text/x-c++src"" , tika . detect ( ""x.cc"" ) ) ; assertEquals ( ""text/x-c++src"" , tika . detect ( ""x.cxx"" ) ) ; assertEquals ( ""text/x-c++src"" , tika . detect ( ""x.cpp"" ) ) ; assertEquals ( ""text/x-chdr"" , tika . detect ( ""x.h"" ) ) ; assertEquals ( ""text/x-c++hdr"" , tika . detect ( ""x.hh"" ) ) ; assertEquals ( ""text/x-fortran"" , tika . detect ( ""x.f"" ) ) ; assertEquals ( ""text/x-fortran"" , tika . detect ( ""x.for"" ) ) ; assertEquals ( ""text/x-fortran"" , tika . detect ( ""x.f77"" ) ) ; assertEquals ( ""text/x-fortran"" , tika . detect ( ""x.f90"" ) ) ; assertEquals ( ""text/x-pascal"" , tika . detect ( ""x.p"" ) ) ; assertEquals ( ""text/x-pascal"" , tika . detect ( ""x.pas"" ) ) ; assertEquals ( ""text/x-java-source"" , tika . detect ( ""x.java"" ) ) ; assertEquals ( ""text/x-setext"" , tika . detect ( ""x.etx"" ) ) ; assertEquals ( ""text/x-uuencode"" , tika . detect ( ""x.uu"" ) ) ; assertEquals ( ""text/x-vcalendar"" , tika . detect ( ""x.vcs"" ) ) ; assertEquals ( ""text/x-vcard"" , tika . detect ( ""x.vcf"" ) ) ; assertEquals ( ""video/3gpp"" , tika . detect ( ""x.3gp"" ) ) ; assertEquals ( ""video/3gpp2"" , tika . detect ( ""x.3g2"" ) ) ; assertEquals ( ""video/h261"" , tika . detect ( ""x.h261"" ) ) ; assertEquals ( ""video/h263"" , tika . detect ( ""x.h263"" ) ) ; assertEquals ( ""video/h264"" , tika . detect ( ""x.h264"" ) ) ; assertEquals ( ""video/jpeg"" , tika . detect ( ""x.jpgv"" ) ) ; assertEquals ( ""video/mj2"" , tika . detect ( ""x.mj2"" ) ) ; assertEquals ( ""video/mj2"" , tika . detect ( ""x.mjp2"" ) ) ; assertEquals ( ""video/mp4"" , tika . detect ( ""x.mp4"" ) ) ; assertEquals ( ""video/mp4"" , tika . detect ( ""x.mp4v"" ) ) ; assertEquals ( ""video/mp4"" , tika . detect ( ""x.mpg4"" ) ) ; assertEquals ( ""video/mpeg"" , tika . detect ( ""x.mpeg"" ) ) ; assertEquals ( ""video/mpeg"" , tika . detect ( ""x.mpg"" ) ) ; assertEquals ( ""video/mpeg"" , tika . detect ( ""x.mpe"" ) ) ; assertEquals ( ""video/mpeg"" , tika . detect ( ""x.m1v"" ) ) ; assertEquals ( ""video/mpeg"" , tika . detect ( ""x.m2v"" ) ) ; assertEquals ( ""video/ogg"" , tika . detect ( ""x.ogv"" ) ) ; assertEquals ( ""video/quicktime"" , tika . detect ( ""x.qt"" ) ) ; assertEquals ( ""video/quicktime"" , tika . detect ( ""x.mov"" ) ) ; assertEquals ( ""video/vnd.fvt"" , tika . detect ( ""x.fvt"" ) ) ; assertEquals ( ""video/vnd.mpegurl"" , tika . detect ( ""x.mxu"" ) ) ; assertEquals ( ""video/vnd.mpegurl"" , tika . detect ( ""x.m4u"" ) ) ; assertEquals ( ""video/vnd.ms-playready.media.pyv"" , tika . detect ( ""x.pyv"" ) ) ; assertEquals ( ""video/vnd.vivo"" , tika . detect ( ""x.viv"" ) ) ; assertEquals ( ""video/x-f4v"" , tika . detect ( ""x.f4v"" ) ) ; assertEquals ( ""video/x-fli"" , tika . detect ( ""x.fli"" ) ) ; assertEquals ( ""video/x-flv"" , tika . detect ( ""x.flv"" ) ) ; assertEquals ( ""video/x-m4v"" , tika . detect ( ""x.m4v"" ) ) ; assertEquals ( ""video/x-ms-asf"" , tika . detect ( ""x.asf"" ) ) ; assertEquals ( ""application/x-ms-asx"" , tika . detect ( ""x.asx"" ) ) ; assertEquals ( ""video/x-ms-wm"" , tika . detect ( ""x.wm"" ) ) ; assertEquals ( ""video/x-ms-wmv"" , tika . detect ( ""x.wmv"" ) ) ; assertEquals ( ""video/x-ms-wmx"" , tika . detect ( ""x.wmx"" ) ) ; assertEquals ( ""video/x-ms-wvx"" , tika . detect ( ""x.wvx"" ) ) ; assertEquals ( ""video/x-msvideo"" , tika . detect ( ""x.avi"" ) ) ; assertEquals ( ""video/x-sgi-movie"" , tika . detect ( ""x.movie"" ) ) ; assertEquals ( ""x-conference/x-cooltalk"" , tika . detect ( ""x.ice"" ) ) ; assertEquals ( ""application/x-grib"" , tika . detect ( ""x.grb"" ) ) ; assertEquals ( ""application/x-grib"" , tika . detect ( ""x.grb1"" ) ) ; assertEquals ( ""application/x-grib"" , tika . detect ( ""x.grb2"" ) ) ; assertEquals ( ""application/dif+xml"" , tika . detect ( ""x.dif"" ) ) ; }",Smelly
 public int getId ( ) { return 0 ; },No
" public void read ( org . apache . thrift . protocol . TProtocol prot , getFollowing_result struct ) throws org . apache . thrift . TException { TTupleProtocol iprot = ( TTupleProtocol ) prot ; BitSet incoming = iprot . readBitSet ( 1 ) ; if ( incoming . get ( 0 ) ) { struct . success = new Key ( ) ; struct . success . read ( iprot ) ; struct . setSuccessIsSet ( true ) ; } }",Smelly
" public void read ( org . apache . thrift . protocol . TProtocol prot , getFollowing_result struct ) throws org . apache . thrift . TException { TTupleProtocol iprot = ( TTupleProtocol ) prot ; BitSet incoming = iprot . readBitSet ( 1 ) ; if ( incoming . get ( 0 ) ) { struct . success = new Key ( ) ; struct . success . read ( iprot ) ; struct . setSuccessIsSet ( true ) ; } }",Smelly
" public static Map < String , Object > productImportFromSpreadsheet ( DispatchContext dctx , Map < String , ? extends Object > context ) { Delegator delegator = dctx . getDelegator ( ) ; Locale locale = ( Locale ) context . get ( ""locale"" ) ; String path = System . getProperty ( ""user.dir"" ) + ""/spreadsheet"" ; List < File > fileItems = FastList . newInstance ( ) ; if ( UtilValidate . isNotEmpty ( path ) ) { File importDir = new File ( path ) ; if ( importDir . isDirectory ( ) && importDir . canRead ( ) ) { File [ ] files = importDir . listFiles ( ) ; for ( int i = 0 ; i < files . length ; i ++ ) { if ( files [ i ] . getName ( ) . toUpperCase ( ) . endsWith ( ""XLS"" ) ) { fileItems . add ( files [ i ] ) ; } } } else { return ServiceUtil . returnError ( UtilProperties . getMessage ( resource , ""ProductProductImportDirectoryNotFound"" , locale ) ) ; } } else { return ServiceUtil . returnError ( UtilProperties . getMessage ( resource , ""ProductProductImportPathNotSpecified"" , locale ) ) ; } if ( fileItems . size ( ) < 1 ) { return ServiceUtil . returnError ( UtilProperties . getMessage ( resource , ""ProductProductImportPathNoSpreadsheetExists"" , locale ) + path ) ; } for ( File item : fileItems ) { List < Map < String , Object > > products = FastList . newInstance ( ) ; List < Map < String , Object > > inventoryItems = FastList . newInstance ( ) ; POIFSFileSystem fs = null ; HSSFWorkbook wb = null ; try { fs = new POIFSFileSystem ( new FileInputStream ( item ) ) ; wb = new HSSFWorkbook ( fs ) ; } catch ( IOException e ) { Debug . logError ( ""Unable to read or create workbook from file"" , module ) ; return ServiceUtil . returnError ( UtilProperties . getMessage ( resource , ""ProductProductImportCannotCreateWorkbookFromFile"" , locale ) ) ; } HSSFSheet sheet = wb . getSheetAt ( 0 ) ; int sheetLastRowNumber = sheet . getLastRowNum ( ) ; for ( int j = 1 ; j <= sheetLastRowNumber ; j ++ ) { HSSFRow row = sheet . getRow ( j ) ; if ( row != null ) { HSSFCell cell2 = row . getCell ( 2 ) ; cell2 . setCellType ( HSSFCell . CELL_TYPE_STRING ) ; String productId = cell2 . getRichStringCellValue ( ) . toString ( ) ; HSSFCell cell5 = row . getCell ( 5 ) ; BigDecimal quantityOnHand = BigDecimal . ZERO ; if ( cell5 != null && cell5 . getCellType ( ) == HSSFCell . CELL_TYPE_NUMERIC ) quantityOnHand = new BigDecimal ( cell5 . getNumericCellValue ( ) ) ; boolean productExists = ImportProductHelper . checkProductExists ( productId , delegator ) ; if ( productId != null && ! productId . trim ( ) . equalsIgnoreCase ( """" ) && ! productExists ) { products . add ( ImportProductHelper . prepareProduct ( productId ) ) ; if ( quantityOnHand . compareTo ( BigDecimal . ZERO ) >= 0 ) inventoryItems . add ( ImportProductHelper . prepareInventoryItem ( productId , quantityOnHand , delegator . getNextSeqId ( ""InventoryItem"" ) ) ) ; else inventoryItems . add ( ImportProductHelper . prepareInventoryItem ( productId , BigDecimal . ZERO , delegator . getNextSeqId ( ""InventoryItem"" ) ) ) ; } int rowNum = row . getRowNum ( ) + 1 ; if ( row . toString ( ) != null && ! row . toString ( ) . trim ( ) . equalsIgnoreCase ( """" ) && productExists ) { Debug . logWarning ( ""Row number "" + rowNum + "" not imported from "" + item . getName ( ) , module ) ; } } } for ( int j = 0 ; j < products . size ( ) ; j ++ ) { GenericValue productGV = delegator . makeValue ( ""Product"" , products . get ( j ) ) ; GenericValue inventoryItemGV = delegator . makeValue ( ""InventoryItem"" , inventoryItems . get ( j ) ) ; if ( ! ImportProductHelper . checkProductExists ( productGV . getString ( ""productId"" ) , delegator ) ) { try { delegator . create ( productGV ) ; delegator . create ( inventoryItemGV ) ; } catch ( GenericEntityException e ) { Debug . logError ( ""Cannot store product"" , module ) ; return ServiceUtil . returnError ( UtilProperties . getMessage ( resource , ""ProductProductImportCannotStoreProduct"" , locale ) ) ; } } } int uploadedProducts = products . size ( ) + 1 ; if ( products . size ( ) > 0 ) Debug . logInfo ( ""Uploaded "" + uploadedProducts + "" products from file "" + item . getName ( ) , module ) ; } return ServiceUtil . returnSuccess ( ) ; }",Smelly
" public void setSubjectKeyIdentifier ( byte [ ] subjectKeyIdentifier ) { setFieldAsOctets ( ExternalPrincipalIdentifierField . SUBJECT_KEY_IDENTIFIER , subjectKeyIdentifier ) ; }",No
 void setSessionState ( SessionState ss ) ;,No
" public String toString ( ) { return ""name: "" + names . get ( 0 ) + "" index: "" + indexes . get ( 0 ) + "" order: "" + sortOrder ; }",No
" private HashSet < String > getRows ( Scanner scanner ) { HashSet < String > rows = new HashSet < > ( ) ; for ( Entry < Key , Value > entry : scanner ) { rows . add ( entry . getKey ( ) . getRow ( ) . toString ( ) ) ; } return rows ; }",No
" public static void parse ( InputStream stream , ContentHandler baseHandler , Metadata metadata , ParseContext context ) throws IOException , SAXException , TikaException { Locale locale = context . get ( Locale . class , Locale . getDefault ( ) ) ; ExtractorFactory . setThreadPrefersEventExtractors ( true ) ; try { OOXMLExtractor extractor ; OPCPackage pkg ; TikaInputStream tis = TikaInputStream . cast ( stream ) ; if ( tis != null && tis . getOpenContainer ( ) instanceof OPCPackage ) { pkg = ( OPCPackage ) tis . getOpenContainer ( ) ; } else if ( tis != null && tis . hasFile ( ) ) { pkg = OPCPackage . open ( tis . getFile ( ) . getPath ( ) , PackageAccess . READ ) ; tis . setOpenContainer ( pkg ) ; } else { InputStream shield = new CloseShieldInputStream ( stream ) ; pkg = OPCPackage . open ( shield ) ; } MediaType type = ZipContainerDetector . detectOfficeOpenXML ( pkg ) ; if ( type == null || OOXMLParser . UNSUPPORTED_OOXML_TYPES . contains ( type ) ) { EmptyParser . INSTANCE . parse ( stream , baseHandler , metadata , context ) ; return ; } metadata . set ( Metadata . CONTENT_TYPE , type . toString ( ) ) ; POIXMLTextExtractor poiExtractor = ExtractorFactory . createExtractor ( pkg ) ; POIXMLDocument document = poiExtractor . getDocument ( ) ; if ( poiExtractor instanceof XSSFEventBasedExcelExtractor ) { extractor = new XSSFExcelExtractorDecorator ( context , ( XSSFEventBasedExcelExtractor ) poiExtractor , locale ) ; } else if ( document == null ) { throw new TikaException ( ""Expecting UserModel based POI OOXML extractor with a document, but none found. "" + ""The extractor returned was a "" + poiExtractor ) ; } else if ( document instanceof XMLSlideShow ) { extractor = new XSLFPowerPointExtractorDecorator ( context , ( XSLFPowerPointExtractor ) poiExtractor ) ; } else if ( document instanceof XWPFDocument ) { extractor = new XWPFWordExtractorDecorator ( context , ( XWPFWordExtractor ) poiExtractor ) ; } else { extractor = new POIXMLTextExtractorDecorator ( context , poiExtractor ) ; } extractor . getMetadataExtractor ( ) . extract ( metadata ) ; extractor . getXHTML ( baseHandler , metadata , context ) ; } catch ( IllegalArgumentException e ) { if ( e . getMessage ( ) != null && e . getMessage ( ) . startsWith ( ""No supported documents found"" ) ) { throw new TikaException ( ""TIKA-418: RuntimeException while getting content"" + "" for thmx and xps file types"" , e ) ; } else { throw new TikaException ( ""Error creating OOXML extractor"" , e ) ; } } catch ( InvalidFormatException e ) { throw new TikaException ( ""Error creating OOXML extractor"" , e ) ; } catch ( OpenXML4JException e ) { throw new TikaException ( ""Error creating OOXML extractor"" , e ) ; } catch ( XmlException e ) { throw new TikaException ( ""Error creating OOXML extractor"" , e ) ; } }",Smelly
" public void read ( org . apache . thrift . protocol . TProtocol prot , getChildDataProducts_result struct ) throws org . apache . thrift . TException { TTupleProtocol iprot = ( TTupleProtocol ) prot ; BitSet incoming = iprot . readBitSet ( 5 ) ; if ( incoming . get ( 0 ) ) { { org . apache . thrift . protocol . TList _list283 = new org . apache . thrift . protocol . TList ( org . apache . thrift . protocol . TType . STRUCT , iprot . readI32 ( ) ) ; struct . success = new ArrayList < org . apache . airavata . model . data . replica . DataProductModel > ( _list283 . size ) ; org . apache . airavata . model . data . replica . DataProductModel _elem284 ; for ( int _i285 = 0 ; _i285 < _list283 . size ; ++ _i285 ) { _elem284 = new org . apache . airavata . model . data . replica . DataProductModel ( ) ; _elem284 . read ( iprot ) ; struct . success . add ( _elem284 ) ; } } struct . setSuccessIsSet ( true ) ; } if ( incoming . get ( 1 ) ) { struct . ire = new org . apache . airavata . model . error . InvalidRequestException ( ) ; struct . ire . read ( iprot ) ; struct . setIreIsSet ( true ) ; } if ( incoming . get ( 2 ) ) { struct . ace = new org . apache . airavata . model . error . AiravataClientException ( ) ; struct . ace . read ( iprot ) ; struct . setAceIsSet ( true ) ; } if ( incoming . get ( 3 ) ) { struct . ase = new org . apache . airavata . model . error . AiravataSystemException ( ) ; struct . ase . read ( iprot ) ; struct . setAseIsSet ( true ) ; } if ( incoming . get ( 4 ) ) { struct . ae = new org . apache . airavata . model . error . AuthorizationException ( ) ; struct . ae . read ( iprot ) ; struct . setAeIsSet ( true ) ; } }",Smelly
" public void read ( org . apache . thrift . protocol . TProtocol prot , onReceivedZeppelinResource_result struct ) throws org . apache . thrift . TException { TTupleProtocol iprot = ( TTupleProtocol ) prot ; }",Smelly
 public void setDoubleField ( double doubleField ) { this . doubleField = doubleField ; },No
" public void doStart ( ) throws Exception { stopping = false ; LOG . info ( ""Attempting to acquire the exclusive lock to become the Master broker"" ) ; PreparedStatement statement = null ; while ( true ) { try { connection = dataSource . getConnection ( ) ; connection . setAutoCommit ( false ) ; String sql = statements . getLockCreateStatement ( ) ; statement = connection . prepareStatement ( sql ) ; if ( statement . getMetaData ( ) != null ) { ResultSet rs = statement . executeQuery ( ) ; rs . next ( ) ; } else { statement . execute ( ) ; } break ; } catch ( Exception e ) { if ( stopping ) { throw new Exception ( ""Cannot start broker as being asked to shut down. Interrupted attempt to acquire lock: "" + e , e ) ; } if ( exceptionHandler != null ) { try { exceptionHandler . handle ( e ) ; } catch ( Throwable handlerException ) { LOG . error ( ""The exception handler "" + exceptionHandler . getClass ( ) . getCanonicalName ( ) + "" threw this exception: "" + handlerException + "" while trying to handle this excpetion: "" + e , handlerException ) ; } } else { LOG . error ( ""Failed to acquire lock: "" + e , e ) ; } } finally { if ( null != statement ) { try { statement . close ( ) ; } catch ( SQLException e1 ) { LOG . warn ( ""Caught while closing statement: "" + e1 , e1 ) ; } statement = null ; } } LOG . debug ( ""Sleeping for "" + lockAcquireSleepInterval + "" milli(s) before trying again to get the lock..."" ) ; try { Thread . sleep ( lockAcquireSleepInterval ) ; } catch ( InterruptedException ie ) { LOG . warn ( ""Master lock retry sleep interrupted"" , ie ) ; } } LOG . info ( ""Becoming the master on dataSource: "" + dataSource ) ; }",Smelly
" public void handle ( Directory directory , Metadata metadata ) throws MetadataException { GeoLocation geoLocation = ( ( GpsDirectory ) directory ) . getGeoLocation ( ) ; if ( geoLocation != null ) { DecimalFormat geoDecimalFormat = new DecimalFormat ( GEO_DECIMAL_FORMAT_STRING , new DecimalFormatSymbols ( Locale . ENGLISH ) ) ; metadata . set ( TikaCoreProperties . LATITUDE , geoDecimalFormat . format ( geoLocation . getLatitude ( ) ) ) ; metadata . set ( TikaCoreProperties . LONGITUDE , geoDecimalFormat . format ( geoLocation . getLongitude ( ) ) ) ; } }",No
" public void read ( org . apache . thrift . protocol . TProtocol prot , Database struct ) throws org . apache . thrift . TException { TTupleProtocol iprot = ( TTupleProtocol ) prot ; BitSet incoming = iprot . readBitSet ( 7 ) ; if ( incoming . get ( 0 ) ) { struct . name = iprot . readString ( ) ; struct . setNameIsSet ( true ) ; } if ( incoming . get ( 1 ) ) { struct . description = iprot . readString ( ) ; struct . setDescriptionIsSet ( true ) ; } if ( incoming . get ( 2 ) ) { struct . locationUri = iprot . readString ( ) ; struct . setLocationUriIsSet ( true ) ; } if ( incoming . get ( 3 ) ) { { org . apache . thrift . protocol . TMap _map100 = new org . apache . thrift . protocol . TMap ( org . apache . thrift . protocol . TType . STRING , org . apache . thrift . protocol . TType . STRING , iprot . readI32 ( ) ) ; struct . parameters = new HashMap < String , String > ( 2 * _map100 . size ) ; for ( int _i101 = 0 ; _i101 < _map100 . size ; ++ _i101 ) { String _key102 ; String _val103 ; _key102 = iprot . readString ( ) ; _val103 = iprot . readString ( ) ; struct . parameters . put ( _key102 , _val103 ) ; } } struct . setParametersIsSet ( true ) ; } if ( incoming . get ( 4 ) ) { struct . privileges = new PrincipalPrivilegeSet ( ) ; struct . privileges . read ( iprot ) ; struct . setPrivilegesIsSet ( true ) ; } if ( incoming . get ( 5 ) ) { struct . ownerName = iprot . readString ( ) ; struct . setOwnerNameIsSet ( true ) ; } if ( incoming . get ( 6 ) ) { struct . ownerType = PrincipalType . findByValue ( iprot . readI32 ( ) ) ; struct . setOwnerTypeIsSet ( true ) ; } }",No
" public void testStringHashStringRangeDeleteThrowsRuntimeException ( ) { final DynamoDB mockDynamoDB = new DynamoDB ( Regions . AP_NORTHEAST_1 ) { @ Override public BatchWriteItemOutcome batchWriteItem ( TableWriteItems ... tableWriteItems ) { throw new RuntimeException ( ""runtimeException"" ) ; } } ; deleteDynamoDB = new DeleteDynamoDB ( ) { @ Override protected DynamoDB getDynamoDB ( ) { return mockDynamoDB ; } } ; final TestRunner deleteRunner = TestRunners . newTestRunner ( deleteDynamoDB ) ; deleteRunner . setProperty ( AbstractDynamoDBProcessor . ACCESS_KEY , ""abcd"" ) ; deleteRunner . setProperty ( AbstractDynamoDBProcessor . SECRET_KEY , ""cdef"" ) ; deleteRunner . setProperty ( AbstractDynamoDBProcessor . REGION , REGION ) ; deleteRunner . setProperty ( AbstractDynamoDBProcessor . TABLE , stringHashStringRangeTableName ) ; deleteRunner . setProperty ( AbstractDynamoDBProcessor . HASH_KEY_NAME , ""hashS"" ) ; deleteRunner . setProperty ( AbstractDynamoDBProcessor . HASH_KEY_VALUE , ""h1"" ) ; deleteRunner . setProperty ( AbstractDynamoDBProcessor . RANGE_KEY_NAME , ""rangeS"" ) ; deleteRunner . setProperty ( AbstractDynamoDBProcessor . RANGE_KEY_VALUE , ""r1"" ) ; deleteRunner . enqueue ( new byte [ ] { } ) ; deleteRunner . run ( 1 ) ; deleteRunner . assertAllFlowFilesTransferred ( AbstractDynamoDBProcessor . REL_FAILURE , 1 ) ; List < MockFlowFile > flowFiles = deleteRunner . getFlowFilesForRelationship ( AbstractDynamoDBProcessor . REL_FAILURE ) ; for ( MockFlowFile flowFile : flowFiles ) { assertEquals ( ""runtimeException"" , flowFile . getAttribute ( AbstractDynamoDBProcessor . DYNAMODB_ERROR_EXCEPTION_MESSAGE ) ) ; } }",No
" public static char toLowerCase ( char letter , char [ ] charset ) { if ( charset == UnicodeGreek ) { if ( letter >= '\u03B1' && letter <= '\u03C9' ) { if ( letter == '\u03C2' ) { return '\u03C3' ; } else { return letter ; } } if ( letter == '\u03AC' ) { return '\u03B1' ; } if ( letter == '\u03AD' ) { return '\u03B5' ; } if ( letter == '\u03AE' ) { return '\u03B7' ; } if ( letter == '\u03AF' || letter == '\u03CA' || letter == '\u0390' ) { return '\u03B9' ; } if ( letter == '\u03CD' || letter == '\u03CB' || letter == '\u03B0' ) { return '\u03C5' ; } if ( letter == '\u03CC' ) { return '\u03BF' ; } if ( letter == '\u03CE' ) { return '\u03C9' ; } if ( letter >= '\u0391' && letter <= '\u03A9' ) { return ( char ) ( letter + 32 ) ; } if ( letter == '\u0386' ) { return '\u03B1' ; } if ( letter == '\u0388' ) { return '\u03B5' ; } if ( letter == '\u0389' ) { return '\u03B7' ; } if ( letter == '\u038A' || letter == '\u03AA' ) { return '\u03B9' ; } if ( letter == '\u038E' || letter == '\u03AB' ) { return '\u03C5' ; } if ( letter == '\u038C' ) { return '\u03BF' ; } if ( letter == '\u038F' ) { return '\u03C9' ; } } else if ( charset == ISO ) { if ( letter >= 0xe1 && letter <= 0xf9 ) { if ( letter == 0xf2 ) { return 0xf3 ; } else { return letter ; } } if ( letter == 0xdc ) { return 0xe1 ; } if ( letter == 0xdd ) { return 0xe5 ; } if ( letter == 0xde ) { return 0xe7 ; } if ( letter == 0xdf || letter == 0xfa || letter == 0xc0 ) { return '\u03B9' ; } if ( letter == 0xfd || letter == 0xfb || letter == 0xe0 ) { return 0xf5 ; } if ( letter == 0xfc ) { return 0xef ; } if ( letter == 0xfe ) { return 0xf9 ; } if ( letter >= 0xc1 && letter <= 0xd9 ) { return ( char ) ( letter + 32 ) ; } if ( letter == 0xb6 ) { return 0xe1 ; } if ( letter == 0xb8 ) { return 0xe5 ; } if ( letter == 0xb9 ) { return 0xe7 ; } if ( letter == 0xba || letter == 0xda ) { return 0xe9 ; } if ( letter == 0xbe || letter == 0xdb ) { return 0xf5 ; } if ( letter == 0xbc ) { return 0xef ; } if ( letter == 0xbf ) { return 0xf9 ; } } else if ( charset == CP1253 ) { if ( letter >= 0xe1 && letter <= 0xf9 ) { if ( letter == 0xf2 ) { return 0xf3 ; } else { return letter ; } } if ( letter == 0xdc ) { return 0xe1 ; } if ( letter == 0xdd ) { return 0xe5 ; } if ( letter == 0xde ) { return 0xe7 ; } if ( letter == 0xdf || letter == 0xfa || letter == 0xc0 ) { return '\u03B9' ; } if ( letter == 0xfd || letter == 0xfb || letter == 0xe0 ) { return 0xf5 ; } if ( letter == 0xfc ) { return 0xef ; } if ( letter == 0xfe ) { return 0xf9 ; } if ( letter >= 0xc1 && letter <= 0xd9 ) { return ( char ) ( letter + 32 ) ; } if ( letter == 0xa2 ) { return 0xe1 ; } if ( letter == 0xb8 ) { return 0xe5 ; } if ( letter == 0xb9 ) { return 0xe7 ; } if ( letter == 0xba || letter == 0xda ) { return 0xe9 ; } if ( letter == 0xbe || letter == 0xdb ) { return 0xf5 ; } if ( letter == 0xbc ) { return 0xef ; } if ( letter == 0xbf ) { return 0xf9 ; } } return Character . toLowerCase ( letter ) ; }",Smelly
 void elementVisited ( Element < T > element ) ;,No
" protected abstract void consumeHandshake ( ChannelHandlerContext ctx , T msg ) throws Exception ;",No
" public static void initMRJob ( Path crawlDb , Path linkDb , Collection < Path > segments , Job job , boolean addBinaryContent ) throws IOException { LOG . info ( ""IndexerMapReduce: crawldb: {}"" , crawlDb ) ; if ( linkDb != null ) LOG . info ( ""IndexerMapReduce: linkdb: {}"" , linkDb ) ; Configuration conf = job . getConfiguration ( ) ; for ( final Path segment : segments ) { LOG . info ( ""IndexerMapReduces: adding segment: {}"" , segment ) ; FileInputFormat . addInputPath ( job , new Path ( segment , CrawlDatum . FETCH_DIR_NAME ) ) ; FileInputFormat . addInputPath ( job , new Path ( segment , CrawlDatum . PARSE_DIR_NAME ) ) ; FileInputFormat . addInputPath ( job , new Path ( segment , ParseData . DIR_NAME ) ) ; FileInputFormat . addInputPath ( job , new Path ( segment , ParseText . DIR_NAME ) ) ; if ( addBinaryContent ) { FileInputFormat . addInputPath ( job , new Path ( segment , Content . DIR_NAME ) ) ; } } FileInputFormat . addInputPath ( job , new Path ( crawlDb , CrawlDb . CURRENT_NAME ) ) ; if ( linkDb != null ) { Path currentLinkDb = new Path ( linkDb , LinkDb . CURRENT_NAME ) ; try { if ( currentLinkDb . getFileSystem ( conf ) . exists ( currentLinkDb ) ) { FileInputFormat . addInputPath ( job , currentLinkDb ) ; } else { LOG . warn ( ""Ignoring linkDb for indexing, no linkDb found in path: {}"" , linkDb ) ; } } catch ( IOException e ) { LOG . warn ( ""Failed to use linkDb ({}) for indexing: {}"" , linkDb , org . apache . hadoop . util . StringUtils . stringifyException ( e ) ) ; } } job . setInputFormatClass ( SequenceFileInputFormat . class ) ; job . setJarByClass ( IndexerMapReduce . class ) ; job . setMapperClass ( IndexerMapReduce . IndexerMapper . class ) ; job . setReducerClass ( IndexerMapReduce . IndexerReducer . class ) ; job . setOutputFormatClass ( IndexerOutputFormat . class ) ; job . setOutputKeyClass ( Text . class ) ; job . setMapOutputValueClass ( NutchWritable . class ) ; job . setOutputValueClass ( NutchWritable . class ) ; }",Smelly
" static String add_escapes ( String str ) { StringBuffer retval = new StringBuffer ( ) ; char ch ; for ( int i = 0 ; i < str . length ( ) ; i ++ ) { switch ( str . charAt ( i ) ) { case 0 : continue ; case '\b' : retval . append ( ""\\b"" ) ; continue ; case '\t' : retval . append ( ""\\t"" ) ; continue ; case '\n' : retval . append ( ""\\n"" ) ; continue ; case '\f' : retval . append ( ""\\f"" ) ; continue ; case '\r' : retval . append ( ""\\r"" ) ; continue ; case '\""' : retval . append ( ""\\\"""" ) ; continue ; case '\'' : retval . append ( ""\\\'"" ) ; continue ; case '\\' : retval . append ( ""\\\\"" ) ; continue ; default : if ( ( ch = str . charAt ( i ) ) < 0x20 || ch > 0x7e ) { String s = ""0000"" + Integer . toString ( ch , 16 ) ; retval . append ( ""\\u"" + s . substring ( s . length ( ) - 4 , s . length ( ) ) ) ; } else { retval . append ( ch ) ; } continue ; } } return retval . toString ( ) ; }",Smelly
 public String getMessage ( ) { return this . message ; },No
 long next ( ) throws IOException ;,No
" public void read ( org . apache . thrift . protocol . TProtocol prot , MultiScanResult struct ) throws org . apache . thrift . TException { TTupleProtocol iprot = ( TTupleProtocol ) prot ; BitSet incoming = iprot . readBitSet ( 7 ) ; if ( incoming . get ( 0 ) ) { { org . apache . thrift . protocol . TList _list45 = new org . apache . thrift . protocol . TList ( org . apache . thrift . protocol . TType . STRUCT , iprot . readI32 ( ) ) ; struct . results = new ArrayList < TKeyValue > ( _list45 . size ) ; for ( int _i46 = 0 ; _i46 < _list45 . size ; ++ _i46 ) { TKeyValue _elem47 ; _elem47 = new TKeyValue ( ) ; _elem47 . read ( iprot ) ; struct . results . add ( _elem47 ) ; } } struct . setResultsIsSet ( true ) ; } if ( incoming . get ( 1 ) ) { { org . apache . thrift . protocol . TMap _map48 = new org . apache . thrift . protocol . TMap ( org . apache . thrift . protocol . TType . STRUCT , org . apache . thrift . protocol . TType . LIST , iprot . readI32 ( ) ) ; struct . failures = new HashMap < TKeyExtent , List < TRange > > ( 2 * _map48 . size ) ; for ( int _i49 = 0 ; _i49 < _map48 . size ; ++ _i49 ) { TKeyExtent _key50 ; List < TRange > _val51 ; _key50 = new TKeyExtent ( ) ; _key50 . read ( iprot ) ; { org . apache . thrift . protocol . TList _list52 = new org . apache . thrift . protocol . TList ( org . apache . thrift . protocol . TType . STRUCT , iprot . readI32 ( ) ) ; _val51 = new ArrayList < TRange > ( _list52 . size ) ; for ( int _i53 = 0 ; _i53 < _list52 . size ; ++ _i53 ) { TRange _elem54 ; _elem54 = new TRange ( ) ; _elem54 . read ( iprot ) ; _val51 . add ( _elem54 ) ; } } struct . failures . put ( _key50 , _val51 ) ; } } struct . setFailuresIsSet ( true ) ; } if ( incoming . get ( 2 ) ) { { org . apache . thrift . protocol . TList _list55 = new org . apache . thrift . protocol . TList ( org . apache . thrift . protocol . TType . STRUCT , iprot . readI32 ( ) ) ; struct . fullScans = new ArrayList < TKeyExtent > ( _list55 . size ) ; for ( int _i56 = 0 ; _i56 < _list55 . size ; ++ _i56 ) { TKeyExtent _elem57 ; _elem57 = new TKeyExtent ( ) ; _elem57 . read ( iprot ) ; struct . fullScans . add ( _elem57 ) ; } } struct . setFullScansIsSet ( true ) ; } if ( incoming . get ( 3 ) ) { struct . partScan = new TKeyExtent ( ) ; struct . partScan . read ( iprot ) ; struct . setPartScanIsSet ( true ) ; } if ( incoming . get ( 4 ) ) { struct . partNextKey = new TKey ( ) ; struct . partNextKey . read ( iprot ) ; struct . setPartNextKeyIsSet ( true ) ; } if ( incoming . get ( 5 ) ) { struct . partNextKeyInclusive = iprot . readBool ( ) ; struct . setPartNextKeyInclusiveIsSet ( true ) ; } if ( incoming . get ( 6 ) ) { struct . more = iprot . readBool ( ) ; struct . setMoreIsSet ( true ) ; } }",Smelly
" public static void main ( String [ ] args ) { String destinationName = null ; Context jndiContext = null ; ConnectionFactory connectionFactory = null ; Connection connection = null ; Session session = null ; Destination destination = null ; MessageConsumer consumer = null ; if ( args . length != 1 ) { LOG . info ( ""Usage: java SimpleConsumer <destination-name>"" ) ; System . exit ( 1 ) ; } destinationName = args [ 0 ] ; LOG . info ( ""Destination name is "" + destinationName ) ; try { jndiContext = new InitialContext ( ) ; } catch ( NamingException e ) { LOG . info ( ""Could not create JNDI API "" + ""context: "" + e . toString ( ) ) ; System . exit ( 1 ) ; } try { connectionFactory = ( ConnectionFactory ) jndiContext . lookup ( ""ConnectionFactory"" ) ; destination = ( Destination ) jndiContext . lookup ( destinationName ) ; } catch ( NamingException e ) { LOG . info ( ""JNDI API lookup failed: "" + e . toString ( ) ) ; System . exit ( 1 ) ; } try { connection = connectionFactory . createConnection ( ) ; session = connection . createSession ( false , Session . AUTO_ACKNOWLEDGE ) ; consumer = session . createConsumer ( destination ) ; connection . start ( ) ; while ( true ) { Message m = consumer . receive ( 1 ) ; if ( m != null ) { if ( m instanceof TextMessage ) { TextMessage message = ( TextMessage ) m ; LOG . info ( ""Reading message: "" + message . getText ( ) ) ; } else { break ; } } } } catch ( JMSException e ) { LOG . info ( ""Exception occurred: "" + e ) ; } finally { if ( connection != null ) { try { connection . close ( ) ; } catch ( JMSException e ) { } } } }",Smelly
" public Object execute ( ) throws Exception { ShellTable table = new ShellTable ( ) ; table . column ( ""Message ID"" ) ; table . column ( ""Content"" ) . maxSize ( 80 ) ; table . column ( ""Charset"" ) ; table . column ( ""Type"" ) ; table . column ( ""Correlation ID"" ) ; table . column ( ""Delivery Mode"" ) ; table . column ( ""Destination"" ) ; table . column ( ""Expiration"" ) ; table . column ( ""Priority"" ) ; table . column ( ""Redelivered"" ) ; table . column ( ""ReplyTo"" ) ; table . column ( ""Timestamp"" ) ; if ( verbose ) { table . column ( ""Properties"" ) ; } List < JmsMessage > messages = getJmsService ( ) . browse ( connectionFactory , queue , selector , username , password ) ; for ( JmsMessage message : messages ) { if ( verbose ) { StringBuilder properties = new StringBuilder ( ) ; for ( String property : message . getProperties ( ) . keySet ( ) ) { properties . append ( property ) . append ( ""="" ) . append ( message . getProperties ( ) . get ( property ) ) . append ( ""\n"" ) ; } table . addRow ( ) . addContent ( message . getMessageId ( ) , message . getContent ( ) , message . getCharset ( ) , message . getType ( ) , message . getCorrelationID ( ) , message . getDeliveryMode ( ) , message . getDestination ( ) , message . getExpiration ( ) , message . getPriority ( ) , message . isRedelivered ( ) , message . getReplyTo ( ) , message . getTimestamp ( ) , properties . toString ( ) ) ; } else { table . addRow ( ) . addContent ( message . getMessageId ( ) , message . getContent ( ) , message . getCharset ( ) , message . getType ( ) , message . getCorrelationID ( ) , message . getDeliveryMode ( ) , message . getDestination ( ) , message . getExpiration ( ) , message . getPriority ( ) , message . isRedelivered ( ) , message . getReplyTo ( ) , message . getTimestamp ( ) ) ; } } table . print ( System . out ) ; return null ; }",No
" public void read ( org . apache . thrift . protocol . TProtocol prot , getChildDataProducts_result struct ) throws org . apache . thrift . TException { TTupleProtocol iprot = ( TTupleProtocol ) prot ; BitSet incoming = iprot . readBitSet ( 5 ) ; if ( incoming . get ( 0 ) ) { { org . apache . thrift . protocol . TList _list283 = new org . apache . thrift . protocol . TList ( org . apache . thrift . protocol . TType . STRUCT , iprot . readI32 ( ) ) ; struct . success = new ArrayList < org . apache . airavata . model . data . replica . DataProductModel > ( _list283 . size ) ; org . apache . airavata . model . data . replica . DataProductModel _elem284 ; for ( int _i285 = 0 ; _i285 < _list283 . size ; ++ _i285 ) { _elem284 = new org . apache . airavata . model . data . replica . DataProductModel ( ) ; _elem284 . read ( iprot ) ; struct . success . add ( _elem284 ) ; } } struct . setSuccessIsSet ( true ) ; } if ( incoming . get ( 1 ) ) { struct . ire = new org . apache . airavata . model . error . InvalidRequestException ( ) ; struct . ire . read ( iprot ) ; struct . setIreIsSet ( true ) ; } if ( incoming . get ( 2 ) ) { struct . ace = new org . apache . airavata . model . error . AiravataClientException ( ) ; struct . ace . read ( iprot ) ; struct . setAceIsSet ( true ) ; } if ( incoming . get ( 3 ) ) { struct . ase = new org . apache . airavata . model . error . AiravataSystemException ( ) ; struct . ase . read ( iprot ) ; struct . setAseIsSet ( true ) ; } if ( incoming . get ( 4 ) ) { struct . ae = new org . apache . airavata . model . error . AuthorizationException ( ) ; struct . ae . read ( iprot ) ; struct . setAeIsSet ( true ) ; } }",Smelly
" public Map getRequestProperties ( PortletWindow window , HttpServletRequest request ) { return Collections . EMPTY_MAP ; }",No
" public void doGet ( HttpServletRequest request , HttpServletResponse response ) throws ServletException , IOException { boolean admin = false ; WeblogRequest weblogRequest = null ; try { weblogRequest = new WeblogRequest ( request ) ; User user = weblogRequest . getUser ( ) ; if ( user == null ) { response . sendError ( HttpServletResponse . SC_NOT_FOUND ) ; return ; } else if ( user . hasGlobalPermission ( ""admin"" ) ) { admin = true ; } } catch ( Exception e ) { response . sendError ( HttpServletResponse . SC_NOT_FOUND ) ; return ; } String startsWith = request . getParameter ( ""startsWith"" ) ; Boolean enabledOnly = null ; int offset = 0 ; int length = MAX_LENGTH ; if ( ""true"" . equals ( request . getParameter ( ""enabled"" ) ) ) { enabledOnly = Boolean . TRUE ; } if ( ""false"" . equals ( request . getParameter ( ""enabled"" ) ) ) { enabledOnly = Boolean . FALSE ; } try { offset = Integer . parseInt ( request . getParameter ( ""offset"" ) ) ; } catch ( Exception ignored ) { } try { length = Integer . parseInt ( request . getParameter ( ""length"" ) ) ; } catch ( Exception ignored ) { } Weblogger roller = WebloggerFactory . getWeblogger ( ) ; try { UserManager umgr = roller . getUserManager ( ) ; List < User > users = umgr . getUsersStartingWith ( startsWith , enabledOnly , offset , length ) ; for ( User user : users ) { response . getWriter ( ) . print ( user . getUserName ( ) ) ; if ( admin ) { response . getWriter ( ) . print ( "","" ) ; response . getWriter ( ) . println ( user . getEmailAddress ( ) ) ; } else { response . getWriter ( ) . print ( "","" ) ; response . getWriter ( ) . println ( user . getScreenName ( ) ) ; } } response . flushBuffer ( ) ; } catch ( WebloggerException e ) { throw new ServletException ( e . getMessage ( ) ) ; } }",Smelly
 private static < S extends org . apache . thrift . scheme . IScheme > S scheme ( org . apache . thrift . protocol . TProtocol proto ) { return ( org . apache . thrift . scheme . StandardScheme . class . equals ( proto . getScheme ( ) ) ? STANDARD_SCHEME_FACTORY : TUPLE_SCHEME_FACTORY ) . getScheme ( ) ; },Smelly
 public abstract void handleValueChangedEvent ( ValueChangedEvent valueChangedEvent ) ;,No
" public boolean isUserInRole ( String role ) { return ""testRole"" . equals ( role ) ; }",No
 private Object readResolve ( ) { return INSTANCE ; },No
" private static Void containsSingleIterable ( Collection < POJO > expected , Iterable < Iterable < POJO > > actual ) { POJO [ ] values = expected . toArray ( new POJO [ 0 ] ) ; assertThat ( actual , containsInAnyOrder ( containsInAnyOrder ( values ) ) ) ; return null ; }",No
 private static < S extends org . apache . thrift . scheme . IScheme > S scheme ( org . apache . thrift . protocol . TProtocol proto ) { return ( org . apache . thrift . scheme . StandardScheme . class . equals ( proto . getScheme ( ) ) ? STANDARD_SCHEME_FACTORY : TUPLE_SCHEME_FACTORY ) . getScheme ( ) ; },Smelly
" T anonymize ( T data , State state ) ;",No
" public void read ( org . apache . thrift . protocol . TProtocol prot , getChildDataProducts_result struct ) throws org . apache . thrift . TException { TTupleProtocol iprot = ( TTupleProtocol ) prot ; BitSet incoming = iprot . readBitSet ( 5 ) ; if ( incoming . get ( 0 ) ) { { org . apache . thrift . protocol . TList _list283 = new org . apache . thrift . protocol . TList ( org . apache . thrift . protocol . TType . STRUCT , iprot . readI32 ( ) ) ; struct . success = new ArrayList < org . apache . airavata . model . data . replica . DataProductModel > ( _list283 . size ) ; org . apache . airavata . model . data . replica . DataProductModel _elem284 ; for ( int _i285 = 0 ; _i285 < _list283 . size ; ++ _i285 ) { _elem284 = new org . apache . airavata . model . data . replica . DataProductModel ( ) ; _elem284 . read ( iprot ) ; struct . success . add ( _elem284 ) ; } } struct . setSuccessIsSet ( true ) ; } if ( incoming . get ( 1 ) ) { struct . ire = new org . apache . airavata . model . error . InvalidRequestException ( ) ; struct . ire . read ( iprot ) ; struct . setIreIsSet ( true ) ; } if ( incoming . get ( 2 ) ) { struct . ace = new org . apache . airavata . model . error . AiravataClientException ( ) ; struct . ace . read ( iprot ) ; struct . setAceIsSet ( true ) ; } if ( incoming . get ( 3 ) ) { struct . ase = new org . apache . airavata . model . error . AiravataSystemException ( ) ; struct . ase . read ( iprot ) ; struct . setAseIsSet ( true ) ; } if ( incoming . get ( 4 ) ) { struct . ae = new org . apache . airavata . model . error . AuthorizationException ( ) ; struct . ae . read ( iprot ) ; struct . setAeIsSet ( true ) ; } }",Smelly
" public void read ( org . apache . thrift . protocol . TProtocol prot , CertificateCredential struct ) throws org . apache . thrift . TException { TTupleProtocol iprot = ( TTupleProtocol ) prot ; struct . communityUser = new CommunityUser ( ) ; struct . communityUser . read ( iprot ) ; struct . setCommunityUserIsSet ( true ) ; struct . x509Cert = iprot . readString ( ) ; struct . setX509CertIsSet ( true ) ; BitSet incoming = iprot . readBitSet ( 6 ) ; if ( incoming . get ( 0 ) ) { struct . notAfter = iprot . readString ( ) ; struct . setNotAfterIsSet ( true ) ; } if ( incoming . get ( 1 ) ) { struct . privateKey = iprot . readString ( ) ; struct . setPrivateKeyIsSet ( true ) ; } if ( incoming . get ( 2 ) ) { struct . lifeTime = iprot . readI64 ( ) ; struct . setLifeTimeIsSet ( true ) ; } if ( incoming . get ( 3 ) ) { struct . notBefore = iprot . readString ( ) ; struct . setNotBeforeIsSet ( true ) ; } if ( incoming . get ( 4 ) ) { struct . persistedTime = iprot . readI64 ( ) ; struct . setPersistedTimeIsSet ( true ) ; } if ( incoming . get ( 5 ) ) { struct . token = iprot . readString ( ) ; struct . setTokenIsSet ( true ) ; } }",Smelly
" public void read ( org . apache . thrift . protocol . TProtocol prot , RDF_BNode struct ) throws org . apache . thrift . TException { TTupleProtocol iprot = ( TTupleProtocol ) prot ; struct . label = iprot . readString ( ) ; struct . setLabelIsSet ( true ) ; }",No
 private static < S extends org . apache . thrift . scheme . IScheme > S scheme ( org . apache . thrift . protocol . TProtocol proto ) { return ( org . apache . thrift . scheme . StandardScheme . class . equals ( proto . getScheme ( ) ) ? STANDARD_SCHEME_FACTORY : TUPLE_SCHEME_FACTORY ) . getScheme ( ) ; },Smelly
" RexNode convertSubQuery ( SqlCall subQuery , SqlToRelConverter parentConverter , boolean isExists , boolean isExplain ) ;",No
" public void read ( org . apache . thrift . protocol . TProtocol prot , show_compact_result struct ) throws org . apache . thrift . TException { TTupleProtocol iprot = ( TTupleProtocol ) prot ; BitSet incoming = iprot . readBitSet ( 1 ) ; if ( incoming . get ( 0 ) ) { struct . success = new ShowCompactResponse ( ) ; struct . success . read ( iprot ) ; struct . setSuccessIsSet ( true ) ; } }",Smelly
" public void read ( org . apache . thrift . protocol . TProtocol prot , getChildDataProducts_result struct ) throws org . apache . thrift . TException { TTupleProtocol iprot = ( TTupleProtocol ) prot ; BitSet incoming = iprot . readBitSet ( 5 ) ; if ( incoming . get ( 0 ) ) { { org . apache . thrift . protocol . TList _list283 = new org . apache . thrift . protocol . TList ( org . apache . thrift . protocol . TType . STRUCT , iprot . readI32 ( ) ) ; struct . success = new ArrayList < org . apache . airavata . model . data . replica . DataProductModel > ( _list283 . size ) ; org . apache . airavata . model . data . replica . DataProductModel _elem284 ; for ( int _i285 = 0 ; _i285 < _list283 . size ; ++ _i285 ) { _elem284 = new org . apache . airavata . model . data . replica . DataProductModel ( ) ; _elem284 . read ( iprot ) ; struct . success . add ( _elem284 ) ; } } struct . setSuccessIsSet ( true ) ; } if ( incoming . get ( 1 ) ) { struct . ire = new org . apache . airavata . model . error . InvalidRequestException ( ) ; struct . ire . read ( iprot ) ; struct . setIreIsSet ( true ) ; } if ( incoming . get ( 2 ) ) { struct . ace = new org . apache . airavata . model . error . AiravataClientException ( ) ; struct . ace . read ( iprot ) ; struct . setAceIsSet ( true ) ; } if ( incoming . get ( 3 ) ) { struct . ase = new org . apache . airavata . model . error . AiravataSystemException ( ) ; struct . ase . read ( iprot ) ; struct . setAseIsSet ( true ) ; } if ( incoming . get ( 4 ) ) { struct . ae = new org . apache . airavata . model . error . AuthorizationException ( ) ; struct . ae . read ( iprot ) ; struct . setAeIsSet ( true ) ; } }",Smelly
 public void close ( ) throws IOException { if ( conn != null ) { conn . close ( ) ; } },Smelly
" public static Map < String , Object > createSubContent ( int index , String line , String rootContent , Map < String , ? extends Object > context , DispatchContext dctx ) { Delegator delegator = dctx . getDelegator ( ) ; LocalDispatcher dispatcher = dctx . getDispatcher ( ) ; GenericValue userLogin = ( GenericValue ) context . get ( ""userLogin"" ) ; String subContents = null , check = "","" , oldChar = ""\"""" , newChar = """" , contentNameInprogress = """" , contentName = """" , contentId = null ; GenericValue Entity = null ; String errMsg = """" , sucMsg = """" ; subContents = line . substring ( index + 1 , line . length ( ) ) ; subContents = subContents . replace ( oldChar , newChar ) ; int size = subContents . length ( ) ; try { for ( index = 0 ; index < size ; index ++ ) { boolean contentNameMatch = false ; if ( subContents . charAt ( index ) == check . charAt ( 0 ) ) { contentName = contentName + contentNameInprogress ; if ( contentName . length ( ) > 100 ) { contentName = contentName . substring ( 0 , 100 ) ; } List < GenericValue > contents = delegator . findByAnd ( ""Content"" , UtilMisc . toMap ( ""contentName"" , contentName ) , UtilMisc . toList ( ""-contentId"" ) , false ) ; if ( contents != null ) { Iterator < GenericValue > contentCheck = contents . iterator ( ) ; while ( contentCheck . hasNext ( ) && contentNameMatch == false ) { GenericValue contentch = contentCheck . next ( ) ; if ( contentch != null ) { List < GenericValue > contentAssocsChecks = delegator . findByAnd ( ""ContentAssoc"" , UtilMisc . toMap ( ""contentId"" , contentch . get ( ""contentId"" ) , ""contentIdTo"" , rootContent ) , null , false ) ; if ( contentAssocsChecks . size ( ) > 0 ) { contentNameMatch = true ; } } } } contentId = null ; if ( contentNameMatch == false ) { Map < String , Object > data = FastMap . newInstance ( ) ; data . put ( ""userLogin"" , userLogin ) ; String dataResourceId = dispatcher . runSync ( ""createDataResource"" , data ) . get ( ""dataResourceId"" ) . toString ( ) ; contentId = delegator . getNextSeqId ( ""Content"" ) ; Entity = null ; Entity = delegator . makeValue ( ""Content"" ) ; Entity . set ( ""contentId"" , contentId ) ; Entity . set ( ""contentName"" , contentName ) ; Entity . set ( ""contentTypeId"" , ""DOCUMENT"" ) ; Entity . set ( ""dataResourceId"" , dataResourceId ) ; Entity . set ( ""createdByUserLogin"" , userLogin . get ( ""userLoginId"" ) ) ; Entity . set ( ""lastModifiedByUserLogin"" , userLogin . get ( ""userLoginId"" ) ) ; Entity . set ( ""createdDate"" , UtilDateTime . nowTimestamp ( ) ) ; Entity . set ( ""lastUpdatedStamp"" , UtilDateTime . nowTimestamp ( ) ) ; Entity . set ( ""lastUpdatedTxStamp"" , UtilDateTime . nowTimestamp ( ) ) ; Entity . set ( ""createdStamp"" , UtilDateTime . nowTimestamp ( ) ) ; Entity . set ( ""createdTxStamp"" , UtilDateTime . nowTimestamp ( ) ) ; delegator . create ( Entity ) ; Map < String , Object > contentAssoc = FastMap . newInstance ( ) ; contentAssoc . put ( ""contentId"" , contentId ) ; contentAssoc . put ( ""contentAssocTypeId"" , ""SUB_CONTENT"" ) ; contentAssoc . put ( ""contentIdTo"" , rootContent ) ; contentAssoc . put ( ""userLogin"" , userLogin ) ; dispatcher . runSync ( ""createContentAssoc"" , contentAssoc ) ; } contentName = """" ; contentNameInprogress = """" ; } if ( ( subContents . charAt ( index ) ) != check . charAt ( 0 ) ) { contentNameInprogress = contentNameInprogress . concat ( Character . toString ( subContents . charAt ( index ) ) ) ; if ( contentNameInprogress . length ( ) > 99 ) { contentName = contentName + contentNameInprogress ; contentNameInprogress = """" ; } } if ( index == size - 1 ) { contentNameMatch = false ; List < GenericValue > contents = delegator . findByAnd ( ""Content"" , UtilMisc . toMap ( ""contentName"" , contentName ) , null , false ) ; if ( contents != null ) { Iterator < GenericValue > contentCheck = contents . iterator ( ) ; while ( contentCheck . hasNext ( ) && contentNameMatch == false ) { GenericValue contentch = contentCheck . next ( ) ; if ( contentch != null ) { List < GenericValue > contentAssocsChecks = delegator . findByAnd ( ""ContentAssoc"" , UtilMisc . toMap ( ""contentId"" , contentch . get ( ""contentId"" ) , ""contentIdTo"" , rootContent ) , null , false ) ; if ( contentAssocsChecks . size ( ) > 0 ) { contentNameMatch = true ; } } } } contentId = null ; if ( contentNameMatch == false ) { Map < String , Object > data = FastMap . newInstance ( ) ; data . put ( ""userLogin"" , userLogin ) ; String dataResourceId = dispatcher . runSync ( ""createDataResource"" , data ) . get ( ""dataResourceId"" ) . toString ( ) ; contentId = delegator . getNextSeqId ( ""Content"" ) ; Entity = null ; Entity = delegator . makeValue ( ""Content"" ) ; Entity . set ( ""contentId"" , contentId ) ; Entity . set ( ""contentName"" , contentName ) ; Entity . set ( ""contentTypeId"" , ""DOCUMENT"" ) ; Entity . set ( ""dataResourceId"" , dataResourceId ) ; Entity . set ( ""createdByUserLogin"" , userLogin . get ( ""userLoginId"" ) ) ; Entity . set ( ""lastModifiedByUserLogin"" , userLogin . get ( ""userLoginId"" ) ) ; Entity . set ( ""createdDate"" , UtilDateTime . nowTimestamp ( ) ) ; Entity . set ( ""lastUpdatedStamp"" , UtilDateTime . nowTimestamp ( ) ) ; Entity . set ( ""lastUpdatedTxStamp"" , UtilDateTime . nowTimestamp ( ) ) ; Entity . set ( ""createdStamp"" , UtilDateTime . nowTimestamp ( ) ) ; Entity . set ( ""createdTxStamp"" , UtilDateTime . nowTimestamp ( ) ) ; delegator . create ( Entity ) ; Map < String , Object > contentAssoc = FastMap . newInstance ( ) ; contentAssoc . put ( ""contentId"" , contentId ) ; contentAssoc . put ( ""contentAssocTypeId"" , ""SUB_CONTENT"" ) ; contentAssoc . put ( ""contentIdTo"" , rootContent ) ; contentAssoc . put ( ""userLogin"" , userLogin ) ; dispatcher . runSync ( ""createContentAssoc"" , contentAssoc ) ; } } } return ServiceUtil . returnSuccess ( sucMsg ) ; } catch ( GenericEntityException e ) { errMsg = ""GenericEntityException "" + UtilMisc . toMap ( ""errMessage"" , e . toString ( ) ) ; Debug . logError ( e , errMsg , module ) ; e . printStackTrace ( ) ; return ServiceUtil . returnError ( errMsg ) ; } catch ( GenericServiceException e ) { errMsg = ""GenericServiceException"" + UtilMisc . toMap ( ""errMessage"" , e . toString ( ) ) ; Debug . logError ( e , errMsg , module ) ; e . printStackTrace ( ) ; return ServiceUtil . returnError ( errMsg ) ; } }",Smelly
" public void read ( org . apache . thrift . protocol . TProtocol prot , getChildDataProducts_result struct ) throws org . apache . thrift . TException { TTupleProtocol iprot = ( TTupleProtocol ) prot ; BitSet incoming = iprot . readBitSet ( 5 ) ; if ( incoming . get ( 0 ) ) { { org . apache . thrift . protocol . TList _list283 = new org . apache . thrift . protocol . TList ( org . apache . thrift . protocol . TType . STRUCT , iprot . readI32 ( ) ) ; struct . success = new ArrayList < org . apache . airavata . model . data . replica . DataProductModel > ( _list283 . size ) ; org . apache . airavata . model . data . replica . DataProductModel _elem284 ; for ( int _i285 = 0 ; _i285 < _list283 . size ; ++ _i285 ) { _elem284 = new org . apache . airavata . model . data . replica . DataProductModel ( ) ; _elem284 . read ( iprot ) ; struct . success . add ( _elem284 ) ; } } struct . setSuccessIsSet ( true ) ; } if ( incoming . get ( 1 ) ) { struct . ire = new org . apache . airavata . model . error . InvalidRequestException ( ) ; struct . ire . read ( iprot ) ; struct . setIreIsSet ( true ) ; } if ( incoming . get ( 2 ) ) { struct . ace = new org . apache . airavata . model . error . AiravataClientException ( ) ; struct . ace . read ( iprot ) ; struct . setAceIsSet ( true ) ; } if ( incoming . get ( 3 ) ) { struct . ase = new org . apache . airavata . model . error . AiravataSystemException ( ) ; struct . ase . read ( iprot ) ; struct . setAseIsSet ( true ) ; } if ( incoming . get ( 4 ) ) { struct . ae = new org . apache . airavata . model . error . AuthorizationException ( ) ; struct . ae . read ( iprot ) ; struct . setAeIsSet ( true ) ; } }",Smelly
" public void read ( org . apache . thrift . protocol . TProtocol prot , getFollowing_result struct ) throws org . apache . thrift . TException { TTupleProtocol iprot = ( TTupleProtocol ) prot ; BitSet incoming = iprot . readBitSet ( 1 ) ; if ( incoming . get ( 0 ) ) { struct . success = new Key ( ) ; struct . success . read ( iprot ) ; struct . setSuccessIsSet ( true ) ; } }",Smelly
" public String sequence ( ) { return Long . toString ( sequence , 16 ) ; }",No
" public void read ( org . apache . thrift . protocol . TProtocol prot , show_compact_result struct ) throws org . apache . thrift . TException { TTupleProtocol iprot = ( TTupleProtocol ) prot ; BitSet incoming = iprot . readBitSet ( 1 ) ; if ( incoming . get ( 0 ) ) { struct . success = new ShowCompactResponse ( ) ; struct . success . read ( iprot ) ; struct . setSuccessIsSet ( true ) ; } }",Smelly
" public static Map < String , Object > getFile ( DispatchContext dctx , Map < String , ? > context ) { Locale locale = ( Locale ) context . get ( ""locale"" ) ; String localFilename = ( String ) context . get ( ""localFilename"" ) ; OutputStream localFile = null ; try { localFile = new FileOutputStream ( localFilename ) ; } catch ( IOException ioe ) { Debug . logError ( ioe , ""[getFile] Problem opening local file"" , module ) ; return ServiceUtil . returnError ( UtilProperties . getMessage ( resource , ""CommonFtpFileCannotBeOpen"" , locale ) ) ; } List < String > errorList = FastList . newInstance ( ) ; FTPClient ftp = new FTPClient ( ) ; try { Integer defaultTimeout = ( Integer ) context . get ( ""defaultTimeout"" ) ; if ( UtilValidate . isNotEmpty ( defaultTimeout ) ) { Debug . logInfo ( ""[getFile] Set default timeout to: "" + defaultTimeout . intValue ( ) + "" milliseconds"" , module ) ; ftp . setDefaultTimeout ( defaultTimeout . intValue ( ) ) ; } ftp . connect ( ( String ) context . get ( ""hostname"" ) ) ; if ( ! FTPReply . isPositiveCompletion ( ftp . getReplyCode ( ) ) ) { errorList . add ( UtilProperties . getMessage ( resource , ""CommonFtpConnectionRefused"" , locale ) ) ; } else { String username = ( String ) context . get ( ""username"" ) ; String password = ( String ) context . get ( ""password"" ) ; if ( ! ftp . login ( username , password ) ) { errorList . add ( UtilProperties . getMessage ( resource , ""CommonFtpLoginFailure"" , UtilMisc . toMap ( ""username"" , username , ""password"" , password ) , locale ) ) ; } else { Boolean binaryTransfer = ( Boolean ) context . get ( ""binaryTransfer"" ) ; boolean binary = ( binaryTransfer == null ) ? false : binaryTransfer . booleanValue ( ) ; if ( binary ) { ftp . setFileType ( FTP . BINARY_FILE_TYPE ) ; } Boolean passiveMode = ( Boolean ) context . get ( ""passiveMode"" ) ; boolean passive = ( passiveMode == null ) ? false : passiveMode . booleanValue ( ) ; if ( passive ) { ftp . enterLocalPassiveMode ( ) ; } if ( ! ftp . retrieveFile ( ( String ) context . get ( ""remoteFilename"" ) , localFile ) ) { errorList . add ( UtilProperties . getMessage ( resource , ""CommonFtpFileNotSentSuccesfully"" , UtilMisc . toMap ( ""replyString"" , ftp . getReplyString ( ) ) , locale ) ) ; } } ftp . logout ( ) ; } } catch ( IOException ioe ) { Debug . logWarning ( ioe , ""[getFile] caught exception: "" + ioe . getMessage ( ) , module ) ; errorList . add ( UtilProperties . getMessage ( resource , ""CommonFtpProblemWithTransfer"" , UtilMisc . toMap ( ""errorString"" , ioe . getMessage ( ) ) , locale ) ) ; } finally { try { if ( ftp . isConnected ( ) ) { ftp . disconnect ( ) ; } } catch ( Exception e ) { Debug . logWarning ( e , ""[getFile] Problem with FTP disconnect: "" , module ) ; } try { localFile . close ( ) ; } catch ( Exception e ) { Debug . logWarning ( e , ""[getFile] Problem closing local file: "" , module ) ; } } if ( errorList . size ( ) > 0 ) { Debug . logError ( ""[getFile] The following error(s) ("" + errorList . size ( ) + "") occurred: "" + errorList , module ) ; return ServiceUtil . returnError ( errorList ) ; } return ServiceUtil . returnSuccess ( ) ; }",Smelly
" protected void emitMetric ( String groupName , String name , String type , String value , GangliaConf gConf , GangliaSlope gSlope ) throws IOException { if ( name == null ) { LOG . warn ( ""Metric was emitted with no name."" ) ; return ; } else if ( value == null ) { LOG . warn ( ""Metric name "" + name + "" was emitted with a null value."" ) ; return ; } else if ( type == null ) { LOG . warn ( ""Metric name "" + name + "", value "" + value + "" has no type."" ) ; return ; } if ( LOG . isDebugEnabled ( ) ) { LOG . debug ( ""Emitting metric "" + name + "", type "" + type + "", value "" + value + "", slope "" + gSlope . name ( ) + "" from hostname "" + getHostName ( ) ) ; } xdr_int ( 128 ) ; xdr_string ( getHostName ( ) ) ; xdr_string ( name ) ; xdr_int ( 0 ) ; xdr_string ( type ) ; xdr_string ( name ) ; xdr_string ( gConf . getUnits ( ) ) ; xdr_int ( gSlope . ordinal ( ) ) ; xdr_int ( gConf . getTmax ( ) ) ; xdr_int ( gConf . getDmax ( ) ) ; xdr_int ( 1 ) ; xdr_string ( ""GROUP"" ) ; xdr_string ( groupName ) ; emitToGangliaHosts ( ) ; xdr_int ( 133 ) ; xdr_string ( getHostName ( ) ) ; xdr_string ( name ) ; xdr_int ( 0 ) ; xdr_string ( ""%s"" ) ; xdr_string ( value ) ; emitToGangliaHosts ( ) ; }",Smelly
 void removeFacet ( Class < ? extends Facet > facetType ) ;,No
" protected ClientCsdlEntityContainer doDeserialize ( final JsonParser jp , final DeserializationContext ctxt ) throws IOException { final ClientCsdlEntityContainer entityContainer = new ClientCsdlEntityContainer ( ) ; for ( ; jp . getCurrentToken ( ) != JsonToken . END_OBJECT ; jp . nextToken ( ) ) { final JsonToken token = jp . getCurrentToken ( ) ; if ( token == JsonToken . FIELD_NAME ) { if ( ""Name"" . equals ( jp . getCurrentName ( ) ) ) { entityContainer . setName ( jp . nextTextValue ( ) ) ; } else if ( ""Extends"" . equals ( jp . getCurrentName ( ) ) ) { entityContainer . setExtendsContainer ( jp . nextTextValue ( ) ) ; } else if ( ""EntitySet"" . equals ( jp . getCurrentName ( ) ) ) { jp . nextToken ( ) ; entityContainer . getEntitySets ( ) . add ( jp . readValueAs ( ClientCsdlEntitySet . class ) ) ; } else if ( ""Singleton"" . equals ( jp . getCurrentName ( ) ) ) { jp . nextToken ( ) ; entityContainer . getSingletons ( ) . add ( jp . readValueAs ( ClientCsdlSingleton . class ) ) ; } else if ( ""ActionImport"" . equals ( jp . getCurrentName ( ) ) ) { jp . nextToken ( ) ; entityContainer . getActionImports ( ) . add ( jp . readValueAs ( ClientCsdlActionImport . class ) ) ; } else if ( ""FunctionImport"" . equals ( jp . getCurrentName ( ) ) ) { jp . nextToken ( ) ; entityContainer . getFunctionImports ( ) . add ( jp . readValueAs ( ClientCsdlFunctionImport . class ) ) ; } else if ( ""Annotation"" . equals ( jp . getCurrentName ( ) ) ) { jp . nextToken ( ) ; entityContainer . getAnnotations ( ) . add ( jp . readValueAs ( ClientCsdlAnnotation . class ) ) ; } } } return entityContainer ; }",Smelly
" public void read ( org . apache . thrift . protocol . TProtocol prot , getChildDataProducts_result struct ) throws org . apache . thrift . TException { TTupleProtocol iprot = ( TTupleProtocol ) prot ; BitSet incoming = iprot . readBitSet ( 5 ) ; if ( incoming . get ( 0 ) ) { { org . apache . thrift . protocol . TList _list283 = new org . apache . thrift . protocol . TList ( org . apache . thrift . protocol . TType . STRUCT , iprot . readI32 ( ) ) ; struct . success = new ArrayList < org . apache . airavata . model . data . replica . DataProductModel > ( _list283 . size ) ; org . apache . airavata . model . data . replica . DataProductModel _elem284 ; for ( int _i285 = 0 ; _i285 < _list283 . size ; ++ _i285 ) { _elem284 = new org . apache . airavata . model . data . replica . DataProductModel ( ) ; _elem284 . read ( iprot ) ; struct . success . add ( _elem284 ) ; } } struct . setSuccessIsSet ( true ) ; } if ( incoming . get ( 1 ) ) { struct . ire = new org . apache . airavata . model . error . InvalidRequestException ( ) ; struct . ire . read ( iprot ) ; struct . setIreIsSet ( true ) ; } if ( incoming . get ( 2 ) ) { struct . ace = new org . apache . airavata . model . error . AiravataClientException ( ) ; struct . ace . read ( iprot ) ; struct . setAceIsSet ( true ) ; } if ( incoming . get ( 3 ) ) { struct . ase = new org . apache . airavata . model . error . AiravataSystemException ( ) ; struct . ase . read ( iprot ) ; struct . setAseIsSet ( true ) ; } if ( incoming . get ( 4 ) ) { struct . ae = new org . apache . airavata . model . error . AuthorizationException ( ) ; struct . ae . read ( iprot ) ; struct . setAeIsSet ( true ) ; } }",Smelly
" protected Exchange sendJaxWsMessageWithHolders ( final String personIdString ) { Exchange exchange = template . send ( ""direct:producer"" , new Processor ( ) { @ SuppressWarnings ( ""unchecked"" ) public void process ( final Exchange exchange ) { final List params = new ArrayList ( ) ; Holder < String > personId = new Holder < String > ( ) ; personId . value = personIdString ; params . add ( personId ) ; Holder < String > ssn = new Holder < String > ( ) ; Holder < String > name = new Holder < String > ( ) ; params . add ( ssn ) ; params . add ( name ) ; exchange . getIn ( ) . setBody ( params ) ; exchange . getIn ( ) . setHeader ( CxfConstants . OPERATION_NAME , ""GetPerson"" ) ; } } ) ; return exchange ; }",No
" public int run ( String [ ] args ) throws Exception { Option helpOpt = new Option ( ""h"" , ""help"" , false , ""show this help message"" ) ; Option normOpt = new Option ( ""n"" , ""normalize"" , false , ""whether to use URLNormalizers on the URL's in the segment"" ) ; Option filtOpt = new Option ( ""f"" , ""filter"" , false , ""whether to use URLFilters on the URL's in the segment"" ) ; @ SuppressWarnings ( ""static-access"" ) Option graphOpt = OptionBuilder . withArgName ( ""webgraphdb"" ) . hasArg ( ) . withDescription ( ""the web graph database to create (if none exists) or use if one does"" ) . create ( ""webgraphdb"" ) ; @ SuppressWarnings ( ""static-access"" ) Option segOpt = OptionBuilder . withArgName ( ""segment"" ) . hasArgs ( ) . withDescription ( ""the segment(s) to use"" ) . create ( ""segment"" ) ; @ SuppressWarnings ( ""static-access"" ) Option segDirOpt = OptionBuilder . withArgName ( ""segmentDir"" ) . hasArgs ( ) . withDescription ( ""the segment directory to use"" ) . create ( ""segmentDir"" ) ; Options options = new Options ( ) ; options . addOption ( helpOpt ) ; options . addOption ( normOpt ) ; options . addOption ( filtOpt ) ; options . addOption ( graphOpt ) ; options . addOption ( segOpt ) ; options . addOption ( segDirOpt ) ; CommandLineParser parser = new GnuParser ( ) ; try { CommandLine line = parser . parse ( options , args ) ; if ( line . hasOption ( ""help"" ) || ! line . hasOption ( ""webgraphdb"" ) || ( ! line . hasOption ( ""segment"" ) && ! line . hasOption ( ""segmentDir"" ) ) ) { HelpFormatter formatter = new HelpFormatter ( ) ; formatter . printHelp ( ""WebGraph"" , options , true ) ; return - 1 ; } String webGraphDb = line . getOptionValue ( ""webgraphdb"" ) ; Path [ ] segPaths = null ; if ( line . hasOption ( ""segment"" ) ) { String [ ] segments = line . getOptionValues ( ""segment"" ) ; segPaths = new Path [ segments . length ] ; for ( int i = 0 ; i < segments . length ; i ++ ) { segPaths [ i ] = new Path ( segments [ i ] ) ; } } if ( line . hasOption ( ""segmentDir"" ) ) { Path dir = new Path ( line . getOptionValue ( ""segmentDir"" ) ) ; FileSystem fs = dir . getFileSystem ( getConf ( ) ) ; FileStatus [ ] fstats = fs . listStatus ( dir , HadoopFSUtil . getPassDirectoriesFilter ( fs ) ) ; segPaths = HadoopFSUtil . getPaths ( fstats ) ; } boolean normalize = false ; if ( line . hasOption ( ""normalize"" ) ) { normalize = true ; } boolean filter = false ; if ( line . hasOption ( ""filter"" ) ) { filter = true ; } createWebGraph ( new Path ( webGraphDb ) , segPaths , normalize , filter ) ; return 0 ; } catch ( Exception e ) { LOG . error ( ""WebGraph: "" + StringUtils . stringifyException ( e ) ) ; return - 2 ; } }",Smelly
" public abstract int doEval ( @ Named ( ""inIndex"" ) int inIndex , @ Named ( ""partitionIndex"" ) int partitionIndex ) throws SchemaChangeException ;",No
" public void read ( org . apache . thrift . protocol . TProtocol prot , getActiveLogs_result struct ) throws org . apache . thrift . TException { TTupleProtocol iprot = ( TTupleProtocol ) prot ; BitSet incoming = iprot . readBitSet ( 1 ) ; if ( incoming . get ( 0 ) ) { { org . apache . thrift . protocol . TList _list327 = new org . apache . thrift . protocol . TList ( org . apache . thrift . protocol . TType . STRING , iprot . readI32 ( ) ) ; struct . success = new ArrayList < String > ( _list327 . size ) ; for ( int _i328 = 0 ; _i328 < _list327 . size ; ++ _i328 ) { String _elem329 ; _elem329 = iprot . readString ( ) ; struct . success . add ( _elem329 ) ; } } struct . setSuccessIsSet ( true ) ; } }",Smelly
 SearchArgument build ( ) ;,No
" public static void executeIncludeExcludeFilterForMeasure ( ColumnPage page , BitSet bitSet , MeasureColumnExecuterFilterInfo measureColumnExecuterFilterInfo , MeasureColumnResolvedFilterInfo measureColumnResolvedFilterInfo , FilterBitSetUpdater filterBitSetUpdater ) { final CarbonMeasure measure = measureColumnResolvedFilterInfo . getMeasure ( ) ; final DataType dataType = FilterUtil . getMeasureDataType ( measureColumnResolvedFilterInfo ) ; int numberOfRows = page . getPageSize ( ) ; BitSet nullBitSet = page . getNullBits ( ) ; Object [ ] filterKeys = measureColumnExecuterFilterInfo . getFilterKeys ( ) ; for ( int i = 0 ; i < filterKeys . length ; i ++ ) { if ( filterKeys [ i ] == null ) { for ( int j = nullBitSet . nextSetBit ( 0 ) ; j >= 0 ; j = nullBitSet . nextSetBit ( j + 1 ) ) { bitSet . flip ( j ) ; } } } AbstractCollection filterSet = measureColumnExecuterFilterInfo . getFilterSet ( ) ; if ( dataType == DataTypes . BYTE ) { ByteOpenHashSet byteOpenHashSet = ( ByteOpenHashSet ) filterSet ; for ( int i = 0 ; i < numberOfRows ; i ++ ) { if ( ! nullBitSet . get ( i ) ) { if ( byteOpenHashSet . contains ( ( byte ) page . getLong ( i ) ) ) { filterBitSetUpdater . updateBitset ( bitSet , i ) ; } } } } else if ( dataType == DataTypes . BOOLEAN ) { BooleanOpenHashSet booleanOpenHashSet = ( BooleanOpenHashSet ) filterSet ; for ( int i = 0 ; i < numberOfRows ; i ++ ) { if ( ! nullBitSet . get ( i ) ) { if ( booleanOpenHashSet . contains ( page . getBoolean ( i ) ) ) { filterBitSetUpdater . updateBitset ( bitSet , i ) ; } } } } else if ( dataType == DataTypes . SHORT ) { ShortOpenHashSet shortOpenHashSet = ( ShortOpenHashSet ) filterSet ; for ( int i = 0 ; i < numberOfRows ; i ++ ) { if ( ! nullBitSet . get ( i ) ) { if ( shortOpenHashSet . contains ( ( short ) page . getLong ( i ) ) ) { filterBitSetUpdater . updateBitset ( bitSet , i ) ; } } } } else if ( dataType == DataTypes . INT ) { IntOpenHashSet intOpenHashSet = ( IntOpenHashSet ) filterSet ; for ( int i = 0 ; i < numberOfRows ; i ++ ) { if ( ! nullBitSet . get ( i ) ) { if ( intOpenHashSet . contains ( ( int ) page . getLong ( i ) ) ) { filterBitSetUpdater . updateBitset ( bitSet , i ) ; } } } } else if ( dataType == DataTypes . FLOAT ) { FloatOpenHashSet floatOpenHashSet = ( FloatOpenHashSet ) filterSet ; for ( int i = 0 ; i < numberOfRows ; i ++ ) { if ( ! nullBitSet . get ( i ) ) { if ( floatOpenHashSet . contains ( ( float ) page . getDouble ( i ) ) ) { filterBitSetUpdater . updateBitset ( bitSet , i ) ; } } } } else if ( dataType == DataTypes . DOUBLE ) { DoubleOpenHashSet doubleOpenHashSet = ( DoubleOpenHashSet ) filterSet ; for ( int i = 0 ; i < numberOfRows ; i ++ ) { if ( ! nullBitSet . get ( i ) ) { if ( doubleOpenHashSet . contains ( page . getDouble ( i ) ) ) { filterBitSetUpdater . updateBitset ( bitSet , i ) ; } } } } else if ( dataType == DataTypes . LONG ) { LongOpenHashSet longOpenHashSet = ( LongOpenHashSet ) filterSet ; for ( int i = 0 ; i < numberOfRows ; i ++ ) { if ( ! nullBitSet . get ( i ) ) { if ( longOpenHashSet . contains ( page . getLong ( i ) ) ) { filterBitSetUpdater . updateBitset ( bitSet , i ) ; } } } } else if ( DataTypes . isDecimal ( dataType ) ) { Set bigDecimalHashSet = ( HashSet ) filterSet ; for ( int i = 0 ; i < numberOfRows ; i ++ ) { if ( ! nullBitSet . get ( i ) ) { final Object measureObjectBasedOnDataType = DataTypeUtil . getMeasureObjectBasedOnDataType ( page , i , dataType , measure ) ; if ( bigDecimalHashSet . contains ( measureObjectBasedOnDataType ) ) { filterBitSetUpdater . updateBitset ( bitSet , i ) ; } } } } else { throw new IllegalArgumentException ( ""Invalid data type"" ) ; } }",Smelly
" public void read ( org . apache . thrift . protocol . TProtocol prot , getChildDataProducts_result struct ) throws org . apache . thrift . TException { TTupleProtocol iprot = ( TTupleProtocol ) prot ; BitSet incoming = iprot . readBitSet ( 5 ) ; if ( incoming . get ( 0 ) ) { { org . apache . thrift . protocol . TList _list283 = new org . apache . thrift . protocol . TList ( org . apache . thrift . protocol . TType . STRUCT , iprot . readI32 ( ) ) ; struct . success = new ArrayList < org . apache . airavata . model . data . replica . DataProductModel > ( _list283 . size ) ; org . apache . airavata . model . data . replica . DataProductModel _elem284 ; for ( int _i285 = 0 ; _i285 < _list283 . size ; ++ _i285 ) { _elem284 = new org . apache . airavata . model . data . replica . DataProductModel ( ) ; _elem284 . read ( iprot ) ; struct . success . add ( _elem284 ) ; } } struct . setSuccessIsSet ( true ) ; } if ( incoming . get ( 1 ) ) { struct . ire = new org . apache . airavata . model . error . InvalidRequestException ( ) ; struct . ire . read ( iprot ) ; struct . setIreIsSet ( true ) ; } if ( incoming . get ( 2 ) ) { struct . ace = new org . apache . airavata . model . error . AiravataClientException ( ) ; struct . ace . read ( iprot ) ; struct . setAceIsSet ( true ) ; } if ( incoming . get ( 3 ) ) { struct . ase = new org . apache . airavata . model . error . AiravataSystemException ( ) ; struct . ase . read ( iprot ) ; struct . setAseIsSet ( true ) ; } if ( incoming . get ( 4 ) ) { struct . ae = new org . apache . airavata . model . error . AuthorizationException ( ) ; struct . ae . read ( iprot ) ; struct . setAeIsSet ( true ) ; } }",Smelly
 public Configuration getConfiguration ( ) { return connection . getConfiguration ( ) ; },No
" public void testDisablePartitionAutoIS ( ) throws Exception { String className = TestHelper . getTestClassName ( ) ; String methodName = TestHelper . getTestMethodName ( ) ; String clusterName = className + ""_"" + methodName ; final int n = 5 ; System . out . println ( ""START "" + clusterName + "" at "" + new Date ( System . currentTimeMillis ( ) ) ) ; MockParticipant [ ] participants = new MockParticipant [ n ] ; TestHelper . setupCluster ( clusterName , _zkaddr , 12918 , ""localhost"" , ""TestDB"" , 1 , 8 , n , 3 , ""MasterSlave"" , true ) ; MockController controller = new MockController ( _zkaddr , clusterName , ""controller_0"" ) ; controller . syncStart ( ) ; for ( int i = 0 ; i < n ; i ++ ) { String instanceName = ""localhost_"" + ( 12918 + i ) ; participants [ i ] = new MockParticipant ( _zkaddr , clusterName , instanceName ) ; participants [ i ] . syncStart ( ) ; } boolean result = ClusterStateVerifier . verifyByZkCallback ( new BestPossAndExtViewZkVerifier ( _zkaddr , clusterName ) ) ; Assert . assertTrue ( result ) ; String command = ""--zkSvr "" + _zkaddr + "" --enablePartition false "" + clusterName + "" localhost_12919 TestDB0 TestDB0_0 TestDB0_5"" ; ClusterSetup . processCommandLineArgs ( command . split ( ""\\s+"" ) ) ; result = ClusterStateVerifier . verifyByZkCallback ( new BestPossAndExtViewZkVerifier ( _zkaddr , clusterName ) ) ; Assert . assertTrue ( result ) ; Map < String , Map < String , String > > expectStateMap = new HashMap < String , Map < String , String > > ( ) ; Map < String , String > expectInstanceStateMap = new HashMap < String , String > ( ) ; expectInstanceStateMap . put ( ""localhost_12919"" , ""OFFLINE"" ) ; expectStateMap . put ( ""TestDB0_0"" , expectInstanceStateMap ) ; expectStateMap . put ( ""TestDB0_5"" , expectInstanceStateMap ) ; result = ZkTestHelper . verifyState ( _zkclient , clusterName , ""TestDB0"" , expectStateMap , ""=="" ) ; Assert . assertTrue ( result , ""localhost_12919"" + "" should be in OFFLINE for [TestDB0_0, TestDB0_5]"" ) ; command = ""--zkSvr "" + _zkaddr + "" --enablePartition true "" + clusterName + "" localhost_12919 TestDB0 TestDB0_0 TestDB0_5"" ; ClusterSetup . processCommandLineArgs ( command . split ( ""\\s+"" ) ) ; result = ClusterStateVerifier . verifyByZkCallback ( new BestPossAndExtViewZkVerifier ( _zkaddr , clusterName ) ) ; Assert . assertTrue ( result ) ; result = ZkTestHelper . verifyState ( _zkclient , clusterName , ""TestDB0"" , expectStateMap , ""!="" ) ; Assert . assertTrue ( result , ""localhost_12919"" + "" should NOT be in OFFLINE"" ) ; controller . syncStop ( ) ; for ( int i = 0 ; i < 5 ; i ++ ) { participants [ i ] . syncStop ( ) ; } System . out . println ( ""END "" + clusterName + "" at "" + new Date ( System . currentTimeMillis ( ) ) ) ; }",Smelly
" public void read ( org . apache . thrift . protocol . TProtocol prot , getChildDataProducts_result struct ) throws org . apache . thrift . TException { TTupleProtocol iprot = ( TTupleProtocol ) prot ; BitSet incoming = iprot . readBitSet ( 5 ) ; if ( incoming . get ( 0 ) ) { { org . apache . thrift . protocol . TList _list283 = new org . apache . thrift . protocol . TList ( org . apache . thrift . protocol . TType . STRUCT , iprot . readI32 ( ) ) ; struct . success = new ArrayList < org . apache . airavata . model . data . replica . DataProductModel > ( _list283 . size ) ; org . apache . airavata . model . data . replica . DataProductModel _elem284 ; for ( int _i285 = 0 ; _i285 < _list283 . size ; ++ _i285 ) { _elem284 = new org . apache . airavata . model . data . replica . DataProductModel ( ) ; _elem284 . read ( iprot ) ; struct . success . add ( _elem284 ) ; } } struct . setSuccessIsSet ( true ) ; } if ( incoming . get ( 1 ) ) { struct . ire = new org . apache . airavata . model . error . InvalidRequestException ( ) ; struct . ire . read ( iprot ) ; struct . setIreIsSet ( true ) ; } if ( incoming . get ( 2 ) ) { struct . ace = new org . apache . airavata . model . error . AiravataClientException ( ) ; struct . ace . read ( iprot ) ; struct . setAceIsSet ( true ) ; } if ( incoming . get ( 3 ) ) { struct . ase = new org . apache . airavata . model . error . AiravataSystemException ( ) ; struct . ase . read ( iprot ) ; struct . setAseIsSet ( true ) ; } if ( incoming . get ( 4 ) ) { struct . ae = new org . apache . airavata . model . error . AuthorizationException ( ) ; struct . ae . read ( iprot ) ; struct . setAeIsSet ( true ) ; } }",Smelly
" public void copyFrom ( User dataHolder ) { this . id = dataHolder . getId ( ) ; this . userName = dataHolder . getUserName ( ) ; this . password = dataHolder . getPassword ( ) ; this . screenName = dataHolder . getScreenName ( ) ; this . fullName = dataHolder . getFullName ( ) ; this . emailAddress = dataHolder . getEmailAddress ( ) ; this . locale = dataHolder . getLocale ( ) ; this . timeZone = dataHolder . getTimeZone ( ) ; this . openIdUrl = dataHolder . getOpenIdUrl ( ) ; this . enabled = dataHolder . getEnabled ( ) ; this . activationCode = dataHolder . getActivationCode ( ) ; try { GlobalPermission adminPerm = new GlobalPermission ( Collections . singletonList ( GlobalPermission . ADMIN ) ) ; this . administrator = WebloggerFactory . getWeblogger ( ) . getUserManager ( ) . checkPermission ( adminPerm , dataHolder ) ; } catch ( WebloggerException ex ) { } }",No
 void setMaxHintWindow ( int ms ) ;,No
 boolean useNewShowLocksFormat ( ) ;,No
 private static < S extends org . apache . thrift . scheme . IScheme > S scheme ( org . apache . thrift . protocol . TProtocol proto ) { return ( org . apache . thrift . scheme . StandardScheme . class . equals ( proto . getScheme ( ) ) ? STANDARD_SCHEME_FACTORY : TUPLE_SCHEME_FACTORY ) . getScheme ( ) ; },Smelly
" public Object accept ( QOMTreeVisitor visitor , Object data ) throws Exception { return visitor . visit ( this , data ) ; }",No
 private static < S extends org . apache . thrift . scheme . IScheme > S scheme ( org . apache . thrift . protocol . TProtocol proto ) { return ( org . apache . thrift . scheme . StandardScheme . class . equals ( proto . getScheme ( ) ) ? STANDARD_SCHEME_FACTORY : TUPLE_SCHEME_FACTORY ) . getScheme ( ) ; },Smelly
 private static < S extends org . apache . thrift . scheme . IScheme > S scheme ( org . apache . thrift . protocol . TProtocol proto ) { return ( org . apache . thrift . scheme . StandardScheme . class . equals ( proto . getScheme ( ) ) ? STANDARD_SCHEME_FACTORY : TUPLE_SCHEME_FACTORY ) . getScheme ( ) ; },Smelly
" String getPrivateKeyFile ( String userName , String hostName ) ;",No
 protected byte getToken ( ) { return BxmlNode . OPEN_START_ELEMENT_TOKEN ; },No
" public void read ( org . apache . thrift . protocol . TProtocol prot , show_compact_result struct ) throws org . apache . thrift . TException { TTupleProtocol iprot = ( TTupleProtocol ) prot ; BitSet incoming = iprot . readBitSet ( 1 ) ; if ( incoming . get ( 0 ) ) { struct . success = new ShowCompactResponse ( ) ; struct . success . read ( iprot ) ; struct . setSuccessIsSet ( true ) ; } }",Smelly
" public static List < TabletMigration > checkMigrationSanity ( Set < TServerInstance > current , List < TabletMigration > migrations ) { List < TabletMigration > result = new ArrayList < > ( migrations . size ( ) ) ; for ( TabletMigration m : migrations ) { if ( m . tablet == null ) { log . warn ( ""Balancer gave back a null tablet "" + m ) ; continue ; } if ( m . newServer == null ) { log . warn ( ""Balancer did not set the destination "" + m ) ; continue ; } if ( m . oldServer == null ) { log . warn ( ""Balancer did not set the source "" + m ) ; continue ; } if ( ! current . contains ( m . oldServer ) ) { log . warn ( ""Balancer wants to move a tablet from a server that is not current: "" + m ) ; continue ; } if ( ! current . contains ( m . newServer ) ) { log . warn ( ""Balancer wants to move a tablet to a server that is not current: "" + m ) ; continue ; } result . add ( m ) ; } return result ; }",No
" public void handle ( Callback [ ] callbacks ) throws IOException , UnsupportedCallbackException { for ( Callback callback : callbacks ) { if ( callback instanceof NameCallback ) { NameCallback nameCallback = ( NameCallback ) callback ; nameCallback . setName ( ""test"" ) ; } else if ( callback instanceof PasswordCallback ) { PasswordCallback passwordCallback = ( PasswordCallback ) callback ; passwordCallback . setPassword ( null ) ; } } }",No
" public void read ( org . apache . thrift . protocol . TProtocol prot , getChildDataProducts_result struct ) throws org . apache . thrift . TException { TTupleProtocol iprot = ( TTupleProtocol ) prot ; BitSet incoming = iprot . readBitSet ( 5 ) ; if ( incoming . get ( 0 ) ) { { org . apache . thrift . protocol . TList _list283 = new org . apache . thrift . protocol . TList ( org . apache . thrift . protocol . TType . STRUCT , iprot . readI32 ( ) ) ; struct . success = new ArrayList < org . apache . airavata . model . data . replica . DataProductModel > ( _list283 . size ) ; org . apache . airavata . model . data . replica . DataProductModel _elem284 ; for ( int _i285 = 0 ; _i285 < _list283 . size ; ++ _i285 ) { _elem284 = new org . apache . airavata . model . data . replica . DataProductModel ( ) ; _elem284 . read ( iprot ) ; struct . success . add ( _elem284 ) ; } } struct . setSuccessIsSet ( true ) ; } if ( incoming . get ( 1 ) ) { struct . ire = new org . apache . airavata . model . error . InvalidRequestException ( ) ; struct . ire . read ( iprot ) ; struct . setIreIsSet ( true ) ; } if ( incoming . get ( 2 ) ) { struct . ace = new org . apache . airavata . model . error . AiravataClientException ( ) ; struct . ace . read ( iprot ) ; struct . setAceIsSet ( true ) ; } if ( incoming . get ( 3 ) ) { struct . ase = new org . apache . airavata . model . error . AiravataSystemException ( ) ; struct . ase . read ( iprot ) ; struct . setAseIsSet ( true ) ; } if ( incoming . get ( 4 ) ) { struct . ae = new org . apache . airavata . model . error . AuthorizationException ( ) ; struct . ae . read ( iprot ) ; struct . setAeIsSet ( true ) ; } }",Smelly
 public TezTaskAttemptID getTaskAttemptId ( ) { return this . attemptId ; },No
" protected void toValue ( ) { setValue ( new String ( getBytes ( ) , StandardCharsets . UTF_8 ) ) ; }",No
" public Method getEvalMethod ( List < TypeInfo > argTypeInfos ) throws UDFArgumentException { assert ( argTypeInfos . size ( ) == 2 ) ; List < TypeInfo > pTypeInfos = null ; List < TypeInfo > modArgTypeInfos = new ArrayList < TypeInfo > ( ) ; if ( argTypeInfos . get ( 0 ) . equals ( TypeInfoFactory . stringTypeInfo ) || argTypeInfos . get ( 1 ) . equals ( TypeInfoFactory . stringTypeInfo ) ) { if ( argTypeInfos . get ( 0 ) . equals ( TypeInfoFactory . decimalTypeInfo ) || argTypeInfos . get ( 1 ) . equals ( TypeInfoFactory . decimalTypeInfo ) ) { modArgTypeInfos . add ( TypeInfoFactory . decimalTypeInfo ) ; modArgTypeInfos . add ( TypeInfoFactory . decimalTypeInfo ) ; } else { modArgTypeInfos . add ( TypeInfoFactory . doubleTypeInfo ) ; modArgTypeInfos . add ( TypeInfoFactory . doubleTypeInfo ) ; } } else { for ( int i = 0 ; i < 2 ; i ++ ) { if ( argTypeInfos . get ( i ) . equals ( TypeInfoFactory . voidTypeInfo ) ) { modArgTypeInfos . add ( TypeInfoFactory . byteTypeInfo ) ; } else { modArgTypeInfos . add ( argTypeInfos . get ( i ) ) ; } } } TypeInfo commonType = FunctionRegistry . getCommonClass ( modArgTypeInfos . get ( 0 ) , modArgTypeInfos . get ( 1 ) ) ; if ( commonType == null ) { throw new UDFArgumentException ( ""Unable to find a common class between"" + ""types "" + modArgTypeInfos . get ( 0 ) . getTypeName ( ) + "" and "" + modArgTypeInfos . get ( 1 ) . getTypeName ( ) ) ; } pTypeInfos = new ArrayList < TypeInfo > ( ) ; pTypeInfos . add ( commonType ) ; pTypeInfos . add ( commonType ) ; Method udfMethod = null ; for ( Method m : Arrays . asList ( udfClass . getMethods ( ) ) ) { if ( m . getName ( ) . equals ( ""evaluate"" ) ) { List < TypeInfo > argumentTypeInfos = TypeInfoUtils . getParameterTypeInfos ( m , pTypeInfos . size ( ) ) ; if ( argumentTypeInfos == null ) { continue ; } boolean match = ( argumentTypeInfos . size ( ) == pTypeInfos . size ( ) ) ; for ( int i = 0 ; i < pTypeInfos . size ( ) && match ; i ++ ) { TypeInfo accepted = argumentTypeInfos . get ( i ) ; if ( ! accepted . accept ( pTypeInfos . get ( i ) ) ) { match = false ; } } if ( match ) { if ( udfMethod != null ) { throw new AmbiguousMethodException ( udfClass , argTypeInfos , Arrays . asList ( new Method [ ] { udfMethod , m } ) ) ; } else { udfMethod = m ; } } } } if ( udfMethod == null ) { throw new NoMatchingMethodException ( udfClass , argTypeInfos , null ) ; } return udfMethod ; }",Smelly
" public void testCorrelateWithComplexFields ( ) { final RelBuilder builder = RelBuilder . create ( config ( ) . build ( ) ) ; final Holder < RexCorrelVariable > v = Holder . of ( null ) ; RelNode root = builder . scan ( ""EMP"" ) . variable ( v ) . scan ( ""DEPT"" ) . filter ( builder . equals ( builder . field ( 0 ) , builder . field ( v . get ( ) , ""DEPTNO"" ) ) ) . correlate ( JoinRelType . LEFT , v . get ( ) . id , builder . field ( 2 , 0 , ""DEPTNO"" ) , builder . getRexBuilder ( ) . makeCall ( SqlStdOperatorTable . AS , builder . field ( 2 , 0 , ""EMPNO"" ) , builder . literal ( ""RENAMED_EMPNO"" ) ) ) . build ( ) ; final String expected = """" + ""LogicalCorrelate(correlation=[$cor0], joinType=[left], requiredColumns=[{0, 7}])\n"" + ""  LogicalProject(RENAMED_EMPNO=[$0], ENAME=[$1], JOB=[$2], MGR=[$3], HIREDATE=[$4], SAL=[$5], COMM=[$6], DEPTNO=[$7])\n"" + ""    LogicalTableScan(table=[[scott, EMP]])\n"" + ""  LogicalFilter(condition=[=($0, $cor0.DEPTNO)])\n"" + ""    LogicalTableScan(table=[[scott, DEPT]])\n"" ; assertThat ( root , hasTree ( expected ) ) ; }",No
" public boolean validatePolicy ( AssertionInfoMap aim , Message message , List < WSSecurityEngineResult > results , List < WSSecurityEngineResult > signedResults , List < WSSecurityEngineResult > encryptedResults ) { Collection < AssertionInfo > ais = aim . get ( SP12Constants . SIGNED_ENDORSING_SUPPORTING_TOKENS ) ; if ( ais == null || ais . isEmpty ( ) ) { return true ; } setMessage ( message ) ; setResults ( results ) ; setSignedResults ( signedResults ) ; setEncryptedResults ( encryptedResults ) ; for ( AssertionInfo ai : ais ) { SupportingToken binding = ( SupportingToken ) ai . getAssertion ( ) ; if ( SPConstants . SupportTokenType . SUPPORTING_TOKEN_SIGNED_ENDORSING != binding . getTokenType ( ) ) { continue ; } ai . setAsserted ( true ) ; setSignedParts ( binding . getSignedParts ( ) ) ; setEncryptedParts ( binding . getEncryptedParts ( ) ) ; setSignedElements ( binding . getSignedElements ( ) ) ; setEncryptedElements ( binding . getEncryptedElements ( ) ) ; List < Token > tokens = binding . getTokens ( ) ; for ( Token token : tokens ) { if ( ! isTokenRequired ( token , message ) ) { continue ; } boolean derived = token . isDerivedKeys ( ) ; setDerived ( derived ) ; boolean processingFailed = false ; if ( token instanceof KerberosToken ) { if ( ! processKerberosTokens ( ) ) { processingFailed = true ; } } else if ( token instanceof SamlToken ) { if ( ! processSAMLTokens ( ) ) { processingFailed = true ; } } else if ( token instanceof X509Token ) { if ( ! processX509Tokens ( ) ) { processingFailed = true ; } } else if ( token instanceof KeyValueToken ) { if ( ! processKeyValueTokens ( ) ) { processingFailed = true ; } } else if ( token instanceof UsernameToken ) { if ( ! processUsernameTokens ( ) ) { processingFailed = true ; } } else if ( token instanceof SecurityContextToken ) { if ( ! processSCTokens ( ) ) { processingFailed = true ; } } else if ( ! ( token instanceof IssuedToken ) ) { processingFailed = true ; } if ( processingFailed ) { ai . setNotAsserted ( ""The received token does not match the signed endorsing supporting token requirement"" ) ; return false ; } } } return true ; }",Smelly
 private static < S extends org . apache . thrift . scheme . IScheme > S scheme ( org . apache . thrift . protocol . TProtocol proto ) { return ( org . apache . thrift . scheme . StandardScheme . class . equals ( proto . getScheme ( ) ) ? STANDARD_SCHEME_FACTORY : TUPLE_SCHEME_FACTORY ) . getScheme ( ) ; },Smelly
" public void read ( org . apache . thrift . protocol . TProtocol prot , TGetFunctionsReq struct ) throws org . apache . thrift . TException { TTupleProtocol iprot = ( TTupleProtocol ) prot ; struct . sessionHandle = new TSessionHandle ( ) ; struct . sessionHandle . read ( iprot ) ; struct . setSessionHandleIsSet ( true ) ; struct . functionName = iprot . readString ( ) ; struct . setFunctionNameIsSet ( true ) ; BitSet incoming = iprot . readBitSet ( 2 ) ; if ( incoming . get ( 0 ) ) { struct . catalogName = iprot . readString ( ) ; struct . setCatalogNameIsSet ( true ) ; } if ( incoming . get ( 1 ) ) { struct . schemaName = iprot . readString ( ) ; struct . setSchemaNameIsSet ( true ) ; } }",Smelly
" public void testOnRegionMove ( ) throws Exception { final TableName tableName = TableName . valueOf ( name . getMethodName ( ) ) ; final int NUM_REGIONS = 10 ; Table htable = TEST_UTIL . createTable ( tableName , new byte [ ] [ ] { FAMILY } , 3 , Bytes . toBytes ( ""aaaaa"" ) , Bytes . toBytes ( ""zzzzz"" ) , NUM_REGIONS ) ; HTableMultiplexer multiplexer = new HTableMultiplexer ( TEST_UTIL . getConfiguration ( ) , PER_REGIONSERVER_QUEUE_SIZE ) ; final RegionLocator regionLocator = TEST_UTIL . getConnection ( ) . getRegionLocator ( tableName ) ; Pair < byte [ ] [ ] , byte [ ] [ ] > startEndRows = regionLocator . getStartEndKeys ( ) ; byte [ ] row = startEndRows . getFirst ( ) [ 1 ] ; assertTrue ( ""2nd region should not start with empty row"" , row != null && row . length > 0 ) ; Put put = new Put ( row ) . addColumn ( FAMILY , QUALIFIER1 , VALUE1 ) ; assertTrue ( ""multiplexer.put returns"" , multiplexer . put ( tableName , put ) ) ; checkExistence ( htable , row , FAMILY , QUALIFIER1 , VALUE1 ) ; final HRegionLocation loc = regionLocator . getRegionLocation ( row ) ; final MiniHBaseCluster hbaseCluster = TEST_UTIL . getHBaseCluster ( ) ; final ServerName originalServer = loc . getServerName ( ) ; ServerName newServer = null ; for ( int i = 0 ; i < SLAVES ; i ++ ) { HRegionServer rs = hbaseCluster . getRegionServer ( i ) ; if ( ! rs . getServerName ( ) . equals ( originalServer . getServerName ( ) ) ) { newServer = rs . getServerName ( ) ; break ; } } assertNotNull ( ""Did not find a new RegionServer to use"" , newServer ) ; LOG . info ( ""Moving "" + loc . getRegionInfo ( ) . getEncodedName ( ) + "" from "" + originalServer + "" to "" + newServer ) ; TEST_UTIL . getAdmin ( ) . move ( loc . getRegionInfo ( ) . getEncodedNameAsBytes ( ) , Bytes . toBytes ( newServer . getServerName ( ) ) ) ; TEST_UTIL . waitUntilAllRegionsAssigned ( tableName ) ; put = new Put ( row ) . addColumn ( FAMILY , QUALIFIER2 , VALUE2 ) ; assertTrue ( ""multiplexer.put returns"" , multiplexer . put ( tableName , put ) ) ; checkExistence ( htable , row , FAMILY , QUALIFIER2 , VALUE2 ) ; }",No
" public SortedMap < K , V > tailMap ( final K fromKey ) { return decorated ( ) . tailMap ( fromKey ) ; }",No
" public RawReader < OrcStruct > getRawReader ( Configuration conf , boolean collapseEvents , int bucket , ValidTxnList validTxnList , Path baseDirectory , Path [ ] deltaDirectory ) throws IOException { Reader reader = null ; boolean isOriginal = false ; if ( baseDirectory != null ) { Path bucketFile ; if ( baseDirectory . getName ( ) . startsWith ( AcidUtils . BASE_PREFIX ) ) { bucketFile = AcidUtils . createBucketFile ( baseDirectory , bucket ) ; } else { isOriginal = true ; bucketFile = findOriginalBucket ( baseDirectory . getFileSystem ( conf ) , baseDirectory , bucket ) ; } reader = OrcFile . createReader ( bucketFile , OrcFile . readerOptions ( conf ) ) ; } return new OrcRawRecordMerger ( conf , collapseEvents , reader , isOriginal , bucket , validTxnList , new Reader . Options ( ) , deltaDirectory ) ; }",No
 private static < S extends org . apache . thrift . scheme . IScheme > S scheme ( org . apache . thrift . protocol . TProtocol proto ) { return ( org . apache . thrift . scheme . StandardScheme . class . equals ( proto . getScheme ( ) ) ? STANDARD_SCHEME_FACTORY : TUPLE_SCHEME_FACTORY ) . getScheme ( ) ; },Smelly
 private static < S extends org . apache . thrift . scheme . IScheme > S scheme ( org . apache . thrift . protocol . TProtocol proto ) { return ( org . apache . thrift . scheme . StandardScheme . class . equals ( proto . getScheme ( ) ) ? STANDARD_SCHEME_FACTORY : TUPLE_SCHEME_FACTORY ) . getScheme ( ) ; },No
" public void looseMarshal ( OpenWireFormat wireFormat , Object o , DataOutput dataOut ) throws IOException { super . looseMarshal ( wireFormat , o , dataOut ) ; }",No
 public Locale getLocale ( ) { return null ; },No
" public void testRecoverNegativeOnePaddedEditLog ( ) throws IOException { testNameNodeRecoveryImpl ( new SafePaddingCorruptor ( ( byte ) - 1 ) , true ) ; testNameNodeRecoveryImpl ( new SafePaddingCorruptor ( ( byte ) - 1 ) , false ) ; }",No
" public void read ( org . apache . thrift . protocol . TProtocol prot , getChildDataProducts_result struct ) throws org . apache . thrift . TException { TTupleProtocol iprot = ( TTupleProtocol ) prot ; BitSet incoming = iprot . readBitSet ( 5 ) ; if ( incoming . get ( 0 ) ) { { org . apache . thrift . protocol . TList _list283 = new org . apache . thrift . protocol . TList ( org . apache . thrift . protocol . TType . STRUCT , iprot . readI32 ( ) ) ; struct . success = new ArrayList < org . apache . airavata . model . data . replica . DataProductModel > ( _list283 . size ) ; org . apache . airavata . model . data . replica . DataProductModel _elem284 ; for ( int _i285 = 0 ; _i285 < _list283 . size ; ++ _i285 ) { _elem284 = new org . apache . airavata . model . data . replica . DataProductModel ( ) ; _elem284 . read ( iprot ) ; struct . success . add ( _elem284 ) ; } } struct . setSuccessIsSet ( true ) ; } if ( incoming . get ( 1 ) ) { struct . ire = new org . apache . airavata . model . error . InvalidRequestException ( ) ; struct . ire . read ( iprot ) ; struct . setIreIsSet ( true ) ; } if ( incoming . get ( 2 ) ) { struct . ace = new org . apache . airavata . model . error . AiravataClientException ( ) ; struct . ace . read ( iprot ) ; struct . setAceIsSet ( true ) ; } if ( incoming . get ( 3 ) ) { struct . ase = new org . apache . airavata . model . error . AiravataSystemException ( ) ; struct . ase . read ( iprot ) ; struct . setAseIsSet ( true ) ; } if ( incoming . get ( 4 ) ) { struct . ae = new org . apache . airavata . model . error . AuthorizationException ( ) ; struct . ae . read ( iprot ) ; struct . setAeIsSet ( true ) ; } }",Smelly
" private static AuditEventBase getTestEvent ( int idx ) { AuthzAuditEvent event = new AuthzAuditEvent ( ) ; event . setClientIP ( ""127.0.0.1"" ) ; event . setAccessResult ( ( short ) ( idx % 2 > 0 ? 1 : 0 ) ) ; event . setAclEnforcer ( ""ranger-acl"" ) ; switch ( idx % 5 ) { case 0 : event . setRepositoryName ( ""hdfsdev"" ) ; event . setRepositoryType ( EnumRepositoryType . HDFS ) ; event . setResourcePath ( ""/tmp/test-audit.log"" ) ; event . setResourceType ( ""file"" ) ; event . setAccessType ( ""read"" ) ; if ( idx % 2 > 0 ) { event . setAclEnforcer ( ""hadoop-acl"" ) ; } break ; case 1 : event . setRepositoryName ( ""hbasedev"" ) ; event . setRepositoryType ( EnumRepositoryType . HBASE ) ; event . setResourcePath ( ""test_table/test_cf/test_col"" ) ; event . setResourceType ( ""column"" ) ; event . setAccessType ( ""read"" ) ; break ; case 2 : event . setRepositoryName ( ""hivedev"" ) ; event . setRepositoryType ( EnumRepositoryType . HIVE ) ; event . setResourcePath ( ""test_database/test_table/test_col"" ) ; event . setResourceType ( ""column"" ) ; event . setAccessType ( ""select"" ) ; break ; case 3 : event . setRepositoryName ( ""knoxdev"" ) ; event . setRepositoryType ( EnumRepositoryType . KNOX ) ; event . setResourcePath ( ""topologies/ranger-admin"" ) ; event . setResourceType ( ""service"" ) ; event . setAccessType ( ""get"" ) ; break ; case 4 : event . setRepositoryName ( ""stormdev"" ) ; event . setRepositoryType ( EnumRepositoryType . STORM ) ; event . setResourcePath ( ""topologies/read-finance-stream"" ) ; event . setResourceType ( ""topology"" ) ; event . setAccessType ( ""submit"" ) ; break ; } event . setEventTime ( new Date ( ) ) ; event . setResultReason ( Integer . toString ( idx ) ) ; return event ; }",Smelly
" public void read ( org . apache . thrift . protocol . TProtocol prot , RolePrincipalGrant struct ) throws org . apache . thrift . TException { TTupleProtocol iprot = ( TTupleProtocol ) prot ; BitSet incoming = iprot . readBitSet ( 7 ) ; if ( incoming . get ( 0 ) ) { struct . roleName = iprot . readString ( ) ; struct . setRoleNameIsSet ( true ) ; } if ( incoming . get ( 1 ) ) { struct . principalName = iprot . readString ( ) ; struct . setPrincipalNameIsSet ( true ) ; } if ( incoming . get ( 2 ) ) { struct . principalType = PrincipalType . findByValue ( iprot . readI32 ( ) ) ; struct . setPrincipalTypeIsSet ( true ) ; } if ( incoming . get ( 3 ) ) { struct . grantOption = iprot . readBool ( ) ; struct . setGrantOptionIsSet ( true ) ; } if ( incoming . get ( 4 ) ) { struct . grantTime = iprot . readI32 ( ) ; struct . setGrantTimeIsSet ( true ) ; } if ( incoming . get ( 5 ) ) { struct . grantorName = iprot . readString ( ) ; struct . setGrantorNameIsSet ( true ) ; } if ( incoming . get ( 6 ) ) { struct . grantorPrincipalType = PrincipalType . findByValue ( iprot . readI32 ( ) ) ; struct . setGrantorPrincipalTypeIsSet ( true ) ; } }",Smelly
" public SystemDiagnostics create ( final FlowFileRepository flowFileRepo , final ContentRepository contentRepo , ProvenanceRepository provenanceRepository ) { final SystemDiagnostics systemDiagnostics = new SystemDiagnostics ( ) ; final MemoryMXBean memory = ManagementFactory . getMemoryMXBean ( ) ; final MemoryUsage heap = memory . getHeapMemoryUsage ( ) ; final MemoryUsage nonHeap = memory . getNonHeapMemoryUsage ( ) ; final OperatingSystemMXBean os = ManagementFactory . getOperatingSystemMXBean ( ) ; final ThreadMXBean threads = ManagementFactory . getThreadMXBean ( ) ; final List < GarbageCollectorMXBean > garbageCollectors = ManagementFactory . getGarbageCollectorMXBeans ( ) ; final RuntimeMXBean runtime = ManagementFactory . getRuntimeMXBean ( ) ; systemDiagnostics . setDaemonThreads ( threads . getDaemonThreadCount ( ) ) ; systemDiagnostics . setTotalThreads ( threads . getThreadCount ( ) ) ; systemDiagnostics . setTotalHeap ( heap . getCommitted ( ) ) ; systemDiagnostics . setUsedHeap ( heap . getUsed ( ) ) ; systemDiagnostics . setMaxHeap ( heap . getMax ( ) ) ; systemDiagnostics . setTotalNonHeap ( nonHeap . getCommitted ( ) ) ; systemDiagnostics . setUsedNonHeap ( nonHeap . getUsed ( ) ) ; systemDiagnostics . setMaxNonHeap ( nonHeap . getMax ( ) ) ; systemDiagnostics . setUptime ( runtime . getUptime ( ) ) ; systemDiagnostics . setAvailableProcessors ( os . getAvailableProcessors ( ) ) ; final double systemLoad = os . getSystemLoadAverage ( ) ; if ( systemLoad >= 0 ) { systemDiagnostics . setProcessorLoadAverage ( systemLoad ) ; } else { systemDiagnostics . setProcessorLoadAverage ( - 1.0 ) ; } final StorageUsage flowFileRepoStorageUsage = new StorageUsage ( ) ; flowFileRepoStorageUsage . setIdentifier ( ""FlowFile Repository"" ) ; try { flowFileRepoStorageUsage . setFreeSpace ( flowFileRepo . getUsableStorageSpace ( ) ) ; flowFileRepoStorageUsage . setTotalSpace ( flowFileRepo . getStorageCapacity ( ) ) ; } catch ( final IOException ioe ) { flowFileRepoStorageUsage . setFreeSpace ( 0L ) ; flowFileRepoStorageUsage . setTotalSpace ( - 1L ) ; logger . warn ( ""Unable to determine FlowFile Repository usage due to {}"" , ioe . toString ( ) ) ; if ( logger . isDebugEnabled ( ) ) { logger . warn ( """" , ioe ) ; } } systemDiagnostics . setFlowFileRepositoryStorageUsage ( flowFileRepoStorageUsage ) ; final Set < String > containerNames = contentRepo . getContainerNames ( ) ; final Map < String , StorageUsage > fileRepositoryUsage = new LinkedHashMap < > ( containerNames . size ( ) ) ; for ( final String containerName : containerNames ) { long containerCapacity = - 1L ; long containerFree = 0L ; try { containerFree = contentRepo . getContainerUsableSpace ( containerName ) ; containerCapacity = contentRepo . getContainerCapacity ( containerName ) ; } catch ( final IOException ioe ) { logger . warn ( ""Unable to determine Content Repository usage for container {} due to {}"" , containerName , ioe . toString ( ) ) ; if ( logger . isDebugEnabled ( ) ) { logger . warn ( """" , ioe ) ; } } final StorageUsage storageUsage = new StorageUsage ( ) ; storageUsage . setIdentifier ( containerName ) ; storageUsage . setFreeSpace ( containerFree ) ; storageUsage . setTotalSpace ( containerCapacity ) ; fileRepositoryUsage . put ( containerName , storageUsage ) ; } systemDiagnostics . setContentRepositoryStorageUsage ( fileRepositoryUsage ) ; final Set < String > provContainerNames = provenanceRepository . getContainerNames ( ) ; final Map < String , StorageUsage > provRepositoryUsage = new LinkedHashMap < > ( provContainerNames . size ( ) ) ; for ( final String containerName : provContainerNames ) { long containerCapacity = - 1L ; long containerFree = 0L ; try { containerFree = provenanceRepository . getContainerUsableSpace ( containerName ) ; containerCapacity = provenanceRepository . getContainerCapacity ( containerName ) ; } catch ( final IOException ioe ) { logger . warn ( ""Unable to determine Provenance Repository usage for container {} due to {}"" , containerName , ioe . toString ( ) ) ; if ( logger . isDebugEnabled ( ) ) { logger . warn ( """" , ioe ) ; } } final StorageUsage storageUsage = new StorageUsage ( ) ; storageUsage . setIdentifier ( containerName ) ; storageUsage . setFreeSpace ( containerFree ) ; storageUsage . setTotalSpace ( containerCapacity ) ; provRepositoryUsage . put ( containerName , storageUsage ) ; } systemDiagnostics . setProvenanceRepositoryStorageUsage ( provRepositoryUsage ) ; final Map < String , GarbageCollection > garbageCollection = new LinkedHashMap < > ( garbageCollectors . size ( ) ) ; for ( final GarbageCollectorMXBean garbageCollector : garbageCollectors ) { final GarbageCollection garbageCollectionEntry = new GarbageCollection ( ) ; garbageCollectionEntry . setCollectionCount ( garbageCollector . getCollectionCount ( ) ) ; garbageCollectionEntry . setCollectionTime ( garbageCollector . getCollectionTime ( ) ) ; garbageCollection . put ( garbageCollector . getName ( ) , garbageCollectionEntry ) ; } systemDiagnostics . setGarbageCollection ( garbageCollection ) ; final OperatingSystemMXBean osStats = ManagementFactory . getOperatingSystemMXBean ( ) ; try { final Class < ? > unixOsMxBeanClass = Class . forName ( ""com.sun.management.UnixOperatingSystemMXBean"" ) ; if ( unixOsMxBeanClass . isAssignableFrom ( osStats . getClass ( ) ) ) { final Method totalPhysicalMemory = unixOsMxBeanClass . getMethod ( ""getTotalPhysicalMemorySize"" ) ; totalPhysicalMemory . setAccessible ( true ) ; final Long ramBytes = ( Long ) totalPhysicalMemory . invoke ( osStats ) ; systemDiagnostics . setTotalPhysicalMemory ( ramBytes ) ; final Method maxFileDescriptors = unixOsMxBeanClass . getMethod ( ""getMaxFileDescriptorCount"" ) ; maxFileDescriptors . setAccessible ( true ) ; final Long maxOpenFileDescriptors = ( Long ) maxFileDescriptors . invoke ( osStats ) ; systemDiagnostics . setMaxOpenFileHandles ( maxOpenFileDescriptors ) ; final Method openFileDescriptors = unixOsMxBeanClass . getMethod ( ""getOpenFileDescriptorCount"" ) ; openFileDescriptors . setAccessible ( true ) ; final Long openDescriptorCount = ( Long ) openFileDescriptors . invoke ( osStats ) ; systemDiagnostics . setOpenFileHandles ( openDescriptorCount ) ; } } catch ( final Throwable t ) { } systemDiagnostics . setCreationTimestamp ( new Date ( ) . getTime ( ) ) ; return systemDiagnostics ; }",Smelly
" protected void populateObject ( Object object ) throws Exception { super . populateObject ( object ) ; Message info = ( Message ) object ; info . setProducerId ( createProducerId ( ""ProducerId:1"" ) ) ; info . setDestination ( createActiveMQDestination ( ""Destination:2"" ) ) ; info . setTransactionId ( createTransactionId ( ""TransactionId:3"" ) ) ; info . setOriginalDestination ( createActiveMQDestination ( ""OriginalDestination:4"" ) ) ; info . setMessageId ( createMessageId ( ""MessageId:5"" ) ) ; info . setOriginalTransactionId ( createTransactionId ( ""OriginalTransactionId:6"" ) ) ; info . setGroupID ( ""GroupID:7"" ) ; info . setGroupSequence ( 1 ) ; info . setCorrelationId ( ""CorrelationId:8"" ) ; info . setPersistent ( true ) ; info . setExpiration ( 1 ) ; info . setPriority ( ( byte ) 1 ) ; info . setReplyTo ( createActiveMQDestination ( ""ReplyTo:9"" ) ) ; info . setTimestamp ( 2 ) ; info . setType ( ""Type:10"" ) ; { ByteArrayOutputStream baos = new ByteArrayOutputStream ( ) ; DataOutputStream dataOut = new DataOutputStream ( baos ) ; MarshallingSupport . writeUTF8 ( dataOut , ""Content:11"" ) ; dataOut . close ( ) ; info . setContent ( baos . toByteSequence ( ) ) ; } { Map map = new HashMap ( ) ; map . put ( ""MarshalledProperties"" , 12 ) ; ByteArrayOutputStream baos = new ByteArrayOutputStream ( ) ; DataOutputStream os = new DataOutputStream ( baos ) ; MarshallingSupport . marshalPrimitiveMap ( map , os ) ; os . close ( ) ; info . setMarshalledProperties ( baos . toByteSequence ( ) ) ; } info . setDataStructure ( createDataStructure ( ""DataStructure:13"" ) ) ; info . setTargetConsumerId ( createConsumerId ( ""TargetConsumerId:14"" ) ) ; info . setCompressed ( false ) ; info . setRedeliveryCounter ( 2 ) ; { BrokerId value [ ] = new BrokerId [ 2 ] ; for ( int i = 0 ; i < 2 ; i ++ ) { value [ i ] = createBrokerId ( ""BrokerPath:15"" ) ; } info . setBrokerPath ( value ) ; } info . setArrival ( 3 ) ; info . setUserID ( ""UserID:16"" ) ; info . setRecievedByDFBridge ( true ) ; }",Smelly
 public void process ( WatchedEvent event ) { },No
 void println ( String s ) throws IOException ;,No
" public static String getProcessId ( Path path ) throws IOException { if ( path == null ) { throw new IOException ( ""Trying to access process id from a null path"" ) ; } LOG . debug ( ""Accessing pid from pid file "" + path ) ; String processId = null ; FileReader fileReader = null ; BufferedReader bufReader = null ; try { File file = new File ( path . toString ( ) ) ; if ( file . exists ( ) ) { fileReader = new FileReader ( file ) ; bufReader = new BufferedReader ( fileReader ) ; while ( true ) { String line = bufReader . readLine ( ) ; if ( line == null ) { break ; } String temp = line . trim ( ) ; if ( ! temp . isEmpty ( ) ) { if ( Shell . WINDOWS ) { try { ConverterUtils . toContainerId ( temp ) ; processId = temp ; break ; } catch ( Exception e ) { } } else { try { Long pid = Long . valueOf ( temp ) ; if ( pid > 0 ) { processId = temp ; break ; } } catch ( Exception e ) { } } } } } } finally { if ( fileReader != null ) { fileReader . close ( ) ; } if ( bufReader != null ) { bufReader . close ( ) ; } } LOG . debug ( ""Got pid "" + ( processId != null ? processId : ""null"" ) + "" from path "" + path ) ; return processId ; }",Smelly
 public TableProvider getTableProvider ( String tableId ) { return new LocalTableProvider ( tableId ) ; },No
 public void setNullCount ( long nullCount ) { this . nullCount = nullCount ; },No
" static VertexAttributePredicate getEndsWithPredicate ( String attrName , Class attrClass , String value ) { return new StringPredicate ( attrName , attrClass , value ) { protected boolean compareValue ( Object vertexAttrVal ) { return ( ( String ) vertexAttrVal ) . endsWith ( value ) ; } } ; }",No
" public void execute ( String input ) { String [ ] commands = input . split ( ""\\s+"" ) ; if ( commands . length < 2 || commands . length > 6 ) { System . err . println ( USAGE ) ; return ; } String principal ; String keytabFileLocation ; String removeOption = null ; int lastIndex ; if ( commands [ commands . length - 1 ] . matches ( ""^all|old|-?\\d+$"" ) ) { if ( commands . length < 3 ) { System . err . println ( USAGE ) ; return ; } lastIndex = commands . length - 3 ; principal = commands [ commands . length - 2 ] ; removeOption = commands [ commands . length - 1 ] ; } else { lastIndex = commands . length - 2 ; principal = commands [ commands . length - 1 ] ; } KOptions kOptions = ToolUtil . parseOptions ( commands , 1 , lastIndex ) ; if ( principal == null || kOptions == null || kOptions . contains ( KadminOption . K ) && kOptions . contains ( KadminOption . KEYTAB ) ) { System . err . println ( USAGE ) ; return ; } keytabFileLocation = kOptions . contains ( KadminOption . K ) ? kOptions . getStringOption ( KadminOption . K ) : kOptions . getStringOption ( KadminOption . KEYTAB ) ; if ( keytabFileLocation == null ) { keytabFileLocation = DEFAULT_KEYTAB_FILE ; } File keytabFile = new File ( keytabFileLocation ) ; try { if ( removeOption . equals ( ""all"" ) ) { getKadmin ( ) . removeKeytabEntriesOf ( keytabFile , principal ) ; } else if ( removeOption . equals ( ""old"" ) ) { getKadmin ( ) . removeOldKeytabEntriesOf ( keytabFile , principal ) ; } else { int kvno = Integer . parseInt ( removeOption ) ; getKadmin ( ) . removeKeytabEntriesOf ( keytabFile , principal , kvno ) ; } System . out . println ( ""Done!"" ) ; } catch ( KrbException e ) { System . err . println ( ""Principal \"""" + principal + ""\"" fail to remove entry from keytab."" + e . getMessage ( ) ) ; } }",Smelly
" public void read ( org . apache . thrift . protocol . TProtocol prot , show_compact_result struct ) throws org . apache . thrift . TException { TTupleProtocol iprot = ( TTupleProtocol ) prot ; BitSet incoming = iprot . readBitSet ( 1 ) ; if ( incoming . get ( 0 ) ) { struct . success = new ShowCompactResponse ( ) ; struct . success . read ( iprot ) ; struct . setSuccessIsSet ( true ) ; } }",Smelly
" private void parseMethods ( ) throws ParsingException , GrammerException { ArrayList methods = new ArrayList ( 10 ) ; Object method ; do { method = parseMethod ( ) ; if ( method != null ) { methods . add ( method ) ; } } while ( method != null ) ; javaClass . methods = ( Method [ ] ) methods . toArray ( new Method [ methods . size ( ) ] ) ; javaClass . methods_count = javaClass . methods . length ; }",Smelly
" public RangerServiceResource buildResource ( final IReferenceableInstance entity ) throws Exception { String qualifiedName = getEntityAttribute ( entity , ENTITY_ATTRIBUTE_QUALIFIED_NAME , String . class ) ; if ( StringUtils . isEmpty ( qualifiedName ) ) { throw new Exception ( ""attribute '"" + ENTITY_ATTRIBUTE_QUALIFIED_NAME + ""' not found in entity"" ) ; } String resourceStr = getResourceNameFromQualifiedName ( qualifiedName ) ; if ( StringUtils . isEmpty ( resourceStr ) ) { throwExceptionWithMessage ( ""resource not found in attribute '"" + ENTITY_ATTRIBUTE_QUALIFIED_NAME + ""': "" + qualifiedName ) ; } String clusterName = getClusterNameFromQualifiedName ( qualifiedName ) ; if ( StringUtils . isEmpty ( clusterName ) ) { throwExceptionWithMessage ( ""cluster-name not found in attribute '"" + ENTITY_ATTRIBUTE_QUALIFIED_NAME + ""': "" + qualifiedName ) ; } String entityType = entity . getTypeName ( ) ; String entityGuid = entity . getId ( ) != null ? entity . getId ( ) . _getId ( ) : null ; String serviceName = getRangerServiceName ( clusterName ) ; Map < String , RangerPolicyResource > elements = new HashMap < String , RangerPolicyResource > ( ) ; if ( StringUtils . equals ( entityType , ENTITY_TYPE_HBASE_TABLE ) ) { String tblName = resourceStr ; if ( StringUtils . isNotEmpty ( tblName ) ) { elements . put ( RANGER_TYPE_HBASE_TABLE , new RangerPolicyResource ( tblName ) ) ; } } else if ( StringUtils . equals ( entityType , ENTITY_TYPE_HBASE_COLUMN_FAMILY ) ) { String [ ] resources = resourceStr . split ( QUALIFIED_NAME_DELIMITER ) ; String tblName = null ; String familyName = null ; if ( resources . length == 2 ) { tblName = resources [ 0 ] ; familyName = resources [ 1 ] ; } else if ( resources . length > 2 ) { StringBuffer tblNameBuf = new StringBuffer ( resources [ 0 ] ) ; for ( int i = 1 ; i < resources . length - 1 ; i ++ ) { tblNameBuf . append ( QUALIFIED_NAME_DELIMITER_CHAR ) . append ( resources [ i ] ) ; } tblName = tblNameBuf . toString ( ) ; familyName = resources [ resources . length - 1 ] ; } if ( StringUtils . isNotEmpty ( tblName ) && StringUtils . isNotEmpty ( familyName ) ) { elements . put ( RANGER_TYPE_HBASE_TABLE , new RangerPolicyResource ( tblName ) ) ; elements . put ( RANGER_TYPE_HBASE_COLUMN_FAMILY , new RangerPolicyResource ( familyName ) ) ; } } else if ( StringUtils . equals ( entityType , ENTITY_TYPE_HBASE_COLUMN ) ) { String [ ] resources = resourceStr . split ( QUALIFIED_NAME_DELIMITER ) ; String tblName = null ; String familyName = null ; String colName = null ; if ( resources . length == 3 ) { tblName = resources [ 0 ] ; familyName = resources [ 1 ] ; colName = resources [ 2 ] ; } else if ( resources . length > 3 ) { StringBuffer tblNameBuf = new StringBuffer ( resources [ 0 ] ) ; for ( int i = 1 ; i < resources . length - 2 ; i ++ ) { tblNameBuf . append ( QUALIFIED_NAME_DELIMITER_CHAR ) . append ( resources [ i ] ) ; } tblName = tblNameBuf . toString ( ) ; familyName = resources [ resources . length - 2 ] ; colName = resources [ resources . length - 1 ] ; } if ( StringUtils . isNotEmpty ( tblName ) && StringUtils . isNotEmpty ( familyName ) && StringUtils . isNotEmpty ( colName ) ) { elements . put ( RANGER_TYPE_HBASE_TABLE , new RangerPolicyResource ( tblName ) ) ; elements . put ( RANGER_TYPE_HBASE_COLUMN_FAMILY , new RangerPolicyResource ( familyName ) ) ; elements . put ( RANGER_TYPE_HBASE_COLUMN , new RangerPolicyResource ( colName ) ) ; } } else { throwExceptionWithMessage ( ""unrecognized entity-type: "" + entityType ) ; } if ( elements . isEmpty ( ) ) { throwExceptionWithMessage ( ""invalid qualifiedName for entity-type '"" + entityType + ""': "" + qualifiedName ) ; } RangerServiceResource ret = new RangerServiceResource ( entityGuid , serviceName , elements ) ; return ret ; }",Smelly
" public void read ( org . apache . thrift . protocol . TProtocol prot , TColumn struct ) throws org . apache . thrift . TException { TTupleProtocol iprot = ( TTupleProtocol ) prot ; BitSet incoming = iprot . readBitSet ( 3 ) ; if ( incoming . get ( 0 ) ) { struct . columnFamily = iprot . readBinary ( ) ; struct . setColumnFamilyIsSet ( true ) ; } if ( incoming . get ( 1 ) ) { struct . columnQualifier = iprot . readBinary ( ) ; struct . setColumnQualifierIsSet ( true ) ; } if ( incoming . get ( 2 ) ) { struct . columnVisibility = iprot . readBinary ( ) ; struct . setColumnVisibilityIsSet ( true ) ; } }",No
 public boolean isFinished ( ) { return future . isDone ( ) ; },No
" public void setRightEnd ( final Group rightEnd ) { checkType ( rightEnd , JPAGroup . class ) ; this . rightEnd = ( JPAGroup ) rightEnd ; }",No
 public CsdlCast setValue ( final CsdlExpression value ) { this . value = value ; return this ; },No
" public ValidationResult validate ( final String subject , final String input , final ValidationContext validationContext ) { try { Hex . decodeHex ( input . toCharArray ( ) ) ; return new ValidationResult . Builder ( ) . valid ( true ) . input ( input ) . subject ( subject ) . build ( ) ; } catch ( final Exception e ) { return new ValidationResult . Builder ( ) . valid ( false ) . explanation ( ""Not a valid Hex String"" ) . input ( input ) . subject ( subject ) . build ( ) ; } }",No
 protected abstract String transformWildcardQuery ( String query ) ;,No
 public long workerId ( ) { return workerId ; },No
 boolean checkContinue ( ) throws ManifoldCFException ;,No
" public static void main ( String [ ] args ) { System . out . println ( ""OK"" ) ; }",No
" RelTraitSet getOrAdd ( List < RelTrait > traits ) { RelTraitSet traitSet1 = map . get ( traits ) ; if ( traitSet1 != null ) { return traitSet1 ; } final RelTraitSet traitSet = new RelTraitSet ( this , traits . toArray ( new RelTrait [ 0 ] ) ) ; map . put ( traits , traitSet ) ; return traitSet ; }",No
 public CompletableFuture < Boolean > addSchemaIfIdleOrCheckCompatible ( SchemaData schema ) { return hasSchema ( ) . thenCompose ( ( hasSchema ) -> { if ( hasSchema || isActive ( ) || ENTRIES_ADDED_COUNTER_UPDATER . get ( this ) != 0 ) { return isSchemaCompatible ( schema ) ; } else { return addSchema ( schema ) . thenApply ( ( ignore ) -> true ) ; } } ) ; },No
" protected void populateObject ( Object object ) throws Exception { super . populateObject ( object ) ; SessionInfo info = ( SessionInfo ) object ; info . setSessionId ( createSessionId ( ""SessionId:1"" ) ) ; }",No
" public int compareTo ( byte [ ] buffer1 , int offset1 , int length1 , byte [ ] buffer2 , int offset2 , int length2 ) { if ( buffer1 == buffer2 && offset1 == offset2 && length1 == length2 ) { return 0 ; } int minLength = Math . min ( length1 , length2 ) ; int minWords = minLength / Longs . BYTES ; int offset1Adj = offset1 + BYTE_ARRAY_BASE_OFFSET ; int offset2Adj = offset2 + BYTE_ARRAY_BASE_OFFSET ; for ( int i = 0 ; i < minWords * Longs . BYTES ; i += Longs . BYTES ) { long lw = theUnsafe . getLong ( buffer1 , offset1Adj + ( long ) i ) ; long rw = theUnsafe . getLong ( buffer2 , offset2Adj + ( long ) i ) ; long diff = lw ^ rw ; if ( diff != 0 ) { if ( ! littleEndian ) { return lessThanUnsigned ( lw , rw ) ? - 1 : 1 ; } int n = 0 ; int y ; int x = ( int ) diff ; if ( x == 0 ) { x = ( int ) ( diff > > > 32 ) ; n = 32 ; } y = x < < 16 ; if ( y == 0 ) { n += 16 ; } else { x = y ; } y = x < < 8 ; if ( y == 0 ) { n += 8 ; } return ( int ) ( ( ( lw > > > n ) & 0xFFL ) - ( ( rw > > > n ) & 0xFFL ) ) ; } } for ( int i = minWords * Longs . BYTES ; i < minLength ; i ++ ) { int result = UnsignedBytes . compare ( buffer1 [ offset1 + i ] , buffer2 [ offset2 + i ] ) ; if ( result != 0 ) { return result ; } } return length1 - length2 ; }",Smelly
 public boolean isType1 ( ) { return fileFont instanceof CFFType1Font ; },No
" public void eval ( ) { final int len = in . end - in . start ; out . start = 0 ; out . end = len ; out . buffer = buffer = buffer . reallocIfNeeded ( len ) ; int charLen ; int index = out . end ; int innerIndex ; for ( int id = in . start ; id < in . end ; id += charLen ) { innerIndex = charLen = org . apache . drill . exec . expr . fn . impl . StringFunctionUtil . utf8CharLen ( in . buffer , id ) ; while ( innerIndex > 0 ) { out . buffer . setByte ( index - innerIndex , in . buffer . getByte ( id + ( charLen - innerIndex ) ) ) ; innerIndex -- ; } index -= charLen ; } }",Smelly
" public void read ( org . apache . thrift . protocol . TProtocol prot , RemoteSpan struct ) throws org . apache . thrift . TException { TTupleProtocol iprot = ( TTupleProtocol ) prot ; BitSet incoming = iprot . readBitSet ( 10 ) ; if ( incoming . get ( 0 ) ) { struct . sender = iprot . readString ( ) ; struct . setSenderIsSet ( true ) ; } if ( incoming . get ( 1 ) ) { struct . svc = iprot . readString ( ) ; struct . setSvcIsSet ( true ) ; } if ( incoming . get ( 2 ) ) { struct . traceId = iprot . readI64 ( ) ; struct . setTraceIdIsSet ( true ) ; } if ( incoming . get ( 3 ) ) { struct . spanId = iprot . readI64 ( ) ; struct . setSpanIdIsSet ( true ) ; } if ( incoming . get ( 4 ) ) { struct . parentId = iprot . readI64 ( ) ; struct . setParentIdIsSet ( true ) ; } if ( incoming . get ( 5 ) ) { struct . start = iprot . readI64 ( ) ; struct . setStartIsSet ( true ) ; } if ( incoming . get ( 6 ) ) { struct . stop = iprot . readI64 ( ) ; struct . setStopIsSet ( true ) ; } if ( incoming . get ( 7 ) ) { struct . description = iprot . readString ( ) ; struct . setDescriptionIsSet ( true ) ; } if ( incoming . get ( 8 ) ) { { org . apache . thrift . protocol . TMap _map11 = new org . apache . thrift . protocol . TMap ( org . apache . thrift . protocol . TType . STRING , org . apache . thrift . protocol . TType . STRING , iprot . readI32 ( ) ) ; struct . data = new HashMap < String , String > ( 2 * _map11 . size ) ; for ( int _i12 = 0 ; _i12 < _map11 . size ; ++ _i12 ) { String _key13 ; String _val14 ; _key13 = iprot . readString ( ) ; _val14 = iprot . readString ( ) ; struct . data . put ( _key13 , _val14 ) ; } } struct . setDataIsSet ( true ) ; } if ( incoming . get ( 9 ) ) { { org . apache . thrift . protocol . TList _list15 = new org . apache . thrift . protocol . TList ( org . apache . thrift . protocol . TType . STRUCT , iprot . readI32 ( ) ) ; struct . annotations = new ArrayList < Annotation > ( _list15 . size ) ; for ( int _i16 = 0 ; _i16 < _list15 . size ; ++ _i16 ) { Annotation _elem17 ; _elem17 = new Annotation ( ) ; _elem17 . read ( iprot ) ; struct . annotations . add ( _elem17 ) ; } } struct . setAnnotationsIsSet ( true ) ; } }",Smelly
 private static < S extends org . apache . thrift . scheme . IScheme > S scheme ( org . apache . thrift . protocol . TProtocol proto ) { return ( org . apache . thrift . scheme . StandardScheme . class . equals ( proto . getScheme ( ) ) ? STANDARD_SCHEME_FACTORY : TUPLE_SCHEME_FACTORY ) . getScheme ( ) ; },Smelly
" public void read ( org . apache . thrift . protocol . TProtocol prot , show_compact_result struct ) throws org . apache . thrift . TException { TTupleProtocol iprot = ( TTupleProtocol ) prot ; BitSet incoming = iprot . readBitSet ( 1 ) ; if ( incoming . get ( 0 ) ) { struct . success = new ShowCompactResponse ( ) ; struct . success . read ( iprot ) ; struct . setSuccessIsSet ( true ) ; } }",Smelly
" public void wrap_ofWrapped_differentMode_delegates_to_createProxy ( ) throws Exception { final DomainObject wrappedObject = new DomainObject ( ) ; final DomainObject domainObject = new WrappedDomainObject ( wrappedObject , WrapperFactory . ExecutionMode . EXECUTE ) ; final DomainObject wrappingObject = wrapperFactory . wrap ( domainObject , WrapperFactory . ExecutionMode . SKIP_RULES ) ; assertThat ( wrappingObject , is ( not ( domainObject ) ) ) ; assertThat ( createProxyCalledWithDomainObject , is ( wrappedObject ) ) ; assertThat ( createProxyCalledWithMode , is ( WrapperFactory . ExecutionMode . SKIP_RULES ) ) ; }",No
 public V get ( Object key ) { V value = super . get ( key ) ; return value != null ? value : ( V ) Long . valueOf ( 0L ) ; },No
" public void read ( org . apache . thrift . protocol . TProtocol prot , checkNamespaceClass_result struct ) throws org . apache . thrift . TException { TTupleProtocol iprot = ( TTupleProtocol ) prot ; BitSet incoming = iprot . readBitSet ( 3 ) ; if ( incoming . get ( 0 ) ) { struct . success = iprot . readBool ( ) ; struct . setSuccessIsSet ( true ) ; } if ( incoming . get ( 1 ) ) { struct . sec = new ThriftSecurityException ( ) ; struct . sec . read ( iprot ) ; struct . setSecIsSet ( true ) ; } if ( incoming . get ( 2 ) ) { struct . tope = new ThriftTableOperationException ( ) ; struct . tope . read ( iprot ) ; struct . setTopeIsSet ( true ) ; } }",Smelly
" public void read ( org . apache . thrift . protocol . TProtocol prot , TabletStats struct ) throws org . apache . thrift . TException { TTupleProtocol iprot = ( TTupleProtocol ) prot ; BitSet incoming = iprot . readBitSet ( 8 ) ; if ( incoming . get ( 0 ) ) { struct . extent = new org . apache . accumulo . core . data . thrift . TKeyExtent ( ) ; struct . extent . read ( iprot ) ; struct . setExtentIsSet ( true ) ; } if ( incoming . get ( 1 ) ) { struct . majors = new ActionStats ( ) ; struct . majors . read ( iprot ) ; struct . setMajorsIsSet ( true ) ; } if ( incoming . get ( 2 ) ) { struct . minors = new ActionStats ( ) ; struct . minors . read ( iprot ) ; struct . setMinorsIsSet ( true ) ; } if ( incoming . get ( 3 ) ) { struct . splits = new ActionStats ( ) ; struct . splits . read ( iprot ) ; struct . setSplitsIsSet ( true ) ; } if ( incoming . get ( 4 ) ) { struct . numEntries = iprot . readI64 ( ) ; struct . setNumEntriesIsSet ( true ) ; } if ( incoming . get ( 5 ) ) { struct . ingestRate = iprot . readDouble ( ) ; struct . setIngestRateIsSet ( true ) ; } if ( incoming . get ( 6 ) ) { struct . queryRate = iprot . readDouble ( ) ; struct . setQueryRateIsSet ( true ) ; } if ( incoming . get ( 7 ) ) { struct . splitCreationTime = iprot . readI64 ( ) ; struct . setSplitCreationTimeIsSet ( true ) ; } }",Smelly
" public void read ( org . apache . thrift . protocol . TProtocol prot , show_compact_result struct ) throws org . apache . thrift . TException { TTupleProtocol iprot = ( TTupleProtocol ) prot ; BitSet incoming = iprot . readBitSet ( 1 ) ; if ( incoming . get ( 0 ) ) { struct . success = new ShowCompactResponse ( ) ; struct . success . read ( iprot ) ; struct . setSuccessIsSet ( true ) ; } }",Smelly
" public void read ( org . apache . thrift . protocol . TProtocol prot , getChildDataProducts_result struct ) throws org . apache . thrift . TException { TTupleProtocol iprot = ( TTupleProtocol ) prot ; BitSet incoming = iprot . readBitSet ( 5 ) ; if ( incoming . get ( 0 ) ) { { org . apache . thrift . protocol . TList _list283 = new org . apache . thrift . protocol . TList ( org . apache . thrift . protocol . TType . STRUCT , iprot . readI32 ( ) ) ; struct . success = new ArrayList < org . apache . airavata . model . data . replica . DataProductModel > ( _list283 . size ) ; org . apache . airavata . model . data . replica . DataProductModel _elem284 ; for ( int _i285 = 0 ; _i285 < _list283 . size ; ++ _i285 ) { _elem284 = new org . apache . airavata . model . data . replica . DataProductModel ( ) ; _elem284 . read ( iprot ) ; struct . success . add ( _elem284 ) ; } } struct . setSuccessIsSet ( true ) ; } if ( incoming . get ( 1 ) ) { struct . ire = new org . apache . airavata . model . error . InvalidRequestException ( ) ; struct . ire . read ( iprot ) ; struct . setIreIsSet ( true ) ; } if ( incoming . get ( 2 ) ) { struct . ace = new org . apache . airavata . model . error . AiravataClientException ( ) ; struct . ace . read ( iprot ) ; struct . setAceIsSet ( true ) ; } if ( incoming . get ( 3 ) ) { struct . ase = new org . apache . airavata . model . error . AiravataSystemException ( ) ; struct . ase . read ( iprot ) ; struct . setAseIsSet ( true ) ; } if ( incoming . get ( 4 ) ) { struct . ae = new org . apache . airavata . model . error . AuthorizationException ( ) ; struct . ae . read ( iprot ) ; struct . setAeIsSet ( true ) ; } }",Smelly
" public void read ( org . apache . thrift . protocol . TProtocol prot , TByteColumn struct ) throws org . apache . thrift . TException { TTupleProtocol iprot = ( TTupleProtocol ) prot ; { org . apache . thrift . protocol . TList _list67 = new org . apache . thrift . protocol . TList ( org . apache . thrift . protocol . TType . BYTE , iprot . readI32 ( ) ) ; struct . values = new ArrayList < Byte > ( _list67 . size ) ; for ( int _i68 = 0 ; _i68 < _list67 . size ; ++ _i68 ) { byte _elem69 ; _elem69 = iprot . readByte ( ) ; struct . values . add ( _elem69 ) ; } } struct . setValuesIsSet ( true ) ; struct . nulls = iprot . readBinary ( ) ; struct . setNullsIsSet ( true ) ; }",Smelly
 private static < S extends org . apache . thrift . scheme . IScheme > S scheme ( org . apache . thrift . protocol . TProtocol proto ) { return ( org . apache . thrift . scheme . StandardScheme . class . equals ( proto . getScheme ( ) ) ? STANDARD_SCHEME_FACTORY : TUPLE_SCHEME_FACTORY ) . getScheme ( ) ; },Smelly
" public void read ( org . apache . thrift . protocol . TProtocol prot , show_compact_result struct ) throws org . apache . thrift . TException { TTupleProtocol iprot = ( TTupleProtocol ) prot ; BitSet incoming = iprot . readBitSet ( 1 ) ; if ( incoming . get ( 0 ) ) { struct . success = new ShowCompactResponse ( ) ; struct . success . read ( iprot ) ; struct . setSuccessIsSet ( true ) ; } }",Smelly
 public int getFlags ( ) { return getToken ( ) > > 4 ; },No
" public void testProtoBufRpc ( ) throws Exception { RpcClient rpcClient = RpcClientFactory . createClient ( conf , HConstants . CLUSTER_ID_DEFAULT ) ; try { BlockingInterface stub = newBlockingStub ( rpcClient , this . isa ) ; TestProtos . EmptyRequestProto emptyRequest = TestProtos . EmptyRequestProto . newBuilder ( ) . build ( ) ; stub . ping ( null , emptyRequest ) ; EchoRequestProto echoRequest = EchoRequestProto . newBuilder ( ) . setMessage ( ""hello"" ) . build ( ) ; EchoResponseProto echoResponse = stub . echo ( null , echoRequest ) ; assertEquals ( ""hello"" , echoResponse . getMessage ( ) ) ; stub . error ( null , emptyRequest ) ; fail ( ""Expected exception is not thrown"" ) ; } finally { rpcClient . close ( ) ; } }",No
" void onRemove ( String interpreterGroupId , String name , String noteId , String paragraphId ) ;",No
" public void read ( org . apache . thrift . protocol . TProtocol prot , getChildDataProducts_result struct ) throws org . apache . thrift . TException { TTupleProtocol iprot = ( TTupleProtocol ) prot ; BitSet incoming = iprot . readBitSet ( 5 ) ; if ( incoming . get ( 0 ) ) { { org . apache . thrift . protocol . TList _list283 = new org . apache . thrift . protocol . TList ( org . apache . thrift . protocol . TType . STRUCT , iprot . readI32 ( ) ) ; struct . success = new ArrayList < org . apache . airavata . model . data . replica . DataProductModel > ( _list283 . size ) ; org . apache . airavata . model . data . replica . DataProductModel _elem284 ; for ( int _i285 = 0 ; _i285 < _list283 . size ; ++ _i285 ) { _elem284 = new org . apache . airavata . model . data . replica . DataProductModel ( ) ; _elem284 . read ( iprot ) ; struct . success . add ( _elem284 ) ; } } struct . setSuccessIsSet ( true ) ; } if ( incoming . get ( 1 ) ) { struct . ire = new org . apache . airavata . model . error . InvalidRequestException ( ) ; struct . ire . read ( iprot ) ; struct . setIreIsSet ( true ) ; } if ( incoming . get ( 2 ) ) { struct . ace = new org . apache . airavata . model . error . AiravataClientException ( ) ; struct . ace . read ( iprot ) ; struct . setAceIsSet ( true ) ; } if ( incoming . get ( 3 ) ) { struct . ase = new org . apache . airavata . model . error . AiravataSystemException ( ) ; struct . ase . read ( iprot ) ; struct . setAseIsSet ( true ) ; } if ( incoming . get ( 4 ) ) { struct . ae = new org . apache . airavata . model . error . AuthorizationException ( ) ; struct . ae . read ( iprot ) ; struct . setAeIsSet ( true ) ; } }",Smelly
 public void paint ( PaintingInfo paintInfo ) { RectanglePaintingInfo rectanglePaintInfo = ( RectanglePaintingInfo ) paintInfo ; int pageWidth = dataStream . getCurrentPage ( ) . getWidth ( ) ; int pageHeight = dataStream . getCurrentPage ( ) . getHeight ( ) ; int yNew ; AFPUnitConverter unitConv = paintingState . getUnitConverter ( ) ; float width = unitConv . pt2units ( rectanglePaintInfo . getWidth ( ) ) ; float height = unitConv . pt2units ( rectanglePaintInfo . getHeight ( ) ) ; float x = unitConv . pt2units ( rectanglePaintInfo . getX ( ) ) ; float y = unitConv . pt2units ( rectanglePaintInfo . getY ( ) ) ; AffineTransform at = paintingState . getData ( ) . getTransform ( ) ; AFPLineDataInfo lineDataInfo = new AFPLineDataInfo ( ) ; lineDataInfo . setColor ( paintingState . getColor ( ) ) ; lineDataInfo . setRotation ( paintingState . getRotation ( ) ) ; lineDataInfo . setThickness ( Math . round ( height ) ) ; switch ( lineDataInfo . getRotation ( ) ) { case 90 : lineDataInfo . setX1 ( Math . round ( ( float ) at . getTranslateY ( ) + x ) ) ; yNew = pageWidth - Math . round ( ( float ) at . getTranslateX ( ) ) + Math . round ( y ) ; lineDataInfo . setY1 ( yNew ) ; lineDataInfo . setY2 ( yNew ) ; lineDataInfo . setX2 ( Math . round ( width + ( float ) at . getTranslateY ( ) + x ) ) ; break ; case 180 : lineDataInfo . setX1 ( pageWidth - Math . round ( ( float ) at . getTranslateX ( ) - x ) ) ; yNew = pageHeight - Math . round ( ( float ) at . getTranslateY ( ) - y ) ; lineDataInfo . setY1 ( yNew ) ; lineDataInfo . setY2 ( yNew ) ; lineDataInfo . setX2 ( pageWidth - Math . round ( ( float ) at . getTranslateX ( ) - x - width ) ) ; break ; case 270 : lineDataInfo . setX1 ( pageHeight - Math . round ( ( float ) at . getTranslateY ( ) - x ) ) ; yNew = Math . round ( ( float ) at . getTranslateX ( ) + y ) ; lineDataInfo . setY1 ( yNew ) ; lineDataInfo . setY2 ( yNew ) ; lineDataInfo . setX2 ( pageHeight - Math . round ( ( float ) at . getTranslateY ( ) - x - width ) ) ; break ; case 0 : default : lineDataInfo . setX1 ( Math . round ( ( float ) at . getTranslateX ( ) + x ) ) ; yNew = Math . round ( ( float ) at . getTranslateY ( ) + y ) ; lineDataInfo . setY1 ( yNew ) ; lineDataInfo . setY2 ( yNew ) ; lineDataInfo . setX2 ( Math . round ( ( float ) at . getTranslateX ( ) + x + width ) ) ; break ; } dataStream . createLine ( lineDataInfo ) ; },Smelly
" public void eval ( ) { out . value = org . apache . drill . exec . expr . fn . impl . HashHelper . hash32 ( in . value , 0 ) ; }",No
" public void read ( org . apache . thrift . protocol . TProtocol prot , show_compact_result struct ) throws org . apache . thrift . TException { TTupleProtocol iprot = ( TTupleProtocol ) prot ; BitSet incoming = iprot . readBitSet ( 1 ) ; if ( incoming . get ( 0 ) ) { struct . success = new ShowCompactResponse ( ) ; struct . success . read ( iprot ) ; struct . setSuccessIsSet ( true ) ; } }",Smelly
" public void read ( org . apache . thrift . protocol . TProtocol prot , getChildDataProducts_result struct ) throws org . apache . thrift . TException { TTupleProtocol iprot = ( TTupleProtocol ) prot ; BitSet incoming = iprot . readBitSet ( 5 ) ; if ( incoming . get ( 0 ) ) { { org . apache . thrift . protocol . TList _list283 = new org . apache . thrift . protocol . TList ( org . apache . thrift . protocol . TType . STRUCT , iprot . readI32 ( ) ) ; struct . success = new ArrayList < org . apache . airavata . model . data . replica . DataProductModel > ( _list283 . size ) ; org . apache . airavata . model . data . replica . DataProductModel _elem284 ; for ( int _i285 = 0 ; _i285 < _list283 . size ; ++ _i285 ) { _elem284 = new org . apache . airavata . model . data . replica . DataProductModel ( ) ; _elem284 . read ( iprot ) ; struct . success . add ( _elem284 ) ; } } struct . setSuccessIsSet ( true ) ; } if ( incoming . get ( 1 ) ) { struct . ire = new org . apache . airavata . model . error . InvalidRequestException ( ) ; struct . ire . read ( iprot ) ; struct . setIreIsSet ( true ) ; } if ( incoming . get ( 2 ) ) { struct . ace = new org . apache . airavata . model . error . AiravataClientException ( ) ; struct . ace . read ( iprot ) ; struct . setAceIsSet ( true ) ; } if ( incoming . get ( 3 ) ) { struct . ase = new org . apache . airavata . model . error . AiravataSystemException ( ) ; struct . ase . read ( iprot ) ; struct . setAseIsSet ( true ) ; } if ( incoming . get ( 4 ) ) { struct . ae = new org . apache . airavata . model . error . AuthorizationException ( ) ; struct . ae . read ( iprot ) ; struct . setAeIsSet ( true ) ; } }",No
" public static < T > Query < T > of ( RelNode rel ) { return new Query < > ( null , null , rel ) ; }",No
 public void afterStateTransitions ( TransactionEvent event ) { },No
 private static < S extends org . apache . thrift . scheme . IScheme > S scheme ( org . apache . thrift . protocol . TProtocol proto ) { return ( org . apache . thrift . scheme . StandardScheme . class . equals ( proto . getScheme ( ) ) ? STANDARD_SCHEME_FACTORY : TUPLE_SCHEME_FACTORY ) . getScheme ( ) ; },Smelly
" public void read ( org . apache . thrift . protocol . TProtocol prot , getChildDataProducts_result struct ) throws org . apache . thrift . TException { TTupleProtocol iprot = ( TTupleProtocol ) prot ; BitSet incoming = iprot . readBitSet ( 5 ) ; if ( incoming . get ( 0 ) ) { { org . apache . thrift . protocol . TList _list283 = new org . apache . thrift . protocol . TList ( org . apache . thrift . protocol . TType . STRUCT , iprot . readI32 ( ) ) ; struct . success = new ArrayList < org . apache . airavata . model . data . replica . DataProductModel > ( _list283 . size ) ; org . apache . airavata . model . data . replica . DataProductModel _elem284 ; for ( int _i285 = 0 ; _i285 < _list283 . size ; ++ _i285 ) { _elem284 = new org . apache . airavata . model . data . replica . DataProductModel ( ) ; _elem284 . read ( iprot ) ; struct . success . add ( _elem284 ) ; } } struct . setSuccessIsSet ( true ) ; } if ( incoming . get ( 1 ) ) { struct . ire = new org . apache . airavata . model . error . InvalidRequestException ( ) ; struct . ire . read ( iprot ) ; struct . setIreIsSet ( true ) ; } if ( incoming . get ( 2 ) ) { struct . ace = new org . apache . airavata . model . error . AiravataClientException ( ) ; struct . ace . read ( iprot ) ; struct . setAceIsSet ( true ) ; } if ( incoming . get ( 3 ) ) { struct . ase = new org . apache . airavata . model . error . AiravataSystemException ( ) ; struct . ase . read ( iprot ) ; struct . setAseIsSet ( true ) ; } if ( incoming . get ( 4 ) ) { struct . ae = new org . apache . airavata . model . error . AuthorizationException ( ) ; struct . ae . read ( iprot ) ; struct . setAeIsSet ( true ) ; } }",No
" public HttpServiceResponse handle ( HttpServiceRequest request ) throws Exception { HttpServiceResponse response = new HttpServiceResponse ( ) ; Map < String , String > params = request . getParams ( ) ; if ( HttpServer . Method . GET == request . getMethod ( ) ) { final String includingBookieId ; final String excludingBookieId ; if ( params != null && params . containsKey ( ""missingreplica"" ) ) { includingBookieId = params . get ( ""missingreplica"" ) ; } else { includingBookieId = null ; } if ( params != null && params . containsKey ( ""excludingmissingreplica"" ) ) { excludingBookieId = params . get ( ""excludingmissingreplica"" ) ; } else { excludingBookieId = null ; } Predicate < List < String > > predicate = null ; if ( ! StringUtils . isBlank ( includingBookieId ) && ! StringUtils . isBlank ( excludingBookieId ) ) { predicate = replicasList -> ( replicasList . contains ( includingBookieId ) && ! replicasList . contains ( excludingBookieId ) ) ; } else if ( ! StringUtils . isBlank ( includingBookieId ) ) { predicate = replicasList -> replicasList . contains ( includingBookieId ) ; } else if ( ! StringUtils . isBlank ( excludingBookieId ) ) { predicate = replicasList -> ! replicasList . contains ( excludingBookieId ) ; } try { List < Long > outputLedgers = Lists . newArrayList ( ) ; LedgerManagerFactory mFactory = LedgerManagerFactory . newLedgerManagerFactory ( conf , zk ) ; LedgerUnderreplicationManager underreplicationManager = mFactory . newLedgerUnderreplicationManager ( ) ; Iterator < Long > iter = underreplicationManager . listLedgersToRereplicate ( predicate ) ; while ( iter . hasNext ( ) ) { outputLedgers . add ( iter . next ( ) ) ; } if ( outputLedgers . isEmpty ( ) ) { response . setCode ( HttpServer . StatusCode . NOT_FOUND ) ; response . setBody ( ""No under replicated ledgers found"" ) ; return response ; } else { response . setCode ( HttpServer . StatusCode . OK ) ; String jsonResponse = JsonUtil . toJson ( outputLedgers ) ; LOG . debug ( ""output body: "" + jsonResponse ) ; response . setBody ( jsonResponse ) ; return response ; } } catch ( Exception e ) { LOG . error ( ""Exception occurred while listing under replicated ledgers"" , e ) ; response . setCode ( HttpServer . StatusCode . NOT_FOUND ) ; response . setBody ( ""Exception when get."" + e . getMessage ( ) ) ; return response ; } } else { response . setCode ( HttpServer . StatusCode . NOT_FOUND ) ; response . setBody ( ""Not found method. Should be GET method"" ) ; return response ; } }",Smelly
" private boolean checkUnrestrictedPoliciesInstalled ( ) { try { byte [ ] data = { 0x00 , 0x01 , 0x02 , 0x03 , 0x04 , 0x05 , 0x06 , 0x07 } ; SecretKey key192 = new SecretKeySpec ( new byte [ ] { 0x00 , 0x01 , 0x02 , 0x03 , 0x04 , 0x05 , 0x06 , 0x07 , 0x08 , 0x09 , 0x0a , 0x0b , 0x0c , 0x0d , 0x0e , 0x0f , 0x10 , 0x11 , 0x12 , 0x13 , 0x14 , 0x15 , 0x16 , 0x17 } , ""AES"" ) ; Cipher c = Cipher . getInstance ( ""AES"" ) ; c . init ( Cipher . ENCRYPT_MODE , key192 ) ; c . doFinal ( data ) ; return true ; } catch ( Exception e ) { } return false ; }",No
" private static void transformSideInputs ( List < PCollectionView < ? > > sideInputs , SingleInputUdfOperator < ? , ? , ? > outputDataSet , FlinkBatchTranslationContext context ) { for ( PCollectionView < ? > input : sideInputs ) { DataSet < ? > broadcastSet = context . getSideInputDataSet ( input ) ; outputDataSet . withBroadcastSet ( broadcastSet , input . getTagInternal ( ) . getId ( ) ) ; } }",No
" public static void generateOrcFile ( Configuration conf , FileSystem fs , Path outputPath , Class recordClass ) throws IOException , InstantiationException , IllegalAccessException , InvocationTargetException { ObjectInspector inspector ; synchronized ( TestVectorizedORCReader . class ) { inspector = ObjectInspectorFactory . getReflectionObjectInspector ( recordClass , ObjectInspectorFactory . ObjectInspectorOptions . JAVA ) ; } Writer writer = OrcFile . createWriter ( fs , outputPath , conf , inspector , 100000 , CompressionKind . ZLIB , 10000 , 10000 ) ; try { Constructor [ ] constructors = recordClass . getConstructors ( ) ; if ( constructors . length != 1 ) { throw new UnsupportedOperationException ( ""The provided recordClass must have exactly one constructor."" ) ; } BatchDataDistribution [ ] dataDist = BatchDataDistribution . values ( ) ; Class [ ] columns = constructors [ 0 ] . getParameterTypes ( ) ; for ( int i = 0 ; i < dataDist . length * 3 ; i ++ ) { Object [ ] [ ] rows = new Object [ columns . length ] [ VectorizedRowBatch . DEFAULT_SIZE ] ; for ( int c = 0 ; c < columns . length ; c ++ ) { if ( ! TYPE_TO_BATCH_GEN_MAP . containsKey ( columns [ c ] ) ) { throw new UnsupportedOperationException ( ""No batch generator defined for type "" + columns [ c ] . getName ( ) ) ; } rows [ c ] = TYPE_TO_BATCH_GEN_MAP . get ( columns [ c ] ) . generateBatch ( dataDist [ ( i + c ) % dataDist . length ] ) ; } for ( int r = 0 ; r < VectorizedRowBatch . DEFAULT_SIZE ; r ++ ) { Object [ ] row = new Object [ columns . length ] ; for ( int c = 0 ; c < columns . length ; c ++ ) { row [ c ] = rows [ c ] [ r ] ; } writer . addRow ( constructors [ 0 ] . newInstance ( row ) ) ; } } } finally { writer . close ( ) ; } }",No
 public int read ( ) { return - 1 ; },No
" public void read ( org . apache . thrift . protocol . TProtocol prot , getChildDataProducts_result struct ) throws org . apache . thrift . TException { TTupleProtocol iprot = ( TTupleProtocol ) prot ; BitSet incoming = iprot . readBitSet ( 5 ) ; if ( incoming . get ( 0 ) ) { { org . apache . thrift . protocol . TList _list283 = new org . apache . thrift . protocol . TList ( org . apache . thrift . protocol . TType . STRUCT , iprot . readI32 ( ) ) ; struct . success = new ArrayList < org . apache . airavata . model . data . replica . DataProductModel > ( _list283 . size ) ; org . apache . airavata . model . data . replica . DataProductModel _elem284 ; for ( int _i285 = 0 ; _i285 < _list283 . size ; ++ _i285 ) { _elem284 = new org . apache . airavata . model . data . replica . DataProductModel ( ) ; _elem284 . read ( iprot ) ; struct . success . add ( _elem284 ) ; } } struct . setSuccessIsSet ( true ) ; } if ( incoming . get ( 1 ) ) { struct . ire = new org . apache . airavata . model . error . InvalidRequestException ( ) ; struct . ire . read ( iprot ) ; struct . setIreIsSet ( true ) ; } if ( incoming . get ( 2 ) ) { struct . ace = new org . apache . airavata . model . error . AiravataClientException ( ) ; struct . ace . read ( iprot ) ; struct . setAceIsSet ( true ) ; } if ( incoming . get ( 3 ) ) { struct . ase = new org . apache . airavata . model . error . AiravataSystemException ( ) ; struct . ase . read ( iprot ) ; struct . setAseIsSet ( true ) ; } if ( incoming . get ( 4 ) ) { struct . ae = new org . apache . airavata . model . error . AuthorizationException ( ) ; struct . ae . read ( iprot ) ; struct . setAeIsSet ( true ) ; } }",Smelly
" public static void main ( String [ ] args ) { Injector injector = Guice . createInjector ( new QuickstartShiroModule ( ) ) ; SecurityManager securityManager = injector . getInstance ( SecurityManager . class ) ; SecurityUtils . setSecurityManager ( securityManager ) ; Subject currentUser = SecurityUtils . getSubject ( ) ; Session session = currentUser . getSession ( ) ; session . setAttribute ( ""someKey"" , ""aValue"" ) ; String value = ( String ) session . getAttribute ( ""someKey"" ) ; if ( value . equals ( ""aValue"" ) ) { log . info ( ""Retrieved the correct value! ["" + value + ""]"" ) ; } if ( ! currentUser . isAuthenticated ( ) ) { UsernamePasswordToken token = new UsernamePasswordToken ( ""lonestarr"" , ""vespa"" ) ; token . setRememberMe ( true ) ; try { currentUser . login ( token ) ; } catch ( UnknownAccountException uae ) { log . info ( ""There is no user with username of "" + token . getPrincipal ( ) ) ; } catch ( IncorrectCredentialsException ice ) { log . info ( ""Password for account "" + token . getPrincipal ( ) + "" was incorrect!"" ) ; } catch ( LockedAccountException lae ) { log . info ( ""The account for username "" + token . getPrincipal ( ) + "" is locked.  "" + ""Please contact your administrator to unlock it."" ) ; } catch ( AuthenticationException ae ) { } } log . info ( ""User ["" + currentUser . getPrincipal ( ) + ""] logged in successfully."" ) ; if ( currentUser . hasRole ( ""schwartz"" ) ) { log . info ( ""May the Schwartz be with you!"" ) ; } else { log . info ( ""Hello, mere mortal."" ) ; } if ( currentUser . isPermitted ( ""lightsaber:weild"" ) ) { log . info ( ""You may use a lightsaber ring.  Use it wisely."" ) ; } else { log . info ( ""Sorry, lightsaber rings are for schwartz masters only."" ) ; } if ( currentUser . isPermitted ( ""winnebago:drive:eagle5"" ) ) { log . info ( ""You are permitted to 'drive' the winnebago with license plate (id) 'eagle5'.  "" + ""Here are the keys - have fun!"" ) ; } else { log . info ( ""Sorry, you aren't allowed to drive the 'eagle5' winnebago!"" ) ; } currentUser . logout ( ) ; System . exit ( 0 ) ; }",Smelly
 private static < S extends org . apache . thrift . scheme . IScheme > S scheme ( org . apache . thrift . protocol . TProtocol proto ) { return ( org . apache . thrift . scheme . StandardScheme . class . equals ( proto . getScheme ( ) ) ? STANDARD_SCHEME_FACTORY : TUPLE_SCHEME_FACTORY ) . getScheme ( ) ; },Smelly
" public void read ( org . apache . thrift . protocol . TProtocol prot , BinaryColumnStatsData struct ) throws org . apache . thrift . TException { TTupleProtocol iprot = ( TTupleProtocol ) prot ; struct . maxColLen = iprot . readI64 ( ) ; struct . setMaxColLenIsSet ( true ) ; struct . avgColLen = iprot . readDouble ( ) ; struct . setAvgColLenIsSet ( true ) ; struct . numNulls = iprot . readI64 ( ) ; struct . setNumNullsIsSet ( true ) ; }",Smelly
" public void read ( org . apache . thrift . protocol . TProtocol prot , StringColumnStatsData struct ) throws org . apache . thrift . TException { TTupleProtocol iprot = ( TTupleProtocol ) prot ; struct . maxColLen = iprot . readI64 ( ) ; struct . setMaxColLenIsSet ( true ) ; struct . avgColLen = iprot . readDouble ( ) ; struct . setAvgColLenIsSet ( true ) ; struct . numNulls = iprot . readI64 ( ) ; struct . setNumNullsIsSet ( true ) ; struct . numDVs = iprot . readI64 ( ) ; struct . setNumDVsIsSet ( true ) ; }",Smelly
" protected String getMBeanAttributeType ( MBeanServerConnection jmxServerConnection , String name , String attribute ) throws Exception { ObjectName oname = new ObjectName ( name ) ; String mattrType = null ; MBeanInfo minfo = jmxServerConnection . getMBeanInfo ( oname ) ; MBeanAttributeInfo attrs [ ] = minfo . getAttributes ( ) ; if ( attrs != null ) { for ( int i = 0 ; mattrType == null && i < attrs . length ; i ++ ) { if ( attribute . equals ( attrs [ i ] . getName ( ) ) ) mattrType = attrs [ i ] . getType ( ) ; } } return mattrType ; }",No
" protected void populateObject ( Object object ) throws Exception { super . populateObject ( object ) ; SessionInfo info = ( SessionInfo ) object ; info . setSessionId ( createSessionId ( ""SessionId:1"" ) ) ; }",No
" public void read ( org . apache . thrift . protocol . TProtocol prot , Graph struct ) throws org . apache . thrift . TException { TTupleProtocol iprot = ( TTupleProtocol ) prot ; BitSet incoming = iprot . readBitSet ( 3 ) ; if ( incoming . get ( 0 ) ) { struct . nodeType = NodeType . findByValue ( iprot . readI32 ( ) ) ; struct . setNodeTypeIsSet ( true ) ; } if ( incoming . get ( 1 ) ) { { org . apache . thrift . protocol . TList _list18 = new org . apache . thrift . protocol . TList ( org . apache . thrift . protocol . TType . STRING , iprot . readI32 ( ) ) ; struct . roots = new ArrayList < String > ( _list18 . size ) ; for ( int _i19 = 0 ; _i19 < _list18 . size ; ++ _i19 ) { String _elem20 ; _elem20 = iprot . readString ( ) ; struct . roots . add ( _elem20 ) ; } } struct . setRootsIsSet ( true ) ; } if ( incoming . get ( 2 ) ) { { org . apache . thrift . protocol . TList _list21 = new org . apache . thrift . protocol . TList ( org . apache . thrift . protocol . TType . STRUCT , iprot . readI32 ( ) ) ; struct . adjacencyList = new ArrayList < Adjacency > ( _list21 . size ) ; for ( int _i22 = 0 ; _i22 < _list21 . size ; ++ _i22 ) { Adjacency _elem23 ; _elem23 = new Adjacency ( ) ; _elem23 . read ( iprot ) ; struct . adjacencyList . add ( _elem23 ) ; } } struct . setAdjacencyListIsSet ( true ) ; } }",Smelly
" public com . google . protobuf . ExtensionRegistry assignDescriptors ( com . google . protobuf . Descriptors . FileDescriptor root ) { descriptor = root ; internal_static_org_apache_hadoop_hive_ql_io_orc_IntegerStatistics_descriptor = getDescriptor ( ) . getMessageTypes ( ) . get ( 0 ) ; internal_static_org_apache_hadoop_hive_ql_io_orc_IntegerStatistics_fieldAccessorTable = new com . google . protobuf . GeneratedMessage . FieldAccessorTable ( internal_static_org_apache_hadoop_hive_ql_io_orc_IntegerStatistics_descriptor , new java . lang . String [ ] { ""Minimum"" , ""Maximum"" , ""Sum"" , } ) ; internal_static_org_apache_hadoop_hive_ql_io_orc_DoubleStatistics_descriptor = getDescriptor ( ) . getMessageTypes ( ) . get ( 1 ) ; internal_static_org_apache_hadoop_hive_ql_io_orc_DoubleStatistics_fieldAccessorTable = new com . google . protobuf . GeneratedMessage . FieldAccessorTable ( internal_static_org_apache_hadoop_hive_ql_io_orc_DoubleStatistics_descriptor , new java . lang . String [ ] { ""Minimum"" , ""Maximum"" , ""Sum"" , } ) ; internal_static_org_apache_hadoop_hive_ql_io_orc_StringStatistics_descriptor = getDescriptor ( ) . getMessageTypes ( ) . get ( 2 ) ; internal_static_org_apache_hadoop_hive_ql_io_orc_StringStatistics_fieldAccessorTable = new com . google . protobuf . GeneratedMessage . FieldAccessorTable ( internal_static_org_apache_hadoop_hive_ql_io_orc_StringStatistics_descriptor , new java . lang . String [ ] { ""Minimum"" , ""Maximum"" , ""Sum"" , } ) ; internal_static_org_apache_hadoop_hive_ql_io_orc_BucketStatistics_descriptor = getDescriptor ( ) . getMessageTypes ( ) . get ( 3 ) ; internal_static_org_apache_hadoop_hive_ql_io_orc_BucketStatistics_fieldAccessorTable = new com . google . protobuf . GeneratedMessage . FieldAccessorTable ( internal_static_org_apache_hadoop_hive_ql_io_orc_BucketStatistics_descriptor , new java . lang . String [ ] { ""Count"" , } ) ; internal_static_org_apache_hadoop_hive_ql_io_orc_DecimalStatistics_descriptor = getDescriptor ( ) . getMessageTypes ( ) . get ( 4 ) ; internal_static_org_apache_hadoop_hive_ql_io_orc_DecimalStatistics_fieldAccessorTable = new com . google . protobuf . GeneratedMessage . FieldAccessorTable ( internal_static_org_apache_hadoop_hive_ql_io_orc_DecimalStatistics_descriptor , new java . lang . String [ ] { ""Minimum"" , ""Maximum"" , ""Sum"" , } ) ; internal_static_org_apache_hadoop_hive_ql_io_orc_DateStatistics_descriptor = getDescriptor ( ) . getMessageTypes ( ) . get ( 5 ) ; internal_static_org_apache_hadoop_hive_ql_io_orc_DateStatistics_fieldAccessorTable = new com . google . protobuf . GeneratedMessage . FieldAccessorTable ( internal_static_org_apache_hadoop_hive_ql_io_orc_DateStatistics_descriptor , new java . lang . String [ ] { ""Minimum"" , ""Maximum"" , } ) ; internal_static_org_apache_hadoop_hive_ql_io_orc_BinaryStatistics_descriptor = getDescriptor ( ) . getMessageTypes ( ) . get ( 6 ) ; internal_static_org_apache_hadoop_hive_ql_io_orc_BinaryStatistics_fieldAccessorTable = new com . google . protobuf . GeneratedMessage . FieldAccessorTable ( internal_static_org_apache_hadoop_hive_ql_io_orc_BinaryStatistics_descriptor , new java . lang . String [ ] { ""Sum"" , } ) ; internal_static_org_apache_hadoop_hive_ql_io_orc_ColumnStatistics_descriptor = getDescriptor ( ) . getMessageTypes ( ) . get ( 7 ) ; internal_static_org_apache_hadoop_hive_ql_io_orc_ColumnStatistics_fieldAccessorTable = new com . google . protobuf . GeneratedMessage . FieldAccessorTable ( internal_static_org_apache_hadoop_hive_ql_io_orc_ColumnStatistics_descriptor , new java . lang . String [ ] { ""NumberOfValues"" , ""IntStatistics"" , ""DoubleStatistics"" , ""StringStatistics"" , ""BucketStatistics"" , ""DecimalStatistics"" , ""DateStatistics"" , ""BinaryStatistics"" , } ) ; internal_static_org_apache_hadoop_hive_ql_io_orc_RowIndexEntry_descriptor = getDescriptor ( ) . getMessageTypes ( ) . get ( 8 ) ; internal_static_org_apache_hadoop_hive_ql_io_orc_RowIndexEntry_fieldAccessorTable = new com . google . protobuf . GeneratedMessage . FieldAccessorTable ( internal_static_org_apache_hadoop_hive_ql_io_orc_RowIndexEntry_descriptor , new java . lang . String [ ] { ""Positions"" , ""Statistics"" , } ) ; internal_static_org_apache_hadoop_hive_ql_io_orc_RowIndex_descriptor = getDescriptor ( ) . getMessageTypes ( ) . get ( 9 ) ; internal_static_org_apache_hadoop_hive_ql_io_orc_RowIndex_fieldAccessorTable = new com . google . protobuf . GeneratedMessage . FieldAccessorTable ( internal_static_org_apache_hadoop_hive_ql_io_orc_RowIndex_descriptor , new java . lang . String [ ] { ""Entry"" , } ) ; internal_static_org_apache_hadoop_hive_ql_io_orc_Stream_descriptor = getDescriptor ( ) . getMessageTypes ( ) . get ( 10 ) ; internal_static_org_apache_hadoop_hive_ql_io_orc_Stream_fieldAccessorTable = new com . google . protobuf . GeneratedMessage . FieldAccessorTable ( internal_static_org_apache_hadoop_hive_ql_io_orc_Stream_descriptor , new java . lang . String [ ] { ""Kind"" , ""Column"" , ""Length"" , } ) ; internal_static_org_apache_hadoop_hive_ql_io_orc_ColumnEncoding_descriptor = getDescriptor ( ) . getMessageTypes ( ) . get ( 11 ) ; internal_static_org_apache_hadoop_hive_ql_io_orc_ColumnEncoding_fieldAccessorTable = new com . google . protobuf . GeneratedMessage . FieldAccessorTable ( internal_static_org_apache_hadoop_hive_ql_io_orc_ColumnEncoding_descriptor , new java . lang . String [ ] { ""Kind"" , ""DictionarySize"" , } ) ; internal_static_org_apache_hadoop_hive_ql_io_orc_StripeFooter_descriptor = getDescriptor ( ) . getMessageTypes ( ) . get ( 12 ) ; internal_static_org_apache_hadoop_hive_ql_io_orc_StripeFooter_fieldAccessorTable = new com . google . protobuf . GeneratedMessage . FieldAccessorTable ( internal_static_org_apache_hadoop_hive_ql_io_orc_StripeFooter_descriptor , new java . lang . String [ ] { ""Streams"" , ""Columns"" , } ) ; internal_static_org_apache_hadoop_hive_ql_io_orc_Type_descriptor = getDescriptor ( ) . getMessageTypes ( ) . get ( 13 ) ; internal_static_org_apache_hadoop_hive_ql_io_orc_Type_fieldAccessorTable = new com . google . protobuf . GeneratedMessage . FieldAccessorTable ( internal_static_org_apache_hadoop_hive_ql_io_orc_Type_descriptor , new java . lang . String [ ] { ""Kind"" , ""Subtypes"" , ""FieldNames"" , ""MaximumLength"" , ""Precision"" , ""Scale"" , } ) ; internal_static_org_apache_hadoop_hive_ql_io_orc_StripeInformation_descriptor = getDescriptor ( ) . getMessageTypes ( ) . get ( 14 ) ; internal_static_org_apache_hadoop_hive_ql_io_orc_StripeInformation_fieldAccessorTable = new com . google . protobuf . GeneratedMessage . FieldAccessorTable ( internal_static_org_apache_hadoop_hive_ql_io_orc_StripeInformation_descriptor , new java . lang . String [ ] { ""Offset"" , ""IndexLength"" , ""DataLength"" , ""FooterLength"" , ""NumberOfRows"" , } ) ; internal_static_org_apache_hadoop_hive_ql_io_orc_UserMetadataItem_descriptor = getDescriptor ( ) . getMessageTypes ( ) . get ( 15 ) ; internal_static_org_apache_hadoop_hive_ql_io_orc_UserMetadataItem_fieldAccessorTable = new com . google . protobuf . GeneratedMessage . FieldAccessorTable ( internal_static_org_apache_hadoop_hive_ql_io_orc_UserMetadataItem_descriptor , new java . lang . String [ ] { ""Name"" , ""Value"" , } ) ; internal_static_org_apache_hadoop_hive_ql_io_orc_StripeStatistics_descriptor = getDescriptor ( ) . getMessageTypes ( ) . get ( 16 ) ; internal_static_org_apache_hadoop_hive_ql_io_orc_StripeStatistics_fieldAccessorTable = new com . google . protobuf . GeneratedMessage . FieldAccessorTable ( internal_static_org_apache_hadoop_hive_ql_io_orc_StripeStatistics_descriptor , new java . lang . String [ ] { ""ColStats"" , } ) ; internal_static_org_apache_hadoop_hive_ql_io_orc_Metadata_descriptor = getDescriptor ( ) . getMessageTypes ( ) . get ( 17 ) ; internal_static_org_apache_hadoop_hive_ql_io_orc_Metadata_fieldAccessorTable = new com . google . protobuf . GeneratedMessage . FieldAccessorTable ( internal_static_org_apache_hadoop_hive_ql_io_orc_Metadata_descriptor , new java . lang . String [ ] { ""StripeStats"" , } ) ; internal_static_org_apache_hadoop_hive_ql_io_orc_Footer_descriptor = getDescriptor ( ) . getMessageTypes ( ) . get ( 18 ) ; internal_static_org_apache_hadoop_hive_ql_io_orc_Footer_fieldAccessorTable = new com . google . protobuf . GeneratedMessage . FieldAccessorTable ( internal_static_org_apache_hadoop_hive_ql_io_orc_Footer_descriptor , new java . lang . String [ ] { ""HeaderLength"" , ""ContentLength"" , ""Stripes"" , ""Types"" , ""Metadata"" , ""NumberOfRows"" , ""Statistics"" , ""RowIndexStride"" , } ) ; internal_static_org_apache_hadoop_hive_ql_io_orc_PostScript_descriptor = getDescriptor ( ) . getMessageTypes ( ) . get ( 19 ) ; internal_static_org_apache_hadoop_hive_ql_io_orc_PostScript_fieldAccessorTable = new com . google . protobuf . GeneratedMessage . FieldAccessorTable ( internal_static_org_apache_hadoop_hive_ql_io_orc_PostScript_descriptor , new java . lang . String [ ] { ""FooterLength"" , ""Compression"" , ""CompressionBlockSize"" , ""Version"" , ""MetadataLength"" , ""Magic"" , } ) ; return null ; }",No
" public void onTrigger ( final ProcessContext context , final ProcessSession session ) throws ProcessException { FlowFile flowFile = session . get ( ) ; if ( flowFile == null ) { return ; } for ( int i = 1 ; i <= context . getProperty ( NUM_COPIES ) . evaluateAttributeExpressions ( flowFile ) . asInteger ( ) ; i ++ ) { FlowFile copy = session . clone ( flowFile ) ; copy = session . putAttribute ( copy , COPY_INDEX_ATTRIBUTE , Integer . toString ( i ) ) ; session . transfer ( copy , REL_SUCCESS ) ; } flowFile = session . putAttribute ( flowFile , COPY_INDEX_ATTRIBUTE , ""0"" ) ; session . transfer ( flowFile , REL_SUCCESS ) ; }",No
