Code,Smelly
" private static class RequestData { private String name ; private RangerAccessRequest request ; private RangerAccessResult result ; public RequestData ( ) { this ( null , null , null ) ; } public RequestData ( String name , RangerAccessRequest request , RangerAccessResult result ) { setName ( name ) ; setRequest ( request ) ; setResult ( result ) ; } public String getName ( ) { return name ; } public RangerAccessRequest getRequest ( ) { return request ; } public RangerAccessResult getResult ( ) { return result ; } public void setName ( String name ) { this . name = name ; } public void setRequest ( RangerAccessRequest request ) { this . request = request ; } public void setResult ( RangerAccessResult result ) { this . result = result ; } } ",Smelly
"public class EdmCastImpl extends AbstractEdmAnnotatableDynamicExpression implements EdmCast { private final CsdlCast cast ; private EdmExpression value ; private EdmType type ; public EdmCastImpl ( final Edm edm , final CsdlCast csdlExp ) { super ( edm , ""Cast"" , csdlExp ) ; this . cast = csdlExp ; } @ Override public Integer getMaxLength ( ) { return cast . getMaxLength ( ) ; } @ Override public Integer getPrecision ( ) { return cast . getPrecision ( ) ; } @ Override public Integer getScale ( ) { return cast . getScale ( ) ; } @ Override public SRID getSrid ( ) { return cast . getSrid ( ) ; } @ Override public EdmType getType ( ) { if ( type == null ) { if ( cast . getType ( ) == null ) { throw new EdmException ( ""Must specify a type for a Cast expression."" ) ; } final EdmTypeInfo typeInfo = new EdmTypeInfo . Builder ( ) . setEdm ( edm ) . setTypeExpression ( cast . getType ( ) ) . build ( ) ; type = typeInfo . getType ( ) ; } return type ; } @ Override public EdmExpression getValue ( ) { if ( value == null ) { if ( cast . getValue ( ) == null ) { throw new EdmException ( ""Cast expressions require an expression value."" ) ; } value = getExpression ( edm , cast . getValue ( ) ) ; } return value ; } @ Override public EdmExpressionType getExpressionType ( ) { return EdmExpressionType . Cast ; } }",Smelly
public class StubSSLSocket extends SSLSocket { public static final int UNTOUCHED = - 1 ; public static final int FALSE = 0 ; public static final int TRUE = 1 ; private int wantClientAuthStatus = UNTOUCHED ; private int needClientAuthStatus = UNTOUCHED ; private int useClientModeStatus = UNTOUCHED ; private final StubSSLSession session ; public StubSSLSocket ( StubSSLSession ses ) { this . session = ses ; } public void setWantClientAuth ( boolean arg0 ) { this . wantClientAuthStatus = arg0 ? TRUE : FALSE ; } public void setNeedClientAuth ( boolean arg0 ) { this . needClientAuthStatus = arg0 ? TRUE : FALSE ; if ( session != null ) { this . session . setIsVerified ( arg0 ) ; } } public void setUseClientMode ( boolean arg0 ) { useClientModeStatus = arg0 ? TRUE : FALSE ; } public boolean getWantClientAuth ( ) { return wantClientAuthStatus == TRUE ; } public boolean getNeedClientAuth ( ) { return needClientAuthStatus == TRUE ; } public boolean getUseClientMode ( ) { return useClientModeStatus == TRUE ; } public int getWantClientAuthStatus ( ) { return wantClientAuthStatus ; } public int getNeedClientAuthStatus ( ) { return needClientAuthStatus ; } public int getUseClientModeStatus ( ) { return useClientModeStatus ; } public SSLSession getSession ( ) { return this . session ; } public String [ ] getSupportedCipherSuites ( ) { return null ; } public String [ ] getEnabledCipherSuites ( ) { return null ; } public void setEnabledCipherSuites ( String [ ] arg0 ) { } public String [ ] getSupportedProtocols ( ) { return null ; } public String [ ] getEnabledProtocols ( ) { return null ; } public void setEnabledProtocols ( String [ ] arg0 ) { } public void addHandshakeCompletedListener ( HandshakeCompletedListener arg0 ) { } public void removeHandshakeCompletedListener ( HandshakeCompletedListener arg0 ) { } public void startHandshake ( ) throws IOException { } public void setEnableSessionCreation ( boolean arg0 ) { } public boolean getEnableSessionCreation ( ) { return false ; } },Smelly
" public static class YAMLClusterConfig { public String clusterName ; public List < ResourceConfig > resources ; public List < ParticipantConfig > participants ; public Boolean autoJoinAllowed ; public static class ResourceConfig { public String name ; public Map < String , String > rebalancer ; public Map < String , Integer > partitions ; public StateModelConfig stateModel ; public ConstraintsConfig constraints ; public Boolean batchMessageMode ; public static class StateModelConfig { public String name ; public List < String > states ; public List < Map < String , String > > transitions ; public String initialState ; } public static class ConstraintsConfig { public StateConstraintsConfig state ; public TransitionConstraintsConfig transition ; public static class StateConstraintsConfig { public List < Map < String , String > > counts ; public List < String > priorityList ; } public static class TransitionConstraintsConfig { public List < String > priorityList ; } } } public static class ParticipantConfig { public String name ; public String host ; public Integer port ; } ",Smelly
"public class BookServerRestSoap extends AbstractBusTestServerBase { public static final String PORT = allocatePort ( BookServerRestSoap . class ) ; private org . eclipse . jetty . server . Server server ; protected void run ( ) { server = new org . eclipse . jetty . server . Server ( ) ; SelectChannelConnector connector = new SelectChannelConnector ( ) ; connector . setPort ( Integer . parseInt ( PORT ) ) ; server . setConnectors ( new Connector [ ] { connector } ) ; WebAppContext webappcontext = new WebAppContext ( ) ; String contextPath = null ; try { contextPath = getClass ( ) . getResource ( ""/jaxrs_soap_rest"" ) . toURI ( ) . getPath ( ) ; } catch ( URISyntaxException e1 ) { e1 . printStackTrace ( ) ; } webappcontext . setContextPath ( ""/test"" ) ; webappcontext . setWar ( contextPath ) ; HandlerCollection handlers = new HandlerCollection ( ) ; handlers . setHandlers ( new Handler [ ] { webappcontext , new DefaultHandler ( ) } ) ; server . setHandler ( handlers ) ; try { server . start ( ) ; } catch ( Exception e ) { e . printStackTrace ( ) ; } } public void tearDown ( ) throws Exception { super . tearDown ( ) ; if ( server != null ) { server . stop ( ) ; server . destroy ( ) ; server = null ; } } public static void main ( String args [ ] ) { try { BookServerRestSoap s = new BookServerRestSoap ( ) ; s . start ( ) ; } catch ( Exception ex ) { ex . printStackTrace ( ) ; System . exit ( - 1 ) ; } finally { System . out . println ( ""done!"" ) ; } } }",No
"@ Explain ( displayName = ""Lock Table"" ) public class LockTableDesc extends DDLDesc implements Serializable { private static final long serialVersionUID = 1L ; private String tableName ; private String mode ; private Map < String , String > partSpec ; private String queryId ; private String queryStr ; public LockTableDesc ( ) { } public LockTableDesc ( String tableName , String mode , Map < String , String > partSpec , String queryId ) { this . tableName = tableName ; this . mode = mode ; this . partSpec = partSpec ; this . queryId = queryId ; } public String getTableName ( ) { return tableName ; } public void setTableName ( String tableName ) { this . tableName = tableName ; } public void setMode ( String mode ) { this . mode = mode ; } public String getMode ( ) { return mode ; } public Map < String , String > getPartSpec ( ) { return partSpec ; } public void setPartSpec ( Map < String , String > partSpec ) { this . partSpec = partSpec ; } public String getQueryId ( ) { return queryId ; } public void setQueryId ( String queryId ) { this . queryId = queryId ; } public String getQueryStr ( ) { return queryStr ; } public void setQueryStr ( String queryStr ) { this . queryStr = queryStr ; } }",Smelly
"@ SuppressWarnings ( ""deprecation"" ) public class MessageBuilderImpl implements MessageBuilder { private static final ByteBuffer EMPTY_CONTENT = ByteBuffer . allocate ( 0 ) ; private final MessageMetadata . Builder msgMetadataBuilder = MessageMetadata . newBuilder ( ) ; private ByteBuffer content = EMPTY_CONTENT ; @ Override public Message < byte [ ] > build ( ) { return MessageImpl . create ( msgMetadataBuilder , content , Schema . BYTES ) ; } @ Override public MessageBuilder setContent ( byte [ ] data ) { setContent ( data , 0 , data . length ) ; return this ; } @ Override public MessageBuilder setContent ( byte [ ] data , int offet , int length ) { this . content = ByteBuffer . wrap ( data , offet , length ) ; return this ; } @ Override public MessageBuilder setContent ( ByteBuffer buf ) { this . content = buf . duplicate ( ) ; return this ; } @ Override public MessageBuilder setProperties ( Map < String , String > properties ) { for ( Map . Entry < String , String > entry : properties . entrySet ( ) ) { msgMetadataBuilder . addProperties ( KeyValue . newBuilder ( ) . setKey ( entry . getKey ( ) ) . setValue ( entry . getValue ( ) ) . build ( ) ) ; } return this ; } @ Override public MessageBuilder setProperty ( String name , String value ) { msgMetadataBuilder . addProperties ( KeyValue . newBuilder ( ) . setKey ( name ) . setValue ( value ) . build ( ) ) ; return this ; } @ Override public MessageBuilder setKey ( String key ) { msgMetadataBuilder . setPartitionKey ( key ) ; return this ; } @ Override public MessageBuilder setEventTime ( long timestamp ) { checkArgument ( timestamp > 0 , ""Invalid timestamp : '%s'"" , timestamp ) ; msgMetadataBuilder . setEventTime ( timestamp ) ; return this ; } @ Override public MessageBuilder setSequenceId ( long sequenceId ) { checkArgument ( sequenceId >= 0 ) ; msgMetadataBuilder . setSequenceId ( sequenceId ) ; return this ; } @ Override public MessageBuilder setReplicationClusters ( List < String > clusters ) { Preconditions . checkNotNull ( clusters ) ; msgMetadataBuilder . clearReplicateTo ( ) ; msgMetadataBuilder . addAllReplicateTo ( clusters ) ; return this ; } @ Override public MessageBuilder disableReplication ( ) { msgMetadataBuilder . clearReplicateTo ( ) ; msgMetadataBuilder . addReplicateTo ( ""__local__"" ) ; return this ; } }",Smelly
"public final class InterfaceMapper { private ToolContext context ; public InterfaceMapper ( ToolContext c ) { this . context = c ; } public JavaInterface map ( InterfaceInfo interfaceInfo ) { JavaInterface intf = new JavaInterface ( ) ; String namespace = interfaceInfo . getName ( ) . getNamespaceURI ( ) ; String packageName = ProcessorUtil . parsePackageName ( namespace , context . mapPackageName ( namespace ) ) ; String loc = ( String ) context . get ( ToolConstants . CFG_WSDLLOCATION ) ; if ( loc == null ) { loc = ( String ) context . get ( ToolConstants . CFG_WSDLURL ) ; } String webServiceName = interfaceInfo . getName ( ) . getLocalPart ( ) ; intf . setWebServiceName ( webServiceName ) ; intf . setName ( NameUtil . mangleNameToClassName ( webServiceName ) ) ; intf . setNamespace ( namespace ) ; intf . setPackageName ( packageName ) ; intf . setLocation ( loc ) ; return intf ; } }",No
"public class SymmetricBinding extends SymmetricAsymmetricBindingBase { private EncryptionToken encryptionToken ; private SignatureToken signatureToken ; private ProtectionToken protectionToken ; public SymmetricBinding ( PolicyBuilder b ) { super ( SP12Constants . INSTANCE , b ) ; } public SymmetricBinding ( SPConstants version , PolicyBuilder b ) { super ( version , b ) ; } public EncryptionToken getEncryptionToken ( ) { return encryptionToken ; } public void setEncryptionToken ( EncryptionToken encryptionToken ) { this . encryptionToken = encryptionToken ; } public ProtectionToken getProtectionToken ( ) { return protectionToken ; } public void setProtectionToken ( ProtectionToken protectionToken ) { this . protectionToken = protectionToken ; } public SignatureToken getSignatureToken ( ) { return signatureToken ; } public void setSignatureToken ( SignatureToken signatureToken ) { this . signatureToken = signatureToken ; } public QName getRealName ( ) { return constants . getSymmetricBinding ( ) ; } public QName getName ( ) { return SP12Constants . INSTANCE . getSymmetricBinding ( ) ; } public PolicyComponent normalize ( ) { All all = new All ( ) ; all . addPolicyComponent ( getPolicy ( ) . getFirstPolicyComponent ( ) ) ; all . addPolicyComponent ( this ) ; return all ; } public Policy getPolicy ( ) { Policy p = new Policy ( ) ; ExactlyOne ea = new ExactlyOne ( ) ; p . addPolicyComponent ( ea ) ; All all = new All ( ) ; if ( this . getProtectionToken ( ) != null ) { all . addPolicyComponent ( this . getProtectionToken ( ) ) ; } if ( this . getSignatureToken ( ) != null ) { all . addPolicyComponent ( this . getSignatureToken ( ) ) ; } if ( this . getEncryptionToken ( ) != null ) { all . addPolicyComponent ( this . getEncryptionToken ( ) ) ; } if ( isIncludeTimestamp ( ) ) { all . addPolicyComponent ( new PrimitiveAssertion ( SP12Constants . INCLUDE_TIMESTAMP ) ) ; } if ( getLayout ( ) != null ) { all . addPolicyComponent ( getLayout ( ) ) ; } ea . addPolicyComponent ( all ) ; PolicyComponent pc = p . normalize ( builder . getPolicyRegistry ( ) , true ) ; if ( pc instanceof Policy ) { return ( Policy ) pc ; } else { p = new Policy ( ) ; p . addPolicyComponent ( pc ) ; return p ; } } public void serialize ( XMLStreamWriter writer ) throws XMLStreamException { String localname = getRealName ( ) . getLocalPart ( ) ; String namespaceURI = getRealName ( ) . getNamespaceURI ( ) ; String prefix ; String writerPrefix = writer . getPrefix ( namespaceURI ) ; if ( writerPrefix == null ) { prefix = getRealName ( ) . getPrefix ( ) ; writer . setPrefix ( prefix , namespaceURI ) ; } else { prefix = writerPrefix ; } writer . writeStartElement ( prefix , localname , namespaceURI ) ; writer . writeNamespace ( prefix , namespaceURI ) ; String policyLocalName = SPConstants . POLICY . getLocalPart ( ) ; String policyNamespaceURI = SPConstants . POLICY . getNamespaceURI ( ) ; String wspPrefix ; String wspWriterPrefix = writer . getPrefix ( policyNamespaceURI ) ; if ( wspWriterPrefix == null ) { wspPrefix = SPConstants . POLICY . getPrefix ( ) ; writer . setPrefix ( wspPrefix , policyNamespaceURI ) ; } else { wspPrefix = wspWriterPrefix ; } writer . writeStartElement ( wspPrefix , policyLocalName , policyNamespaceURI ) ; if ( encryptionToken != null ) { encryptionToken . serialize ( writer ) ; } else if ( protectionToken != null ) { protectionToken . serialize ( writer ) ; } else { throw new RuntimeException ( ""Either EncryptionToken or ProtectionToken must be set"" ) ; } AlgorithmSuite algorithmSuite = getAlgorithmSuite ( ) ; if ( algorithmSuite == null ) { throw new RuntimeException ( ""AlgorithmSuite must be set"" ) ; } algorithmSuite . serialize ( writer ) ; Layout layout = getLayout ( ) ; if ( layout != null ) { layout . serialize ( writer ) ; } if ( isIncludeTimestamp ( ) ) { writer . writeStartElement ( prefix , SPConstants . INCLUDE_TIMESTAMP , namespaceURI ) ; writer . writeEndElement ( ) ; } if ( SPConstants . ProtectionOrder . EncryptBeforeSigning == getProtectionOrder ( ) ) { writer . writeStartElement ( prefix , SPConstants . ENCRYPT_BEFORE_SIGNING , namespaceURI ) ; writer . writeEndElement ( ) ; } if ( isSignatureProtection ( ) ) { writer . writeStartElement ( prefix , SPConstants . ENCRYPT_SIGNATURE , namespaceURI ) ; writer . writeEndElement ( ) ; } if ( isEntireHeadersAndBodySignatures ( ) ) { writer . writeEmptyElement ( prefix , SPConstants . ONLY_SIGN_ENTIRE_HEADERS_AND_BODY , namespaceURI ) ; } writer . writeEndElement ( ) ; writer . writeEndElement ( ) ; } }",Smelly
"public class Main { protected static final String HELP_OPT = ""h"" ; protected static final String VERSION_OPT = ""v"" ; protected static final String VERBOSE_OPT = ""V"" ; protected static final String LOG_KIT_OPT = ""k"" ; protected static final String LOGGER_OPT = ""l"" ; protected static final String LOG_LEVEL_OPT = ""u"" ; protected static final String CONTEXT_DIR_OPT = ""c"" ; protected static final String DEST_DIR_OPT = ""d"" ; protected static final String WORK_DIR_OPT = ""w"" ; protected static final String CONFIG_FILE_OPT = ""C"" ; protected static final String BROKEN_LINK_FILE_OPT = ""b"" ; protected static final String URI_FILE_OPT = ""f"" ; protected static final String XCONF_OPT = ""x"" ; protected static final String AGENT_OPT = ""a"" ; protected static final String ACCEPT_OPT = ""p"" ; protected static final String FOLLOW_LINKS_OPT = ""r"" ; protected static final String PRECOMPILE_ONLY_OPT = ""P"" ; protected static final String CONFIRM_EXTENSIONS_OPT = ""e"" ; protected static final String LOAD_CLASS_OPT = ""L"" ; protected static final String DEFAULT_FILENAME_OPT = ""D"" ; protected static final String URI_GROUP_NAME_OPT = ""n"" ; protected static final String HELP_LONG = ""help"" ; protected static final String VERSION_LONG = ""version"" ; protected static final String VERBOSE_LONG = ""verbose"" ; protected static final String LOG_KIT_LONG = ""logKitconfig"" ; protected static final String LOGGER_LONG = ""Logger"" ; protected static final String LOG_LEVEL_LONG = ""logLevel"" ; protected static final String CONTEXT_DIR_LONG = ""contextDir"" ; protected static final String DEST_DIR_LONG = ""destDir"" ; protected static final String WORK_DIR_LONG = ""workDir"" ; protected static final String CONFIG_FILE_LONG = ""configFile"" ; protected static final String BROKEN_LINK_FILE_LONG = ""brokenLinkFile"" ; protected static final String URI_FILE_LONG = ""uriFile"" ; protected static final String XCONF_LONG = ""xconf"" ; protected static final String AGENT_LONG = ""userAgent"" ; protected static final String ACCEPT_LONG = ""accept"" ; protected static final String FOLLOW_LINKS_LONG = ""followLinks"" ; protected static final String PRECOMPILE_ONLY_LONG = ""precompileOnly"" ; protected static final String CONFIRM_EXTENSIONS_LONG = ""confirmExtensions"" ; protected static final String LOAD_CLASS_LONG = ""loadClass"" ; protected static final String DEFAULT_FILENAME_LONG = ""defaultFilename"" ; protected static final String URI_LONG = ""uri"" ; protected static final String URI_GROUP_NAME_LONG = ""uris"" ; private static Options options ; private static OutputStreamListener listener ; private static void setOptions ( ) { options = new Options ( ) ; options . addOption ( new Option ( HELP_OPT , HELP_LONG , false , ""print this message and exit"" ) ) ; options . addOption ( new Option ( VERSION_OPT , VERSION_LONG , false , ""print the version information and exit"" ) ) ; options . addOption ( new Option ( VERBOSE_OPT , VERBOSE_LONG , false , ""enable verbose messages to System.out"" ) ) ; options . addOption ( new Option ( LOG_KIT_OPT , LOG_KIT_LONG , true , ""use given file for LogKit Management configuration"" ) ) ; options . addOption ( new Option ( LOGGER_OPT , LOGGER_LONG , true , ""use given logger category as default logger for the Cocoon engine"" ) ) ; options . addOption ( new Option ( LOG_LEVEL_OPT , LOG_LEVEL_LONG , true , ""choose the minimum log level for logging (DEBUG, INFO, WARN, ERROR, FATAL_ERROR) for startup logging"" ) ) ; options . addOption ( new Option ( CONTEXT_DIR_OPT , CONTEXT_DIR_LONG , true , ""use given dir as context"" ) ) ; options . addOption ( new Option ( DEST_DIR_OPT , DEST_DIR_LONG , true , ""use given dir as destination"" ) ) ; options . addOption ( new Option ( WORK_DIR_OPT , WORK_DIR_LONG , true , ""use given dir as working directory"" ) ) ; options . addOption ( new Option ( CONFIG_FILE_OPT , CONFIG_FILE_LONG , true , ""specify alternate location of the configuration"" + "" file (default is ${contextDir}/cocoon.xconf)"" ) ) ; options . addOption ( new Option ( BROKEN_LINK_FILE_OPT , BROKEN_LINK_FILE_LONG , true , ""send a list of broken links to a file (one URI per line)"" ) ) ; options . addOption ( new Option ( URI_FILE_OPT , URI_FILE_LONG , true , ""use a text file with uris to process (one URI per line)"" ) ) ; options . addOption ( new Option ( XCONF_OPT , XCONF_LONG , true , ""specify a file containing XML configuration details"" + "" for the command line interface"" ) ) ; options . addOption ( new Option ( AGENT_OPT , AGENT_LONG , true , ""use given string for user-agent header"" ) ) ; options . addOption ( new Option ( ACCEPT_OPT , ACCEPT_LONG , true , ""use given string for accept header"" ) ) ; options . addOption ( new Option ( FOLLOW_LINKS_OPT , FOLLOW_LINKS_LONG , true , ""process pages linked from starting page or not"" + "" (boolean argument is expected, default is true)"" ) ) ; options . addOption ( new Option ( PRECOMPILE_ONLY_OPT , PRECOMPILE_ONLY_LONG , true , ""generate java code for xsp and xmap files"" ) ) ; options . addOption ( new Option ( CONFIRM_EXTENSIONS_OPT , CONFIRM_EXTENSIONS_LONG , true , ""confirm that file extensions match mime-type of"" + "" pages and amend filename accordingly (default"" + "" is true)"" ) ) ; options . addOption ( new Option ( LOAD_CLASS_OPT , LOAD_CLASS_LONG , true , ""specify a class to be loaded at startup (specifically"" + "" for use with JDBC). Can be used multiple times"" ) ) ; options . addOption ( new Option ( DEFAULT_FILENAME_OPT , DEFAULT_FILENAME_LONG , true , ""specify a filename to be appended to a URI when the"" + "" URI refers to a directory"" ) ) ; options . addOption ( new Option ( URI_GROUP_NAME_OPT , URI_GROUP_NAME_LONG , true , ""specify which <uris> element to process in the configuration"" + "" file specified with the -x parameter"" ) ) ; } public static void main ( String [ ] args ) throws Exception { Main . setOptions ( ) ; CommandLine line = new PosixParser ( ) . parse ( options , args ) ; listener = new OutputStreamListener ( System . out ) ; CocoonBean cocoon = new CocoonBean ( ) ; cocoon . addListener ( listener ) ; if ( line . hasOption ( HELP_OPT ) ) { printUsage ( ) ; } else if ( line . hasOption ( VERSION_OPT ) ) { printVersion ( ) ; } String uriGroup = null ; if ( line . hasOption ( URI_GROUP_NAME_OPT ) ) { uriGroup = line . getOptionValue ( URI_GROUP_NAME_OPT ) ; } String destDir = null ; if ( line . hasOption ( XCONF_OPT ) ) { destDir = Main . processXConf ( cocoon , line . getOptionValue ( XCONF_OPT ) , destDir , uriGroup ) ; } if ( line . hasOption ( DEST_DIR_OPT ) ) { destDir = line . getOptionValue ( DEST_DIR_OPT ) ; } if ( line . hasOption ( VERBOSE_OPT ) ) { cocoon . setVerbose ( true ) ; } if ( line . hasOption ( PRECOMPILE_ONLY_OPT ) ) { cocoon . setPrecompileOnly ( true ) ; } if ( line . hasOption ( WORK_DIR_OPT ) ) { String workDir = line . getOptionValue ( WORK_DIR_OPT ) ; if ( workDir . equals ( """" ) ) { listener . messageGenerated ( ""Careful, you must specify a work dir when using the -w/--workDir argument"" ) ; System . exit ( 1 ) ; } else { cocoon . setWorkDir ( line . getOptionValue ( WORK_DIR_OPT ) ) ; } } if ( line . hasOption ( CONTEXT_DIR_OPT ) ) { String contextDir = line . getOptionValue ( CONTEXT_DIR_OPT ) ; if ( contextDir . equals ( """" ) ) { listener . messageGenerated ( ""Careful, you must specify a configuration file when using the -c/--contextDir argument"" ) ; System . exit ( 1 ) ; } else { cocoon . setContextDir ( contextDir ) ; } } if ( line . hasOption ( CONFIG_FILE_OPT ) ) { cocoon . setConfigFile ( line . getOptionValue ( CONFIG_FILE_OPT ) ) ; } if ( line . hasOption ( LOG_KIT_OPT ) ) { cocoon . setLogKit ( line . getOptionValue ( LOG_KIT_OPT ) ) ; } if ( line . hasOption ( LOGGER_OPT ) ) { cocoon . setLogger ( line . getOptionValue ( LOGGER_OPT ) ) ; } if ( line . hasOption ( LOG_LEVEL_OPT ) ) { cocoon . setLogLevel ( line . getOptionValue ( LOG_LEVEL_OPT ) ) ; } if ( line . hasOption ( AGENT_OPT ) ) { cocoon . setAgentOptions ( line . getOptionValue ( AGENT_OPT ) ) ; } if ( line . hasOption ( ACCEPT_OPT ) ) { cocoon . setAcceptOptions ( line . getOptionValue ( ACCEPT_OPT ) ) ; } if ( line . hasOption ( DEFAULT_FILENAME_OPT ) ) { cocoon . setDefaultFilename ( line . getOptionValue ( DEFAULT_FILENAME_OPT ) ) ; } if ( line . hasOption ( BROKEN_LINK_FILE_OPT ) ) { listener . setReportFile ( line . getOptionValue ( BROKEN_LINK_FILE_OPT ) ) ; } if ( line . hasOption ( FOLLOW_LINKS_OPT ) ) { cocoon . setFollowLinks ( BooleanUtils . toBoolean ( line . getOptionValue ( FOLLOW_LINKS_OPT ) ) ) ; } if ( line . hasOption ( CONFIRM_EXTENSIONS_OPT ) ) { cocoon . setConfirmExtensions ( BooleanUtils . toBoolean ( line . getOptionValue ( CONFIRM_EXTENSIONS_OPT , ""yes"" ) ) ) ; } if ( line . hasOption ( LOAD_CLASS_OPT ) ) { cocoon . addLoadedClasses ( Arrays . asList ( line . getOptionValues ( LOAD_CLASS_OPT ) ) ) ; } if ( line . hasOption ( URI_FILE_OPT ) ) { cocoon . addTargets ( BeanConfigurator . processURIFile ( line . getOptionValue ( URI_FILE_OPT ) ) , destDir ) ; } cocoon . addTargets ( line . getArgList ( ) , destDir ) ; listener . messageGenerated ( CocoonBean . getProlog ( ) ) ; if ( cocoon . getTargetCount ( ) == 0 && cocoon . isPrecompileOnly ( ) ) { listener . messageGenerated ( ""Please, specify at least one starting URI."" ) ; System . exit ( 1 ) ; } cocoon . initialize ( ) ; cocoon . process ( ) ; cocoon . dispose ( ) ; listener . complete ( ) ; int exitCode = ( listener . isSuccessful ( ) ? 0 : 1 ) ; System . exit ( exitCode ) ; } private static String processXConf ( CocoonBean cocoon , String filename , String destDir , String uriGroup ) { try { final DocumentBuilder builder = DocumentBuilderFactory . newInstance ( ) . newDocumentBuilder ( ) ; final Document xconf = builder . parse ( new File ( filename ) . toURL ( ) . toExternalForm ( ) ) ; return BeanConfigurator . configure ( xconf , cocoon , destDir , uriGroup , listener ) ; } catch ( Exception e ) { System . out . println ( ""ERROR: "" + e . getMessage ( ) ) ; return destDir ; } } private static void printUsage ( ) { HelpFormatter formatter = new HelpFormatter ( ) ; formatter . printHelp ( ""cocoon cli [options] [targets]"" , CocoonBean . getProlog ( ) , options , ""Note: the context directory defaults to '"" + Constants . DEFAULT_CONTEXT_DIR + ""'"" ) ; System . exit ( 0 ) ; } private static void printVersion ( ) { System . out . println ( Constants . VERSION ) ; System . exit ( 0 ) ; } }",No
"public class W3CNamespaceContext implements NamespaceContext { private Element currentNode ; public String getNamespaceURI ( String prefix ) { String name = prefix ; if ( name . length ( ) == 0 ) { name = ""xmlns"" ; } else { name = ""xmlns:"" + prefix ; } return getNamespaceURI ( currentNode , name ) ; } private String getNamespaceURI ( Element e , String name ) { Attr attr = e . getAttributeNode ( name ) ; if ( attr == null ) { Node n = e . getParentNode ( ) ; if ( n instanceof Element && n != e ) { return getNamespaceURI ( ( Element ) n , name ) ; } } else { return attr . getValue ( ) ; } return null ; } public String getPrefix ( String uri ) { return getPrefix ( currentNode , uri ) ; } private String getPrefix ( Element e , String uri ) { NamedNodeMap attributes = e . getAttributes ( ) ; if ( attributes != null ) { for ( int i = 0 ; i < attributes . getLength ( ) ; i ++ ) { Attr a = ( Attr ) attributes . item ( i ) ; String val = a . getValue ( ) ; if ( val != null && val . equals ( uri ) ) { String name = a . getNodeName ( ) ; if ( ""xmlns"" . equals ( name ) ) { return """" ; } else { return name . substring ( 6 ) ; } } } } Node n = e . getParentNode ( ) ; if ( n instanceof Element && n != e ) { return getPrefix ( ( Element ) n , uri ) ; } return null ; } public Iterator < String > getPrefixes ( String uri ) { List < String > prefixes = new ArrayList < String > ( ) ; String prefix = getPrefix ( uri ) ; if ( prefix != null ) { prefixes . add ( prefix ) ; } return prefixes . iterator ( ) ; } public Element getElement ( ) { return currentNode ; } public void setElement ( Element cn ) { this . currentNode = cn ; } }",Smelly
 private static class NonSerializable { ,No
"@ Entity @ Table ( name = ""roles"" ) @ Cache ( usage = CacheConcurrencyStrategy . READ_WRITE ) public class Role { private Long id ; private String name ; private String description ; private Set < String > permissions ; protected Role ( ) { } public Role ( String name ) { this . name = name ; } @ Id @ GeneratedValue public Long getId ( ) { return id ; } public void setId ( Long id ) { this . id = id ; } @ Basic ( optional = false ) @ Column ( length = 100 ) @ Index ( name = ""idx_roles_name"" ) public String getName ( ) { return name ; } public void setName ( String name ) { this . name = name ; } @ Basic ( optional = false ) @ Column ( length = 255 ) public String getDescription ( ) { return description ; } public void setDescription ( String description ) { this . description = description ; } @ ElementCollection ( targetClass = String . class ) @ JoinTable ( name = ""roles_permissions"" ) @ Cache ( usage = CacheConcurrencyStrategy . READ_WRITE ) public Set < String > getPermissions ( ) { return permissions ; } public void setPermissions ( Set < String > permissions ) { this . permissions = permissions ; } }",Smelly
"@ Private @ Unstable public class AllocationConfigurationException extends Exception { private static final long serialVersionUID = 4046517047810854249L ; public AllocationConfigurationException ( String message ) { super ( message ) ; } public AllocationConfigurationException ( String message , Throwable t ) { super ( message , t ) ; } }",No
"public class PDFRoot extends PDFDictionary { public static final int PAGEMODE_USENONE = 0 ; public static final int PAGEMODE_USEOUTLINES = 1 ; public static final int PAGEMODE_USETHUMBS = 2 ; public static final int PAGEMODE_FULLSCREEN = 3 ; private final PDFDocument document ; private PDFDPartRoot dPartRoot ; private PDFArray af ; private static final PDFName [ ] PAGEMODE_NAMES = new PDFName [ ] { new PDFName ( ""UseNone"" ) , new PDFName ( ""UseOutlines"" ) , new PDFName ( ""UseThumbs"" ) , new PDFName ( ""FullScreen"" ) , } ; public PDFRoot ( PDFDocument document , PDFPages pages ) { this . document = document ; setObjectNumber ( document ) ; put ( ""Type"" , new PDFName ( ""Catalog"" ) ) ; setRootPages ( pages ) ; setLanguage ( ""x-unknown"" ) ; } public int output ( OutputStream stream ) throws IOException { if ( document . getProfile ( ) . getPDFUAMode ( ) . isEnabled ( ) ) { PDFDictionary d = new PDFDictionary ( ) ; d . put ( ""DisplayDocTitle"" , true ) ; put ( ""ViewerPreferences"" , d ) ; } getDocument ( ) . getProfile ( ) . verifyTaggedPDF ( ) ; return super . output ( stream ) ; } public void setPageMode ( int mode ) { put ( ""PageMode"" , PAGEMODE_NAMES [ mode ] ) ; } public int getPageMode ( ) { PDFName mode = ( PDFName ) get ( ""PageMode"" ) ; if ( mode != null ) { for ( int i = 0 ; i < PAGEMODE_NAMES . length ; i ++ ) { if ( PAGEMODE_NAMES [ i ] . equals ( mode ) ) { return i ; } } throw new IllegalStateException ( ""Unknown /PageMode encountered: "" + mode ) ; } else { return PAGEMODE_USENONE ; } } public void addPage ( PDFPage page ) { PDFPages pages = getRootPages ( ) ; pages . addPage ( page ) ; } public void setRootPages ( PDFPages pages ) { put ( ""Pages"" , pages . makeReference ( ) ) ; } public PDFPages getRootPages ( ) { PDFReference ref = ( PDFReference ) get ( ""Pages"" ) ; return ( ref != null ? ( PDFPages ) ref . getObject ( ) : null ) ; } public void setPageLabels ( PDFPageLabels pageLabels ) { put ( ""PageLabels"" , pageLabels . makeReference ( ) ) ; } public PDFPageLabels getPageLabels ( ) { PDFReference ref = ( PDFReference ) get ( ""PageLabels"" ) ; return ( ref != null ? ( PDFPageLabels ) ref . getObject ( ) : null ) ; } public void setRootOutline ( PDFOutline out ) { put ( ""Outlines"" , out . makeReference ( ) ) ; PDFName mode = ( PDFName ) get ( ""PageMode"" ) ; if ( mode == null ) { setPageMode ( PAGEMODE_USEOUTLINES ) ; } } public PDFOutline getRootOutline ( ) { PDFReference ref = ( PDFReference ) get ( ""Outlines"" ) ; return ( ref != null ? ( PDFOutline ) ref . getObject ( ) : null ) ; } public void setNames ( PDFNames names ) { put ( ""Names"" , names . makeReference ( ) ) ; } public PDFNames getNames ( ) { PDFReference ref = ( PDFReference ) get ( ""Names"" ) ; return ( ref != null ? ( PDFNames ) ref . getObject ( ) : null ) ; } public void setMetadata ( PDFMetadata meta ) { if ( getDocumentSafely ( ) . getPDFVersion ( ) . compareTo ( Version . V1_4 ) >= 0 ) { put ( ""Metadata"" , meta . makeReference ( ) ) ; } } public PDFMetadata getMetadata ( ) { PDFReference ref = ( PDFReference ) get ( ""Metadata"" ) ; return ( ref != null ? ( PDFMetadata ) ref . getObject ( ) : null ) ; } public PDFArray getOutputIntents ( ) { return ( PDFArray ) get ( ""OutputIntents"" ) ; } public void addOutputIntent ( PDFOutputIntent outputIntent ) { if ( getDocumentSafely ( ) . getPDFVersion ( ) . compareTo ( Version . V1_4 ) >= 0 ) { PDFArray outputIntents = getOutputIntents ( ) ; if ( outputIntents == null ) { outputIntents = new PDFArray ( this ) ; put ( ""OutputIntents"" , outputIntents ) ; } outputIntents . add ( outputIntent ) ; } } void setVersion ( Version version ) { put ( ""Version"" , new PDFName ( version . toString ( ) ) ) ; } public String getLanguage ( ) { return ( String ) get ( ""Lang"" ) ; } public void setLanguage ( Locale locale ) { if ( locale == null ) { throw new NullPointerException ( ""locale must not be null"" ) ; } setLanguage ( LanguageTags . toLanguageTag ( locale ) ) ; } private void setLanguage ( String lang ) { put ( ""Lang"" , lang ) ; } public void setStructTreeRoot ( PDFStructTreeRoot structTreeRoot ) { if ( structTreeRoot == null ) { throw new NullPointerException ( ""structTreeRoot must not be null"" ) ; } put ( ""StructTreeRoot"" , structTreeRoot ) ; } public PDFStructTreeRoot getStructTreeRoot ( ) { return ( PDFStructTreeRoot ) get ( ""StructTreeRoot"" ) ; } public void makeTagged ( ) { PDFDictionary dict = new PDFDictionary ( ) ; dict . put ( ""Marked"" , Boolean . TRUE ) ; put ( ""MarkInfo"" , dict ) ; } public PDFDictionary getMarkInfo ( ) { return ( PDFDictionary ) get ( ""MarkInfo"" ) ; } public PDFDPartRoot getDPartRoot ( ) { if ( dPartRoot == null ) { dPartRoot = getDocument ( ) . getFactory ( ) . makeDPartRoot ( ) ; put ( ""DPartRoot"" , dPartRoot . makeReference ( ) ) ; } return dPartRoot ; } public void addAF ( PDFFileSpec fileSpec , String filename ) { if ( af == null ) { af = new PDFArray ( ) ; put ( ""AF"" , af ) ; } af . add ( fileSpec ) ; fileSpec . put ( ""UF"" , filename ) ; fileSpec . put ( ""AFRelationship"" , new PDFName ( ""Data"" ) ) ; } }",Smelly
"@ Entity ( name = ""IDC_Person"" ) @ Inheritance ( strategy = InheritanceType . SINGLE_TABLE ) public abstract class Person implements IPerson { private static int ids = 1 ; @ Id private int id = ++ ids ; @ Basic private String firstName ; @ Basic private String lastName ; @ OneToOne private Address homeAddress ; public void setFirstName ( String firstName ) { this . firstName = firstName ; } public String getFirstName ( ) { return this . firstName ; } public void setLastName ( String lastName ) { this . lastName = lastName ; } public String getLastName ( ) { return this . lastName ; } public void setHomeAddress ( IAddress homeAddress ) { this . homeAddress = ( Address ) homeAddress ; } public IAddress getHomeAddress ( ) { return this . homeAddress ; } }",Smelly
"public class StandardNodeHeartbeat implements NodeHeartbeat { private final NodeIdentifier nodeId ; private final long timestamp ; private final NodeConnectionStatus connectionStatus ; private final int flowFileCount ; private final long flowFileBytes ; private final int activeThreadCount ; private final long systemStartTime ; public StandardNodeHeartbeat ( final NodeIdentifier nodeId , final long timestamp , final NodeConnectionStatus connectionStatus , final int flowFileCount , final long flowFileBytes , final int activeThreadCount , final long systemStartTime ) { this . timestamp = timestamp ; this . nodeId = nodeId ; this . connectionStatus = connectionStatus ; this . flowFileCount = flowFileCount ; this . flowFileBytes = flowFileBytes ; this . activeThreadCount = activeThreadCount ; this . systemStartTime = systemStartTime ; } @ Override public NodeIdentifier getNodeIdentifier ( ) { return nodeId ; } @ Override public long getTimestamp ( ) { return timestamp ; } @ Override public NodeConnectionStatus getConnectionStatus ( ) { return connectionStatus ; } @ Override public int getFlowFileCount ( ) { return flowFileCount ; } @ Override public long getFlowFileBytes ( ) { return flowFileBytes ; } @ Override public int getActiveThreadCount ( ) { return activeThreadCount ; } @ Override public long getSystemStartTime ( ) { return systemStartTime ; } public static StandardNodeHeartbeat fromHeartbeatMessage ( final HeartbeatMessage message , final long timestamp ) { final Heartbeat heartbeat = message . getHeartbeat ( ) ; final HeartbeatPayload payload = HeartbeatPayload . unmarshal ( heartbeat . getPayload ( ) ) ; return new StandardNodeHeartbeat ( heartbeat . getNodeIdentifier ( ) , timestamp , heartbeat . getConnectionStatus ( ) , ( int ) payload . getTotalFlowFileCount ( ) , payload . getTotalFlowFileBytes ( ) , payload . getActiveThreadCount ( ) , payload . getSystemStartTime ( ) ) ; } }",Smelly
"public final class GenMRSkewJoinProcessor { private GenMRSkewJoinProcessor ( ) { } @ SuppressWarnings ( ""unchecked"" ) public static void processSkewJoin ( JoinOperator joinOp , Task < ? extends Serializable > currTask , ParseContext parseCtx ) throws SemanticException { if ( ! GenMRSkewJoinProcessor . skewJoinEnabled ( parseCtx . getConf ( ) , joinOp ) ) { return ; } List < Task < ? extends Serializable > > children = currTask . getChildTasks ( ) ; if ( children != null && children . size ( ) > 1 ) { throw new SemanticException ( ""Should not happened"" ) ; } Task < ? extends Serializable > child = children != null && children . size ( ) == 1 ? children . get ( 0 ) : null ; Path baseTmpDir = parseCtx . getContext ( ) . getMRTmpPath ( ) ; JoinDesc joinDescriptor = joinOp . getConf ( ) ; Map < Byte , List < ExprNodeDesc > > joinValues = joinDescriptor . getExprs ( ) ; int numAliases = joinValues . size ( ) ; Map < Byte , Path > bigKeysDirMap = new HashMap < Byte , Path > ( ) ; Map < Byte , Map < Byte , Path > > smallKeysDirMap = new HashMap < Byte , Map < Byte , Path > > ( ) ; Map < Byte , Path > skewJoinJobResultsDir = new HashMap < Byte , Path > ( ) ; Byte [ ] tags = joinDescriptor . getTagOrder ( ) ; for ( int i = 0 ; i < numAliases ; i ++ ) { Byte alias = tags [ i ] ; bigKeysDirMap . put ( alias , getBigKeysDir ( baseTmpDir , alias ) ) ; Map < Byte , Path > smallKeysMap = new HashMap < Byte , Path > ( ) ; smallKeysDirMap . put ( alias , smallKeysMap ) ; for ( Byte src2 : tags ) { if ( ! src2 . equals ( alias ) ) { smallKeysMap . put ( src2 , getSmallKeysDir ( baseTmpDir , alias , src2 ) ) ; } } skewJoinJobResultsDir . put ( alias , getBigKeysSkewJoinResultDir ( baseTmpDir , alias ) ) ; } joinDescriptor . setHandleSkewJoin ( true ) ; joinDescriptor . setBigKeysDirMap ( bigKeysDirMap ) ; joinDescriptor . setSmallKeysDirMap ( smallKeysDirMap ) ; joinDescriptor . setSkewKeyDefinition ( HiveConf . getIntVar ( parseCtx . getConf ( ) , HiveConf . ConfVars . HIVESKEWJOINKEY ) ) ; HashMap < Path , Task < ? extends Serializable > > bigKeysDirToTaskMap = new HashMap < Path , Task < ? extends Serializable > > ( ) ; List < Serializable > listWorks = new ArrayList < Serializable > ( ) ; List < Task < ? extends Serializable > > listTasks = new ArrayList < Task < ? extends Serializable > > ( ) ; MapredWork currPlan = ( MapredWork ) currTask . getWork ( ) ; TableDesc keyTblDesc = ( TableDesc ) currPlan . getReduceWork ( ) . getKeyDesc ( ) . clone ( ) ; List < String > joinKeys = Utilities . getColumnNames ( keyTblDesc . getProperties ( ) ) ; List < String > joinKeyTypes = Utilities . getColumnTypes ( keyTblDesc . getProperties ( ) ) ; Map < Byte , TableDesc > tableDescList = new HashMap < Byte , TableDesc > ( ) ; Map < Byte , RowSchema > rowSchemaList = new HashMap < Byte , RowSchema > ( ) ; Map < Byte , List < ExprNodeDesc > > newJoinValues = new HashMap < Byte , List < ExprNodeDesc > > ( ) ; Map < Byte , List < ExprNodeDesc > > newJoinKeys = new HashMap < Byte , List < ExprNodeDesc > > ( ) ; List < TableDesc > newJoinValueTblDesc = new ArrayList < TableDesc > ( ) ; for ( Byte tag : tags ) { newJoinValueTblDesc . add ( null ) ; } for ( int i = 0 ; i < numAliases ; i ++ ) { Byte alias = tags [ i ] ; List < ExprNodeDesc > valueCols = joinValues . get ( alias ) ; String colNames = """" ; String colTypes = """" ; int columnSize = valueCols . size ( ) ; List < ExprNodeDesc > newValueExpr = new ArrayList < ExprNodeDesc > ( ) ; List < ExprNodeDesc > newKeyExpr = new ArrayList < ExprNodeDesc > ( ) ; ArrayList < ColumnInfo > columnInfos = new ArrayList < ColumnInfo > ( ) ; boolean first = true ; for ( int k = 0 ; k < columnSize ; k ++ ) { TypeInfo type = valueCols . get ( k ) . getTypeInfo ( ) ; String newColName = i + ""_VALUE_"" + k ; ColumnInfo columnInfo = new ColumnInfo ( newColName , type , alias . toString ( ) , false ) ; columnInfos . add ( columnInfo ) ; newValueExpr . add ( new ExprNodeColumnDesc ( columnInfo . getType ( ) , columnInfo . getInternalName ( ) , columnInfo . getTabAlias ( ) , false ) ) ; if ( ! first ) { colNames = colNames + "","" ; colTypes = colTypes + "","" ; } first = false ; colNames = colNames + newColName ; colTypes = colTypes + valueCols . get ( k ) . getTypeString ( ) ; } for ( int k = 0 ; k < joinKeys . size ( ) ; k ++ ) { if ( ! first ) { colNames = colNames + "","" ; colTypes = colTypes + "","" ; } first = false ; colNames = colNames + joinKeys . get ( k ) ; colTypes = colTypes + joinKeyTypes . get ( k ) ; ColumnInfo columnInfo = new ColumnInfo ( joinKeys . get ( k ) , TypeInfoFactory . getPrimitiveTypeInfo ( joinKeyTypes . get ( k ) ) , alias . toString ( ) , false ) ; columnInfos . add ( columnInfo ) ; newKeyExpr . add ( new ExprNodeColumnDesc ( columnInfo . getType ( ) , columnInfo . getInternalName ( ) , columnInfo . getTabAlias ( ) , false ) ) ; } newJoinValues . put ( alias , newValueExpr ) ; newJoinKeys . put ( alias , newKeyExpr ) ; tableDescList . put ( alias , Utilities . getTableDesc ( colNames , colTypes ) ) ; rowSchemaList . put ( alias , new RowSchema ( columnInfos ) ) ; String valueColNames = """" ; String valueColTypes = """" ; first = true ; for ( int k = 0 ; k < columnSize ; k ++ ) { String newColName = i + ""_VALUE_"" + k ; if ( ! first ) { valueColNames = valueColNames + "","" ; valueColTypes = valueColTypes + "","" ; } valueColNames = valueColNames + newColName ; valueColTypes = valueColTypes + valueCols . get ( k ) . getTypeString ( ) ; first = false ; } newJoinValueTblDesc . set ( Byte . valueOf ( ( byte ) i ) , Utilities . getTableDesc ( valueColNames , valueColTypes ) ) ; } joinDescriptor . setSkewKeysValuesTables ( tableDescList ) ; joinDescriptor . setKeyTableDesc ( keyTblDesc ) ; for ( int i = 0 ; i < numAliases - 1 ; i ++ ) { Byte src = tags [ i ] ; MapWork newPlan = PlanUtils . getMapRedWork ( ) . getMapWork ( ) ; boolean mapperCannotSpanPartns = parseCtx . getConf ( ) . getBoolVar ( HiveConf . ConfVars . HIVE_MAPPER_CANNOT_SPAN_MULTIPLE_PARTITIONS ) ; newPlan . setMapperCannotSpanPartns ( mapperCannotSpanPartns ) ; MapredWork clonePlan = Utilities . clonePlan ( currPlan ) ; Operator < ? extends OperatorDesc > [ ] parentOps = new TableScanOperator [ tags . length ] ; for ( int k = 0 ; k < tags . length ; k ++ ) { Operator < ? extends OperatorDesc > ts = GenMapRedUtils . createTemporaryTableScanOperator ( rowSchemaList . get ( ( byte ) k ) ) ; ( ( TableScanOperator ) ts ) . setTableDesc ( tableDescList . get ( ( byte ) k ) ) ; parentOps [ k ] = ts ; } Operator < ? extends OperatorDesc > tblScan_op = parentOps [ i ] ; ArrayList < String > aliases = new ArrayList < String > ( ) ; String alias = src . toString ( ) ; aliases . add ( alias ) ; Path bigKeyDirPath = bigKeysDirMap . get ( src ) ; newPlan . getPathToAliases ( ) . put ( bigKeyDirPath . toString ( ) , aliases ) ; newPlan . getAliasToWork ( ) . put ( alias , tblScan_op ) ; PartitionDesc part = new PartitionDesc ( tableDescList . get ( src ) , null ) ; newPlan . getPathToPartitionInfo ( ) . put ( bigKeyDirPath . toString ( ) , part ) ; newPlan . getAliasToPartnInfo ( ) . put ( alias , part ) ; Operator < ? extends OperatorDesc > reducer = clonePlan . getReduceWork ( ) . getReducer ( ) ; assert reducer instanceof JoinOperator ; JoinOperator cloneJoinOp = ( JoinOperator ) reducer ; String dumpFilePrefix = ""mapfile"" + PlanUtils . getCountForMapJoinDumpFilePrefix ( ) ; MapJoinDesc mapJoinDescriptor = new MapJoinDesc ( newJoinKeys , keyTblDesc , newJoinValues , newJoinValueTblDesc , newJoinValueTblDesc , joinDescriptor . getOutputColumnNames ( ) , i , joinDescriptor . getConds ( ) , joinDescriptor . getFilters ( ) , joinDescriptor . getNoOuterJoin ( ) , dumpFilePrefix ) ; mapJoinDescriptor . setTagOrder ( tags ) ; mapJoinDescriptor . setHandleSkewJoin ( false ) ; mapJoinDescriptor . setNullSafes ( joinDescriptor . getNullSafes ( ) ) ; MapredLocalWork localPlan = new MapredLocalWork ( new LinkedHashMap < String , Operator < ? extends OperatorDesc > > ( ) , new LinkedHashMap < String , FetchWork > ( ) ) ; Map < Byte , Path > smallTblDirs = smallKeysDirMap . get ( src ) ; for ( int j = 0 ; j < numAliases ; j ++ ) { if ( j == i ) { continue ; } Byte small_alias = tags [ j ] ; Operator < ? extends OperatorDesc > tblScan_op2 = parentOps [ j ] ; localPlan . getAliasToWork ( ) . put ( small_alias . toString ( ) , tblScan_op2 ) ; Path tblDir = smallTblDirs . get ( small_alias ) ; localPlan . getAliasToFetchWork ( ) . put ( small_alias . toString ( ) , new FetchWork ( tblDir , tableDescList . get ( small_alias ) ) ) ; } newPlan . setMapLocalWork ( localPlan ) ; MapJoinOperator mapJoinOp = ( MapJoinOperator ) OperatorFactory . getAndMakeChild ( mapJoinDescriptor , ( RowSchema ) null , parentOps ) ; List < Operator < ? extends OperatorDesc > > childOps = cloneJoinOp . getChildOperators ( ) ; for ( Operator < ? extends OperatorDesc > childOp : childOps ) { childOp . replaceParent ( cloneJoinOp , mapJoinOp ) ; } mapJoinOp . setChildOperators ( childOps ) ; HiveConf jc = new HiveConf ( parseCtx . getConf ( ) , GenMRSkewJoinProcessor . class ) ; newPlan . setNumMapTasks ( HiveConf . getIntVar ( jc , HiveConf . ConfVars . HIVESKEWJOINMAPJOINNUMMAPTASK ) ) ; newPlan . setMinSplitSize ( HiveConf . getLongVar ( jc , HiveConf . ConfVars . HIVESKEWJOINMAPJOINMINSPLIT ) ) ; newPlan . setInputformat ( HiveInputFormat . class . getName ( ) ) ; MapredWork w = new MapredWork ( ) ; w . setMapWork ( newPlan ) ; Task < ? extends Serializable > skewJoinMapJoinTask = TaskFactory . get ( w , jc ) ; bigKeysDirToTaskMap . put ( bigKeyDirPath , skewJoinMapJoinTask ) ; listWorks . add ( skewJoinMapJoinTask . getWork ( ) ) ; listTasks . add ( skewJoinMapJoinTask ) ; } if ( children != null ) { for ( Task < ? extends Serializable > tsk : listTasks ) { for ( Task < ? extends Serializable > oldChild : children ) { tsk . addDependentTask ( oldChild ) ; } } } if ( child != null ) { currTask . removeDependentTask ( child ) ; listTasks . add ( child ) ; } ConditionalResolverSkewJoinCtx context = new ConditionalResolverSkewJoinCtx ( bigKeysDirToTaskMap , child ) ; ConditionalWork cndWork = new ConditionalWork ( listWorks ) ; ConditionalTask cndTsk = ( ConditionalTask ) TaskFactory . get ( cndWork , parseCtx . getConf ( ) ) ; cndTsk . setListTasks ( listTasks ) ; cndTsk . setResolver ( new ConditionalResolverSkewJoin ( ) ) ; cndTsk . setResolverCtx ( context ) ; currTask . setChildTasks ( new ArrayList < Task < ? extends Serializable > > ( ) ) ; currTask . addDependentTask ( cndTsk ) ; return ; } public static boolean skewJoinEnabled ( HiveConf conf , JoinOperator joinOp ) { if ( conf != null && ! conf . getBoolVar ( HiveConf . ConfVars . HIVESKEWJOIN ) ) { return false ; } if ( ! joinOp . getConf ( ) . isNoOuterJoin ( ) ) { return false ; } byte pos = 0 ; for ( Byte tag : joinOp . getConf ( ) . getTagOrder ( ) ) { if ( tag != pos ) { return false ; } pos ++ ; } return true ; } private static String skewJoinPrefix = ""hive_skew_join"" ; private static String UNDERLINE = ""_"" ; private static String BIGKEYS = ""bigkeys"" ; private static String SMALLKEYS = ""smallkeys"" ; private static String RESULTS = ""results"" ; static Path getBigKeysDir ( Path baseDir , Byte srcTbl ) { return new Path ( baseDir , skewJoinPrefix + UNDERLINE + BIGKEYS + UNDERLINE + srcTbl ) ; } static Path getBigKeysSkewJoinResultDir ( Path baseDir , Byte srcTbl ) { return new Path ( baseDir , skewJoinPrefix + UNDERLINE + BIGKEYS + UNDERLINE + RESULTS + UNDERLINE + srcTbl ) ; } static Path getSmallKeysDir ( Path baseDir , Byte srcTblBigTbl , Byte srcTblSmallTbl ) { return new Path ( baseDir , skewJoinPrefix + UNDERLINE + SMALLKEYS + UNDERLINE + srcTblBigTbl + UNDERLINE + srcTblSmallTbl ) ; } }",No
"public abstract class _RWCompoundPainting extends BaseDataObject { private static final long serialVersionUID = 1L ; public static final String PAINTING_ID_PK_COLUMN = ""PAINTING_ID"" ; public static final Property < BigDecimal > ESTIMATED_PRICE = Property . create ( ""estimatedPrice"" , BigDecimal . class ) ; public static final Property < String > PAINTING_TITLE = Property . create ( ""paintingTitle"" , String . class ) ; public static final Property < String > TEXT_REVIEW = Property . create ( ""textReview"" , String . class ) ; protected BigDecimal estimatedPrice ; protected String paintingTitle ; protected String textReview ; public void setEstimatedPrice ( BigDecimal estimatedPrice ) { beforePropertyWrite ( ""estimatedPrice"" , this . estimatedPrice , estimatedPrice ) ; this . estimatedPrice = estimatedPrice ; } public BigDecimal getEstimatedPrice ( ) { beforePropertyRead ( ""estimatedPrice"" ) ; return this . estimatedPrice ; } public void setPaintingTitle ( String paintingTitle ) { beforePropertyWrite ( ""paintingTitle"" , this . paintingTitle , paintingTitle ) ; this . paintingTitle = paintingTitle ; } public String getPaintingTitle ( ) { beforePropertyRead ( ""paintingTitle"" ) ; return this . paintingTitle ; } public void setTextReview ( String textReview ) { beforePropertyWrite ( ""textReview"" , this . textReview , textReview ) ; this . textReview = textReview ; } public String getTextReview ( ) { beforePropertyRead ( ""textReview"" ) ; return this . textReview ; } @ Override public Object readPropertyDirectly ( String propName ) { if ( propName == null ) { throw new IllegalArgumentException ( ) ; } switch ( propName ) { case ""estimatedPrice"" : return this . estimatedPrice ; case ""paintingTitle"" : return this . paintingTitle ; case ""textReview"" : return this . textReview ; default : return super . readPropertyDirectly ( propName ) ; } } @ Override public void writePropertyDirectly ( String propName , Object val ) { if ( propName == null ) { throw new IllegalArgumentException ( ) ; } switch ( propName ) { case ""estimatedPrice"" : this . estimatedPrice = ( BigDecimal ) val ; break ; case ""paintingTitle"" : this . paintingTitle = ( String ) val ; break ; case ""textReview"" : this . textReview = ( String ) val ; break ; default : super . writePropertyDirectly ( propName , val ) ; } } private void writeObject ( ObjectOutputStream out ) throws IOException { writeSerialized ( out ) ; } private void readObject ( ObjectInputStream in ) throws IOException , ClassNotFoundException { readSerialized ( in ) ; } @ Override protected void writeState ( ObjectOutputStream out ) throws IOException { super . writeState ( out ) ; out . writeObject ( this . estimatedPrice ) ; out . writeObject ( this . paintingTitle ) ; out . writeObject ( this . textReview ) ; } @ Override protected void readState ( ObjectInputStream in ) throws IOException , ClassNotFoundException { super . readState ( in ) ; this . estimatedPrice = ( BigDecimal ) in . readObject ( ) ; this . paintingTitle = ( String ) in . readObject ( ) ; this . textReview = ( String ) in . readObject ( ) ; } }",Smelly
"public abstract class RemoteGroupPort extends AbstractPort implements Port , RemoteDestination { public RemoteGroupPort ( String id , String name , ProcessGroup processGroup , ConnectableType type , ProcessScheduler scheduler ) { super ( id , name , processGroup , type , scheduler ) ; } public abstract RemoteProcessGroup getRemoteProcessGroup ( ) ; public abstract TransferDirection getTransferDirection ( ) ; @ Override public abstract boolean isUseCompression ( ) ; public abstract void setUseCompression ( boolean useCompression ) ; public abstract boolean getTargetExists ( ) ; public abstract String getTargetIdentifier ( ) ; public abstract boolean isTargetRunning ( ) ; public abstract Integer getBatchCount ( ) ; public abstract void setBatchCount ( Integer batchCount ) ; public abstract String getBatchSize ( ) ; public abstract void setBatchSize ( String batchSize ) ; public abstract String getBatchDuration ( ) ; public abstract void setBatchDuration ( String batchDuration ) ; }",Smelly
"public class XMLHandler extends LexicalHandlerImpl implements ARPErrorNumbers , Names { boolean encodingProblems = false ; protected Map < IRI , Map < String , ARPLocation > > idsUsed = new HashMap < > ( ) ; protected int idsUsedCount = 0 ; public XMLHandler ( ) { } public void triple ( ANode s , ANode p , ANode o ) { StatementHandler stmt ; boolean bad = s . isTainted ( ) || p . isTainted ( ) || o . isTainted ( ) ; if ( bad ) { stmt = badStatementHandler ; } else { stmt = handlers . getStatementHandler ( ) ; } AResourceInternal subj = ( AResourceInternal ) s ; AResourceInternal pred = ( AResourceInternal ) p ; if ( ! bad ) subj . setHasBeenUsed ( ) ; if ( o instanceof AResource ) { AResourceInternal obj = ( AResourceInternal ) o ; if ( ! bad ) obj . setHasBeenUsed ( ) ; stmt . statement ( subj , pred , obj ) ; } else stmt . statement ( subj , pred , ( ALiteral ) o ) ; } FrameI frame ; @ Override public void startPrefixMapping ( String prefix , String uri ) throws SAXParseException { checkNamespaceURI ( uri ) ; handlers . getNamespaceHandler ( ) . startPrefixMapping ( prefix , uri ) ; } @ Override public void endPrefixMapping ( String prefix ) { handlers . getNamespaceHandler ( ) . endPrefixMapping ( prefix ) ; } public Locator getLocator ( ) { return locator ; } Locator locator ; @ Override public void setDocumentLocator ( Locator locator ) { this . locator = locator ; } static final private boolean DEBUG = false ; @ Override public void startElement ( String uri , String localName , String rawName , Attributes atts ) throws SAXException { if ( Thread . interrupted ( ) ) warning ( null , ERR_INTERRUPTED , ""Interrupt detected."" ) ; FrameI oldFrame = frame ; frame = frame . startElement ( uri , localName , rawName , atts ) ; if ( DEBUG ) System . err . println ( ""<"" + rawName + ""> :: "" + getSimpleName ( oldFrame . getClass ( ) ) + "" --> "" + getSimpleName ( frame . getClass ( ) ) ) ; } @ Override public void endElement ( String uri , String localName , String rawName ) throws SAXException { frame . endElement ( ) ; frame = frame . getParent ( ) ; frame . afterChild ( ) ; if ( DEBUG ) System . err . println ( ""</"" + rawName + ""> :: <--"" + getSimpleName ( frame . getClass ( ) ) ) ; } static public String getSimpleName ( Class < ? extends FrameI > c ) { String rslt [ ] = c . getName ( ) . split ( ""\\."" ) ; return rslt [ rslt . length - 1 ] ; } @ Override public void characters ( char ch [ ] , int start , int length ) throws SAXException { frame . characters ( ch , start , length ) ; } @ Override public void ignorableWhitespace ( char ch [ ] , int start , int length ) throws SAXException { characters ( ch , start , length ) ; } void setUserData ( String nodeId , Object v ) { nodeIdUserData . put ( nodeId , v ) ; } Object getUserData ( String nodeId ) { return nodeIdUserData . get ( nodeId ) ; } @ Override public void comment ( char [ ] ch , int start , int length ) throws SAXParseException { frame . comment ( ch , start , length ) ; } @ Override public void processingInstruction ( String target , String data ) throws SAXException { frame . processingInstruction ( target , data ) ; } public void warning ( Taint taintMe , int id , String msg ) throws SAXParseException { if ( options . getErrorMode ( id ) != EM_IGNORE ) warning ( taintMe , id , location ( ) , msg ) ; } void warning ( Taint taintMe , int id , ARPLocation loc , String msg ) throws SAXParseException { if ( options . getErrorMode ( id ) != EM_IGNORE ) warning ( taintMe , id , new ParseException ( id , loc , msg ) { private static final long serialVersionUID = 1990910846204964756L ; } ) ; } void generalError ( int id , Exception e ) throws SAXParseException { ARPLocation where = new ARPLocation ( locator ) ; warning ( null , id , new ParseException ( id , where , e ) ) ; } void warning ( Taint taintMe , int id , SAXParseException e ) throws SAXParseException { try { switch ( options . getErrorMode ( id ) ) { case EM_IGNORE : break ; case EM_WARNING : handlers . getErrorHandler ( ) . warning ( e ) ; break ; case EM_ERROR : if ( taintMe != null ) taintMe . taint ( ) ; handlers . getErrorHandler ( ) . error ( e ) ; break ; case EM_FATAL : handlers . getErrorHandler ( ) . fatalError ( e ) ; break ; } } catch ( SAXParseException xx ) { throw xx ; } catch ( SAXException ee ) { throw new WrappedException ( ee ) ; } if ( e instanceof ParseException && ( ( ParseException ) e ) . isPromoted ( ) ) throw e ; if ( options . getErrorMode ( id ) == EM_FATAL ) { throw new FatalParsingErrorException ( ) ; } } @ Override public void error ( SAXParseException e ) throws SAXParseException { warning ( null , ERR_SAX_ERROR , e ) ; } @ Override public void warning ( SAXParseException e ) throws SAXParseException { warning ( null , WARN_SAX_WARNING , e ) ; } @ Override public void fatalError ( SAXParseException e ) throws SAXException { warning ( null , ERR_SAX_FATAL_ERROR , e ) ; throw new FatalParsingErrorException ( ) ; } public void endLocalScope ( ANode v ) { if ( handlers . getExtendedHandler ( ) != nullScopeHandler ) { ARPResource bn = ( ARPResource ) v ; if ( ! bn . getHasBeenUsed ( ) ) return ; if ( bn . hasNodeID ( ) ) { if ( handlers . getExtendedHandler ( ) . discardNodesWithNodeID ( ) ) return ; String bnodeID = bn . nodeID ; if ( ! nodeIdUserData . containsKey ( bnodeID ) ) nodeIdUserData . put ( bnodeID , null ) ; } else { handlers . getExtendedHandler ( ) . endBNodeScope ( bn ) ; } } } public void endRDF ( ) { handlers . getExtendedHandler ( ) . endRDF ( ) ; } public void startRDF ( ) { handlers . getExtendedHandler ( ) . startRDF ( ) ; } boolean ignoring ( int eCode ) { return options . getErrorMode ( eCode ) == EM_IGNORE ; } public boolean isError ( int eCode ) { return options . getErrorMode ( eCode ) == EM_ERROR ; } protected AbsXMLContext initialContext ( String base , String lang ) throws SAXParseException { return initialContextWithBase ( base ) . withLang ( this , lang ) ; } private boolean allowRelativeReferences = false ; private AbsXMLContext initialContextWithBase ( String base ) throws SAXParseException { allowRelativeReferences = false ; if ( base == null ) { warning ( null , IGN_NO_BASE_URI_SPECIFIED , ""Base URI not specified for input file; local URI references will be in error."" ) ; return new XMLBaselessContext ( this , ERR_RESOLVING_URI_AGAINST_NULL_BASE ) ; } else if ( base . equals ( """" ) ) { allowRelativeReferences = true ; warning ( null , IGN_NO_BASE_URI_SPECIFIED , ""Base URI specified as \""\""; local URI references will not be resolved."" ) ; return new XMLBaselessContext ( this , WARN_RESOLVING_URI_AGAINST_EMPTY_BASE ) ; } else { return new XMLBaselessContext ( this , ERR_RESOLVING_AGAINST_RELATIVE_BASE ) . withBase ( this , base ) ; } } private ARPOptions options = ARPOptions . createNewOptions ( ) ; private ARPHandlers handlers = ARPHandlers . createNewHandlers ( ) ; StatementHandler getStatementHandler ( ) { return handlers . getStatementHandler ( ) ; } public ARPHandlers getHandlers ( ) { return handlers ; } public ARPOptions getOptions ( ) { return options ; } public void setOptionsWith ( ARPOptions newOpts ) { options = newOpts . copy ( ) ; } public void setHandlersWith ( ARPHandlers newHh ) { handlers = ARPHandlers . createNewHandlers ( ) ; handlers . setErrorHandler ( newHh . getErrorHandler ( ) ) ; handlers . setExtendedHandler ( newHh . getExtendedHandler ( ) ) ; handlers . setNamespaceHandler ( newHh . getNamespaceHandler ( ) ) ; handlers . setStatementHandler ( newHh . getStatementHandler ( ) ) ; } private Map < String , Object > nodeIdUserData ; public void initParse ( String base , String lang ) throws SAXParseException { nodeIdUserData = new HashMap < > ( ) ; idsUsed = ignoring ( WARN_REDEFINITION_OF_ID ) ? null : new HashMap < > ( ) ; idsUsedCount = 0 ; if ( options . getEmbedding ( ) ) frame = new LookingForRDF ( this , initialContext ( base , lang ) ) ; else frame = new StartStateRDForDescription ( this , initialContext ( base , lang ) ) ; } void afterParse ( ) { while ( frame != null ) { frame . abort ( ) ; frame = frame . getParent ( ) ; } endBnodeScope ( ) ; idsUsed = null ; } void endBnodeScope ( ) { if ( handlers . getExtendedHandler ( ) != nullScopeHandler ) { for ( String nodeId : nodeIdUserData . keySet ( ) ) { ARPResource bn = new ARPResource ( this , nodeId ) ; handlers . getExtendedHandler ( ) . endBNodeScope ( bn ) ; } } } public ARPLocation location ( ) { return new ARPLocation ( locator ) ; } private IRIFactory factory = null ; IRIFactory iriFactory ( ) { if ( factory == null ) { factory = options . getIRIFactory ( ) ; if ( factory == null ) factory = ARPOptions . getIRIFactoryGlobal ( ) ; } return factory ; } private void checkNamespaceURI ( String uri ) throws SAXParseException { ( ( Frame ) frame ) . checkEncoding ( null , uri ) ; if ( uri . length ( ) != 0 ) { IRI u = iriFactory ( ) . create ( uri ) ; if ( ! u . isAbsolute ( ) ) { warning ( null , WARN_RELATIVE_NAMESPACE_URI_DEPRECATED , ""The namespace URI: <"" + uri + ""> is relative. Such use has been deprecated by the W3C, and may result in RDF interoperability failures. Use an absolute namespace URI."" ) ; } try { if ( ! u . toASCIIString ( ) . equals ( u . toString ( ) ) ) warning ( null , WARN_BAD_NAMESPACE_URI , ""Non-ascii characters in a namespace URI may not be completely portable: <"" + u . toString ( ) + "">. Resulting RDF URI references are legal."" ) ; } catch ( MalformedURLException e ) { warning ( null , WARN_BAD_NAMESPACE_URI , ""Bad namespace URI: <"" + u . toString ( ) + "">. "" + e . getMessage ( ) ) ; } if ( uri . startsWith ( rdfns ) && ! uri . equals ( rdfns ) ) warning ( null , WARN_BAD_RDF_NAMESPACE_URI , ""Namespace URI ref <"" + uri + ""> may not be used in RDF/XML."" ) ; if ( uri . startsWith ( xmlns ) && ! uri . equals ( xmlns ) ) warning ( null , WARN_BAD_XML_NAMESPACE_URI , ""Namespace URI ref <"" + uri + ""> may not be used in RDF/XML."" ) ; } } public boolean allowRelativeURIs ( ) { return allowRelativeReferences ; } private IRI sameDocRef ; public IRI sameDocRef ( ) { if ( sameDocRef == null ) { sameDocRef = iriFactory ( ) . create ( """" ) ; } return sameDocRef ; } private StatementHandler badStatementHandler = nullStatementHandler ; public void setBadStatementHandler ( StatementHandler sh ) { badStatementHandler = sh ; } final public static StatementHandler nullStatementHandler = new StatementHandler ( ) { @ Override public void statement ( AResource s , AResource p , AResource o ) { } @ Override public void statement ( AResource s , AResource p , ALiteral o ) { } } ; final public static ExtendedHandler nullScopeHandler = new ExtendedHandler ( ) { @ Override public void endBNodeScope ( AResource bnode ) { } @ Override public void startRDF ( ) { } @ Override public void endRDF ( ) { } @ Override public boolean discardNodesWithNodeID ( ) { return true ; } } ; }",No
"@ Entity @ Inheritance ( strategy = InheritanceType . JOINED ) public class EagerPC { @ Id private int id ; @ Column ( name = ""strngfld"" , length = 50 ) private String stringField ; @ OneToOne ( cascade = { CascadeType . PERSIST , CascadeType . REMOVE } ) private HelperPC eager ; @ Column ( name = ""eagsub"" ) @ OneToOne ( cascade = { CascadeType . PERSIST , CascadeType . REMOVE } ) private HelperPC4 eagerSub ; @ OneToOne ( cascade = { CascadeType . PERSIST , CascadeType . REMOVE } ) private HelperPC2 recurse ; @ OneToOne ( cascade = { CascadeType . PERSIST , CascadeType . REMOVE } ) private HelperPC helper ; @ Transient private List eagerCollection = new LinkedList ( ) ; @ Transient private List recurseCollection = new LinkedList ( ) ; @ Transient private List helperCollection = new LinkedList ( ) ; public EagerPC ( ) { } public EagerPC ( int id ) { this . id = id ; } public String getStringField ( ) { return this . stringField ; } public void setStringField ( String stringField ) { this . stringField = stringField ; } public HelperPC getEager ( ) { return this . eager ; } public void setEager ( HelperPC eager ) { this . eager = eager ; } public HelperPC2 getRecurse ( ) { return this . recurse ; } public void setRecurse ( HelperPC2 recurse ) { this . recurse = recurse ; } public HelperPC getHelper ( ) { return this . helper ; } public void setHelper ( HelperPC helper ) { this . helper = helper ; } public List getEagerCollection ( ) { return this . eagerCollection ; } public void setEagerCollection ( List eagerCollection ) { this . eagerCollection = eagerCollection ; } public List getRecurseCollection ( ) { return this . recurseCollection ; } public void setRecurseCollection ( List recurseCollection ) { this . recurseCollection = recurseCollection ; } public List getHelperCollection ( ) { return this . helperCollection ; } public void setHelperCollection ( List helperCollection ) { this . helperCollection = helperCollection ; } public HelperPC4 getEagerSub ( ) { return this . eagerSub ; } public void setEagerSub ( HelperPC4 eagerSub ) { this . eagerSub = eagerSub ; } public int getId ( ) { return id ; } public void setId ( int id ) { this . id = id ; } }",Smelly
public abstract class AbstractSAXFragment implements XMLFragment { public void toDOM ( Node node ) throws Exception { toSAX ( new DOMBuilder ( node ) ) ; } },No
"public class AddMavenOneProjectAction extends AddMavenProjectAction { protected ContinuumProjectBuildingResult doExecute ( String pomUrl , int selectedProjectGroup , boolean checkProtocol , boolean scmUseCache ) throws ContinuumException { ContinuumProjectBuildingResult result = getContinuum ( ) . addMavenOneProject ( pomUrl , selectedProjectGroup , checkProtocol , scmUseCache , this . getBuildDefinitionTemplateId ( ) ) ; AuditLog event = new AuditLog ( hidePasswordInUrl ( pomUrl ) , AuditLogConstants . ADD_M1_PROJECT ) ; event . setCategory ( AuditLogConstants . PROJECT ) ; event . setCurrentUser ( getPrincipal ( ) ) ; if ( result == null || result . hasErrors ( ) ) { event . setAction ( AuditLogConstants . ADD_M1_PROJECT_FAILED ) ; } event . log ( ) ; return result ; } public String getM1Pom ( ) { return getPom ( ) ; } public void setM1Pom ( String pom ) { setPom ( pom ) ; } public File getM1PomFile ( ) { return getPomFile ( ) ; } public void setM1PomFile ( File pomFile ) { setPomFile ( pomFile ) ; } public String getM1PomUrl ( ) { return getPomUrl ( ) ; } public void setM1PomUrl ( String pomUrl ) { setPomUrl ( pomUrl ) ; } }",Smelly
"public class HiveStoragePlugin extends AbstractStoragePlugin { static final org . slf4j . Logger logger = org . slf4j . LoggerFactory . getLogger ( HiveStoragePlugin . class ) ; private final HiveStoragePluginConfig config ; private HiveSchemaFactory schemaFactory ; private final DrillbitContext context ; private final String name ; private final HiveConf hiveConf ; public HiveStoragePlugin ( HiveStoragePluginConfig config , DrillbitContext context , String name ) throws ExecutionSetupException { this . config = config ; this . context = context ; this . name = name ; this . hiveConf = createHiveConf ( config . getHiveConfigOverride ( ) ) ; this . schemaFactory = new HiveSchemaFactory ( this , name , hiveConf ) ; } public HiveConf getHiveConf ( ) { return hiveConf ; } public HiveStoragePluginConfig getConfig ( ) { return config ; } public String getName ( ) { return name ; } public DrillbitContext getContext ( ) { return context ; } @ Override public HiveScan getPhysicalScan ( String userName , JSONOptions selection , List < SchemaPath > columns ) throws IOException { HiveReadEntry hiveReadEntry = selection . getListWith ( new ObjectMapper ( ) , new TypeReference < HiveReadEntry > ( ) { } ) ; try { if ( hiveReadEntry . getJdbcTableType ( ) == TableType . VIEW ) { throw new UnsupportedOperationException ( ""Querying views created in Hive from Drill is not supported in current version."" ) ; } return new HiveScan ( userName , hiveReadEntry , this , columns , null ) ; } catch ( ExecutionSetupException e ) { throw new IOException ( e ) ; } } @ Override public synchronized void registerSchemas ( SchemaConfig schemaConfig , SchemaPlus parent ) throws IOException { try { schemaFactory . registerSchemas ( schemaConfig , parent ) ; return ; } catch ( Throwable e ) { Throwable ex = e ; for ( ; ; ) { if ( ex instanceof MetaException || ex instanceof TTransportException ) { break ; } if ( ex . getCause ( ) == null || ex . getCause ( ) == ex ) { logger . error ( ""Hive metastore register schemas failed"" , e ) ; throw new DrillRuntimeException ( ""Unknown Hive error"" , e ) ; } ex = ex . getCause ( ) ; } } try { schemaFactory . close ( ) ; } catch ( Throwable t ) { logger . warn ( ""Schema factory forced close failed, error ignored"" , t ) ; } try { schemaFactory = new HiveSchemaFactory ( this , name , hiveConf ) ; } catch ( ExecutionSetupException e ) { throw new DrillRuntimeException ( e ) ; } schemaFactory . registerSchemas ( schemaConfig , parent ) ; logger . debug ( ""Successfully recovered from a Hive metastore connection failure."" ) ; } @ Override public Set < StoragePluginOptimizerRule > getLogicalOptimizerRules ( OptimizerRulesContext optimizerContext ) { final String defaultPartitionValue = hiveConf . get ( ConfVars . DEFAULTPARTITIONNAME . varname ) ; ImmutableSet . Builder < StoragePluginOptimizerRule > ruleBuilder = ImmutableSet . builder ( ) ; ruleBuilder . add ( HivePushPartitionFilterIntoScan . getFilterOnProject ( optimizerContext , defaultPartitionValue ) ) ; ruleBuilder . add ( HivePushPartitionFilterIntoScan . getFilterOnScan ( optimizerContext , defaultPartitionValue ) ) ; return ruleBuilder . build ( ) ; } @ Override public Set < StoragePluginOptimizerRule > getPhysicalOptimizerRules ( OptimizerRulesContext optimizerRulesContext ) { if ( optimizerRulesContext . getPlannerSettings ( ) . getOptions ( ) . getOption ( ExecConstants . HIVE_OPTIMIZE_SCAN_WITH_NATIVE_READERS ) . bool_val ) { return ImmutableSet . < StoragePluginOptimizerRule > of ( ConvertHiveParquetScanToDrillParquetScan . INSTANCE ) ; } return ImmutableSet . of ( ) ; } private static HiveConf createHiveConf ( final Map < String , String > hiveConfigOverride ) { final HiveConf hiveConf = new HiveConf ( ) ; for ( Entry < String , String > config : hiveConfigOverride . entrySet ( ) ) { final String key = config . getKey ( ) ; final String value = config . getValue ( ) ; hiveConf . set ( key , value ) ; logger . trace ( ""HiveConfig Override {}={}"" , key , value ) ; } return hiveConf ; } }",Smelly
"public class TestNumberUtil { @ Test public void testNumberToAsciiBytes ( ) { Random r = new Random ( System . currentTimeMillis ( ) ) ; Number n = r . nextInt ( ) ; assertArrayEquals ( String . valueOf ( n . shortValue ( ) ) . getBytes ( ) , NumberUtil . toAsciiBytes ( n . shortValue ( ) ) ) ; n = r . nextInt ( ) ; assertArrayEquals ( String . valueOf ( n . intValue ( ) ) . getBytes ( ) , NumberUtil . toAsciiBytes ( n . intValue ( ) ) ) ; n = r . nextLong ( ) ; assertArrayEquals ( String . valueOf ( n . longValue ( ) ) . getBytes ( ) , NumberUtil . toAsciiBytes ( n . longValue ( ) ) ) ; n = r . nextFloat ( ) ; assertArrayEquals ( String . valueOf ( n . floatValue ( ) ) . getBytes ( ) , NumberUtil . toAsciiBytes ( n . floatValue ( ) ) ) ; n = r . nextDouble ( ) ; assertArrayEquals ( String . valueOf ( n . doubleValue ( ) ) . getBytes ( ) , NumberUtil . toAsciiBytes ( n . doubleValue ( ) ) ) ; } @ Test public void testParseInt ( ) { int int1 = 0 ; byte [ ] bytes1 = Double . toString ( int1 ) . getBytes ( ) ; assertEquals ( int1 , NumberUtil . parseInt ( bytes1 , 0 , bytes1 . length ) ) ; int int2 = - 7 ; byte [ ] bytes2 = Double . toString ( int2 ) . getBytes ( ) ; assertEquals ( int2 , NumberUtil . parseInt ( bytes2 , 0 , bytes2 . length ) ) ; int int3 = + 128 ; byte [ ] bytes3 = Double . toString ( int3 ) . getBytes ( ) ; assertEquals ( int3 , NumberUtil . parseInt ( bytes3 , 0 , bytes3 . length ) ) ; int int4 = 4 ; byte [ ] bytes4 = Double . toString ( int4 ) . getBytes ( ) ; assertEquals ( int4 , NumberUtil . parseInt ( bytes4 , 0 , bytes4 . length ) ) ; byte [ ] bytes5 = ""0123-456789"" . getBytes ( ) ; assertEquals ( - 456 , NumberUtil . parseInt ( bytes5 , 4 , 4 ) ) ; } @ Test public void testParseDouble ( ) { double double1 = 2.0015E7 ; byte [ ] bytes1 = Double . toString ( double1 ) . getBytes ( ) ; assertEquals ( double1 , NumberUtil . parseDouble ( bytes1 , 0 , bytes1 . length ) , 0.0 ) ; double double2 = 1.345E-7 ; byte [ ] bytes2 = Double . toString ( double2 ) . getBytes ( ) ; assertEquals ( double2 , NumberUtil . parseDouble ( bytes2 , 0 , bytes2 . length ) , 0.0 ) ; double double3 = - 1.345E-7 ; byte [ ] bytes3 = Double . toString ( double3 ) . getBytes ( ) ; assertEquals ( double3 , NumberUtil . parseDouble ( bytes3 , 0 , bytes3 . length ) , 0.0 ) ; double double4 = 4 ; byte [ ] bytes4 = Double . toString ( double4 ) . getBytes ( ) ; assertEquals ( double4 , NumberUtil . parseDouble ( bytes4 , 0 , bytes4 . length ) , 0.0 ) ; byte [ ] bytes5 = ""0123456789.012345E012345"" . getBytes ( ) ; assertEquals ( 6789.012345E01 , NumberUtil . parseDouble ( bytes5 , 6 , 14 ) , 0.0 ) ; } }",No
" public static class Builder { private int layoutVersion = 0 ; private String bookieHost = null ; private String journalDirs = null ; private String ledgerDirs = null ; private String instanceId = null ; private Builder ( ) { } private Builder ( int layoutVersion , String bookieHost , String journalDirs , String ledgerDirs , String instanceId ) { this . layoutVersion = layoutVersion ; this . bookieHost = bookieHost ; this . journalDirs = journalDirs ; this . ledgerDirs = ledgerDirs ; this . instanceId = instanceId ; } public Builder setLayoutVersion ( int layoutVersion ) { this . layoutVersion = layoutVersion ; return this ; } public Builder setBookieHost ( String bookieHost ) { this . bookieHost = bookieHost ; return this ; } public Builder setJournalDirs ( String journalDirs ) { this . journalDirs = journalDirs ; return this ; } public Builder setLedgerDirs ( String ledgerDirs ) { this . ledgerDirs = ledgerDirs ; return this ; } public Builder setInstanceId ( String instanceId ) { this . instanceId = instanceId ; return this ; } public Cookie build ( ) { return new Cookie ( layoutVersion , bookieHost , journalDirs , ledgerDirs , instanceId ) ; } ",No
" private class MoveIntermediateToDoneRunnable implements Runnable { @ Override public void run ( ) { try { LOG . info ( ""Starting scan to move intermediate done files"" ) ; hsManager . scanIntermediateDirectory ( ) ; } catch ( IOException e ) { LOG . error ( ""Error while scanning intermediate done dir "" , e ) ; } } ",No
@ Embeddable public class Embed_ToMany { protected String name1 ; protected String name2 ; protected String name3 ; @ OneToMany ( fetch = FetchType . EAGER ) public List < EntityB1 > bs = new ArrayList < EntityB1 > ( ) ; public String getName1 ( ) { return name1 ; } public void setName1 ( String name1 ) { this . name1 = name1 ; } public String getName2 ( ) { return name2 ; } public void setName2 ( String name2 ) { this . name2 = name2 ; } public String getName3 ( ) { return name3 ; } public void setName3 ( String name3 ) { this . name3 = name3 ; } public List < EntityB1 > getEntityBs ( ) { return bs ; } public void addEntityB ( EntityB1 b ) { bs . add ( b ) ; } },Smelly
"@ XmlType public abstract class AnyPatch extends AbstractBaseBean implements AttributablePatch { private static final long serialVersionUID = - 7445489774552440544L ; private String key ; private StringReplacePatchItem realm ; private final Set < StringPatchItem > auxClasses = new HashSet < > ( ) ; private final Set < AttrPatch > plainAttrs = new HashSet < > ( ) ; private final Set < AttrTO > virAttrs = new HashSet < > ( ) ; private final Set < StringPatchItem > resources = new HashSet < > ( ) ; public String getKey ( ) { return key ; } @ PathParam ( ""key"" ) public void setKey ( final String key ) { this . key = key ; } public StringReplacePatchItem getRealm ( ) { return realm ; } public void setRealm ( final StringReplacePatchItem realm ) { this . realm = realm ; } @ XmlElementWrapper ( name = ""auxClasses"" ) @ XmlElement ( name = ""auxClass"" ) @ JsonProperty ( ""auxClasses"" ) public Set < StringPatchItem > getAuxClasses ( ) { return auxClasses ; } @ XmlElementWrapper ( name = ""plainAttrs"" ) @ XmlElement ( name = ""attribute"" ) @ JsonProperty ( ""plainAttrs"" ) @ Override public Set < AttrPatch > getPlainAttrs ( ) { return plainAttrs ; } @ XmlElementWrapper ( name = ""virAttrs"" ) @ XmlElement ( name = ""attribute"" ) @ JsonProperty ( ""virAttrs"" ) @ Override public Set < AttrTO > getVirAttrs ( ) { return virAttrs ; } @ XmlElementWrapper ( name = ""resources"" ) @ XmlElement ( name = ""resource"" ) @ JsonProperty ( ""resources"" ) public Set < StringPatchItem > getResources ( ) { return resources ; } @ JsonIgnore public boolean isEmpty ( ) { return realm == null && auxClasses . isEmpty ( ) && plainAttrs . isEmpty ( ) && virAttrs . isEmpty ( ) && resources . isEmpty ( ) ; } }",Smelly
"public class DefaultModelProblem implements ModelProblem { private final String source ; private final int lineNumber ; private final int columnNumber ; private final String modelId ; private final String message ; private final Exception exception ; private final Severity severity ; private final Version version ; public DefaultModelProblem ( String message , Severity severity , Version version , Model source , int lineNumber , int columnNumber , Exception exception ) { this ( message , severity , version , ModelProblemUtils . toPath ( source ) , lineNumber , columnNumber , ModelProblemUtils . toId ( source ) , exception ) ; } public DefaultModelProblem ( String message , Severity severity , Version version , String source , int lineNumber , int columnNumber , String modelId , Exception exception ) { this . message = message ; this . severity = ( severity != null ) ? severity : Severity . ERROR ; this . source = ( source != null ) ? source : """" ; this . lineNumber = lineNumber ; this . columnNumber = columnNumber ; this . modelId = ( modelId != null ) ? modelId : """" ; this . exception = exception ; this . version = version ; } @ Override public String getSource ( ) { return source ; } @ Override public int getLineNumber ( ) { return lineNumber ; } @ Override public int getColumnNumber ( ) { return columnNumber ; } @ Override public String getModelId ( ) { return modelId ; } @ Override public Exception getException ( ) { return exception ; } @ Override public String getMessage ( ) { String msg ; if ( message != null && message . length ( ) > 0 ) { msg = message ; } else { msg = exception . getMessage ( ) ; if ( msg == null ) { msg = """" ; } } return msg ; } @ Override public Severity getSeverity ( ) { return severity ; } @ Override public Version getVersion ( ) { return version ; } @ Override public String toString ( ) { StringBuilder buffer = new StringBuilder ( 128 ) ; buffer . append ( '[' ) . append ( getSeverity ( ) ) . append ( ""] "" ) ; buffer . append ( getMessage ( ) ) ; buffer . append ( "" @ "" ) . append ( ModelProblemUtils . formatLocation ( this , null ) ) ; return buffer . toString ( ) ; } }",Smelly
"public class RelationshipLoader extends AbstractLoader { private static final Logger LOGGER = LoggerFactory . getLogger ( DbLoader . class ) ; private final ObjectNameGenerator nameGenerator ; RelationshipLoader ( DbLoaderConfiguration config , DbLoaderDelegate delegate , ObjectNameGenerator nameGenerator ) { super ( null , config , delegate ) ; this . nameGenerator = nameGenerator ; } @ Override public void load ( DatabaseMetaData metaData , DbLoadDataStore map ) throws SQLException { if ( config . isSkipRelationshipsLoading ( ) ) { return ; } for ( Map . Entry < String , Set < ExportedKey > > entry : map . getExportedKeysEntrySet ( ) ) { if ( LOGGER . isDebugEnabled ( ) ) { LOGGER . debug ( ""Process keys for: "" + entry . getKey ( ) ) ; } Set < ExportedKey > exportedKeys = entry . getValue ( ) ; ExportedKey key = exportedKeys . iterator ( ) . next ( ) ; if ( key == null ) { throw new IllegalStateException ( ) ; } ExportedKey . KeyData PK = key . getPk ( ) ; ExportedKey . KeyData FK = key . getFk ( ) ; DbEntity pkEntity = map . getDbEntity ( PK . getTable ( ) ) ; DbEntity fkEntity = map . getDbEntity ( FK . getTable ( ) ) ; if ( pkEntity == null || fkEntity == null ) { throw new IllegalStateException ( ) ; } DbRelationship forwardRelationship = new DbRelationship ( ) ; forwardRelationship . setSourceEntity ( pkEntity ) ; forwardRelationship . setTargetEntityName ( fkEntity ) ; DbRelationshipDetected reverseRelationship = new DbRelationshipDetected ( ) ; reverseRelationship . setFkName ( FK . getName ( ) ) ; reverseRelationship . setSourceEntity ( fkEntity ) ; reverseRelationship . setTargetEntityName ( pkEntity ) ; reverseRelationship . setToMany ( false ) ; createAndAppendJoins ( exportedKeys , pkEntity , fkEntity , forwardRelationship , reverseRelationship ) ; boolean toDependentPK = isToDependentPK ( forwardRelationship ) ; boolean toMany = isToMany ( toDependentPK , fkEntity , forwardRelationship ) ; forwardRelationship . setToDependentPK ( toDependentPK ) ; forwardRelationship . setToMany ( toMany ) ; setRelationshipName ( pkEntity , forwardRelationship ) ; setRelationshipName ( fkEntity , reverseRelationship ) ; checkAndAddRelationship ( pkEntity , forwardRelationship ) ; checkAndAddRelationship ( fkEntity , reverseRelationship ) ; } } private void setRelationshipName ( DbEntity entity , DbRelationship relationship ) { relationship . setName ( NameBuilder . builder ( relationship , entity ) . baseName ( nameGenerator . relationshipName ( relationship ) ) . name ( ) ) ; } private void checkAndAddRelationship ( DbEntity entity , DbRelationship relationship ) { TableFilter sourceTableFilter = config . getFiltersConfig ( ) . tableFilter ( relationship . getSourceEntity ( ) . getCatalog ( ) , relationship . getSourceEntity ( ) . getSchema ( ) ) ; TableFilter targetTableFilter = config . getFiltersConfig ( ) . tableFilter ( relationship . getTargetEntity ( ) . getCatalog ( ) , relationship . getTargetEntity ( ) . getSchema ( ) ) ; if ( ! sourceTableFilter . getIncludeTableRelationshipFilter ( entity . getName ( ) ) . isIncluded ( relationship . getName ( ) ) ) { return ; } if ( relationship . getJoins ( ) . isEmpty ( ) ) { return ; } for ( DbJoin join : relationship . getJoins ( ) ) { if ( ! sourceTableFilter . getIncludeTableColumnFilter ( entity . getName ( ) ) . isIncluded ( join . getSourceName ( ) ) || ! targetTableFilter . getIncludeTableColumnFilter ( relationship . getTargetEntityName ( ) ) . isIncluded ( join . getTargetName ( ) ) ) { return ; } } if ( delegate . dbRelationshipLoaded ( entity , relationship ) ) { entity . addRelationship ( relationship ) ; } } private boolean isToMany ( boolean toDependentPK , DbEntity fkEntity , DbRelationship forwardRelationship ) { return ! toDependentPK || fkEntity . getPrimaryKeys ( ) . size ( ) != forwardRelationship . getJoins ( ) . size ( ) ; } private boolean isToDependentPK ( DbRelationship forwardRelationship ) { for ( DbJoin dbJoin : forwardRelationship . getJoins ( ) ) { if ( ! dbJoin . getTarget ( ) . isPrimaryKey ( ) ) { return false ; } } return true ; } private void createAndAppendJoins ( Set < ExportedKey > exportedKeys , DbEntity pkEntity , DbEntity fkEntity , DbRelationship forwardRelationship , DbRelationship reverseRelationship ) { for ( ExportedKey exportedKey : exportedKeys ) { String pkName = exportedKey . getPk ( ) . getColumn ( ) ; String fkName = exportedKey . getFk ( ) . getColumn ( ) ; DbAttribute pkAtt = pkEntity . getAttribute ( pkName ) ; if ( pkAtt == null ) { LOGGER . info ( ""no attribute for declared primary key: "" + pkName ) ; continue ; } DbAttribute fkAtt = fkEntity . getAttribute ( fkName ) ; if ( fkAtt == null ) { LOGGER . info ( ""no attribute for declared foreign key: "" + fkName ) ; continue ; } addJoin ( forwardRelationship , pkName , fkName ) ; addJoin ( reverseRelationship , fkName , pkName ) ; } } private void addJoin ( DbRelationship relationship , String sourceName , String targetName ) { for ( DbJoin join : relationship . getJoins ( ) ) { if ( join . getSourceName ( ) . equals ( sourceName ) && join . getTargetName ( ) . equals ( targetName ) ) { return ; } } relationship . addJoin ( new DbJoin ( relationship , sourceName , targetName ) ) ; } }",No
"public class ShiftWithLowMemoryProfileTest { @ Test public void testWithLowMemory ( ) throws Exception { String name = this . getClass ( ) . getSimpleName ( ) ; String namespace = this . getClass ( ) . getPackage ( ) . getName ( ) . replaceAll ( ""\\."" , ""/"" ) ; Map < String , Object > parameters = new HashMap < String , Object > ( ) ; parameters . put ( RutaEngine . PARAM_LOW_MEMORY_PROFILE , true ) ; CAS cas = RutaTestUtils . process ( namespace + ""/"" + name + RutaEngine . SCRIPT_FILE_EXTENSION , namespace + ""/"" + name + "".txt"" , parameters , 50 ) ; Type t = cas . getTypeSystem ( ) . getType ( ""org.apache.uima.ruta.type.W"" ) ; AnnotationIndex < AnnotationFS > ai = cas . getAnnotationIndex ( t ) ; assertEquals ( 1 , ai . size ( ) ) ; FSIterator < AnnotationFS > iterator = ai . iterator ( ) ; assertEquals ( ""A"" , iterator . next ( ) . getCoveredText ( ) ) ; cas . release ( ) ; } }",No
"@ Explain ( displayName = ""Alter Table Partition Merge Files"" ) public class AlterTablePartMergeFilesDesc { private String tableName ; private HashMap < String , String > partSpec ; private ListBucketingCtx lbCtx ; private List < Path > inputDir = new ArrayList < Path > ( ) ; private Path outputDir = null ; public AlterTablePartMergeFilesDesc ( String tableName , HashMap < String , String > partSpec ) { this . tableName = tableName ; this . partSpec = partSpec ; } @ Explain ( displayName = ""table name"" ) public String getTableName ( ) { return tableName ; } public void setTableName ( String tableName ) { this . tableName = tableName ; } @ Explain ( displayName = ""partition desc"" ) public HashMap < String , String > getPartSpec ( ) { return partSpec ; } public void setPartSpec ( HashMap < String , String > partSpec ) { this . partSpec = partSpec ; } public Path getOutputDir ( ) { return outputDir ; } public void setOutputDir ( Path outputDir ) { this . outputDir = outputDir ; } public List < Path > getInputDir ( ) { return inputDir ; } public void setInputDir ( List < Path > inputDir ) { this . inputDir = inputDir ; } public ListBucketingCtx getLbCtx ( ) { return lbCtx ; } public void setLbCtx ( ListBucketingCtx lbCtx ) { this . lbCtx = lbCtx ; } }",Smelly
"@ Entity @ Table ( name = ""PROCESS"" ) public class Process { private final static Logger logger = LoggerFactory . getLogger ( Process . class ) ; private String processId ; private String experimentId ; private Timestamp creationTime ; private Timestamp lastUpdateTime ; private String processDetail ; private String applicationInterfaceId ; private String taskDag ; private String applicationDeploymentId ; private String computeResourceId ; private String gatewayExecutionId ; private boolean enableEmailNotification ; private String emailAddresses ; private String storageId ; private String experimentDataDir ; private String userName ; private Experiment experiment ; private Collection < ProcessError > processErrors ; private Collection < ProcessInput > processInputs ; private Collection < ProcessOutput > processOutputs ; private ProcessResourceSchedule processResourceSchedule ; private Collection < ProcessStatus > processStatuses ; private Collection < Task > tasks ; private String userDn ; private boolean generateCert ; @ Id @ Column ( name = ""PROCESS_ID"" ) public String getProcessId ( ) { return processId ; } public void setProcessId ( String processId ) { this . processId = processId ; } @ Column ( name = ""EXPERIMENT_ID"" ) public String getExperimentId ( ) { return experimentId ; } public void setExperimentId ( String experimentId ) { this . experimentId = experimentId ; } @ Column ( name = ""CREATION_TIME"" ) public Timestamp getCreationTime ( ) { return creationTime ; } public void setCreationTime ( Timestamp creationTime ) { this . creationTime = creationTime ; } @ Column ( name = ""LAST_UPDATE_TIME"" ) public Timestamp getLastUpdateTime ( ) { return lastUpdateTime ; } public void setLastUpdateTime ( Timestamp lastUpdateTime ) { this . lastUpdateTime = lastUpdateTime ; } @ Lob @ Column ( name = ""PROCESS_DETAIL"" ) public String getProcessDetail ( ) { return processDetail ; } public void setProcessDetail ( String processDetail ) { this . processDetail = processDetail ; } @ Column ( name = ""APPLICATION_INTERFACE_ID"" ) public String getApplicationInterfaceId ( ) { return applicationInterfaceId ; } public void setApplicationInterfaceId ( String applicationInterfaceId ) { this . applicationInterfaceId = applicationInterfaceId ; } @ Column ( name = ""USERNAME"" ) public String getUserName ( ) { return userName ; } public void setUserName ( String userName ) { this . userName = userName ; } @ Column ( name = ""STORAGE_RESOURCE_ID"" ) public String getStorageId ( ) { return storageId ; } public void setStorageId ( String storageId ) { this . storageId = storageId ; } @ Lob @ Column ( name = ""TASK_DAG"" ) public String getTaskDag ( ) { return taskDag ; } public void setTaskDag ( String taskDag ) { this . taskDag = taskDag ; } @ Column ( name = ""APPLICATION_DEPLOYMENT_ID"" ) public String getApplicationDeploymentId ( ) { return applicationDeploymentId ; } public void setApplicationDeploymentId ( String applicationDeploymentId ) { this . applicationDeploymentId = applicationDeploymentId ; } @ Column ( name = ""COMPUTE_RESOURCE_ID"" ) public String getComputeResourceId ( ) { return computeResourceId ; } public void setComputeResourceId ( String computeResourceId ) { this . computeResourceId = computeResourceId ; } @ Column ( name = ""GATEWAY_EXECUTION_ID"" ) public String getGatewayExecutionId ( ) { return gatewayExecutionId ; } public void setGatewayExecutionId ( String gatewayExecutionId ) { this . gatewayExecutionId = gatewayExecutionId ; } @ Column ( name = ""ENABLE_EMAIL_NOTIFICATION"" ) public boolean getEnableEmailNotification ( ) { return enableEmailNotification ; } public void setEnableEmailNotification ( boolean enableEmailNotification ) { this . enableEmailNotification = enableEmailNotification ; } @ Lob @ Column ( name = ""EMAIL_ADDRESSES"" ) public String getEmailAddresses ( ) { return emailAddresses ; } public void setEmailAddresses ( String emailAddresses ) { this . emailAddresses = emailAddresses ; } @ Column ( name = ""USER_DN"" ) public String getUserDn ( ) { return userDn ; } public void setUserDn ( String userDn ) { this . userDn = userDn ; } @ Column ( name = ""GENERATE_CERT"" ) public boolean getGenerateCert ( ) { return generateCert ; } public void setGenerateCert ( boolean generateCert ) { this . generateCert = generateCert ; } @ Column ( name = ""EXPERIMENT_DATA_DIR"" ) public String getExperimentDataDir ( ) { return experimentDataDir ; } public void setExperimentDataDir ( String experimentDataDir ) { this . experimentDataDir = experimentDataDir ; } @ ManyToOne @ JoinColumn ( name = ""EXPERIMENT_ID"" , referencedColumnName = ""EXPERIMENT_ID"" ) public Experiment getExperiment ( ) { return experiment ; } public void setExperiment ( Experiment experimentByExperimentId ) { this . experiment = experimentByExperimentId ; } @ OneToMany ( mappedBy = ""process"" ) public Collection < ProcessError > getProcessErrors ( ) { return processErrors ; } public void setProcessErrors ( Collection < ProcessError > processErrorsByProcessId ) { this . processErrors = processErrorsByProcessId ; } @ OneToMany ( mappedBy = ""process"" ) public Collection < ProcessInput > getProcessInputs ( ) { return processInputs ; } public void setProcessInputs ( Collection < ProcessInput > processInputsByProcessId ) { this . processInputs = processInputsByProcessId ; } @ OneToMany ( mappedBy = ""process"" ) public Collection < ProcessOutput > getProcessOutputs ( ) { return processOutputs ; } public void setProcessOutputs ( Collection < ProcessOutput > processOutputsByProcessId ) { this . processOutputs = processOutputsByProcessId ; } @ OneToOne ( mappedBy = ""process"" ) public ProcessResourceSchedule getProcessResourceSchedule ( ) { return processResourceSchedule ; } public void setProcessResourceSchedule ( ProcessResourceSchedule processResourceSchedulesByProcessId ) { this . processResourceSchedule = processResourceSchedulesByProcessId ; } @ OneToMany ( mappedBy = ""process"" ) public Collection < ProcessStatus > getProcessStatuses ( ) { return processStatuses ; } public void setProcessStatuses ( Collection < ProcessStatus > processStatusesByProcessId ) { this . processStatuses = processStatusesByProcessId ; } @ OneToMany ( mappedBy = ""process"" ) public Collection < Task > getTasks ( ) { return tasks ; } public void setTasks ( Collection < Task > taskByProcessId ) { this . tasks = taskByProcessId ; } }",Smelly
"public class TestAMInfos { @ Test public void testAMInfosWithoutRecoveryEnabled ( ) throws Exception { int runCount = 0 ; MRApp app = new MRAppWithHistory ( 1 , 0 , false , this . getClass ( ) . getName ( ) , true , ++ runCount ) ; Configuration conf = new Configuration ( ) ; conf . setBoolean ( MRJobConfig . JOB_UBERTASK_ENABLE , false ) ; Job job = app . submit ( conf ) ; app . waitForState ( job , JobState . RUNNING ) ; long am1StartTime = app . getAllAMInfos ( ) . get ( 0 ) . getStartTime ( ) ; Assert . assertEquals ( ""No of tasks not correct"" , 1 , job . getTasks ( ) . size ( ) ) ; Iterator < Task > it = job . getTasks ( ) . values ( ) . iterator ( ) ; Task mapTask = it . next ( ) ; app . waitForState ( mapTask , TaskState . RUNNING ) ; TaskAttempt taskAttempt = mapTask . getAttempts ( ) . values ( ) . iterator ( ) . next ( ) ; app . waitForState ( taskAttempt , TaskAttemptState . RUNNING ) ; app . stop ( ) ; app = new MRAppWithHistory ( 1 , 0 , false , this . getClass ( ) . getName ( ) , false , ++ runCount ) ; conf = new Configuration ( ) ; conf . setBoolean ( MRJobConfig . MR_AM_JOB_RECOVERY_ENABLE , false ) ; conf . setBoolean ( MRJobConfig . JOB_UBERTASK_ENABLE , false ) ; job = app . submit ( conf ) ; app . waitForState ( job , JobState . RUNNING ) ; Assert . assertEquals ( ""No of tasks not correct"" , 1 , job . getTasks ( ) . size ( ) ) ; it = job . getTasks ( ) . values ( ) . iterator ( ) ; mapTask = it . next ( ) ; List < AMInfo > amInfos = app . getAllAMInfos ( ) ; Assert . assertEquals ( 2 , amInfos . size ( ) ) ; AMInfo amInfoOne = amInfos . get ( 0 ) ; Assert . assertEquals ( am1StartTime , amInfoOne . getStartTime ( ) ) ; app . stop ( ) ; } }",No
"public class TableMeta implements Serializable { private static final long serialVersionUID = 1L ; protected String TABLE_CAT ; protected String TABLE_SCHEM ; protected String TABLE_NAME ; protected String TABLE_TYPE ; protected String REMARKS ; protected String TYPE_CAT ; protected String TYPE_SCHEM ; protected String TYPE_NAME ; protected String SELF_REFERENCING_COL_NAME ; protected String REF_GENERATION ; private List < ColumnMeta > columns = new ArrayList < ColumnMeta > ( ) ; public TableMeta ( ) { } public TableMeta ( String tABLE_CAT , String tABLE_SCHEM , String tABLE_NAME , String tABLE_TYPE , String rEMARKS , String tYPE_CAT , String tYPE_SCHEM , String tYPE_NAME , String sELF_REFERENCING_COL_NAME , String rEF_GENERATION ) { super ( ) ; TABLE_CAT = tABLE_CAT ; TABLE_SCHEM = tABLE_SCHEM ; TABLE_NAME = tABLE_NAME ; TABLE_TYPE = tABLE_TYPE ; REMARKS = rEMARKS ; TYPE_CAT = tYPE_CAT ; TYPE_SCHEM = tYPE_SCHEM ; TYPE_NAME = tYPE_NAME ; SELF_REFERENCING_COL_NAME = sELF_REFERENCING_COL_NAME ; REF_GENERATION = rEF_GENERATION ; } public String getTABLE_CAT ( ) { return TABLE_CAT ; } public void setTABLE_CAT ( String tABLE_CAT ) { TABLE_CAT = tABLE_CAT ; } public String getTABLE_SCHEM ( ) { return TABLE_SCHEM ; } public void setTABLE_SCHEM ( String tABLE_SCHEM ) { TABLE_SCHEM = tABLE_SCHEM ; } public String getTABLE_NAME ( ) { return TABLE_NAME ; } public void setTABLE_NAME ( String tABLE_NAME ) { TABLE_NAME = tABLE_NAME ; } public String getTABLE_TYPE ( ) { return TABLE_TYPE ; } public void setTABLE_TYPE ( String tABLE_TYPE ) { TABLE_TYPE = tABLE_TYPE ; } public String getREMARKS ( ) { return REMARKS ; } public void setREMARKS ( String rEMARKS ) { REMARKS = rEMARKS ; } public String getTYPE_CAT ( ) { return TYPE_CAT ; } public void setTYPE_CAT ( String tYPE_CAT ) { TYPE_CAT = tYPE_CAT ; } public String getTYPE_SCHEM ( ) { return TYPE_SCHEM ; } public void setTYPE_SCHEM ( String tYPE_SCHEM ) { TYPE_SCHEM = tYPE_SCHEM ; } public String getTYPE_NAME ( ) { return TYPE_NAME ; } public void setTYPE_NAME ( String tYPE_NAME ) { TYPE_NAME = tYPE_NAME ; } public String getSELF_REFERENCING_COL_NAME ( ) { return SELF_REFERENCING_COL_NAME ; } public void setSELF_REFERENCING_COL_NAME ( String sELF_REFERENCING_COL_NAME ) { SELF_REFERENCING_COL_NAME = sELF_REFERENCING_COL_NAME ; } public String getREF_GENERATION ( ) { return REF_GENERATION ; } public void setREF_GENERATION ( String rEF_GENERATION ) { REF_GENERATION = rEF_GENERATION ; } public List < ColumnMeta > getColumns ( ) { return columns ; } public void setColumns ( List < ColumnMeta > columns ) { this . columns = columns ; } public void addColumn ( ColumnMeta column ) { this . columns . add ( column ) ; } }",Smelly
 private static class TxnInfoTupleSchemeFactory implements SchemeFactory { public TxnInfoTupleScheme getScheme ( ) { return new TxnInfoTupleScheme ( ) ; } ,No
" private static class RDF_QuadTupleScheme extends TupleScheme < RDF_Quad > { @ Override public void write ( org . apache . thrift . protocol . TProtocol prot , RDF_Quad struct ) throws org . apache . thrift . TException { TTupleProtocol oprot = ( TTupleProtocol ) prot ; struct . S . write ( oprot ) ; struct . P . write ( oprot ) ; struct . O . write ( oprot ) ; BitSet optionals = new BitSet ( ) ; if ( struct . isSetG ( ) ) { optionals . set ( 0 ) ; } oprot . writeBitSet ( optionals , 1 ) ; if ( struct . isSetG ( ) ) { struct . G . write ( oprot ) ; } } @ Override public void read ( org . apache . thrift . protocol . TProtocol prot , RDF_Quad struct ) throws org . apache . thrift . TException { TTupleProtocol iprot = ( TTupleProtocol ) prot ; struct . S = new RDF_Term ( ) ; struct . S . read ( iprot ) ; struct . setSIsSet ( true ) ; struct . P = new RDF_Term ( ) ; struct . P . read ( iprot ) ; struct . setPIsSet ( true ) ; struct . O = new RDF_Term ( ) ; struct . O . read ( iprot ) ; struct . setOIsSet ( true ) ; BitSet incoming = iprot . readBitSet ( 1 ) ; if ( incoming . get ( 0 ) ) { struct . G = new RDF_Term ( ) ; struct . G . read ( iprot ) ; struct . setGIsSet ( true ) ; } } } ",No
"@ Deprecated public class ClientConfiguration implements Serializable { private static final long serialVersionUID = 1L ; private final ClientConfigurationData confData = new ClientConfigurationData ( ) ; public Authentication getAuthentication ( ) { return confData . getAuthentication ( ) ; } public void setAuthentication ( Authentication authentication ) { confData . setAuthentication ( authentication ) ; } public void setAuthentication ( String authPluginClassName , String authParamsString ) throws UnsupportedAuthenticationException { confData . setAuthentication ( AuthenticationFactory . create ( authPluginClassName , authParamsString ) ) ; } public void setAuthentication ( String authPluginClassName , Map < String , String > authParams ) throws UnsupportedAuthenticationException { confData . setAuthentication ( AuthenticationFactory . create ( authPluginClassName , authParams ) ) ; } public long getOperationTimeoutMs ( ) { return confData . getOperationTimeoutMs ( ) ; } public void setOperationTimeout ( int operationTimeout , TimeUnit unit ) { checkArgument ( operationTimeout >= 0 ) ; confData . setOperationTimeoutMs ( unit . toMillis ( operationTimeout ) ) ; } public int getIoThreads ( ) { return confData . getNumIoThreads ( ) ; } public void setIoThreads ( int numIoThreads ) { checkArgument ( numIoThreads > 0 ) ; confData . setNumIoThreads ( numIoThreads ) ; } public int getListenerThreads ( ) { return confData . getNumListenerThreads ( ) ; } public void setListenerThreads ( int numListenerThreads ) { checkArgument ( numListenerThreads > 0 ) ; confData . setNumListenerThreads ( numListenerThreads ) ; } public int getConnectionsPerBroker ( ) { return confData . getConnectionsPerBroker ( ) ; } public void setConnectionsPerBroker ( int connectionsPerBroker ) { checkArgument ( connectionsPerBroker > 0 , ""Connections per broker need to be greater than 0"" ) ; confData . setConnectionsPerBroker ( connectionsPerBroker ) ; } public boolean isUseTcpNoDelay ( ) { return confData . isUseTcpNoDelay ( ) ; } public void setUseTcpNoDelay ( boolean useTcpNoDelay ) { confData . setUseTcpNoDelay ( useTcpNoDelay ) ; } public boolean isUseTls ( ) { return confData . isUseTls ( ) ; } public void setUseTls ( boolean useTls ) { confData . setUseTls ( useTls ) ; } public String getTlsTrustCertsFilePath ( ) { return confData . getTlsTrustCertsFilePath ( ) ; } public void setTlsTrustCertsFilePath ( String tlsTrustCertsFilePath ) { confData . setTlsTrustCertsFilePath ( tlsTrustCertsFilePath ) ; } public boolean isTlsAllowInsecureConnection ( ) { return confData . isTlsAllowInsecureConnection ( ) ; } public void setTlsAllowInsecureConnection ( boolean tlsAllowInsecureConnection ) { confData . setTlsAllowInsecureConnection ( tlsAllowInsecureConnection ) ; } public long getStatsIntervalSeconds ( ) { return confData . getStatsIntervalSeconds ( ) ; } public void setStatsInterval ( long statsInterval , TimeUnit unit ) { confData . setStatsIntervalSeconds ( unit . toSeconds ( statsInterval ) ) ; } public int getConcurrentLookupRequest ( ) { return confData . getConcurrentLookupRequest ( ) ; } public void setConcurrentLookupRequest ( int concurrentLookupRequest ) { confData . setConcurrentLookupRequest ( concurrentLookupRequest ) ; } public int getMaxNumberOfRejectedRequestPerConnection ( ) { return confData . getMaxNumberOfRejectedRequestPerConnection ( ) ; } public void setMaxNumberOfRejectedRequestPerConnection ( int maxNumberOfRejectedRequestPerConnection ) { confData . setMaxNumberOfRejectedRequestPerConnection ( maxNumberOfRejectedRequestPerConnection ) ; } public boolean isTlsHostnameVerificationEnable ( ) { return confData . isTlsHostnameVerificationEnable ( ) ; } public void setTlsHostnameVerificationEnable ( boolean tlsHostnameVerificationEnable ) { confData . setTlsHostnameVerificationEnable ( tlsHostnameVerificationEnable ) ; } public ClientConfiguration setServiceUrl ( String serviceUrl ) { confData . setServiceUrl ( serviceUrl ) ; return this ; } public void setConnectionTimeout ( int duration , TimeUnit unit ) { confData . setConnectionTimeoutMs ( ( int ) unit . toMillis ( duration ) ) ; } public long getConnectionTimeoutMs ( ) { return confData . getConnectionTimeoutMs ( ) ; } public ClientConfigurationData getConfigurationData ( ) { return confData ; } }",Smelly
"public class SecureConversationTokenBuilder implements AssertionBuilder < Element > { PolicyBuilder builder ; public SecureConversationTokenBuilder ( PolicyBuilder b ) { builder = b ; } public QName [ ] getKnownElements ( ) { return new QName [ ] { SP11Constants . SECURE_CONVERSATION_TOKEN , SP12Constants . SECURE_CONVERSATION_TOKEN } ; } public Assertion build ( Element element , AssertionBuilderFactory factory ) throws IllegalArgumentException { SPConstants consts = SP11Constants . SP_NS . equals ( element . getNamespaceURI ( ) ) ? SP11Constants . INSTANCE : SP12Constants . INSTANCE ; SecureConversationToken conversationToken = new SecureConversationToken ( consts ) ; conversationToken . setOptional ( PolicyConstants . isOptional ( element ) ) ; conversationToken . setIgnorable ( PolicyConstants . isIgnorable ( element ) ) ; String attribute = DOMUtils . getAttribute ( element , consts . getIncludeToken ( ) ) ; if ( attribute != null ) { conversationToken . setInclusion ( consts . getInclusionFromAttributeValue ( attribute . trim ( ) ) ) ; } Element elem = DOMUtils . getFirstElement ( element ) ; boolean foundPolicy = false ; while ( elem != null ) { QName qn = DOMUtils . getElementQName ( elem ) ; if ( Constants . isPolicyElement ( qn ) ) { foundPolicy = true ; if ( DOMUtils . getFirstChildWithName ( elem , consts . getNamespace ( ) , SPConstants . REQUIRE_DERIVED_KEYS ) != null ) { conversationToken . setDerivedKeys ( true ) ; } else if ( DOMUtils . getFirstChildWithName ( elem , SP12Constants . REQUIRE_IMPLIED_DERIVED_KEYS ) != null ) { conversationToken . setImpliedDerivedKeys ( true ) ; } else if ( DOMUtils . getFirstChildWithName ( elem , SP12Constants . REQUIRE_EXPLICIT_DERIVED_KEYS ) != null ) { conversationToken . setExplicitDerivedKeys ( true ) ; } if ( DOMUtils . getFirstChildWithName ( elem , consts . getNamespace ( ) , SPConstants . REQUIRE_EXTERNAL_URI_REFERENCE ) != null ) { conversationToken . setRequireExternalUriRef ( true ) ; } if ( DOMUtils . getFirstChildWithName ( elem , consts . getNamespace ( ) , SPConstants . SC10_SECURITY_CONTEXT_TOKEN ) != null ) { conversationToken . setSc10SecurityContextToken ( true ) ; } if ( DOMUtils . getFirstChildWithName ( elem , consts . getNamespace ( ) , SPConstants . SC13_SECURITY_CONTEXT_TOKEN ) != null ) { conversationToken . setSc13SecurityContextToken ( true ) ; } Element bootstrapPolicyElement = DOMUtils . getFirstChildWithName ( elem , consts . getNamespace ( ) , SPConstants . BOOTSTRAP_POLICY ) ; if ( bootstrapPolicyElement != null ) { Policy policy = builder . getPolicy ( DOMUtils . getFirstElement ( bootstrapPolicyElement ) ) ; conversationToken . setBootstrapPolicy ( policy ) ; } } else if ( consts . getNamespace ( ) . equals ( qn . getNamespaceURI ( ) ) && SPConstants . ISSUER . equals ( qn . getLocalPart ( ) ) ) { conversationToken . setIssuerEpr ( DOMUtils . getFirstElement ( elem ) ) ; } elem = DOMUtils . getNextElement ( elem ) ; } if ( ! foundPolicy && consts != SP11Constants . INSTANCE ) { throw new IllegalArgumentException ( ""sp:SecureConversationToken/wsp:Policy must have a value"" ) ; } return conversationToken ; } }",No
" public static class KeyValueDecoder extends BaseDecoder { public KeyValueDecoder ( final InputStream in ) { super ( in ) ; } @ Override protected Cell parseCell ( ) throws IOException { return KeyValueUtil . createKeyValueFromInputStream ( in , false ) ; } ",No
"public class XBayaConfiguration extends Observable implements Observer { private static final Logger logger = LoggerFactory . getLogger ( XBayaConfiguration . class ) ; private String title = XBayaConstants . APPLICATION_NAME ; private String workflow = null ; private String ogceWorkflow = null ; private List < String > localRegistris = new ArrayList < String > ( ) ; private URI gpelEngineURL = XBayaConstants . DEFAULT_GPEL_ENGINE_URL ; private URI gpelTemplateID = null ; private URI gpelInstanceID = null ; private String odeURL = XBayaConstants . DEFAULT_ODE_URL ; private URI workflowInterpreterURL = XBayaConstants . DEFAULT_WORKFLOW_INTERPRETER_URL ; private URI proxyURI = XBayaConstants . DEFAULT_PROXY_URI ; private URI dscURL = XBayaConstants . DEFAULT_DSC_URL ; private boolean startMonitor = false ; private URI brokerURL = XBayaConstants . DEFAULT_BROKER_URL ; private String topic = null ; private boolean pullMode = true ; private URI messageBoxURL = XBayaConstants . DEFAULT_MESSAGE_BOX_URL ; private URI karmaURL = null ; private URI karmaWorkflowInstanceID = null ; private String myProxyServer = XBayaConstants . DEFAULT_MYPROXY_SERVER ; private int myProxyPort = XBayaConstants . DEFAULT_MYPROXY_PORT ; private int myProxyLifetime = XBayaConstants . DEFAULT_MYPROXY_LIFTTIME ; private String myProxyUsername = null ; private String myProxyPassphrase = null ; private boolean loadMyProxy = false ; private boolean loadRunJythonWorkflow = false ; private int width ; private int height ; private int x = 50 ; private int y = 50 ; private List < Throwable > errors ; private boolean closeOnExit = true ; private boolean collectProvenance = false ; private boolean provenanceSmartRun = false ; private boolean runWithCrossProduct = true ; private String trustedCertLocation = """" ; private JCRComponentRegistry jcrComponentRegistry = null ; private XBayaExecutionMode xbayaExecutionMode = XBayaExecutionMode . IDE ; private List < XBayaExecutionModeListener > xbayaExecutionModeChangeListners = new ArrayList < XBayaExecutionModeListener > ( ) ; private boolean regURLSetByCMD = false ; private Map < ThriftServiceType , ThriftClientData > thriftClientDataList = new HashMap < ThriftServiceType , ThriftClientData > ( ) ; public enum XBayaExecutionMode { IDE , MONITOR } public XBayaConfiguration ( ) { this . errors = new ArrayList < Throwable > ( ) ; String systemConfig = System . getProperty ( ""xbaya.config"" ) ; try { if ( systemConfig != null ) { loadConfiguration ( systemConfig ) ; } } catch ( RuntimeException e ) { String message = ""Error while reading a configuration file, "" + systemConfig ; logger . warn ( message , e ) ; } } public void loadConfiguration ( String configFilePath ) { File configFile = new File ( configFilePath ) ; URI uri = configFile . toURI ( ) ; loadConfiguration ( uri ) ; } private void loadConfiguration ( URI uri ) { LeadDeploymentConfig config = LeadDeploymentConfig . loadConfig ( null , uri ) ; URI gpel = config . getGpelUrl ( ) ; if ( gpel != null ) { this . gpelEngineURL = config . getGpelUrl ( ) ; } URI dsc = config . getDscUrl ( ) ; if ( dsc != null ) { this . dscURL = dsc ; } URI broker = config . getBrokerUrl ( ) ; if ( broker != null ) { this . brokerURL = broker ; } URI msgBox = config . getMsgBoxUrl ( ) ; if ( msgBox != null ) { this . messageBoxURL = msgBox ; } } public String getTitle ( ) { return this . title ; } public void setTitle ( String title ) { this . title = title ; } public String getWorkflow ( ) { return this . workflow ; } public void setWorkflow ( String defaultWorkflow ) { this . workflow = defaultWorkflow ; } public void setOGCEWorkflow ( String ogceWorkflow ) { this . ogceWorkflow = ogceWorkflow ; } public String getOGCEWorkflow ( ) { return this . ogceWorkflow ; } public void enableLocalRegistry ( ) { addLocalRegistry ( XBayaPathConstants . WSDL_DIRECTORY ) ; } public void addLocalRegistry ( String path ) { this . localRegistris . add ( path ) ; } public List < String > getLocalRegistry ( ) { return this . localRegistris ; } public URI getGPELEngineURL ( ) { return this . gpelEngineURL ; } public void setGPELEngineURL ( URI gpelEngineURL ) { this . gpelEngineURL = gpelEngineURL ; } public void setGPELTemplateID ( URI templateID ) { this . gpelTemplateID = templateID ; } public URI getGPELTemplateID ( ) { return this . gpelTemplateID ; } public URI getGPELInstanceID ( ) { return this . gpelInstanceID ; } public void setGPELInstanceID ( URI gpelInstanceID ) { this . gpelInstanceID = gpelInstanceID ; } public URI getDSCURL ( ) { return this . dscURL ; } public void setDSCURL ( URI dscURL ) { this . dscURL = dscURL ; } public String getTopic ( ) { return this . topic ; } public void setTopic ( String topic ) { this . topic = topic ; } public URI getMessageBoxURL ( ) { return this . messageBoxURL ; } public void setMessageBoxURL ( URI messageBoxURL ) { this . messageBoxURL = messageBoxURL ; } public boolean isPullMode ( ) { return this . pullMode ; } public void setPullMode ( boolean pullMode ) { this . pullMode = pullMode ; } public URI getBrokerURL ( ) { return this . brokerURL ; } public void setBrokerURL ( URI brokerURL ) { this . brokerURL = brokerURL ; } public boolean isStartMonitor ( ) { return this . startMonitor ; } public void setStartMonitor ( boolean startMonitor ) { this . startMonitor = startMonitor ; } public URI getKarmaURL ( ) { return this . karmaURL ; } public void setKarmaURL ( URI kermaURI ) { this . karmaURL = kermaURI ; } public URI getKarmaWorkflowInstanceID ( ) { return this . karmaWorkflowInstanceID ; } public void setKarmaWorkflowInstanceID ( URI karmaWorkflowInstanceID ) { this . karmaWorkflowInstanceID = karmaWorkflowInstanceID ; } public String getMyProxyServer ( ) { return this . myProxyServer ; } public void setMyProxyServer ( String myProxyServer ) { this . myProxyServer = myProxyServer ; } public int getMyProxyPort ( ) { return this . myProxyPort ; } public void setMyProxyPort ( int myProxyPort ) { this . myProxyPort = myProxyPort ; } public int getMyProxyLifetime ( ) { return this . myProxyLifetime ; } public void setMyProxyLifetime ( int myProxyLifetime ) { this . myProxyLifetime = myProxyLifetime ; } public String getMyProxyUsername ( ) { return this . myProxyUsername ; } public void setMyProxyUsername ( String myProxyUsername ) { this . myProxyUsername = myProxyUsername ; } public String getOdeURL ( ) { return this . odeURL ; } public void setOdeURL ( String odeURL ) { this . odeURL = odeURL ; } public URI getWorkflowInterpreterURL ( ) { return this . workflowInterpreterURL ; } public void setWorkflowInterpreterURL ( URI workflowInterpreterURL ) { this . workflowInterpreterURL = workflowInterpreterURL ; } public void setProxyURI ( URI proxyURI ) { this . proxyURI = proxyURI ; } public String getMyProxyPassphrase ( ) { return this . myProxyPassphrase ; } public void setMyProxyPassphrase ( String myProxyPassphrase ) { this . myProxyPassphrase = myProxyPassphrase ; } public boolean isLoadMyProxy ( ) { return this . loadMyProxy ; } public void setLoadMyProxy ( boolean loadMyProxy ) { this . loadMyProxy = loadMyProxy ; } public boolean isLoadRunJythonWorkflow ( ) { return this . loadRunJythonWorkflow ; } public void setLoadRunJythonWorkflow ( boolean loadRunJythonWorkflow ) { this . loadRunJythonWorkflow = loadRunJythonWorkflow ; } public int getHeight ( ) { return this . height ; } public void setHeight ( int height ) { this . height = height ; } public int getWidth ( ) { return this . width ; } public void setWidth ( int width ) { this . width = width ; } public void addError ( Throwable e ) { this . errors . add ( e ) ; } public Iterable < Throwable > getErrors ( ) { return this . errors ; } public String getODEURL ( ) { return this . odeURL ; } public URI getProxyURI ( ) { return this . proxyURI ; } public void setCloseOnExit ( boolean b ) { this . closeOnExit = b ; } public boolean isCloseOnExit ( ) { return this . closeOnExit ; } public void servicesChanged ( ThriftServiceType type ) { if ( type == ThriftServiceType . API_SERVICE ) { try { Client airavataClient = XBayaUtil . getAiravataClient ( getThriftClientData ( ThriftServiceType . API_SERVICE ) ) ; if ( getJcrComponentRegistry ( ) == null ) { setJcrComponentRegistry ( new JCRComponentRegistry ( getThriftClientData ( ThriftServiceType . API_SERVICE ) . getGatewayId ( ) , airavataClient ) ) ; } else { getJcrComponentRegistry ( ) . setClient ( airavataClient ) ; } triggerObservers ( getJcrComponentRegistry ( ) ) ; } catch ( AiravataClientConnectException e ) { logger . error ( e . getMessage ( ) , e ) ; } } } protected void triggerObservers ( Object o ) { setChanged ( ) ; notifyObservers ( o ) ; } public void update ( Observable observable , Object o ) { triggerObservers ( observable ) ; } public boolean isCollectProvenance ( ) { return collectProvenance ; } public boolean isProvenanceSmartRun ( ) { return provenanceSmartRun ; } public void setCollectProvenance ( boolean collectProvenance ) { this . collectProvenance = collectProvenance ; } public void setProvenanceSmartRun ( boolean provenanceSmartRun ) { this . provenanceSmartRun = provenanceSmartRun ; } public void setRunWithCrossProduct ( boolean runWithCrossProduct ) { this . runWithCrossProduct = runWithCrossProduct ; } public boolean isRunWithCrossProduct ( ) { return runWithCrossProduct ; } public String getTrustedCertLocation ( ) { return trustedCertLocation ; } public void setTrustedCertLocation ( String trustedCertLocation ) { this . trustedCertLocation = trustedCertLocation ; } public XBayaExecutionMode getXbayaExecutionMode ( ) { return xbayaExecutionMode ; } public void setXbayaExecutionMode ( XBayaExecutionMode xbayaExecutionMode ) { boolean modeChanged = ( this . xbayaExecutionMode != xbayaExecutionMode ) ; this . xbayaExecutionMode = xbayaExecutionMode ; if ( modeChanged ) { for ( XBayaExecutionModeListener listner : xbayaExecutionModeChangeListners ) { try { listner . executionModeChanged ( this ) ; } catch ( Exception e ) { logger . error ( e . getMessage ( ) , e ) ; } } } } public void registerExecutionModeChangeListener ( XBayaExecutionModeListener listner ) { xbayaExecutionModeChangeListners . add ( listner ) ; } public void unregisterExecutionModeChangeListener ( XBayaExecutionModeListener listner ) { if ( xbayaExecutionModeChangeListners . contains ( listner ) ) { xbayaExecutionModeChangeListners . remove ( listner ) ; } } public int getX ( ) { return x ; } public void setX ( int x ) { this . x = x ; } public int getY ( ) { return y ; } public void setY ( int y ) { this . y = y ; } public JCRComponentRegistry getJcrComponentRegistry ( ) { return jcrComponentRegistry ; } public void setJcrComponentRegistry ( JCRComponentRegistry jcrComponentRegistry ) { this . jcrComponentRegistry = jcrComponentRegistry ; } public boolean isRegURLSetByCMD ( ) { return regURLSetByCMD ; } public void setRegURLSetByCMD ( boolean regURLSetByCMD ) { this . regURLSetByCMD = regURLSetByCMD ; } public Map < ThriftServiceType , ThriftClientData > getThriftClientDataList ( ) { return thriftClientDataList ; } public void addThriftClientData ( ThriftClientData data ) { getThriftClientDataList ( ) . put ( data . getServiceType ( ) , data ) ; servicesChanged ( data . getServiceType ( ) ) ; } public ThriftClientData getThriftClientData ( ThriftServiceType serviceType ) { return ( isThriftServiceDataExist ( serviceType ) ? getThriftClientDataList ( ) . get ( serviceType ) : null ) ; } public boolean isThriftServiceDataExist ( ThriftServiceType serviceType ) { return getThriftClientDataList ( ) . containsKey ( serviceType ) ; } }",Smelly
" private static class AttributeImpl implements Attribute { private final Lattice . Column column ; private final TableImpl table ; private AttributeImpl ( Lattice . Column column , TableImpl table ) { this . column = column ; this . table = table ; } @ Override public String toString ( ) { return getLabel ( ) ; } public String getLabel ( ) { return column . alias ; } public Table getTable ( ) { return table ; } public double estimateSpace ( ) { return 0 ; } public String getCandidateColumnName ( ) { return null ; } public String getDatatype ( Dialect dialect ) { return null ; } public List < Attribute > getAncestorAttributes ( ) { return ImmutableList . of ( ) ; } ",Smelly
"public class ActiveMQInitialContextFactory implements InitialContextFactory { private static final String [ ] DEFAULT_CONNECTION_FACTORY_NAMES = { ""ConnectionFactory"" , ""XAConnectionFactory"" , ""QueueConnectionFactory"" , ""TopicConnectionFactory"" } ; private String connectionPrefix = ""connection."" ; private String queuePrefix = ""queue."" ; private String topicPrefix = ""topic."" ; public Context getInitialContext ( Hashtable environment ) throws NamingException { Map < String , Object > data = new ConcurrentHashMap < String , Object > ( ) ; String [ ] names = getConnectionFactoryNames ( environment ) ; for ( int i = 0 ; i < names . length ; i ++ ) { ActiveMQConnectionFactory factory = null ; String name = names [ i ] ; try { factory = createConnectionFactory ( name , environment ) ; } catch ( Exception e ) { throw new NamingException ( ""Invalid broker URL"" ) ; } data . put ( name , factory ) ; } createQueues ( data , environment ) ; createTopics ( data , environment ) ; data . put ( ""dynamicQueues"" , new LazyCreateContext ( ) { private static final long serialVersionUID = 6503881346214855588L ; protected Object createEntry ( String name ) { return new ActiveMQQueue ( name ) ; } } ) ; data . put ( ""dynamicTopics"" , new LazyCreateContext ( ) { private static final long serialVersionUID = 2019166796234979615L ; protected Object createEntry ( String name ) { return new ActiveMQTopic ( name ) ; } } ) ; return createContext ( environment , data ) ; } public String getTopicPrefix ( ) { return topicPrefix ; } public void setTopicPrefix ( String topicPrefix ) { this . topicPrefix = topicPrefix ; } public String getQueuePrefix ( ) { return queuePrefix ; } public void setQueuePrefix ( String queuePrefix ) { this . queuePrefix = queuePrefix ; } protected ReadOnlyContext createContext ( Hashtable environment , Map < String , Object > data ) { return new ReadOnlyContext ( environment , data ) ; } protected ActiveMQConnectionFactory createConnectionFactory ( String name , Hashtable environment ) throws URISyntaxException { Hashtable temp = new Hashtable ( environment ) ; if ( DEFAULT_CONNECTION_FACTORY_NAMES [ 1 ] . equals ( name ) ) { temp . put ( ""xa"" , String . valueOf ( true ) ) ; } String prefix = connectionPrefix + name + ""."" ; for ( Iterator iter = environment . entrySet ( ) . iterator ( ) ; iter . hasNext ( ) ; ) { Map . Entry entry = ( Map . Entry ) iter . next ( ) ; String key = ( String ) entry . getKey ( ) ; if ( key . startsWith ( prefix ) ) { temp . remove ( key ) ; key = key . substring ( prefix . length ( ) ) ; temp . put ( key , entry . getValue ( ) ) ; } } return createConnectionFactory ( temp ) ; } protected String [ ] getConnectionFactoryNames ( Map environment ) { String factoryNames = ( String ) environment . get ( ""connectionFactoryNames"" ) ; if ( factoryNames != null ) { List < String > list = new ArrayList < String > ( ) ; for ( StringTokenizer enumeration = new StringTokenizer ( factoryNames , "","" ) ; enumeration . hasMoreTokens ( ) ; ) { list . add ( enumeration . nextToken ( ) . trim ( ) ) ; } int size = list . size ( ) ; if ( size > 0 ) { String [ ] answer = new String [ size ] ; list . toArray ( answer ) ; return answer ; } } return DEFAULT_CONNECTION_FACTORY_NAMES ; } protected void createQueues ( Map < String , Object > data , Hashtable environment ) { for ( Iterator iter = environment . entrySet ( ) . iterator ( ) ; iter . hasNext ( ) ; ) { Map . Entry entry = ( Map . Entry ) iter . next ( ) ; String key = entry . getKey ( ) . toString ( ) ; if ( key . startsWith ( queuePrefix ) ) { String jndiName = key . substring ( queuePrefix . length ( ) ) ; data . put ( jndiName , createQueue ( entry . getValue ( ) . toString ( ) ) ) ; } } } protected void createTopics ( Map < String , Object > data , Hashtable environment ) { for ( Iterator iter = environment . entrySet ( ) . iterator ( ) ; iter . hasNext ( ) ; ) { Map . Entry entry = ( Map . Entry ) iter . next ( ) ; String key = entry . getKey ( ) . toString ( ) ; if ( key . startsWith ( topicPrefix ) ) { String jndiName = key . substring ( topicPrefix . length ( ) ) ; data . put ( jndiName , createTopic ( entry . getValue ( ) . toString ( ) ) ) ; } } } protected Queue createQueue ( String name ) { return new ActiveMQQueue ( name ) ; } protected Topic createTopic ( String name ) { return new ActiveMQTopic ( name ) ; } protected ActiveMQConnectionFactory createConnectionFactory ( Hashtable environment ) throws URISyntaxException { ActiveMQConnectionFactory answer = needsXA ( environment ) ? new ActiveMQXAConnectionFactory ( ) : new ActiveMQConnectionFactory ( ) ; Properties properties = new Properties ( ) ; properties . putAll ( environment ) ; answer . setProperties ( properties ) ; return answer ; } private boolean needsXA ( Hashtable environment ) { boolean isXA = Boolean . parseBoolean ( ( String ) environment . get ( ""xa"" ) ) ; environment . remove ( ""xa"" ) ; return isXA ; } public String getConnectionPrefix ( ) { return connectionPrefix ; } public void setConnectionPrefix ( String connectionPrefix ) { this . connectionPrefix = connectionPrefix ; } }",Smelly
"class NodeTypeTemplateImpl extends NamedTemplate implements NodeTypeTemplate { private static final PropertyDefinition [ ] EMPTY_PROPERTY_DEFINITION_ARRAY = new PropertyDefinition [ 0 ] ; private static final NodeDefinition [ ] EMPTY_NODE_DEFINITION_ARRAY = new NodeDefinition [ 0 ] ; protected boolean isMixin ; protected boolean isOrderable ; protected boolean isAbstract ; protected boolean queryable ; private String primaryItemOakName = null ; @ Nonnull private String [ ] superTypeOakNames = new String [ 0 ] ; private List < PropertyDefinitionTemplateImpl > propertyDefinitionTemplates = null ; private List < NodeDefinitionTemplateImpl > nodeDefinitionTemplates = null ; NodeTypeTemplateImpl ( NameMapper mapper ) { super ( mapper ) ; } NodeTypeTemplateImpl ( NameMapper mapper , NodeTypeDefinition definition ) throws ConstraintViolationException { super ( mapper , definition . getName ( ) ) ; setMixin ( definition . isMixin ( ) ) ; setOrderableChildNodes ( definition . hasOrderableChildNodes ( ) ) ; setAbstract ( definition . isAbstract ( ) ) ; setQueryable ( definition . isQueryable ( ) ) ; String primaryItemName = definition . getPrimaryItemName ( ) ; if ( primaryItemName != null ) { setPrimaryItemName ( primaryItemName ) ; } setDeclaredSuperTypeNames ( definition . getDeclaredSupertypeNames ( ) ) ; PropertyDefinition [ ] pds = definition . getDeclaredPropertyDefinitions ( ) ; if ( pds != null ) { propertyDefinitionTemplates = Lists . newArrayListWithCapacity ( pds . length ) ; for ( PropertyDefinition pd : pds ) { propertyDefinitionTemplates . add ( new PropertyDefinitionTemplateImpl ( mapper , pd ) ) ; } } NodeDefinition [ ] nds = definition . getDeclaredChildNodeDefinitions ( ) ; if ( nds != null ) { nodeDefinitionTemplates = Lists . newArrayListWithCapacity ( nds . length ) ; for ( NodeDefinition nd : nds ) { nodeDefinitionTemplates . add ( new NodeDefinitionTemplateImpl ( mapper , nd ) ) ; } } } Tree writeTo ( Tree parent , boolean allowUpdate ) throws RepositoryException { String oakName = getOakName ( ) ; Tree type = parent . getChild ( oakName ) ; if ( type . exists ( ) ) { if ( allowUpdate ) { type . remove ( ) ; } else { throw new NodeTypeExistsException ( ""Node type "" + getName ( ) + "" already exists"" ) ; } } type = parent . addChild ( oakName ) ; type . setProperty ( JCR_PRIMARYTYPE , NT_NODETYPE , Type . NAME ) ; type . setProperty ( JCR_NODETYPENAME , oakName , Type . NAME ) ; if ( superTypeOakNames . length > 0 ) { type . setProperty ( JCR_SUPERTYPES , Arrays . asList ( superTypeOakNames ) , Type . NAMES ) ; } type . setProperty ( JCR_IS_ABSTRACT , isAbstract ) ; type . setProperty ( JCR_IS_QUERYABLE , queryable ) ; type . setProperty ( JCR_ISMIXIN , isMixin ) ; type . setProperty ( JCR_HASORDERABLECHILDNODES , isOrderable ) ; if ( primaryItemOakName != null ) { type . setProperty ( JCR_PRIMARYITEMNAME , primaryItemOakName , Type . NAME ) ; } if ( propertyDefinitionTemplates != null ) { int pdn = 1 ; for ( PropertyDefinitionTemplateImpl pdt : propertyDefinitionTemplates ) { Tree tree = type . addChild ( JCR_PROPERTYDEFINITION + ""["" + pdn ++ + ""]"" ) ; tree . setProperty ( JCR_PRIMARYTYPE , NT_PROPERTYDEFINITION , Type . NAME ) ; pdt . writeTo ( tree ) ; } } if ( nodeDefinitionTemplates != null ) { int ndn = 1 ; for ( NodeDefinitionTemplateImpl ndt : nodeDefinitionTemplates ) { Tree tree = type . addChild ( JCR_CHILDNODEDEFINITION + ""["" + ndn ++ + ""]"" ) ; tree . setProperty ( JCR_PRIMARYTYPE , NT_CHILDNODEDEFINITION , Type . NAME ) ; ndt . writeTo ( tree ) ; } } return type ; } @ Override public boolean isMixin ( ) { return isMixin ; } @ Override public void setMixin ( boolean mixin ) { this . isMixin = mixin ; } @ Override public boolean hasOrderableChildNodes ( ) { return isOrderable ; } @ Override public void setOrderableChildNodes ( boolean orderable ) { this . isOrderable = orderable ; } @ Override public boolean isAbstract ( ) { return isAbstract ; } @ Override public void setAbstract ( boolean abstractStatus ) { this . isAbstract = abstractStatus ; } @ Override public boolean isQueryable ( ) { return queryable ; } @ Override public void setQueryable ( boolean queryable ) { this . queryable = queryable ; } @ Override public String getPrimaryItemName ( ) { return getJcrNameAllowNull ( primaryItemOakName ) ; } @ Override public void setPrimaryItemName ( String jcrName ) throws ConstraintViolationException { this . primaryItemOakName = getOakNameAllowNullOrThrowConstraintViolation ( jcrName ) ; } @ Override public String [ ] getDeclaredSupertypeNames ( ) { return getJcrNamesAllowNull ( superTypeOakNames ) ; } @ Override public void setDeclaredSuperTypeNames ( String [ ] jcrNames ) throws ConstraintViolationException { this . superTypeOakNames = getOakNamesOrThrowConstraintViolation ( jcrNames ) ; } @ Override public PropertyDefinition [ ] getDeclaredPropertyDefinitions ( ) { if ( propertyDefinitionTemplates != null ) { return propertyDefinitionTemplates . toArray ( EMPTY_PROPERTY_DEFINITION_ARRAY ) ; } else { return null ; } } @ Override public List < ? extends PropertyDefinitionTemplate > getPropertyDefinitionTemplates ( ) { if ( propertyDefinitionTemplates == null ) { propertyDefinitionTemplates = Lists . newArrayList ( ) ; } return propertyDefinitionTemplates ; } @ Override public NodeDefinition [ ] getDeclaredChildNodeDefinitions ( ) { if ( nodeDefinitionTemplates != null ) { return nodeDefinitionTemplates . toArray ( EMPTY_NODE_DEFINITION_ARRAY ) ; } else { return null ; } } @ Override public List < ? extends NodeDefinitionTemplate > getNodeDefinitionTemplates ( ) { if ( nodeDefinitionTemplates == null ) { nodeDefinitionTemplates = Lists . newArrayList ( ) ; } return nodeDefinitionTemplates ; } public String toString ( ) { return String . format ( ""NodeTypeTemplate(%s)"" , getOakName ( ) ) ; } }",Smelly
" static class QueryExecutor implements Callable < ResultObjectProvider > { StoreQuery query ; Executor executor ; Object [ ] params ; Range range ; public ResultObjectProvider call ( ) throws Exception { return executor . executeQuery ( query , params , range ) ; } ",No
"public class DeleteProjectNotifierAction extends ContinuumActionSupport { private int projectId ; private int projectGroupId ; private int notifierId ; private String notifierType ; private String recipient ; private boolean fromGroupPage = false ; private String projectGroupName = """" ; public String execute ( ) throws ContinuumException { try { checkRemoveProjectNotifierAuthorization ( getProjectGroupName ( ) ) ; } catch ( AuthorizationRequiredException authzE ) { addActionError ( authzE . getMessage ( ) ) ; return REQUIRES_AUTHORIZATION ; } getContinuum ( ) . removeNotifier ( projectId , notifierId ) ; if ( fromGroupPage ) { return ""to_group_page"" ; } return SUCCESS ; } public String doDefault ( ) throws ContinuumException { try { checkRemoveProjectNotifierAuthorization ( getProjectGroupName ( ) ) ; } catch ( AuthorizationRequiredException authzE ) { addActionError ( authzE . getMessage ( ) ) ; return REQUIRES_AUTHORIZATION ; } ProjectNotifier notifier = getContinuum ( ) . getNotifier ( projectId , notifierId ) ; notifierType = notifier . getType ( ) ; recipient = GenerateRecipentNotifier . generate ( notifier ) ; return ""delete"" ; } public void setProjectId ( int projectId ) { this . projectId = projectId ; } public int getProjectId ( ) { return projectId ; } public void setNotifierId ( int notifierId ) { this . notifierId = notifierId ; } public int getNotifierId ( ) { return notifierId ; } public void setNotifierType ( String notifierType ) { this . notifierType = notifierType ; } public String getNotifierType ( ) { return notifierType ; } public int getProjectGroupId ( ) { return projectGroupId ; } public void setProjectGroupId ( int projectGroupId ) { this . projectGroupId = projectGroupId ; } public String getRecipient ( ) { return recipient ; } public void setRecipient ( String recipient ) { this . recipient = recipient ; } public boolean isFromGroupPage ( ) { return fromGroupPage ; } public void setFromGroupPage ( boolean fromGroupPage ) { this . fromGroupPage = fromGroupPage ; } public String getProjectGroupName ( ) throws ContinuumException { if ( StringUtils . isEmpty ( projectGroupName ) ) { if ( projectGroupId != 0 ) { projectGroupName = getContinuum ( ) . getProjectGroup ( projectGroupId ) . getName ( ) ; } else { projectGroupName = getContinuum ( ) . getProjectGroupByProjectId ( projectId ) . getName ( ) ; } } return projectGroupName ; } }",Smelly
"class CompiledExpression implements EJBQLCompiledExpression { private String source ; private String rootId ; private Map < String , ClassDescriptor > descriptorsById ; private Map < String , ObjRelationship > incomingById ; private EJBQLExpression expression ; private SQLResult result ; private PrefetchTreeNode prefetchTree ; public ClassDescriptor getEntityDescriptor ( String idVariable ) { if ( idVariable == null ) { return null ; } return descriptorsById . get ( Compiler . normalizeIdPath ( idVariable ) ) ; } public SQLResult getResult ( ) { return result ; } public ClassDescriptor getRootDescriptor ( ) { return rootId != null ? getEntityDescriptor ( rootId ) : null ; } public List < DbRelationship > getIncomingRelationships ( String identifier ) { ObjRelationship relationship = incomingById . get ( identifier ) ; if ( relationship == null ) { return Collections . emptyList ( ) ; } return relationship . getDbRelationships ( ) ; } public EJBQLExpression getExpression ( ) { return expression ; } public String getSource ( ) { return source ; } void setExpression ( EJBQLExpression expression ) { this . expression = expression ; } void setDescriptorsById ( Map < String , ClassDescriptor > descriptorsById ) { this . descriptorsById = descriptorsById ; } void setIncomingById ( Map < String , ObjRelationship > incomingById ) { this . incomingById = incomingById ; } void setSource ( String source ) { this . source = source ; } void setRootId ( String rootId ) { this . rootId = rootId ; } void setResult ( SQLResult resultSetMapping ) { this . result = resultSetMapping ; } public PrefetchTreeNode getPrefetchTree ( ) { return prefetchTree ; } public void setPrefetchTree ( PrefetchTreeNode prefetchTree ) { this . prefetchTree = prefetchTree ; } }",Smelly
 private static abstract class EmptyCell implements ExtendedCell { @ Override public void setSequenceId ( long seqId ) { } @ Override public void setTimestamp ( long ts ) { } @ Override public void setTimestamp ( byte [ ] ts ) { } @ Override public byte [ ] getRowArray ( ) { return EMPTY_BYTE_ARRAY ; } @ Override public int getRowOffset ( ) { return 0 ; } @ Override public short getRowLength ( ) { return 0 ; } @ Override public byte [ ] getFamilyArray ( ) { return EMPTY_BYTE_ARRAY ; } @ Override public int getFamilyOffset ( ) { return 0 ; } @ Override public byte getFamilyLength ( ) { return 0 ; } @ Override public byte [ ] getQualifierArray ( ) { return EMPTY_BYTE_ARRAY ; } @ Override public int getQualifierOffset ( ) { return 0 ; } @ Override public int getQualifierLength ( ) { return 0 ; } @ Override public long getSequenceId ( ) { return 0 ; } @ Override public byte [ ] getValueArray ( ) { return EMPTY_BYTE_ARRAY ; } @ Override public int getValueOffset ( ) { return 0 ; } @ Override public int getValueLength ( ) { return 0 ; } @ Override public byte [ ] getTagsArray ( ) { return EMPTY_BYTE_ARRAY ; } @ Override public int getTagsOffset ( ) { return 0 ; } @ Override public int getTagsLength ( ) { return 0 ; } ,Smelly
 class EdgeManagerPluginContextImpl implements EdgeManagerPluginContext { private final UserPayload userPayload ; EdgeManagerPluginContextImpl ( UserPayload userPayload ) { this . userPayload = userPayload ; } @ Override public UserPayload getUserPayload ( ) { return userPayload ; } @ Override public String getSourceVertexName ( ) { return sourceVertex . getName ( ) ; } @ Override public String getDestinationVertexName ( ) { return destinationVertex . getName ( ) ; } @ Override public int getSourceVertexNumTasks ( ) { return sourceVertex . getTotalTasks ( ) ; } @ Override public int getDestinationVertexNumTasks ( ) { return destinationVertex . getTotalTasks ( ) ; } @ Override public String getVertexGroupName ( ) { if ( destinationVertex . getGroupInputSpecList ( ) != null ) { for ( GroupInputSpec group : destinationVertex . getGroupInputSpecList ( ) ) { if ( group . getGroupVertices ( ) . contains ( getSourceVertexName ( ) ) ) { return group . getGroupName ( ) ; } } } return null ; } ,Smelly
" public static class Inner { public int fieldVal = 0 ; public int fieldVal2 = 0 ; private int _int = 0 ; private boolean _boolean = false ; private String _string = null ; private String _default = null ; private Inner _inner = null ; private Inner _nullInner = null ; private int [ ] _range1 = new int [ 2 ] ; private int [ ] _range2 = new int [ 2 ] ; public Inner ( ) { } public int getInt ( ) { return _int ; } public void setInt ( int i ) { _int = i ; } public boolean getBoolean ( ) { return _boolean ; } public void setBoolean ( boolean b ) { _boolean = b ; } public String getString ( ) { return _string ; } public void setString ( String s ) { _string = s ; } public String getDefault ( ) { return _default ; } public void setDefault ( String s ) { _default = s ; } public int [ ] getRange1 ( ) { return _range1 ; } public void setRange1 ( int min , int max ) { _range1 [ 0 ] = min ; _range1 [ 1 ] = max ; } public int [ ] getRange2 ( ) { return _range2 ; } public void setRange2 ( int min , int max ) { _range2 [ 0 ] = min ; _range2 [ 1 ] = max ; } public void setMixed ( String s , int i ) { _int = i ; _string = s ; } public Inner getInner ( ) { if ( _inner == null ) _inner = new Inner ( ) ; return _inner ; } public void setInner ( Inner in ) { _inner = in ; } public Inner getNullInner ( ) { return _nullInner ; } public void setNullInner ( Inner in ) { _nullInner = in ; } ",Smelly
"@ Deprecated public class KafkaSpout extends BaseRichSpout { static enum EmitState { EMITTED_MORE_LEFT , EMITTED_END , NO_EMITTED } private static final Logger LOG = LoggerFactory . getLogger ( KafkaSpout . class ) ; SpoutConfig _spoutConfig ; SpoutOutputCollector _collector ; PartitionCoordinator _coordinator ; DynamicPartitionConnections _connections ; ZkState _state ; long _lastUpdateMs = 0 ; int _currPartitionIndex = 0 ; public KafkaSpout ( SpoutConfig spoutConf ) { _spoutConfig = spoutConf ; } @ Override public void open ( Map conf , final TopologyContext context , final SpoutOutputCollector collector ) { _collector = collector ; String topologyInstanceId = context . getStormId ( ) ; Map < String , Object > stateConf = new HashMap < > ( conf ) ; List < String > zkServers = _spoutConfig . zkServers ; if ( zkServers == null ) { zkServers = ( List < String > ) conf . get ( Config . STORM_ZOOKEEPER_SERVERS ) ; } Integer zkPort = _spoutConfig . zkPort ; if ( zkPort == null ) { zkPort = ( ( Number ) conf . get ( Config . STORM_ZOOKEEPER_PORT ) ) . intValue ( ) ; } stateConf . put ( Config . TRANSACTIONAL_ZOOKEEPER_SERVERS , zkServers ) ; stateConf . put ( Config . TRANSACTIONAL_ZOOKEEPER_PORT , zkPort ) ; stateConf . put ( Config . TRANSACTIONAL_ZOOKEEPER_ROOT , _spoutConfig . zkRoot ) ; _state = new ZkState ( stateConf ) ; _connections = new DynamicPartitionConnections ( _spoutConfig , KafkaUtils . makeBrokerReader ( conf , _spoutConfig ) ) ; int totalTasks = context . getComponentTasks ( context . getThisComponentId ( ) ) . size ( ) ; if ( _spoutConfig . hosts instanceof StaticHosts ) { _coordinator = new StaticCoordinator ( _connections , conf , _spoutConfig , _state , context . getThisTaskIndex ( ) , totalTasks , context . getThisTaskId ( ) , topologyInstanceId ) ; } else { _coordinator = new ZkCoordinator ( _connections , conf , _spoutConfig , _state , context . getThisTaskIndex ( ) , totalTasks , context . getThisTaskId ( ) , topologyInstanceId ) ; } context . registerMetric ( ""kafkaOffset"" , new IMetric ( ) { KafkaUtils . KafkaOffsetMetric _kafkaOffsetMetric = new KafkaUtils . KafkaOffsetMetric ( _connections ) ; @ Override public Object getValueAndReset ( ) { List < PartitionManager > pms = _coordinator . getMyManagedPartitions ( ) ; Set < Partition > latestPartitions = new HashSet ( ) ; for ( PartitionManager pm : pms ) { latestPartitions . add ( pm . getPartition ( ) ) ; } _kafkaOffsetMetric . refreshPartitions ( latestPartitions ) ; for ( PartitionManager pm : pms ) { _kafkaOffsetMetric . setOffsetData ( pm . getPartition ( ) , pm . getOffsetData ( ) ) ; } return _kafkaOffsetMetric . getValueAndReset ( ) ; } } , _spoutConfig . metricsTimeBucketSizeInSecs ) ; context . registerMetric ( ""kafkaPartition"" , new IMetric ( ) { @ Override public Object getValueAndReset ( ) { List < PartitionManager > pms = _coordinator . getMyManagedPartitions ( ) ; Map concatMetricsDataMaps = new HashMap ( ) ; for ( PartitionManager pm : pms ) { concatMetricsDataMaps . putAll ( pm . getMetricsDataMap ( ) ) ; } return concatMetricsDataMaps ; } } , _spoutConfig . metricsTimeBucketSizeInSecs ) ; } @ Override public void close ( ) { _state . close ( ) ; } @ Override public void nextTuple ( ) { List < PartitionManager > managers = _coordinator . getMyManagedPartitions ( ) ; for ( int i = 0 ; i < managers . size ( ) ; i ++ ) { try { _currPartitionIndex = _currPartitionIndex % managers . size ( ) ; EmitState state = managers . get ( _currPartitionIndex ) . next ( _collector ) ; if ( state != EmitState . EMITTED_MORE_LEFT ) { _currPartitionIndex = ( _currPartitionIndex + 1 ) % managers . size ( ) ; } if ( state != EmitState . NO_EMITTED ) { break ; } } catch ( FailedFetchException e ) { LOG . warn ( ""Fetch failed"" , e ) ; _coordinator . refresh ( ) ; } } long diffWithNow = System . currentTimeMillis ( ) - _lastUpdateMs ; if ( diffWithNow > _spoutConfig . stateUpdateIntervalMs || diffWithNow < 0 ) { commit ( ) ; } } @ Override public void ack ( Object msgId ) { KafkaMessageId id = ( KafkaMessageId ) msgId ; PartitionManager m = _coordinator . getManager ( id . partition ) ; if ( m != null ) { m . ack ( id . offset ) ; } else { PartitionManager newManager = tryToFindNewManager ( id . partition ) ; if ( newManager != null ) { newManager . ack ( id . offset ) ; } } } @ Override public void fail ( Object msgId ) { KafkaMessageId id = ( KafkaMessageId ) msgId ; PartitionManager m = _coordinator . getManager ( id . partition ) ; if ( m != null ) { m . fail ( id . offset ) ; } else { PartitionManager newManager = tryToFindNewManager ( id . partition ) ; if ( newManager != null ) { newManager . fail ( id . offset ) ; } } } @ Override public void deactivate ( ) { commit ( ) ; } @ Override public void declareOutputFields ( OutputFieldsDeclarer declarer ) { if ( ! Strings . isNullOrEmpty ( _spoutConfig . outputStreamId ) ) { declarer . declareStream ( _spoutConfig . outputStreamId , _spoutConfig . scheme . getOutputFields ( ) ) ; } else { declarer . declare ( _spoutConfig . scheme . getOutputFields ( ) ) ; } } @ Override public Map < String , Object > getComponentConfiguration ( ) { Map < String , Object > configuration = super . getComponentConfiguration ( ) ; if ( configuration == null ) { configuration = new HashMap < > ( ) ; } String configKeyPrefix = ""config."" ; configuration . put ( configKeyPrefix + ""topics"" , this . _spoutConfig . topic ) ; StringBuilder zkServers = new StringBuilder ( ) ; if ( _spoutConfig . zkServers != null && _spoutConfig . zkServers . size ( ) > 0 ) { for ( String zkServer : this . _spoutConfig . zkServers ) { zkServers . append ( zkServer + "":"" + this . _spoutConfig . zkPort + "","" ) ; } configuration . put ( configKeyPrefix + ""zkServers"" , zkServers . toString ( ) ) ; } BrokerHosts brokerHosts = this . _spoutConfig . hosts ; String zkRoot = this . _spoutConfig . zkRoot + ""/"" + this . _spoutConfig . id ; if ( brokerHosts instanceof ZkHosts ) { ZkHosts zkHosts = ( ZkHosts ) brokerHosts ; configuration . put ( configKeyPrefix + ""zkNodeBrokers"" , zkHosts . brokerZkPath ) ; } else if ( brokerHosts instanceof StaticHosts ) { StaticHosts staticHosts = ( StaticHosts ) brokerHosts ; GlobalPartitionInformation globalPartitionInformation = staticHosts . getPartitionInformation ( ) ; boolean useTopicNameForPath = globalPartitionInformation . getbUseTopicNameForPartitionPathId ( ) ; if ( useTopicNameForPath ) { zkRoot += ( ""/"" + this . _spoutConfig . topic ) ; } List < Partition > partitions = globalPartitionInformation . getOrderedPartitions ( ) ; StringBuilder staticPartitions = new StringBuilder ( ) ; StringBuilder leaderHosts = new StringBuilder ( ) ; for ( Partition partition : partitions ) { staticPartitions . append ( partition . partition + "","" ) ; leaderHosts . append ( partition . host . host + "":"" + partition . host . port ) . append ( "","" ) ; } configuration . put ( configKeyPrefix + ""partitions"" , staticPartitions . toString ( ) ) ; configuration . put ( configKeyPrefix + ""leaders"" , leaderHosts . toString ( ) ) ; } configuration . put ( configKeyPrefix + ""zkRoot"" , zkRoot ) ; return configuration ; } private PartitionManager tryToFindNewManager ( Partition partition ) { for ( PartitionManager partitionManager : _coordinator . getMyManagedPartitions ( ) ) { if ( partitionManager . getPartition ( ) . partition == partition . partition && partitionManager . getPartition ( ) . topic . equals ( partition . topic ) ) { return partitionManager ; } } return null ; } private void commit ( ) { _lastUpdateMs = System . currentTimeMillis ( ) ; for ( PartitionManager manager : _coordinator . getMyManagedPartitions ( ) ) { manager . commit ( ) ; } } }",No
 public static class VisualizationConfig { boolean useCircles = true ; StatType motion = StatType . allmax ; StatType color = StatType . allavg ; int spacing = 40 ; String url ; ,No
"public class PropertyValueImpl extends DynamicOperandImpl { private final String selectorName ; private final String propertyName ; private final int propertyType ; private SelectorImpl selector ; public PropertyValueImpl ( String selectorName , String propertyName ) { this ( selectorName , propertyName , null ) ; } public PropertyValueImpl ( String selectorName , String propertyName , String propertyType ) { this . selectorName = selectorName ; this . propertyName = propertyName ; this . propertyType = propertyType == null ? PropertyType . UNDEFINED : SQL2Parser . getPropertyTypeFromName ( propertyType ) ; } public String getSelectorName ( ) { return selectorName ; } public String getPropertyName ( ) { return propertyName ; } @ Override boolean accept ( AstVisitor v ) { return v . visit ( this ) ; } @ Override public String toString ( ) { String s = quote ( selectorName ) + '.' + quote ( propertyName ) ; if ( propertyType != PropertyType . UNDEFINED ) { s = ""property("" + s + "", '"" + PropertyType . nameFromValue ( propertyType ) . toLowerCase ( Locale . ENGLISH ) + ""')"" ; } return s ; } @ Override public boolean supportsRangeConditions ( ) { return ! propertyName . equals ( Query . JCR_PATH ) ; } @ Override public PropertyExistenceImpl getPropertyExistence ( ) { if ( propertyName . equals ( ""*"" ) ) { return null ; } return new PropertyExistenceImpl ( selector , selectorName , propertyName ) ; } @ Override public PropertyValue currentProperty ( ) { boolean asterisk = PathUtils . getName ( propertyName ) . equals ( ""*"" ) ; if ( ! asterisk ) { PropertyValue p = selector . currentProperty ( propertyName ) ; return matchesPropertyType ( p ) ? p : null ; } Tree tree = getTree ( selector . currentPath ( ) ) ; if ( tree == null || ! tree . exists ( ) ) { return null ; } if ( ! asterisk ) { String name = PathUtils . getName ( propertyName ) ; if ( ! tree . hasProperty ( name ) ) { return null ; } PropertyState p = tree . getProperty ( name ) ; return matchesPropertyType ( p ) ? PropertyValues . create ( p ) : null ; } List < String > values = new ArrayList < String > ( ) ; for ( PropertyState p : tree . getProperties ( ) ) { if ( matchesPropertyType ( p ) ) { Iterables . addAll ( values , p . getValue ( Type . STRINGS ) ) ; } } return PropertyValues . newString ( values ) ; } private boolean matchesPropertyType ( PropertyValue value ) { if ( value == null ) { return false ; } if ( propertyType == PropertyType . UNDEFINED ) { return true ; } return value . getType ( ) . tag ( ) == propertyType ; } private boolean matchesPropertyType ( PropertyState state ) { if ( state == null ) { return false ; } if ( propertyType == PropertyType . UNDEFINED ) { return true ; } return state . getType ( ) . tag ( ) == propertyType ; } public void bindSelector ( SourceImpl source ) { selector = source . getExistingSelector ( selectorName ) ; } @ Override public void restrict ( FilterImpl f , Operator operator , PropertyValue v ) { if ( f . getSelector ( ) == selector ) { if ( operator == Operator . NOT_EQUAL && v != null ) { return ; } f . restrictProperty ( propertyName , operator , v ) ; if ( propertyType != PropertyType . UNDEFINED ) { f . restrictPropertyType ( propertyName , operator , propertyType ) ; } } } @ Override public boolean canRestrictSelector ( SelectorImpl s ) { return s == selector ; } @ Override int getPropertyType ( ) { return propertyType ; } }",No
" public class Producer { protected ConnectionFactory factory ; protected transient Connection connection ; protected transient Session session ; protected transient MessageProducer producer ; protected static final int messageSize = 1024 ; public Producer ( String brokerURL , String interest , int messageSize , long ttl ) throws JMSException { factory = new ActiveMQConnectionFactory ( brokerURL ) ; connection = factory . createConnection ( ) ; connection . start ( ) ; session = connection . createSession ( false , Session . AUTO_ACKNOWLEDGE ) ; producer = session . createProducer ( session . createTopic ( interest ) ) ; producer . setDeliveryMode ( DeliveryMode . NON_PERSISTENT ) ; if ( ttl > 0 ) { producer . setTimeToLive ( ttl ) ; } } public void close ( ) throws JMSException { if ( connection != null ) { connection . close ( ) ; } } protected void sendMessage ( ) throws JMSException { TextMessage textMessage = session . createTextMessage ( ""test message"" ) ; producer . send ( textMessage ) ; } protected void sendMessages ( int count ) throws JMSException { for ( int i = 0 ; i < count ; i ++ ) { TextMessage textMessage = session . createTextMessage ( createMessageText ( i ) ) ; producer . send ( textMessage ) ; } } private String createMessageText ( int index ) { StringBuffer buffer = new StringBuffer ( messageSize ) ; buffer . append ( ""Message: "" + index + "" sent at: "" + new Date ( ) ) ; if ( buffer . length ( ) > messageSize ) { return buffer . substring ( 0 , messageSize ) ; } for ( int i = buffer . length ( ) ; i < messageSize ; i ++ ) { buffer . append ( ' ' ) ; } return buffer . toString ( ) ; } protected void commitTransaction ( ) throws JMSException { session . commit ( ) ; } ",No
"@ StrutsTag ( name = ""updownselect"" , tldTagClass = ""org.apache.struts2.views.jsp.ui.UpDownSelectTag"" , description = ""Create a Select component with buttons to move the elements in the select component up and down"" ) public class UpDownSelect extends Select { private static final Logger LOG = LoggerFactory . getLogger ( UpDownSelect . class ) ; final public static String TEMPLATE = ""updownselect"" ; protected String allowMoveUp ; protected String allowMoveDown ; protected String allowSelectAll ; protected String moveUpLabel ; protected String moveDownLabel ; protected String selectAllLabel ; public String getDefaultTemplate ( ) { return TEMPLATE ; } public UpDownSelect ( ValueStack stack , HttpServletRequest request , HttpServletResponse response ) { super ( stack , request , response ) ; } public void evaluateParams ( ) { super . evaluateParams ( ) ; if ( size == null || size . trim ( ) . length ( ) <= 0 ) { addParameter ( ""size"" , ""5"" ) ; } if ( multiple == null || multiple . trim ( ) . length ( ) <= 0 ) { addParameter ( ""multiple"" , Boolean . TRUE ) ; } if ( allowMoveUp != null ) { addParameter ( ""allowMoveUp"" , findValue ( allowMoveUp , Boolean . class ) ) ; } if ( allowMoveDown != null ) { addParameter ( ""allowMoveDown"" , findValue ( allowMoveDown , Boolean . class ) ) ; } if ( allowSelectAll != null ) { addParameter ( ""allowSelectAll"" , findValue ( allowSelectAll , Boolean . class ) ) ; } if ( moveUpLabel != null ) { addParameter ( ""moveUpLabel"" , findString ( moveUpLabel ) ) ; } if ( moveDownLabel != null ) { addParameter ( ""moveDownLabel"" , findString ( moveDownLabel ) ) ; } if ( selectAllLabel != null ) { addParameter ( ""selectAllLabel"" , findString ( selectAllLabel ) ) ; } Form ancestorForm = ( Form ) findAncestor ( Form . class ) ; if ( ancestorForm != null ) { enableAncestorFormCustomOnsubmit ( ) ; Map m = ( Map ) ancestorForm . getParameters ( ) . get ( ""updownselectIds"" ) ; if ( m == null ) { m = new LinkedHashMap ( ) ; } m . put ( getParameters ( ) . get ( ""id"" ) , getParameters ( ) . get ( ""headerKey"" ) ) ; ancestorForm . getParameters ( ) . put ( ""updownselectIds"" , m ) ; } else { LOG . warn ( ""no ancestor form found for updownselect "" + this + "", therefore autoselect of all elements upon form submission will not work "" ) ; } } public String getAllowMoveUp ( ) { return allowMoveUp ; } @ StrutsTagAttribute ( description = ""Whether move up button should be displayed"" , type = ""Boolean"" , defaultValue = ""true"" ) public void setAllowMoveUp ( String allowMoveUp ) { this . allowMoveUp = allowMoveUp ; } public String getAllowMoveDown ( ) { return allowMoveDown ; } @ StrutsTagAttribute ( description = ""Whether move down button should be displayed"" , type = ""Boolean"" , defaultValue = ""true"" ) public void setAllowMoveDown ( String allowMoveDown ) { this . allowMoveDown = allowMoveDown ; } public String getAllowSelectAll ( ) { return allowSelectAll ; } @ StrutsTagAttribute ( description = ""Whether or not select all button should be displayed"" , type = ""Boolean"" , defaultValue = ""true"" ) public void setAllowSelectAll ( String allowSelectAll ) { this . allowSelectAll = allowSelectAll ; } public String getMoveUpLabel ( ) { return moveUpLabel ; } @ StrutsTagAttribute ( description = ""Text to display on the move up button"" , defaultValue = ""^"" ) public void setMoveUpLabel ( String moveUpLabel ) { this . moveUpLabel = moveUpLabel ; } public String getMoveDownLabel ( ) { return moveDownLabel ; } @ StrutsTagAttribute ( description = ""Text to display on the move down button"" , defaultValue = ""v"" ) public void setMoveDownLabel ( String moveDownLabel ) { this . moveDownLabel = moveDownLabel ; } public String getSelectAllLabel ( ) { return selectAllLabel ; } @ StrutsTagAttribute ( description = ""Text to display on the select all button"" , defaultValue = ""*"" ) public void setSelectAllLabel ( String selectAllLabel ) { this . selectAllLabel = selectAllLabel ; } }",Smelly
" private static class HiveObjectRefStandardScheme extends StandardScheme < HiveObjectRef > { public void read ( org . apache . thrift . protocol . TProtocol iprot , HiveObjectRef struct ) throws org . apache . thrift . TException { org . apache . thrift . protocol . TField schemeField ; iprot . readStructBegin ( ) ; while ( true ) { schemeField = iprot . readFieldBegin ( ) ; if ( schemeField . type == org . apache . thrift . protocol . TType . STOP ) { break ; } switch ( schemeField . id ) { case 1 : if ( schemeField . type == org . apache . thrift . protocol . TType . I32 ) { struct . objectType = HiveObjectType . findByValue ( iprot . readI32 ( ) ) ; struct . setObjectTypeIsSet ( true ) ; } else { org . apache . thrift . protocol . TProtocolUtil . skip ( iprot , schemeField . type ) ; } break ; case 2 : if ( schemeField . type == org . apache . thrift . protocol . TType . STRING ) { struct . dbName = iprot . readString ( ) ; struct . setDbNameIsSet ( true ) ; } else { org . apache . thrift . protocol . TProtocolUtil . skip ( iprot , schemeField . type ) ; } break ; case 3 : if ( schemeField . type == org . apache . thrift . protocol . TType . STRING ) { struct . objectName = iprot . readString ( ) ; struct . setObjectNameIsSet ( true ) ; } else { org . apache . thrift . protocol . TProtocolUtil . skip ( iprot , schemeField . type ) ; } break ; case 4 : if ( schemeField . type == org . apache . thrift . protocol . TType . LIST ) { { org . apache . thrift . protocol . TList _list8 = iprot . readListBegin ( ) ; struct . partValues = new ArrayList < String > ( _list8 . size ) ; for ( int _i9 = 0 ; _i9 < _list8 . size ; ++ _i9 ) { String _elem10 ; _elem10 = iprot . readString ( ) ; struct . partValues . add ( _elem10 ) ; } iprot . readListEnd ( ) ; } struct . setPartValuesIsSet ( true ) ; } else { org . apache . thrift . protocol . TProtocolUtil . skip ( iprot , schemeField . type ) ; } break ; case 5 : if ( schemeField . type == org . apache . thrift . protocol . TType . STRING ) { struct . columnName = iprot . readString ( ) ; struct . setColumnNameIsSet ( true ) ; } else { org . apache . thrift . protocol . TProtocolUtil . skip ( iprot , schemeField . type ) ; } break ; default : org . apache . thrift . protocol . TProtocolUtil . skip ( iprot , schemeField . type ) ; } iprot . readFieldEnd ( ) ; } iprot . readStructEnd ( ) ; struct . validate ( ) ; } public void write ( org . apache . thrift . protocol . TProtocol oprot , HiveObjectRef struct ) throws org . apache . thrift . TException { struct . validate ( ) ; oprot . writeStructBegin ( STRUCT_DESC ) ; if ( struct . objectType != null ) { oprot . writeFieldBegin ( OBJECT_TYPE_FIELD_DESC ) ; oprot . writeI32 ( struct . objectType . getValue ( ) ) ; oprot . writeFieldEnd ( ) ; } if ( struct . dbName != null ) { oprot . writeFieldBegin ( DB_NAME_FIELD_DESC ) ; oprot . writeString ( struct . dbName ) ; oprot . writeFieldEnd ( ) ; } if ( struct . objectName != null ) { oprot . writeFieldBegin ( OBJECT_NAME_FIELD_DESC ) ; oprot . writeString ( struct . objectName ) ; oprot . writeFieldEnd ( ) ; } if ( struct . partValues != null ) { oprot . writeFieldBegin ( PART_VALUES_FIELD_DESC ) ; { oprot . writeListBegin ( new org . apache . thrift . protocol . TList ( org . apache . thrift . protocol . TType . STRING , struct . partValues . size ( ) ) ) ; for ( String _iter11 : struct . partValues ) { oprot . writeString ( _iter11 ) ; } oprot . writeListEnd ( ) ; } oprot . writeFieldEnd ( ) ; } if ( struct . columnName != null ) { oprot . writeFieldBegin ( COLUMN_NAME_FIELD_DESC ) ; oprot . writeString ( struct . columnName ) ; oprot . writeFieldEnd ( ) ; } oprot . writeFieldStop ( ) ; oprot . writeStructEnd ( ) ; } ",No
"public class PrintReplicationRecords implements Runnable { private static final Logger log = LoggerFactory . getLogger ( PrintReplicationRecords . class ) ; private Connector conn ; private PrintStream out ; private SimpleDateFormat sdf ; public PrintReplicationRecords ( Connector conn , PrintStream out ) { this . conn = conn ; this . out = out ; this . sdf = new SimpleDateFormat ( ""yyyy-MM-dd HH:mm:ss,SSS"" ) ; } @ Override public void run ( ) { Scanner s ; out . println ( sdf . format ( new Date ( ) ) + "" Replication entries from metadata table"" ) ; out . println ( ""------------------------------------------------------------------"" ) ; try { s = conn . createScanner ( MetadataTable . NAME , Authorizations . EMPTY ) ; } catch ( TableNotFoundException e ) { log . error ( ""Metadata table does not exist"" ) ; return ; } s . setRange ( ReplicationSection . getRange ( ) ) ; s . fetchColumnFamily ( ReplicationSection . COLF ) ; for ( Entry < Key , Value > entry : s ) { try { out . println ( entry . getKey ( ) . toStringNoTruncate ( ) + ""="" + ProtobufUtil . toString ( Status . parseFrom ( entry . getValue ( ) . get ( ) ) ) ) ; } catch ( InvalidProtocolBufferException e ) { out . println ( entry . getKey ( ) . toStringNoTruncate ( ) + ""= Could not deserialize Status message"" ) ; } } out . println ( ) ; out . println ( sdf . format ( new Date ( ) ) + "" Replication entries from replication table"" ) ; out . println ( ""--------------------------------------------------------------------"" ) ; try { s = conn . createScanner ( ReplicationTable . NAME , Authorizations . EMPTY ) ; } catch ( TableNotFoundException e ) { log . error ( ""Replication table does not exist"" ) ; return ; } for ( Entry < Key , Value > entry : s ) { try { out . println ( entry . getKey ( ) . toStringNoTruncate ( ) + ""="" + ProtobufUtil . toString ( Status . parseFrom ( entry . getValue ( ) . get ( ) ) ) ) ; } catch ( InvalidProtocolBufferException e ) { out . println ( entry . getKey ( ) . toStringNoTruncate ( ) + ""= Could not deserialize Status message"" ) ; } } } }",No
"public class TestDataTransferKeepalive { Configuration conf = new HdfsConfiguration ( ) ; private MiniDFSCluster cluster ; private FileSystem fs ; private InetSocketAddress dnAddr ; private DataNode dn ; private DFSClient dfsClient ; private static Path TEST_FILE = new Path ( ""/test"" ) ; private static final int KEEPALIVE_TIMEOUT = 1000 ; private static final int WRITE_TIMEOUT = 3000 ; @ Before public void setup ( ) throws Exception { conf . setInt ( DFS_DATANODE_SOCKET_REUSE_KEEPALIVE_KEY , KEEPALIVE_TIMEOUT ) ; conf . setInt ( DFS_CLIENT_MAX_BLOCK_ACQUIRE_FAILURES_KEY , 0 ) ; cluster = new MiniDFSCluster . Builder ( conf ) . numDataNodes ( 1 ) . build ( ) ; fs = cluster . getFileSystem ( ) ; dfsClient = ( ( DistributedFileSystem ) fs ) . dfs ; dfsClient . peerCache . clear ( ) ; String poolId = cluster . getNamesystem ( ) . getBlockPoolId ( ) ; dn = cluster . getDataNodes ( ) . get ( 0 ) ; DatanodeRegistration dnReg = DataNodeTestUtils . getDNRegistrationForBP ( dn , poolId ) ; dnAddr = NetUtils . createSocketAddr ( dnReg . getXferAddr ( ) ) ; } @ After public void teardown ( ) { cluster . shutdown ( ) ; } @ Test ( timeout = 30000 ) public void testKeepaliveTimeouts ( ) throws Exception { DFSTestUtil . createFile ( fs , TEST_FILE , 1L , ( short ) 1 , 0L ) ; assertEquals ( 0 , dfsClient . peerCache . size ( ) ) ; assertXceiverCount ( 0 ) ; DFSTestUtil . readFile ( fs , TEST_FILE ) ; assertEquals ( 1 , dfsClient . peerCache . size ( ) ) ; assertXceiverCount ( 1 ) ; Thread . sleep ( KEEPALIVE_TIMEOUT * 2 ) ; assertXceiverCount ( 0 ) ; assertEquals ( 1 , dfsClient . peerCache . size ( ) ) ; Peer peer = dfsClient . peerCache . get ( dn . getDatanodeId ( ) , false ) ; assertNotNull ( peer ) ; assertEquals ( - 1 , peer . getInputStream ( ) . read ( ) ) ; } @ Test ( timeout = 30000 ) public void testSlowReader ( ) throws Exception { DataNodeProperties props = cluster . stopDataNode ( 0 ) ; props . conf . setInt ( DFS_DATANODE_SOCKET_WRITE_TIMEOUT_KEY , WRITE_TIMEOUT ) ; props . conf . setInt ( DFS_DATANODE_SOCKET_REUSE_KEEPALIVE_KEY , 120000 ) ; assertTrue ( cluster . restartDataNode ( props , true ) ) ; cluster . triggerHeartbeats ( ) ; dn = cluster . getDataNodes ( ) . get ( 0 ) ; DFSTestUtil . createFile ( fs , TEST_FILE , 1024 * 1024 * 8L , ( short ) 1 , 0L ) ; FSDataInputStream stm = fs . open ( TEST_FILE ) ; try { stm . read ( ) ; assertXceiverCount ( 1 ) ; long totalSleepTime = 0 ; long sleepTime = WRITE_TIMEOUT + 100 ; while ( getXceiverCountWithoutServer ( ) > 0 && totalSleepTime < 5000 ) { Thread . sleep ( sleepTime ) ; totalSleepTime += sleepTime ; sleepTime = 100 ; } assertXceiverCount ( 0 ) ; } finally { IOUtils . closeStream ( stm ) ; } } @ Test ( timeout = 30000 ) public void testManyClosedSocketsInCache ( ) throws Exception { DFSTestUtil . createFile ( fs , TEST_FILE , 1L , ( short ) 1 , 0L ) ; InputStream [ ] stms = new InputStream [ 5 ] ; try { for ( int i = 0 ; i < stms . length ; i ++ ) { stms [ i ] = fs . open ( TEST_FILE ) ; } for ( InputStream stm : stms ) { IOUtils . copyBytes ( stm , new NullOutputStream ( ) , 1024 ) ; } } finally { IOUtils . cleanup ( null , stms ) ; } DFSClient client = ( ( DistributedFileSystem ) fs ) . dfs ; assertEquals ( 5 , client . peerCache . size ( ) ) ; Thread . sleep ( 1500 ) ; assertXceiverCount ( 0 ) ; assertEquals ( 5 , client . peerCache . size ( ) ) ; DFSTestUtil . readFile ( fs , TEST_FILE ) ; } private void assertXceiverCount ( int expected ) { int count = getXceiverCountWithoutServer ( ) ; if ( count != expected ) { ReflectionUtils . printThreadInfo ( new PrintWriter ( System . err ) , ""Thread dumps"" ) ; fail ( ""Expected "" + expected + "" xceivers, found "" + count ) ; } } private int getXceiverCountWithoutServer ( ) { return dn . getXceiverCount ( ) - 1 ; } }",No
"public class DestinationPathTest extends TestSupport { public void testPathParse ( ) { assertParse ( ""FOO"" , new String [ ] { ""FOO"" } ) ; assertParse ( ""FOO.BAR"" , new String [ ] { ""FOO"" , ""BAR"" } ) ; assertParse ( ""FOO.*"" , new String [ ] { ""FOO"" , ""*"" } ) ; assertParse ( ""FOO.>"" , new String [ ] { ""FOO"" , "">"" } ) ; assertParse ( ""FOO.BAR.XYZ"" , new String [ ] { ""FOO"" , ""BAR"" , ""XYZ"" } ) ; assertParse ( ""FOO.BAR."" , new String [ ] { ""FOO"" , ""BAR"" , """" } ) ; } protected void assertParse ( String subject , String [ ] expected ) { String [ ] path = DestinationPath . getDestinationPaths ( subject ) ; assertArrayEqual ( subject , expected , path ) ; } }",No
"public class SqlDropType extends SqlDropObject { private static final SqlOperator OPERATOR = new SqlSpecialOperator ( ""DROP TYPE"" , SqlKind . DROP_TYPE ) ; SqlDropType ( SqlParserPos pos , boolean ifExists , SqlIdentifier name ) { super ( OPERATOR , pos , ifExists , name ) ; } }",No
"@ Provider public class WebApplicationExceptionMapper implements ExceptionMapper < WebApplicationException > { private static final Logger logger = LoggerFactory . getLogger ( WebApplicationExceptionMapper . class ) ; private static final String EXCEPTION_SEPARATOR = "": "" ; @ Override public Response toResponse ( WebApplicationException exception ) { String message = exception . getMessage ( ) ; if ( message == null ) { message = StringUtils . EMPTY ; } if ( message . contains ( EXCEPTION_SEPARATOR ) ) { message = StringUtils . substringAfter ( message , EXCEPTION_SEPARATOR ) ; } final Response response = exception . getResponse ( ) ; logger . info ( String . format ( ""%s. Returning %s response."" , exception , response . getStatus ( ) ) ) ; if ( logger . isDebugEnabled ( ) ) { logger . debug ( StringUtils . EMPTY , exception ) ; } return Response . status ( response . getStatus ( ) ) . entity ( message ) . type ( ""text/plain"" ) . build ( ) ; } }",No
"public class SecuritySettings implements ISecuritySettings { private IAuthorizationStrategy authorizationStrategy = IAuthorizationStrategy . ALLOW_ALL ; private IAuthenticationStrategy authenticationStrategy ; private ICryptFactory cryptFactory ; private boolean enforceMounts = false ; private IUnauthorizedComponentInstantiationListener unauthorizedComponentInstantiationListener = new IUnauthorizedComponentInstantiationListener ( ) { @ Override public void onUnauthorizedInstantiation ( final Component component ) { throw new UnauthorizedInstantiationException ( component . getClass ( ) ) ; } } ; @ Override public IAuthorizationStrategy getAuthorizationStrategy ( ) { return authorizationStrategy ; } @ Override public synchronized ICryptFactory getCryptFactory ( ) { if ( cryptFactory == null ) { cryptFactory = new KeyInSessionSunJceCryptFactory ( ) ; } return cryptFactory ; } @ Override public boolean getEnforceMounts ( ) { return enforceMounts ; } @ Override public IUnauthorizedComponentInstantiationListener getUnauthorizedComponentInstantiationListener ( ) { return unauthorizedComponentInstantiationListener ; } @ Override public void setAuthorizationStrategy ( IAuthorizationStrategy strategy ) { Args . notNull ( strategy , ""authorization strategy"" ) ; authorizationStrategy = strategy ; } @ Override public void setCryptFactory ( ICryptFactory cryptFactory ) { Args . notNull ( cryptFactory , ""Crypt factory"" ) ; this . cryptFactory = cryptFactory ; } @ Override public void setEnforceMounts ( boolean enforce ) { enforceMounts = enforce ; } @ Override public void setUnauthorizedComponentInstantiationListener ( IUnauthorizedComponentInstantiationListener unauthorizedComponentInstantiationListener ) { this . unauthorizedComponentInstantiationListener = unauthorizedComponentInstantiationListener ; } @ Override public IAuthenticationStrategy getAuthenticationStrategy ( ) { if ( authenticationStrategy == null ) { authenticationStrategy = new DefaultAuthenticationStrategy ( ""LoggedIn"" ) ; } return authenticationStrategy ; } @ Override public void setAuthenticationStrategy ( final IAuthenticationStrategy strategy ) { authenticationStrategy = strategy ; } }",Smelly
"public class WSComponentPort extends ComponentDataPort { public static final String DEFAULT = ""default"" ; private WSComponent component ; private XmlElement elementElement ; private Object value ; private String defaultValue ; private String targetNamespace ; private boolean schemaUsed ; private XmlElement annotation ; private XmlElement appinfo ; private boolean optional ; private String applicationArgument ; private int inputOrder ; public WSComponentPort ( String name , DataType type , WSComponent component ) { super ( name ) ; this . component = component ; this . type = type ; this . schemaUsed = false ; } public WSComponent getComponent ( ) { return this . component ; } @ Override public WSPort createPort ( ) { WSPort port = new WSPort ( ) ; port . setName ( this . name ) ; port . setComponentPort ( this ) ; return port ; } public boolean isSchemaUsed ( ) { return this . schemaUsed ; } public String getTargetNamespace ( ) { return this . targetNamespace ; } public XmlElement getElement ( ) { return this . elementElement ; } public String getDefaultValue ( ) { return this . defaultValue ; } public void setDefaultValue ( String defaultValue ) { this . defaultValue = defaultValue ; } public Object getValue ( ) { return this . value ; } public void setValue ( Object value ) { this . value = value ; } public String getApplicationArgument ( ) { return applicationArgument ; } public void setApplicationArgument ( String applicationArgument ) { this . applicationArgument = applicationArgument ; } public int getInputOrder ( ) { return inputOrder ; } public void setInputOrder ( int inputOrder ) { this . inputOrder = inputOrder ; } public XmlElement getAppinfo ( ) { return this . appinfo ; } public boolean isOptional ( ) { return this . optional ; } private void parse ( XmlElement element ) throws ComponentException { this . name = element . attributeValue ( WSConstants . NAME_ATTRIBUTE ) ; String typeQNameString = element . attributeValue ( WSConstants . TYPE_ATTRIBUTE ) ; if ( typeQNameString == null ) { } else { } this . annotation = element . element ( null , WSConstants . ANNOTATION_TAG ) ; if ( this . annotation != null ) { XmlElement documentationElement = this . annotation . element ( null , WSConstants . DOCUMENTATION_TAG ) ; if ( documentationElement != null ) { this . description = documentationElement . requiredText ( ) ; } this . appinfo = this . annotation . element ( null , WSConstants . APPINFO_TAG ) ; } this . defaultValue = element . attributeValue ( WSConstants . DEFAULT_ATTRIBUTE ) ; if ( this . defaultValue == null && this . annotation != null ) { XmlElement defaultElement = this . annotation . element ( null , DEFAULT ) ; if ( defaultElement != null ) { for ( Object child : defaultElement . children ( ) ) { if ( child instanceof XmlElement ) { this . defaultValue = XMLUtil . xmlElementToString ( ( XmlElement ) child ) ; } } } } String minOccurs = element . attributeValue ( WSConstants . MIN_OCCURS_ATTRIBUTE ) ; if ( ""0"" . equals ( minOccurs ) ) { this . optional = true ; } else { this . optional = false ; } } }",Smelly
" private class CustomProvider extends CsdlAbstractEdmProvider { @ Override public CsdlEntitySet getEntitySet ( final FullQualifiedName entityContainer , final String entitySetName ) throws ODataException { if ( entitySetName != null ) { return new CsdlEntitySet ( ) . setName ( ""entitySetName"" ) ; } return null ; } @ Override public CsdlSingleton getSingleton ( final FullQualifiedName entityContainer , final String singletonName ) throws ODataException { if ( singletonName != null ) { return new CsdlSingleton ( ) . setName ( ""singletonName"" ) ; } return null ; } @ Override public CsdlActionImport getActionImport ( final FullQualifiedName entityContainer , final String actionImportName ) throws ODataException { if ( actionImportName != null ) { return new CsdlActionImport ( ) . setName ( ""actionImportName"" ) ; } return null ; } @ Override public CsdlFunctionImport getFunctionImport ( final FullQualifiedName entityContainer , final String functionImportName ) throws ODataException { if ( functionImportName != null ) { return new CsdlFunctionImport ( ) . setName ( ""functionImportName"" ) ; } return null ; } @ Override public CsdlEntityContainer getEntityContainer ( ) throws ODataException { CsdlEntityContainer container = new CsdlEntityContainer ( ) ; List < CsdlEntitySet > entitySets = new ArrayList < CsdlEntitySet > ( ) ; entitySets . add ( new CsdlEntitySet ( ) . setName ( ""entitySetName"" ) ) ; entitySets . add ( new CsdlEntitySet ( ) . setName ( ""entitySetName2"" ) ) ; container . setEntitySets ( entitySets ) ; List < CsdlSingleton > singletons = new ArrayList < CsdlSingleton > ( ) ; singletons . add ( new CsdlSingleton ( ) . setName ( ""singletonName"" ) ) ; singletons . add ( new CsdlSingleton ( ) . setName ( ""singletonName2"" ) ) ; container . setSingletons ( singletons ) ; List < CsdlActionImport > actionImports = new ArrayList < CsdlActionImport > ( ) ; actionImports . add ( new CsdlActionImport ( ) . setName ( ""actionImportName"" ) ) ; actionImports . add ( new CsdlActionImport ( ) . setName ( ""actionImportName2"" ) ) ; container . setActionImports ( actionImports ) ; List < CsdlFunctionImport > functionImports = new ArrayList < CsdlFunctionImport > ( ) ; functionImports . add ( new CsdlFunctionImport ( ) . setName ( ""functionImportName"" ) ) ; functionImports . add ( new CsdlFunctionImport ( ) . setName ( ""functionImportName2"" ) ) ; container . setFunctionImports ( functionImports ) ; return container ; } } ",Smelly
"public final class ExpressionBuilder implements NodeVisitor { private static final int CACHE_SIZE ; private static final String CACHE_SIZE_PROP = ""org.apache.el.ExpressionBuilder.CACHE_SIZE"" ; static { if ( System . getSecurityManager ( ) == null ) { CACHE_SIZE = Integer . parseInt ( System . getProperty ( CACHE_SIZE_PROP , ""5000"" ) ) ; } else { CACHE_SIZE = AccessController . doPrivileged ( new PrivilegedAction < Integer > ( ) { @ Override public Integer run ( ) { return Integer . valueOf ( System . getProperty ( CACHE_SIZE_PROP , ""5000"" ) ) ; } } ) . intValue ( ) ; } } private static final ConcurrentCache < String , Node > cache = new ConcurrentCache < String , Node > ( CACHE_SIZE ) ; private FunctionMapper fnMapper ; private VariableMapper varMapper ; private String expression ; public ExpressionBuilder ( String expression , ELContext ctx ) throws ELException { this . expression = expression ; FunctionMapper ctxFn = ctx . getFunctionMapper ( ) ; VariableMapper ctxVar = ctx . getVariableMapper ( ) ; if ( ctxFn != null ) { this . fnMapper = new FunctionMapperFactory ( ctxFn ) ; } if ( ctxVar != null ) { this . varMapper = new VariableMapperFactory ( ctxVar ) ; } } public static final Node createNode ( String expr ) throws ELException { Node n = createNodeInternal ( expr ) ; return n ; } private static final Node createNodeInternal ( String expr ) throws ELException { if ( expr == null ) { throw new ELException ( MessageFactory . get ( ""error.null"" ) ) ; } Node n = cache . get ( expr ) ; if ( n == null ) { try { n = ( new ELParser ( new StringReader ( expr ) ) ) . CompositeExpression ( ) ; int numChildren = n . jjtGetNumChildren ( ) ; if ( numChildren == 1 ) { n = n . jjtGetChild ( 0 ) ; } else { Class < ? > type = null ; Node child = null ; for ( int i = 0 ; i < numChildren ; i ++ ) { child = n . jjtGetChild ( i ) ; if ( child instanceof AstLiteralExpression ) continue ; if ( type == null ) type = child . getClass ( ) ; else { if ( ! type . equals ( child . getClass ( ) ) ) { throw new ELException ( MessageFactory . get ( ""error.mixed"" , expr ) ) ; } } } } if ( n instanceof AstDeferredExpression || n instanceof AstDynamicExpression ) { n = n . jjtGetChild ( 0 ) ; } cache . put ( expr , n ) ; } catch ( Exception e ) { throw new ELException ( MessageFactory . get ( ""error.parseFail"" , expr ) , e ) ; } } return n ; } private void prepare ( Node node ) throws ELException { try { node . accept ( this ) ; } catch ( Exception e ) { if ( e instanceof ELException ) { throw ( ELException ) e ; } else { throw ( new ELException ( e ) ) ; } } if ( this . fnMapper instanceof FunctionMapperFactory ) { this . fnMapper = ( ( FunctionMapperFactory ) this . fnMapper ) . create ( ) ; } if ( this . varMapper instanceof VariableMapperFactory ) { this . varMapper = ( ( VariableMapperFactory ) this . varMapper ) . create ( ) ; } } private Node build ( ) throws ELException { Node n = createNodeInternal ( this . expression ) ; this . prepare ( n ) ; if ( n instanceof AstDeferredExpression || n instanceof AstDynamicExpression ) { n = n . jjtGetChild ( 0 ) ; } return n ; } @ Override public void visit ( Node node ) throws ELException { if ( node instanceof AstFunction ) { AstFunction funcNode = ( AstFunction ) node ; if ( this . fnMapper == null ) { throw new ELException ( MessageFactory . get ( ""error.fnMapper.null"" ) ) ; } Method m = fnMapper . resolveFunction ( funcNode . getPrefix ( ) , funcNode . getLocalName ( ) ) ; if ( m == null ) { throw new ELException ( MessageFactory . get ( ""error.fnMapper.method"" , funcNode . getOutputName ( ) ) ) ; } int pcnt = m . getParameterTypes ( ) . length ; if ( node . jjtGetNumChildren ( ) != pcnt ) { throw new ELException ( MessageFactory . get ( ""error.fnMapper.paramcount"" , funcNode . getOutputName ( ) , """" + pcnt , """" + node . jjtGetNumChildren ( ) ) ) ; } } else if ( node instanceof AstIdentifier && this . varMapper != null ) { String variable = ( ( AstIdentifier ) node ) . getImage ( ) ; this . varMapper . resolveVariable ( variable ) ; } } public ValueExpression createValueExpression ( Class < ? > expectedType ) throws ELException { Node n = this . build ( ) ; return new ValueExpressionImpl ( this . expression , n , this . fnMapper , this . varMapper , expectedType ) ; } public MethodExpression createMethodExpression ( Class < ? > expectedReturnType , Class < ? > [ ] expectedParamTypes ) throws ELException { Node n = this . build ( ) ; if ( ! n . isParametersProvided ( ) && expectedParamTypes == null ) { throw new NullPointerException ( MessageFactory . get ( ""error.method.nullParms"" ) ) ; } if ( n instanceof AstValue || n instanceof AstIdentifier ) { return new MethodExpressionImpl ( expression , n , this . fnMapper , this . varMapper , expectedReturnType , expectedParamTypes ) ; } else if ( n instanceof AstLiteralExpression ) { return new MethodExpressionLiteral ( expression , expectedReturnType , expectedParamTypes ) ; } else { throw new ELException ( ""Not a Valid Method Expression: "" + expression ) ; } } }",No
"@ RunWith ( JUnit4 . class ) public class DirectTimerInternalsTest { private MockClock clock ; @ Mock private TransformWatermarks watermarks ; private TimerUpdateBuilder timerUpdateBuilder ; private DirectTimerInternals internals ; @ Before public void setup ( ) { MockitoAnnotations . initMocks ( this ) ; clock = MockClock . fromInstant ( new Instant ( 0 ) ) ; timerUpdateBuilder = TimerUpdate . builder ( StructuralKey . of ( 1234 , VarIntCoder . of ( ) ) ) ; internals = DirectTimerInternals . create ( clock , watermarks , timerUpdateBuilder ) ; } @ Test public void setTimerAddsToBuilder ( ) { TimerData eventTimer = TimerData . of ( StateNamespaces . global ( ) , new Instant ( 20145L ) , TimeDomain . EVENT_TIME ) ; TimerData processingTimer = TimerData . of ( StateNamespaces . global ( ) , new Instant ( 125555555L ) , TimeDomain . PROCESSING_TIME ) ; TimerData synchronizedProcessingTimer = TimerData . of ( StateNamespaces . global ( ) , new Instant ( 98745632189L ) , TimeDomain . SYNCHRONIZED_PROCESSING_TIME ) ; internals . setTimer ( eventTimer ) ; internals . setTimer ( processingTimer ) ; internals . setTimer ( synchronizedProcessingTimer ) ; assertThat ( internals . getTimerUpdate ( ) . getSetTimers ( ) , containsInAnyOrder ( eventTimer , synchronizedProcessingTimer , processingTimer ) ) ; } @ Test public void deleteTimerDeletesOnBuilder ( ) { TimerData eventTimer = TimerData . of ( StateNamespaces . global ( ) , new Instant ( 20145L ) , TimeDomain . EVENT_TIME ) ; TimerData processingTimer = TimerData . of ( StateNamespaces . global ( ) , new Instant ( 125555555L ) , TimeDomain . PROCESSING_TIME ) ; TimerData synchronizedProcessingTimer = TimerData . of ( StateNamespaces . global ( ) , new Instant ( 98745632189L ) , TimeDomain . SYNCHRONIZED_PROCESSING_TIME ) ; internals . deleteTimer ( eventTimer ) ; internals . deleteTimer ( processingTimer ) ; internals . deleteTimer ( synchronizedProcessingTimer ) ; assertThat ( internals . getTimerUpdate ( ) . getDeletedTimers ( ) , containsInAnyOrder ( eventTimer , synchronizedProcessingTimer , processingTimer ) ) ; } @ Test public void getProcessingTimeIsClockNow ( ) { assertThat ( internals . currentProcessingTime ( ) , equalTo ( clock . now ( ) ) ) ; Instant oldProcessingTime = internals . currentProcessingTime ( ) ; clock . advance ( Duration . standardHours ( 12 ) ) ; assertThat ( internals . currentProcessingTime ( ) , equalTo ( clock . now ( ) ) ) ; assertThat ( internals . currentProcessingTime ( ) , equalTo ( oldProcessingTime . plus ( Duration . standardHours ( 12 ) ) ) ) ; } @ Test public void getSynchronizedProcessingTimeIsWatermarkSynchronizedInputTime ( ) { when ( watermarks . getSynchronizedProcessingInputTime ( ) ) . thenReturn ( new Instant ( 12345L ) ) ; assertThat ( internals . currentSynchronizedProcessingTime ( ) , equalTo ( new Instant ( 12345L ) ) ) ; } @ Test public void getInputWatermarkTimeUsesWatermarkTime ( ) { when ( watermarks . getInputWatermark ( ) ) . thenReturn ( new Instant ( 8765L ) ) ; assertThat ( internals . currentInputWatermarkTime ( ) , equalTo ( new Instant ( 8765L ) ) ) ; } @ Test public void getOutputWatermarkTimeUsesWatermarkTime ( ) { when ( watermarks . getOutputWatermark ( ) ) . thenReturn ( new Instant ( 25525L ) ) ; assertThat ( internals . currentOutputWatermarkTime ( ) , equalTo ( new Instant ( 25525L ) ) ) ; } }",Smelly
"public abstract class _SimpleLockingTestEntity extends BaseDataObject { private static final long serialVersionUID = 1L ; public static final String LOCKING_TEST_ID_PK_COLUMN = ""LOCKING_TEST_ID"" ; public static final Property < String > DESCRIPTION = Property . create ( ""description"" , String . class ) ; public static final Property < Integer > INT_COLUMN_NOTNULL = Property . create ( ""intColumnNotnull"" , Integer . class ) ; public static final Property < Integer > INT_COLUMN_NULL = Property . create ( ""intColumnNull"" , Integer . class ) ; public static final Property < String > NAME = Property . create ( ""name"" , String . class ) ; protected String description ; protected int intColumnNotnull ; protected Integer intColumnNull ; protected String name ; public void setDescription ( String description ) { beforePropertyWrite ( ""description"" , this . description , description ) ; this . description = description ; } public String getDescription ( ) { beforePropertyRead ( ""description"" ) ; return this . description ; } public void setIntColumnNotnull ( int intColumnNotnull ) { beforePropertyWrite ( ""intColumnNotnull"" , this . intColumnNotnull , intColumnNotnull ) ; this . intColumnNotnull = intColumnNotnull ; } public int getIntColumnNotnull ( ) { beforePropertyRead ( ""intColumnNotnull"" ) ; return this . intColumnNotnull ; } public void setIntColumnNull ( int intColumnNull ) { beforePropertyWrite ( ""intColumnNull"" , this . intColumnNull , intColumnNull ) ; this . intColumnNull = intColumnNull ; } public int getIntColumnNull ( ) { beforePropertyRead ( ""intColumnNull"" ) ; if ( this . intColumnNull == null ) { return 0 ; } return this . intColumnNull ; } public void setName ( String name ) { beforePropertyWrite ( ""name"" , this . name , name ) ; this . name = name ; } public String getName ( ) { beforePropertyRead ( ""name"" ) ; return this . name ; } @ Override public Object readPropertyDirectly ( String propName ) { if ( propName == null ) { throw new IllegalArgumentException ( ) ; } switch ( propName ) { case ""description"" : return this . description ; case ""intColumnNotnull"" : return this . intColumnNotnull ; case ""intColumnNull"" : return this . intColumnNull ; case ""name"" : return this . name ; default : return super . readPropertyDirectly ( propName ) ; } } @ Override public void writePropertyDirectly ( String propName , Object val ) { if ( propName == null ) { throw new IllegalArgumentException ( ) ; } switch ( propName ) { case ""description"" : this . description = ( String ) val ; break ; case ""intColumnNotnull"" : this . intColumnNotnull = val == null ? 0 : ( int ) val ; break ; case ""intColumnNull"" : this . intColumnNull = ( Integer ) val ; break ; case ""name"" : this . name = ( String ) val ; break ; default : super . writePropertyDirectly ( propName , val ) ; } } private void writeObject ( ObjectOutputStream out ) throws IOException { writeSerialized ( out ) ; } private void readObject ( ObjectInputStream in ) throws IOException , ClassNotFoundException { readSerialized ( in ) ; } @ Override protected void writeState ( ObjectOutputStream out ) throws IOException { super . writeState ( out ) ; out . writeObject ( this . description ) ; out . writeInt ( this . intColumnNotnull ) ; out . writeObject ( this . intColumnNull ) ; out . writeObject ( this . name ) ; } @ Override protected void readState ( ObjectInputStream in ) throws IOException , ClassNotFoundException { super . readState ( in ) ; this . description = ( String ) in . readObject ( ) ; this . intColumnNotnull = in . readInt ( ) ; this . intColumnNull = ( Integer ) in . readObject ( ) ; this . name = ( String ) in . readObject ( ) ; } }",Smelly
"public class X500PrincipalParser { public static final int LEASTSIGNIFICANT = 0 ; public static final int MOSTSIGNIFICANT = 1 ; public static final String attrCN = ""CN"" ; public static final String attrOU = ""OU"" ; public static final String attrO = ""O"" ; public static final String attrC = ""C"" ; public static final String attrL = ""L"" ; public static final String attrST = ""ST"" ; public static final String attrSTREET = ""STREET"" ; public static final String attrEMAIL = ""EMAILADDRESS"" ; public static final String attrUID = ""UID"" ; private List < List < String > > rdnNameArray = new ArrayList < > ( ) ; private static final String attrTerminator = ""="" ; public X500PrincipalParser ( X500Principal principal ) { parseDN ( principal . getName ( X500Principal . RFC2253 ) ) ; } public List < Object > getAllValues ( String attributeID ) { List < Object > retList = new ArrayList < > ( ) ; String searchPart = attributeID + attrTerminator ; for ( List < String > nameList : rdnNameArray ) { String namePart = nameList . get ( 0 ) ; if ( namePart . startsWith ( searchPart ) ) { retList . add ( namePart . substring ( searchPart . length ( ) ) ) ; } } return retList ; } public String getC ( ) { return findPart ( attrC ) ; } public String getCN ( ) { return findPart ( attrCN ) ; } public String getEMAILDDRESS ( ) { return findPart ( attrEMAIL ) ; } public String getL ( ) { return findPart ( attrL ) ; } public String getO ( ) { return findPart ( attrO ) ; } public String getOU ( ) { return findPart ( attrOU ) ; } public String getST ( ) { return findPart ( attrST ) ; } public String getSTREET ( ) { return findPart ( attrSTREET ) ; } public String getUID ( ) { return findPart ( attrUID ) ; } private String findPart ( String attributeID ) { return findSignificantPart ( attributeID , MOSTSIGNIFICANT ) ; } private String findSignificantPart ( String attributeID , int significance ) { String retNamePart = null ; String searchPart = attributeID + attrTerminator ; for ( Object o : rdnNameArray ) { ArrayList nameList = ( ArrayList ) o ; String namePart = ( String ) nameList . get ( 0 ) ; if ( namePart . startsWith ( searchPart ) ) { retNamePart = namePart . substring ( searchPart . length ( ) ) ; if ( significance == MOSTSIGNIFICANT ) { break ; } } } return retNamePart ; } private void parseDN ( String dn ) throws IllegalArgumentException { int startIndex = 0 ; char c = '\0' ; List < String > nameValues = new ArrayList < > ( ) ; rdnNameArray . clear ( ) ; while ( startIndex < dn . length ( ) ) { int endIndex ; for ( endIndex = startIndex ; endIndex < dn . length ( ) ; endIndex ++ ) { c = dn . charAt ( endIndex ) ; if ( c == ',' || c == '+' ) { break ; } if ( c == '\\' ) { endIndex ++ ; } } if ( endIndex > dn . length ( ) ) { throw new IllegalArgumentException ( ""unterminated escape "" + dn ) ; } nameValues . add ( dn . substring ( startIndex , endIndex ) ) ; if ( c != '+' ) { rdnNameArray . add ( nameValues ) ; if ( endIndex != dn . length ( ) ) { nameValues = new ArrayList < > ( ) ; } else { nameValues = null ; } } startIndex = endIndex + 1 ; } if ( nameValues != null ) { throw new IllegalArgumentException ( ""improperly terminated DN "" + dn ) ; } } }",Smelly
"public class JCAConnectionPoolStatsImpl extends JCAConnectionStatsImpl { private CountStatisticImpl closeCount ; private CountStatisticImpl createCount ; private BoundedRangeStatisticImpl freePoolSize ; private BoundedRangeStatisticImpl poolSize ; private RangeStatisticImpl waitingThreadCount ; public JCAConnectionPoolStatsImpl ( String connectionFactory , String managedConnectionFactory , TimeStatisticImpl waitTime , TimeStatisticImpl useTime , CountStatisticImpl closeCount , CountStatisticImpl createCount , BoundedRangeStatisticImpl freePoolSize , BoundedRangeStatisticImpl poolSize , RangeStatisticImpl waitingThreadCount ) { super ( connectionFactory , managedConnectionFactory , waitTime , useTime ) ; this . closeCount = closeCount ; this . createCount = createCount ; this . freePoolSize = freePoolSize ; this . poolSize = poolSize ; this . waitingThreadCount = waitingThreadCount ; addStatistic ( ""freePoolSize"" , freePoolSize ) ; addStatistic ( ""poolSize"" , poolSize ) ; addStatistic ( ""waitingThreadCount"" , waitingThreadCount ) ; } public CountStatisticImpl getCloseCount ( ) { return closeCount ; } public CountStatisticImpl getCreateCount ( ) { return createCount ; } public BoundedRangeStatisticImpl getFreePoolSize ( ) { return freePoolSize ; } public BoundedRangeStatisticImpl getPoolSize ( ) { return poolSize ; } public RangeStatisticImpl getWaitingThreadCount ( ) { return waitingThreadCount ; } }",Smelly
 static class JsonProperty { String key ; public String getKey ( ) { return key ; } public void setKey ( String key ) { this . key = key ; } public String getValue ( ) { return value ; } public void setValue ( String value ) { this . value = value ; } public boolean getIsFinal ( ) { return isFinal ; } public void setIsFinal ( boolean isFinal ) { this . isFinal = isFinal ; } public String getResource ( ) { return resource ; } public void setResource ( String resource ) { this . resource = resource ; ,Smelly
"public class BrokerStatsBase extends AdminResource { private static final Logger log = LoggerFactory . getLogger ( BrokerStatsBase . class ) ; @ GET @ Path ( ""/metrics"" ) @ ApiOperation ( value = ""Gets the metrics for Monitoring"" , notes = ""Requested should be executed by Monitoring agent on each broker to fetch the metrics"" , response = Metrics . class , responseContainer = ""List"" ) @ ApiResponses ( value = { @ ApiResponse ( code = 403 , message = ""Don't have admin permission"" ) } ) public Collection < Metrics > getMetrics ( ) throws Exception { validateSuperUserAccess ( ) ; try { Collection < Metrics > metrics = pulsar ( ) . getMetricsGenerator ( ) . generate ( ) ; return metrics ; } catch ( Exception e ) { log . error ( ""[{}] Failed to generate metrics"" , clientAppId ( ) , e ) ; throw new RestException ( e ) ; } } @ GET @ Path ( ""/mbeans"" ) @ ApiOperation ( value = ""Get all the mbean details of this broker JVM"" , response = Metrics . class , responseContainer = ""List"" ) @ ApiResponses ( value = { @ ApiResponse ( code = 403 , message = ""Don't have admin permission"" ) } ) public Collection < Metrics > getMBeans ( ) throws Exception { validateSuperUserAccess ( ) ; try { Collection < Metrics > metrics = MBeanStatsGenerator . generate ( pulsar ( ) ) ; return metrics ; } catch ( Exception e ) { log . error ( ""[{}] Failed to generate mbean stats"" , clientAppId ( ) , e ) ; throw new RestException ( e ) ; } } @ GET @ Path ( ""/destinations"" ) @ ApiOperation ( value = ""Get all the topic stats by namespace"" , response = OutputStream . class , responseContainer = ""OutputStream"" ) @ ApiResponses ( value = { @ ApiResponse ( code = 403 , message = ""Don't have admin permission"" ) } ) public StreamingOutput getTopics2 ( ) throws Exception { validateSuperUserAccess ( ) ; return output -> pulsar ( ) . getBrokerService ( ) . getDimensionMetrics ( statsBuf -> { try { output . write ( statsBuf . array ( ) , statsBuf . arrayOffset ( ) , statsBuf . readableBytes ( ) ) ; } catch ( Exception e ) { throw new WebApplicationException ( e ) ; } } ) ; } @ GET @ Path ( ""/allocator-stats/{allocator}"" ) @ ApiOperation ( value = ""Get the stats for the Netty allocator. Available allocators are 'default' and 'ml-cache'"" , response = AllocatorStats . class ) @ ApiResponses ( value = { @ ApiResponse ( code = 403 , message = ""Don't have admin permission"" ) } ) public AllocatorStats getAllocatorStats ( @ PathParam ( ""allocator"" ) String allocatorName ) throws Exception { validateSuperUserAccess ( ) ; try { return AllocatorStatsGenerator . generate ( allocatorName ) ; } catch ( IllegalArgumentException e ) { throw new RestException ( Status . NOT_ACCEPTABLE , e . getMessage ( ) ) ; } catch ( Exception e ) { log . error ( ""[{}] Failed to generate allocator stats"" , clientAppId ( ) , e ) ; throw new RestException ( e ) ; } } @ GET @ Path ( ""/bookieops"" ) @ ApiOperation ( value = ""Get pending bookie client op stats by namesapce"" , response = PendingBookieOpsStats . class , responseContainer = ""Map"" ) @ ApiResponses ( value = { @ ApiResponse ( code = 403 , message = ""Don't have admin permission"" ) } ) public Map < String , Map < String , PendingBookieOpsStats > > getPendingBookieOpsStats ( ) throws Exception { validateSuperUserAccess ( ) ; try { return BookieClientStatsGenerator . generate ( pulsar ( ) ) ; } catch ( Exception e ) { log . error ( ""[{}] Failed to generate pending bookie ops stats for topicss"" , clientAppId ( ) , e ) ; throw new RestException ( e ) ; } } @ GET @ Path ( ""/load-report"" ) @ ApiOperation ( value = ""Get Load for this broker"" , notes = ""consists of topics stats & systemResourceUsage"" , response = LoadReport . class ) @ ApiResponses ( value = { @ ApiResponse ( code = 403 , message = ""Don't have admin permission"" ) } ) public LoadManagerReport getLoadReport ( ) throws Exception { validateSuperUserAccess ( ) ; try { return ( pulsar ( ) . getLoadManager ( ) . get ( ) ) . generateLoadReport ( ) ; } catch ( Exception e ) { log . error ( ""[{}] Failed to generate LoadReport for broker, reason [{}]"" , clientAppId ( ) , e . getMessage ( ) , e ) ; throw new RestException ( e ) ; } } protected Map < Long , Collection < ResourceUnit > > internalBrokerResourceAvailability ( NamespaceName namespace ) { try { LoadManager lm = pulsar ( ) . getLoadManager ( ) . get ( ) ; if ( lm instanceof SimpleLoadManagerImpl ) { return ( ( SimpleLoadManagerImpl ) lm ) . getResourceAvailabilityFor ( namespace ) . asMap ( ) ; } else { throw new RestException ( Status . CONFLICT , lm . getClass ( ) . getName ( ) + "" does not support this operation"" ) ; } } catch ( Exception e ) { log . error ( ""Unable to get Resource Availability - [{}]"" , e ) ; throw new RestException ( e ) ; } } }",Smelly
" private class RackLocalContainerAssigner extends ContainerAssigner { RackLocalContainerAssigner ( ) { super ( ""RackLocal"" ) ; } @ Override public CookieContainerRequest assignNewContainer ( Container container ) { String location = RackResolver . resolve ( container . getNodeId ( ) . getHost ( ) ) . getNetworkLocation ( ) ; CookieContainerRequest assigned = getMatchingRequestWithPriority ( container , location ) ; doBookKeepingForAssignedContainer ( assigned , container , location , false ) ; return assigned ; } @ Override public CookieContainerRequest assignReUsedContainer ( Container container , boolean honorLocality ) { if ( ! honorLocality ) { String location = heldContainers . get ( container . getId ( ) ) . getRack ( ) ; CookieContainerRequest assigned = getMatchingRequestWithoutPriority ( container , location , false ) ; doBookKeepingForAssignedContainer ( assigned , container , location , honorLocality ) ; return assigned ; } return null ; } ",No
"public class RmiConsumer extends DefaultConsumer < BeanExchange > implements InvocationHandler { private final RmiEndpoint endpoint ; private Remote stub ; private Remote proxy ; public RmiConsumer ( RmiEndpoint endpoint , Processor processor ) { super ( endpoint , processor ) ; this . endpoint = endpoint ; } @ Override protected void doStart ( ) throws Exception { Class [ ] interfaces = new Class [ endpoint . getRemoteInterfaces ( ) . size ( ) ] ; endpoint . getRemoteInterfaces ( ) . toArray ( interfaces ) ; proxy = ( Remote ) Proxy . newProxyInstance ( endpoint . getClassLoader ( ) , interfaces , this ) ; stub = UnicastRemoteObject . exportObject ( proxy , endpoint . getPort ( ) ) ; try { Registry registry = endpoint . getRegistry ( ) ; String name = endpoint . getName ( ) ; registry . bind ( name , stub ) ; } catch ( Exception e ) { try { UnicastRemoteObject . unexportObject ( stub , true ) ; } catch ( Throwable ignore ) { } stub = null ; throw e ; } super . doStart ( ) ; } @ Override protected void doStop ( ) throws Exception { super . doStop ( ) ; try { Registry registry = endpoint . getRegistry ( ) ; registry . unbind ( endpoint . getName ( ) ) ; } catch ( Throwable e ) { } UnicastRemoteObject . unexportObject ( proxy , true ) ; } public Object invoke ( Object proxy , Method method , Object [ ] args ) throws Throwable { if ( ! isStarted ( ) ) { throw new IllegalStateException ( ""The endpoint is not active: "" + getEndpoint ( ) . getEndpointUri ( ) ) ; } BeanInvocation invocation = new BeanInvocation ( method , args ) ; BeanExchange exchange = getEndpoint ( ) . createExchange ( ) ; exchange . setInvocation ( invocation ) ; getProcessor ( ) . process ( exchange ) ; Throwable fault = exchange . getException ( ) ; if ( fault != null ) { throw new InvocationTargetException ( fault ) ; } return exchange . getOut ( ) . getBody ( ) ; } public Remote getProxy ( ) { return proxy ; } public Remote getStub ( ) { return stub ; } }",No
"public class BuildResultsListAction extends AbstractBuildAction { private static final Logger logger = LoggerFactory . getLogger ( BuildResultsListAction . class ) ; private Project project ; private Collection < BuildResult > buildResults ; private Collection < String > selectedBuildResults ; private int projectId ; private int projectGroupId ; private String projectName ; private String projectGroupName = """" ; public String execute ( ) throws ContinuumException { try { checkViewProjectGroupAuthorization ( getProjectGroupName ( ) ) ; } catch ( AuthorizationRequiredException e ) { return REQUIRES_AUTHORIZATION ; } project = getContinuum ( ) . getProject ( projectId ) ; buildResults = getContinuum ( ) . getBuildResultsForProject ( projectId ) ; return SUCCESS ; } public String remove ( ) throws ContinuumException { try { checkModifyProjectGroupAuthorization ( getProjectGroupName ( ) ) ; } catch ( AuthorizationRequiredException e ) { return REQUIRES_AUTHORIZATION ; } if ( this . isConfirmed ( ) ) { if ( selectedBuildResults != null && ! selectedBuildResults . isEmpty ( ) ) { for ( String id : selectedBuildResults ) { int buildId = Integer . parseInt ( id ) ; try { logger . info ( ""Removing BuildResult with id="" + buildId ) ; getContinuum ( ) . removeBuildResult ( buildId ) ; AuditLog event = new AuditLog ( ""Build Result id="" + buildId , AuditLogConstants . REMOVE_BUILD_RESULT ) ; event . setCategory ( AuditLogConstants . BUILD_RESULT ) ; event . setCurrentUser ( getPrincipal ( ) ) ; event . log ( ) ; } catch ( ContinuumException e ) { logger . error ( ""Error removing BuildResult with id="" + buildId ) ; addActionError ( getText ( ""buildResult.delete.error"" , ""Unable to delete build result"" , new Integer ( buildId ) . toString ( ) ) ) ; } } } return SUCCESS ; } else { List < String > buildResultsRemovable = new ArrayList < String > ( ) ; if ( selectedBuildResults != null && ! selectedBuildResults . isEmpty ( ) ) { for ( String id : selectedBuildResults ) { int buildId = Integer . parseInt ( id ) ; try { if ( canRemoveBuildResult ( getContinuum ( ) . getBuildResult ( buildId ) ) ) { buildResultsRemovable . add ( Integer . toString ( buildId ) ) ; } else { this . addActionMessage ( getResourceBundle ( ) . getString ( ""buildResult.cannot.delete"" ) ) ; return SUCCESS ; } } catch ( BuildManagerException e ) { logger . error ( e . getMessage ( ) ) ; throw new ContinuumException ( e . getMessage ( ) , e ) ; } } } this . setSelectedBuildResults ( buildResultsRemovable ) ; } return CONFIRM ; } public int getProjectId ( ) { return projectId ; } public void setProjectId ( int projectId ) { this . projectId = projectId ; } public Collection < BuildResult > getBuildResults ( ) { return buildResults ; } public String getProjectName ( ) { return projectName ; } public void setProjectName ( String projectName ) { this . projectName = projectName ; } public Project getProject ( ) { return project ; } public String getProjectGroupName ( ) throws ContinuumException { if ( StringUtils . isEmpty ( projectGroupName ) ) { projectGroupName = getContinuum ( ) . getProject ( projectId ) . getProjectGroup ( ) . getName ( ) ; } return projectGroupName ; } public Collection < String > getSelectedBuildResults ( ) { return selectedBuildResults ; } public void setSelectedBuildResults ( Collection < String > selectedBuildResults ) { this . selectedBuildResults = selectedBuildResults ; } public int getProjectGroupId ( ) { return projectGroupId ; } public void setProjectGroupId ( int projectGroupId ) { this . projectGroupId = projectGroupId ; } }",Smelly
public abstract class AbstractProducibleDescription extends AbstractAspectalizableDescription implements ProducibleDescription { protected String className ; protected String name ; protected boolean createId = true ; public String getClassName ( ) { return className ; } public String getName ( ) { return name ; } public void setClassName ( String string ) { className = string ; } public void setName ( String string ) { name = string ; } public boolean createId ( ) { return this . createId ; } public void setCreateId ( boolean value ) { this . createId = value ; } },Smelly
"public class DefaultSelectionListBuilder implements SelectionListBuilder , Serviceable { private ServiceManager serviceManager ; public void service ( ServiceManager manager ) throws ServiceException { this . serviceManager = manager ; } public SelectionList build ( Element selectionListElement , Datatype datatype ) throws Exception { SelectionList selectionList ; String src = selectionListElement . getAttribute ( ""src"" ) ; if ( src . length ( ) > 0 ) { boolean dynamic = DomHelper . getAttributeAsBoolean ( selectionListElement , ""dynamic"" , false ) ; if ( ! dynamic ) { selectionListElement = readSelectionList ( src ) ; selectionList = buildStaticList ( selectionListElement , datatype ) ; } else { selectionList = new DynamicSelectionList ( datatype , src , serviceManager ) ; } } else { selectionList = buildStaticList ( selectionListElement , datatype ) ; } return selectionList ; } private SelectionList buildStaticList ( Element selectionListElement , Datatype datatype ) throws Exception { StaticSelectionList selectionList = new StaticSelectionList ( datatype ) ; Convertor convertor = null ; Convertor . FormatCache formatCache = new DefaultFormatCache ( ) ; NodeList children = selectionListElement . getChildNodes ( ) ; for ( int i = 0 ; children . item ( i ) != null ; i ++ ) { Node node = children . item ( i ) ; if ( convertor == null && node instanceof Element && Constants . WD_NS . equals ( node . getNamespaceURI ( ) ) && ""convertor"" . equals ( node . getLocalName ( ) ) ) { Element convertorConfigElement = ( Element ) node ; try { convertor = datatype . getBuilder ( ) . buildConvertor ( convertorConfigElement ) ; } catch ( Exception e ) { throw new SAXException ( ""Error building convertor from convertor configuration embedded in selection list XML."" , e ) ; } } else if ( node instanceof Element && Constants . WD_NS . equals ( node . getNamespaceURI ( ) ) && ""item"" . equals ( node . getLocalName ( ) ) ) { if ( convertor == null ) { convertor = datatype . getConvertor ( ) ; } Element element = ( Element ) node ; String stringValue = element . getAttribute ( ""value"" ) ; Object value ; if ( """" . equals ( stringValue ) ) { value = null ; } else { value = convertor . convertFromString ( stringValue , Locale . US , formatCache ) ; if ( value == null ) { throw new Exception ( ""Could not convert the value \"""" + stringValue + ""\"" to the type "" + datatype . getDescriptiveName ( ) + "", defined at "" + DomHelper . getLocation ( element ) ) ; } } XMLizable label = null ; Element labelEl = DomHelper . getChildElement ( element , Constants . WD_NS , ""label"" ) ; if ( labelEl != null ) { label = DomHelper . compileElementContent ( labelEl ) ; } selectionList . addItem ( value , label ) ; } } return selectionList ; } private Element readSelectionList ( String src ) throws Exception { SourceResolver resolver = null ; Source source = null ; try { resolver = ( SourceResolver ) serviceManager . lookup ( SourceResolver . ROLE ) ; source = resolver . resolveURI ( src ) ; InputSource inputSource = new InputSource ( source . getInputStream ( ) ) ; inputSource . setSystemId ( source . getURI ( ) ) ; Document document = DomHelper . parse ( inputSource ) ; Element selectionListElement = document . getDocumentElement ( ) ; if ( ! Constants . WD_NS . equals ( selectionListElement . getNamespaceURI ( ) ) || ! ""selection-list"" . equals ( selectionListElement . getLocalName ( ) ) ) throw new Exception ( ""Excepted a wd:selection-list element at "" + DomHelper . getLocation ( selectionListElement ) ) ; return selectionListElement ; } finally { if ( source != null ) resolver . release ( source ) ; if ( resolver != null ) serviceManager . release ( resolver ) ; } } }",No
"public class LdapFilterUtils { public static String getFilter ( IValue value ) { if ( value . isString ( ) ) { return ""("" + value . getAttribute ( ) . getDescription ( ) + ""="" + getEncodedValue ( value . getStringValue ( ) ) + "")"" ; } else { StringBuffer filter = new StringBuffer ( ) ; filter . append ( ""("" ) ; filter . append ( value . getAttribute ( ) . getDescription ( ) ) ; filter . append ( ""="" ) ; byte [ ] bytes = value . getBinaryValue ( ) ; for ( int i = 0 ; i < bytes . length ; i ++ ) { int b = ( int ) bytes [ i ] ; if ( b < 0 ) { b = 256 + b ; } String s = Integer . toHexString ( b ) ; filter . append ( ""\\"" ) ; if ( s . length ( ) == 1 ) { filter . append ( ""0"" ) ; } filter . append ( s ) ; } filter . append ( "")"" ) ; return filter . toString ( ) ; } } public static String getEncodedValue ( String value ) { value = value . replaceAll ( ""\\\\"" , ""\\\\5c"" ) ; value = value . replaceAll ( """" + '\u0000' , ""\\\\00"" ) ; value = value . replaceAll ( ""\\*"" , ""\\\\2a"" ) ; value = value . replaceAll ( ""\\("" , ""\\\\28"" ) ; value = value . replaceAll ( ""\\)"" , ""\\\\29"" ) ; return value ; } }",No
"public class PizzaImpl implements Pizza { public OrderPizzaResponseType orderPizza ( OrderPizzaType body , CallerIDHeaderType callerID ) { OrderPizzaResponseType resp = new OrderPizzaResponseType ( ) ; if ( body . getToppings ( ) . getTopping ( ) . get ( 0 ) . contains ( ""NoHeader"" ) ) { resp . setMinutesUntilReady ( 100 ) ; } else { resp . setMinutesUntilReady ( 100 + Integer . parseInt ( callerID . getPhoneNumber ( ) ) ) ; } return resp ; } }",No
" public static class NonNullValidator implements Validator { @ Override public void ensureValid ( String name , Object value ) { if ( value == null ) { throw new ConfigException ( name , ""null"" , ""entry must be non null"" ) ; } } public String toString ( ) { return ""non-null string"" ; } ",No
"public class DataTableTag extends UIComponentTag { private String first ; private String rows ; private String value ; private String var ; private String bgcolor ; private String border ; private String cellpadding ; private String cellspacing ; private String columnClasses ; private String dir ; private String footerClass ; private String frame ; private String headerClass ; private String lang ; private String onclick ; private String ondblclick ; private String onkeydown ; private String onkeypress ; private String onkeyup ; private String onmousedown ; private String onmousemove ; private String onmouseout ; private String onmouseover ; private String onmouseup ; private String rowClasses ; private String rules ; private String style ; private String styleClass ; private String summary ; private String title ; private String width ; public void setFirst ( String first ) { this . first = first ; } public void setRows ( String rows ) { this . rows = rows ; } public void setValue ( String value ) { this . value = value ; } public void setVar ( String var ) { this . var = var ; } public void setBgcolor ( String bgcolor ) { this . bgcolor = bgcolor ; } public void setBorder ( String border ) { this . border = border ; } public void setCellpadding ( String cellpadding ) { this . cellpadding = cellpadding ; } public void setCellspacing ( String cellspacing ) { this . cellspacing = cellspacing ; } public void setColumnClasses ( String columnClasses ) { this . columnClasses = columnClasses ; } public void setDir ( String dir ) { this . dir = dir ; } public void setFooterClass ( String footerClass ) { this . footerClass = footerClass ; } public void setFrame ( String frame ) { this . frame = frame ; } public void setHeaderClass ( String headerClass ) { this . headerClass = headerClass ; } public void setLang ( String lang ) { this . lang = lang ; } public void setOnclick ( String onclick ) { this . onclick = onclick ; } public void setOndblclick ( String ondblclick ) { this . ondblclick = ondblclick ; } public void setOnkeydown ( String onkeydown ) { this . onkeydown = onkeydown ; } public void setOnkeypress ( String onkeypress ) { this . onkeypress = onkeypress ; } public void setOnkeyup ( String onkeyup ) { this . onkeyup = onkeyup ; } public void setOnmousedown ( String onmousedown ) { this . onmousedown = onmousedown ; } public void setOnmousemove ( String onmousemove ) { this . onmousemove = onmousemove ; } public void setOnmouseout ( String onmouseout ) { this . onmouseout = onmouseout ; } public void setOnmouseover ( String onmouseover ) { this . onmouseover = onmouseover ; } public void setOnmouseup ( String onmouseup ) { this . onmouseup = onmouseup ; } public void setRowClasses ( String rowClasses ) { this . rowClasses = rowClasses ; } public void setRules ( String rules ) { this . rules = rules ; } public void setStyle ( String style ) { this . style = style ; } public void setStyleClass ( String styleClass ) { this . styleClass = styleClass ; } public void setSummary ( String summary ) { this . summary = summary ; } public void setTitle ( String title ) { this . title = title ; } public void setWidth ( String width ) { this . width = width ; } public String getRendererType ( ) { return ""javax.faces.Table"" ; } public String getComponentType ( ) { return ""javax.faces.HtmlDataTable"" ; } protected void setProperties ( UIComponent component ) { super . setProperties ( component ) ; UIData data ; try { data = ( UIData ) component ; } catch ( ClassCastException cce ) { throw new FacesException ( ""Tag <"" + getClass ( ) . getName ( ) + ""> expected UIData. "" + ""Got <"" + component . getClass ( ) . getName ( ) + "">"" ) ; } if ( first != null ) { if ( FacesUtils . isExpression ( first ) ) { data . setValueBinding ( ""first"" , createValueBinding ( first ) ) ; } else { data . setFirst ( Integer . parseInt ( first ) ) ; } } if ( rows != null ) { if ( FacesUtils . isExpression ( rows ) ) { data . setValueBinding ( ""rows"" , createValueBinding ( rows ) ) ; } else { data . setRows ( Integer . parseInt ( rows ) ) ; } } if ( value != null ) { if ( FacesUtils . isExpression ( value ) ) { data . setValueBinding ( ""value"" , createValueBinding ( value ) ) ; } else { data . setValue ( value ) ; } } data . setVar ( var ) ; setProperty ( component , ""bgcolor"" , bgcolor ) ; setIntegerProperty ( component , ""border"" , border ) ; setProperty ( component , ""cellpadding"" , cellpadding ) ; setProperty ( component , ""cellspacing"" , cellspacing ) ; setProperty ( component , ""columnClasses"" , columnClasses ) ; setProperty ( component , ""dir"" , dir ) ; setProperty ( component , ""footerClass"" , footerClass ) ; setProperty ( component , ""frame"" , frame ) ; setProperty ( component , ""headerClass"" , headerClass ) ; setProperty ( component , ""lang"" , lang ) ; setProperty ( component , ""onclick"" , onclick ) ; setProperty ( component , ""ondblclick"" , ondblclick ) ; setProperty ( component , ""onkeydown"" , onkeydown ) ; setProperty ( component , ""onkeypress"" , onkeypress ) ; setProperty ( component , ""onkeyup"" , onkeyup ) ; setProperty ( component , ""onmousedown"" , onmousedown ) ; setProperty ( component , ""onmousemove"" , onmousemove ) ; setProperty ( component , ""onmouseout"" , onmouseout ) ; setProperty ( component , ""onmouseover"" , onmouseover ) ; setProperty ( component , ""onmouseup"" , onmouseup ) ; setProperty ( component , ""rowClasses"" , rowClasses ) ; setProperty ( component , ""rules"" , rules ) ; setProperty ( component , ""style"" , style ) ; setProperty ( component , ""styleClass"" , styleClass ) ; setProperty ( component , ""summary"" , summary ) ; setProperty ( component , ""title"" , title ) ; setProperty ( component , ""width"" , width ) ; } public void recycle ( ) { super . recycle ( ) ; first = null ; rows = null ; value = null ; var = null ; bgcolor = null ; border = null ; cellpadding = null ; cellspacing = null ; columnClasses = null ; dir = null ; footerClass = null ; frame = null ; headerClass = null ; lang = null ; onclick = null ; ondblclick = null ; onkeydown = null ; onkeypress = null ; onkeyup = null ; onmousedown = null ; onmousemove = null ; onmouseout = null ; onmouseover = null ; onmouseup = null ; rowClasses = null ; rules = null ; style = null ; styleClass = null ; summary = null ; title = null ; width = null ; } }",Smelly
"public class ConfigurationCacheService { private static final Logger LOG = LoggerFactory . getLogger ( ConfigurationCacheService . class ) ; private final ZooKeeperCache cache ; private ZooKeeperDataCache < TenantInfo > propertiesCache ; private ZooKeeperDataCache < Policies > policiesCache ; private ZooKeeperDataCache < ClusterData > clustersCache ; private ZooKeeperChildrenCache clustersListCache ; private ZooKeeperChildrenCache failureDomainListCache ; private ZooKeeperDataCache < NamespaceIsolationPolicies > namespaceIsolationPoliciesCache ; private ZooKeeperDataCache < FailureDomain > failureDomainCache ; public static final String POLICIES = ""policies"" ; public static final String FAILURE_DOMAIN = ""failureDomain"" ; public final String CLUSTER_FAILURE_DOMAIN_ROOT ; public static final String POLICIES_ROOT = ""/admin/policies"" ; private static final String CLUSTERS_ROOT = ""/admin/clusters"" ; public ConfigurationCacheService ( ZooKeeperCache cache ) throws PulsarServerException { this ( cache , null ) ; } public ConfigurationCacheService ( ZooKeeperCache cache , String configuredClusterName ) throws PulsarServerException { this . cache = cache ; initZK ( ) ; this . propertiesCache = new ZooKeeperDataCache < TenantInfo > ( cache ) { @ Override public TenantInfo deserialize ( String path , byte [ ] content ) throws Exception { return ObjectMapperFactory . getThreadLocal ( ) . readValue ( content , TenantInfo . class ) ; } } ; this . policiesCache = new ZooKeeperDataCache < Policies > ( cache ) { @ Override public Policies deserialize ( String path , byte [ ] content ) throws Exception { return ObjectMapperFactory . getThreadLocal ( ) . readValue ( content , Policies . class ) ; } } ; this . clustersCache = new ZooKeeperDataCache < ClusterData > ( cache ) { @ Override public ClusterData deserialize ( String path , byte [ ] content ) throws Exception { return ObjectMapperFactory . getThreadLocal ( ) . readValue ( content , ClusterData . class ) ; } } ; this . clustersListCache = new ZooKeeperChildrenCache ( cache , CLUSTERS_ROOT ) ; CLUSTER_FAILURE_DOMAIN_ROOT = CLUSTERS_ROOT + ""/"" + configuredClusterName + ""/"" + FAILURE_DOMAIN ; if ( isNotBlank ( configuredClusterName ) ) { createFailureDomainRoot ( cache . getZooKeeper ( ) , CLUSTER_FAILURE_DOMAIN_ROOT ) ; this . failureDomainListCache = new ZooKeeperChildrenCache ( cache , CLUSTER_FAILURE_DOMAIN_ROOT ) ; } this . namespaceIsolationPoliciesCache = new ZooKeeperDataCache < NamespaceIsolationPolicies > ( cache ) { @ Override @ SuppressWarnings ( ""unchecked"" ) public NamespaceIsolationPolicies deserialize ( String path , byte [ ] content ) throws Exception { return new NamespaceIsolationPolicies ( ( Map < String , NamespaceIsolationData > ) ObjectMapperFactory . getThreadLocal ( ) . readValue ( content , new TypeReference < Map < String , NamespaceIsolationData > > ( ) { } ) ) ; } } ; this . failureDomainCache = new ZooKeeperDataCache < FailureDomain > ( cache ) { @ Override public FailureDomain deserialize ( String path , byte [ ] content ) throws Exception { return ObjectMapperFactory . getThreadLocal ( ) . readValue ( content , FailureDomain . class ) ; } } ; } private void createFailureDomainRoot ( ZooKeeper zk , String path ) { try { final String clusterZnodePath = Paths . get ( path ) . getParent ( ) . toString ( ) ; if ( zk . exists ( clusterZnodePath , false ) != null && zk . exists ( path , false ) == null ) { try { byte [ ] data = """" . getBytes ( ) ; ZkUtils . createFullPathOptimistic ( zk , path , data , Ids . OPEN_ACL_UNSAFE , CreateMode . PERSISTENT ) ; LOG . info ( ""Successfully created failure-domain znode at {}"" , path ) ; } catch ( KeeperException . NodeExistsException e ) { } } } catch ( KeeperException . NodeExistsException e ) { } catch ( Exception e ) { LOG . warn ( ""Failed to create failure-domain znode {} "" , path , e ) ; } } private void initZK ( ) throws PulsarServerException { String [ ] paths = new String [ ] { CLUSTERS_ROOT , POLICIES_ROOT } ; try { ZooKeeper zk = cache . getZooKeeper ( ) ; for ( String path : paths ) { try { if ( zk . exists ( path , false ) == null ) { ZkUtils . createFullPathOptimistic ( zk , path , new byte [ 0 ] , Ids . OPEN_ACL_UNSAFE , CreateMode . PERSISTENT ) ; } } catch ( KeeperException . NodeExistsException e ) { } } } catch ( Exception e ) { LOG . error ( e . getMessage ( ) , e ) ; throw new PulsarServerException ( e ) ; } } public ZooKeeperCache cache ( ) { return cache ; } public ZooKeeperDataCache < TenantInfo > propertiesCache ( ) { return this . propertiesCache ; } public ZooKeeperDataCache < Policies > policiesCache ( ) { return this . policiesCache ; } public ZooKeeperDataCache < ClusterData > clustersCache ( ) { return this . clustersCache ; } public ZooKeeperChildrenCache clustersListCache ( ) { return this . clustersListCache ; } public ZooKeeperChildrenCache failureDomainListCache ( ) { return this . failureDomainListCache ; } public ZooKeeper getZooKeeper ( ) { return this . cache . getZooKeeper ( ) ; } public ZooKeeperDataCache < NamespaceIsolationPolicies > namespaceIsolationPoliciesCache ( ) { return this . namespaceIsolationPoliciesCache ; } public ZooKeeperDataCache < FailureDomain > failureDomainCache ( ) { return this . failureDomainCache ; } }",No
"public class AuthRequest { public static final String _rcsid = ""@(#)$Id: AuthRequest.java 988245 2010-08-23 18:39:35Z kwright $"" ; protected String userID ; protected String className ; protected String identifyingString ; protected ConfigParams configParameters ; protected int maxConnections ; protected boolean answerComplete = false ; protected AuthorizationResponse answerResponse = null ; protected Throwable answerException = null ; public AuthRequest ( String userID , String className , String identifyingString , ConfigParams configParameters , int maxConnections ) { this . userID = userID ; this . className = className ; this . identifyingString = identifyingString ; this . configParameters = configParameters ; this . maxConnections = maxConnections ; } public String getUserID ( ) { return userID ; } public String getClassName ( ) { return className ; } public String getIdentifyingString ( ) { return identifyingString ; } public ConfigParams getConfigurationParams ( ) { return configParameters ; } public int getMaxConnections ( ) { return maxConnections ; } public void waitForComplete ( ) throws InterruptedException { synchronized ( this ) { if ( answerComplete ) return ; this . wait ( ) ; } } public void completeRequest ( AuthorizationResponse answerResponse , Throwable answerException ) { synchronized ( this ) { if ( answerComplete ) return ; answerComplete = true ; this . answerResponse = answerResponse ; this . answerException = answerException ; this . notifyAll ( ) ; } } public AuthorizationResponse getAnswerResponse ( ) { return answerResponse ; } public Throwable getAnswerException ( ) { return answerException ; } }",Smelly
 public static class Flags { public File directory = null ; public boolean ignoreErrors = true ; public String token = TOKEN_DEFAULT ; public CodeFormat format = null ; public String name = null ; public String suffix = null ; ,Smelly
"public class ClusterTest { final Double TOPOLOGY_WORKER_DEFAULT_MEMORY_ALLOCATION = 768.0 ; private Map < String , Object > getConfig ( String key , Object value ) { Map < String , Object > topConf = getEmptyConfig ( ) ; topConf . put ( key , value ) ; return topConf ; } private Map < String , Object > getEmptyConfig ( ) { Map < String , Object > topConf = new HashMap < > ( ) ; return topConf ; } private Map < String , Object > getPopulatedConfig ( ) { Map < String , Object > topConf = new HashMap < > ( ) ; topConf . put ( Config . TOPOLOGY_WORKER_GC_CHILDOPTS , ""-Xmx128m"" ) ; topConf . put ( Config . WORKER_GC_CHILDOPTS , ""-Xmx256m"" ) ; topConf . put ( Config . TOPOLOGY_WORKER_CHILDOPTS , ""-Xmx512m"" ) ; topConf . put ( Config . WORKER_CHILDOPTS , ""-Xmx768m"" ) ; topConf . put ( Config . WORKER_HEAP_MEMORY_MB , 1024 ) ; topConf . put ( Config . TOPOLOGY_WORKER_LOGWRITER_CHILDOPTS , ""-Xmx64m"" ) ; return topConf ; } private void singleValueTest ( String key , String value , double expectedValue ) { Map < String , Object > topConf = getConfig ( key , value ) ; Assert . assertEquals ( expectedValue , Cluster . getAssignedMemoryForSlot ( topConf ) . doubleValue ( ) , 0 ) ; } @ Test public void getAssignedMemoryForSlot_allNull ( ) { Map < String , Object > topConf = getEmptyConfig ( ) ; Assert . assertEquals ( TOPOLOGY_WORKER_DEFAULT_MEMORY_ALLOCATION , Cluster . getAssignedMemoryForSlot ( topConf ) ) ; } @ Test public void getAssignedMemoryForSlot_topologyWorkerGcChildopts ( ) { singleValueTest ( Config . TOPOLOGY_WORKER_GC_CHILDOPTS , ""-Xmx128m"" , 128.0 ) ; } @ Test public void getAssignedMemoryForSlot_workerGcChildopts ( ) { singleValueTest ( Config . WORKER_GC_CHILDOPTS , ""-Xmx256m"" , 256.0 ) ; } @ Test public void getAssignedMemoryForSlot_topologyWorkerChildopts ( ) { singleValueTest ( Config . TOPOLOGY_WORKER_CHILDOPTS , ""-Xmx512m"" , 512.0 ) ; } @ Test public void getAssignedMemoryForSlot_workerChildopts ( ) { singleValueTest ( Config . WORKER_CHILDOPTS , ""-Xmx768m"" , 768.0 ) ; } @ Test public void getAssignedMemoryForSlot_workerHeapMemoryMb ( ) { Map < String , Object > topConf = getConfig ( Config . WORKER_HEAP_MEMORY_MB , 1024 ) ; Assert . assertEquals ( 1024.0 , Cluster . getAssignedMemoryForSlot ( topConf ) . doubleValue ( ) , 0 ) ; } @ Test public void getAssignedMemoryForSlot_topologyWorkerLwChildopts ( ) { singleValueTest ( Config . TOPOLOGY_WORKER_LOGWRITER_CHILDOPTS , ""-Xmx64m"" , TOPOLOGY_WORKER_DEFAULT_MEMORY_ALLOCATION + 64.0 ) ; } @ Test public void getAssignedMemoryForSlot_all ( ) { Map < String , Object > topConf = getPopulatedConfig ( ) ; Assert . assertEquals ( 128.0 + 64.0 , Cluster . getAssignedMemoryForSlot ( topConf ) . doubleValue ( ) , 0 ) ; } }",Smelly
"public class AuxServicesEvent extends AbstractEvent < AuxServicesEventType > { private final String user ; private final String serviceId ; private final ByteBuffer serviceData ; private final ApplicationId appId ; private final Container container ; public AuxServicesEvent ( AuxServicesEventType eventType , ApplicationId appId ) { this ( eventType , null , appId , null , null ) ; } public AuxServicesEvent ( AuxServicesEventType eventType , Container container ) { this ( eventType , null , container . getContainerId ( ) . getApplicationAttemptId ( ) . getApplicationId ( ) , null , null , container ) ; } public AuxServicesEvent ( AuxServicesEventType eventType , String user , ApplicationId appId , String serviceId , ByteBuffer serviceData ) { this ( eventType , user , appId , serviceId , serviceData , null ) ; } public AuxServicesEvent ( AuxServicesEventType eventType , String user , ApplicationId appId , String serviceId , ByteBuffer serviceData , Container container ) { super ( eventType ) ; this . user = user ; this . appId = appId ; this . serviceId = serviceId ; this . serviceData = serviceData ; this . container = container ; } public String getServiceID ( ) { return serviceId ; } public ByteBuffer getServiceData ( ) { return serviceData ; } public String getUser ( ) { return user ; } public ApplicationId getApplicationID ( ) { return appId ; } public Container getContainer ( ) { return container ; } }",No
"public class OS400FTPEntryParser extends ConfigurableFTPFileEntryParserImpl { private static final String DEFAULT_DATE_FORMAT = ""yy/MM/dd HH:mm:ss"" ; private static final String REGEX = ""(\\S+)\\s+"" + ""(\\d+)\\s+"" + ""(\\S+)\\s+(\\S+)\\s+"" + ""(\\*\\S+)\\s+"" + ""(\\S+/?)\\s*"" ; public OS400FTPEntryParser ( ) { this ( null ) ; } public OS400FTPEntryParser ( FTPClientConfig config ) { super ( REGEX ) ; configure ( config ) ; } public FTPFile parseFTPEntry ( String entry ) { FTPFile file = new FTPFile ( ) ; file . setRawListing ( entry ) ; int type ; if ( matches ( entry ) ) { String usr = group ( 1 ) ; String filesize = group ( 2 ) ; String datestr = group ( 3 ) + "" "" + group ( 4 ) ; String typeStr = group ( 5 ) ; String name = group ( 6 ) ; try { file . setTimestamp ( super . parseTimestamp ( datestr ) ) ; } catch ( ParseException e ) { } if ( typeStr . equalsIgnoreCase ( ""*STMF"" ) ) { type = FTPFile . FILE_TYPE ; } else if ( typeStr . equalsIgnoreCase ( ""*DIR"" ) ) { type = FTPFile . DIRECTORY_TYPE ; } else { type = FTPFile . UNKNOWN_TYPE ; } file . setType ( type ) ; file . setUser ( usr ) ; try { file . setSize ( Long . parseLong ( filesize ) ) ; } catch ( NumberFormatException e ) { } if ( name . endsWith ( ""/"" ) ) { name = name . substring ( 0 , name . length ( ) - 1 ) ; } int pos = name . lastIndexOf ( '/' ) ; if ( pos > - 1 ) { name = name . substring ( pos + 1 ) ; } file . setName ( name ) ; return file ; } return null ; } @ Override protected FTPClientConfig getDefaultConfiguration ( ) { return new FTPClientConfig ( FTPClientConfig . SYST_OS400 , DEFAULT_DATE_FORMAT , null , null , null , null ) ; } }",No
"public class ConstantTest extends LanguageTestSupport { public void testSimpleExpressions ( ) throws Exception { assertExpression ( ""a value"" , ""a value"" ) ; } public void testPredicates ( ) throws Exception { assertPredicate ( ""another value"" ) ; } protected String getLanguageName ( ) { return ""constant"" ; } }",No
"public class UpdateBuilder { private final PrefixHandler prefixHandler ; private final WhereQuadHolder whereProcessor ; private List < QuadHolder > inserts = new ArrayList < QuadHolder > ( ) ; private List < QuadHolder > deletes = new ArrayList < QuadHolder > ( ) ; private Map < Var , Node > values ; private Node with ; public UpdateBuilder ( ) { this . prefixHandler = new PrefixHandler ( ) ; this . whereProcessor = new WhereQuadHolder ( prefixHandler ) ; this . values = new HashMap < Var , Node > ( ) ; this . with = null ; } public UpdateBuilder ( PrologClause < ? > prologClause ) { this ( prologClause . getPrologHandler ( ) . getPrefixes ( ) ) ; } public UpdateBuilder ( PrefixMapping pMap ) { this . prefixHandler = new PrefixHandler ( pMap ) ; this . whereProcessor = new WhereQuadHolder ( prefixHandler ) ; } private ExtendedIterator < Quad > getQuads ( Collection < QuadHolder > holders ) { ExtendedIterator < Quad > result = NiceIterator . emptyIterator ( ) ; for ( QuadHolder holder : holders ) { result = result . andThen ( holder . setValues ( values ) . getQuads ( ) ) ; } return result ; } public Update build ( ) { if ( deletes . isEmpty ( ) && inserts . isEmpty ( ) ) { throw new IllegalStateException ( ""At least one delete or insert must be specified"" ) ; } if ( whereProcessor . isEmpty ( ) ) { return buildNoWhere ( ) ; } return buildWhere ( ) ; } public UpdateRequest buildRequest ( ) { UpdateRequest req = new UpdateRequest ( build ( ) ) ; req . setPrefixMapping ( prefixHandler . getPrefixes ( ) ) ; return req ; } public UpdateRequest appendTo ( UpdateRequest req ) { req . add ( build ( ) ) ; for ( Map . Entry < String , String > entry : prefixHandler . getPrefixes ( ) . getNsPrefixMap ( ) . entrySet ( ) ) { req . setPrefix ( entry . getKey ( ) , entry . getValue ( ) ) ; } return req ; } private Update buildNoWhere ( ) { if ( inserts . isEmpty ( ) ) { QuadDataAcc quadData = new QuadDataAcc ( getQuads ( deletes ) . mapWith ( new Function < Quad , Quad > ( ) { @ Override public Quad apply ( Quad arg0 ) { return check ( arg0 ) ; } } ) . toList ( ) ) ; return new UpdateDataDelete ( quadData ) ; } if ( deletes . isEmpty ( ) ) { QuadDataAcc quadData = new QuadDataAcc ( getQuads ( inserts ) . mapWith ( new Function < Quad , Quad > ( ) { @ Override public Quad apply ( Quad t ) { return check ( t ) ; } } ) . toList ( ) ) ; return new UpdateDataInsert ( quadData ) ; } throw new IllegalStateException ( ""Can not have both insert and delete without a where clause"" ) ; } private Update buildWhere ( ) { UpdateModify retval = new UpdateModify ( ) ; if ( with != null ) { Node graph = values . get ( with ) ; if ( graph == null ) { graph = with ; } retval . setWithIRI ( graph ) ; } QuadAcc acc ; Iterator < Quad > iter ; if ( ! inserts . isEmpty ( ) ) { retval . setHasInsertClause ( true ) ; acc = retval . getInsertAcc ( ) ; iter = getQuads ( inserts ) ; while ( iter . hasNext ( ) ) { acc . addQuad ( iter . next ( ) ) ; } } if ( ! deletes . isEmpty ( ) ) { retval . setHasDeleteClause ( true ) ; acc = retval . getDeleteAcc ( ) ; iter = getQuads ( deletes ) ; while ( iter . hasNext ( ) ) { acc . addQuad ( iter . next ( ) ) ; } } retval . setElement ( whereProcessor . setVars ( values ) . build ( ) ) ; return retval ; } public TriplePath makeTriplePath ( Object s , Object p , Object o ) { final Object po = AbstractQueryBuilder . makeNodeOrPath ( p , prefixHandler . getPrefixes ( ) ) ; if ( po instanceof Path ) { return new TriplePath ( makeNode ( s ) , ( Path ) po , makeNode ( o ) ) ; } else { return new TriplePath ( new Triple ( makeNode ( s ) , ( Node ) po , makeNode ( o ) ) ) ; } } public Node makeNode ( Object o ) { return AbstractQueryBuilder . makeNode ( o , prefixHandler . getPrefixes ( ) ) ; } public Var makeVar ( Object o ) { return AbstractQueryBuilder . makeVar ( o ) ; } public String quote ( String s ) { return AbstractQueryBuilder . quote ( s ) ; } public UpdateBuilder addInsert ( Object g , Object s , Object p , Object o ) { return addInsert ( new Quad ( makeNode ( g ) , makeNode ( s ) , makeNode ( p ) , makeNode ( o ) ) ) ; } public UpdateBuilder addInsert ( Quad quad ) { inserts . add ( new SingleQuadHolder ( quad ) ) ; return this ; } public UpdateBuilder addInsert ( Object s , Object p , Object o ) { addInsert ( new Triple ( makeNode ( s ) , makeNode ( p ) , makeNode ( o ) ) ) ; return this ; } public UpdateBuilder addInsert ( Triple t ) { inserts . add ( new SingleQuadHolder ( t ) ) ; return this ; } public UpdateBuilder addInsert ( Object g , Triple t ) { Quad q = new Quad ( AbstractQueryBuilder . makeNode ( g , prefixHandler . getPrefixes ( ) ) , t ) ; inserts . add ( new SingleQuadHolder ( q ) ) ; return this ; } public UpdateBuilder addInsert ( Model model ) { inserts . add ( new ModelQuadHolder ( model ) ) ; return this ; } public UpdateBuilder addInsert ( Collection < Triple > collection ) { inserts . add ( new CollectionQuadHolder ( collection ) ) ; return this ; } public UpdateBuilder addInsertQuads ( Collection < Quad > collection ) { inserts . add ( new QuadCollectionHolder ( collection ) ) ; return this ; } public UpdateBuilder addInsert ( Iterator < Triple > iter ) { inserts . add ( new CollectionQuadHolder ( iter ) ) ; return this ; } public UpdateBuilder addInsert ( Object g , Model model ) { inserts . add ( new ModelQuadHolder ( AbstractQueryBuilder . makeNode ( g , prefixHandler . getPrefixes ( ) ) , model ) ) ; return this ; } public UpdateBuilder addInsert ( Object g , Collection < Triple > collection ) { inserts . add ( new CollectionQuadHolder ( AbstractQueryBuilder . makeNode ( g , prefixHandler . getPrefixes ( ) ) , collection ) ) ; return this ; } public UpdateBuilder addInsert ( Object g , Iterator < Triple > iter ) { inserts . add ( new CollectionQuadHolder ( AbstractQueryBuilder . makeNode ( g , prefixHandler . getPrefixes ( ) ) , iter ) ) ; return this ; } public UpdateBuilder addInsert ( AbstractQueryBuilder < ? > queryBuilder ) { inserts . add ( new QBQuadHolder ( queryBuilder ) ) ; return this ; } public UpdateBuilder addInsert ( Object graph , AbstractQueryBuilder < ? > queryBuilder ) { inserts . add ( new QBQuadHolder ( AbstractQueryBuilder . makeNode ( graph , prefixHandler . getPrefixes ( ) ) , queryBuilder ) ) ; return this ; } public UpdateBuilder addDelete ( Object g , Object s , Object p , Object o ) { return addDelete ( new Quad ( AbstractQueryBuilder . makeNode ( g , prefixHandler . getPrefixes ( ) ) , AbstractQueryBuilder . makeNode ( s , prefixHandler . getPrefixes ( ) ) , AbstractQueryBuilder . makeNode ( p , prefixHandler . getPrefixes ( ) ) , AbstractQueryBuilder . makeNode ( o , prefixHandler . getPrefixes ( ) ) ) ) ; } public UpdateBuilder addDelete ( Quad quad ) { deletes . add ( new SingleQuadHolder ( quad ) ) ; return this ; } public UpdateBuilder addDeleteQuads ( Collection < Quad > collection ) { deletes . add ( new QuadCollectionHolder ( collection ) ) ; return this ; } public UpdateBuilder addDelete ( Object s , Object p , Object o ) { addDelete ( new Triple ( AbstractQueryBuilder . makeNode ( s , prefixHandler . getPrefixes ( ) ) , AbstractQueryBuilder . makeNode ( p , prefixHandler . getPrefixes ( ) ) , AbstractQueryBuilder . makeNode ( o , prefixHandler . getPrefixes ( ) ) ) ) ; return this ; } public UpdateBuilder addDelete ( Triple t ) { deletes . add ( new SingleQuadHolder ( t ) ) ; return this ; } public UpdateBuilder addDelete ( Object g , Triple t ) { Quad q = new Quad ( AbstractQueryBuilder . makeNode ( g , prefixHandler . getPrefixes ( ) ) , t ) ; deletes . add ( new SingleQuadHolder ( q ) ) ; return this ; } public UpdateBuilder addDelete ( Model model ) { deletes . add ( new ModelQuadHolder ( model ) ) ; return this ; } public UpdateBuilder addDelete ( Collection < Triple > collection ) { deletes . add ( new CollectionQuadHolder ( collection ) ) ; return this ; } public UpdateBuilder addDelete ( Iterator < Triple > iter ) { deletes . add ( new CollectionQuadHolder ( iter ) ) ; return this ; } public UpdateBuilder addDelete ( Object g , Model model ) { deletes . add ( new ModelQuadHolder ( AbstractQueryBuilder . makeNode ( g , prefixHandler . getPrefixes ( ) ) , model ) ) ; return this ; } public UpdateBuilder addDelete ( Object g , Collection < Triple > collection ) { deletes . add ( new CollectionQuadHolder ( AbstractQueryBuilder . makeNode ( g , prefixHandler . getPrefixes ( ) ) , collection ) ) ; return this ; } public UpdateBuilder addDelete ( Object g , Iterator < Triple > iter ) { deletes . add ( new CollectionQuadHolder ( AbstractQueryBuilder . makeNode ( g , prefixHandler . getPrefixes ( ) ) , iter ) ) ; return this ; } public UpdateBuilder addDelete ( AbstractQueryBuilder < ? > queryBuilder ) { deletes . add ( new QBQuadHolder ( queryBuilder ) ) ; return this ; } public UpdateBuilder addDelete ( Object graph , AbstractQueryBuilder < ? > queryBuilder ) { deletes . add ( new QBQuadHolder ( AbstractQueryBuilder . makeNode ( graph , prefixHandler . getPrefixes ( ) ) , queryBuilder ) ) ; return this ; } public UpdateBuilder addPrefix ( String pfx , Resource uri ) { return addPrefix ( pfx , uri . getURI ( ) ) ; } public UpdateBuilder addPrefix ( String pfx , Node uri ) { return addPrefix ( pfx , uri . getURI ( ) ) ; } public UpdateBuilder addPrefix ( String pfx , String uri ) { prefixHandler . addPrefix ( pfx , uri ) ; return this ; } public UpdateBuilder addPrefixes ( Map < String , String > prefixes ) { prefixHandler . addPrefixes ( prefixes ) ; return this ; } public UpdateBuilder addPrefixes ( PrefixMapping prefixes ) { prefixHandler . addPrefixes ( prefixes ) ; return this ; } public ExprFactory getExprFactory ( ) { return prefixHandler . getExprFactory ( ) ; } public void setVar ( Var var , Node value ) { if ( value == null ) { values . remove ( var ) ; } else { values . put ( var , value ) ; } } public void setVar ( Object var , Object value ) { if ( value == null ) { setVar ( AbstractQueryBuilder . makeVar ( var ) , null ) ; } else { setVar ( AbstractQueryBuilder . makeVar ( var ) , AbstractQueryBuilder . makeNode ( value , prefixHandler . getPrefixes ( ) ) ) ; } } private Quad check ( Quad q ) { if ( Var . isVar ( q . getGraph ( ) ) ) throw new QueryParseException ( ""Variables not permitted in data quad"" , - 1 , - 1 ) ; if ( Var . isVar ( q . getSubject ( ) ) || Var . isVar ( q . getPredicate ( ) ) || Var . isVar ( q . getObject ( ) ) ) throw new QueryParseException ( ""Variables not permitted in data quad"" , - 1 , - 1 ) ; if ( q . getSubject ( ) . isLiteral ( ) ) throw new QueryParseException ( ""Literals not allowed as subjects in data"" , - 1 , - 1 ) ; return q ; } public UpdateBuilder addAll ( WhereHandler whereHandler ) { whereProcessor . addAll ( whereHandler ) ; return this ; } public UpdateBuilder addWhere ( TriplePath t ) throws IllegalArgumentException { whereProcessor . addWhere ( t ) ; return this ; } public UpdateBuilder addWhere ( WhereClause < ? > whereClause ) throws IllegalArgumentException { whereProcessor . addAll ( whereClause . getWhereHandler ( ) ) ; return this ; } public UpdateBuilder addOptional ( TriplePath t ) throws IllegalArgumentException { whereProcessor . addOptional ( t ) ; return this ; } public UpdateBuilder addOptional ( WhereHandler whereHandler ) { whereProcessor . addOptional ( whereHandler ) ; return this ; } public UpdateBuilder addFilter ( String expression ) throws ParseException { whereProcessor . addFilter ( expression ) ; return this ; } public UpdateBuilder addSubQuery ( AbstractQueryBuilder < ? > subQuery ) { whereProcessor . addSubQuery ( subQuery ) ; return this ; } public UpdateBuilder addUnion ( AbstractQueryBuilder < ? > subQuery ) { whereProcessor . addUnion ( subQuery ) ; return this ; } public UpdateBuilder addGraph ( Node graph , WhereHandler subQuery ) { whereProcessor . addGraph ( graph , subQuery ) ; return this ; } public UpdateBuilder addBind ( Expr expr , Var var ) { whereProcessor . addBind ( expr , var ) ; return this ; } public UpdateBuilder addBind ( String expression , Var var ) throws ParseException { whereProcessor . addBind ( expression , var ) ; return this ; } public Node list ( Object ... objs ) { Node retval = NodeFactory . createBlankNode ( ) ; Node lastObject = retval ; for ( int i = 0 ; i < objs . length ; i ++ ) { Node n = makeNode ( objs [ i ] ) ; addWhere ( new TriplePath ( new Triple ( lastObject , RDF . first . asNode ( ) , n ) ) ) ; if ( i + 1 < objs . length ) { Node nextObject = NodeFactory . createBlankNode ( ) ; addWhere ( new TriplePath ( new Triple ( lastObject , RDF . rest . asNode ( ) , nextObject ) ) ) ; lastObject = nextObject ; } else { addWhere ( new TriplePath ( new Triple ( lastObject , RDF . rest . asNode ( ) , RDF . nil . asNode ( ) ) ) ) ; } } return retval ; } public UpdateBuilder addWhere ( Triple t ) { return addWhere ( new TriplePath ( t ) ) ; } public UpdateBuilder addWhere ( FrontsTriple t ) { return addWhere ( t . asTriple ( ) ) ; } public UpdateBuilder addWhere ( Object s , Object p , Object o ) { return addWhere ( makeTriplePath ( s , p , o ) ) ; } public UpdateBuilder addOptional ( Triple t ) { return addOptional ( new TriplePath ( t ) ) ; } public UpdateBuilder addOptional ( FrontsTriple t ) { return addOptional ( t . asTriple ( ) ) ; } public UpdateBuilder addOptional ( Object s , Object p , Object o ) { return addOptional ( makeTriplePath ( s , p , o ) ) ; } public UpdateBuilder addOptional ( AbstractQueryBuilder < ? > t ) { whereProcessor . addOptional ( t . getWhereHandler ( ) ) ; return this ; } public UpdateBuilder addFilter ( Expr expression ) { whereProcessor . addFilter ( expression ) ; return this ; } public UpdateBuilder addGraph ( Object graph , AbstractQueryBuilder < ? > subQuery ) { whereProcessor . addGraph ( makeNode ( graph ) , subQuery . getWhereHandler ( ) ) ; return this ; } public UpdateBuilder addBind ( Expr expression , Object var ) { whereProcessor . addBind ( expression , makeVar ( var ) ) ; return this ; } public UpdateBuilder addBind ( String expression , Object var ) throws ParseException { whereProcessor . addBind ( expression , makeVar ( var ) ) ; return this ; } public UpdateBuilder addMinus ( AbstractQueryBuilder < ? > t ) { whereProcessor . addMinus ( t ) ; return this ; } public UpdateBuilder with ( Object iri ) { if ( iri == null ) { with = null ; } Node n = makeNode ( iri ) ; if ( n . isLiteral ( ) ) { throw new IllegalArgumentException ( String . format ( ""IRI '%s' must not be a literal"" , iri ) ) ; } with = n ; return this ; } public UpdateDeleteWhere buildDeleteWhere ( ) { QuadAcc quadAcc = new QuadAcc ( whereProcessor . getQuads ( ) . toList ( ) ) ; return new UpdateDeleteWhere ( quadAcc ) ; } public UpdateDeleteWhere buildDeleteWhere ( AbstractQueryBuilder < ? > queryBuilder ) { QuadAcc quadAcc = new QuadAcc ( new QBQuadHolder ( queryBuilder ) . getQuads ( ) . toList ( ) ) ; return new UpdateDeleteWhere ( quadAcc ) ; } }",No
public class TemplateImage extends AbstractTemplateWidget { public static String DEFAULT_IMAGE_DATA = null ; public static boolean DEFAULT_SHOW_SAVE_AS_BUTTON = true ; public static boolean DEFAULT_SHOW_CLEAR_BUTTON = true ; public static boolean DEFAULT_SHOW_BROWSE_BUTTON = true ; private String imageData = DEFAULT_IMAGE_DATA ; private boolean showSaveAsButton = DEFAULT_SHOW_SAVE_AS_BUTTON ; private boolean showClearButton = DEFAULT_SHOW_CLEAR_BUTTON ; private boolean showBrowseButton = DEFAULT_SHOW_BROWSE_BUTTON ; private int imageWidth = TemplateWidget . DEFAULT_SIZE ; private int imageHeight = TemplateWidget . DEFAULT_SIZE ; public TemplateImage ( TemplateWidget parent ) { super ( parent ) ; } public int getImageHeight ( ) { return imageHeight ; } public String getImageData ( ) { return imageData ; } public int getImageWidth ( ) { return imageWidth ; } public boolean isShowBrowseButton ( ) { return showBrowseButton ; } public boolean isShowClearButton ( ) { return showClearButton ; } public boolean isShowSaveAsButton ( ) { return showSaveAsButton ; } public void setImageHeight ( int imageHeight ) { this . imageHeight = imageHeight ; } public void setImageData ( String imageData ) { this . imageData = imageData ; } public void setShowBrowseButton ( boolean showBrowseButton ) { this . showBrowseButton = showBrowseButton ; } public void setShowClearButton ( boolean showClearButton ) { this . showClearButton = showClearButton ; } public void setShowSaveAsButton ( boolean showSaveAsButton ) { this . showSaveAsButton = showSaveAsButton ; } public void setImageWidth ( int imageWidth ) { this . imageWidth = imageWidth ; } },Smelly
"public class HiveSessionImpl implements HiveSession { private final SessionHandle sessionHandle ; private String username ; private final String password ; private final HiveConf hiveConf ; private final SessionState sessionState ; private String ipAddress ; private static final String FETCH_WORK_SERDE_CLASS = ""org.apache.hadoop.hive.serde2.lazy.LazySimpleSerDe"" ; private static final Log LOG = LogFactory . getLog ( HiveSessionImpl . class ) ; private SessionManager sessionManager ; private OperationManager operationManager ; private IMetaStoreClient metastoreClient = null ; private final Set < OperationHandle > opHandleSet = new HashSet < OperationHandle > ( ) ; public HiveSessionImpl ( TProtocolVersion protocol , String username , String password , HiveConf serverhiveConf , Map < String , String > sessionConfMap , String ipAddress ) { this . username = username ; this . password = password ; this . sessionHandle = new SessionHandle ( protocol ) ; this . hiveConf = new HiveConf ( serverhiveConf ) ; this . ipAddress = ipAddress ; if ( sessionConfMap != null ) { for ( Map . Entry < String , String > entry : sessionConfMap . entrySet ( ) ) { hiveConf . verifyAndSet ( entry . getKey ( ) , entry . getValue ( ) ) ; } } hiveConf . set ( ConfVars . HIVESESSIONID . varname , sessionHandle . getHandleIdentifier ( ) . toString ( ) ) ; hiveConf . set ( ListSinkOperator . OUTPUT_FORMATTER , FetchFormatter . ThriftFormatter . class . getName ( ) ) ; hiveConf . setInt ( ListSinkOperator . OUTPUT_PROTOCOL , protocol . getValue ( ) ) ; sessionState = new SessionState ( hiveConf , username ) ; sessionState . setIsHiveServerQuery ( true ) ; SessionState . start ( sessionState ) ; } @ Override public TProtocolVersion getProtocolVersion ( ) { return sessionHandle . getProtocolVersion ( ) ; } @ Override public SessionManager getSessionManager ( ) { return sessionManager ; } @ Override public void setSessionManager ( SessionManager sessionManager ) { this . sessionManager = sessionManager ; } private OperationManager getOperationManager ( ) { return operationManager ; } @ Override public void setOperationManager ( OperationManager operationManager ) { this . operationManager = operationManager ; } @ Override public void open ( ) { SessionState . start ( sessionState ) ; } protected synchronized void acquire ( ) throws HiveSQLException { SessionState . setCurrentSessionState ( sessionState ) ; } protected synchronized void release ( ) { assert sessionState != null ; SessionState . detachSession ( ) ; } @ Override public SessionHandle getSessionHandle ( ) { return sessionHandle ; } @ Override public String getUsername ( ) { return username ; } @ Override public String getPassword ( ) { return password ; } @ Override public HiveConf getHiveConf ( ) { hiveConf . setVar ( HiveConf . ConfVars . HIVEFETCHOUTPUTSERDE , FETCH_WORK_SERDE_CLASS ) ; return hiveConf ; } @ Override public IMetaStoreClient getMetaStoreClient ( ) throws HiveSQLException { if ( metastoreClient == null ) { try { metastoreClient = new HiveMetaStoreClient ( getHiveConf ( ) ) ; } catch ( MetaException e ) { throw new HiveSQLException ( e ) ; } } return metastoreClient ; } @ Override public GetInfoValue getInfo ( GetInfoType getInfoType ) throws HiveSQLException { acquire ( ) ; try { switch ( getInfoType ) { case CLI_SERVER_NAME : return new GetInfoValue ( ""Hive"" ) ; case CLI_DBMS_NAME : return new GetInfoValue ( ""Apache Hive"" ) ; case CLI_DBMS_VER : return new GetInfoValue ( HiveVersionInfo . getVersion ( ) ) ; case CLI_MAX_COLUMN_NAME_LEN : return new GetInfoValue ( 128 ) ; case CLI_MAX_SCHEMA_NAME_LEN : return new GetInfoValue ( 128 ) ; case CLI_MAX_TABLE_NAME_LEN : return new GetInfoValue ( 128 ) ; case CLI_TXN_CAPABLE : default : throw new HiveSQLException ( ""Unrecognized GetInfoType value: "" + getInfoType . toString ( ) ) ; } } finally { release ( ) ; } } @ Override public OperationHandle executeStatement ( String statement , Map < String , String > confOverlay ) throws HiveSQLException { return executeStatementInternal ( statement , confOverlay , false ) ; } @ Override public OperationHandle executeStatementAsync ( String statement , Map < String , String > confOverlay ) throws HiveSQLException { return executeStatementInternal ( statement , confOverlay , true ) ; } private OperationHandle executeStatementInternal ( String statement , Map < String , String > confOverlay , boolean runAsync ) throws HiveSQLException { acquire ( ) ; OperationManager operationManager = getOperationManager ( ) ; ExecuteStatementOperation operation = operationManager . newExecuteStatementOperation ( getSession ( ) , statement , confOverlay , runAsync ) ; OperationHandle opHandle = operation . getHandle ( ) ; try { operation . run ( ) ; opHandleSet . add ( opHandle ) ; return opHandle ; } catch ( HiveSQLException e ) { if ( ! runAsync ) { operationManager . closeOperation ( opHandle ) ; } throw e ; } finally { release ( ) ; } } @ Override public OperationHandle getTypeInfo ( ) throws HiveSQLException { acquire ( ) ; OperationManager operationManager = getOperationManager ( ) ; GetTypeInfoOperation operation = operationManager . newGetTypeInfoOperation ( getSession ( ) ) ; OperationHandle opHandle = operation . getHandle ( ) ; try { operation . run ( ) ; opHandleSet . add ( opHandle ) ; return opHandle ; } catch ( HiveSQLException e ) { operationManager . closeOperation ( opHandle ) ; throw e ; } finally { release ( ) ; } } @ Override public OperationHandle getCatalogs ( ) throws HiveSQLException { acquire ( ) ; OperationManager operationManager = getOperationManager ( ) ; GetCatalogsOperation operation = operationManager . newGetCatalogsOperation ( getSession ( ) ) ; OperationHandle opHandle = operation . getHandle ( ) ; try { operation . run ( ) ; opHandleSet . add ( opHandle ) ; return opHandle ; } catch ( HiveSQLException e ) { operationManager . closeOperation ( opHandle ) ; throw e ; } finally { release ( ) ; } } @ Override public OperationHandle getSchemas ( String catalogName , String schemaName ) throws HiveSQLException { acquire ( ) ; OperationManager operationManager = getOperationManager ( ) ; GetSchemasOperation operation = operationManager . newGetSchemasOperation ( getSession ( ) , catalogName , schemaName ) ; OperationHandle opHandle = operation . getHandle ( ) ; try { operation . run ( ) ; opHandleSet . add ( opHandle ) ; return opHandle ; } catch ( HiveSQLException e ) { operationManager . closeOperation ( opHandle ) ; throw e ; } finally { release ( ) ; } } @ Override public OperationHandle getTables ( String catalogName , String schemaName , String tableName , List < String > tableTypes ) throws HiveSQLException { acquire ( ) ; OperationManager operationManager = getOperationManager ( ) ; MetadataOperation operation = operationManager . newGetTablesOperation ( getSession ( ) , catalogName , schemaName , tableName , tableTypes ) ; OperationHandle opHandle = operation . getHandle ( ) ; try { operation . run ( ) ; opHandleSet . add ( opHandle ) ; return opHandle ; } catch ( HiveSQLException e ) { operationManager . closeOperation ( opHandle ) ; throw e ; } finally { release ( ) ; } } @ Override public OperationHandle getTableTypes ( ) throws HiveSQLException { acquire ( ) ; OperationManager operationManager = getOperationManager ( ) ; GetTableTypesOperation operation = operationManager . newGetTableTypesOperation ( getSession ( ) ) ; OperationHandle opHandle = operation . getHandle ( ) ; try { operation . run ( ) ; opHandleSet . add ( opHandle ) ; return opHandle ; } catch ( HiveSQLException e ) { operationManager . closeOperation ( opHandle ) ; throw e ; } finally { release ( ) ; } } @ Override public OperationHandle getColumns ( String catalogName , String schemaName , String tableName , String columnName ) throws HiveSQLException { acquire ( ) ; OperationManager operationManager = getOperationManager ( ) ; GetColumnsOperation operation = operationManager . newGetColumnsOperation ( getSession ( ) , catalogName , schemaName , tableName , columnName ) ; OperationHandle opHandle = operation . getHandle ( ) ; try { operation . run ( ) ; opHandleSet . add ( opHandle ) ; return opHandle ; } catch ( HiveSQLException e ) { operationManager . closeOperation ( opHandle ) ; throw e ; } finally { release ( ) ; } } @ Override public OperationHandle getFunctions ( String catalogName , String schemaName , String functionName ) throws HiveSQLException { acquire ( ) ; OperationManager operationManager = getOperationManager ( ) ; GetFunctionsOperation operation = operationManager . newGetFunctionsOperation ( getSession ( ) , catalogName , schemaName , functionName ) ; OperationHandle opHandle = operation . getHandle ( ) ; try { operation . run ( ) ; opHandleSet . add ( opHandle ) ; return opHandle ; } catch ( HiveSQLException e ) { operationManager . closeOperation ( opHandle ) ; throw e ; } finally { release ( ) ; } } @ Override public void close ( ) throws HiveSQLException { try { acquire ( ) ; if ( metastoreClient != null ) { metastoreClient . close ( ) ; } for ( OperationHandle opHandle : opHandleSet ) { operationManager . closeOperation ( opHandle ) ; } opHandleSet . clear ( ) ; HiveHistory hiveHist = sessionState . getHiveHistory ( ) ; if ( null != hiveHist ) { hiveHist . closeStream ( ) ; } sessionState . close ( ) ; } catch ( IOException ioe ) { throw new HiveSQLException ( ""Failure to close"" , ioe ) ; } finally { release ( ) ; } } @ Override public SessionState getSessionState ( ) { return sessionState ; } @ Override public String getUserName ( ) { return username ; } @ Override public void setUserName ( String userName ) { this . username = userName ; } @ Override public void cancelOperation ( OperationHandle opHandle ) throws HiveSQLException { acquire ( ) ; try { sessionManager . getOperationManager ( ) . cancelOperation ( opHandle ) ; } finally { release ( ) ; } } @ Override public void closeOperation ( OperationHandle opHandle ) throws HiveSQLException { acquire ( ) ; try { operationManager . closeOperation ( opHandle ) ; opHandleSet . remove ( opHandle ) ; } finally { release ( ) ; } } @ Override public TableSchema getResultSetMetadata ( OperationHandle opHandle ) throws HiveSQLException { acquire ( ) ; try { return sessionManager . getOperationManager ( ) . getOperationResultSetSchema ( opHandle ) ; } finally { release ( ) ; } } @ Override public RowSet fetchResults ( OperationHandle opHandle , FetchOrientation orientation , long maxRows ) throws HiveSQLException { acquire ( ) ; try { return sessionManager . getOperationManager ( ) . getOperationNextRowSet ( opHandle , orientation , maxRows ) ; } finally { release ( ) ; } } @ Override public RowSet fetchResults ( OperationHandle opHandle ) throws HiveSQLException { acquire ( ) ; try { return sessionManager . getOperationManager ( ) . getOperationNextRowSet ( opHandle ) ; } finally { release ( ) ; } } protected HiveSession getSession ( ) { return this ; } @ Override public String getIpAddress ( ) { return ipAddress ; } @ Override public void setIpAddress ( String ipAddress ) { this . ipAddress = ipAddress ; } @ Override public String getDelegationToken ( HiveAuthFactory authFactory , String owner , String renewer ) throws HiveSQLException { HiveAuthFactory . verifyProxyAccess ( getUsername ( ) , owner , getIpAddress ( ) , getHiveConf ( ) ) ; return authFactory . getDelegationToken ( owner , renewer ) ; } @ Override public void cancelDelegationToken ( HiveAuthFactory authFactory , String tokenStr ) throws HiveSQLException { HiveAuthFactory . verifyProxyAccess ( getUsername ( ) , getUserFromToken ( authFactory , tokenStr ) , getIpAddress ( ) , getHiveConf ( ) ) ; authFactory . cancelDelegationToken ( tokenStr ) ; } @ Override public void renewDelegationToken ( HiveAuthFactory authFactory , String tokenStr ) throws HiveSQLException { HiveAuthFactory . verifyProxyAccess ( getUsername ( ) , getUserFromToken ( authFactory , tokenStr ) , getIpAddress ( ) , getHiveConf ( ) ) ; authFactory . renewDelegationToken ( tokenStr ) ; } private String getUserFromToken ( HiveAuthFactory authFactory , String tokenStr ) throws HiveSQLException { return authFactory . getUserFromToken ( tokenStr ) ; } }",Smelly
"public class CarbonDataLoadConfiguration { private DataField [ ] dataFields ; private AbsoluteTableIdentifier tableIdentifier ; private String [ ] header ; private String segmentId ; private String taskNo ; private BucketingInfo bucketingInfo ; private String bucketHashMethod ; private String segmentPath ; private Map < String , Object > dataLoadProperties = new HashMap < > ( ) ; private boolean preFetch ; private int dimensionCount ; private int measureCount ; private int noDictionaryCount ; private int complexDictionaryColumnCount ; private int complexNonDictionaryColumnCount ; private long schemaUpdatedTimeStamp ; private int numberOfSortColumns ; private int numberOfNoDictSortColumns ; private TableSpec tableSpec ; private short writingCoresCount ; private SortColumnRangeInfo sortColumnRangeInfo ; private boolean carbonTransactionalTable ; private String dataWritePath ; private String columnCompressor ; private int numberOfLoadingCores ; private DataLoadMetrics metrics ; private boolean nonSchemaColumnsPresent ; private boolean skipParsers = false ; public boolean isSkipParsers ( ) { return skipParsers ; } public void setSkipParsers ( boolean skipParsers ) { this . skipParsers = skipParsers ; } public CarbonDataLoadConfiguration ( ) { } public void setDataFields ( DataField [ ] dataFields ) { this . dataFields = dataFields ; for ( DataField dataField : dataFields ) { CarbonColumn column = dataField . getColumn ( ) ; if ( column . isDimension ( ) ) { dimensionCount ++ ; if ( column . isComplex ( ) ) { if ( ! dataField . isDateDataType ( ) ) { complexNonDictionaryColumnCount ++ ; } else { complexDictionaryColumnCount ++ ; } } else if ( ! dataField . isDateDataType ( ) ) { noDictionaryCount ++ ; } } if ( column . isMeasure ( ) ) { measureCount ++ ; } } } public DataField [ ] getDataFields ( ) { return dataFields ; } public int getDimensionCount ( ) { return dimensionCount ; } public int getNoDictionaryCount ( ) { return noDictionaryCount ; } public int getComplexDictionaryColumnCount ( ) { return complexDictionaryColumnCount ; } public int getMeasureCount ( ) { return measureCount ; } public void setNumberOfSortColumns ( int numberOfSortColumns ) { this . numberOfSortColumns = numberOfSortColumns ; } public int getNumberOfSortColumns ( ) { return this . numberOfSortColumns ; } public boolean isSortTable ( ) { return this . numberOfSortColumns > 0 ; } public void setNumberOfNoDictSortColumns ( int numberOfNoDictSortColumns ) { this . numberOfNoDictSortColumns = numberOfNoDictSortColumns ; } public int getNumberOfNoDictSortColumns ( ) { return this . numberOfNoDictSortColumns ; } public String [ ] getHeader ( ) { return header ; } public void setHeader ( String [ ] header ) { this . header = header ; } public AbsoluteTableIdentifier getTableIdentifier ( ) { return tableIdentifier ; } public void setTableIdentifier ( AbsoluteTableIdentifier tableIdentifier ) { this . tableIdentifier = tableIdentifier ; } public String getSegmentId ( ) { return segmentId ; } public void setSegmentId ( String segmentId ) { this . segmentId = segmentId ; } public String getTaskNo ( ) { return taskNo ; } public void setTaskNo ( String taskNo ) { this . taskNo = taskNo ; } public void setDataLoadProperty ( String key , Object value ) { dataLoadProperties . put ( key , value ) ; } public Object getDataLoadProperty ( String key ) { return dataLoadProperties . get ( key ) ; } public BucketingInfo getBucketingInfo ( ) { return bucketingInfo ; } public void setBucketingInfo ( BucketingInfo bucketingInfo ) { this . bucketingInfo = bucketingInfo ; } public boolean isPreFetch ( ) { return preFetch ; } public void setPreFetch ( boolean preFetch ) { this . preFetch = preFetch ; } public long getSchemaUpdatedTimeStamp ( ) { return schemaUpdatedTimeStamp ; } public void setSchemaUpdatedTimeStamp ( long schemaUpdatedTimeStamp ) { this . schemaUpdatedTimeStamp = schemaUpdatedTimeStamp ; } public DataType [ ] getMeasureDataType ( ) { List < CarbonMeasure > visibleMeasures = tableSpec . getCarbonTable ( ) . getVisibleMeasures ( ) ; DataType [ ] type = new DataType [ visibleMeasures . size ( ) ] ; for ( int i = 0 ; i < type . length ; i ++ ) { type [ i ] = visibleMeasures . get ( i ) . getDataType ( ) ; } return type ; } public DataType [ ] getMeasureDataTypeAsDataFieldOrder ( ) { List < Integer > measureIndexes = new ArrayList < > ( dataFields . length ) ; int measureCount = 0 ; for ( int i = 0 ; i < dataFields . length ; i ++ ) { if ( ! dataFields [ i ] . getColumn ( ) . isDimension ( ) ) { measureIndexes . add ( i ) ; measureCount ++ ; } } DataType [ ] type = new DataType [ measureCount ] ; for ( int i = 0 ; i < type . length ; i ++ ) { type [ i ] = dataFields [ measureIndexes . get ( i ) ] . getColumn ( ) . getDataType ( ) ; } return type ; } public CarbonColumn [ ] getNoDictAndComplexDimensions ( ) { List < CarbonDimension > visibleDimensions = tableSpec . getCarbonTable ( ) . getVisibleDimensions ( ) ; List < CarbonColumn > noDictionaryDimensions = new ArrayList < > ( ) ; for ( int i = 0 ; i < visibleDimensions . size ( ) ; i ++ ) { if ( visibleDimensions . get ( i ) . getDataType ( ) != DataTypes . DATE ) { noDictionaryDimensions . add ( visibleDimensions . get ( i ) ) ; } } return noDictionaryDimensions . toArray ( new CarbonColumn [ 0 ] ) ; } public boolean [ ] getSortColumnMapping ( ) { boolean [ ] sortColumnMapping = new boolean [ dataFields . length ] ; for ( int i = 0 ; i < sortColumnMapping . length ; i ++ ) { if ( dataFields [ i ] . getColumn ( ) . getColumnSchema ( ) . isSortColumn ( ) ) { sortColumnMapping [ i ] = true ; } } return sortColumnMapping ; } public TableSpec getTableSpec ( ) { return tableSpec ; } public void setTableSpec ( TableSpec tableSpec ) { this . tableSpec = tableSpec ; } public short getWritingCoresCount ( ) { return writingCoresCount ; } public void setWritingCoresCount ( short writingCoresCount ) { this . writingCoresCount = writingCoresCount ; } public String getDataWritePath ( ) { return dataWritePath ; } public void setDataWritePath ( String dataWritePath ) { this . dataWritePath = dataWritePath ; } public SortColumnRangeInfo getSortColumnRangeInfo ( ) { return sortColumnRangeInfo ; } public void setSortColumnRangeInfo ( SortColumnRangeInfo sortColumnRangeInfo ) { this . sortColumnRangeInfo = sortColumnRangeInfo ; } public boolean isCarbonTransactionalTable ( ) { return carbonTransactionalTable ; } public void setCarbonTransactionalTable ( boolean carbonTransactionalTable ) { this . carbonTransactionalTable = carbonTransactionalTable ; } public int getComplexNonDictionaryColumnCount ( ) { return complexNonDictionaryColumnCount ; } public String getColumnCompressor ( ) { return columnCompressor ; } public void setColumnCompressor ( String columnCompressor ) { this . columnCompressor = columnCompressor ; } public int getNumberOfLoadingCores ( ) { return numberOfLoadingCores ; } public void setNumberOfLoadingCores ( int numberOfLoadingCores ) { this . numberOfLoadingCores = numberOfLoadingCores ; } public String getSegmentPath ( ) { return segmentPath ; } public void setSegmentPath ( String segmentPath ) { this . segmentPath = segmentPath ; } public DataLoadMetrics getMetrics ( ) { return metrics ; } public void setMetrics ( DataLoadMetrics metrics ) { this . metrics = metrics ; } public String getBucketHashMethod ( ) { return bucketHashMethod ; } public void setBucketHashMethod ( String bucketHashMethod ) { this . bucketHashMethod = bucketHashMethod ; } public boolean isNonSchemaColumnsPresent ( ) { return nonSchemaColumnsPresent ; } public void setNonSchemaColumnsPresent ( boolean nonSchemaColumnsPresent ) { this . nonSchemaColumnsPresent = nonSchemaColumnsPresent ; } }",Smelly
"public class TestFieldDeclarationOrder extends AbstractTestCase { public TestFieldDeclarationOrder ( String test ) { super ( test , ""metacactusapp"" ) ; } public void testSubclass ( ) { ClassMetaData meta = JPAFacadeHelper . getMetaData ( getEmf ( ) , FieldOrderPCSubclass . class ) ; FieldMetaData [ ] fmds = meta . getFieldsInListingOrder ( ) ; assertEquals ( 11 , fmds . length ) ; assertEquals ( ""firstField"" , fmds [ 0 ] . getName ( ) ) ; assertEquals ( ""secondField"" , fmds [ 1 ] . getName ( ) ) ; assertEquals ( ""thirdField"" , fmds [ 2 ] . getName ( ) ) ; assertEquals ( ""unmanagedField"" , fmds [ 3 ] . getName ( ) ) ; assertEquals ( ""intField"" , fmds [ 4 ] . getName ( ) ) ; assertEquals ( ""oneToOneField"" , fmds [ 5 ] . getName ( ) ) ; assertEquals ( ""sub1"" , fmds [ 6 ] . getName ( ) ) ; assertEquals ( ""sub2"" , fmds [ 7 ] . getName ( ) ) ; assertEquals ( ""sub3"" , fmds [ 8 ] . getName ( ) ) ; assertEquals ( ""unmanagedSubField"" , fmds [ 9 ] . getName ( ) ) ; assertEquals ( ""undeclaredSubField"" , fmds [ 10 ] . getName ( ) ) ; } public void testSuperclass ( ) { ClassMetaData meta = JPAFacadeHelper . getMetaData ( getEmf ( ) , FieldOrderPC . class ) ; FieldMetaData [ ] fmds = meta . getFieldsInListingOrder ( ) ; assertEquals ( 6 , fmds . length ) ; assertEquals ( ""firstField"" , fmds [ 0 ] . getName ( ) ) ; assertEquals ( ""secondField"" , fmds [ 1 ] . getName ( ) ) ; assertEquals ( ""thirdField"" , fmds [ 2 ] . getName ( ) ) ; assertEquals ( ""unmanagedField"" , fmds [ 3 ] . getName ( ) ) ; assertEquals ( ""intField"" , fmds [ 4 ] . getName ( ) ) ; assertEquals ( ""oneToOneField"" , fmds [ 5 ] . getName ( ) ) ; } }",No
"@ Entity public class OneManyLazyChild { @ Id @ GeneratedValue private long id ; private String name ; @ ManyToOne ( fetch = FetchType . LAZY ) @ JoinColumn ( name = ""PARENT_ID"" ) private OneManyEagerParent parent ; @ Version private Integer optLock ; public long getId ( ) { return id ; } public String getName ( ) { return name ; } public void setName ( String name ) { this . name = name ; } public OneManyEagerParent getParent ( ) { return parent ; } public void setParent ( OneManyEagerParent parent ) { this . parent = parent ; } }",Smelly
" private static class LastOnRowByteBufferExtendedCell extends EmptyByteBufferExtendedCell { private static final int FIXED_OVERHEAD = ClassSize . OBJECT + ClassSize . REFERENCE + Bytes . SIZEOF_INT + Bytes . SIZEOF_SHORT ; private final ByteBuffer rowBuff ; private final int roffset ; private final short rlength ; public LastOnRowByteBufferExtendedCell ( final ByteBuffer row , int roffset , short rlength ) { this . rowBuff = row ; this . roffset = roffset ; this . rlength = rlength ; } @ Override public long heapSize ( ) { if ( this . rowBuff . hasArray ( ) ) { return ClassSize . align ( FIXED_OVERHEAD + rlength ) ; } return ClassSize . align ( FIXED_OVERHEAD ) ; } @ Override public ByteBuffer getRowByteBuffer ( ) { return this . rowBuff ; } @ Override public int getRowPosition ( ) { return this . roffset ; } @ Override public short getRowLength ( ) { return this . rlength ; } @ Override public long getTimestamp ( ) { return HConstants . OLDEST_TIMESTAMP ; } @ Override public byte getTypeByte ( ) { return KeyValue . Type . Minimum . getCode ( ) ; } @ Override public Type getType ( ) { throw new UnsupportedOperationException ( ) ; } ",Smelly
" public static class BigDecimalToString extends AbstractNumberToStringConverter < BigDecimal > { public BigDecimalToString ( ) { super ( BigDecimal . class ) ; } @ Override protected String format ( BigDecimal obj , NumberFormat nf ) throws ConversionException { return nf . format ( obj . doubleValue ( ) ) ; } ",No
" static class AFPIncludeFormMapMaker extends ElementMapping . Maker { public FONode make ( FONode parent ) { return new AFPIncludeFormMapElement ( parent , INCLUDE_FORM_MAP ) ; } ",No
"class FinishCreateNamespace extends MasterRepo { private static final long serialVersionUID = 1L ; private NamespaceInfo namespaceInfo ; public FinishCreateNamespace ( NamespaceInfo ti ) { this . namespaceInfo = ti ; } @ Override public long isReady ( long tid , Master environment ) throws Exception { return 0 ; } @ Override public Repo < Master > call ( long id , Master env ) throws Exception { Utils . unreserveNamespace ( namespaceInfo . namespaceId , id , true ) ; env . getEventCoordinator ( ) . event ( ""Created namespace %s "" , namespaceInfo . namespaceName ) ; LoggerFactory . getLogger ( FinishCreateNamespace . class ) . debug ( ""Created table "" + namespaceInfo . namespaceId + "" "" + namespaceInfo . namespaceName ) ; return null ; } @ Override public String getReturn ( ) { return namespaceInfo . namespaceId ; } @ Override public void undo ( long tid , Master env ) throws Exception { } }",No
"public class ExternalContextImpl extends ExternalContext { private Context context ; private Request request ; private Response response ; public ExternalContextImpl ( Context context , Request request , Response response ) { this . context = context ; this . request = request ; this . response = response ; } public void dispatch ( String url ) throws IOException { FacesRedirector redirector = ( FacesRedirector ) request . getAttribute ( FacesAction . REQUEST_REDIRECTOR_ATTRIBUTE ) ; if ( redirector == null ) { throw new IOException ( ""Can not dispatch to <"" + url + "">: Redirector missing."" ) ; } redirector . dispatch ( url ) ; } public String encodeActionURL ( String url ) { FacesRedirector redirector = ( FacesRedirector ) request . getAttribute ( FacesAction . REQUEST_REDIRECTOR_ATTRIBUTE ) ; if ( redirector == null ) { throw new RuntimeException ( ""Can not encode action URL <"" + url + "">: Redirector missing."" ) ; } return redirector . encodeActionURL ( url ) ; } public String encodeNamespace ( String ns ) { return ns ; } public String encodeResourceURL ( String url ) { FacesRedirector redirector = ( FacesRedirector ) request . getAttribute ( FacesAction . REQUEST_REDIRECTOR_ATTRIBUTE ) ; if ( redirector == null ) { throw new RuntimeException ( ""Can not encode resource URL <"" + url + "">: Redirector missing."" ) ; } return redirector . encodeResourceURL ( url ) ; } public Map getApplicationMap ( ) { return new ApplicationMap ( this . context ) ; } public String getAuthType ( ) { return this . request . getAuthType ( ) ; } public Object getContext ( ) { return this . context ; } public String getInitParameter ( String parameter ) { return this . context . getInitParameter ( parameter ) ; } public Map getInitParameterMap ( ) { return new InitParameterMap ( this . context ) ; } public String getRemoteUser ( ) { return this . request . getRemoteUser ( ) ; } public Object getRequest ( ) { return this . request ; } public String getRequestContextPath ( ) { return this . request . getContextPath ( ) ; } public Map getRequestCookieMap ( ) { System . err . println ( ""WARNING: getRequestCookieMap called."" ) ; return Collections . EMPTY_MAP ; } public Map getRequestHeaderMap ( ) { return new RequestHeaderMap ( this . request ) ; } public Map getRequestHeaderValuesMap ( ) { return new RequestHeaderValuesMap ( this . request ) ; } public Locale getRequestLocale ( ) { return this . request . getLocale ( ) ; } public Iterator getRequestLocales ( ) { return new EnumerationIterator ( this . request . getLocales ( ) ) ; } public Map getRequestMap ( ) { return new RequestMap ( this . request ) ; } public Map getRequestParameterMap ( ) { return new RequestParameterMap ( this . request ) ; } public Iterator getRequestParameterNames ( ) { return new EnumerationIterator ( this . request . getParameterNames ( ) ) ; } public Map getRequestParameterValuesMap ( ) { return new RequestParameterValuesMap ( this . request ) ; } public String getRequestPathInfo ( ) { StringBuffer path = new StringBuffer ( ) ; boolean slash = false ; String s = request . getServletPath ( ) ; if ( s != null ) { path . append ( s ) ; slash = s . endsWith ( ""/"" ) ; } s = request . getPathInfo ( ) ; if ( s != null ) { if ( s . startsWith ( ""/"" ) ) { if ( slash ) { s = s . substring ( 1 ) ; } } else { if ( ! slash ) { path . append ( '/' ) ; } } path . append ( s ) ; } return path . toString ( ) ; } public String getRequestServletPath ( ) { return """" ; } public URL getResource ( String resource ) throws MalformedURLException { return this . context . getResource ( resource ) ; } public InputStream getResourceAsStream ( String resource ) { return this . context . getResourceAsStream ( resource ) ; } public Set getResourcePaths ( String path ) { System . err . println ( ""WARNING: getResourcePaths("" + path + "") called."" ) ; throw new UnsupportedOperationException ( ) ; } public Object getResponse ( ) { return this . response ; } public Object getSession ( boolean create ) { return this . request . getSession ( create ) ; } public Map getSessionMap ( ) { return new SessionMap ( request . getSession ( ) ) ; } public Principal getUserPrincipal ( ) { return this . request . getUserPrincipal ( ) ; } public boolean isUserInRole ( String role ) { return this . request . isUserInRole ( role ) ; } public void log ( String message ) { System . err . println ( ""WARNING: log("" + message + "") called."" ) ; } public void log ( String message , Throwable e ) { System . err . println ( ""WARNING: log("" + message + "", "" + e + "") called."" ) ; } public void redirect ( String url ) throws IOException { FacesRedirector redirector = ( FacesRedirector ) request . getAttribute ( FacesAction . REQUEST_REDIRECTOR_ATTRIBUTE ) ; if ( redirector == null ) { throw new IOException ( ""Can not redirect to <"" + url + "">: Redirector missing."" ) ; } redirector . redirect ( url ) ; } }",Smelly
"public abstract class _MeaningfulPkTest2 extends BaseDataObject { private static final long serialVersionUID = 1L ; public static final String PK_ATTRIBUTE_PK_COLUMN = ""PK_ATTRIBUTE"" ; public static final Property < Integer > INTEGER_ATTRIBUTE = Property . create ( ""integerAttribute"" , Integer . class ) ; public static final Property < Integer > INTEGER_NULLABLE_ATTRIBUTE = Property . create ( ""integerNullableAttribute"" , Integer . class ) ; public static final Property < Integer > PK_ATTRIBUTE = Property . create ( ""pkAttribute"" , Integer . class ) ; protected Integer integerAttribute ; protected Integer integerNullableAttribute ; protected Integer pkAttribute ; public void setIntegerAttribute ( Integer integerAttribute ) { beforePropertyWrite ( ""integerAttribute"" , this . integerAttribute , integerAttribute ) ; this . integerAttribute = integerAttribute ; } public Integer getIntegerAttribute ( ) { beforePropertyRead ( ""integerAttribute"" ) ; return this . integerAttribute ; } public void setIntegerNullableAttribute ( Integer integerNullableAttribute ) { beforePropertyWrite ( ""integerNullableAttribute"" , this . integerNullableAttribute , integerNullableAttribute ) ; this . integerNullableAttribute = integerNullableAttribute ; } public Integer getIntegerNullableAttribute ( ) { beforePropertyRead ( ""integerNullableAttribute"" ) ; return this . integerNullableAttribute ; } public void setPkAttribute ( Integer pkAttribute ) { beforePropertyWrite ( ""pkAttribute"" , this . pkAttribute , pkAttribute ) ; this . pkAttribute = pkAttribute ; } public Integer getPkAttribute ( ) { beforePropertyRead ( ""pkAttribute"" ) ; return this . pkAttribute ; } @ Override public Object readPropertyDirectly ( String propName ) { if ( propName == null ) { throw new IllegalArgumentException ( ) ; } switch ( propName ) { case ""integerAttribute"" : return this . integerAttribute ; case ""integerNullableAttribute"" : return this . integerNullableAttribute ; case ""pkAttribute"" : return this . pkAttribute ; default : return super . readPropertyDirectly ( propName ) ; } } @ Override public void writePropertyDirectly ( String propName , Object val ) { if ( propName == null ) { throw new IllegalArgumentException ( ) ; } switch ( propName ) { case ""integerAttribute"" : this . integerAttribute = ( Integer ) val ; break ; case ""integerNullableAttribute"" : this . integerNullableAttribute = ( Integer ) val ; break ; case ""pkAttribute"" : this . pkAttribute = ( Integer ) val ; break ; default : super . writePropertyDirectly ( propName , val ) ; } } private void writeObject ( ObjectOutputStream out ) throws IOException { writeSerialized ( out ) ; } private void readObject ( ObjectInputStream in ) throws IOException , ClassNotFoundException { readSerialized ( in ) ; } @ Override protected void writeState ( ObjectOutputStream out ) throws IOException { super . writeState ( out ) ; out . writeObject ( this . integerAttribute ) ; out . writeObject ( this . integerNullableAttribute ) ; out . writeObject ( this . pkAttribute ) ; } @ Override protected void readState ( ObjectInputStream in ) throws IOException , ClassNotFoundException { super . readState ( in ) ; this . integerAttribute = ( Integer ) in . readObject ( ) ; this . integerNullableAttribute = ( Integer ) in . readObject ( ) ; this . pkAttribute = ( Integer ) in . readObject ( ) ; } }",Smelly
public class TestObjectAsAggregated { public Object getAggregate ( ) { return null ; } },No
"@ XmlType ( name = ""nodeGCDiagnosticsSnapshot"" ) public class NodeGCDiagnosticsSnapshotDTO { private String nodeId ; private String address ; private Integer apiPort ; private GCDiagnosticsSnapshotDTO snapshot ; @ ApiModelProperty ( ""The unique ID that identifies the node"" ) public String getNodeId ( ) { return nodeId ; } public void setNodeId ( String nodeId ) { this . nodeId = nodeId ; } @ ApiModelProperty ( ""The API address of the node"" ) public String getAddress ( ) { return address ; } public void setAddress ( String address ) { this . address = address ; } @ ApiModelProperty ( ""The API port used to communicate with the node"" ) public Integer getApiPort ( ) { return apiPort ; } public void setApiPort ( Integer apiPort ) { this . apiPort = apiPort ; } @ ApiModelProperty ( ""The Garbage Collection Diagnostics Snapshot"" ) public GCDiagnosticsSnapshotDTO getSnapshot ( ) { return snapshot ; } public void setSnapshot ( GCDiagnosticsSnapshotDTO snapshot ) { this . snapshot = snapshot ; } }",Smelly
"@ Entity public class OneManyEagerParent { @ Id @ GeneratedValue private long id ; private String name ; @ OneToMany ( mappedBy = ""parent"" , fetch = FetchType . EAGER ) @ OrderBy ( ""name ASC"" ) private List < OneManyLazyChild > lazychildren = new ArrayList < OneManyLazyChild > ( ) ; @ OneToMany ( mappedBy = ""parent"" , fetch = FetchType . EAGER ) @ OrderBy ( ""name ASC"" ) private List < OneManyEagerChild > eagerchildren = new ArrayList < OneManyEagerChild > ( ) ; @ Version private Integer optLock ; public long getId ( ) { return id ; } public List < OneManyLazyChild > getLazyChildren ( ) { return lazychildren ; } public void addLazyChild ( OneManyLazyChild child ) { child . setParent ( this ) ; lazychildren . add ( child ) ; } public List < OneManyEagerChild > getEagerChildren ( ) { return eagerchildren ; } public void addEagerChild ( OneManyEagerChild child ) { child . setParent ( this ) ; eagerchildren . add ( child ) ; } public String getName ( ) { return name ; } public void setName ( String name ) { this . name = name ; } }",Smelly
" static class OpenBaseCharType extends CharType { OpenBaseCharType ( ) { super ( false , true ) ; } @ Override public void setJdbcObject ( PreparedStatement st , String val , int pos , int type , int precision ) throws Exception { if ( type == Types . CLOB || type == Types . LONGVARCHAR ) { st . setString ( pos , val ) ; } else { super . setJdbcObject ( st , val , pos , type , precision ) ; } } } ",No
"public class PigQueryInterpreter extends BasePigInterpreter { private static Logger LOGGER = LoggerFactory . getLogger ( PigQueryInterpreter . class ) ; private PigServer pigServer ; private int maxResult ; public PigQueryInterpreter ( Properties properties ) { super ( properties ) ; } @ Override public void open ( ) { pigServer = getPigInterpreter ( ) . getPigServer ( ) ; maxResult = Integer . parseInt ( getProperty ( ""zeppelin.pig.maxResult"" ) ) ; } @ Override public void close ( ) { } @ Override public InterpreterResult interpret ( String st , InterpreterContext context ) { String alias = ""paragraph_"" + context . getParagraphId ( ) . replace ( ""-"" , ""_"" ) ; String [ ] lines = st . split ( ""\n"" ) ; List < String > queries = new ArrayList < > ( ) ; for ( int i = 0 ; i < lines . length ; ++ i ) { if ( i == lines . length - 1 ) { lines [ i ] = alias + "" = "" + lines [ i ] ; } queries . add ( lines [ i ] ) ; } StringBuilder resultBuilder = new StringBuilder ( ""%table "" ) ; try { pigServer . setJobName ( createJobName ( st , context ) ) ; File tmpScriptFile = PigUtils . createTempPigScript ( queries ) ; ScriptState . start ( pigServer . getPigContext ( ) . getExecutionEngine ( ) . instantiateScriptState ( ) ) ; PigStats . start ( pigServer . getPigContext ( ) . getExecutionEngine ( ) . instantiatePigStats ( ) ) ; PigScriptListener scriptListener = new PigScriptListener ( ) ; ScriptState . get ( ) . registerListener ( scriptListener ) ; listenerMap . put ( context . getParagraphId ( ) , scriptListener ) ; pigServer . registerScript ( tmpScriptFile . getAbsolutePath ( ) ) ; Schema schema = pigServer . dumpSchema ( alias ) ; boolean schemaKnown = ( schema != null ) ; if ( schemaKnown ) { for ( int i = 0 ; i < schema . size ( ) ; ++ i ) { Schema . FieldSchema field = schema . getField ( i ) ; resultBuilder . append ( field . alias != null ? field . alias : ""col_"" + i ) ; if ( i != schema . size ( ) - 1 ) { resultBuilder . append ( ""\t"" ) ; } } resultBuilder . append ( ""\n"" ) ; } Iterator < Tuple > iter = pigServer . openIterator ( alias ) ; boolean firstRow = true ; int index = 0 ; while ( iter . hasNext ( ) && index <= maxResult ) { index ++ ; Tuple tuple = iter . next ( ) ; if ( firstRow && ! schemaKnown ) { for ( int i = 0 ; i < tuple . size ( ) ; ++ i ) { resultBuilder . append ( ""c_"" + i + ""\t"" ) ; } resultBuilder . append ( ""\n"" ) ; firstRow = false ; } resultBuilder . append ( StringUtils . join ( tuple . iterator ( ) , ""\t"" ) ) ; resultBuilder . append ( ""\n"" ) ; } if ( index >= maxResult && iter . hasNext ( ) ) { resultBuilder . append ( ""\n<font color=red>Results are limited by "" + maxResult + "".</font>"" ) ; } } catch ( IOException e ) { if ( e instanceof FrontendException ) { FrontendException fe = ( FrontendException ) e ; if ( ! fe . getMessage ( ) . contains ( ""Backend error :"" ) ) { LOGGER . error ( ""Fail to run pig query."" , e ) ; return new InterpreterResult ( Code . ERROR , ExceptionUtils . getStackTrace ( e ) ) ; } } if ( e . getCause ( ) instanceof ParseException ) { return new InterpreterResult ( Code . ERROR , e . getMessage ( ) ) ; } PigStats stats = PigStats . get ( ) ; if ( stats != null ) { String errorMsg = stats . getDisplayString ( ) ; if ( errorMsg != null ) { return new InterpreterResult ( Code . ERROR , errorMsg ) ; } } LOGGER . error ( ""Fail to run pig query."" , e ) ; return new InterpreterResult ( Code . ERROR , ExceptionUtils . getStackTrace ( e ) ) ; } finally { listenerMap . remove ( context . getParagraphId ( ) ) ; } return new InterpreterResult ( Code . SUCCESS , resultBuilder . toString ( ) ) ; } @ Override public PigServer getPigServer ( ) { return this . pigServer ; } private PigInterpreter getPigInterpreter ( ) { LazyOpenInterpreter lazy = null ; PigInterpreter pig = null ; Interpreter p = getInterpreterInTheSameSessionByClassName ( PigInterpreter . class . getName ( ) ) ; while ( p instanceof WrappedInterpreter ) { if ( p instanceof LazyOpenInterpreter ) { lazy = ( LazyOpenInterpreter ) p ; } p = ( ( WrappedInterpreter ) p ) . getInnerInterpreter ( ) ; } pig = ( PigInterpreter ) p ; if ( lazy != null ) { lazy . open ( ) ; } return pig ; } }",No
" public static class FailingCipherProvider implements CipherProvider { public FailingCipherProvider ( ) { super ( ) ; throw new RuntimeException ( ""BAD!"" ) ; } @ Override public Configuration getConf ( ) { return null ; } @ Override public void setConf ( Configuration conf ) { } @ Override public String getName ( ) { return null ; } @ Override public String [ ] getSupportedCiphers ( ) { return null ; } @ Override public Cipher getCipher ( String name ) { return null ; } } ",Smelly
"@ ThreadSafe public final class InlineJdbc extends JdbcElement { private final String jdbcDriver ; private final String jdbcUri ; private final String jdbcUsername ; private final String jdbcPassword ; private final String jdbcPasswordLookup ; private final int poolMaxsize ; private final int poolMinsize ; private final int idleMaxsize ; private final int timeBetweenEvictionRunsMillis ; private final int poolSleeptime ; private final int poolLifetime ; private final int poolDeadlockMaxwait ; private final int poolDeadlockRetrywait ; private final String poolJdbcTestStmt ; private final String poolXaWrapperClass ; InlineJdbc ( Element element ) throws GenericEntityConfException { super ( element ) ; String lineNumberText = EntityConfigUtil . createConfigFileLineNumberText ( element ) ; String jdbcDriver = element . getAttribute ( ""jdbc-driver"" ) . intern ( ) ; if ( jdbcDriver . isEmpty ( ) ) { throw new GenericEntityConfException ( ""<inline-jdbc> element jdbc-driver attribute is empty"" + lineNumberText ) ; } this . jdbcDriver = jdbcDriver ; String jdbcUri = element . getAttribute ( ""jdbc-uri"" ) . intern ( ) ; if ( jdbcUri . isEmpty ( ) ) { throw new GenericEntityConfException ( ""<inline-jdbc> element jdbc-uri attribute is empty"" + lineNumberText ) ; } this . jdbcUri = jdbcUri ; String jdbcUsername = element . getAttribute ( ""jdbc-username"" ) . intern ( ) ; if ( jdbcUsername . isEmpty ( ) ) { throw new GenericEntityConfException ( ""<inline-jdbc> element jdbc-username attribute is empty"" + lineNumberText ) ; } this . jdbcUsername = jdbcUsername ; this . jdbcPassword = element . getAttribute ( ""jdbc-password"" ) . intern ( ) ; this . jdbcPasswordLookup = element . getAttribute ( ""jdbc-password-lookup"" ) . intern ( ) ; String poolMaxsize = element . getAttribute ( ""pool-maxsize"" ) ; if ( poolMaxsize . isEmpty ( ) ) { this . poolMaxsize = 50 ; } else { try { this . poolMaxsize = Integer . parseInt ( poolMaxsize ) ; } catch ( Exception e ) { throw new GenericEntityConfException ( ""<inline-jdbc> element pool-maxsize attribute is invalid"" + lineNumberText ) ; } } String poolMinsize = element . getAttribute ( ""pool-minsize"" ) ; if ( poolMinsize . isEmpty ( ) ) { this . poolMinsize = 2 ; } else { try { this . poolMinsize = Integer . parseInt ( poolMinsize ) ; } catch ( Exception e ) { throw new GenericEntityConfException ( ""<inline-jdbc> element pool-minsize attribute is invalid"" + lineNumberText ) ; } } String idleMaxsize = element . getAttribute ( ""idle-maxsize"" ) ; if ( idleMaxsize . isEmpty ( ) ) { this . idleMaxsize = this . poolMaxsize / 2 ; } else { try { this . idleMaxsize = Integer . parseInt ( idleMaxsize ) ; } catch ( Exception e ) { throw new GenericEntityConfException ( ""<inline-jdbc> element idle-maxsize attribute is invalid"" + lineNumberText ) ; } } String timeBetweenEvictionRunsMillis = element . getAttribute ( ""time-between-eviction-runs-millis"" ) ; if ( timeBetweenEvictionRunsMillis . isEmpty ( ) ) { this . timeBetweenEvictionRunsMillis = 600000 ; } else { try { this . timeBetweenEvictionRunsMillis = Integer . parseInt ( timeBetweenEvictionRunsMillis ) ; } catch ( Exception e ) { throw new GenericEntityConfException ( ""<inline-jdbc> element time-between-eviction-runs-millis attribute is invalid"" + lineNumberText ) ; } } String poolSleeptime = element . getAttribute ( ""pool-sleeptime"" ) ; if ( poolSleeptime . isEmpty ( ) ) { this . poolSleeptime = 300000 ; } else { try { this . poolSleeptime = Integer . parseInt ( poolSleeptime ) ; } catch ( Exception e ) { throw new GenericEntityConfException ( ""<inline-jdbc> element pool-sleeptime attribute is invalid"" + lineNumberText ) ; } } String poolLifetime = element . getAttribute ( ""pool-lifetime"" ) ; if ( poolLifetime . isEmpty ( ) ) { this . poolLifetime = 600000 ; } else { try { this . poolLifetime = Integer . parseInt ( poolLifetime ) ; } catch ( Exception e ) { throw new GenericEntityConfException ( ""<inline-jdbc> element pool-lifetime attribute is invalid"" + lineNumberText ) ; } } String poolDeadlockMaxwait = element . getAttribute ( ""pool-deadlock-maxwait"" ) ; if ( poolDeadlockMaxwait . isEmpty ( ) ) { this . poolDeadlockMaxwait = 300000 ; } else { try { this . poolDeadlockMaxwait = Integer . parseInt ( poolDeadlockMaxwait ) ; } catch ( Exception e ) { throw new GenericEntityConfException ( ""<inline-jdbc> element pool-deadlock-maxwait attribute is invalid"" + lineNumberText ) ; } } String poolDeadlockRetrywait = element . getAttribute ( ""pool-deadlock-retrywait"" ) ; if ( poolDeadlockRetrywait . isEmpty ( ) ) { this . poolDeadlockRetrywait = 10000 ; } else { try { this . poolDeadlockRetrywait = Integer . parseInt ( poolDeadlockRetrywait ) ; } catch ( Exception e ) { throw new GenericEntityConfException ( ""<inline-jdbc> element pool-deadlock-retrywait attribute is invalid"" + lineNumberText ) ; } } this . poolJdbcTestStmt = element . getAttribute ( ""pool-jdbc-test-stmt"" ) . intern ( ) ; this . poolXaWrapperClass = element . getAttribute ( ""pool-xa-wrapper-class"" ) . intern ( ) ; } public String getJdbcDriver ( ) { return this . jdbcDriver ; } public String getJdbcUri ( ) { return this . jdbcUri ; } public String getJdbcUsername ( ) { return this . jdbcUsername ; } public String getJdbcPassword ( ) { return this . jdbcPassword ; } public String getJdbcPasswordLookup ( ) { return this . jdbcPasswordLookup ; } public int getPoolMaxsize ( ) { return this . poolMaxsize ; } public int getPoolMinsize ( ) { return this . poolMinsize ; } public int getIdleMaxsize ( ) { return this . idleMaxsize ; } public int getTimeBetweenEvictionRunsMillis ( ) { return this . timeBetweenEvictionRunsMillis ; } public int getPoolSleeptime ( ) { return this . poolSleeptime ; } public int getPoolLifetime ( ) { return this . poolLifetime ; } public int getPoolDeadlockMaxwait ( ) { return this . poolDeadlockMaxwait ; } public int getPoolDeadlockRetrywait ( ) { return this . poolDeadlockRetrywait ; } public String getPoolJdbcTestStmt ( ) { return this . poolJdbcTestStmt ; } public String getPoolXaWrapperClass ( ) { return this . poolXaWrapperClass ; } }",Smelly
"final class ValidatingColumnWriteStore implements ColumnWriteStore { private final String [ ] expected ; int counter = 0 ; ValidatingColumnWriteStore ( String [ ] expected ) { this . expected = expected ; } @ Override public ColumnWriter getColumnWriter ( final ColumnDescriptor path ) { return new ColumnWriter ( ) { private void validate ( Object value , int repetitionLevel , int definitionLevel ) { String actual = Arrays . toString ( path . getPath ( ) ) + "": "" + value + "", r:"" + repetitionLevel + "", d:"" + definitionLevel ; assertEquals ( ""event #"" + counter , expected [ counter ] , actual ) ; ++ counter ; } @ Override public void writeNull ( int repetitionLevel , int definitionLevel ) { validate ( null , repetitionLevel , definitionLevel ) ; } @ Override public void write ( Binary value , int repetitionLevel , int definitionLevel ) { validate ( value . toStringUsingUTF8 ( ) , repetitionLevel , definitionLevel ) ; } @ Override public void write ( boolean value , int repetitionLevel , int definitionLevel ) { validate ( value , repetitionLevel , definitionLevel ) ; } @ Override public void write ( int value , int repetitionLevel , int definitionLevel ) { validate ( value , repetitionLevel , definitionLevel ) ; } @ Override public void write ( long value , int repetitionLevel , int definitionLevel ) { validate ( value , repetitionLevel , definitionLevel ) ; } @ Override public void write ( float value , int repetitionLevel , int definitionLevel ) { validate ( value , repetitionLevel , definitionLevel ) ; } @ Override public void write ( double value , int repetitionLevel , int definitionLevel ) { validate ( value , repetitionLevel , definitionLevel ) ; } } ; } public void validate ( ) { assertEquals ( ""read all events"" , expected . length , counter ) ; } @ Override public void endRecord ( ) { } @ Override public void flush ( ) { } @ Override public long getAllocatedSize ( ) { return 0 ; } @ Override public long getBufferedSize ( ) { return 0 ; } @ Override public String memUsageString ( ) { return null ; } }",No
"public class StringMessageMapper implements MqttMessageMapper { public Values toValues ( MqttMessage message ) { return new Values ( message . getTopic ( ) , new String ( message . getMessage ( ) ) ) ; } public Fields outputFields ( ) { return new Fields ( ""topic"" , ""message"" ) ; } }",No
"public class StandaloneAccumuloCluster implements AccumuloCluster { @ SuppressWarnings ( ""unused"" ) private static final Logger log = LoggerFactory . getLogger ( StandaloneAccumuloCluster . class ) ; static final List < ServerType > ALL_SERVER_TYPES = Collections . unmodifiableList ( Arrays . asList ( ServerType . MASTER , ServerType . TABLET_SERVER , ServerType . TRACER , ServerType . GARBAGE_COLLECTOR , ServerType . MONITOR ) ) ; private Instance instance ; private ClientConfiguration clientConf ; private String accumuloHome , clientAccumuloConfDir , serverAccumuloConfDir , hadoopConfDir ; private Path tmp ; private List < ClusterUser > users ; private String serverUser ; public StandaloneAccumuloCluster ( ClientConfiguration clientConf , Path tmp , List < ClusterUser > users , String serverUser ) { this ( new ZooKeeperInstance ( clientConf ) , clientConf , tmp , users , serverUser ) ; } public StandaloneAccumuloCluster ( Instance instance , ClientConfiguration clientConf , Path tmp , List < ClusterUser > users , String serverUser ) { this . instance = instance ; this . clientConf = clientConf ; this . tmp = tmp ; this . users = users ; this . serverUser = serverUser ; } public String getAccumuloHome ( ) { return accumuloHome ; } public void setAccumuloHome ( String accumuloHome ) { this . accumuloHome = accumuloHome ; } public String getClientAccumuloConfDir ( ) { return clientAccumuloConfDir ; } public void setClientAccumuloConfDir ( String accumuloConfDir ) { this . clientAccumuloConfDir = accumuloConfDir ; } public String getServerAccumuloConfDir ( ) { return serverAccumuloConfDir ; } public void setServerAccumuloConfDir ( String accumuloConfDir ) { this . serverAccumuloConfDir = accumuloConfDir ; } public String getHadoopConfDir ( ) { if ( null == hadoopConfDir ) { hadoopConfDir = System . getenv ( ""HADOOP_CONF_DIR"" ) ; } if ( null == hadoopConfDir ) { throw new IllegalArgumentException ( ""Cannot determine HADOOP_CONF_DIR for standalone cluster"" ) ; } return hadoopConfDir ; } public void setHadoopConfDir ( String hadoopConfDir ) { this . hadoopConfDir = hadoopConfDir ; } @ Override public String getInstanceName ( ) { return instance . getInstanceName ( ) ; } @ Override public String getZooKeepers ( ) { return instance . getZooKeepers ( ) ; } @ Override public Connector getConnector ( String user , AuthenticationToken token ) throws AccumuloException , AccumuloSecurityException { return instance . getConnector ( user , token ) ; } @ Override public ClientConfiguration getClientConfig ( ) { return clientConf ; } @ Override public StandaloneClusterControl getClusterControl ( ) { return new StandaloneClusterControl ( serverUser , null == accumuloHome ? System . getenv ( ""ACCUMULO_HOME"" ) : accumuloHome , null == clientAccumuloConfDir ? System . getenv ( ""ACCUMULO_CONF_DIR"" ) : clientAccumuloConfDir , null == serverAccumuloConfDir ? System . getenv ( ""ACCUMULO_CONF_DIR"" ) : serverAccumuloConfDir ) ; } @ Override public void start ( ) throws IOException { StandaloneClusterControl control = getClusterControl ( ) ; control . setGoalState ( MasterGoalState . NORMAL . toString ( ) ) ; for ( ServerType type : ALL_SERVER_TYPES ) { control . startAllServers ( type ) ; } } @ Override public void stop ( ) throws IOException { StandaloneClusterControl control = getClusterControl ( ) ; for ( ServerType type : ALL_SERVER_TYPES ) { control . stopAllServers ( type ) ; } } public Configuration getHadoopConfiguration ( ) { String confDir = getHadoopConfDir ( ) ; final Configuration conf = CachedConfiguration . getInstance ( ) ; conf . addResource ( new Path ( confDir , ""core-site.xml"" ) ) ; conf . addResource ( new Path ( confDir , ""hdfs-site.xml"" ) ) ; return conf ; } @ Override public FileSystem getFileSystem ( ) throws IOException { Configuration conf = getHadoopConfiguration ( ) ; return FileSystem . get ( conf ) ; } @ Override public Path getTemporaryPath ( ) { return tmp ; } public ClusterUser getUser ( int offset ) { checkArgument ( offset >= 0 && offset < users . size ( ) , ""Invalid offset, should be non-negative and less than "" + users . size ( ) ) ; return users . get ( offset ) ; } @ Override public AccumuloConfiguration getSiteConfiguration ( ) { Configuration conf = new Configuration ( false ) ; Path accumuloSite = new Path ( serverAccumuloConfDir , ""accumulo-site.xml"" ) ; conf . addResource ( accumuloSite ) ; return new ConfigurationCopy ( Iterables . concat ( AccumuloConfiguration . getDefaultConfiguration ( ) , conf ) ) ; } }",Smelly
 private static class CloseSession_resultStandardSchemeFactory implements SchemeFactory { public CloseSession_resultStandardScheme getScheme ( ) { return new CloseSession_resultStandardScheme ( ) ; } ,No
"public class PropertyHolderFactory { private static final Logger logger = WebBeansLoggerFacade . getLogger ( PropertyHolderFactory . class ) ; private static final String PROPERTY_FILE = ""org/apache/webbeans/newtests/injection/injectionpoint/tests/PlaceHolder.properties"" ; private volatile static Properties placeHolderProperties ; @ Inject private DataTransformer dataTransformer ; @ Inject private PropertyEncryptor propertyEncryptor ; public synchronized static Properties getProperties ( ) { if ( placeHolderProperties == null ) { placeHolderProperties = PropertyLoader . getProperties ( PROPERTY_FILE ) ; logger . info ( ""loaded "" + placeHolderProperties ) ; } return placeHolderProperties ; } @ Produces @ PropertyHolder public String getPlaceHolderValue ( InjectionPoint injectionPoint ) { logger . log ( Level . INFO , ""getPlaceHolderValue {0}"" , injectionPoint ) ; String keyName = injectionPoint . getAnnotated ( ) . getAnnotation ( PropertyHolder . class ) . value ( ) ; if ( isBlank ( keyName ) ) { keyName = injectionPoint . getMember ( ) . getName ( ) ; } List < String > stringList = new ArrayList < String > ( ) ; stringList . add ( injectionPoint . getMember ( ) . getDeclaringClass ( ) . getName ( ) ) ; stringList . add ( ""."" ) ; stringList . add ( keyName ) ; keyName = dataTransformer . concatStrings ( stringList ) ; logger . info ( ""Fetching value for key: "" + keyName ) ; String keyValue = System . getProperty ( keyName ) ; if ( isBlank ( keyValue ) ) { Properties properties = PropertyHolderFactory . getProperties ( ) ; keyValue = properties . getProperty ( keyName ) ; } keyValue = this . decryptProperty ( keyValue ) ; logger . info ( ""Produced property : Key->{"" + keyName + ""}, Value->{"" + keyValue + ""}"" ) ; return keyValue ; } private String decryptProperty ( String propertyValue ) { logger . info ( ""Checking if decrypting of value is needed for "" + propertyValue ) ; if ( ! isEmpty ( propertyValue ) && propertyValue . matches ( ""ENC(\\S+)"" ) ) { String decryptPropertyValue = substringBetween ( propertyValue , ""ENC("" , "")"" ) ; propertyValue = propertyEncryptor . decryptProperty ( decryptPropertyValue ) ; } return propertyValue ; } public static boolean isBlank ( String str ) { int strLen ; if ( str == null || ( strLen = str . length ( ) ) == 0 ) { return true ; } for ( int i = 0 ; i < strLen ; i ++ ) { if ( ( Character . isWhitespace ( str . charAt ( i ) ) == false ) ) { return false ; } } return true ; } public static boolean isEmpty ( String str ) { return str == null || str . length ( ) == 0 ; } public void setDataTransformer ( DataTransformer dataTransformer ) { this . dataTransformer = dataTransformer ; } public static final int INDEX_NOT_FOUND = - 1 ; public static String substringBetween ( String str , String open , String close ) { if ( str == null || open == null || close == null ) { return null ; } int start = str . indexOf ( open ) ; if ( start != INDEX_NOT_FOUND ) { int end = str . indexOf ( close , start + open . length ( ) ) ; if ( end != INDEX_NOT_FOUND ) { return str . substring ( start + open . length ( ) , end ) ; } } return null ; } }",No
"public class Subscription implements Serializable , Comparable < Subscription > { private String id = UUIDGenerator . generateUUID ( ) ; private String title ; private String author ; private String feedUrl ; private String siteUrl ; private Date lastUpdated ; private int inboundlinks = 0 ; private int inboundblogs = 0 ; private Set < PlanetGroup > groups = new HashSet < PlanetGroup > ( ) ; private Set < SubscriptionEntry > entries = new HashSet < SubscriptionEntry > ( ) ; public Subscription ( ) { } public int compareTo ( Subscription other ) { String otherString = other . getTitle ( ) + other . getFeedURL ( ) ; String thisString = getTitle ( ) + getFeedURL ( ) ; return thisString . compareTo ( otherString ) ; } public boolean equals ( Object other ) { if ( this == other ) { return true ; } if ( ! ( other instanceof Subscription ) ) { return false ; } final Subscription that = ( Subscription ) other ; return this . feedUrl . equals ( that . getFeedURL ( ) ) ; } public int hashCode ( ) { return this . feedUrl . hashCode ( ) ; } public String toString ( ) { StringBuilder buf = new StringBuilder ( ) ; buf . append ( ""{"" ) ; buf . append ( getFeedURL ( ) ) . append ( "", "" ) ; buf . append ( getSiteURL ( ) ) . append ( "", "" ) ; buf . append ( getTitle ( ) ) . append ( "", "" ) ; buf . append ( getAuthor ( ) ) . append ( "", "" ) ; buf . append ( getLastUpdated ( ) ) ; buf . append ( ""}"" ) ; return buf . toString ( ) ; } public String getId ( ) { return id ; } public void setId ( String id ) { this . id = id ; } public String getTitle ( ) { return title ; } public void setTitle ( String title ) { this . title = title ; } public String getAuthor ( ) { return author ; } public void setAuthor ( String author ) { this . author = author ; } public String getFeedURL ( ) { return feedUrl ; } public void setFeedURL ( String feedUrl ) { this . feedUrl = feedUrl ; } public String getSiteURL ( ) { return siteUrl ; } public void setSiteURL ( String siteUrl ) { this . siteUrl = siteUrl ; } public Date getLastUpdated ( ) { return lastUpdated ; } public void setLastUpdated ( Date lastUpdated ) { this . lastUpdated = lastUpdated ; } public int getInboundlinks ( ) { return inboundlinks ; } public void setInboundlinks ( int inboundlinks ) { this . inboundlinks = inboundlinks ; } public int getInboundblogs ( ) { return inboundblogs ; } public void setInboundblogs ( int inboundblogs ) { this . inboundblogs = inboundblogs ; } public Set < PlanetGroup > getGroups ( ) { return groups ; } private void setGroups ( Set < PlanetGroup > groups ) { this . groups = groups ; } public Set < SubscriptionEntry > getEntries ( ) { return entries ; } private void setEntries ( Set < SubscriptionEntry > entries ) { this . entries = entries ; } public void addEntry ( SubscriptionEntry entry ) { entry . setSubscription ( this ) ; this . getEntries ( ) . add ( entry ) ; } public void addEntries ( Collection < SubscriptionEntry > newEntries ) { for ( SubscriptionEntry entry : newEntries ) { entry . setSubscription ( this ) ; } this . getEntries ( ) . addAll ( newEntries ) ; } public String getName ( ) { return getTitle ( ) ; } public String getURL ( ) { return siteUrl ; } }",Smelly
"public class ImageViewerController extends HttpServlet { @ Override protected void doGet ( HttpServletRequest request , HttpServletResponse response ) throws ServletException , IOException { final ViewableContent content = ( ViewableContent ) request . getAttribute ( ViewableContent . CONTENT_REQUEST_ATTRIBUTE ) ; if ( ""image/png"" . equals ( content . getContentType ( ) ) || ""image/jpeg"" . equals ( content . getContentType ( ) ) || ""image/gif"" . equals ( content . getContentType ( ) ) ) { request . getRequestDispatcher ( ""/WEB-INF/jsp/image.jsp"" ) . include ( request , response ) ; } else { final PrintWriter out = response . getWriter ( ) ; out . println ( ""Unexpected content type: "" + content . getContentType ( ) ) ; } } }",No
"public class SqlSelect extends SqlCall { public static final int FROM_OPERAND = 2 ; public static final int WHERE_OPERAND = 3 ; public static final int HAVING_OPERAND = 5 ; SqlNodeList keywordList ; SqlNodeList selectList ; SqlNode from ; SqlNode where ; SqlNodeList groupBy ; SqlNode having ; SqlNodeList windowDecls ; SqlNodeList orderBy ; SqlNode offset ; SqlNode fetch ; public SqlSelect ( SqlParserPos pos , SqlNodeList keywordList , SqlNodeList selectList , SqlNode from , SqlNode where , SqlNodeList groupBy , SqlNode having , SqlNodeList windowDecls , SqlNodeList orderBy , SqlNode offset , SqlNode fetch ) { super ( pos ) ; this . keywordList = Objects . requireNonNull ( keywordList != null ? keywordList : new SqlNodeList ( pos ) ) ; this . selectList = selectList ; this . from = from ; this . where = where ; this . groupBy = groupBy ; this . having = having ; this . windowDecls = Objects . requireNonNull ( windowDecls != null ? windowDecls : new SqlNodeList ( pos ) ) ; this . orderBy = orderBy ; this . offset = offset ; this . fetch = fetch ; } public SqlOperator getOperator ( ) { return SqlSelectOperator . INSTANCE ; } @ Override public SqlKind getKind ( ) { return SqlKind . SELECT ; } @ Override public List < SqlNode > getOperandList ( ) { return ImmutableNullableList . of ( keywordList , selectList , from , where , groupBy , having , windowDecls , orderBy , offset , fetch ) ; } @ Override public void setOperand ( int i , SqlNode operand ) { switch ( i ) { case 0 : keywordList = Objects . requireNonNull ( ( SqlNodeList ) operand ) ; break ; case 1 : selectList = ( SqlNodeList ) operand ; break ; case 2 : from = operand ; break ; case 3 : where = operand ; break ; case 4 : groupBy = ( SqlNodeList ) operand ; break ; case 5 : having = operand ; break ; case 6 : windowDecls = Objects . requireNonNull ( ( SqlNodeList ) operand ) ; break ; case 7 : orderBy = ( SqlNodeList ) operand ; break ; case 8 : offset = operand ; break ; case 9 : fetch = operand ; break ; default : throw new AssertionError ( i ) ; } } public final boolean isDistinct ( ) { return getModifierNode ( SqlSelectKeyword . DISTINCT ) != null ; } public final SqlNode getModifierNode ( SqlSelectKeyword modifier ) { for ( SqlNode keyword : keywordList ) { SqlSelectKeyword keyword2 = ( ( SqlLiteral ) keyword ) . symbolValue ( SqlSelectKeyword . class ) ; if ( keyword2 == modifier ) { return keyword ; } } return null ; } public final SqlNode getFrom ( ) { return from ; } public void setFrom ( SqlNode from ) { this . from = from ; } public final SqlNodeList getGroup ( ) { return groupBy ; } public void setGroupBy ( SqlNodeList groupBy ) { this . groupBy = groupBy ; } public final SqlNode getHaving ( ) { return having ; } public void setHaving ( SqlNode having ) { this . having = having ; } public final SqlNodeList getSelectList ( ) { return selectList ; } public void setSelectList ( SqlNodeList selectList ) { this . selectList = selectList ; } public final SqlNode getWhere ( ) { return where ; } public void setWhere ( SqlNode whereClause ) { this . where = whereClause ; } @ Nonnull public final SqlNodeList getWindowList ( ) { return windowDecls ; } public final SqlNodeList getOrderList ( ) { return orderBy ; } public void setOrderBy ( SqlNodeList orderBy ) { this . orderBy = orderBy ; } public final SqlNode getOffset ( ) { return offset ; } public void setOffset ( SqlNode offset ) { this . offset = offset ; } public final SqlNode getFetch ( ) { return fetch ; } public void setFetch ( SqlNode fetch ) { this . fetch = fetch ; } public void validate ( SqlValidator validator , SqlValidatorScope scope ) { validator . validateQuery ( this , scope , validator . getUnknownType ( ) ) ; } @ Override public void unparse ( SqlWriter writer , int leftPrec , int rightPrec ) { if ( ! writer . inQuery ( ) ) { final SqlWriter . Frame frame = writer . startList ( SqlWriter . FrameTypeEnum . SUB_QUERY , ""("" , "")"" ) ; writer . getDialect ( ) . unparseCall ( writer , this , 0 , 0 ) ; writer . endList ( frame ) ; } else { writer . getDialect ( ) . unparseCall ( writer , this , leftPrec , rightPrec ) ; } } public boolean hasOrderBy ( ) { return orderBy != null && orderBy . size ( ) != 0 ; } public boolean hasWhere ( ) { return where != null ; } public boolean isKeywordPresent ( SqlSelectKeyword targetKeyWord ) { return getModifierNode ( targetKeyWord ) != null ; } }",Smelly
"@ Deprecated public class Snake { private static final int DEFAULT_LENGTH = 5 ; private final int id ; private final WsOutbound outbound ; private Direction direction ; private int length = DEFAULT_LENGTH ; private Location head ; private Deque < Location > tail = new ArrayDeque < Location > ( ) ; private String hexColor ; public Snake ( int id , WsOutbound outbound ) { this . id = id ; this . outbound = outbound ; this . hexColor = SnakeWebSocketServlet . getRandomHexColor ( ) ; resetState ( ) ; } private void resetState ( ) { this . direction = Direction . NONE ; this . head = SnakeWebSocketServlet . getRandomLocation ( ) ; this . tail . clear ( ) ; this . length = DEFAULT_LENGTH ; } private synchronized void kill ( ) { resetState ( ) ; try { CharBuffer response = CharBuffer . wrap ( ""{'type': 'dead'}"" ) ; outbound . writeTextMessage ( response ) ; } catch ( IOException ioe ) { } } private synchronized void reward ( ) { length ++ ; try { CharBuffer response = CharBuffer . wrap ( ""{'type': 'kill'}"" ) ; outbound . writeTextMessage ( response ) ; } catch ( IOException ioe ) { } } public synchronized void update ( Collection < Snake > snakes ) { Location nextLocation = head . getAdjacentLocation ( direction ) ; if ( nextLocation . x >= SnakeWebSocketServlet . PLAYFIELD_WIDTH ) { nextLocation . x = 0 ; } if ( nextLocation . y >= SnakeWebSocketServlet . PLAYFIELD_HEIGHT ) { nextLocation . y = 0 ; } if ( nextLocation . x < 0 ) { nextLocation . x = SnakeWebSocketServlet . PLAYFIELD_WIDTH ; } if ( nextLocation . y < 0 ) { nextLocation . y = SnakeWebSocketServlet . PLAYFIELD_HEIGHT ; } if ( direction != Direction . NONE ) { tail . addFirst ( head ) ; if ( tail . size ( ) > length ) { tail . removeLast ( ) ; } head = nextLocation ; } handleCollisions ( snakes ) ; } private void handleCollisions ( Collection < Snake > snakes ) { for ( Snake snake : snakes ) { boolean headCollision = id != snake . id && snake . getHead ( ) . equals ( head ) ; boolean tailCollision = snake . getTail ( ) . contains ( head ) ; if ( headCollision || tailCollision ) { kill ( ) ; if ( id != snake . id ) { snake . reward ( ) ; } } } } public synchronized Location getHead ( ) { return head ; } public synchronized Collection < Location > getTail ( ) { return tail ; } public synchronized void setDirection ( Direction direction ) { this . direction = direction ; } public synchronized String getLocationsJson ( ) { StringBuilder sb = new StringBuilder ( ) ; sb . append ( String . format ( ""{x: %d, y: %d}"" , Integer . valueOf ( head . x ) , Integer . valueOf ( head . y ) ) ) ; for ( Location location : tail ) { sb . append ( ',' ) ; sb . append ( String . format ( ""{x: %d, y: %d}"" , Integer . valueOf ( location . x ) , Integer . valueOf ( location . y ) ) ) ; } return String . format ( ""{'id':%d,'body':[%s]}"" , Integer . valueOf ( id ) , sb . toString ( ) ) ; } public int getId ( ) { return id ; } public String getHexColor ( ) { return hexColor ; } }",Smelly
"public class DriverAdapterCPDS implements ConnectionPoolDataSource , Referenceable , Serializable , ObjectFactory { private static final String KEY_USER = ""user"" ; private static final String KEY_PASSWORD = ""password"" ; private static final long serialVersionUID = - 4820523787212147844L ; private static final String GET_CONNECTION_CALLED = ""A PooledConnection was already requested from this source, "" + ""further initialization is not allowed."" ; private String description ; private String url ; private String userName ; private char [ ] userPassword ; private String driver ; private int loginTimeout ; private transient PrintWriter logWriter ; private boolean poolPreparedStatements ; private int maxIdle = 10 ; private long timeBetweenEvictionRunsMillis = BaseObjectPoolConfig . DEFAULT_TIME_BETWEEN_EVICTION_RUNS_MILLIS ; private int numTestsPerEvictionRun = - 1 ; private int minEvictableIdleTimeMillis = - 1 ; private int maxPreparedStatements = - 1 ; private volatile boolean getConnectionCalled ; private Properties connectionProperties ; static { DriverManager . getDrivers ( ) ; } private boolean accessToUnderlyingConnectionAllowed ; public DriverAdapterCPDS ( ) { } @ Override public PooledConnection getPooledConnection ( ) throws SQLException { return getPooledConnection ( getUser ( ) , getPassword ( ) ) ; } @ Override public PooledConnection getPooledConnection ( final String pooledUserName , final String pooledUserPassword ) throws SQLException { getConnectionCalled = true ; PooledConnectionImpl pooledConnection = null ; try { if ( connectionProperties != null ) { update ( connectionProperties , KEY_USER , pooledUserName ) ; update ( connectionProperties , KEY_PASSWORD , pooledUserPassword ) ; pooledConnection = new PooledConnectionImpl ( DriverManager . getConnection ( getUrl ( ) , connectionProperties ) ) ; } else { pooledConnection = new PooledConnectionImpl ( DriverManager . getConnection ( getUrl ( ) , pooledUserName , pooledUserPassword ) ) ; } pooledConnection . setAccessToUnderlyingConnectionAllowed ( isAccessToUnderlyingConnectionAllowed ( ) ) ; } catch ( final ClassCircularityError e ) { if ( connectionProperties != null ) { pooledConnection = new PooledConnectionImpl ( DriverManager . getConnection ( getUrl ( ) , connectionProperties ) ) ; } else { pooledConnection = new PooledConnectionImpl ( DriverManager . getConnection ( getUrl ( ) , pooledUserName , pooledUserPassword ) ) ; } pooledConnection . setAccessToUnderlyingConnectionAllowed ( isAccessToUnderlyingConnectionAllowed ( ) ) ; } KeyedObjectPool < PStmtKey , DelegatingPreparedStatement > stmtPool = null ; if ( isPoolPreparedStatements ( ) ) { final GenericKeyedObjectPoolConfig < DelegatingPreparedStatement > config = new GenericKeyedObjectPoolConfig < > ( ) ; config . setMaxTotalPerKey ( Integer . MAX_VALUE ) ; config . setBlockWhenExhausted ( false ) ; config . setMaxWaitMillis ( 0 ) ; config . setMaxIdlePerKey ( getMaxIdle ( ) ) ; if ( getMaxPreparedStatements ( ) <= 0 ) { config . setTimeBetweenEvictionRunsMillis ( getTimeBetweenEvictionRunsMillis ( ) ) ; config . setNumTestsPerEvictionRun ( getNumTestsPerEvictionRun ( ) ) ; config . setMinEvictableIdleTimeMillis ( getMinEvictableIdleTimeMillis ( ) ) ; } else { config . setMaxTotal ( getMaxPreparedStatements ( ) ) ; config . setTimeBetweenEvictionRunsMillis ( - 1 ) ; config . setNumTestsPerEvictionRun ( 0 ) ; config . setMinEvictableIdleTimeMillis ( 0 ) ; } stmtPool = new GenericKeyedObjectPool < > ( pooledConnection , config ) ; pooledConnection . setStatementPool ( stmtPool ) ; } return pooledConnection ; } @ Override public Logger getParentLogger ( ) throws SQLFeatureNotSupportedException { throw new SQLFeatureNotSupportedException ( ) ; } @ Override public Reference getReference ( ) throws NamingException { final String factory = getClass ( ) . getName ( ) ; final Reference ref = new Reference ( getClass ( ) . getName ( ) , factory , null ) ; ref . add ( new StringRefAddr ( ""description"" , getDescription ( ) ) ) ; ref . add ( new StringRefAddr ( ""driver"" , getDriver ( ) ) ) ; ref . add ( new StringRefAddr ( ""loginTimeout"" , String . valueOf ( getLoginTimeout ( ) ) ) ) ; ref . add ( new StringRefAddr ( KEY_PASSWORD , getPassword ( ) ) ) ; ref . add ( new StringRefAddr ( KEY_USER , getUser ( ) ) ) ; ref . add ( new StringRefAddr ( ""url"" , getUrl ( ) ) ) ; ref . add ( new StringRefAddr ( ""poolPreparedStatements"" , String . valueOf ( isPoolPreparedStatements ( ) ) ) ) ; ref . add ( new StringRefAddr ( ""maxIdle"" , String . valueOf ( getMaxIdle ( ) ) ) ) ; ref . add ( new StringRefAddr ( ""timeBetweenEvictionRunsMillis"" , String . valueOf ( getTimeBetweenEvictionRunsMillis ( ) ) ) ) ; ref . add ( new StringRefAddr ( ""numTestsPerEvictionRun"" , String . valueOf ( getNumTestsPerEvictionRun ( ) ) ) ) ; ref . add ( new StringRefAddr ( ""minEvictableIdleTimeMillis"" , String . valueOf ( getMinEvictableIdleTimeMillis ( ) ) ) ) ; ref . add ( new StringRefAddr ( ""maxPreparedStatements"" , String . valueOf ( getMaxPreparedStatements ( ) ) ) ) ; return ref ; } @ Override public Object getObjectInstance ( final Object refObj , final Name name , final Context context , final Hashtable < ? , ? > env ) throws Exception { DriverAdapterCPDS cpds = null ; if ( refObj instanceof Reference ) { final Reference ref = ( Reference ) refObj ; if ( ref . getClassName ( ) . equals ( getClass ( ) . getName ( ) ) ) { RefAddr ra = ref . get ( ""description"" ) ; if ( ra != null && ra . getContent ( ) != null ) { setDescription ( ra . getContent ( ) . toString ( ) ) ; } ra = ref . get ( ""driver"" ) ; if ( ra != null && ra . getContent ( ) != null ) { setDriver ( ra . getContent ( ) . toString ( ) ) ; } ra = ref . get ( ""url"" ) ; if ( ra != null && ra . getContent ( ) != null ) { setUrl ( ra . getContent ( ) . toString ( ) ) ; } ra = ref . get ( KEY_USER ) ; if ( ra != null && ra . getContent ( ) != null ) { setUser ( ra . getContent ( ) . toString ( ) ) ; } ra = ref . get ( KEY_PASSWORD ) ; if ( ra != null && ra . getContent ( ) != null ) { setPassword ( ra . getContent ( ) . toString ( ) ) ; } ra = ref . get ( ""poolPreparedStatements"" ) ; if ( ra != null && ra . getContent ( ) != null ) { setPoolPreparedStatements ( Boolean . valueOf ( ra . getContent ( ) . toString ( ) ) . booleanValue ( ) ) ; } ra = ref . get ( ""maxIdle"" ) ; if ( ra != null && ra . getContent ( ) != null ) { setMaxIdle ( Integer . parseInt ( ra . getContent ( ) . toString ( ) ) ) ; } ra = ref . get ( ""timeBetweenEvictionRunsMillis"" ) ; if ( ra != null && ra . getContent ( ) != null ) { setTimeBetweenEvictionRunsMillis ( Integer . parseInt ( ra . getContent ( ) . toString ( ) ) ) ; } ra = ref . get ( ""numTestsPerEvictionRun"" ) ; if ( ra != null && ra . getContent ( ) != null ) { setNumTestsPerEvictionRun ( Integer . parseInt ( ra . getContent ( ) . toString ( ) ) ) ; } ra = ref . get ( ""minEvictableIdleTimeMillis"" ) ; if ( ra != null && ra . getContent ( ) != null ) { setMinEvictableIdleTimeMillis ( Integer . parseInt ( ra . getContent ( ) . toString ( ) ) ) ; } ra = ref . get ( ""maxPreparedStatements"" ) ; if ( ra != null && ra . getContent ( ) != null ) { setMaxPreparedStatements ( Integer . parseInt ( ra . getContent ( ) . toString ( ) ) ) ; } ra = ref . get ( ""accessToUnderlyingConnectionAllowed"" ) ; if ( ra != null && ra . getContent ( ) != null ) { setAccessToUnderlyingConnectionAllowed ( Boolean . valueOf ( ra . getContent ( ) . toString ( ) ) . booleanValue ( ) ) ; } cpds = this ; } } return cpds ; } private void assertInitializationAllowed ( ) throws IllegalStateException { if ( getConnectionCalled ) { throw new IllegalStateException ( GET_CONNECTION_CALLED ) ; } } public Properties getConnectionProperties ( ) { return connectionProperties ; } public void setConnectionProperties ( final Properties props ) { assertInitializationAllowed ( ) ; connectionProperties = props ; if ( connectionProperties != null ) { if ( connectionProperties . containsKey ( KEY_USER ) ) { setUser ( connectionProperties . getProperty ( KEY_USER ) ) ; } if ( connectionProperties . containsKey ( KEY_PASSWORD ) ) { setPassword ( connectionProperties . getProperty ( KEY_PASSWORD ) ) ; } } } public String getDescription ( ) { return description ; } public void setDescription ( final String v ) { this . description = v ; } public char [ ] getPasswordCharArray ( ) { return userPassword ; } public String getPassword ( ) { return Utils . toString ( userPassword ) ; } public void setPassword ( final char [ ] userPassword ) { assertInitializationAllowed ( ) ; this . userPassword = userPassword ; update ( connectionProperties , KEY_PASSWORD , Utils . toString ( userPassword ) ) ; } public void setPassword ( final String userPassword ) { assertInitializationAllowed ( ) ; this . userPassword = Utils . toCharArray ( userPassword ) ; update ( connectionProperties , KEY_PASSWORD , userPassword ) ; } public String getUrl ( ) { return url ; } public void setUrl ( final String v ) { assertInitializationAllowed ( ) ; this . url = v ; } public String getUser ( ) { return userName ; } public void setUser ( final String v ) { assertInitializationAllowed ( ) ; this . userName = v ; update ( connectionProperties , KEY_USER , v ) ; } public String getDriver ( ) { return driver ; } public void setDriver ( final String v ) throws ClassNotFoundException { assertInitializationAllowed ( ) ; this . driver = v ; Class . forName ( v ) ; } @ Override public int getLoginTimeout ( ) { return loginTimeout ; } @ Override public PrintWriter getLogWriter ( ) { return logWriter ; } @ Override public void setLoginTimeout ( final int seconds ) { loginTimeout = seconds ; } @ Override public void setLogWriter ( final PrintWriter out ) { logWriter = out ; } public boolean isPoolPreparedStatements ( ) { return poolPreparedStatements ; } public void setPoolPreparedStatements ( final boolean poolPreparedStatements ) { assertInitializationAllowed ( ) ; this . poolPreparedStatements = poolPreparedStatements ; } public int getMaxIdle ( ) { return this . maxIdle ; } public void setMaxIdle ( final int maxIdle ) { assertInitializationAllowed ( ) ; this . maxIdle = maxIdle ; } public long getTimeBetweenEvictionRunsMillis ( ) { return timeBetweenEvictionRunsMillis ; } public void setTimeBetweenEvictionRunsMillis ( final long timeBetweenEvictionRunsMillis ) { assertInitializationAllowed ( ) ; this . timeBetweenEvictionRunsMillis = timeBetweenEvictionRunsMillis ; } public int getNumTestsPerEvictionRun ( ) { return numTestsPerEvictionRun ; } public void setNumTestsPerEvictionRun ( final int numTestsPerEvictionRun ) { assertInitializationAllowed ( ) ; this . numTestsPerEvictionRun = numTestsPerEvictionRun ; } public int getMinEvictableIdleTimeMillis ( ) { return minEvictableIdleTimeMillis ; } public void setMinEvictableIdleTimeMillis ( final int minEvictableIdleTimeMillis ) { assertInitializationAllowed ( ) ; this . minEvictableIdleTimeMillis = minEvictableIdleTimeMillis ; } public synchronized boolean isAccessToUnderlyingConnectionAllowed ( ) { return this . accessToUnderlyingConnectionAllowed ; } public synchronized void setAccessToUnderlyingConnectionAllowed ( final boolean allow ) { this . accessToUnderlyingConnectionAllowed = allow ; } public int getMaxPreparedStatements ( ) { return maxPreparedStatements ; } public void setMaxPreparedStatements ( final int maxPreparedStatements ) { this . maxPreparedStatements = maxPreparedStatements ; } private void update ( final Properties properties , final String key , final String value ) { if ( properties != null ) { if ( value == null ) { properties . remove ( key ) ; } else { properties . setProperty ( key , value ) ; } } } }",Smelly
"@ Entity @ Table ( name = ""x_policy_export_audit"" ) @ XmlRootElement public class XXPolicyExportAudit extends XXDBBase implements java . io . Serializable { private static final long serialVersionUID = 1L ; @ Id @ SequenceGenerator ( name = ""X_POLICY_EXPORT_SEQ"" , sequenceName = ""X_POLICY_EXPORT_SEQ"" , allocationSize = 1 ) @ GeneratedValue ( strategy = GenerationType . AUTO , generator = ""X_POLICY_EXPORT_SEQ"" ) @ Column ( name = ""ID"" ) protected Long id ; @ Override public void setId ( Long id ) { this . id = id ; } @ Override public Long getId ( ) { return id ; } @ Column ( name = ""CLIENT_IP"" , nullable = false , length = 255 ) protected String clientIP ; @ Column ( name = ""AGENT_ID"" , length = 255 ) protected String agentId ; @ Column ( name = ""REQ_EPOCH"" , nullable = false ) protected Long requestedEpoch ; @ Temporal ( TemporalType . TIMESTAMP ) @ Column ( name = ""LAST_UPDATED"" ) protected Date lastUpdated ; @ Column ( name = ""REPOSITORY_NAME"" , length = 1024 ) protected String repositoryName ; @ Column ( name = ""EXPORTED_JSON"" , length = 30000 ) protected String exportedJson ; @ Column ( name = ""HTTP_RET_CODE"" , nullable = false ) protected int httpRetCode ; @ Column ( name = ""CLUSTER_NAME"" , nullable = false , length = 255 ) protected String clusterName ; public XXPolicyExportAudit ( ) { } @ Override public int getMyClassType ( ) { return AppConstants . CLASS_TYPE_XA_POLICY_EXPORT_AUDIT ; } public void setClientIP ( String clientIP ) { this . clientIP = clientIP ; } public String getClientIP ( ) { return this . clientIP ; } public void setAgentId ( String agentId ) { this . agentId = agentId ; } public String getAgentId ( ) { return this . agentId ; } public void setRequestedEpoch ( Long requestedEpoch ) { this . requestedEpoch = requestedEpoch ; } public Long getRequestedEpoch ( ) { return this . requestedEpoch ; } public void setLastUpdated ( Date lastUpdated ) { this . lastUpdated = lastUpdated ; } public Date getLastUpdated ( ) { return this . lastUpdated ; } public void setRepositoryName ( String repositoryName ) { this . repositoryName = repositoryName ; } public String getRepositoryName ( ) { return this . repositoryName ; } public void setExportedJson ( String exportedJson ) { this . exportedJson = exportedJson ; } public String getExportedJson ( ) { return this . exportedJson ; } public void setHttpRetCode ( int httpRetCode ) { this . httpRetCode = httpRetCode ; } public int getHttpRetCode ( ) { return this . httpRetCode ; } public void setClusterName ( String clusterName ) { this . clusterName = clusterName ; } public String getClusterName ( ) { return clusterName ; } @ Override public String toString ( ) { String str = ""XXPolicyExportAudit={"" ; str += super . toString ( ) ; str += ""clientIP={"" + clientIP + ""} "" ; str += ""agentId={"" + agentId + ""} "" ; str += ""requestedEpoch={"" + requestedEpoch + ""} "" ; str += ""lastUpdated={"" + lastUpdated + ""} "" ; str += ""repositoryName={"" + repositoryName + ""} "" ; str += ""exportedJson={"" + exportedJson + ""} "" ; str += ""httpRetCode={"" + httpRetCode + ""} "" ; str += ""clusterName={"" + clusterName + ""} "" ; str += ""}"" ; return str ; } @ Override public boolean equals ( Object obj ) { if ( ! super . equals ( obj ) ) { return false ; } XXPolicyExportAudit other = ( XXPolicyExportAudit ) obj ; if ( ( this . clientIP == null && other . clientIP != null ) || ( this . clientIP != null && ! this . clientIP . equals ( other . clientIP ) ) ) { return false ; } if ( ( this . agentId == null && other . agentId != null ) || ( this . agentId != null && ! this . agentId . equals ( other . agentId ) ) ) { return false ; } if ( ( this . requestedEpoch == null && other . requestedEpoch != null ) || ( this . requestedEpoch != null && ! this . requestedEpoch . equals ( other . requestedEpoch ) ) ) { return false ; } if ( ( this . lastUpdated == null && other . lastUpdated != null ) || ( this . lastUpdated != null && ! this . lastUpdated . equals ( other . lastUpdated ) ) ) { return false ; } if ( ( this . repositoryName == null && other . repositoryName != null ) || ( this . repositoryName != null && ! this . repositoryName . equals ( other . repositoryName ) ) ) { return false ; } if ( ( this . exportedJson == null && other . exportedJson != null ) || ( this . exportedJson != null && ! this . exportedJson . equals ( other . exportedJson ) ) ) { return false ; } if ( this . httpRetCode != other . httpRetCode ) return false ; if ( ( this . clusterName == null && other . clusterName != null ) || ( this . clusterName != null && ! this . clusterName . equals ( other . clusterName ) ) ) { return false ; } return true ; } public static String getEnumName ( String fieldName ) { return null ; } }",Smelly
"@ Entity public class MultipleSameTypedEmbedded { @ Id @ GeneratedValue private long id ; private String name ; @ Embedded @ AttributeOverride ( name = ""name"" , column = @ Column ( name = ""E1_NAME"" ) ) @ AssociationOverride ( name = ""rel"" , joinColumns = @ JoinColumn ( name = ""E1_REL"" ) ) private EmbeddableWithRelation embed1 ; @ Embedded @ AttributeOverride ( name = ""name"" , column = @ Column ( name = ""E2_NAME"" ) ) @ AssociationOverride ( name = ""rel"" , joinColumns = @ JoinColumn ( name = ""E2_REL"" ) ) private EmbeddableWithRelation embed2 ; @ Version private Integer optLock ; public long getId ( ) { return id ; } public EmbeddableWithRelation getEmbed1 ( ) { return embed1 ; } public void setEmbed1 ( EmbeddableWithRelation embed1 ) { this . embed1 = embed1 ; } public EmbeddableWithRelation getEmbed2 ( ) { return embed2 ; } public void setEmbed2 ( EmbeddableWithRelation embed2 ) { this . embed2 = embed2 ; } public String getName ( ) { return name ; } public void setName ( String name ) { this . name = name ; } }",Smelly
"@ Entity @ Table ( name = ""L2_AttachE"" ) public class AttachE implements Serializable { private Object version ; private String estr ; private int eint ; private double edbl ; private AttachB b ; private AttachF f ; private Date date ; public void setEstr ( String estr ) { this . estr = estr ; } public String getEstr ( ) { return this . estr ; } public void setEint ( int eint ) { this . eint = eint ; } public int getEint ( ) { return this . eint ; } public void setEdbl ( double edbl ) { this . edbl = edbl ; } public double getEdbl ( ) { return this . edbl ; } public void setB ( AttachB b ) { this . b = b ; } public AttachB getB ( ) { return this . b ; } public void setF ( AttachF f ) { this . f = f ; } public AttachF getF ( ) { return this . f ; } public void setDate ( Date date ) { this . date = date ; } public Date getDate ( ) { return this . date ; } }",Smelly
" public static class State { public final int id ; public final PrimitiveColumnIO primitiveColumnIO ; public final int maxDefinitionLevel ; public final int maxRepetitionLevel ; public final PrimitiveTypeName primitive ; public final ColumnReader column ; public final String [ ] fieldPath ; public final int [ ] indexFieldPath ; public final GroupConverter [ ] groupConverterPath ; public final PrimitiveConverter primitiveConverter ; public final String primitiveField ; public final int primitiveFieldIndex ; public final int [ ] nextLevel ; private int [ ] definitionLevelToDepth ; private State [ ] nextState ; private Case [ ] [ ] [ ] caseLookup ; private List < Case > definedCases ; private List < Case > undefinedCases ; private State ( int id , PrimitiveColumnIO primitiveColumnIO , ColumnReader column , int [ ] nextLevel , GroupConverter [ ] groupConverterPath , PrimitiveConverter primitiveConverter ) { this . id = id ; this . primitiveColumnIO = primitiveColumnIO ; this . maxDefinitionLevel = primitiveColumnIO . getDefinitionLevel ( ) ; this . maxRepetitionLevel = primitiveColumnIO . getRepetitionLevel ( ) ; this . column = column ; this . nextLevel = nextLevel ; this . groupConverterPath = groupConverterPath ; this . primitiveConverter = primitiveConverter ; this . primitive = primitiveColumnIO . getType ( ) . asPrimitiveType ( ) . getPrimitiveTypeName ( ) ; this . fieldPath = primitiveColumnIO . getFieldPath ( ) ; this . primitiveField = fieldPath [ fieldPath . length - 1 ] ; this . indexFieldPath = primitiveColumnIO . getIndexFieldPath ( ) ; this . primitiveFieldIndex = indexFieldPath [ indexFieldPath . length - 1 ] ; } public int getDepth ( int definitionLevel ) { return definitionLevelToDepth [ definitionLevel ] ; } public List < Case > getDefinedCases ( ) { return definedCases ; } public List < Case > getUndefinedCases ( ) { return undefinedCases ; } public Case getCase ( int currentLevel , int d , int nextR ) { return caseLookup [ currentLevel ] [ d ] [ nextR ] ; } public State getNextState ( int nextR ) { return nextState [ nextR ] ; } ",Smelly
"@ RunWith ( FrameworkRunner . class ) @ CreateDS ( name = ""AddPerfDS"" , partitions = { @ CreatePartition ( name = ""example"" , suffix = ""dc=example,dc=com"" , contextEntry = @ ContextEntry ( entryLdif = ""dn: dc=example,dc=com\n"" + ""dc: example\n"" + ""objectClass: top\n"" + ""objectClass: domain\n\n"" ) , indexes = { @ CreateIndex ( attribute = ""objectClass"" ) , @ CreateIndex ( attribute = ""sn"" ) , @ CreateIndex ( attribute = ""cn"" ) , @ CreateIndex ( attribute = ""displayName"" ) } ) , @ CreatePartition ( name = ""test"" , suffix = ""dc=test,dc=com"" , contextEntry = @ ContextEntry ( entryLdif = ""dn: dc=test,dc=com\n"" + ""dc: test\n"" + ""objectClass: top\n"" + ""objectClass: domain\n\n"" ) , indexes = { @ CreateIndex ( attribute = ""objectClass"" ) , @ CreateIndex ( attribute = ""sn"" ) , @ CreateIndex ( attribute = ""cn"" ) , @ CreateIndex ( attribute = ""displayName"" ) } ) } , enableChangeLog = true ) @ CreateLdapServer ( transports = { @ CreateTransport ( protocol = ""LDAP"" ) , @ CreateTransport ( protocol = ""LDAPS"" ) } ) public class OperationWithIndexTest extends AbstractLdapTestUnit { private LdapNetworkConnection connection ; @ Before public void setup ( ) throws Exception { connection = ( LdapNetworkConnection ) LdapApiIntegrationUtils . getPooledAdminConnection ( getLdapServer ( ) ) ; connection . setTimeOut ( 0 ) ; getService ( ) . shutdown ( ) ; getService ( ) . startup ( ) ; } @ After public void shutdown ( ) throws Exception { LdapApiIntegrationUtils . releasePooledAdminConnection ( connection , getLdapServer ( ) ) ; } @ Test @ Ignore public void testAddPerf ( ) throws Exception { Dn dn = new Dn ( ""cn=test,ou=system"" ) ; Entry entry = new DefaultEntry ( getService ( ) . getSchemaManager ( ) , dn , ""ObjectClass: top"" , ""ObjectClass: person"" , ""sn: TEST"" , ""cn: test"" ) ; connection . add ( entry ) ; int nbIterations = 8000 ; long t0 = System . currentTimeMillis ( ) ; long t00 = 0L ; long tt0 = System . currentTimeMillis ( ) ; for ( int i = 0 ; i < nbIterations ; i ++ ) { if ( i % 1000 == 0 ) { long tt1 = System . currentTimeMillis ( ) ; System . out . println ( i + "", "" + ( tt1 - tt0 ) ) ; tt0 = tt1 ; } if ( i == 500 ) { t00 = System . currentTimeMillis ( ) ; } dn = new Dn ( ""uid="" + i + "",dc=example,dc=com"" ) ; entry = new DefaultEntry ( getService ( ) . getSchemaManager ( ) , dn , ""objectClass: top"" , ""objectClass: person"" , ""objectClass: organizationalPerson"" , ""objectClass: inetOrgPerson"" , ""uid"" , Integer . toString ( i ) , ""mail: A-A-R.Awg-Rosli@acme.com"" , ""title: Snr Operations Technician (D)"" , ""sn: Awg-Rosli"" , ""departmentNumber: SMDS - UIA/G/MMO52D"" , ""cn: Awg-Rosli, Awg-Abd-Rahim SMDS-UIA/G/MMO52D"" , ""description: UI - S"" , ""telephoneNumber: 555-1212"" , ""givenName: Awg-Abd-Rahim"" , ""businessCategory: Ops MDS (Malaysia) Sdn Bhd"" , ""displayName"" , i + ""Awg-Rosli, Awg-Abd-Rahim SMDS-UIA/G/MMO52D"" , ""employeeNumber: A-A-R.Awg-Rosli"" , ""pwdPolicySubEntry: ads-pwdId=cproint,ou=passwordPolicies,ads-interceptorId=authenticationInterceptor,ou=interceptors,ads-directoryServiceId=default,ou=config"" ) ; connection . add ( entry ) ; } long t1 = System . currentTimeMillis ( ) ; Long deltaWarmed = ( t1 - t00 ) ; System . out . println ( ""Delta : "" + deltaWarmed + ""( "" + ( ( ( nbIterations - 500 ) * 1000 ) / deltaWarmed ) + "" per s ) /"" + ( t1 - t0 ) ) ; Entry entry1 = null ; Entry entry2 = null ; Entry entry3 = null ; long ns0 = System . currentTimeMillis ( ) ; EntryCursor results = connection . search ( ""dc=example,dc=com"" , ""(displayName=1234Awg-Rosli, Awg-Abd-Rahim SMDS-UIA/G/MMO52D)"" , SearchScope . SUBTREE , ""*"" ) ; while ( results . next ( ) ) { if ( entry1 == null ) { entry1 = results . get ( ) ; } } results . close ( ) ; long ns1 = System . currentTimeMillis ( ) ; System . out . println ( ""Delta search : "" + ( ns1 - ns0 ) ) ; long ns2 = System . currentTimeMillis ( ) ; results = connection . search ( ""dc=example,dc=com"" , ""(displayName=3456*)"" , SearchScope . SUBTREE , ""*"" ) ; while ( results . next ( ) ) { if ( entry2 == null ) { entry2 = results . get ( ) ; } } results . close ( ) ; long ns3 = System . currentTimeMillis ( ) ; System . out . println ( ""Delta search substring : "" + ( ns3 - ns2 ) ) ; long ns4 = System . currentTimeMillis ( ) ; results = connection . search ( ""dc=example,dc=com"" , ""(uid=6789)"" , SearchScope . SUBTREE , ""*"" ) ; while ( results . next ( ) ) { if ( entry3 == null ) { entry3 = results . get ( ) ; } } results . close ( ) ; long ns5 = System . currentTimeMillis ( ) ; System . out . println ( ""Delta search no index : "" + ( ns5 - ns4 ) ) ; connection . close ( ) ; System . out . println ( ""--------------> Shuting Down"" ) ; long ns6 = System . currentTimeMillis ( ) ; getService ( ) . shutdown ( ) ; long ns7 = System . currentTimeMillis ( ) ; System . out . println ( ""--------------> completed in "" + ( ns7 - ns6 ) ) ; long ns8 = System . currentTimeMillis ( ) ; getService ( ) . startup ( ) ; long ns9 = System . currentTimeMillis ( ) ; System . out . println ( ""--------------> Starting up completed in "" + ( ns9 - ns8 ) ) ; connection = ( LdapNetworkConnection ) LdapApiIntegrationUtils . getPooledAdminConnection ( getLdapServer ( ) ) ; long ns10 = System . currentTimeMillis ( ) ; results = connection . search ( ""dc=example,dc=com"" , ""(displayName=345*)"" , SearchScope . SUBTREE , ""*"" ) ; while ( results . next ( ) ) { entry3 = results . get ( ) ; break ; } results . close ( ) ; long ns11 = System . currentTimeMillis ( ) ; System . out . println ( ""New Delta search substring : "" + ( ns11 - ns10 ) ) ; connection . close ( ) ; System . out . println ( ""--------------> Shuting Down 2"" ) ; long ns12 = System . currentTimeMillis ( ) ; getService ( ) . shutdown ( ) ; long ns13 = System . currentTimeMillis ( ) ; System . out . println ( ""--------------> completed in "" + ( ns13 - ns12 ) ) ; long ns14 = System . currentTimeMillis ( ) ; getService ( ) . startup ( ) ; long ns15 = System . currentTimeMillis ( ) ; System . out . println ( ""--------------> Starting up completed in "" + ( ns15 - ns14 ) ) ; connection = ( LdapNetworkConnection ) LdapApiIntegrationUtils . getPooledAdminConnection ( getLdapServer ( ) ) ; long ns16 = System . currentTimeMillis ( ) ; results = connection . search ( ""dc=example,dc=com"" , ""(displayName=345*)"" , SearchScope . SUBTREE , ""*"" ) ; while ( results . next ( ) ) { entry3 = results . get ( ) ; break ; } results . close ( ) ; long ns17 = System . currentTimeMillis ( ) ; System . out . println ( ""New Delta search substring : "" + ( ns17 - ns16 ) ) ; connection . close ( ) ; } @ Test public void testModify ( ) throws Exception { Dn dn = new Dn ( ""uid=1,dc=example,dc=com"" ) ; Entry entry = new DefaultEntry ( getService ( ) . getSchemaManager ( ) , dn , ""objectClass: top"" , ""objectClass: person"" , ""objectClass: organizationalPerson"" , ""objectClass: inetOrgPerson"" , ""uid: 1"" , ""mail: test@acme.com"" , ""title: technician"" , ""sn: Test"" , ""departmentNumber: Dep1"" , ""cn: entryTest"" , ""description: Test entry"" , ""telephoneNumber: 123 456"" , ""givenName: Test user"" , ""businessCategory: Test ops"" , ""displayName: testUser"" , ""employeeNumber: Test user"" , ""pwdPolicySubEntry: ads-pwdId=cproint,ou=passwordPolicies,ads-interceptorId=authenticationInterceptor,ou=interceptors,ads-directoryServiceId=default,ou=config"" ) ; connection . add ( entry ) ; EntryCursor results = connection . search ( ""dc=example,dc=com"" , ""(displayName=T*)"" , SearchScope . SUBTREE , ""*"" ) ; while ( results . next ( ) ) { Entry result = results . get ( ) ; assertTrue ( result . contains ( ""displayName"" , ""testUser"" ) ) ; } results . close ( ) ; connection . modify ( dn , new DefaultModification ( ModificationOperation . REPLACE_ATTRIBUTE , ""displayName"" , ""anotherTest"" ) ) ; results = connection . search ( ""dc=example,dc=com"" , ""(displayName=a*)"" , SearchScope . SUBTREE , ""*"" ) ; while ( results . next ( ) ) { Entry result = results . get ( ) ; assertTrue ( result . contains ( ""displayName"" , ""anotherTest"" ) ) ; } results . close ( ) ; results = connection . search ( ""dc=example,dc=com"" , ""(displayName=T*)"" , SearchScope . SUBTREE , ""*"" ) ; assertFalse ( results . next ( ) ) ; results . close ( ) ; connection . delete ( dn ) ; } @ Test public void testModifyReplace ( ) throws LdapException , CursorException , IOException { Dn dn = new Dn ( ""uid=1,dc=example,dc=com"" ) ; Entry entry = new DefaultEntry ( getService ( ) . getSchemaManager ( ) , dn , ""objectClass: top"" , ""objectClass: person"" , ""objectClass: organizationalPerson"" , ""objectClass: inetOrgPerson"" , ""uid: 1"" , ""mail: test@acme.com"" , ""title: technician"" , ""sn: Test"" , ""departmentNumber: Dep1"" , ""cn: entryTest"" , ""description: Test entry"" , ""telephoneNumber: 123 456"" , ""givenName: Test user"" , ""businessCategory: Test ops"" , ""displayName: testUser"" , ""employeeNumber: Test user"" , ""pwdPolicySubEntry: ads-pwdId=cproint,ou=passwordPolicies,ads-interceptorId=authenticationInterceptor,ou=interceptors,ads-directoryServiceId=default,ou=config"" ) ; connection . add ( entry ) ; EntryCursor results = connection . search ( ""dc=example,dc=com"" , ""(cn=e*)"" , SearchScope . SUBTREE , ""*"" ) ; int nbFound = 0 ; while ( results . next ( ) ) { Entry result = results . get ( ) ; assertTrue ( result . contains ( ""cn"" , ""entryTest"" ) ) ; nbFound ++ ; } results . close ( ) ; assertEquals ( 1 , nbFound ) ; Modification modification = new DefaultModification ( ModificationOperation . REPLACE_ATTRIBUTE , ""cn"" , ""New cn"" ) ; connection . modify ( dn , modification ) ; results = connection . search ( ""dc=example,dc=com"" , ""(cn=e*)"" , SearchScope . SUBTREE , ""*"" ) ; assertFalse ( results . next ( ) ) ; results . close ( ) ; results = connection . search ( ""dc=example,dc=com"" , ""(cn=n*)"" , SearchScope . SUBTREE , ""*"" ) ; nbFound = 0 ; while ( results . next ( ) ) { Entry result = results . get ( ) ; assertTrue ( result . contains ( ""cn"" , ""New cn"" ) ) ; nbFound ++ ; } assertEquals ( 1 , nbFound ) ; results . close ( ) ; results = connection . search ( ""dc=example,dc=com"" , ""(cn=*)"" , SearchScope . SUBTREE , ""*"" ) ; nbFound = 0 ; while ( results . next ( ) ) { Entry result = results . get ( ) ; assertTrue ( result . contains ( ""cn"" , ""New cn"" ) ) ; nbFound ++ ; } assertEquals ( 1 , nbFound ) ; results . close ( ) ; connection . delete ( dn ) ; } @ Test public void testModifyAdd ( ) throws LdapException , CursorException , IOException { Dn dn = new Dn ( ""uid=1,dc=example,dc=com"" ) ; Entry entry = new DefaultEntry ( getService ( ) . getSchemaManager ( ) , dn , ""objectClass: top"" , ""objectClass: person"" , ""objectClass: organizationalPerson"" , ""objectClass: inetOrgPerson"" , ""uid: 1"" , ""mail: test@acme.com"" , ""title: technician"" , ""sn: Test"" , ""departmentNumber: Dep1"" , ""cn: entryTest"" , ""description: Test entry"" , ""telephoneNumber: 123 456"" , ""givenName: Test user"" , ""businessCategory: Test ops"" , ""employeeNumber: Test user"" , ""pwdPolicySubEntry: ads-pwdId=cproint,ou=passwordPolicies,ads-interceptorId=authenticationInterceptor,ou=interceptors,ads-directoryServiceId=default,ou=config"" ) ; connection . add ( entry ) ; EntryCursor results = connection . search ( ""dc=example,dc=com"" , ""(cn=e*)"" , SearchScope . SUBTREE , ""*"" ) ; int nbFound = 0 ; while ( results . next ( ) ) { Entry result = results . get ( ) ; assertTrue ( result . contains ( ""cn"" , ""entryTest"" ) ) ; nbFound ++ ; } results . close ( ) ; assertEquals ( 1 , nbFound ) ; Modification modification = new DefaultModification ( ModificationOperation . ADD_ATTRIBUTE , ""cn"" , ""New cn"" ) ; connection . modify ( dn , modification ) ; results = connection . search ( ""dc=example,dc=com"" , ""(cn=e*)"" , SearchScope . SUBTREE , ""*"" ) ; nbFound = 0 ; while ( results . next ( ) ) { Entry result = results . get ( ) ; assertTrue ( result . contains ( ""cn"" , ""entryTest"" ) ) ; nbFound ++ ; } assertEquals ( 1 , nbFound ) ; results . close ( ) ; results = connection . search ( ""dc=example,dc=com"" , ""(cn=n*)"" , SearchScope . SUBTREE , ""*"" ) ; nbFound = 0 ; while ( results . next ( ) ) { Entry result = results . get ( ) ; assertTrue ( result . contains ( ""cn"" , ""New cn"" ) ) ; nbFound ++ ; } assertEquals ( 1 , nbFound ) ; results . close ( ) ; results = connection . search ( ""dc=example,dc=com"" , ""(cn=*)"" , SearchScope . SUBTREE , ""*"" ) ; nbFound = 0 ; while ( results . next ( ) ) { Entry result = results . get ( ) ; assertTrue ( result . contains ( ""cn"" , ""New cn"" , ""entryTest"" ) ) ; nbFound ++ ; } assertEquals ( 1 , nbFound ) ; results . close ( ) ; modification = new DefaultModification ( ModificationOperation . ADD_ATTRIBUTE , ""displayName"" , ""testUser"" ) ; connection . modify ( dn , modification ) ; results = connection . search ( ""dc=example,dc=com"" , ""(displayName=t*)"" , SearchScope . SUBTREE , ""*"" ) ; nbFound = 0 ; while ( results . next ( ) ) { Entry result = results . get ( ) ; assertTrue ( result . contains ( ""displayName"" , ""testUser"" ) ) ; nbFound ++ ; } assertEquals ( 1 , nbFound ) ; results . close ( ) ; results = connection . search ( ""dc=example,dc=com"" , ""(displayName=*)"" , SearchScope . SUBTREE , ""*"" ) ; nbFound = 0 ; while ( results . next ( ) ) { Entry result = results . get ( ) ; assertTrue ( result . contains ( ""displayName"" , ""testUser"" ) ) ; nbFound ++ ; } assertEquals ( 1 , nbFound ) ; results . close ( ) ; connection . delete ( dn ) ; } @ Test public void testModifyDelete ( ) throws LdapException , CursorException , IOException { Dn dn = new Dn ( ""uid=1,dc=example,dc=com"" ) ; Entry entry = new DefaultEntry ( getService ( ) . getSchemaManager ( ) , dn , ""objectClass: top"" , ""objectClass: person"" , ""objectClass: organizationalPerson"" , ""objectClass: inetOrgPerson"" , ""uid: 1"" , ""mail: test@acme.com"" , ""title: technician"" , ""sn: Test"" , ""departmentNumber: Dep1"" , ""cn: entryTest"" , ""cn: test2"" , ""description: Test entry"" , ""telephoneNumber: 123 456"" , ""givenName: Test user"" , ""displayName: testEntry"" , ""businessCategory: Test ops"" , ""employeeNumber: Test user"" , ""pwdPolicySubEntry: ads-pwdId=cproint,ou=passwordPolicies,ads-interceptorId=authenticationInterceptor,ou=interceptors,ads-directoryServiceId=default,ou=config"" ) ; connection . add ( entry ) ; EntryCursor results = connection . search ( ""dc=example,dc=com"" , ""(cn=e*)"" , SearchScope . SUBTREE , ""*"" ) ; int nbFound = 0 ; while ( results . next ( ) ) { Entry result = results . get ( ) ; assertTrue ( result . contains ( ""cn"" , ""entryTest"" ) ) ; nbFound ++ ; } results . close ( ) ; assertEquals ( 1 , nbFound ) ; Modification modification = new DefaultModification ( ModificationOperation . REMOVE_ATTRIBUTE , ""displayName"" , ""testEntry"" ) ; connection . modify ( dn , modification ) ; results = connection . search ( ""dc=example,dc=com"" , ""(displayName=t*)"" , SearchScope . SUBTREE , ""*"" ) ; assertFalse ( results . next ( ) ) ; results . close ( ) ; results = connection . search ( ""dc=example,dc=com"" , ""(displayName=n*)"" , SearchScope . SUBTREE , ""*"" ) ; assertFalse ( results . next ( ) ) ; results . close ( ) ; modification = new DefaultModification ( ModificationOperation . REMOVE_ATTRIBUTE , ""cn"" , ""test2"" ) ; connection . modify ( dn , modification ) ; results = connection . search ( ""dc=example,dc=com"" , ""(cn=E*)"" , SearchScope . SUBTREE , ""*"" ) ; nbFound = 0 ; while ( results . next ( ) ) { Entry result = results . get ( ) ; assertFalse ( result . contains ( ""cn"" , ""test2"" ) ) ; assertTrue ( result . contains ( ""cn"" , ""entryTest"" ) ) ; nbFound ++ ; } assertEquals ( 1 , nbFound ) ; results . close ( ) ; results = connection . search ( ""dc=example,dc=com"" , ""(cn=t*)"" , SearchScope . SUBTREE , ""*"" ) ; assertFalse ( results . next ( ) ) ; results . close ( ) ; results = connection . search ( ""dc=example,dc=com"" , ""(cn=*)"" , SearchScope . SUBTREE , ""*"" ) ; nbFound = 0 ; while ( results . next ( ) ) { Entry result = results . get ( ) ; assertFalse ( result . contains ( ""cn"" , ""test2"" ) ) ; assertTrue ( result . contains ( ""cn"" , ""entryTest"" ) ) ; nbFound ++ ; } assertEquals ( 1 , nbFound ) ; results . close ( ) ; connection . delete ( dn ) ; } @ Test public void testSimpleSearch ( ) throws Exception { Dn dn1 = new Dn ( ""cn=test,ou=system"" ) ; Entry entry1 = new DefaultEntry ( getService ( ) . getSchemaManager ( ) , dn1 , ""ObjectClass: top"" , ""ObjectClass: person"" , ""sn: TEST"" , ""cn: test"" ) ; connection . add ( entry1 ) ; Dn dn2 = new Dn ( ""cn=test,dc=test,dc=com"" ) ; Entry entry2 = new DefaultEntry ( getService ( ) . getSchemaManager ( ) , dn2 , ""ObjectClass: top"" , ""ObjectClass: person"" , ""sn: TEST"" , ""cn: test"" ) ; connection . add ( entry2 ) ; Dn dn3 = new Dn ( ""cn=test,dc=example,dc=com"" ) ; Entry entry3 = new DefaultEntry ( getService ( ) . getSchemaManager ( ) , dn3 , ""ObjectClass: top"" , ""ObjectClass: person"" , ""sn: TEST"" , ""cn: test"" ) ; connection . add ( entry3 ) ; EntryCursor cursor = connection . search ( """" , ""(cn=test)"" , SearchScope . SUBTREE ) ; List < String > entries = new ArrayList < String > ( ) ; while ( cursor . next ( ) ) { Entry entryFound = cursor . get ( ) ; assertNotNull ( entryFound ) ; entries . add ( entryFound . getDn ( ) . getName ( ) ) ; } SearchResultDone done = cursor . getSearchResultDone ( ) ; assertNotNull ( done ) ; assertEquals ( ResultCodeEnum . SUCCESS , done . getLdapResult ( ) . getResultCode ( ) ) ; assertEquals ( 3 , entries . size ( ) ) ; assertTrue ( entries . contains ( ""cn=test,dc=test,dc=com"" ) ) ; assertTrue ( entries . contains ( ""cn=test,dc=example,dc=com"" ) ) ; assertTrue ( entries . contains ( ""cn=test,ou=system"" ) ) ; cursor . close ( ) ; } }",No
"public class Test01Exceptions extends TestCase { public static void main ( String args [ ] ) { TestRunner . run ( new TestSuite ( Test01Exceptions . class ) ) ; } boolean verbose = false ; final String fieldName = ""bi"" ; String [ ] exceptionQueries = { ""*"" , ""a*"" , ""ab*"" , ""?"" , ""a?"" , ""ab?"" , ""a???b"" , ""a?"" , ""a*b?"" , ""word1 word2"" , ""word2 AND"" , ""word1 OR"" , ""AND(word2)"" , ""AND(word2,)"" , ""AND(word2,word1,)"" , ""OR(word2)"" , ""OR(word2 ,"" , ""OR(word2 , word1 ,)"" , ""xx NOT"" , ""xx (a AND b)"" , ""(a AND b"" , ""a OR b)"" , ""or(word2+ not ord+, and xyz,def)"" , """" } ; public void test01Exceptions ( ) throws Exception { String m = ExceptionQueryTst . getFailQueries ( exceptionQueries , verbose ) ; if ( m . length ( ) > 0 ) { fail ( ""No ParseException for:\n"" + m ) ; } } }",No
@ Entity public class EntityB1 implements Serializable { @ Id int id ; @ Column ( length = 30 ) String name ; @ OneToOne EntityA_Embed_MappedToOne entityA ; public int getId ( ) { return id ; } public void setId ( int id ) { this . id = id ; } public String getName ( ) { return name ; } public void setName ( String name ) { this . name = name ; } public EntityA_Embed_MappedToOne getEntityA ( ) { return entityA ; } public void setEntityA ( EntityA_Embed_MappedToOne entityA ) { this . entityA = entityA ; } },Smelly
"public class QNodeTypeDefinitionBuilder { private Name name = null ; private List < Name > supertypes = new ArrayList < Name > ( ) ; private boolean isMixin = false ; private boolean isOrderable = false ; private Name primaryItemName = null ; private List < QPropertyDefinition > propertyDefinitions = new ArrayList < QPropertyDefinition > ( ) ; private List < QNodeDefinition > childNodeDefinitions = new ArrayList < QNodeDefinition > ( ) ; private boolean isAbstract = false ; private boolean isQueryable = true ; private List < Name > supportedMixins = null ; public void setName ( Name name ) { this . name = name ; } public Name getName ( ) { return name ; } public void setSupertypes ( Name [ ] supertypes ) { this . supertypes . clear ( ) ; this . supertypes . addAll ( Arrays . asList ( supertypes ) ) ; } public Name [ ] getSuperTypes ( ) { if ( supertypes . size ( ) > 0 || isMixin ( ) || NameConstants . NT_BASE . equals ( getName ( ) ) ) { return supertypes . toArray ( new Name [ supertypes . size ( ) ] ) ; } else { return new Name [ ] { NameConstants . NT_BASE } ; } } public void setMixin ( boolean isMixin ) { this . isMixin = isMixin ; } public boolean isMixin ( ) { return isMixin ; } public void setSupportedMixinTypes ( Name [ ] names ) { if ( names == null ) { supportedMixins = null ; } else { supportedMixins = new ArrayList < Name > ( Arrays . asList ( names ) ) ; } } public Name [ ] getSupportedMixinTypes ( ) { if ( supportedMixins == null ) { return null ; } else { return supportedMixins . toArray ( new Name [ supportedMixins . size ( ) ] ) ; } } public void setOrderableChildNodes ( boolean isOrderable ) { this . isOrderable = isOrderable ; } public boolean hasOrderableChildNodes ( ) { return isOrderable ; } public void setPrimaryItemName ( Name primaryItemName ) { this . primaryItemName = primaryItemName ; } public Name getPrimaryItemName ( ) { return primaryItemName ; } public boolean isAbstract ( ) { return isAbstract ; } public void setAbstract ( boolean isAbstract ) { this . isAbstract = isAbstract ; } public boolean isQueryable ( ) { return isQueryable ; } public void setQueryable ( boolean queryable ) { isQueryable = queryable ; } public void setPropertyDefs ( QPropertyDefinition [ ] propDefs ) { propertyDefinitions . clear ( ) ; propertyDefinitions . addAll ( Arrays . asList ( propDefs ) ) ; } public QPropertyDefinition [ ] getPropertyDefs ( ) { return propertyDefinitions . toArray ( new QPropertyDefinition [ propertyDefinitions . size ( ) ] ) ; } public void setChildNodeDefs ( QNodeDefinition [ ] childDefs ) { childNodeDefinitions . clear ( ) ; childNodeDefinitions . addAll ( Arrays . asList ( childDefs ) ) ; } public QNodeDefinition [ ] getChildNodeDefs ( ) { return childNodeDefinitions . toArray ( new QNodeDefinition [ childNodeDefinitions . size ( ) ] ) ; } public QNodeTypeDefinition build ( ) throws IllegalStateException { return new QNodeTypeDefinitionImpl ( getName ( ) , getSuperTypes ( ) , getSupportedMixinTypes ( ) , isMixin ( ) , isAbstract ( ) , isQueryable ( ) , hasOrderableChildNodes ( ) , getPrimaryItemName ( ) , getPropertyDefs ( ) , getChildNodeDefs ( ) ) ; } }",Smelly
"public class VersionTest extends AbstractVersionManagementTest { private static Logger log = LoggerFactory . getLogger ( VersionTest . class ) ; private static String VERSION_STORAGE_PATH = ""/jcr:system/jcr:versionStorage"" ; protected boolean isExecutable ( ) { return EvaluationUtil . isExecutable ( ( SessionImpl ) superuser , acMgr ) ; } protected JackrabbitAccessControlList getPolicy ( AccessControlManager acMgr , String path , Principal princ ) throws RepositoryException , NotExecutableException { return EvaluationUtil . getPolicy ( acMgr , path , princ ) ; } protected Map < String , Value > getRestrictions ( Session s , String path ) throws RepositoryException , NotExecutableException { return EvaluationUtil . getRestrictions ( s , path ) ; } public void testReadVersionInfo ( ) throws RepositoryException , NotExecutableException { Node n = createVersionableNode ( testRootNode ) ; modifyPrivileges ( VERSION_STORAGE_PATH , Privilege . JCR_READ , false ) ; Node n2 = ( Node ) getTestSession ( ) . getItem ( n . getPath ( ) ) ; try { n2 . getVersionHistory ( ) ; fail ( ) ; } catch ( AccessDeniedException e ) { } catch ( ItemNotFoundException e ) { } try { n2 . getBaseVersion ( ) ; fail ( ) ; } catch ( AccessDeniedException e ) { } catch ( ItemNotFoundException e ) { } } public void testReadVersionInfo2 ( ) throws RepositoryException , NotExecutableException { Node n = createVersionableNode ( testRootNode ) ; modifyPrivileges ( VERSION_STORAGE_PATH , Privilege . JCR_READ , true ) ; Node n2 = ( Node ) getTestSession ( ) . getItem ( n . getPath ( ) ) ; n2 . getVersionHistory ( ) ; n2 . getBaseVersion ( ) ; } public void testReadVersionInfo3 ( ) throws RepositoryException , NotExecutableException { Node trn = getTestNode ( ) ; modifyPrivileges ( trn . getPath ( ) , PrivilegeRegistry . REP_WRITE , true ) ; modifyPrivileges ( trn . getPath ( ) , Privilege . JCR_NODE_TYPE_MANAGEMENT , true ) ; modifyPrivileges ( trn . getPath ( ) , Privilege . JCR_VERSION_MANAGEMENT , true ) ; modifyPrivileges ( VERSION_STORAGE_PATH , Privilege . JCR_READ , false ) ; Node n = createVersionableNode ( trn ) ; assertTrue ( n . isNodeType ( mixVersionable ) ) ; assertFalse ( n . isModified ( ) ) ; try { n . getVersionHistory ( ) ; n . getBaseVersion ( ) ; fail ( ""No READ permission in the version storage"" ) ; } catch ( AccessDeniedException e ) { log . debug ( e . getMessage ( ) ) ; } catch ( ItemNotFoundException e ) { log . debug ( e . getMessage ( ) ) ; } } }",No
"class TaskCallbackManager { private static final class TaskCallbacks { private final Queue < TaskCallbackImpl > callbacks = new PriorityQueue < > ( ) ; private final Object lock = new Object ( ) ; private long nextSeqNum = 0L ; List < TaskCallbackImpl > update ( TaskCallbackImpl cb ) { synchronized ( lock ) { callbacks . add ( cb ) ; List < TaskCallbackImpl > callbacksToUpdate = new ArrayList < > ( ) ; while ( ! callbacks . isEmpty ( ) && callbacks . peek ( ) . matchSeqNum ( nextSeqNum ) ) { ++ nextSeqNum ; TaskCallbackImpl callback = callbacks . poll ( ) ; callbacksToUpdate . add ( callback ) ; if ( callback . coordinator . commitRequest ( ) . isDefined ( ) ) { break ; } } return callbacksToUpdate ; } } } private long seqNum = 0L ; private final TaskCallbacks completedCallbacks = new TaskCallbacks ( ) ; private final ScheduledExecutorService timer ; private final TaskCallbackListener listener ; private final long timeout ; private final int maxConcurrency ; private final HighResolutionClock clock ; public TaskCallbackManager ( TaskCallbackListener listener , ScheduledExecutorService timer , long timeout , int maxConcurrency , HighResolutionClock clock ) { this . listener = listener ; this . timer = timer ; this . timeout = timeout ; this . maxConcurrency = maxConcurrency ; this . clock = clock ; } public TaskCallbackImpl createCallback ( TaskName taskName , IncomingMessageEnvelope envelope , ReadableCoordinator coordinator ) { final TaskCallbackImpl callback = new TaskCallbackImpl ( listener , taskName , envelope , coordinator , seqNum ++ , clock . nanoTime ( ) ) ; if ( timer != null ) { Runnable timerTask = new Runnable ( ) { @ Override public void run ( ) { ThreadUtil . logThreadDump ( ""Thread dump at task callback timeout"" ) ; String msg = ""Callback for task {} "" + callback . taskName + "" timed out after "" + timeout + "" ms."" ; callback . failure ( new SamzaException ( msg ) ) ; } } ; ScheduledFuture scheduledFuture = timer . schedule ( timerTask , timeout , TimeUnit . MILLISECONDS ) ; callback . setScheduledFuture ( scheduledFuture ) ; } return callback ; } public List < TaskCallbackImpl > updateCallback ( TaskCallbackImpl callback ) { if ( maxConcurrency > 1 ) { return completedCallbacks . update ( callback ) ; } else { return ImmutableList . of ( callback ) ; } } }",No
public class IngresSqlDialect extends SqlDialect { public static final SqlDialect DEFAULT = new IngresSqlDialect ( EMPTY_CONTEXT . withDatabaseProduct ( DatabaseProduct . INGRES ) ) ; public IngresSqlDialect ( Context context ) { super ( context ) ; } },No
"public class FieldNameBasedTupleToKafkaMapper < K , V > implements TupleToKafkaMapper < K , V > { public static final String BOLT_KEY = ""key"" ; public static final String BOLT_MESSAGE = ""message"" ; public String boltKeyField ; public String boltMessageField ; public FieldNameBasedTupleToKafkaMapper ( ) { this ( BOLT_KEY , BOLT_MESSAGE ) ; } public FieldNameBasedTupleToKafkaMapper ( String boltKeyField , String boltMessageField ) { this . boltKeyField = boltKeyField ; this . boltMessageField = boltMessageField ; } @ Override public K getKeyFromTuple ( Tuple tuple ) { return tuple . contains ( boltKeyField ) ? ( K ) tuple . getValueByField ( boltKeyField ) : null ; } @ Override public V getMessageFromTuple ( Tuple tuple ) { return ( V ) tuple . getValueByField ( boltMessageField ) ; } }",No
"@ XmlRootElement ( name = ""notification"" ) @ XmlType public class NotificationTO extends AbstractBaseBean implements EntityTO { private static final long serialVersionUID = - 6145117115632592612L ; private String key ; private final List < String > events = new ArrayList < > ( ) ; @ XmlJavaTypeAdapter ( XmlGenericMapAdapter . class ) @ JsonIgnore private final Map < String , String > abouts = new HashMap < > ( ) ; private String recipientsFIQL ; private final List < String > staticRecipients = new ArrayList < > ( ) ; private String recipientAttrName ; private boolean selfAsRecipient ; private String recipientsProviderClassName ; private String sender ; private String subject ; private String template ; private TraceLevel traceLevel ; private boolean active ; @ JsonProperty public Map < String , String > getAbouts ( ) { return abouts ; } @ XmlElementWrapper ( name = ""events"" ) @ XmlElement ( name = ""event"" ) @ JsonProperty ( ""events"" ) public List < String > getEvents ( ) { return events ; } @ XmlElementWrapper ( name = ""staticRecipients"" ) @ XmlElement ( name = ""staticRecipient"" ) @ JsonProperty ( ""staticRecipients"" ) public List < String > getStaticRecipients ( ) { return staticRecipients ; } @ Override public String getKey ( ) { return key ; } @ PathParam ( ""key"" ) @ Override public void setKey ( final String key ) { this . key = key ; } public String getRecipientsFIQL ( ) { return recipientsFIQL ; } public void setRecipientsFIQL ( final String recipientsFIQL ) { this . recipientsFIQL = recipientsFIQL ; } public String getRecipientAttrName ( ) { return recipientAttrName ; } public void setRecipientAttrName ( final String recipientAttrName ) { this . recipientAttrName = recipientAttrName ; } public boolean isSelfAsRecipient ( ) { return selfAsRecipient ; } public void setSelfAsRecipient ( final boolean selfAsRecipient ) { this . selfAsRecipient = selfAsRecipient ; } public String getRecipientsProviderClassName ( ) { return recipientsProviderClassName ; } public void setRecipientsProviderClassName ( final String recipientsProviderClassName ) { this . recipientsProviderClassName = recipientsProviderClassName ; } public String getSender ( ) { return sender ; } public void setSender ( final String sender ) { this . sender = sender ; } public String getSubject ( ) { return subject ; } public void setSubject ( final String subject ) { this . subject = subject ; } public String getTemplate ( ) { return template ; } public void setTemplate ( final String template ) { this . template = template ; } public TraceLevel getTraceLevel ( ) { return traceLevel ; } public void setTraceLevel ( final TraceLevel traceLevel ) { this . traceLevel = traceLevel ; } public boolean isActive ( ) { return active ; } public void setActive ( final boolean active ) { this . active = active ; } }",Smelly
"public class AbstractLogsViewBot { private SWTBotView view ; public AbstractLogsViewBot ( String title ) { view = new SWTWorkbenchBot ( ) . viewByTitle ( title ) ; } public String getLogsText ( ) { view . show ( ) ; SWTBotToolbarPushButton refreshButton = view . toolbarPushButton ( ""Refresh"" ) ; if ( refreshButton . isEnabled ( ) ) { refreshButton . click ( ) ; } return view . bot ( ) . styledText ( ) . getText ( ) ; } public void waitForText ( final String text ) { view . show ( ) ; view . bot ( ) . waitUntil ( new DefaultCondition ( ) { @ Override public boolean test ( ) throws Exception { SWTBotToolbarPushButton refreshButton = view . toolbarPushButton ( ""Refresh"" ) ; if ( refreshButton . isEnabled ( ) ) { refreshButton . click ( ) ; } return view . bot ( ) . styledText ( ) . getText ( ) . contains ( text ) ; } @ Override public String getFailureMessage ( ) { return ""Text '"" + text + ""' not found."" ; } } ) ; } }",No
"@ RunWith ( JUnit4 . class ) public class SideInputTranslationTest implements Serializable { private static final AtomicReference < Boolean > SIDE_INPUT_ACCESSED = new AtomicReference < > ( ) ; @ Test public void testMapAsEntrySetSideInput ( ) { SIDE_INPUT_ACCESSED . set ( false ) ; ApexPipelineOptions options = PipelineOptionsFactory . as ( ApexPipelineOptions . class ) ; options . setApplicationName ( ""SideInputTranslationTest"" ) ; options . setRunner ( TestApexRunner . class ) ; Pipeline pipeline = Pipeline . create ( options ) ; final PCollectionView < Map < String , Integer > > view = pipeline . apply ( ""CreateSideInput"" , Create . of ( KV . of ( ""a"" , 1 ) , KV . of ( ""b"" , 3 ) ) ) . apply ( View . asMap ( ) ) ; PCollection < KV < String , Integer > > output = pipeline . apply ( ""CreateMainInput"" , Create . of ( 2 ) ) . apply ( ""OutputSideInputs"" , ParDo . of ( new DoFn < Integer , KV < String , Integer > > ( ) { @ ProcessElement public void processElement ( ProcessContext c ) { assertEquals ( ( int ) c . element ( ) , c . sideInput ( view ) . size ( ) ) ; assertEquals ( ( int ) c . element ( ) , c . sideInput ( view ) . entrySet ( ) . size ( ) ) ; for ( Entry < String , Integer > entry : c . sideInput ( view ) . entrySet ( ) ) { c . output ( KV . of ( entry . getKey ( ) , entry . getValue ( ) ) ) ; } SIDE_INPUT_ACCESSED . set ( true ) ; } } ) . withSideInputs ( view ) ) ; PAssert . that ( output ) . containsInAnyOrder ( KV . of ( ""a"" , 1 ) , KV . of ( ""b"" , 3 ) ) ; pipeline . run ( ) ; assertTrue ( SIDE_INPUT_ACCESSED . get ( ) ) ; } @ Test public void testListSideInputTranslation ( ) throws Exception { assertEquals ( ListCoder . of ( KvCoder . of ( VoidCoder . of ( ) , VarIntCoder . of ( ) ) ) , getTranslatedSideInputCoder ( ImmutableList . of ( 11 , 13 , 17 , 23 ) , View . asList ( ) ) ) ; } @ Test public void testMapSideInputTranslation ( ) throws Exception { assertEquals ( ListCoder . of ( KvCoder . of ( VoidCoder . of ( ) , KvCoder . of ( StringUtf8Coder . of ( ) , VarIntCoder . of ( ) ) ) ) , getTranslatedSideInputCoder ( ImmutableList . of ( KV . of ( ""a"" , 1 ) , KV . of ( ""b"" , 3 ) ) , View . asMap ( ) ) ) ; } @ Test public void testMultimapSideInputTranslation ( ) throws Exception { assertEquals ( ListCoder . of ( KvCoder . of ( VoidCoder . of ( ) , KvCoder . of ( StringUtf8Coder . of ( ) , VarIntCoder . of ( ) ) ) ) , getTranslatedSideInputCoder ( ImmutableList . of ( KV . of ( ""a"" , 1 ) , KV . of ( ""a"" , 2 ) , KV . of ( ""b"" , 3 ) ) , View . asMultimap ( ) ) ) ; } private < T > Coder < ? > getTranslatedSideInputCoder ( List < T > items , PTransform < PCollection < T > , ? extends PCollectionView < ? > > viewTransform ) throws Exception { Pipeline p = Pipeline . create ( ) ; PCollectionView < ? > view = p . apply ( Create . of ( items ) ) . apply ( viewTransform ) ; p . apply ( Create . of ( 1 ) ) . apply ( ""ParDo"" , ParDo . of ( new DoFn < Integer , KV < String , Integer > > ( ) { @ ProcessElement public void processElement ( ProcessContext c ) { } } ) . withSideInputs ( view ) ) ; DAG dag = TestApexRunner . translate ( p , PipelineOptionsFactory . create ( ) . as ( ApexPipelineOptions . class ) ) ; OperatorMeta om = dag . getOperatorMeta ( ""ParDo/ParMultiDo(Anonymous)"" ) ; assertNotNull ( om ) ; assertEquals ( 2 , om . getInputStreams ( ) . size ( ) ) ; DAG . InputPortMeta sideInput = null ; for ( DAG . InputPortMeta input : om . getInputStreams ( ) . keySet ( ) ) { if ( ""sideInput1"" . equals ( ( ( LogicalPlan . InputPortMeta ) input ) . getPortName ( ) ) ) { sideInput = input ; } } assertNotNull ( ""could not find stream for: sideInput1"" , sideInput ) ; CoderAdapterStreamCodec sc = ( CoderAdapterStreamCodec ) sideInput . getAttributes ( ) . get ( PortContext . STREAM_CODEC ) ; @ SuppressWarnings ( ""rawtypes"" ) ApexStreamTupleCoder < ? > coder = ( ApexStreamTupleCoder < ? > ) sc . getCoder ( ) ; @ SuppressWarnings ( ""rawtypes"" ) FullWindowedValueCoder < ? > fwvc = ( FullWindowedValueCoder ) coder . getValueCoder ( ) ; return fwvc . getValueCoder ( ) ; } }",No
"@ Path ( ""/site-to-site"" ) @ Api ( value = ""/site-to-site"" , description = ""Provide access to site to site with this NiFi"" ) public class SiteToSiteResource extends ApplicationResource { private static final Logger logger = LoggerFactory . getLogger ( SiteToSiteResource . class ) ; private NiFiServiceFacade serviceFacade ; private ClusterCoordinator clusterCoordinator ; private Authorizer authorizer ; private final ResponseCreator responseCreator = new ResponseCreator ( ) ; private final VersionNegotiator transportProtocolVersionNegotiator = new TransportProtocolVersionNegotiator ( 1 ) ; private final HttpRemoteSiteListener transactionManager ; private final PeerDescriptionModifier peerDescriptionModifier ; public SiteToSiteResource ( final NiFiProperties nifiProperties ) { transactionManager = HttpRemoteSiteListener . getInstance ( nifiProperties ) ; peerDescriptionModifier = new PeerDescriptionModifier ( nifiProperties ) ; } protected void authorizeSiteToSite ( ) { serviceFacade . authorizeAccess ( lookup -> { final Authorizable siteToSite = lookup . getSiteToSite ( ) ; siteToSite . authorize ( authorizer , RequestAction . READ , NiFiUserUtils . getNiFiUser ( ) ) ; } ) ; } @ GET @ Consumes ( MediaType . WILDCARD ) @ Produces ( MediaType . APPLICATION_JSON ) @ ApiOperation ( value = ""Returns the details about this NiFi necessary to communicate via site to site"" , response = ControllerEntity . class , authorizations = { @ Authorization ( value = ""Read - /site-to-site"" ) } ) @ ApiResponses ( value = { @ ApiResponse ( code = 400 , message = ""NiFi was unable to complete the request because it was invalid. The request should not be retried without modification."" ) , @ ApiResponse ( code = 401 , message = ""Client could not be authenticated."" ) , @ ApiResponse ( code = 403 , message = ""Client is not authorized to make this request."" ) , @ ApiResponse ( code = 409 , message = ""The request was valid but NiFi was not in the appropriate state to process it. Retrying the same request later may be successful."" ) } ) public Response getSiteToSiteDetails ( @ Context HttpServletRequest req ) { authorizeSiteToSite ( ) ; if ( isReplicateRequest ( ) ) { return replicate ( HttpMethod . GET ) ; } final ControllerDTO controller = serviceFacade . getSiteToSiteDetails ( ) ; final boolean modificationNeededRaw = peerDescriptionModifier . isModificationNeeded ( SiteToSiteTransportProtocol . RAW ) ; final boolean modificationNeededHttp = peerDescriptionModifier . isModificationNeeded ( SiteToSiteTransportProtocol . HTTP ) ; if ( modificationNeededRaw || modificationNeededHttp ) { final PeerDescription source = getSourcePeerDescription ( req ) ; final Boolean isSiteToSiteSecure = controller . isSiteToSiteSecure ( ) ; final String siteToSiteHostname = getSiteToSiteHostname ( req ) ; final Map < String , String > httpHeaders = getHttpHeaders ( req ) ; if ( modificationNeededRaw ) { final PeerDescription rawTarget = new PeerDescription ( siteToSiteHostname , controller . getRemoteSiteListeningPort ( ) , isSiteToSiteSecure ) ; final PeerDescription modifiedRawTarget = peerDescriptionModifier . modify ( source , rawTarget , SiteToSiteTransportProtocol . RAW , PeerDescriptionModifier . RequestType . SiteToSiteDetail , new HashMap < > ( httpHeaders ) ) ; controller . setRemoteSiteListeningPort ( modifiedRawTarget . getPort ( ) ) ; } if ( modificationNeededHttp ) { final PeerDescription httpTarget = new PeerDescription ( siteToSiteHostname , controller . getRemoteSiteHttpListeningPort ( ) , isSiteToSiteSecure ) ; final PeerDescription modifiedHttpTarget = peerDescriptionModifier . modify ( source , httpTarget , SiteToSiteTransportProtocol . HTTP , PeerDescriptionModifier . RequestType . SiteToSiteDetail , new HashMap < > ( httpHeaders ) ) ; controller . setRemoteSiteHttpListeningPort ( modifiedHttpTarget . getPort ( ) ) ; if ( ! controller . isSiteToSiteSecure ( ) && modifiedHttpTarget . isSecure ( ) ) { controller . setSiteToSiteSecure ( true ) ; } } } final ControllerEntity entity = new ControllerEntity ( ) ; entity . setController ( controller ) ; if ( isEmpty ( req . getHeader ( HttpHeaders . PROTOCOL_VERSION ) ) ) { logger . debug ( ""Converting result to provide backward compatibility..."" ) ; controller . setRemoteSiteHttpListeningPort ( null ) ; } return noCache ( Response . ok ( entity ) ) . build ( ) ; } private PeerDescription getSourcePeerDescription ( @ Context HttpServletRequest req ) { return new PeerDescription ( req . getRemoteHost ( ) , req . getRemotePort ( ) , req . isSecure ( ) ) ; } private Map < String , String > getHttpHeaders ( @ Context HttpServletRequest req ) { final Map < String , String > headers = new HashMap < > ( ) ; final Enumeration < String > headerNames = req . getHeaderNames ( ) ; while ( headerNames . hasMoreElements ( ) ) { final String name = headerNames . nextElement ( ) ; headers . put ( name , req . getHeader ( name ) ) ; } return headers ; } @ GET @ Path ( ""/peers"" ) @ Consumes ( MediaType . WILDCARD ) @ Produces ( { MediaType . APPLICATION_JSON , MediaType . APPLICATION_XML } ) @ ApiOperation ( value = ""Returns the available Peers and its status of this NiFi"" , response = PeersEntity . class , authorizations = { @ Authorization ( value = ""Read - /site-to-site"" ) } ) @ ApiResponses ( value = { @ ApiResponse ( code = 400 , message = ""NiFi was unable to complete the request because it was invalid. The request should not be retried without modification."" ) , @ ApiResponse ( code = 401 , message = ""Client could not be authenticated."" ) , @ ApiResponse ( code = 403 , message = ""Client is not authorized to make this request."" ) , @ ApiResponse ( code = 409 , message = ""The request was valid but NiFi was not in the appropriate state to process it. Retrying the same request later may be successful."" ) } ) public Response getPeers ( @ Context HttpServletRequest req ) { authorizeSiteToSite ( ) ; if ( ! properties . isSiteToSiteHttpEnabled ( ) ) { return responseCreator . httpSiteToSiteIsNotEnabledResponse ( ) ; } final Integer transportProtocolVersion ; try { transportProtocolVersion = negotiateTransportProtocolVersion ( req , transportProtocolVersionNegotiator ) ; } catch ( BadRequestException e ) { return responseCreator . badRequestResponse ( e ) ; } final List < PeerDTO > peers = new ArrayList < > ( ) ; final PeerDescription source = getSourcePeerDescription ( req ) ; final boolean modificationNeeded = peerDescriptionModifier . isModificationNeeded ( SiteToSiteTransportProtocol . HTTP ) ; final Map < String , String > headers = modificationNeeded ? getHttpHeaders ( req ) : null ; if ( properties . isNode ( ) ) { try { final Map < NodeIdentifier , NodeWorkload > clusterWorkload = clusterCoordinator . getClusterWorkload ( ) ; clusterWorkload . forEach ( ( nodeId , workload ) -> { final String siteToSiteHostname = nodeId . getSiteToSiteAddress ( ) == null ? nodeId . getApiAddress ( ) : nodeId . getSiteToSiteAddress ( ) ; final int siteToSitePort = nodeId . getSiteToSiteHttpApiPort ( ) == null ? nodeId . getApiPort ( ) : nodeId . getSiteToSiteHttpApiPort ( ) ; PeerDescription target = new PeerDescription ( siteToSiteHostname , siteToSitePort , nodeId . isSiteToSiteSecure ( ) ) ; if ( modificationNeeded ) { target = peerDescriptionModifier . modify ( source , target , SiteToSiteTransportProtocol . HTTP , PeerDescriptionModifier . RequestType . Peers , new HashMap < > ( headers ) ) ; } final PeerDTO peer = new PeerDTO ( ) ; peer . setHostname ( target . getHostname ( ) ) ; peer . setPort ( target . getPort ( ) ) ; peer . setSecure ( target . isSecure ( ) ) ; peer . setFlowFileCount ( workload . getFlowFileCount ( ) ) ; peers . add ( peer ) ; } ) ; } catch ( IOException e ) { throw new RuntimeException ( ""Failed to retrieve cluster workload due to "" + e , e ) ; } } else { final PeerDTO peer = new PeerDTO ( ) ; final String siteToSiteHostname = getSiteToSiteHostname ( req ) ; PeerDescription target = new PeerDescription ( siteToSiteHostname , properties . getRemoteInputHttpPort ( ) , properties . isSiteToSiteSecure ( ) ) ; if ( modificationNeeded ) { target = peerDescriptionModifier . modify ( source , target , SiteToSiteTransportProtocol . HTTP , PeerDescriptionModifier . RequestType . Peers , new HashMap < > ( headers ) ) ; } peer . setHostname ( target . getHostname ( ) ) ; peer . setPort ( target . getPort ( ) ) ; peer . setSecure ( target . isSecure ( ) ) ; peer . setFlowFileCount ( 0 ) ; peers . add ( peer ) ; } final PeersEntity entity = new PeersEntity ( ) ; entity . setPeers ( peers ) ; return noCache ( setCommonHeaders ( Response . ok ( entity ) , transportProtocolVersion , transactionManager ) ) . build ( ) ; } private String getSiteToSiteHostname ( final HttpServletRequest req ) { final String remoteInputHost = properties . getRemoteInputHost ( ) ; String localName ; try { localName = InetAddress . getLocalHost ( ) . getHostName ( ) ; } catch ( UnknownHostException e ) { if ( logger . isDebugEnabled ( ) ) { logger . debug ( ""Failed to get local host name using InetAddress."" , e ) ; } localName = req . getLocalName ( ) ; } return isEmpty ( remoteInputHost ) ? localName : remoteInputHost ; } public void setServiceFacade ( final NiFiServiceFacade serviceFacade ) { this . serviceFacade = serviceFacade ; } public void setAuthorizer ( Authorizer authorizer ) { this . authorizer = authorizer ; } @ Override public void setClusterCoordinator ( final ClusterCoordinator clusterCoordinator ) { super . setClusterCoordinator ( clusterCoordinator ) ; this . clusterCoordinator = clusterCoordinator ; } }",Smelly
"@ Entity @ FetchGroups ( { @ FetchGroup ( name = ""all"" , attributes = { @ FetchAttribute ( name = ""bs"" , recursionDepth = 0 ) , @ FetchAttribute ( name = ""pcStringMap"" ) , @ FetchAttribute ( name = ""bigIntegerPCMap"" , recursionDepth = 0 ) , @ FetchAttribute ( name = ""embeddedE"" , recursionDepth = 0 ) , @ FetchAttribute ( name = ""embeddedA"" , recursionDepth = 0 ) } ) } ) @ Table ( name = ""K_ATTACHD"" ) public class AttachD implements Serializable { @ Id @ GeneratedValue ( strategy = GenerationType . AUTO ) @ Column ( name = ""D_ID"" ) private int id ; private Object version ; @ Basic private String dstr ; @ Basic private int dint ; @ Basic private double ddbl ; @ ManyToOne ( cascade = { CascadeType . PERSIST , CascadeType . MERGE } ) private AttachA a ; @ ManyToMany ( mappedBy = ""ds"" , cascade = { CascadeType . PERSIST , CascadeType . MERGE } ) private Set < AttachB > bs = new HashSet ( ) ; @ PersistentMap ( keyCascade = { CascadeType . PERSIST , CascadeType . MERGE } ) @ KeyColumn ( name = ""strngmap"" ) private Map < AttachA , String > pcStringMap = new HashMap ( ) ; @ PersistentMap ( elementCascade = { CascadeType . PERSIST , CascadeType . MERGE } ) @ KeyColumn ( name = ""intmap"" ) private TreeMap < BigInteger , AttachF > bigIntegerPCMap = new TreeMap < BigInteger , AttachF > ( ) ; @ Embedded private AttachE embeddedE ; @ Embedded private AttachA embeddedA ; public int getId ( ) { return id ; } public void setDstr ( String dstr ) { this . dstr = dstr ; } public String getDstr ( ) { return this . dstr ; } public void setDint ( int dint ) { this . dint = dint ; } public int getDint ( ) { return this . dint ; } public void setDdbl ( double ddbl ) { this . ddbl = ddbl ; } public double getDdbl ( ) { return this . ddbl ; } public AttachA getA ( ) { return a ; } public void setA ( AttachA a ) { this . a = a ; } public void setBs ( Set bs ) { this . bs = bs ; } public Set getBs ( ) { return this . bs ; } public void setPcStringMap ( Map pcStringMap ) { this . pcStringMap = pcStringMap ; } public Map getPcStringMap ( ) { return this . pcStringMap ; } public void setBigIntegerPCMap ( TreeMap bigIntegerPCMap ) { this . bigIntegerPCMap = bigIntegerPCMap ; } public TreeMap getBigIntegerPCMap ( ) { return this . bigIntegerPCMap ; } public void setEmbeddedE ( AttachE embeddedE ) { this . embeddedE = embeddedE ; } public AttachE getEmbeddedE ( ) { return this . embeddedE ; } public void setEmbeddedA ( AttachA embeddedA ) { this . embeddedA = embeddedA ; } public AttachA getEmbeddedA ( ) { return this . embeddedA ; } public Object getVersion ( ) { return this . version ; } }",Smelly
"@ InterfaceAudience . Private public class MetricsBalancerSourceImpl extends BaseSourceImpl implements MetricsBalancerSource { private MetricHistogram blanceClusterHisto ; private MutableFastCounter miscCount ; public MetricsBalancerSourceImpl ( ) { this ( METRICS_NAME , METRICS_DESCRIPTION , METRICS_CONTEXT , METRICS_JMX_CONTEXT ) ; } public MetricsBalancerSourceImpl ( String metricsName , String metricsDescription , String metricsContext , String metricsJmxContext ) { super ( metricsName , metricsDescription , metricsContext , metricsJmxContext ) ; updateBalancerStatus ( true ) ; } @ Override public void init ( ) { blanceClusterHisto = metricsRegistry . newTimeHistogram ( BALANCE_CLUSTER ) ; miscCount = metricsRegistry . newCounter ( MISC_INVOATION_COUNT , """" , 0L ) ; } @ Override public void updateBalanceCluster ( long time ) { blanceClusterHisto . add ( time ) ; } @ Override public void incrMiscInvocations ( ) { miscCount . incr ( ) ; } @ Override public void updateBalancerStatus ( boolean status ) { metricsRegistry . tag ( BALANCER_STATUS , """" , String . valueOf ( status ) , true ) ; } }",No
"@ XmlAccessorType ( XmlAccessType . FIELD ) @ XmlType ( name = ""service-ref_handlerType"" , propOrder = { ""description"" , ""displayName"" , ""icon"" , ""handlerName"" , ""handlerClass"" , ""initParam"" , ""soapHeader"" , ""soapRole"" , ""portName"" } ) public class ServiceRefHandlerType { protected List < DescriptionType > description ; @ XmlElement ( name = ""display-name"" ) protected List < DisplayNameType > displayName ; protected List < IconType > icon ; @ XmlElement ( name = ""handler-name"" , required = true ) protected org . apache . cxf . jaxws . javaee . CString handlerName ; @ XmlElement ( name = ""handler-class"" , required = true ) protected FullyQualifiedClassType handlerClass ; @ XmlElement ( name = ""init-param"" ) protected List < ParamValueType > initParam ; @ XmlElement ( name = ""soap-header"" ) protected List < XsdQNameType > soapHeader ; @ XmlElement ( name = ""soap-role"" ) protected List < org . apache . cxf . jaxws . javaee . CString > soapRole ; @ XmlElement ( name = ""port-name"" ) protected List < org . apache . cxf . jaxws . javaee . CString > portName ; @ XmlAttribute @ XmlJavaTypeAdapter ( CollapsedStringAdapter . class ) @ XmlID protected java . lang . String id ; public List < DescriptionType > getDescription ( ) { if ( description == null ) { description = new ArrayList < DescriptionType > ( ) ; } return this . description ; } public List < DisplayNameType > getDisplayName ( ) { if ( displayName == null ) { displayName = new ArrayList < DisplayNameType > ( ) ; } return this . displayName ; } public List < IconType > getIcon ( ) { if ( icon == null ) { icon = new ArrayList < IconType > ( ) ; } return this . icon ; } public org . apache . cxf . jaxws . javaee . CString getHandlerName ( ) { return handlerName ; } public void setHandlerName ( org . apache . cxf . jaxws . javaee . CString value ) { this . handlerName = value ; } public FullyQualifiedClassType getHandlerClass ( ) { return handlerClass ; } public void setHandlerClass ( FullyQualifiedClassType value ) { this . handlerClass = value ; } public List < ParamValueType > getInitParam ( ) { if ( initParam == null ) { initParam = new ArrayList < ParamValueType > ( ) ; } return this . initParam ; } public List < XsdQNameType > getSoapHeader ( ) { if ( soapHeader == null ) { soapHeader = new ArrayList < XsdQNameType > ( ) ; } return this . soapHeader ; } public List < org . apache . cxf . jaxws . javaee . CString > getSoapRole ( ) { if ( soapRole == null ) { soapRole = new ArrayList < org . apache . cxf . jaxws . javaee . CString > ( ) ; } return this . soapRole ; } public List < org . apache . cxf . jaxws . javaee . CString > getPortName ( ) { if ( portName == null ) { portName = new ArrayList < org . apache . cxf . jaxws . javaee . CString > ( ) ; } return this . portName ; } public java . lang . String getId ( ) { return id ; } public void setId ( java . lang . String value ) { this . id = value ; } }",Smelly
"public class InterpreterSetting { private static final Logger logger = LoggerFactory . getLogger ( InterpreterSetting . class ) ; private static final String SHARED_PROCESS = ""shared_process"" ; private String id ; private String name ; private String group ; private transient Map < String , String > infos ; private Object properties ; private Status status ; private String errorReason ; @ SerializedName ( ""interpreterGroup"" ) private List < InterpreterInfo > interpreterInfos ; private final transient Map < String , InterpreterGroup > interpreterGroupRef = new HashMap < > ( ) ; private List < Dependency > dependencies = new LinkedList < > ( ) ; private InterpreterOption option ; private transient String path ; @ SerializedName ( ""runner"" ) private InterpreterRunner interpreterRunner ; @ Deprecated private transient InterpreterGroupFactory interpreterGroupFactory ; private final transient ReentrantReadWriteLock . ReadLock interpreterGroupReadLock ; private final transient ReentrantReadWriteLock . WriteLock interpreterGroupWriteLock ; public InterpreterSetting ( ) { ReentrantReadWriteLock lock = new ReentrantReadWriteLock ( ) ; interpreterGroupReadLock = lock . readLock ( ) ; interpreterGroupWriteLock = lock . writeLock ( ) ; } public InterpreterSetting ( String id , String name , String group , List < InterpreterInfo > interpreterInfos , Object properties , List < Dependency > dependencies , InterpreterOption option , String path , InterpreterRunner runner ) { this ( ) ; this . id = id ; this . name = name ; this . group = group ; this . interpreterInfos = interpreterInfos ; this . properties = properties ; this . dependencies = dependencies ; this . option = option ; this . path = path ; this . status = Status . READY ; this . interpreterRunner = runner ; } public InterpreterSetting ( String name , String group , List < InterpreterInfo > interpreterInfos , Object properties , List < Dependency > dependencies , InterpreterOption option , String path , InterpreterRunner runner ) { this ( generateId ( ) , name , group , interpreterInfos , properties , dependencies , option , path , runner ) ; } public InterpreterSetting ( InterpreterSetting o ) { this ( generateId ( ) , o . getName ( ) , o . getGroup ( ) , o . getInterpreterInfos ( ) , o . getProperties ( ) , o . getDependencies ( ) , o . getOption ( ) , o . getPath ( ) , o . getInterpreterRunner ( ) ) ; } public String getId ( ) { return id ; } public String getName ( ) { return name ; } String getGroup ( ) { return group ; } private String getInterpreterProcessKey ( String user , String noteId ) { InterpreterOption option = getOption ( ) ; String key ; if ( getOption ( ) . isExistingProcess ) { key = Constants . EXISTING_PROCESS ; } else if ( getOption ( ) . isProcess ( ) ) { key = ( option . perUserIsolated ( ) ? user : """" ) + "":"" + ( option . perNoteIsolated ( ) ? noteId : """" ) ; } else { key = SHARED_PROCESS ; } return key ; } private boolean isEqualInterpreterKeyProcessKey ( String refKey , String processKey ) { InterpreterOption option = getOption ( ) ; int validCount = 0 ; if ( getOption ( ) . isProcess ( ) && ! ( option . perUserIsolated ( ) == true && option . perNoteIsolated ( ) == true ) ) { List < String > processList = Arrays . asList ( processKey . split ( "":"" ) ) ; List < String > refList = Arrays . asList ( refKey . split ( "":"" ) ) ; if ( refList . size ( ) <= 1 || processList . size ( ) <= 1 ) { return refKey . equals ( processKey ) ; } if ( processList . get ( 0 ) . equals ( """" ) || processList . get ( 0 ) . equals ( refList . get ( 0 ) ) ) { validCount = validCount + 1 ; } if ( processList . get ( 1 ) . equals ( """" ) || processList . get ( 1 ) . equals ( refList . get ( 1 ) ) ) { validCount = validCount + 1 ; } return ( validCount >= 2 ) ; } else { return refKey . equals ( processKey ) ; } } String getInterpreterSessionKey ( String user , String noteId ) { InterpreterOption option = getOption ( ) ; String key ; if ( option . isExistingProcess ( ) ) { key = Constants . EXISTING_PROCESS ; } else if ( option . perNoteScoped ( ) && option . perUserScoped ( ) ) { key = user + "":"" + noteId ; } else if ( option . perUserScoped ( ) ) { key = user ; } else if ( option . perNoteScoped ( ) ) { key = noteId ; } else { key = ""shared_session"" ; } logger . debug ( ""Interpreter session key: {}, for note: {}, user: {}, InterpreterSetting Name: "" + ""{}"" , key , noteId , user , getName ( ) ) ; return key ; } public InterpreterGroup getInterpreterGroup ( String user , String noteId ) { String key = getInterpreterProcessKey ( user , noteId ) ; if ( ! interpreterGroupRef . containsKey ( key ) ) { String interpreterGroupId = getId ( ) + "":"" + key ; InterpreterGroup intpGroup = interpreterGroupFactory . createInterpreterGroup ( interpreterGroupId , getOption ( ) ) ; interpreterGroupWriteLock . lock ( ) ; logger . debug ( ""create interpreter group with groupId:"" + interpreterGroupId ) ; interpreterGroupRef . put ( key , intpGroup ) ; interpreterGroupWriteLock . unlock ( ) ; } try { interpreterGroupReadLock . lock ( ) ; return interpreterGroupRef . get ( key ) ; } finally { interpreterGroupReadLock . unlock ( ) ; } } public Collection < InterpreterGroup > getAllInterpreterGroups ( ) { try { interpreterGroupReadLock . lock ( ) ; return new LinkedList < > ( interpreterGroupRef . values ( ) ) ; } finally { interpreterGroupReadLock . unlock ( ) ; } } void closeAndRemoveInterpreterGroup ( String noteId , String user ) { if ( user . equals ( ""anonymous"" ) ) { user = """" ; } String processKey = getInterpreterProcessKey ( user , noteId ) ; String sessionKey = getInterpreterSessionKey ( user , noteId ) ; List < InterpreterGroup > groupToRemove = new LinkedList < > ( ) ; InterpreterGroup groupItem ; for ( String intpKey : new HashSet < > ( interpreterGroupRef . keySet ( ) ) ) { if ( isEqualInterpreterKeyProcessKey ( intpKey , processKey ) ) { interpreterGroupWriteLock . lock ( ) ; groupItem = interpreterGroupRef . get ( intpKey ) ; interpreterGroupWriteLock . unlock ( ) ; groupToRemove . add ( groupItem ) ; } for ( InterpreterGroup groupToClose : groupToRemove ) { groupToClose . close ( interpreterGroupRef , intpKey , sessionKey ) ; } groupToRemove . clear ( ) ; } } void closeAndRemoveAllInterpreterGroups ( ) { for ( String processKey : new HashSet < > ( interpreterGroupRef . keySet ( ) ) ) { InterpreterGroup interpreterGroup = interpreterGroupRef . get ( processKey ) ; for ( String sessionKey : new HashSet < > ( interpreterGroup . keySet ( ) ) ) { interpreterGroup . close ( interpreterGroupRef , processKey , sessionKey ) ; } } } void shutdownAndRemoveAllInterpreterGroups ( ) { for ( InterpreterGroup interpreterGroup : interpreterGroupRef . values ( ) ) { interpreterGroup . shutdown ( ) ; } } public Object getProperties ( ) { return properties ; } public List < Dependency > getDependencies ( ) { if ( dependencies == null ) { return new LinkedList < > ( ) ; } return dependencies ; } public void setDependencies ( List < Dependency > dependencies ) { this . dependencies = dependencies ; } public InterpreterOption getOption ( ) { if ( option == null ) { option = new InterpreterOption ( ) ; } return option ; } public void setOption ( InterpreterOption option ) { this . option = option ; } public String getPath ( ) { return path ; } public void setPath ( String path ) { this . path = path ; } public List < InterpreterInfo > getInterpreterInfos ( ) { return interpreterInfos ; } void setInterpreterGroupFactory ( InterpreterGroupFactory interpreterGroupFactory ) { this . interpreterGroupFactory = interpreterGroupFactory ; } void appendDependencies ( List < Dependency > dependencies ) { for ( Dependency dependency : dependencies ) { if ( ! this . dependencies . contains ( dependency ) ) { this . dependencies . add ( dependency ) ; } } } void setInterpreterOption ( InterpreterOption interpreterOption ) { this . option = interpreterOption ; } public void setProperties ( Properties p ) { this . properties = p ; } void setGroup ( String group ) { this . group = group ; } void setName ( String name ) { this . name = name ; } public enum Status { DOWNLOADING_DEPENDENCIES , ERROR , READY } public Status getStatus ( ) { return status ; } public void setStatus ( Status status ) { this . status = status ; } public String getErrorReason ( ) { return errorReason ; } public void setErrorReason ( String errorReason ) { this . errorReason = errorReason ; } public void setInfos ( Map < String , String > infos ) { this . infos = infos ; } public Map < String , String > getInfos ( ) { return infos ; } public InterpreterRunner getInterpreterRunner ( ) { return interpreterRunner ; } public void setInterpreterRunner ( InterpreterRunner interpreterRunner ) { this . interpreterRunner = interpreterRunner ; } }",Smelly
"public class RevocationInfoChoice extends Asn1Choice { protected enum RevocationInfoChoiceField implements EnumType { CRL , OTHER ; @ Override public int getValue ( ) { return ordinal ( ) ; } @ Override public String getName ( ) { return name ( ) ; } } static Asn1FieldInfo [ ] fieldInfos = new Asn1FieldInfo [ ] { new Asn1FieldInfo ( RevocationInfoChoiceField . CRL , CertificateList . class ) , new ImplicitField ( RevocationInfoChoiceField . OTHER , OtherRevocationInfoFormat . class ) } ; public RevocationInfoChoice ( ) { super ( fieldInfos ) ; } public CertificateList getCRL ( ) { return getChoiceValueAs ( RevocationInfoChoiceField . CRL , CertificateList . class ) ; } public void setCRL ( CertificateList crl ) { setChoiceValue ( RevocationInfoChoiceField . CRL , crl ) ; } public OtherRevocationInfoFormat getOther ( ) { return getChoiceValueAs ( RevocationInfoChoiceField . OTHER , OtherRevocationInfoFormat . class ) ; } public void setOther ( OtherRevocationInfoFormat other ) { setChoiceValue ( RevocationInfoChoiceField . OTHER , other ) ; } }",Smelly
 public static class ColumnMetaStub { private String TABLE_CAT ; private String TABLE_SCHEM ; private String TABLE_NAME ; private String COLUMN_NAME ; private int DATA_TYPE ; private String TYPE_NAME ; private int COLUMN_SIZE ; private int BUFFER_LENGTH ; private int DECIMAL_DIGITS ; private int NUM_PREC_RADIX ; private int NULLABLE ; private String REMARKS ; private String COLUMN_DEF ; private int SQL_DATA_TYPE ; private int SQL_DATETIME_SUB ; private int CHAR_OCTET_LENGTH ; private int ORDINAL_POSITION ; private String IS_NULLABLE ; private String SCOPE_CATLOG ; private String SCOPE_SCHEMA ; private String SCOPE_TABLE ; private short SOURCE_DATA_TYPE ; private String IS_AUTOINCREMENT ; public String getTABLE_CAT ( ) { return TABLE_CAT ; } public void setTABLE_CAT ( String tABLE_CAT ) { TABLE_CAT = tABLE_CAT ; } public String getTABLE_SCHEM ( ) { return TABLE_SCHEM ; } public void setTABLE_SCHEM ( String tABLE_SCHEM ) { TABLE_SCHEM = tABLE_SCHEM ; } public String getTABLE_NAME ( ) { return TABLE_NAME ; } public void setTABLE_NAME ( String tABLE_NAME ) { TABLE_NAME = tABLE_NAME ; } public String getCOLUMN_NAME ( ) { return COLUMN_NAME ; } public void setCOLUMN_NAME ( String cOLUMN_NAME ) { COLUMN_NAME = cOLUMN_NAME ; } public int getDATA_TYPE ( ) { return DATA_TYPE ; } public void setDATA_TYPE ( int dATA_TYPE ) { DATA_TYPE = dATA_TYPE ; } public String getTYPE_NAME ( ) { return TYPE_NAME ; } public void setTYPE_NAME ( String tYPE_NAME ) { TYPE_NAME = tYPE_NAME ; } public int getCOLUMN_SIZE ( ) { return COLUMN_SIZE ; } public void setCOLUMN_SIZE ( int cOLUMN_SIZE ) { COLUMN_SIZE = cOLUMN_SIZE ; } public int getBUFFER_LENGTH ( ) { return BUFFER_LENGTH ; } public void setBUFFER_LENGTH ( int bUFFER_LENGTH ) { BUFFER_LENGTH = bUFFER_LENGTH ; } public int getDECIMAL_DIGITS ( ) { return DECIMAL_DIGITS ; } public void setDECIMAL_DIGITS ( int dECIMAL_DIGITS ) { DECIMAL_DIGITS = dECIMAL_DIGITS ; } public int getNUM_PREC_RADIX ( ) { return NUM_PREC_RADIX ; } public void setNUM_PREC_RADIX ( int nUM_PREC_RADIX ) { NUM_PREC_RADIX = nUM_PREC_RADIX ; } public int getNULLABLE ( ) { return NULLABLE ; } public void setNULLABLE ( int nULLABLE ) { NULLABLE = nULLABLE ; } public String getREMARKS ( ) { return REMARKS ; } public void setREMARKS ( String rEMARKS ) { REMARKS = rEMARKS ; } public String getCOLUMN_DEF ( ) { return COLUMN_DEF ; } public void setCOLUMN_DEF ( String cOLUMN_DEF ) { COLUMN_DEF = cOLUMN_DEF ; } public int getSQL_DATA_TYPE ( ) { return SQL_DATA_TYPE ; } public void setSQL_DATA_TYPE ( int sQL_DATA_TYPE ) { SQL_DATA_TYPE = sQL_DATA_TYPE ; } public int getSQL_DATETIME_SUB ( ) { return SQL_DATETIME_SUB ; } public void setSQL_DATETIME_SUB ( int sQL_DATETIME_SUB ) { SQL_DATETIME_SUB = sQL_DATETIME_SUB ; } public int getCHAR_OCTET_LENGTH ( ) { return CHAR_OCTET_LENGTH ; } public void setCHAR_OCTET_LENGTH ( int cHAR_OCTET_LENGTH ) { CHAR_OCTET_LENGTH = cHAR_OCTET_LENGTH ; } public int getORDINAL_POSITION ( ) { return ORDINAL_POSITION ; } public void setORDINAL_POSITION ( int oRDINAL_POSITION ) { ORDINAL_POSITION = oRDINAL_POSITION ; } public String getIS_NULLABLE ( ) { return IS_NULLABLE ; } public void setIS_NULLABLE ( String iS_NULLABLE ) { IS_NULLABLE = iS_NULLABLE ; } public String getSCOPE_CATLOG ( ) { return SCOPE_CATLOG ; } public void setSCOPE_CATLOG ( String sCOPE_CATLOG ) { SCOPE_CATLOG = sCOPE_CATLOG ; } public String getSCOPE_SCHEMA ( ) { return SCOPE_SCHEMA ; } public void setSCOPE_SCHEMA ( String sCOPE_SCHEMA ) { SCOPE_SCHEMA = sCOPE_SCHEMA ; } public String getSCOPE_TABLE ( ) { return SCOPE_TABLE ; } public void setSCOPE_TABLE ( String sCOPE_TABLE ) { SCOPE_TABLE = sCOPE_TABLE ; } public short getSOURCE_DATA_TYPE ( ) { return SOURCE_DATA_TYPE ; } public void setSOURCE_DATA_TYPE ( short sOURCE_DATA_TYPE ) { SOURCE_DATA_TYPE = sOURCE_DATA_TYPE ; } public String getIS_AUTOINCREMENT ( ) { return IS_AUTOINCREMENT ; } public void setIS_AUTOINCREMENT ( String iS_AUTOINCREMENT ) { this . IS_AUTOINCREMENT = iS_AUTOINCREMENT ; } } ,Smelly
 private static class addLocalSubmissionDetails_argsTupleSchemeFactory implements SchemeFactory { public addLocalSubmissionDetails_argsTupleScheme getScheme ( ) { return new addLocalSubmissionDetails_argsTupleScheme ( ) ; } ,No
"public class FinAccountHelper { public static final String module = FinAccountHelper . class . getName ( ) ; public static int decimals = UtilNumber . getBigDecimalScale ( ""finaccount.decimals"" ) ; public static int rounding = UtilNumber . getBigDecimalRoundingMode ( ""finaccount.rounding"" ) ; public static final BigDecimal ZERO = BigDecimal . ZERO . setScale ( decimals , rounding ) ; public static final String giftCertFinAccountTypeId = ""GIFTCERT_ACCOUNT"" ; public static final boolean defaultPinRequired = false ; static char [ ] char_pool = new char [ 10 + 26 ] ; static { int j = 0 ; for ( int i = ""0"" . charAt ( 0 ) ; i <= ""9"" . charAt ( 0 ) ; i ++ ) { char_pool [ j ++ ] = ( char ) i ; } for ( int i = ""A"" . charAt ( 0 ) ; i <= ""Z"" . charAt ( 0 ) ; i ++ ) { char_pool [ j ++ ] = ( char ) i ; } } public static BigDecimal addFirstEntryAmount ( BigDecimal initialValue , List < GenericValue > transactions , String fieldName , int decimals , int rounding ) throws GenericEntityException { if ( ( transactions != null ) && ( transactions . size ( ) == 1 ) ) { GenericValue firstEntry = transactions . get ( 0 ) ; if ( firstEntry . get ( fieldName ) != null ) { BigDecimal valueToAdd = firstEntry . getBigDecimal ( fieldName ) ; return initialValue . add ( valueToAdd ) . setScale ( decimals , rounding ) ; } else { return initialValue ; } } else { return initialValue ; } } public static String getNewFinAccountCode ( int codeLength , Delegator delegator ) throws GenericEntityException { Random r = new Random ( ) ; boolean foundUniqueNewCode = false ; StringBuilder newAccountCode = null ; long count = 0 ; while ( ! foundUniqueNewCode ) { newAccountCode = new StringBuilder ( codeLength ) ; for ( int i = 0 ; i < codeLength ; i ++ ) { newAccountCode . append ( char_pool [ r . nextInt ( char_pool . length ) ] ) ; } List < GenericValue > existingAccountsWithCode = delegator . findByAnd ( ""FinAccount"" , UtilMisc . toMap ( ""finAccountCode"" , newAccountCode . toString ( ) ) , null , false ) ; if ( existingAccountsWithCode . size ( ) == 0 ) { foundUniqueNewCode = true ; } count ++ ; if ( count > 999999 ) { throw new GenericEntityException ( ""Unable to locate unique FinAccountCode! Length ["" + codeLength + ""]"" ) ; } } return newAccountCode . toString ( ) ; } public static GenericValue getFinAccountFromCode ( String finAccountCode , Delegator delegator ) throws GenericEntityException { if ( finAccountCode == null ) { return null ; } Pattern filterRegex = Pattern . compile ( ""[^0-9A-Z]"" ) ; finAccountCode = finAccountCode . toUpperCase ( ) . replaceAll ( filterRegex . pattern ( ) , """" ) ; GenericValue encryptedFinAccount = delegator . makeValue ( ""FinAccount"" , UtilMisc . toMap ( ""finAccountCode"" , finAccountCode ) ) ; delegator . encryptFields ( encryptedFinAccount ) ; String encryptedFinAccountCode = encryptedFinAccount . getString ( ""finAccountCode"" ) ; List < GenericValue > accounts = delegator . findByAnd ( ""FinAccount"" , UtilMisc . toMap ( ""finAccountCode"" , encryptedFinAccountCode ) , null , false ) ; accounts = EntityUtil . filterByDate ( accounts ) ; if ( UtilValidate . isEmpty ( accounts ) ) { Debug . logWarning ( ""No fin account found for account code ["" + finAccountCode + ""]"" , module ) ; return null ; } else if ( accounts . size ( ) > 1 ) { Debug . logError ( ""Multiple fin accounts found"" , module ) ; return null ; } else { return accounts . get ( 0 ) ; } } public static BigDecimal getBalance ( String finAccountId , Timestamp asOfDateTime , Delegator delegator ) throws GenericEntityException { if ( asOfDateTime == null ) asOfDateTime = UtilDateTime . nowTimestamp ( ) ; BigDecimal incrementTotal = ZERO ; BigDecimal decrementTotal = ZERO ; EntityConditionList < EntityCondition > incrementConditions = EntityCondition . makeCondition ( UtilMisc . toList ( EntityCondition . makeCondition ( ""finAccountId"" , EntityOperator . EQUALS , finAccountId ) , EntityCondition . makeCondition ( ""transactionDate"" , EntityOperator . LESS_THAN_EQUAL_TO , asOfDateTime ) , EntityCondition . makeCondition ( UtilMisc . toList ( EntityCondition . makeCondition ( ""finAccountTransTypeId"" , EntityOperator . EQUALS , ""DEPOSIT"" ) , EntityCondition . makeCondition ( ""finAccountTransTypeId"" , EntityOperator . EQUALS , ""ADJUSTMENT"" ) ) , EntityOperator . OR ) ) , EntityOperator . AND ) ; List < GenericValue > transSums = delegator . findList ( ""FinAccountTransSum"" , incrementConditions , UtilMisc . toSet ( ""amount"" ) , null , null , false ) ; incrementTotal = addFirstEntryAmount ( incrementTotal , transSums , ""amount"" , ( decimals + 1 ) , rounding ) ; EntityConditionList < EntityExpr > decrementConditions = EntityCondition . makeCondition ( UtilMisc . toList ( EntityCondition . makeCondition ( ""finAccountId"" , EntityOperator . EQUALS , finAccountId ) , EntityCondition . makeCondition ( ""transactionDate"" , EntityOperator . LESS_THAN_EQUAL_TO , asOfDateTime ) , EntityCondition . makeCondition ( ""finAccountTransTypeId"" , EntityOperator . EQUALS , ""WITHDRAWAL"" ) ) , EntityOperator . AND ) ; transSums = delegator . findList ( ""FinAccountTransSum"" , decrementConditions , UtilMisc . toSet ( ""amount"" ) , null , null , false ) ; decrementTotal = addFirstEntryAmount ( decrementTotal , transSums , ""amount"" , ( decimals + 1 ) , rounding ) ; return incrementTotal . subtract ( decrementTotal ) . setScale ( decimals , rounding ) ; } public static BigDecimal getAvailableBalance ( String finAccountId , Timestamp asOfDateTime , Delegator delegator ) throws GenericEntityException { if ( asOfDateTime == null ) asOfDateTime = UtilDateTime . nowTimestamp ( ) ; BigDecimal netBalance = getBalance ( finAccountId , asOfDateTime , delegator ) ; EntityConditionList < EntityCondition > authorizationConditions = EntityCondition . makeCondition ( UtilMisc . toList ( EntityCondition . makeCondition ( ""finAccountId"" , EntityOperator . EQUALS , finAccountId ) , EntityCondition . makeCondition ( ""authorizationDate"" , EntityOperator . LESS_THAN_EQUAL_TO , asOfDateTime ) , EntityUtil . getFilterByDateExpr ( asOfDateTime ) ) , EntityOperator . AND ) ; List < GenericValue > authSums = delegator . findList ( ""FinAccountAuthSum"" , authorizationConditions , UtilMisc . toSet ( ""amount"" ) , null , null , false ) ; BigDecimal authorizationsTotal = addFirstEntryAmount ( ZERO , authSums , ""amount"" , ( decimals + 1 ) , rounding ) ; return netBalance . subtract ( authorizationsTotal ) . setScale ( decimals , rounding ) ; } public static boolean validateFinAccount ( GenericValue finAccount ) { return false ; } public static boolean validatePin ( Delegator delegator , String finAccountId , String pinNumber ) { GenericValue finAccount = null ; try { finAccount = delegator . findOne ( ""FinAccount"" , UtilMisc . toMap ( ""finAccountId"" , finAccountId ) , false ) ; } catch ( GenericEntityException e ) { Debug . logError ( e , module ) ; } if ( finAccount != null ) { String dbPin = finAccount . getString ( ""finAccountCode"" ) ; Debug . logInfo ( ""FinAccount Pin Validation: [Sent: "" + pinNumber + ""] [Actual: "" + dbPin + ""]"" , module ) ; if ( dbPin != null && dbPin . equals ( pinNumber ) ) { return true ; } } else { Debug . logInfo ( ""FinAccount record not found ("" + finAccountId + "")"" , module ) ; } return false ; } public static String generateRandomFinNumber ( Delegator delegator , int length , boolean isId ) throws GenericEntityException { if ( length > 19 ) { length = 19 ; } Random rand = new Random ( ) ; boolean isValid = false ; String number = null ; while ( ! isValid ) { number = """" ; for ( int i = 0 ; i < length ; i ++ ) { int randInt = rand . nextInt ( 9 ) ; number = number + randInt ; } if ( isId ) { int check = UtilValidate . getLuhnCheckDigit ( number ) ; number = number + check ; if ( checkFinAccountNumber ( number ) ) { isValid = checkIsNumberInDatabase ( delegator , number ) ; } } else { isValid = true ; } } return number ; } private static boolean checkIsNumberInDatabase ( Delegator delegator , String number ) throws GenericEntityException { GenericValue finAccount = delegator . findOne ( ""FinAccount"" , UtilMisc . toMap ( ""finAccountId"" , number ) , false ) ; return finAccount == null ; } public static boolean checkFinAccountNumber ( String number ) { number = number . replaceAll ( ""\\D"" , """" ) ; return UtilValidate . sumIsMod10 ( UtilValidate . getLuhnSum ( number ) ) ; } }",No
" static class RemoveMethodsArgs { public RemoveMethodsArgs ( final MethodScope methodScope , final String prefix , final Class < ? > returnType , final boolean canBeVoid , final int paramCount ) { this . methodScope = methodScope ; this . prefix = prefix ; this . returnType = returnType ; this . canBeVoid = canBeVoid ; this . paramCount = paramCount ; } public MethodScope methodScope ; public String prefix ; public Class < ? > returnType ; public boolean canBeVoid ; public int paramCount ; ",No
"public class DefaultRepositoryRequest implements RepositoryRequest { private boolean offline ; private boolean forceUpdate ; private ArtifactRepository localRepository ; private List < ArtifactRepository > remoteRepositories ; public DefaultRepositoryRequest ( ) { } public DefaultRepositoryRequest ( RepositoryRequest repositoryRequest ) { setLocalRepository ( repositoryRequest . getLocalRepository ( ) ) ; setRemoteRepositories ( repositoryRequest . getRemoteRepositories ( ) ) ; setOffline ( repositoryRequest . isOffline ( ) ) ; setForceUpdate ( repositoryRequest . isForceUpdate ( ) ) ; } public static RepositoryRequest getRepositoryRequest ( MavenSession session , MavenProject project ) { RepositoryRequest request = new DefaultRepositoryRequest ( ) ; request . setLocalRepository ( session . getLocalRepository ( ) ) ; if ( project != null ) { request . setRemoteRepositories ( project . getPluginArtifactRepositories ( ) ) ; } request . setOffline ( session . isOffline ( ) ) ; request . setForceUpdate ( session . getRequest ( ) . isUpdateSnapshots ( ) ) ; return request ; } public boolean isOffline ( ) { return offline ; } public DefaultRepositoryRequest setOffline ( boolean offline ) { this . offline = offline ; return this ; } public boolean isForceUpdate ( ) { return forceUpdate ; } public DefaultRepositoryRequest setForceUpdate ( boolean forceUpdate ) { this . forceUpdate = forceUpdate ; return this ; } public ArtifactRepository getLocalRepository ( ) { return localRepository ; } public DefaultRepositoryRequest setLocalRepository ( ArtifactRepository localRepository ) { this . localRepository = localRepository ; return this ; } public List < ArtifactRepository > getRemoteRepositories ( ) { if ( remoteRepositories == null ) { remoteRepositories = new ArrayList < > ( ) ; } return remoteRepositories ; } public DefaultRepositoryRequest setRemoteRepositories ( List < ArtifactRepository > remoteRepositories ) { this . remoteRepositories = remoteRepositories ; return this ; } }",No
"public class CharAssociation implements Cloneable { private final int offset ; private final int count ; private final int [ ] subIntervals ; private Map < String , Object > predications ; private static volatile Map < String , PredicationMerger > predicationMergers ; interface PredicationMerger { Object merge ( String key , Object v1 , Object v2 ) ; } public CharAssociation ( int offset , int count , int [ ] subIntervals ) { this . offset = offset ; this . count = count ; this . subIntervals = ( ( subIntervals != null ) && ( subIntervals . length > 2 ) ) ? subIntervals : null ; } public CharAssociation ( int offset , int count ) { this ( offset , count , null ) ; } public CharAssociation ( int [ ] subIntervals ) { this ( getSubIntervalsStart ( subIntervals ) , getSubIntervalsLength ( subIntervals ) , subIntervals ) ; } public int getOffset ( ) { return offset ; } public int getCount ( ) { return count ; } public int getStart ( ) { return getOffset ( ) ; } public int getEnd ( ) { return getOffset ( ) + getCount ( ) ; } public boolean isDisjoint ( ) { return subIntervals != null ; } public int [ ] getSubIntervals ( ) { return subIntervals ; } public int getSubIntervalCount ( ) { return ( subIntervals != null ) ? ( subIntervals . length / 2 ) : 0 ; } public boolean contained ( int offset , int count ) { int s = offset ; int e = offset + count ; if ( ! isDisjoint ( ) ) { int s0 = getStart ( ) ; int e0 = getEnd ( ) ; return ( s0 >= s ) && ( e0 <= e ) ; } else { int ns = getSubIntervalCount ( ) ; for ( int i = 0 ; i < ns ; i ++ ) { int s0 = subIntervals [ 2 * i + 0 ] ; int e0 = subIntervals [ 2 * i + 1 ] ; if ( ( s0 >= s ) && ( e0 <= e ) ) { return true ; } } return false ; } } public void setPredication ( String key , Object value ) { if ( predications == null ) { predications = new HashMap < String , Object > ( ) ; } if ( predications != null ) { predications . put ( key , value ) ; } } public Object getPredication ( String key ) { if ( predications != null ) { return predications . get ( key ) ; } else { return null ; } } public void mergePredication ( String key , Object value ) { if ( predications == null ) { predications = new HashMap < String , Object > ( ) ; } if ( predications != null ) { if ( predications . containsKey ( key ) ) { Object v1 = predications . get ( key ) ; Object v2 = value ; predications . put ( key , mergePredicationValues ( key , v1 , v2 ) ) ; } else { predications . put ( key , value ) ; } } } public static Object mergePredicationValues ( String key , Object v1 , Object v2 ) { PredicationMerger pm = getPredicationMerger ( key ) ; if ( pm != null ) { return pm . merge ( key , v1 , v2 ) ; } else if ( v2 != null ) { return v2 ; } else { return v1 ; } } public void mergePredications ( CharAssociation ca ) { if ( ca . predications != null ) { for ( Map . Entry < String , Object > e : ca . predications . entrySet ( ) ) { mergePredication ( e . getKey ( ) , e . getValue ( ) ) ; } } } public Object clone ( ) { try { CharAssociation ca = ( CharAssociation ) super . clone ( ) ; if ( predications != null ) { ca . predications = new HashMap < String , Object > ( predications ) ; } return ca ; } catch ( CloneNotSupportedException e ) { return null ; } } public static void setPredicationMerger ( String key , PredicationMerger pm ) { if ( predicationMergers == null ) { predicationMergers = new HashMap < String , PredicationMerger > ( ) ; } if ( predicationMergers != null ) { predicationMergers . put ( key , pm ) ; } } public static PredicationMerger getPredicationMerger ( String key ) { if ( predicationMergers != null ) { return predicationMergers . get ( key ) ; } else { return null ; } } public static CharAssociation [ ] replicate ( CharAssociation a , int repeat ) { CharAssociation [ ] aa = new CharAssociation [ repeat ] ; for ( int i = 0 , n = aa . length ; i < n ; i ++ ) { aa [ i ] = ( CharAssociation ) a . clone ( ) ; } return aa ; } public static CharAssociation join ( CharAssociation [ ] aa ) { CharAssociation ca ; int [ ] ia = extractIntervals ( aa ) ; if ( ( ia == null ) || ( ia . length == 0 ) ) { ca = new CharAssociation ( 0 , 0 ) ; } else if ( ia . length == 2 ) { int s = ia [ 0 ] ; int e = ia [ 1 ] ; ca = new CharAssociation ( s , e - s ) ; } else { ca = new CharAssociation ( mergeIntervals ( ia ) ) ; } return mergePredicates ( ca , aa ) ; } private static CharAssociation mergePredicates ( CharAssociation ca , CharAssociation [ ] aa ) { for ( CharAssociation a : aa ) { ca . mergePredications ( a ) ; } return ca ; } private static int getSubIntervalsStart ( int [ ] ia ) { int us = Integer . MAX_VALUE ; int ue = Integer . MIN_VALUE ; if ( ia != null ) { for ( int i = 0 , n = ia . length ; i < n ; i += 2 ) { int s = ia [ i + 0 ] ; int e = ia [ i + 1 ] ; if ( s < us ) { us = s ; } if ( e > ue ) { ue = e ; } } if ( ue < 0 ) { ue = 0 ; } if ( us > ue ) { us = ue ; } } return us ; } private static int getSubIntervalsLength ( int [ ] ia ) { int us = Integer . MAX_VALUE ; int ue = Integer . MIN_VALUE ; if ( ia != null ) { for ( int i = 0 , n = ia . length ; i < n ; i += 2 ) { int s = ia [ i + 0 ] ; int e = ia [ i + 1 ] ; if ( s < us ) { us = s ; } if ( e > ue ) { ue = e ; } } if ( ue < 0 ) { ue = 0 ; } if ( us > ue ) { us = ue ; } } return ue - us ; } private static int [ ] extractIntervals ( CharAssociation [ ] aa ) { int ni = 0 ; for ( CharAssociation a : aa ) { if ( a . isDisjoint ( ) ) { ni += a . getSubIntervalCount ( ) ; } else { ni += 1 ; } } int [ ] sa = new int [ ni ] ; int [ ] ea = new int [ ni ] ; for ( int i = 0 , k = 0 ; i < aa . length ; i ++ ) { CharAssociation a = aa [ i ] ; if ( a . isDisjoint ( ) ) { int [ ] da = a . getSubIntervals ( ) ; for ( int j = 0 ; j < da . length ; j += 2 ) { sa [ k ] = da [ j + 0 ] ; ea [ k ] = da [ j + 1 ] ; k ++ ; } } else { sa [ k ] = a . getStart ( ) ; ea [ k ] = a . getEnd ( ) ; k ++ ; } } return sortIntervals ( sa , ea ) ; } private static final int [ ] SORT_INCREMENTS_16 = { 1391376 , 463792 , 198768 , 86961 , 33936 , 13776 , 4592 , 1968 , 861 , 336 , 112 , 48 , 21 , 7 , 3 , 1 } ; private static final int [ ] SORT_INCREMENTS_03 = { 7 , 3 , 1 } ; private static int [ ] sortIntervals ( int [ ] sa , int [ ] ea ) { assert sa != null ; assert ea != null ; assert sa . length == ea . length ; int ni = sa . length ; int [ ] incr = ( ni < 21 ) ? SORT_INCREMENTS_03 : SORT_INCREMENTS_16 ; for ( int anIncr : incr ) { for ( int h = anIncr , i = h , n = ni , j ; i < n ; i ++ ) { int s1 = sa [ i ] ; int e1 = ea [ i ] ; for ( j = i ; j >= h ; j -= h ) { int s2 = sa [ j - h ] ; int e2 = ea [ j - h ] ; if ( s2 > s1 ) { sa [ j ] = s2 ; ea [ j ] = e2 ; } else if ( ( s2 == s1 ) && ( e2 > e1 ) ) { sa [ j ] = s2 ; ea [ j ] = e2 ; } else { break ; } } sa [ j ] = s1 ; ea [ j ] = e1 ; } } int [ ] ia = new int [ ni * 2 ] ; for ( int i = 0 ; i < ni ; i ++ ) { ia [ ( i * 2 ) + 0 ] = sa [ i ] ; ia [ ( i * 2 ) + 1 ] = ea [ i ] ; } return ia ; } private static int [ ] mergeIntervals ( int [ ] ia ) { int ni = ia . length ; int i ; int n ; int nm ; int is ; int ie ; for ( i = 0 , n = ni , nm = 0 , is = ie = - 1 ; i < n ; i += 2 ) { int s = ia [ i + 0 ] ; int e = ia [ i + 1 ] ; if ( ( ie < 0 ) || ( s > ie ) ) { is = s ; ie = e ; nm ++ ; } else if ( s >= is ) { if ( e > ie ) { ie = e ; } } } int [ ] mi = new int [ nm * 2 ] ; for ( i = 0 , n = ni , nm = 0 , is = ie = - 1 ; i < n ; i += 2 ) { int s = ia [ i + 0 ] ; int e = ia [ i + 1 ] ; int k = nm * 2 ; if ( ( ie < 0 ) || ( s > ie ) ) { is = s ; ie = e ; mi [ k + 0 ] = is ; mi [ k + 1 ] = ie ; nm ++ ; } else if ( s >= is ) { if ( e > ie ) { ie = e ; } mi [ k - 1 ] = ie ; } } return mi ; } @ Override public String toString ( ) { StringBuffer sb = new StringBuffer ( ) ; sb . append ( '[' ) ; sb . append ( offset ) ; sb . append ( ',' ) ; sb . append ( count ) ; sb . append ( ']' ) ; return sb . toString ( ) ; } }",No
"public final class LocalClient { private static final Logger LOG = Logger . getLogger ( LocalClient . class . getName ( ) ) ; private static final String CLIENT_REMOTE_ID = ClientRemoteIdentifier . NONE ; private final PreparedDriverFolderLauncher launcher ; private final LocalRuntimeDriverConfigurationGenerator configurationGenerator ; @ Inject private LocalClient ( final PreparedDriverFolderLauncher launcher , final LocalRuntimeDriverConfigurationGenerator configurationGenerator ) { this . launcher = launcher ; this . configurationGenerator = configurationGenerator ; } private void submit ( final LocalSubmissionFromCS localSubmissionFromCS ) throws IOException { final File driverFolder = new File ( localSubmissionFromCS . getJobFolder ( ) , PreparedDriverFolderLauncher . DRIVER_FOLDER_NAME ) ; if ( ! driverFolder . exists ( ) ) { throw new IOException ( ""The Driver folder "" + driverFolder . getAbsolutePath ( ) + "" doesn't exist."" ) ; } configurationGenerator . writeConfiguration ( localSubmissionFromCS . getJobFolder ( ) , localSubmissionFromCS . getJobId ( ) , CLIENT_REMOTE_ID ) ; launcher . launch ( driverFolder , localSubmissionFromCS . getDriverStdoutPath ( ) , localSubmissionFromCS . getDriverStderrPath ( ) ) ; } public static void main ( final String [ ] args ) throws IOException , InjectionException { final File jobSubmissionParametersFile = new File ( args [ 0 ] ) ; final File localAppSubmissionParametersFile = new File ( args [ 1 ] ) ; if ( ! ( jobSubmissionParametersFile . exists ( ) && jobSubmissionParametersFile . canRead ( ) ) ) { throw new IOException ( ""Unable to open and read "" + jobSubmissionParametersFile . getAbsolutePath ( ) ) ; } if ( ! ( localAppSubmissionParametersFile . exists ( ) && localAppSubmissionParametersFile . canRead ( ) ) ) { throw new IOException ( ""Unable to open and read "" + localAppSubmissionParametersFile . getAbsolutePath ( ) ) ; } final LocalSubmissionFromCS localSubmissionFromCS = LocalSubmissionFromCS . fromSubmissionParameterFiles ( jobSubmissionParametersFile , localAppSubmissionParametersFile ) ; LOG . log ( Level . INFO , ""Local job submission received from C#: {0}"" , localSubmissionFromCS ) ; final Configuration runtimeConfiguration = localSubmissionFromCS . getRuntimeConfiguration ( ) ; final LocalClient client = Tang . Factory . getTang ( ) . newInjector ( runtimeConfiguration ) . getInstance ( LocalClient . class ) ; client . submit ( localSubmissionFromCS ) ; } }",No
"public class VersionLockManager extends AbstractLockManager { private boolean _versionCheckOnReadLock = true ; private boolean _versionUpdateOnWriteLock = true ; private boolean _refreshing = false ; public int getLockLevel ( OpenJPAStateManager sm ) { while ( sm . getOwner ( ) != null ) sm = sm . getOwner ( ) ; Number level = ( Number ) sm . getLock ( ) ; return ( level == null ) ? LOCK_NONE : level . intValue ( ) ; } protected void setLockLevel ( OpenJPAStateManager sm , int level ) { sm . setLock ( level ) ; } public void release ( OpenJPAStateManager sm ) { sm . setLock ( null ) ; } public void lock ( OpenJPAStateManager sm , int level , int timeout , Object sdata ) { commonLock ( sm , level , timeout , sdata , ! _refreshing ) ; } public void refreshLock ( OpenJPAStateManager sm , int level , int timeout , Object sdata ) { try { _refreshing = true ; commonLock ( sm , level , timeout , sdata , false ) ; } finally { _refreshing = false ; } } private void commonLock ( OpenJPAStateManager sm , int level , int timeout , Object sdata , boolean postLockVersionCheck ) { if ( level == LOCK_NONE ) return ; while ( sm . getOwner ( ) != null ) sm = sm . getOwner ( ) ; int oldLevel = getLockLevel ( sm ) ; if ( ! sm . isPersistent ( ) || sm . isNew ( ) || level <= oldLevel ) return ; try { lockInternal ( sm , level , timeout , sdata , postLockVersionCheck ) ; } catch ( RuntimeException re ) { setLockLevel ( sm , oldLevel ) ; throw re ; } } protected void lockInternal ( OpenJPAStateManager sm , int level , int timeout , Object sdata , boolean postLockVersionCheck ) { optimisticLockInternal ( sm , level , timeout , sdata , postLockVersionCheck ) ; } protected void optimisticLockInternal ( OpenJPAStateManager sm , int level , int timeout , Object sdata , boolean postLockVersionCheck ) { setLockLevel ( sm , level ) ; if ( level >= LockLevels . LOCK_WRITE && _versionUpdateOnWriteLock ) getContext ( ) . transactional ( sm . getManagedInstance ( ) , true , null ) ; else if ( level >= LockLevels . LOCK_READ && _versionCheckOnReadLock ) getContext ( ) . transactional ( sm . getManagedInstance ( ) , false , null ) ; } public void setVersionCheckOnReadLock ( boolean versionCheckOnReadLock ) { _versionCheckOnReadLock = versionCheckOnReadLock ; } public boolean getVersionCheckOnReadLock ( ) { return _versionCheckOnReadLock ; } public void setVersionUpdateOnWriteLock ( boolean versionUpdateOnWriteLock ) { _versionUpdateOnWriteLock = versionUpdateOnWriteLock ; } public boolean getVersionUpdateOnWriteLock ( ) { return _versionUpdateOnWriteLock ; } }",No
"public class ThrottleSpecManager extends org . apache . manifoldcf . core . database . BaseTable { public static final String _rcsid = ""@(#)$Id: ThrottleSpecManager.java 988245 2010-08-23 18:39:35Z kwright $"" ; public final static String ownerNameField = ""ownername"" ; public final static String descriptionField = ""description"" ; public final static String matchField = ""matchstring"" ; public final static String throttleField = ""throttle"" ; public ThrottleSpecManager ( IDBInterface database ) throws ManifoldCFException { super ( database , ""throttlespec"" ) ; } public void install ( String ownerTable , String owningTablePrimaryKey ) throws ManifoldCFException { while ( true ) { Map existing = getTableSchema ( null , null ) ; if ( existing == null ) { HashMap map = new HashMap ( ) ; map . put ( ownerNameField , new ColumnDescription ( ""VARCHAR(32)"" , false , false , ownerTable , owningTablePrimaryKey , false ) ) ; map . put ( descriptionField , new ColumnDescription ( ""VARCHAR(255)"" , false , true , null , null , false ) ) ; map . put ( matchField , new ColumnDescription ( ""VARCHAR(255)"" , false , true , null , null , false ) ) ; map . put ( throttleField , new ColumnDescription ( ""FLOAT"" , false , false , null , null , false ) ) ; performCreate ( map , null ) ; } else { if ( existing . get ( matchField ) == null ) { HashMap map = new HashMap ( ) ; map . put ( matchField , new ColumnDescription ( ""VARCHAR(255)"" , false , true , null , null , false ) ) ; performAlter ( map , null , null , null ) ; performModification ( ""UPDATE "" + getTableName ( ) + "" SET "" + matchField + ""=match"" , null , null ) ; ArrayList list = new ArrayList ( ) ; list . add ( ""match"" ) ; performAlter ( null , null , list , null ) ; } } IndexDescription ownerIndex = new IndexDescription ( false , new String [ ] { ownerNameField } ) ; Map indexes = getTableIndexes ( null , null ) ; Iterator iter = indexes . keySet ( ) . iterator ( ) ; while ( iter . hasNext ( ) ) { String indexName = ( String ) iter . next ( ) ; IndexDescription id = ( IndexDescription ) indexes . get ( indexName ) ; if ( ownerIndex != null && id . equals ( ownerIndex ) ) ownerIndex = null ; else if ( indexName . indexOf ( ""_pkey"" ) == - 1 ) performRemoveIndex ( indexName ) ; } if ( ownerIndex != null ) performAddIndex ( null , ownerIndex ) ; break ; } } public void deinstall ( ) throws ManifoldCFException { performDrop ( null ) ; } public IResultSet readRows ( String name ) throws ManifoldCFException { ArrayList list = new ArrayList ( ) ; String query = buildConjunctionClause ( list , new ClauseDescription [ ] { new UnitaryClause ( ownerNameField , name ) } ) ; return performQuery ( ""SELECT "" + descriptionField + "" AS description,"" + matchField + "" AS match,"" + throttleField + "" AS value FROM "" + getTableName ( ) + "" WHERE "" + query , list , null , null ) ; } public int maxClauseGetRows ( ) { return findConjunctionClauseMax ( new ClauseDescription [ ] { } ) ; } public void getRows ( IRepositoryConnection [ ] connections , Map indexMap , ArrayList ownerNameParams ) throws ManifoldCFException { ArrayList list = new ArrayList ( ) ; String query = buildConjunctionClause ( list , new ClauseDescription [ ] { new MultiClause ( ownerNameField , ownerNameParams ) } ) ; IResultSet set = performQuery ( ""SELECT * FROM "" + getTableName ( ) + "" WHERE "" + query , list , null , null ) ; int i = 0 ; while ( i < set . getRowCount ( ) ) { IResultRow row = set . getRow ( i ) ; String ownerName = ( String ) row . getValue ( ownerNameField ) ; int index = ( ( Integer ) indexMap . get ( ownerName ) ) . intValue ( ) ; String description = ( String ) row . getValue ( descriptionField ) ; String match = ( String ) row . getValue ( matchField ) ; float throttle = new Float ( row . getValue ( throttleField ) . toString ( ) ) . floatValue ( ) ; connections [ index ] . addThrottleValue ( match , description , throttle ) ; i ++ ; } } public void writeRows ( String owner , IRepositoryConnection connection ) throws ManifoldCFException { beginTransaction ( ) ; try { int i = 0 ; HashMap map = new HashMap ( ) ; String [ ] matches = connection . getThrottles ( ) ; while ( i < matches . length ) { String match = matches [ i ++ ] ; String description = connection . getThrottleDescription ( match ) ; float value = connection . getThrottleValue ( match ) ; map . clear ( ) ; map . put ( matchField , match ) ; if ( description != null && description . length ( ) > 0 ) map . put ( descriptionField , description ) ; map . put ( throttleField , new Float ( value ) ) ; map . put ( ownerNameField , owner ) ; performInsert ( map , null ) ; } } catch ( ManifoldCFException e ) { signalRollback ( ) ; throw e ; } catch ( Error e ) { signalRollback ( ) ; throw e ; } finally { endTransaction ( ) ; } } public void deleteRows ( String owner ) throws ManifoldCFException { ArrayList list = new ArrayList ( ) ; String query = buildConjunctionClause ( list , new ClauseDescription [ ] { new UnitaryClause ( ownerNameField , owner ) } ) ; performDelete ( ""WHERE "" + query , list , null ) ; } }",No
 @ ViewModelLayout ( ) class CustomerViewModelWithDefaults { ,No
"public class ComputeResourceFileSystemResource extends AppCatAbstractResource { private final static Logger logger = LoggerFactory . getLogger ( ComputeResourceFileSystemResource . class ) ; private String computeResourceId ; private ComputeResourceResource computeHostResource ; private String path ; private String fileSystem ; @ Override public void remove ( Object identifier ) throws AppCatalogException { HashMap < String , String > ids ; if ( identifier instanceof Map ) { ids = ( HashMap < String , String > ) identifier ; } else { logger . error ( ""Identifier should be a map with the field name and it's value"" ) ; throw new AppCatalogException ( ""Identifier should be a map with the field name and it's value"" ) ; } EntityManager em = null ; try { em = AppCatalogJPAUtils . getEntityManager ( ) ; em . getTransaction ( ) . begin ( ) ; AppCatalogQueryGenerator generator = new AppCatalogQueryGenerator ( COMPUTE_RESOURCE_FILE_SYSTEM ) ; generator . setParameter ( ComputeResourceFileSystemConstants . COMPUTE_RESOURCE_ID , ids . get ( ComputeResourceFileSystemConstants . COMPUTE_RESOURCE_ID ) ) ; generator . setParameter ( ComputeResourceFileSystemConstants . FILE_SYSTEM , ids . get ( ComputeResourceFileSystemConstants . FILE_SYSTEM ) ) ; Query q = generator . deleteQuery ( em ) ; q . executeUpdate ( ) ; em . getTransaction ( ) . commit ( ) ; if ( em . isOpen ( ) ) { if ( em . getTransaction ( ) . isActive ( ) ) { em . getTransaction ( ) . rollback ( ) ; } em . close ( ) ; } } catch ( ApplicationSettingsException e ) { logger . error ( e . getMessage ( ) , e ) ; throw new AppCatalogException ( e ) ; } finally { if ( em != null && em . isOpen ( ) ) { if ( em . getTransaction ( ) . isActive ( ) ) { em . getTransaction ( ) . rollback ( ) ; } em . close ( ) ; } } } @ Override public AppCatalogResource get ( Object identifier ) throws AppCatalogException { HashMap < String , String > ids ; if ( identifier instanceof Map ) { ids = ( HashMap < String , String > ) identifier ; } else { logger . error ( ""Identifier should be a map with the field name and it's value"" ) ; throw new AppCatalogException ( ""Identifier should be a map with the field name and it's value"" ) ; } EntityManager em = null ; try { em = AppCatalogJPAUtils . getEntityManager ( ) ; em . getTransaction ( ) . begin ( ) ; AppCatalogQueryGenerator generator = new AppCatalogQueryGenerator ( COMPUTE_RESOURCE_FILE_SYSTEM ) ; generator . setParameter ( ComputeResourceFileSystemConstants . COMPUTE_RESOURCE_ID , ids . get ( ComputeResourceFileSystemConstants . COMPUTE_RESOURCE_ID ) ) ; generator . setParameter ( ComputeResourceFileSystemConstants . FILE_SYSTEM , ids . get ( ComputeResourceFileSystemConstants . FILE_SYSTEM ) ) ; Query q = generator . selectQuery ( em ) ; ComputeResourceFileSystem computeResourceFileSystem = ( ComputeResourceFileSystem ) q . getSingleResult ( ) ; ComputeResourceFileSystemResource computeResourceFileSystemResource = ( ComputeResourceFileSystemResource ) AppCatalogJPAUtils . getResource ( AppCatalogResourceType . COMPUTE_RESOURCE_FILE_SYSTEM , computeResourceFileSystem ) ; em . getTransaction ( ) . commit ( ) ; if ( em . isOpen ( ) ) { if ( em . getTransaction ( ) . isActive ( ) ) { em . getTransaction ( ) . rollback ( ) ; } em . close ( ) ; } return computeResourceFileSystemResource ; } catch ( ApplicationSettingsException e ) { logger . error ( e . getMessage ( ) , e ) ; throw new AppCatalogException ( e ) ; } finally { if ( em != null && em . isOpen ( ) ) { if ( em . getTransaction ( ) . isActive ( ) ) { em . getTransaction ( ) . rollback ( ) ; } em . close ( ) ; } } } @ Override public List < AppCatalogResource > get ( String fieldName , Object value ) throws AppCatalogException { List < AppCatalogResource > computeResourceFileSystemResources = new ArrayList < AppCatalogResource > ( ) ; EntityManager em = null ; try { em = AppCatalogJPAUtils . getEntityManager ( ) ; em . getTransaction ( ) . begin ( ) ; AppCatalogQueryGenerator generator = new AppCatalogQueryGenerator ( COMPUTE_RESOURCE_FILE_SYSTEM ) ; Query q ; if ( ( fieldName . equals ( ComputeResourceFileSystemConstants . COMPUTE_RESOURCE_ID ) ) || ( fieldName . equals ( ComputeResourceFileSystemConstants . PATH ) ) || ( fieldName . equals ( ComputeResourceFileSystemConstants . FILE_SYSTEM ) ) ) { generator . setParameter ( fieldName , value ) ; q = generator . selectQuery ( em ) ; List < ? > results = q . getResultList ( ) ; for ( Object result : results ) { ComputeResourceFileSystem computeResourceFileSystem = ( ComputeResourceFileSystem ) result ; ComputeResourceFileSystemResource computeResourceFileSystemResource = ( ComputeResourceFileSystemResource ) AppCatalogJPAUtils . getResource ( AppCatalogResourceType . COMPUTE_RESOURCE_FILE_SYSTEM , computeResourceFileSystem ) ; computeResourceFileSystemResources . add ( computeResourceFileSystemResource ) ; } } else { em . getTransaction ( ) . commit ( ) ; if ( em . isOpen ( ) ) { if ( em . getTransaction ( ) . isActive ( ) ) { em . getTransaction ( ) . rollback ( ) ; } em . close ( ) ; } logger . error ( ""Unsupported field name for Compute Resource File System Resource."" , new IllegalArgumentException ( ) ) ; throw new IllegalArgumentException ( ""Unsupported field name for Compute Resource File System Resource."" ) ; } em . getTransaction ( ) . commit ( ) ; if ( em . isOpen ( ) ) { if ( em . getTransaction ( ) . isActive ( ) ) { em . getTransaction ( ) . rollback ( ) ; } em . close ( ) ; } } catch ( ApplicationSettingsException e ) { logger . error ( e . getMessage ( ) , e ) ; throw new AppCatalogException ( e ) ; } finally { if ( em != null && em . isOpen ( ) ) { if ( em . getTransaction ( ) . isActive ( ) ) { em . getTransaction ( ) . rollback ( ) ; } em . close ( ) ; } } return computeResourceFileSystemResources ; } @ Override public List < AppCatalogResource > getAll ( ) throws AppCatalogException { return null ; } @ Override public List < String > getAllIds ( ) throws AppCatalogException { return null ; } @ Override public List < String > getIds ( String fieldName , Object value ) throws AppCatalogException { List < String > computeResourceFileSystemResourceIDs = new ArrayList < String > ( ) ; EntityManager em = null ; try { em = AppCatalogJPAUtils . getEntityManager ( ) ; em . getTransaction ( ) . begin ( ) ; AppCatalogQueryGenerator generator = new AppCatalogQueryGenerator ( COMPUTE_RESOURCE_FILE_SYSTEM ) ; Query q ; if ( ( fieldName . equals ( ComputeResourceFileSystemConstants . COMPUTE_RESOURCE_ID ) ) || ( fieldName . equals ( ComputeResourceFileSystemConstants . PATH ) ) || ( fieldName . equals ( ComputeResourceFileSystemConstants . FILE_SYSTEM ) ) ) { generator . setParameter ( fieldName , value ) ; q = generator . selectQuery ( em ) ; List < ? > results = q . getResultList ( ) ; for ( Object result : results ) { ComputeResourceFileSystem computeResourceFileSystem = ( ComputeResourceFileSystem ) result ; ComputeResourceFileSystemResource computeResourceFileSystemResource = ( ComputeResourceFileSystemResource ) AppCatalogJPAUtils . getResource ( AppCatalogResourceType . COMPUTE_RESOURCE_FILE_SYSTEM , computeResourceFileSystem ) ; computeResourceFileSystemResourceIDs . add ( computeResourceFileSystemResource . getComputeResourceId ( ) ) ; } } else { em . getTransaction ( ) . commit ( ) ; if ( em . isOpen ( ) ) { if ( em . getTransaction ( ) . isActive ( ) ) { em . getTransaction ( ) . rollback ( ) ; } em . close ( ) ; } logger . error ( ""Unsupported field name for Compute Resource File System Resource."" , new IllegalArgumentException ( ) ) ; throw new IllegalArgumentException ( ""Unsupported field name for Compute Resource File System Resource."" ) ; } em . getTransaction ( ) . commit ( ) ; if ( em . isOpen ( ) ) { if ( em . getTransaction ( ) . isActive ( ) ) { em . getTransaction ( ) . rollback ( ) ; } em . close ( ) ; } } catch ( ApplicationSettingsException e ) { logger . error ( e . getMessage ( ) , e ) ; throw new AppCatalogException ( e ) ; } finally { if ( em != null && em . isOpen ( ) ) { if ( em . getTransaction ( ) . isActive ( ) ) { em . getTransaction ( ) . rollback ( ) ; } em . close ( ) ; } } return computeResourceFileSystemResourceIDs ; } @ Override public void save ( ) throws AppCatalogException { EntityManager em = null ; try { em = AppCatalogJPAUtils . getEntityManager ( ) ; ComputeResourceFileSystem existingComputeResourceFileSystem = em . find ( ComputeResourceFileSystem . class , new ComputeResourceFileSystem_PK ( computeResourceId , fileSystem ) ) ; if ( em . isOpen ( ) ) { if ( em . getTransaction ( ) . isActive ( ) ) { em . getTransaction ( ) . rollback ( ) ; } em . close ( ) ; } ComputeResourceFileSystem computeResourceFileSystem ; em = AppCatalogJPAUtils . getEntityManager ( ) ; em . getTransaction ( ) . begin ( ) ; if ( existingComputeResourceFileSystem == null ) { computeResourceFileSystem = new ComputeResourceFileSystem ( ) ; } else { computeResourceFileSystem = existingComputeResourceFileSystem ; } computeResourceFileSystem . setComputeResourceId ( getComputeResourceId ( ) ) ; ComputeResource computeResource = em . find ( ComputeResource . class , getComputeResourceId ( ) ) ; computeResourceFileSystem . setComputeResource ( computeResource ) ; computeResourceFileSystem . setPath ( getPath ( ) ) ; computeResourceFileSystem . setFileSystem ( getFileSystem ( ) ) ; if ( existingComputeResourceFileSystem == null ) { em . persist ( computeResourceFileSystem ) ; } else { em . merge ( computeResourceFileSystem ) ; } em . getTransaction ( ) . commit ( ) ; if ( em . isOpen ( ) ) { if ( em . getTransaction ( ) . isActive ( ) ) { em . getTransaction ( ) . rollback ( ) ; } em . close ( ) ; } } catch ( Exception e ) { logger . error ( e . getMessage ( ) , e ) ; throw new AppCatalogException ( e ) ; } finally { if ( em != null && em . isOpen ( ) ) { if ( em . getTransaction ( ) . isActive ( ) ) { em . getTransaction ( ) . rollback ( ) ; } em . close ( ) ; } } } @ Override public boolean isExists ( Object identifier ) throws AppCatalogException { HashMap < String , String > ids ; if ( identifier instanceof Map ) { ids = ( HashMap < String , String > ) identifier ; } else { logger . error ( ""Identifier should be a map with the field name and it's value"" ) ; throw new AppCatalogException ( ""Identifier should be a map with the field name and it's value"" ) ; } EntityManager em = null ; try { em = AppCatalogJPAUtils . getEntityManager ( ) ; ComputeResourceFileSystem computeResourceFileSystem = em . find ( ComputeResourceFileSystem . class , new ComputeResourceFileSystem_PK ( ids . get ( ComputeResourceFileSystemConstants . COMPUTE_RESOURCE_ID ) , ids . get ( ComputeResourceFileSystemConstants . FILE_SYSTEM ) ) ) ; if ( em . isOpen ( ) ) { if ( em . getTransaction ( ) . isActive ( ) ) { em . getTransaction ( ) . rollback ( ) ; } em . close ( ) ; } return computeResourceFileSystem != null ; } catch ( ApplicationSettingsException e ) { logger . error ( e . getMessage ( ) , e ) ; throw new AppCatalogException ( e ) ; } finally { if ( em != null && em . isOpen ( ) ) { if ( em . getTransaction ( ) . isActive ( ) ) { em . getTransaction ( ) . rollback ( ) ; } em . close ( ) ; } } } public String getComputeResourceId ( ) { return computeResourceId ; } public ComputeResourceResource getComputeHostResource ( ) { return computeHostResource ; } public String getPath ( ) { return path ; } public String getFileSystem ( ) { return fileSystem ; } public void setComputeResourceId ( String computeResourceId ) { this . computeResourceId = computeResourceId ; } public void setComputeHostResource ( ComputeResourceResource computeHostResource ) { this . computeHostResource = computeHostResource ; } public void setPath ( String path ) { this . path = path ; } public void setFileSystem ( String fileSystem ) { this . fileSystem = fileSystem ; } }",Smelly
"class PropertyDefinitionTemplateImpl extends AbstractItemDefinitionTemplate implements PropertyDefinitionTemplate { private int type ; private String [ ] constraints ; private Value [ ] defaultValues ; private boolean multiple ; private boolean fullTextSearchable ; private boolean queryOrderable ; private String [ ] queryOperators ; PropertyDefinitionTemplateImpl ( NamePathResolver resolver ) { super ( resolver ) ; type = PropertyType . STRING ; fullTextSearchable = true ; queryOrderable = true ; queryOperators = Operator . getAllQueryOperators ( ) ; } PropertyDefinitionTemplateImpl ( PropertyDefinition def , NamePathResolver resolver ) throws ConstraintViolationException { super ( def , resolver ) ; type = def . getRequiredType ( ) ; defaultValues = def . getDefaultValues ( ) ; multiple = def . isMultiple ( ) ; fullTextSearchable = def . isFullTextSearchable ( ) ; queryOrderable = def . isQueryOrderable ( ) ; queryOperators = def . getAvailableQueryOperators ( ) ; setValueConstraints ( def . getValueConstraints ( ) ) ; } public void setRequiredType ( int type ) { PropertyType . nameFromValue ( type ) ; this . type = type ; } public void setValueConstraints ( String [ ] constraints ) { this . constraints = constraints ; } public void setDefaultValues ( Value [ ] defaultValues ) { this . defaultValues = defaultValues ; } public void setMultiple ( boolean multiple ) { this . multiple = multiple ; } public void setAvailableQueryOperators ( String [ ] operators ) { queryOperators = operators ; } public void setFullTextSearchable ( boolean searchable ) { fullTextSearchable = searchable ; } public void setQueryOrderable ( boolean orderable ) { queryOrderable = orderable ; } public int getRequiredType ( ) { return type ; } public String [ ] getValueConstraints ( ) { return constraints ; } public Value [ ] getDefaultValues ( ) { return defaultValues ; } public boolean isMultiple ( ) { return multiple ; } public String [ ] getAvailableQueryOperators ( ) { return queryOperators ; } public boolean isFullTextSearchable ( ) { return fullTextSearchable ; } public boolean isQueryOrderable ( ) { return queryOrderable ; } }",Smelly
"public class IrcProjectNotifierEditAction extends AbstractProjectNotifierEditAction { private String host ; private int port = 6667 ; private String channel ; private String nick ; private String alternateNick ; private String username ; private String fullName ; private String password ; private boolean ssl = false ; protected void initConfiguration ( Map < String , String > configuration ) { host = configuration . get ( ""host"" ) ; if ( configuration . get ( ""port"" ) != null ) { port = Integer . parseInt ( configuration . get ( ""port"" ) ) ; } channel = configuration . get ( ""channel"" ) ; nick = configuration . get ( ""nick"" ) ; alternateNick = configuration . get ( ""alternateNick"" ) ; username = configuration . get ( ""username"" ) ; fullName = configuration . get ( ""fullName"" ) ; password = configuration . get ( ""password"" ) ; if ( configuration . get ( ""ssl"" ) != null ) { ssl = Boolean . parseBoolean ( configuration . get ( ""ssl"" ) ) ; } } protected void setNotifierConfiguration ( ProjectNotifier notifier ) { HashMap < String , String > configuration = new HashMap < String , String > ( ) ; configuration . put ( ""host"" , host ) ; configuration . put ( ""port"" , String . valueOf ( port ) ) ; configuration . put ( ""channel"" , channel ) ; configuration . put ( ""nick"" , nick ) ; configuration . put ( ""alternateNick"" , alternateNick ) ; configuration . put ( ""username"" , username ) ; configuration . put ( ""fullName"" , fullName ) ; configuration . put ( ""password"" , password ) ; configuration . put ( ""ssl"" , String . valueOf ( ssl ) ) ; notifier . setConfiguration ( configuration ) ; } public String getHost ( ) { return host ; } public void setHost ( String host ) { this . host = host ; } public int getPort ( ) { return port ; } public void setPort ( int port ) { this . port = port ; } public String getChannel ( ) { return channel ; } public void setChannel ( String channel ) { this . channel = channel ; } public String getNick ( ) { return nick ; } public void setNick ( String nick ) { this . nick = nick ; } public String getAlternateNick ( ) { return alternateNick ; } public void setAlternateNick ( String alternateNick ) { this . alternateNick = alternateNick ; } public String getUsername ( ) { return username ; } public void setUsername ( String username ) { this . username = username ; } public String getFullName ( ) { return fullName ; } public void setFullName ( String fullName ) { this . fullName = fullName ; } public String getPassword ( ) { return password ; } public void setPassword ( String password ) { this . password = password ; } public boolean isSsl ( ) { return ssl ; } public void setSsl ( boolean ssl ) { this . ssl = ssl ; } }",Smelly
"public class IdlField extends IdlDefnImplBase { protected static final Logger LOG = LogUtils . getL7dLogger ( IdlField . class ) ; private IdlType type ; protected IdlField ( IdlScopeBase parent , String name , IdlType idlType ) { super ( parent , name ) ; this . type = idlType ; } public static IdlField create ( IdlScopeBase parent , String name , IdlType type ) { return new IdlField ( parent , name , type ) ; } IdlType type ( ) { return this . type ; } public void write ( PrintWriter pw ) { if ( ! type . isEmptyDef ( ) ) { pw . print ( indent ( ) + type . fullName ( definedIn ( ) . scopeName ( ) ) + "" "" ) ; pw . print ( localName ( ) ) ; pw . println ( "";"" ) ; } else { LOG . log ( Level . WARNING , ""Ignoring Field "" + localName ( ) + "" with Empty Type."" ) ; } } public boolean isEmptyDef ( ) { return type . isEmptyDef ( ) ; } public IdlScopeBase getCircularScope ( IdlScopeBase startScope , List < Object > doneDefn ) { return type . getCircularScope ( startScope , doneDefn ) ; } }",No
 public static class Doop extends CssClassUiEvent < Object > { private static final long serialVersionUID = 1L ; ,No
"@ NoJSR250Annotations public class ClientProxyFactoryBean extends AbstractBasicInterceptorProvider { protected boolean configured ; private ClientFactoryBean clientFactoryBean ; private String username ; private String password ; private Map < String , Object > properties ; private Bus bus ; private List < Feature > features = new ArrayList < Feature > ( ) ; private DataBinding dataBinding ; public ClientProxyFactoryBean ( ) { this ( new ClientFactoryBean ( ) ) ; } public ClientProxyFactoryBean ( ClientFactoryBean fact ) { super ( ) ; this . clientFactoryBean = fact ; } public void initFeatures ( ) { this . clientFactoryBean . setFeatures ( features ) ; this . getServiceFactory ( ) . setFeatures ( features ) ; } public < ProxyServiceType > ProxyServiceType create ( Class < ProxyServiceType > serviceClass ) { setServiceClass ( serviceClass ) ; return serviceClass . cast ( create ( ) ) ; } private void configureObject ( ) { if ( configured ) { return ; } if ( bus == null ) { bus = BusFactory . getThreadDefaultBus ( ) ; } Configurer configurer = bus . getExtension ( Configurer . class ) ; String name = getConfiguredName ( ) ; if ( null != configurer && name != null ) { configurer . configureBean ( name , this ) ; } configured = true ; } protected String getConfiguredName ( ) { QName name = getEndpointName ( ) ; if ( name == null ) { return null ; } return name . toString ( ) + "".client.proxyFactory"" ; } public synchronized Object create ( ) { ClassLoaderHolder orig = null ; try { if ( getBus ( ) != null ) { ClassLoader loader = getBus ( ) . getExtension ( ClassLoader . class ) ; if ( loader != null ) { orig = ClassLoaderUtils . setThreadContextClassloader ( loader ) ; } } configureObject ( ) ; if ( properties == null ) { properties = new HashMap < String , Object > ( ) ; } if ( username != null ) { AuthorizationPolicy authPolicy = new AuthorizationPolicy ( ) ; authPolicy . setUserName ( username ) ; authPolicy . setPassword ( password ) ; properties . put ( AuthorizationPolicy . class . getName ( ) , authPolicy ) ; } initFeatures ( ) ; clientFactoryBean . setProperties ( properties ) ; if ( bus != null ) { clientFactoryBean . setBus ( bus ) ; } if ( dataBinding != null ) { clientFactoryBean . setDataBinding ( dataBinding ) ; } Client c = clientFactoryBean . create ( ) ; if ( getInInterceptors ( ) != null ) { c . getInInterceptors ( ) . addAll ( getInInterceptors ( ) ) ; } if ( getOutInterceptors ( ) != null ) { c . getOutInterceptors ( ) . addAll ( getOutInterceptors ( ) ) ; } if ( getInFaultInterceptors ( ) != null ) { c . getInFaultInterceptors ( ) . addAll ( getInFaultInterceptors ( ) ) ; } if ( getOutFaultInterceptors ( ) != null ) { c . getOutFaultInterceptors ( ) . addAll ( getOutFaultInterceptors ( ) ) ; } ClientProxy handler = clientClientProxy ( c ) ; Class < ? > classes [ ] = getImplementingClasses ( ) ; Object obj = Proxy . newProxyInstance ( clientFactoryBean . getServiceClass ( ) . getClassLoader ( ) , classes , handler ) ; this . getServiceFactory ( ) . sendEvent ( FactoryBeanListener . Event . PROXY_CREATED , classes , handler , obj ) ; return obj ; } finally { if ( orig != null ) { orig . reset ( ) ; } } } protected Class < ? > [ ] getImplementingClasses ( ) { Class < ? > cls = clientFactoryBean . getServiceClass ( ) ; try { if ( cls . getMethod ( ""close"" ) != null ) { return new Class [ ] { cls } ; } } catch ( Exception e ) { } return new Class [ ] { cls , Closeable . class } ; } protected ClientProxy clientClientProxy ( Client c ) { return new ClientProxy ( c ) ; } public ClientFactoryBean getClientFactoryBean ( ) { return clientFactoryBean ; } public void setClientFactoryBean ( ClientFactoryBean clientFactoryBean ) { this . clientFactoryBean = clientFactoryBean ; } public String getPassword ( ) { return password ; } public void setPassword ( String password ) { this . password = password ; } public Class < ? > getServiceClass ( ) { return clientFactoryBean . getServiceClass ( ) ; } public void setServiceClass ( Class < ? > serviceClass ) { clientFactoryBean . setServiceClass ( serviceClass ) ; } public String getUsername ( ) { return username ; } public void setUsername ( String username ) { this . username = username ; } public String getWsdlLocation ( ) { return getWsdlURL ( ) ; } public void setWsdlLocation ( String wsdlURL ) { setWsdlURL ( wsdlURL ) ; } public String getWsdlURL ( ) { return clientFactoryBean . getServiceFactory ( ) . getWsdlURL ( ) ; } public void setWsdlURL ( String wsdlURL ) { clientFactoryBean . getServiceFactory ( ) . setWsdlURL ( wsdlURL ) ; } public QName getEndpointName ( ) { QName qn = clientFactoryBean . getEndpointName ( ) ; if ( qn == null ) { qn = clientFactoryBean . getServiceFactory ( ) . getEndpointName ( false ) ; } return qn ; } public void setEndpointName ( QName endpointName ) { clientFactoryBean . setEndpointName ( endpointName ) ; } public QName getServiceName ( ) { return getServiceFactory ( ) . getServiceQName ( ) ; } public void setServiceName ( QName serviceName ) { getServiceFactory ( ) . setServiceName ( serviceName ) ; } public String getAddress ( ) { return clientFactoryBean . getAddress ( ) ; } public void setAddress ( String add ) { clientFactoryBean . setAddress ( add ) ; } public ConduitSelector getConduitSelector ( ) { return clientFactoryBean . getConduitSelector ( ) ; } public void setConduitSelector ( ConduitSelector selector ) { clientFactoryBean . setConduitSelector ( selector ) ; } public void setBindingId ( String bind ) { clientFactoryBean . setBindingId ( bind ) ; } public String getBindingId ( ) { return clientFactoryBean . getBindingId ( ) ; } public void setTransportId ( String transportId ) { clientFactoryBean . setTransportId ( transportId ) ; } public String getTransportId ( ) { return clientFactoryBean . getTransportId ( ) ; } public ReflectionServiceFactoryBean getServiceFactory ( ) { return clientFactoryBean . getServiceFactory ( ) ; } public void setServiceFactory ( ReflectionServiceFactoryBean sf ) { clientFactoryBean . setServiceFactory ( sf ) ; } public Bus getBus ( ) { return bus ; } public void setBus ( Bus bus ) { this . bus = bus ; clientFactoryBean . setBus ( bus ) ; } public Map < String , Object > getProperties ( ) { return properties ; } public void setProperties ( Map < String , Object > properties ) { this . properties = properties ; } public List < Feature > getFeatures ( ) { return features ; } public void setFeatures ( List < ? extends Feature > f ) { this . features = CastUtils . cast ( f ) ; } public DataBinding getDataBinding ( ) { return dataBinding ; } public void setDataBinding ( DataBinding dataBinding ) { this . dataBinding = dataBinding ; } public void setBindingConfig ( BindingConfiguration config ) { getClientFactoryBean ( ) . setBindingConfig ( config ) ; } public BindingConfiguration getBindingConfig ( ) { return getClientFactoryBean ( ) . getBindingConfig ( ) ; } }",Smelly
"public class VariableAssignmentExpression extends AbstractGroovyExpression { private String type = null ; private String name ; private GroovyExpression value ; public VariableAssignmentExpression ( String type , String name , GroovyExpression v ) { this . type = type ; this . name = name ; this . value = v ; } public VariableAssignmentExpression ( String name , GroovyExpression v ) { this ( null , name , v ) ; } @ Override public void generateGroovy ( GroovyGenerationContext context ) { if ( type == null ) { context . append ( ""def "" ) ; } else { context . append ( type ) ; context . append ( "" "" ) ; } context . append ( name ) ; context . append ( ""="" ) ; value . generateGroovy ( context ) ; } @ Override public List < GroovyExpression > getChildren ( ) { return Collections . singletonList ( value ) ; } @ Override public GroovyExpression copy ( List < GroovyExpression > newChildren ) { assert newChildren . size ( ) == 1 ; return new VariableAssignmentExpression ( name , newChildren . get ( 0 ) ) ; } }",No
"public class TestInitializeEagerly extends SingleEMFTestCase { public void setUp ( ) throws Exception { super . setUp ( RuntimeTest1 . class , ""openjpa.InitializeEagerly"" , ""true"" , ""openjpa.BrokerFactory"" , DummyBrokerFactory . class . getName ( ) ) ; } public void test ( ) { assertNotNull ( emf ) ; } }",No
public class DeleteUserCommand extends DropUserCommand { },No
"public class MemDatasetMetadata extends DatasetMetadata { private Version arq ; private Version jdbc ; public MemDatasetMetadata ( DatasetConnection connection ) throws SQLException { super ( connection ) ; arq = new Version ( ) ; arq . addClass ( ARQ . class ) ; jdbc = new Version ( ) ; jdbc . addClass ( JenaJDBC . class ) ; } @ Override public int getDatabaseMajorVersion ( ) { return 2 ; } @ Override public int getDatabaseMinorVersion ( ) { return 10 ; } @ Override public String getDatabaseProductName ( ) { return ""Apache Jena - ARQ - In-Memory"" ; } @ Override public String getDatabaseProductVersion ( ) { return arq . toString ( ) ; } @ Override public int getDriverMajorVersion ( ) { return 0 ; } @ Override public int getDriverMinorVersion ( ) { return 1 ; } @ Override public String getDriverName ( ) { return ""Apache Jena - JDBC - In-Memory Driver"" ; } @ Override public String getDriverVersion ( ) { return jdbc . toString ( ) ; } @ Override public String getURL ( ) { return ""http://jena.apache.org"" ; } @ Override public boolean usesLocalFilePerTable ( ) { return false ; } @ Override public boolean usesLocalFiles ( ) { return false ; } }",Smelly
"@ Entity @ Table ( name = ""EXPERIMENT"" ) public class Experiment { private final static Logger logger = LoggerFactory . getLogger ( Experiment . class ) ; private String experimentId ; private String projectId ; private String gatewayId ; private String experimentType ; private String userName ; private String experimentName ; private Timestamp creationTime ; private String description ; private String executionId ; private String gatewayExecutionId ; private String gatewayInstanceId ; private Boolean enableEmailNotification ; private String emailAddresses ; private Users user ; private Project project ; private Collection < ExperimentError > experimentErrors ; private Collection < ExperimentInput > experimentInputs ; private Collection < ExperimentOutput > experimentOutputs ; private Collection < ExperimentStatus > experimentStatuses ; private Collection < Process > processes ; private UserConfigurationData userConfigurationData ; @ Id @ Column ( name = ""EXPERIMENT_ID"" ) public String getExperimentId ( ) { return experimentId ; } public void setExperimentId ( String experimentId ) { this . experimentId = experimentId ; } @ Column ( name = ""GATEWAY_ID"" ) public String getGatewayId ( ) { return gatewayId ; } public void setGatewayId ( String gatewayId ) { this . gatewayId = gatewayId ; } @ Column ( name = ""PROJECT_ID"" ) public String getProjectId ( ) { return projectId ; } public void setProjectId ( String projectId ) { this . projectId = projectId ; } @ Column ( name = ""EXPERIMENT_TYPE"" ) public String getExperimentType ( ) { return experimentType ; } public void setExperimentType ( String experimentType ) { this . experimentType = experimentType ; } @ Column ( name = ""USER_NAME"" ) public String getUserName ( ) { return userName ; } public void setUserName ( String userName ) { this . userName = userName ; } @ Column ( name = ""EXPERIMENT_NAME"" ) public String getExperimentName ( ) { return experimentName ; } public void setExperimentName ( String experimentName ) { this . experimentName = experimentName ; } @ Column ( name = ""CREATION_TIME"" ) public Timestamp getCreationTime ( ) { return creationTime ; } public void setCreationTime ( Timestamp creationTime ) { this . creationTime = creationTime ; } @ Column ( name = ""DESCRIPTION"" ) public String getDescription ( ) { return description ; } public void setDescription ( String description ) { this . description = description ; } @ Column ( name = ""EXECUTION_ID"" ) public String getExecutionId ( ) { return executionId ; } public void setExecutionId ( String executionId ) { this . executionId = executionId ; } @ Column ( name = ""GATEWAY_EXECUTION_ID"" ) public String getGatewayExecutionId ( ) { return gatewayExecutionId ; } public void setGatewayExecutionId ( String gatewayExecutionId ) { this . gatewayExecutionId = gatewayExecutionId ; } @ Column ( name = ""GATEWAY_INSTANCE_ID"" ) public String getGatewayInstanceId ( ) { return gatewayInstanceId ; } public void setGatewayInstanceId ( String gatewayInstanceId ) { this . gatewayInstanceId = gatewayInstanceId ; } @ Column ( name = ""ENABLE_EMAIL_NOTIFICATION"" ) public Boolean getEnableEmailNotification ( ) { return enableEmailNotification ; } public void setEnableEmailNotification ( Boolean enableEmailNotification ) { this . enableEmailNotification = enableEmailNotification ; } @ Lob @ Column ( name = ""EMAIL_ADDRESSES"" ) public String getEmailAddresses ( ) { return emailAddresses ; } public void setEmailAddresses ( String emailAddresses ) { this . emailAddresses = emailAddresses ; } @ ManyToOne @ JoinColumn ( name = ""PROJECT_ID"" , referencedColumnName = ""PROJECT_ID"" , nullable = false ) public Project getProject ( ) { return project ; } public void setProject ( Project projectByProjectId ) { this . project = projectByProjectId ; } @ OneToMany ( mappedBy = ""experiment"" ) public Collection < ExperimentError > getExperimentErrors ( ) { return experimentErrors ; } public void setExperimentErrors ( Collection < ExperimentError > experimentErrorsByExperimentId ) { this . experimentErrors = experimentErrorsByExperimentId ; } @ OneToMany ( mappedBy = ""experiment"" ) public Collection < ExperimentInput > getExperimentInputs ( ) { return experimentInputs ; } public void setExperimentInputs ( Collection < ExperimentInput > experimentInputsByExperimentId ) { this . experimentInputs = experimentInputsByExperimentId ; } @ OneToMany ( mappedBy = ""experiment"" ) public Collection < ExperimentOutput > getExperimentOutputs ( ) { return experimentOutputs ; } public void setExperimentOutputs ( Collection < ExperimentOutput > experimentOutputsByExperimentId ) { this . experimentOutputs = experimentOutputsByExperimentId ; } @ OneToMany ( mappedBy = ""experiment"" ) public Collection < ExperimentStatus > getExperimentStatuses ( ) { return experimentStatuses ; } public void setExperimentStatuses ( Collection < ExperimentStatus > experimentStatusesByExperimentId ) { this . experimentStatuses = experimentStatusesByExperimentId ; } @ OneToMany ( mappedBy = ""experiment"" ) public Collection < Process > getProcesses ( ) { return processes ; } public void setProcesses ( Collection < Process > processesesByExperimentId ) { this . processes = processesesByExperimentId ; } @ OneToOne ( mappedBy = ""experiment"" ) public UserConfigurationData getUserConfigurationData ( ) { return userConfigurationData ; } public void setUserConfigurationData ( UserConfigurationData userConfigurationDataByExperimentId ) { this . userConfigurationData = userConfigurationDataByExperimentId ; } }",Smelly
"public class DocumentumObjectImpl extends UnicastRemoteObject implements IDocumentumObject { public static final String _rcsid = ""@(#)$Id: DocumentumObjectImpl.java 988245 2010-08-23 18:39:35Z kwright $"" ; protected IDfPersistentObject object ; protected IDfSession session ; public DocumentumObjectImpl ( IDfSession session , IDfPersistentObject object ) throws RemoteException { super ( 0 , new RMILocalClientSocketFactory ( ) , new RMILocalSocketFactory ( ) ) ; this . session = session ; this . object = object ; } public void release ( ) throws RemoteException { object = null ; session = null ; } public boolean exists ( ) throws DocumentumException , RemoteException { return ( object != null ) ; } public String getObjectId ( ) throws DocumentumException , RemoteException { try { return object . getObjectId ( ) . toString ( ) ; } catch ( DfException e ) { throw new DocumentumException ( ""Documentum exception: "" + e . getMessage ( ) ) ; } } public String getObjectName ( ) throws DocumentumException , RemoteException { try { return ( ( IDfSysObject ) object ) . getObjectName ( ) ; } catch ( DfException e ) { throw new DocumentumException ( ""Documentum exception: "" + e . getMessage ( ) ) ; } } public String getContentType ( ) throws DocumentumException , RemoteException { try { return ( ( IDfSysObject ) object ) . getContentType ( ) ; } catch ( DfException e ) { throw new DocumentumException ( ""Documentum exception: "" + e . getMessage ( ) ) ; } } public String getACLDomain ( ) throws DocumentumException , RemoteException { try { return ( ( IDfSysObject ) object ) . getACLDomain ( ) ; } catch ( DfException e ) { throw new DocumentumException ( ""Documentum exception: "" + e . getMessage ( ) ) ; } } public String getACLName ( ) throws DocumentumException , RemoteException { try { return ( ( IDfSysObject ) object ) . getACLName ( ) ; } catch ( DfException e ) { throw new DocumentumException ( ""Documentum exception: "" + e . getMessage ( ) ) ; } } public boolean isDeleted ( ) throws DocumentumException , RemoteException { try { return object . isDeleted ( ) ; } catch ( DfException e ) { throw new DocumentumException ( ""Documentum exception: "" + e . getMessage ( ) ) ; } } public boolean isHidden ( ) throws DocumentumException , RemoteException { try { return ( ( IDfSysObject ) object ) . isHidden ( ) ; } catch ( DfException e ) { throw new DocumentumException ( ""Documentum exception: "" + e . getMessage ( ) ) ; } } public int getPermit ( ) throws DocumentumException , RemoteException { try { return ( ( IDfSysObject ) object ) . getPermit ( ) ; } catch ( DfException e ) { throw new DocumentumException ( ""Documentum exception: "" + e . getMessage ( ) ) ; } } public long getContentSize ( ) throws DocumentumException , RemoteException { try { return ( ( IDfSysObject ) object ) . getContentSize ( ) ; } catch ( DfException e ) { throw new DocumentumException ( ""Documentum exception: "" + e . getMessage ( ) ) ; } } public int getPageCount ( ) throws DocumentumException , RemoteException { try { return ( ( IDfSysObject ) object ) . getPageCount ( ) ; } catch ( DfException e ) { throw new DocumentumException ( ""Documentum exception: "" + e . getMessage ( ) ) ; } } public String getVersionLabel ( ) throws DocumentumException , RemoteException { try { String versionLabel ; IDfVersionPolicy policy = ( ( IDfSysObject ) object ) . getVersionPolicy ( ) ; if ( policy != null ) { versionLabel = policy . getSameLabel ( ) ; if ( versionLabel == null ) versionLabel = """" ; } else versionLabel = """" ; return versionLabel ; } catch ( DfException e ) { throw new DocumentumException ( ""Documentum exception: "" + e . getMessage ( ) ) ; } } public String getTypeName ( ) throws DocumentumException , RemoteException { try { return ( ( IDfSysObject ) object ) . getTypeName ( ) ; } catch ( DfException e ) { throw new DocumentumException ( ""Documentum exception: "" + e . getMessage ( ) ) ; } } public String getVStamp ( ) throws DocumentumException , RemoteException { try { return object . getString ( ""i_vstamp"" ) ; } catch ( DfException e ) { throw new DocumentumException ( ""Documentum exception: "" + e . getMessage ( ) ) ; } } public String [ ] getFolderPaths ( Map pathMapCache ) throws DocumentumException , RemoteException { try { int count = ( ( IDfSysObject ) object ) . getFolderIdCount ( ) ; ArrayList list = new ArrayList ( ) ; int i = 0 ; while ( i < count ) { IDfId folderID = ( ( IDfSysObject ) object ) . getFolderId ( i ++ ) ; String folderIDString = folderID . getId ( ) ; String [ ] folderPath = ( String [ ] ) pathMapCache . get ( folderIDString ) ; if ( folderPath == null ) { IDfFolder folder = ( IDfFolder ) session . getObject ( folderID ) ; if ( folder == null ) folderPath = new String [ 0 ] ; else { int folderPathCount = folder . getFolderPathCount ( ) ; folderPath = new String [ folderPathCount ] ; int j = 0 ; while ( j < folderPathCount ) { folderPath [ j ] = folder . getFolderPath ( j ) ; j ++ ; } } pathMapCache . put ( folderIDString , folderPath ) ; } int j = 0 ; while ( j < folderPath . length ) { list . add ( folderPath [ j ++ ] ) ; } } String [ ] rval = new String [ list . size ( ) ] ; i = 0 ; while ( i < rval . length ) { rval [ i ] = ( String ) list . get ( i ) ; i ++ ; } return rval ; } catch ( DfAuthenticationException ex ) { throw new DocumentumException ( ""Bad credentials: "" + ex . getMessage ( ) , DocumentumException . TYPE_BADCREDENTIALS ) ; } catch ( DfIdentityException ex ) { throw new DocumentumException ( ""Bad docbase name: "" + ex . getMessage ( ) , DocumentumException . TYPE_BADCONNECTIONPARAMS ) ; } catch ( DfDocbaseUnreachableException e ) { throw new DocumentumException ( ""Docbase unreachable: "" + e . getMessage ( ) , DocumentumException . TYPE_SERVICEINTERRUPTION ) ; } catch ( DfIOException e ) { throw new DocumentumException ( ""Docbase io exception: "" + e . getMessage ( ) , DocumentumException . TYPE_SERVICEINTERRUPTION ) ; } catch ( DfException e ) { throw new DocumentumException ( ""Documentum error: "" + e . getMessage ( ) ) ; } } public String getFile ( String path ) throws DocumentumException , RemoteException { try { return ( ( IDfSysObject ) object ) . getFile ( path ) ; } catch ( DfAuthenticationException ex ) { throw new DocumentumException ( ""Bad credentials: "" + ex . getMessage ( ) , DocumentumException . TYPE_BADCREDENTIALS ) ; } catch ( DfIdentityException ex ) { throw new DocumentumException ( ""Bad docbase name: "" + ex . getMessage ( ) , DocumentumException . TYPE_BADCONNECTIONPARAMS ) ; } catch ( DfDocbaseUnreachableException e ) { throw new DocumentumException ( ""Docbase unreachable: "" + e . getMessage ( ) , DocumentumException . TYPE_SERVICEINTERRUPTION ) ; } catch ( DfIOException e ) { throw new DocumentumException ( ""Docbase io exception: "" + e . getMessage ( ) , DocumentumException . TYPE_SERVICEINTERRUPTION ) ; } catch ( DfException dfe ) { String errorMessage = dfe . getMessage ( ) ; if ( errorMessage . indexOf ( ""[DM_CONTENT_E_CANT_START_PULL]"" ) == - 1 ) throw new DocumentumException ( dfe . getMessage ( ) , DocumentumException . TYPE_SERVICEINTERRUPTION ) ; throw new DocumentumException ( dfe . getMessage ( ) , DocumentumException . TYPE_NOTALLOWED ) ; } } public String [ ] getAttributeValues ( String attribute ) throws DocumentumException , RemoteException { try { int valueCount = object . getValueCount ( attribute ) ; String [ ] values = new String [ valueCount ] ; int y = 0 ; while ( y < valueCount ) { String value = object . getRepeatingString ( attribute , y ) ; values [ y ++ ] = value ; } return values ; } catch ( DfAuthenticationException ex ) { throw new DocumentumException ( ""Bad credentials: "" + ex . getMessage ( ) , DocumentumException . TYPE_BADCREDENTIALS ) ; } catch ( DfIdentityException ex ) { throw new DocumentumException ( ""Bad docbase name: "" + ex . getMessage ( ) , DocumentumException . TYPE_BADCONNECTIONPARAMS ) ; } catch ( DfDocbaseUnreachableException e ) { throw new DocumentumException ( ""Docbase unreachable: "" + e . getMessage ( ) , DocumentumException . TYPE_SERVICEINTERRUPTION ) ; } catch ( DfIOException e ) { throw new DocumentumException ( ""Docbase io exception: "" + e . getMessage ( ) , DocumentumException . TYPE_SERVICEINTERRUPTION ) ; } catch ( DfException e ) { throw new DocumentumException ( ""Documentum error: "" + e . getMessage ( ) ) ; } } public int getUserState ( ) throws DocumentumException , RemoteException { try { return ( ( IDfUser ) object ) . getUserState ( ) ; } catch ( DfAuthenticationException ex ) { throw new DocumentumException ( ""Bad credentials: "" + ex . getMessage ( ) , DocumentumException . TYPE_BADCREDENTIALS ) ; } catch ( DfIdentityException ex ) { throw new DocumentumException ( ""Bad docbase name: "" + ex . getMessage ( ) , DocumentumException . TYPE_BADCONNECTIONPARAMS ) ; } catch ( DfDocbaseUnreachableException e ) { throw new DocumentumException ( ""Docbase unreachable: "" + e . getMessage ( ) , DocumentumException . TYPE_SERVICEINTERRUPTION ) ; } catch ( DfIOException e ) { throw new DocumentumException ( ""Docbase io exception: "" + e . getMessage ( ) , DocumentumException . TYPE_SERVICEINTERRUPTION ) ; } catch ( DfException e ) { throw new DocumentumException ( ""Documentum error: "" + e . getMessage ( ) ) ; } } public String getUserName ( ) throws DocumentumException , RemoteException { try { return ( ( IDfUser ) object ) . getUserName ( ) ; } catch ( DfAuthenticationException ex ) { throw new DocumentumException ( ""Bad credentials: "" + ex . getMessage ( ) , DocumentumException . TYPE_BADCREDENTIALS ) ; } catch ( DfIdentityException ex ) { throw new DocumentumException ( ""Bad docbase name: "" + ex . getMessage ( ) , DocumentumException . TYPE_BADCONNECTIONPARAMS ) ; } catch ( DfDocbaseUnreachableException e ) { throw new DocumentumException ( ""Docbase unreachable: "" + e . getMessage ( ) , DocumentumException . TYPE_SERVICEINTERRUPTION ) ; } catch ( DfIOException e ) { throw new DocumentumException ( ""Docbase io exception: "" + e . getMessage ( ) , DocumentumException . TYPE_SERVICEINTERRUPTION ) ; } catch ( DfException e ) { throw new DocumentumException ( ""Documentum error: "" + e . getMessage ( ) ) ; } } }",Smelly
"public class DigestInfo extends Asn1SequenceType { protected enum DigestInfoField implements EnumType { DIGEST_ALGORITHM , DIGEST ; @ Override public int getValue ( ) { return ordinal ( ) ; } @ Override public String getName ( ) { return name ( ) ; } } static Asn1FieldInfo [ ] fieldInfos = new Asn1FieldInfo [ ] { new Asn1FieldInfo ( DigestInfoField . DIGEST_ALGORITHM , AlgorithmIdentifier . class ) , new Asn1FieldInfo ( DigestInfoField . DIGEST , Asn1OctetString . class ) } ; public DigestInfo ( ) { super ( fieldInfos ) ; } public AlgorithmIdentifier getAlgorithmId ( ) { return getFieldAs ( DigestInfoField . DIGEST_ALGORITHM , AlgorithmIdentifier . class ) ; } public void setDigestAlgorithm ( AlgorithmIdentifier digestAlgorithm ) { setFieldAs ( DigestInfoField . DIGEST_ALGORITHM , digestAlgorithm ) ; } public byte [ ] getDigest ( ) { return getFieldAsOctets ( DigestInfoField . DIGEST ) ; } public void setDigest ( byte [ ] digest ) { setFieldAsOctets ( DigestInfoField . DIGEST , digest ) ; } }",Smelly
"public class EntityDataLoader { public static final String module = EntityDataLoader . class . getName ( ) ; public static String getPathsString ( String helperName ) { StringBuilder pathBuffer = new StringBuilder ( ) ; if ( UtilValidate . isNotEmpty ( helperName ) ) { Datasource datasourceInfo = EntityConfigUtil . getDatasource ( helperName ) ; for ( SqlLoadPath sqlLoadPath : datasourceInfo . getSqlLoadPathList ( ) ) { String prependEnv = sqlLoadPath . getPrependEnv ( ) ; pathBuffer . append ( pathBuffer . length ( ) == 0 ? """" : "";"" ) ; if ( UtilValidate . isNotEmpty ( prependEnv ) ) { pathBuffer . append ( System . getProperty ( prependEnv ) ) ; pathBuffer . append ( ""/"" ) ; } pathBuffer . append ( sqlLoadPath . getPath ( ) ) ; } } return pathBuffer . toString ( ) ; } public static List < URL > getUrlList ( String helperName ) { Datasource datasourceInfo = EntityConfigUtil . getDatasource ( helperName ) ; return getUrlList ( helperName , null , datasourceInfo . getReadDataList ( ) ) ; } public static List < URL > getUrlList ( String helperName , String componentName ) { Datasource datasourceInfo = EntityConfigUtil . getDatasource ( helperName ) ; return getUrlList ( helperName , componentName , datasourceInfo . getReadDataList ( ) ) ; } public static < E > List < URL > getUrlList ( String helperName , List < E > readerNames ) { return getUrlList ( helperName , null , readerNames ) ; } public static < E > List < URL > getUrlList ( String helperName , String componentName , List < E > readerNames ) { String paths = getPathsString ( helperName ) ; List < URL > urlList = new LinkedList < URL > ( ) ; if ( readerNames != null ) { for ( Object readerInfo : readerNames ) { String readerName = null ; if ( readerInfo instanceof String ) { readerName = ( String ) readerInfo ; } else if ( readerInfo instanceof ReadData ) { readerName = ( ( ReadData ) readerInfo ) . getReaderName ( ) ; } else if ( readerInfo instanceof Element ) { readerName = ( ( Element ) readerInfo ) . getAttribute ( ""reader-name"" ) ; } else { throw new IllegalArgumentException ( ""Reader name list does not contain String(s) or Element(s)"" ) ; } readerName = readerName . trim ( ) ; if ( ""tenant"" . equals ( readerName ) && ""N"" . equals ( UtilProperties . getPropertyValue ( ""general.properties"" , ""multitenant"" ) ) ) { continue ; } EntityDataReader entityDataReaderInfo = null ; try { entityDataReaderInfo = EntityConfigUtil . getEntityDataReader ( readerName ) ; if ( entityDataReaderInfo == null ) { Debug . logInfo ( ""Could not find entity-data-reader named: "" + readerName + "". Creating a new reader with this name. "" , module ) ; entityDataReaderInfo = new EntityDataReader ( readerName ) ; } } catch ( GenericEntityConfException e ) { Debug . logWarning ( e , ""Exception thrown while getting entity data reader config: "" , module ) ; } if ( entityDataReaderInfo != null ) { for ( Resource resourceElement : entityDataReaderInfo . getResourceList ( ) ) { ResourceHandler handler = new MainResourceHandler ( EntityConfigUtil . ENTITY_ENGINE_XML_FILENAME , resourceElement . getLoader ( ) , resourceElement . getLocation ( ) ) ; try { urlList . add ( handler . getURL ( ) ) ; } catch ( GenericConfigException e ) { String errorMsg = ""Could not get URL for Main ResourceHandler: "" + e . toString ( ) ; Debug . logWarning ( errorMsg , module ) ; } } for ( ComponentConfig . EntityResourceInfo componentResourceInfo : ComponentConfig . getAllEntityResourceInfos ( ""data"" , componentName ) ) { if ( readerName . equals ( componentResourceInfo . readerName ) ) { ResourceHandler handler = componentResourceInfo . createResourceHandler ( ) ; try { urlList . add ( handler . getURL ( ) ) ; } catch ( GenericConfigException e ) { String errorMsg = ""Could not get URL for Component ResourceHandler: "" + e . toString ( ) ; Debug . logWarning ( errorMsg , module ) ; } } } } else { String errorMsg = ""Could not find entity-data-reader named: "" + readerName ; Debug . logWarning ( errorMsg , module ) ; } } } else { String errorMsg = ""Could not find datasource named: "" + helperName ; Debug . logWarning ( errorMsg , module ) ; } if ( UtilValidate . isNotEmpty ( paths ) ) { StringTokenizer tokenizer = new StringTokenizer ( paths , "";"" ) ; while ( tokenizer . hasMoreTokens ( ) ) { String path = tokenizer . nextToken ( ) . toLowerCase ( ) ; File loadDir = new File ( path ) ; if ( loadDir . exists ( ) && loadDir . isDirectory ( ) ) { File [ ] files = loadDir . listFiles ( ) ; List < File > tempFileList = new LinkedList < File > ( ) ; for ( File file : files ) { if ( file . getName ( ) . toLowerCase ( ) . endsWith ( "".xml"" ) ) { tempFileList . add ( file ) ; } } Collections . sort ( tempFileList ) ; for ( File dataFile : tempFileList ) { if ( dataFile . exists ( ) ) { URL url = null ; try { url = dataFile . toURI ( ) . toURL ( ) ; urlList . add ( url ) ; } catch ( java . net . MalformedURLException e ) { String xmlError = ""Error loading XML file \"""" + dataFile . getAbsolutePath ( ) + ""\""; Error was: "" + e . getMessage ( ) ; Debug . logError ( xmlError , module ) ; } } else { String errorMsg = ""Could not find file: \"""" + dataFile . getAbsolutePath ( ) + ""\"""" ; Debug . logError ( errorMsg , module ) ; } } } } } return urlList ; } public static List < URL > getUrlByComponentList ( String helperName , List < String > components , List < String > readerNames ) { List < URL > urlList = new LinkedList < URL > ( ) ; for ( String readerName : readerNames ) { List < String > loadReaderNames = new LinkedList < String > ( ) ; loadReaderNames . add ( readerName ) ; for ( String component : components ) { urlList . addAll ( getUrlList ( helperName , component , loadReaderNames ) ) ; } } return urlList ; } public static List < URL > getUrlByComponentList ( String helperName , List < String > components ) { Datasource datasourceInfo = EntityConfigUtil . getDatasource ( helperName ) ; List < String > readerNames = new LinkedList < String > ( ) ; for ( ReadData readerInfo : datasourceInfo . getReadDataList ( ) ) { String readerName = readerInfo . getReaderName ( ) ; if ( ""tenant"" . equals ( readerName ) && ""N"" . equals ( UtilProperties . getPropertyValue ( ""general.properties"" , ""multitenant"" ) ) ) { continue ; } readerNames . add ( readerName ) ; } return getUrlByComponentList ( helperName , components , readerNames ) ; } public static int loadData ( URL dataUrl , String helperName , Delegator delegator , List < Object > errorMessages ) throws GenericEntityException { return loadData ( dataUrl , helperName , delegator , errorMessages , - 1 ) ; } public static int loadData ( URL dataUrl , String helperName , Delegator delegator , List < Object > errorMessages , int txTimeout ) throws GenericEntityException { return loadData ( dataUrl , helperName , delegator , errorMessages , txTimeout , false , false , false ) ; } public static int loadData ( URL dataUrl , String helperName , Delegator delegator , List < Object > errorMessages , int txTimeout , boolean dummyFks , boolean maintainTxs , boolean tryInsert ) throws GenericEntityException { int rowsChanged = 0 ; if ( dataUrl == null ) { String errMsg = ""Cannot load data, dataUrl was null"" ; errorMessages . add ( errMsg ) ; Debug . logError ( errMsg , module ) ; return 0 ; } Debug . logVerbose ( ""[install.loadData] Loading XML Resource: \"""" + dataUrl . toExternalForm ( ) + ""\"""" , module ) ; try { EntitySaxReader reader = null ; if ( txTimeout > 0 ) { reader = new EntitySaxReader ( delegator , txTimeout ) ; } else { reader = new EntitySaxReader ( delegator ) ; } reader . setCreateDummyFks ( dummyFks ) ; reader . setMaintainTxStamps ( maintainTxs ) ; rowsChanged += reader . parse ( dataUrl ) ; } catch ( Exception e ) { String xmlError = ""[install.loadData]: Error loading XML Resource \"""" + dataUrl . toExternalForm ( ) + ""\""; Error was: "" + e . getMessage ( ) ; errorMessages . add ( xmlError ) ; Debug . logError ( e , xmlError , module ) ; } return rowsChanged ; } public static int generateData ( Delegator delegator , List < Object > errorMessages ) throws GenericEntityException { int rowsChanged = 0 ; ModelReader reader = delegator . getModelReader ( ) ; for ( String entityName : reader . getEntityNames ( ) ) { ModelEntity entity = reader . getModelEntity ( entityName ) ; String baseName = entity . getPlainTableName ( ) ; if ( entity instanceof ModelViewEntity ) { baseName = ModelUtil . javaNameToDbName ( entity . getEntityName ( ) ) ; } if ( baseName != null ) { try { List < GenericValue > toBeStored = new LinkedList < GenericValue > ( ) ; toBeStored . add ( delegator . makeValue ( ""SecurityPermission"" , ""permissionId"" , baseName + ""_ADMIN"" , ""description"" , ""Permission to Administer a "" + entity . getEntityName ( ) + "" entity."" ) ) ; toBeStored . add ( delegator . makeValue ( ""SecurityGroupPermission"" , ""groupId"" , ""FULLADMIN"" , ""permissionId"" , baseName + ""_ADMIN"" ) ) ; rowsChanged += delegator . storeAll ( toBeStored ) ; } catch ( GenericEntityException e ) { errorMessages . add ( ""[install.generateData] ERROR: Failed Security Generation for entity \"""" + baseName + ""\"""" ) ; } } } return rowsChanged ; } }",No
"public class PanelGridTag extends UIComponentTag { private String bgcolor ; private String border ; private String cellpadding ; private String cellspacing ; private String columnClasses ; private String columns ; private String dir ; private String footerClass ; private String frame ; private String headerClass ; private String lang ; private String onclick ; private String ondblclick ; private String onkeydown ; private String onkeypress ; private String onkeyup ; private String onmousedown ; private String onmousemove ; private String onmouseout ; private String onmouseover ; private String onmouseup ; private String rowClasses ; private String rules ; private String style ; private String styleClass ; private String summary ; private String title ; private String width ; public void setBgcolor ( String bgcolor ) { this . bgcolor = bgcolor ; } public void setBorder ( String border ) { this . border = border ; } public void setCellpadding ( String cellpadding ) { this . cellpadding = cellpadding ; } public void setCellspacing ( String cellspacing ) { this . cellspacing = cellspacing ; } public void setColumnClasses ( String columnClasses ) { this . columnClasses = columnClasses ; } public void setColumns ( String columns ) { this . columns = columns ; } public void setDir ( String dir ) { this . dir = dir ; } public void setFooterClass ( String footerClass ) { this . footerClass = footerClass ; } public void setFrame ( String frame ) { this . frame = frame ; } public void setHeaderClass ( String headerClass ) { this . headerClass = headerClass ; } public void setLang ( String lang ) { this . lang = lang ; } public void setOnclick ( String onclick ) { this . onclick = onclick ; } public void setOndblclick ( String ondblclick ) { this . ondblclick = ondblclick ; } public void setOnkeydown ( String onkeydown ) { this . onkeydown = onkeydown ; } public void setOnkeypress ( String onkeypress ) { this . onkeypress = onkeypress ; } public void setOnkeyup ( String onkeyup ) { this . onkeyup = onkeyup ; } public void setOnmousedown ( String onmousedown ) { this . onmousedown = onmousedown ; } public void setOnmousemove ( String onmousemove ) { this . onmousemove = onmousemove ; } public void setOnmouseout ( String onmouseout ) { this . onmouseout = onmouseout ; } public void setOnmouseover ( String onmouseover ) { this . onmouseover = onmouseover ; } public void setOnmouseup ( String onmouseup ) { this . onmouseup = onmouseup ; } public void setRowClasses ( String rowClasses ) { this . rowClasses = rowClasses ; } public void setRules ( String rules ) { this . rules = rules ; } public void setStyle ( String style ) { this . style = style ; } public void setStyleClass ( String styleClass ) { this . styleClass = styleClass ; } public void setSummary ( String summary ) { this . summary = summary ; } public void setTitle ( String title ) { this . title = title ; } public void setWidth ( String width ) { this . width = width ; } public String getRendererType ( ) { return ""javax.faces.Grid"" ; } public String getComponentType ( ) { return ""javax.faces.HtmlPanelGrid"" ; } protected void setProperties ( UIComponent component ) { super . setProperties ( component ) ; if ( ! ( component instanceof UIPanel ) ) { throw new FacesException ( ""Tag <"" + getClass ( ) . getName ( ) + ""> expected UIPanel. "" + ""Got <"" + component . getClass ( ) . getName ( ) + "">"" ) ; } setProperty ( component , ""bgcolor"" , bgcolor ) ; setIntegerProperty ( component , ""border"" , border ) ; setProperty ( component , ""cellpadding"" , cellpadding ) ; setProperty ( component , ""cellspacing"" , cellspacing ) ; setProperty ( component , ""columnClasses"" , columnClasses ) ; setIntegerProperty ( component , ""columns"" , columns ) ; setProperty ( component , ""dir"" , dir ) ; setProperty ( component , ""footerClass"" , footerClass ) ; setProperty ( component , ""frame"" , frame ) ; setProperty ( component , ""headerClass"" , headerClass ) ; setProperty ( component , ""lang"" , lang ) ; setProperty ( component , ""onclick"" , onclick ) ; setProperty ( component , ""ondblclick"" , ondblclick ) ; setProperty ( component , ""onkeydown"" , onkeydown ) ; setProperty ( component , ""onkeypress"" , onkeypress ) ; setProperty ( component , ""onkeyup"" , onkeyup ) ; setProperty ( component , ""onmousedown"" , onmousedown ) ; setProperty ( component , ""onmousemove"" , onmousemove ) ; setProperty ( component , ""onmouseout"" , onmouseout ) ; setProperty ( component , ""onmouseover"" , onmouseover ) ; setProperty ( component , ""onmouseup"" , onmouseup ) ; setProperty ( component , ""rowClasses"" , rowClasses ) ; setProperty ( component , ""rules"" , rules ) ; setProperty ( component , ""style"" , style ) ; setProperty ( component , ""styleClass"" , styleClass ) ; setProperty ( component , ""summary"" , summary ) ; setProperty ( component , ""title"" , title ) ; setProperty ( component , ""width"" , width ) ; } public void recycle ( ) { super . recycle ( ) ; bgcolor = null ; border = null ; cellpadding = null ; cellspacing = null ; columnClasses = null ; columns = null ; dir = null ; footerClass = null ; frame = null ; headerClass = null ; lang = null ; onclick = null ; ondblclick = null ; onkeydown = null ; onkeypress = null ; onkeyup = null ; onmousedown = null ; onmousemove = null ; onmouseout = null ; onmouseover = null ; onmouseup = null ; rowClasses = null ; rules = null ; style = null ; styleClass = null ; summary = null ; title = null ; width = null ; } }",Smelly
 public static class LoopTagStatus { Object current ; int index ; int count ; boolean first ; boolean last ; int begin ; int end ; int step ; public Object getCurrent ( ) { return current ; } public int getIndex ( ) { return index ; } public int getCount ( ) { return count ; } public boolean isFirst ( ) { return first ; } public boolean isLast ( ) { return last ; } public int getBegin ( ) { return begin ; } public int getEnd ( ) { return end ; } public int getStep ( ) { return step ; } ,Smelly
"public class AbstractJAXRSFactoryBean extends AbstractEndpointFactory { private static final Logger LOG = LogUtils . getL7dLogger ( AbstractJAXRSFactoryBean . class ) ; private static final ResourceBundle BUNDLE = BundleUtils . getBundle ( AbstractJAXRSFactoryBean . class ) ; protected List < String > schemaLocations ; protected JAXRSServiceFactoryBean serviceFactory ; protected List < ? > entityProviders ; protected AbstractJAXRSFactoryBean ( JAXRSServiceFactoryBean serviceFactory ) { this . serviceFactory = serviceFactory ; setBindingId ( JAXRSBindingFactory . JAXRS_BINDING_ID ) ; } public Bus getBus ( ) { Bus b = super . getBus ( ) ; checkBindingFactory ( b ) ; return b ; } public void setServiceName ( QName name ) { super . setServiceName ( name ) ; serviceFactory . setServiceName ( name ) ; } private void checkBindingFactory ( Bus bus ) { BindingFactoryManager bfm = bus . getExtension ( BindingFactoryManager . class ) ; try { bfm . getBindingFactory ( JAXRSBindingFactory . JAXRS_BINDING_ID ) ; } catch ( Throwable b ) { bfm . registerBindingFactory ( JAXRSBindingFactory . JAXRS_BINDING_ID , new JAXRSBindingFactory ( bus ) ) ; } } public void setBus ( Bus bus ) { super . setBus ( bus ) ; checkBindingFactory ( bus ) ; serviceFactory . setBus ( bus ) ; } protected EndpointInfo createEndpointInfo ( ) throws BusException { String transportId = getTransportId ( ) ; if ( transportId == null && getAddress ( ) != null ) { DestinationFactory df = getDestinationFactory ( ) ; if ( df == null ) { DestinationFactoryManager dfm = getBus ( ) . getExtension ( DestinationFactoryManager . class ) ; df = dfm . getDestinationFactoryForUri ( getAddress ( ) ) ; } if ( df != null ) { transportId = df . getTransportIds ( ) . get ( 0 ) ; } } if ( transportId == null ) { transportId = ""http://cxf.apache.org/transports/http"" ; } setTransportId ( transportId ) ; EndpointInfo ei = new EndpointInfo ( ) ; ei . setTransportId ( transportId ) ; ei . setName ( serviceFactory . getService ( ) . getName ( ) ) ; ei . setAddress ( getAddress ( ) ) ; BindingInfo bindingInfo = createBindingInfo ( ) ; ei . setBinding ( bindingInfo ) ; if ( ! StringUtils . isEmpty ( publishedEndpointUrl ) ) { ei . setProperty ( ""publishedEndpointUrl"" , publishedEndpointUrl ) ; } serviceFactory . sendEvent ( FactoryBeanListener . Event . ENDPOINTINFO_CREATED , ei ) ; return ei ; } protected BindingInfo createBindingInfo ( ) { BindingFactoryManager mgr = getBus ( ) . getExtension ( BindingFactoryManager . class ) ; String binding = getBindingId ( ) ; BindingConfiguration bindingConfig = getBindingConfig ( ) ; if ( binding == null && bindingConfig != null ) { binding = bindingConfig . getBindingId ( ) ; } if ( binding == null ) { binding = JAXRSBindingFactory . JAXRS_BINDING_ID ; } try { BindingFactory bindingFactory = mgr . getBindingFactory ( binding ) ; setBindingFactory ( bindingFactory ) ; BindingInfo bi = bindingFactory . createBindingInfo ( serviceFactory . getService ( ) , binding , bindingConfig ) ; for ( BindingOperationInfo boi : bi . getOperations ( ) ) { serviceFactory . sendEvent ( FactoryBeanListener . Event . BINDING_OPERATION_CREATED , boi , boi ) ; } serviceFactory . sendEvent ( FactoryBeanListener . Event . BINDING_CREATED , bi ) ; return bi ; } catch ( BusException ex ) { ex . printStackTrace ( ) ; } return null ; } public JAXRSServiceFactoryBean getServiceFactory ( ) { return serviceFactory ; } public void setServiceFactory ( JAXRSServiceFactoryBean serviceFactory ) { this . serviceFactory = serviceFactory ; } protected Endpoint createEndpoint ( ) throws BusException , EndpointException { Service service = serviceFactory . getService ( ) ; if ( service == null ) { service = serviceFactory . create ( ) ; } EndpointInfo ei = createEndpointInfo ( ) ; Endpoint ep = new EndpointImpl ( getBus ( ) , getServiceFactory ( ) . getService ( ) , ei ) ; if ( properties != null ) { ep . putAll ( properties ) ; } if ( getInInterceptors ( ) != null ) { ep . getInInterceptors ( ) . addAll ( getInInterceptors ( ) ) ; } if ( getOutInterceptors ( ) != null ) { ep . getOutInterceptors ( ) . addAll ( getOutInterceptors ( ) ) ; } if ( getInFaultInterceptors ( ) != null ) { ep . getInFaultInterceptors ( ) . addAll ( getInFaultInterceptors ( ) ) ; } if ( getOutFaultInterceptors ( ) != null ) { ep . getOutFaultInterceptors ( ) . addAll ( getOutFaultInterceptors ( ) ) ; } List < ClassResourceInfo > list = serviceFactory . getRealClassResourceInfo ( ) ; for ( ClassResourceInfo cri : list ) { initializeAnnotationInterceptors ( ep , cri . getServiceClass ( ) ) ; serviceFactory . sendEvent ( FactoryBeanListener . Event . ENDPOINT_SELECTED , ei , ep , cri . getServiceClass ( ) ) ; } return ep ; } public void setSchemaLocation ( String schema ) { setSchemaLocations ( Collections . singletonList ( schema ) ) ; } public void setSchemaLocations ( List < String > schemas ) { this . schemaLocations = schemas ; } public List < ? > getProviders ( ) { return entityProviders ; } public void setProviders ( List < ? extends Object > providers ) { this . entityProviders = providers ; } public void setProvider ( Object provider ) { setProviders ( Collections . singletonList ( provider ) ) ; } protected void checkResources ( boolean server ) { List < ClassResourceInfo > list = serviceFactory . getRealClassResourceInfo ( ) ; if ( server ) { for ( Iterator < ClassResourceInfo > it = list . iterator ( ) ; it . hasNext ( ) ; ) { ClassResourceInfo cri = it . next ( ) ; if ( cri . isCreatedFromModel ( ) && cri . getServiceClass ( ) == cri . getResourceClass ( ) && ! InjectionUtils . isConcreteClass ( cri . getServiceClass ( ) ) ) { it . remove ( ) ; } } } if ( list . size ( ) == 0 ) { org . apache . cxf . common . i18n . Message msg = new org . apache . cxf . common . i18n . Message ( ""NO_RESOURCES_AVAILABLE"" , BUNDLE ) ; LOG . severe ( msg . toString ( ) ) ; throw new WebApplicationException ( Response . Status . NOT_FOUND ) ; } } protected ProviderFactory setupFactory ( Endpoint ep ) { ProviderFactory factory = ProviderFactory . getInstance ( getBus ( ) ) ; if ( entityProviders != null ) { factory . setUserProviders ( entityProviders ) ; } setDataBindingProvider ( factory , ep . getService ( ) ) ; factory . setBus ( getBus ( ) ) ; factory . initProviders ( serviceFactory . getRealClassResourceInfo ( ) ) ; if ( schemaLocations != null ) { factory . setSchemaLocations ( schemaLocations ) ; } ep . put ( ProviderFactory . class . getName ( ) , factory ) ; return factory ; } protected void setDataBindingProvider ( ProviderFactory factory , Service s ) { List < ClassResourceInfo > cris = serviceFactory . getRealClassResourceInfo ( ) ; if ( getDataBinding ( ) == null && cris . size ( ) > 0 ) { org . apache . cxf . annotations . DataBinding ann = cris . get ( 0 ) . getServiceClass ( ) . getAnnotation ( org . apache . cxf . annotations . DataBinding . class ) ; if ( ann != null ) { try { setDataBinding ( ann . value ( ) . newInstance ( ) ) ; } catch ( Exception ex ) { LOG . warning ( ""DataBinding "" + ann . value ( ) + "" can not be loaded"" ) ; } } } DataBinding db = getDataBinding ( ) ; if ( db == null ) { return ; } if ( db instanceof PropertiesAwareDataBinding ) { Map < Class < ? > , Type > allClasses = ResourceUtils . getAllRequestResponseTypes ( cris , false ) . getAllTypes ( ) ; Map < String , Object > props = new HashMap < String , Object > ( ) ; props . put ( PropertiesAwareDataBinding . TYPES_PROPERTY , allClasses ) ; ( ( PropertiesAwareDataBinding ) db ) . initialize ( props ) ; } else { if ( s instanceof JAXRSServiceImpl ) { ( ( JAXRSServiceImpl ) s ) . setCreateServiceModel ( true ) ; } db . initialize ( s ) ; } factory . setUserProviders ( Collections . singletonList ( new DataBindingProvider < Object > ( db ) ) ) ; } public void setModelBeans ( UserResource ... resources ) { setModelBeans ( Arrays . asList ( resources ) ) ; } public void setModelBeans ( List < UserResource > resources ) { serviceFactory . setUserResources ( resources ) ; } public void setModelBeansWithServiceClass ( List < UserResource > resources , Class < ? > ... sClasses ) { serviceFactory . setUserResourcesWithServiceClass ( resources , sClasses ) ; } public void setModelRef ( String modelRef ) { List < UserResource > resources = ResourceUtils . getUserResources ( modelRef , getBus ( ) ) ; if ( resources != null ) { serviceFactory . setUserResources ( resources ) ; } } public void setModelRefWithServiceClass ( String modelRef , Class < ? > ... sClasses ) { List < UserResource > resources = ResourceUtils . getUserResources ( modelRef , getBus ( ) ) ; if ( resources != null ) { serviceFactory . setUserResourcesWithServiceClass ( resources , sClasses ) ; } } }",Smelly
" public static class Builder < T > { private ExecutorService pool ; private TableName tableName ; private RowAccess < ? extends Row > rows ; private SubmittedRows submittedRows = SubmittedRows . ALL ; private Batch . Callback < T > callback ; private boolean needResults ; private int rpcTimeout ; private int operationTimeout ; private CancellableRegionServerCallable callable ; private Object [ ] results ; private Builder ( ) { } private Builder ( Batch . Callback < T > callback ) { this . callback = callback ; } Builder < T > setResults ( Object [ ] results ) { this . results = results ; if ( results != null && results . length != 0 ) { setNeedResults ( true ) ; } return this ; } public Builder < T > setPool ( ExecutorService pool ) { this . pool = pool ; return this ; } public Builder < T > setRpcTimeout ( int rpcTimeout ) { this . rpcTimeout = rpcTimeout ; return this ; } public Builder < T > setOperationTimeout ( int operationTimeout ) { this . operationTimeout = operationTimeout ; return this ; } public Builder < T > setTableName ( TableName tableName ) { this . tableName = tableName ; return this ; } public Builder < T > setRowAccess ( List < ? extends Row > rows ) { this . rows = new ListRowAccess < > ( rows ) ; return this ; } public Builder < T > setRowAccess ( RowAccess < ? extends Row > rows ) { this . rows = rows ; return this ; } public Builder < T > setSubmittedRows ( SubmittedRows submittedRows ) { this . submittedRows = submittedRows ; return this ; } public Builder < T > setNeedResults ( boolean needResults ) { this . needResults = needResults ; return this ; } Builder < T > setCallable ( CancellableRegionServerCallable callable ) { this . callable = callable ; return this ; } public AsyncProcessTask < T > build ( ) { return new AsyncProcessTask < > ( pool , tableName , rows , submittedRows , callback , callable , needResults , rpcTimeout , operationTimeout , results ) ; } ",Smelly
public abstract class GraphMemBase extends GraphBase { protected int count ; public final TripleStore store ; public GraphMemBase ( ) { store = createTripleStore ( ) ; count = 1 ; } protected abstract TripleStore createTripleStore ( ) ; public GraphMemBase openAgain ( ) { count += 1 ; return this ; } protected abstract void destroy ( ) ; @ Override public void close ( ) { if ( -- count == 0 ) { destroy ( ) ; super . close ( ) ; } } protected final boolean isSafeForEquality ( Triple t ) { return t . isConcrete ( ) && ! t . getObject ( ) . isLiteral ( ) ; } },No
"public class BindVariableValueTest extends AbstractQOMTest { private static final String STRING_VALUE = ""JSR"" ; private static final long LONG_VALUE = 283 ; private static final double DOUBLE_VALUE = Math . PI ; private static final boolean BOOLEAN_VALUE = true ; private static final Calendar DATE_VALUE = Calendar . getInstance ( ) ; private static final BigDecimal DECIMAL_VALUE = new BigDecimal ( LONG_VALUE ) ; private static final String URI_VALUE = ""http://example.com/"" ; private Query qomQuery ; private Query sqlQuery ; protected void setUp ( ) throws Exception { super . setUp ( ) ; qomQuery = qf . createQuery ( qf . selector ( testNodeType , ""s"" ) , qf . and ( qf . childNode ( ""s"" , testRoot ) , qf . comparison ( qf . propertyValue ( ""s"" , propertyName1 ) , QueryObjectModelConstants . JCR_OPERATOR_EQUAL_TO , qf . bindVariable ( ""v"" ) ) ) , null , null ) ; sqlQuery = qm . createQuery ( qomQuery . getStatement ( ) , Query . JCR_SQL2 ) ; } protected void tearDown ( ) throws Exception { qomQuery = null ; super . tearDown ( ) ; } public void testBindVariableNames ( ) throws RepositoryException { String [ ] names = qomQuery . getBindVariableNames ( ) ; assertNotNull ( names ) ; assertEquals ( 1 , names . length ) ; assertEquals ( ""v"" , names [ 0 ] ) ; } public void testIllegalArgumentException ( ) throws RepositoryException { try { bindVariableValue ( qomQuery , ""x"" , vf . createValue ( STRING_VALUE ) ) ; fail ( ""Query.bindValue() must throw IllegalArgumentException for unknown variable name"" ) ; } catch ( IllegalArgumentException e ) { } try { bindVariableValue ( sqlQuery , ""x"" , vf . createValue ( STRING_VALUE ) ) ; fail ( ""Query.bindValue() must throw IllegalArgumentException for unknown variable name"" ) ; } catch ( IllegalArgumentException e ) { } } public void testString ( ) throws RepositoryException { Node n = testRootNode . addNode ( nodeName1 , testNodeType ) ; n . setProperty ( propertyName1 , STRING_VALUE ) ; superuser . save ( ) ; bindVariableValue ( qomQuery , ""v"" , vf . createValue ( STRING_VALUE ) ) ; checkResult ( qomQuery . execute ( ) , new Node [ ] { n } ) ; bindVariableValue ( sqlQuery , ""v"" , vf . createValue ( STRING_VALUE ) ) ; checkResult ( sqlQuery . execute ( ) , new Node [ ] { n } ) ; } public void testDate ( ) throws RepositoryException { Node n = testRootNode . addNode ( nodeName1 , testNodeType ) ; n . setProperty ( propertyName1 , DATE_VALUE ) ; superuser . save ( ) ; bindVariableValue ( sqlQuery , ""v"" , vf . createValue ( DATE_VALUE ) ) ; checkResult ( sqlQuery . execute ( ) , new Node [ ] { n } ) ; bindVariableValue ( qomQuery , ""v"" , vf . createValue ( DATE_VALUE ) ) ; checkResult ( qomQuery . execute ( ) , new Node [ ] { n } ) ; } public void testLong ( ) throws RepositoryException { Node n = testRootNode . addNode ( nodeName1 , testNodeType ) ; n . setProperty ( propertyName1 , LONG_VALUE ) ; superuser . save ( ) ; bindVariableValue ( qomQuery , ""v"" , vf . createValue ( LONG_VALUE ) ) ; checkResult ( qomQuery . execute ( ) , new Node [ ] { n } ) ; bindVariableValue ( sqlQuery , ""v"" , vf . createValue ( LONG_VALUE ) ) ; checkResult ( sqlQuery . execute ( ) , new Node [ ] { n } ) ; } public void testDouble ( ) throws RepositoryException { Node n = testRootNode . addNode ( nodeName1 , testNodeType ) ; n . setProperty ( propertyName1 , DOUBLE_VALUE ) ; superuser . save ( ) ; bindVariableValue ( qomQuery , ""v"" , vf . createValue ( DOUBLE_VALUE ) ) ; checkResult ( qomQuery . execute ( ) , new Node [ ] { n } ) ; bindVariableValue ( sqlQuery , ""v"" , vf . createValue ( DOUBLE_VALUE ) ) ; checkResult ( sqlQuery . execute ( ) , new Node [ ] { n } ) ; } public void testBoolean ( ) throws RepositoryException { Node n = testRootNode . addNode ( nodeName1 , testNodeType ) ; n . setProperty ( propertyName1 , BOOLEAN_VALUE ) ; superuser . save ( ) ; bindVariableValue ( qomQuery , ""v"" , vf . createValue ( BOOLEAN_VALUE ) ) ; checkResult ( qomQuery . execute ( ) , new Node [ ] { n } ) ; bindVariableValue ( sqlQuery , ""v"" , vf . createValue ( BOOLEAN_VALUE ) ) ; checkResult ( sqlQuery . execute ( ) , new Node [ ] { n } ) ; } public void testName ( ) throws RepositoryException { Value name = vf . createValue ( STRING_VALUE , PropertyType . NAME ) ; Node n = testRootNode . addNode ( nodeName1 , testNodeType ) ; n . setProperty ( propertyName1 , name ) ; superuser . save ( ) ; bindVariableValue ( qomQuery , ""v"" , name ) ; checkResult ( qomQuery . execute ( ) , new Node [ ] { n } ) ; bindVariableValue ( sqlQuery , ""v"" , name ) ; checkResult ( sqlQuery . execute ( ) , new Node [ ] { n } ) ; } public void testPath ( ) throws RepositoryException { Node n = testRootNode . addNode ( nodeName1 , testNodeType ) ; Value path = vf . createValue ( n . getPath ( ) , PropertyType . PATH ) ; n . setProperty ( propertyName1 , path ) ; superuser . save ( ) ; bindVariableValue ( qomQuery , ""v"" , path ) ; checkResult ( qomQuery . execute ( ) , new Node [ ] { n } ) ; bindVariableValue ( sqlQuery , ""v"" , path ) ; checkResult ( sqlQuery . execute ( ) , new Node [ ] { n } ) ; } public void testReference ( ) throws RepositoryException , NotExecutableException { Node n = testRootNode . addNode ( nodeName1 , testNodeType ) ; superuser . save ( ) ; ensureMixinType ( n , mixReferenceable ) ; superuser . save ( ) ; n . setProperty ( propertyName1 , n ) ; superuser . save ( ) ; bindVariableValue ( qomQuery , ""v"" , vf . createValue ( n ) ) ; checkResult ( qomQuery . execute ( ) , new Node [ ] { n } ) ; bindVariableValue ( sqlQuery , ""v"" , vf . createValue ( n ) ) ; checkResult ( sqlQuery . execute ( ) , new Node [ ] { n } ) ; } public void testWeakReference ( ) throws RepositoryException , NotExecutableException { Node n = testRootNode . addNode ( nodeName1 , testNodeType ) ; superuser . save ( ) ; ensureMixinType ( n , mixReferenceable ) ; superuser . save ( ) ; n . setProperty ( propertyName1 , vf . createValue ( n , true ) ) ; superuser . save ( ) ; bindVariableValue ( qomQuery , ""v"" , vf . createValue ( n , true ) ) ; checkResult ( qomQuery . execute ( ) , new Node [ ] { n } ) ; bindVariableValue ( sqlQuery , ""v"" , vf . createValue ( n , true ) ) ; checkResult ( sqlQuery . execute ( ) , new Node [ ] { n } ) ; } public void testURI ( ) throws RepositoryException { Value value = vf . createValue ( URI_VALUE , PropertyType . URI ) ; Node n = testRootNode . addNode ( nodeName1 , testNodeType ) ; n . setProperty ( propertyName1 , value ) ; superuser . save ( ) ; bindVariableValue ( qomQuery , ""v"" , value ) ; checkResult ( qomQuery . execute ( ) , new Node [ ] { n } ) ; bindVariableValue ( sqlQuery , ""v"" , value ) ; checkResult ( sqlQuery . execute ( ) , new Node [ ] { n } ) ; } public void testDecimal ( ) throws RepositoryException { Value value = vf . createValue ( DECIMAL_VALUE ) ; Node n = testRootNode . addNode ( nodeName1 , testNodeType ) ; n . setProperty ( propertyName1 , value ) ; superuser . save ( ) ; bindVariableValue ( qomQuery , ""v"" , value ) ; checkResult ( qomQuery . execute ( ) , new Node [ ] { n } ) ; bindVariableValue ( sqlQuery , ""v"" , value ) ; checkResult ( sqlQuery . execute ( ) , new Node [ ] { n } ) ; } }",No
"public class Context { private AegisContext globalContext ; private Collection < Attachment > attachments ; private Fault fault ; private Map < Class < ? > , Object > properties ; private Map < String , Object > namedProperties ; public Context ( AegisContext aegisContext ) { this . globalContext = aegisContext ; this . properties = new HashMap < Class < ? > , Object > ( ) ; } public TypeMapping getTypeMapping ( ) { return globalContext . getTypeMapping ( ) ; } public Collection < Attachment > getAttachments ( ) { return attachments ; } public void setAttachments ( Collection < Attachment > attachments ) { this . attachments = attachments ; } public boolean isWriteXsiTypes ( ) { return globalContext . isWriteXsiTypes ( ) ; } public boolean isReadXsiTypes ( ) { return globalContext . isReadXsiTypes ( ) ; } public void setFault ( Fault fault ) { this . fault = fault ; } public Fault getFault ( ) { return fault ; } public AegisContext getGlobalContext ( ) { return globalContext ; } public boolean isMtomEnabled ( ) { return globalContext . isMtomEnabled ( ) ; } public < T > T getProperty ( Class < T > key ) { return key . cast ( properties . get ( key ) ) ; } public void setProperty ( Object value ) { properties . put ( value . getClass ( ) , value ) ; } public void setProperty ( String name , Object value ) { namedProperties . put ( name , value ) ; } public < T > T getProperty ( String name , Class < T > type ) { return type . cast ( namedProperties . get ( name ) ) ; } }",Smelly
"public class ExecMapperContext { public static final Log l4j = ExecMapper . l4j ; private Path lastInputPath = null ; private Path currentInputPath = null ; private boolean inputFileChecked = false ; private String fileId = null ; private MapredLocalWork localWork = null ; private Map < String , FetchOperator > fetchOperators ; private JobConf jc ; private IOContext ioCxt ; private String currentBigBucketFile = null ; public String getCurrentBigBucketFile ( ) { return currentBigBucketFile ; } public void setCurrentBigBucketFile ( String currentBigBucketFile ) { this . currentBigBucketFile = currentBigBucketFile ; } public ExecMapperContext ( ) { ioCxt = IOContext . get ( ) ; } public void clear ( ) { IOContext . clear ( ) ; ioCxt = null ; } public boolean inputFileChanged ( ) { if ( ! inputFileChecked ) { currentInputPath = this . ioCxt . getInputPath ( ) ; inputFileChecked = true ; } return lastInputPath == null || ! lastInputPath . equals ( currentInputPath ) ; } public void resetRow ( ) { lastInputPath = currentInputPath ; inputFileChecked = false ; } public Path getLastInputPath ( ) { return lastInputPath ; } public void setLastInputPath ( Path lastInputPath ) { this . lastInputPath = lastInputPath ; } public Path getCurrentInputPath ( ) { currentInputPath = this . ioCxt . getInputPath ( ) ; return currentInputPath ; } public void setCurrentInputPath ( Path currentInputPath ) { this . currentInputPath = currentInputPath ; } public JobConf getJc ( ) { return jc ; } public void setJc ( JobConf jc ) { this . jc = jc ; } public MapredLocalWork getLocalWork ( ) { return localWork ; } public void setLocalWork ( MapredLocalWork localWork ) { this . localWork = localWork ; } public String getFileId ( ) { return fileId ; } public void setFileId ( String fileId ) { this . fileId = fileId ; } public Map < String , FetchOperator > getFetchOperators ( ) { return fetchOperators ; } public void setFetchOperators ( Map < String , FetchOperator > fetchOperators ) { this . fetchOperators = fetchOperators ; } public IOContext getIoCxt ( ) { return ioCxt ; } public void setIoCxt ( IOContext ioCxt ) { this . ioCxt = ioCxt ; } }",Smelly
"@ RunWith ( PowerMockRunner . class ) @ PrepareForTest ( KafkaOffsetBackingStore . class ) @ PowerMockIgnore ( { ""javax.management.*"" , ""javax.crypto.*"" } ) @ SuppressWarnings ( { ""unchecked"" , ""deprecation"" } ) public class KafkaOffsetBackingStoreTest { private static final String TOPIC = ""connect-offsets"" ; private static final short TOPIC_PARTITIONS = 2 ; private static final short TOPIC_REPLICATION_FACTOR = 5 ; private static final Map < String , String > DEFAULT_PROPS = new HashMap < > ( ) ; private static final DistributedConfig DEFAULT_DISTRIBUTED_CONFIG ; static { DEFAULT_PROPS . put ( CommonClientConfigs . BOOTSTRAP_SERVERS_CONFIG , ""broker1:9092,broker2:9093"" ) ; DEFAULT_PROPS . put ( DistributedConfig . OFFSET_STORAGE_TOPIC_CONFIG , TOPIC ) ; DEFAULT_PROPS . put ( DistributedConfig . OFFSET_STORAGE_REPLICATION_FACTOR_CONFIG , Short . toString ( TOPIC_REPLICATION_FACTOR ) ) ; DEFAULT_PROPS . put ( DistributedConfig . OFFSET_STORAGE_PARTITIONS_CONFIG , Integer . toString ( TOPIC_PARTITIONS ) ) ; DEFAULT_PROPS . put ( DistributedConfig . CONFIG_TOPIC_CONFIG , ""connect-configs"" ) ; DEFAULT_PROPS . put ( DistributedConfig . CONFIG_STORAGE_REPLICATION_FACTOR_CONFIG , Short . toString ( TOPIC_REPLICATION_FACTOR ) ) ; DEFAULT_PROPS . put ( DistributedConfig . GROUP_ID_CONFIG , ""connect"" ) ; DEFAULT_PROPS . put ( DistributedConfig . STATUS_STORAGE_TOPIC_CONFIG , ""status-topic"" ) ; DEFAULT_PROPS . put ( DistributedConfig . KEY_CONVERTER_CLASS_CONFIG , ""org.apache.kafka.connect.json.JsonConverter"" ) ; DEFAULT_PROPS . put ( DistributedConfig . VALUE_CONVERTER_CLASS_CONFIG , ""org.apache.kafka.connect.json.JsonConverter"" ) ; DEFAULT_PROPS . put ( DistributedConfig . INTERNAL_KEY_CONVERTER_CLASS_CONFIG , ""org.apache.kafka.connect.json.JsonConverter"" ) ; DEFAULT_PROPS . put ( DistributedConfig . INTERNAL_VALUE_CONVERTER_CLASS_CONFIG , ""org.apache.kafka.connect.json.JsonConverter"" ) ; DEFAULT_DISTRIBUTED_CONFIG = new DistributedConfig ( DEFAULT_PROPS ) ; } private static final Map < ByteBuffer , ByteBuffer > FIRST_SET = new HashMap < > ( ) ; static { FIRST_SET . put ( buffer ( ""key"" ) , buffer ( ""value"" ) ) ; FIRST_SET . put ( null , null ) ; } private static final ByteBuffer TP0_KEY = buffer ( ""TP0KEY"" ) ; private static final ByteBuffer TP1_KEY = buffer ( ""TP1KEY"" ) ; private static final ByteBuffer TP2_KEY = buffer ( ""TP2KEY"" ) ; private static final ByteBuffer TP0_VALUE = buffer ( ""VAL0"" ) ; private static final ByteBuffer TP1_VALUE = buffer ( ""VAL1"" ) ; private static final ByteBuffer TP2_VALUE = buffer ( ""VAL2"" ) ; private static final ByteBuffer TP0_VALUE_NEW = buffer ( ""VAL0_NEW"" ) ; private static final ByteBuffer TP1_VALUE_NEW = buffer ( ""VAL1_NEW"" ) ; @ Mock KafkaBasedLog < byte [ ] , byte [ ] > storeLog ; private KafkaOffsetBackingStore store ; private Capture < String > capturedTopic = EasyMock . newCapture ( ) ; private Capture < Map < String , Object > > capturedProducerProps = EasyMock . newCapture ( ) ; private Capture < Map < String , Object > > capturedConsumerProps = EasyMock . newCapture ( ) ; private Capture < Map < String , Object > > capturedAdminProps = EasyMock . newCapture ( ) ; private Capture < NewTopic > capturedNewTopic = EasyMock . newCapture ( ) ; private Capture < Callback < ConsumerRecord < byte [ ] , byte [ ] > > > capturedConsumedCallback = EasyMock . newCapture ( ) ; @ Before public void setUp ( ) throws Exception { store = PowerMock . createPartialMockAndInvokeDefaultConstructor ( KafkaOffsetBackingStore . class , ""createKafkaBasedLog"" ) ; } @ Test public void testStartStop ( ) throws Exception { expectConfigure ( ) ; expectStart ( Collections . emptyList ( ) ) ; expectStop ( ) ; PowerMock . replayAll ( ) ; store . configure ( DEFAULT_DISTRIBUTED_CONFIG ) ; assertEquals ( TOPIC , capturedTopic . getValue ( ) ) ; assertEquals ( ""org.apache.kafka.common.serialization.ByteArraySerializer"" , capturedProducerProps . getValue ( ) . get ( ProducerConfig . KEY_SERIALIZER_CLASS_CONFIG ) ) ; assertEquals ( ""org.apache.kafka.common.serialization.ByteArraySerializer"" , capturedProducerProps . getValue ( ) . get ( ProducerConfig . VALUE_SERIALIZER_CLASS_CONFIG ) ) ; assertEquals ( ""org.apache.kafka.common.serialization.ByteArrayDeserializer"" , capturedConsumerProps . getValue ( ) . get ( ConsumerConfig . KEY_DESERIALIZER_CLASS_CONFIG ) ) ; assertEquals ( ""org.apache.kafka.common.serialization.ByteArrayDeserializer"" , capturedConsumerProps . getValue ( ) . get ( ConsumerConfig . VALUE_DESERIALIZER_CLASS_CONFIG ) ) ; assertEquals ( TOPIC , capturedNewTopic . getValue ( ) . name ( ) ) ; assertEquals ( TOPIC_PARTITIONS , capturedNewTopic . getValue ( ) . numPartitions ( ) ) ; assertEquals ( TOPIC_REPLICATION_FACTOR , capturedNewTopic . getValue ( ) . replicationFactor ( ) ) ; store . start ( ) ; store . stop ( ) ; PowerMock . verifyAll ( ) ; } @ Test public void testReloadOnStart ( ) throws Exception { expectConfigure ( ) ; expectStart ( Arrays . asList ( new ConsumerRecord < > ( TOPIC , 0 , 0 , 0L , TimestampType . CREATE_TIME , 0L , 0 , 0 , TP0_KEY . array ( ) , TP0_VALUE . array ( ) ) , new ConsumerRecord < > ( TOPIC , 1 , 0 , 0L , TimestampType . CREATE_TIME , 0L , 0 , 0 , TP1_KEY . array ( ) , TP1_VALUE . array ( ) ) , new ConsumerRecord < > ( TOPIC , 0 , 1 , 0L , TimestampType . CREATE_TIME , 0L , 0 , 0 , TP0_KEY . array ( ) , TP0_VALUE_NEW . array ( ) ) , new ConsumerRecord < > ( TOPIC , 1 , 1 , 0L , TimestampType . CREATE_TIME , 0L , 0 , 0 , TP1_KEY . array ( ) , TP1_VALUE_NEW . array ( ) ) ) ) ; expectStop ( ) ; PowerMock . replayAll ( ) ; store . configure ( DEFAULT_DISTRIBUTED_CONFIG ) ; store . start ( ) ; HashMap < ByteBuffer , ByteBuffer > data = Whitebox . getInternalState ( store , ""data"" ) ; assertEquals ( TP0_VALUE_NEW , data . get ( TP0_KEY ) ) ; assertEquals ( TP1_VALUE_NEW , data . get ( TP1_KEY ) ) ; store . stop ( ) ; PowerMock . verifyAll ( ) ; } @ Test public void testGetSet ( ) throws Exception { expectConfigure ( ) ; expectStart ( Collections . emptyList ( ) ) ; expectStop ( ) ; final Capture < Callback < Void > > firstGetReadToEndCallback = EasyMock . newCapture ( ) ; storeLog . readToEnd ( EasyMock . capture ( firstGetReadToEndCallback ) ) ; PowerMock . expectLastCall ( ) . andAnswer ( ( ) -> { firstGetReadToEndCallback . getValue ( ) . onCompletion ( null , null ) ; return null ; } ) ; Capture < org . apache . kafka . clients . producer . Callback > callback0 = EasyMock . newCapture ( ) ; storeLog . send ( EasyMock . aryEq ( TP0_KEY . array ( ) ) , EasyMock . aryEq ( TP0_VALUE . array ( ) ) , EasyMock . capture ( callback0 ) ) ; PowerMock . expectLastCall ( ) ; Capture < org . apache . kafka . clients . producer . Callback > callback1 = EasyMock . newCapture ( ) ; storeLog . send ( EasyMock . aryEq ( TP1_KEY . array ( ) ) , EasyMock . aryEq ( TP1_VALUE . array ( ) ) , EasyMock . capture ( callback1 ) ) ; PowerMock . expectLastCall ( ) ; final Capture < Callback < Void > > secondGetReadToEndCallback = EasyMock . newCapture ( ) ; storeLog . readToEnd ( EasyMock . capture ( secondGetReadToEndCallback ) ) ; PowerMock . expectLastCall ( ) . andAnswer ( new IAnswer < Object > ( ) { @ Override public Object answer ( ) throws Throwable { capturedConsumedCallback . getValue ( ) . onCompletion ( null , new ConsumerRecord < > ( TOPIC , 0 , 0 , 0L , TimestampType . CREATE_TIME , 0L , 0 , 0 , TP0_KEY . array ( ) , TP0_VALUE . array ( ) ) ) ; capturedConsumedCallback . getValue ( ) . onCompletion ( null , new ConsumerRecord < > ( TOPIC , 1 , 0 , 0L , TimestampType . CREATE_TIME , 0L , 0 , 0 , TP1_KEY . array ( ) , TP1_VALUE . array ( ) ) ) ; secondGetReadToEndCallback . getValue ( ) . onCompletion ( null , null ) ; return null ; } } ) ; final Capture < Callback < Void > > thirdGetReadToEndCallback = EasyMock . newCapture ( ) ; storeLog . readToEnd ( EasyMock . capture ( thirdGetReadToEndCallback ) ) ; PowerMock . expectLastCall ( ) . andAnswer ( new IAnswer < Object > ( ) { @ Override public Object answer ( ) throws Throwable { capturedConsumedCallback . getValue ( ) . onCompletion ( null , new ConsumerRecord < > ( TOPIC , 0 , 1 , 0L , TimestampType . CREATE_TIME , 0L , 0 , 0 , TP0_KEY . array ( ) , TP0_VALUE_NEW . array ( ) ) ) ; capturedConsumedCallback . getValue ( ) . onCompletion ( null , new ConsumerRecord < > ( TOPIC , 1 , 1 , 0L , TimestampType . CREATE_TIME , 0L , 0 , 0 , TP1_KEY . array ( ) , TP1_VALUE_NEW . array ( ) ) ) ; thirdGetReadToEndCallback . getValue ( ) . onCompletion ( null , null ) ; return null ; } } ) ; PowerMock . replayAll ( ) ; store . configure ( DEFAULT_DISTRIBUTED_CONFIG ) ; store . start ( ) ; Map < ByteBuffer , ByteBuffer > offsets = store . get ( Arrays . asList ( TP0_KEY , TP1_KEY ) ) . get ( 10000 , TimeUnit . MILLISECONDS ) ; assertNull ( offsets . get ( TP0_KEY ) ) ; assertNull ( offsets . get ( TP1_KEY ) ) ; Map < ByteBuffer , ByteBuffer > toSet = new HashMap < > ( ) ; toSet . put ( TP0_KEY , TP0_VALUE ) ; toSet . put ( TP1_KEY , TP1_VALUE ) ; final AtomicBoolean invoked = new AtomicBoolean ( false ) ; Future < Void > setFuture = store . set ( toSet , new Callback < Void > ( ) { @ Override public void onCompletion ( Throwable error , Void result ) { invoked . set ( true ) ; } } ) ; assertFalse ( setFuture . isDone ( ) ) ; callback1 . getValue ( ) . onCompletion ( null , null ) ; assertFalse ( invoked . get ( ) ) ; callback0 . getValue ( ) . onCompletion ( null , null ) ; setFuture . get ( 10000 , TimeUnit . MILLISECONDS ) ; assertTrue ( invoked . get ( ) ) ; offsets = store . get ( Arrays . asList ( TP0_KEY , TP1_KEY ) ) . get ( 10000 , TimeUnit . MILLISECONDS ) ; assertEquals ( TP0_VALUE , offsets . get ( TP0_KEY ) ) ; assertEquals ( TP1_VALUE , offsets . get ( TP1_KEY ) ) ; offsets = store . get ( Arrays . asList ( TP0_KEY , TP1_KEY ) ) . get ( 10000 , TimeUnit . MILLISECONDS ) ; assertEquals ( TP0_VALUE_NEW , offsets . get ( TP0_KEY ) ) ; assertEquals ( TP1_VALUE_NEW , offsets . get ( TP1_KEY ) ) ; store . stop ( ) ; PowerMock . verifyAll ( ) ; } @ Test public void testGetSetNull ( ) throws Exception { expectConfigure ( ) ; expectStart ( Collections . emptyList ( ) ) ; Capture < org . apache . kafka . clients . producer . Callback > callback0 = EasyMock . newCapture ( ) ; storeLog . send ( EasyMock . isNull ( byte [ ] . class ) , EasyMock . aryEq ( TP0_VALUE . array ( ) ) , EasyMock . capture ( callback0 ) ) ; PowerMock . expectLastCall ( ) ; Capture < org . apache . kafka . clients . producer . Callback > callback1 = EasyMock . newCapture ( ) ; storeLog . send ( EasyMock . aryEq ( TP1_KEY . array ( ) ) , EasyMock . isNull ( byte [ ] . class ) , EasyMock . capture ( callback1 ) ) ; PowerMock . expectLastCall ( ) ; final Capture < Callback < Void > > secondGetReadToEndCallback = EasyMock . newCapture ( ) ; storeLog . readToEnd ( EasyMock . capture ( secondGetReadToEndCallback ) ) ; PowerMock . expectLastCall ( ) . andAnswer ( ( ) -> { capturedConsumedCallback . getValue ( ) . onCompletion ( null , new ConsumerRecord < > ( TOPIC , 0 , 0 , 0L , TimestampType . CREATE_TIME , 0L , 0 , 0 , ( byte [ ] ) null , TP0_VALUE . array ( ) ) ) ; capturedConsumedCallback . getValue ( ) . onCompletion ( null , new ConsumerRecord < > ( TOPIC , 1 , 0 , 0L , TimestampType . CREATE_TIME , 0L , 0 , 0 , TP1_KEY . array ( ) , ( byte [ ] ) null ) ) ; secondGetReadToEndCallback . getValue ( ) . onCompletion ( null , null ) ; return null ; } ) ; expectStop ( ) ; PowerMock . replayAll ( ) ; store . configure ( DEFAULT_DISTRIBUTED_CONFIG ) ; store . start ( ) ; Map < ByteBuffer , ByteBuffer > toSet = new HashMap < > ( ) ; toSet . put ( null , TP0_VALUE ) ; toSet . put ( TP1_KEY , null ) ; final AtomicBoolean invoked = new AtomicBoolean ( false ) ; Future < Void > setFuture = store . set ( toSet , new Callback < Void > ( ) { @ Override public void onCompletion ( Throwable error , Void result ) { invoked . set ( true ) ; } } ) ; assertFalse ( setFuture . isDone ( ) ) ; callback1 . getValue ( ) . onCompletion ( null , null ) ; assertFalse ( invoked . get ( ) ) ; callback0 . getValue ( ) . onCompletion ( null , null ) ; setFuture . get ( 10000 , TimeUnit . MILLISECONDS ) ; assertTrue ( invoked . get ( ) ) ; Map < ByteBuffer , ByteBuffer > offsets = store . get ( Arrays . asList ( null , TP1_KEY ) ) . get ( 10000 , TimeUnit . MILLISECONDS ) ; assertEquals ( TP0_VALUE , offsets . get ( null ) ) ; assertNull ( offsets . get ( TP1_KEY ) ) ; store . stop ( ) ; PowerMock . verifyAll ( ) ; } @ Test public void testSetFailure ( ) throws Exception { expectConfigure ( ) ; expectStart ( Collections . emptyList ( ) ) ; expectStop ( ) ; Capture < org . apache . kafka . clients . producer . Callback > callback0 = EasyMock . newCapture ( ) ; storeLog . send ( EasyMock . aryEq ( TP0_KEY . array ( ) ) , EasyMock . aryEq ( TP0_VALUE . array ( ) ) , EasyMock . capture ( callback0 ) ) ; PowerMock . expectLastCall ( ) ; Capture < org . apache . kafka . clients . producer . Callback > callback1 = EasyMock . newCapture ( ) ; storeLog . send ( EasyMock . aryEq ( TP1_KEY . array ( ) ) , EasyMock . aryEq ( TP1_VALUE . array ( ) ) , EasyMock . capture ( callback1 ) ) ; PowerMock . expectLastCall ( ) ; Capture < org . apache . kafka . clients . producer . Callback > callback2 = EasyMock . newCapture ( ) ; storeLog . send ( EasyMock . aryEq ( TP2_KEY . array ( ) ) , EasyMock . aryEq ( TP2_VALUE . array ( ) ) , EasyMock . capture ( callback2 ) ) ; PowerMock . expectLastCall ( ) ; PowerMock . replayAll ( ) ; store . configure ( DEFAULT_DISTRIBUTED_CONFIG ) ; store . start ( ) ; Map < ByteBuffer , ByteBuffer > toSet = new HashMap < > ( ) ; toSet . put ( TP0_KEY , TP0_VALUE ) ; toSet . put ( TP1_KEY , TP1_VALUE ) ; toSet . put ( TP2_KEY , TP2_VALUE ) ; final AtomicBoolean invoked = new AtomicBoolean ( false ) ; final AtomicBoolean invokedFailure = new AtomicBoolean ( false ) ; Future < Void > setFuture = store . set ( toSet , new Callback < Void > ( ) { @ Override public void onCompletion ( Throwable error , Void result ) { invoked . set ( true ) ; if ( error != null ) invokedFailure . set ( true ) ; } } ) ; assertFalse ( setFuture . isDone ( ) ) ; callback1 . getValue ( ) . onCompletion ( null , null ) ; assertFalse ( invoked . get ( ) ) ; callback2 . getValue ( ) . onCompletion ( null , new KafkaException ( ""bogus error"" ) ) ; assertTrue ( invoked . get ( ) ) ; assertTrue ( invokedFailure . get ( ) ) ; callback0 . getValue ( ) . onCompletion ( null , null ) ; try { setFuture . get ( 10000 , TimeUnit . MILLISECONDS ) ; fail ( ""Should have seen KafkaException thrown when waiting on KafkaOffsetBackingStore.set() future"" ) ; } catch ( ExecutionException e ) { assertNotNull ( e . getCause ( ) ) ; assertTrue ( e . getCause ( ) instanceof KafkaException ) ; } store . stop ( ) ; PowerMock . verifyAll ( ) ; } private void expectConfigure ( ) throws Exception { PowerMock . expectPrivate ( store , ""createKafkaBasedLog"" , EasyMock . capture ( capturedTopic ) , EasyMock . capture ( capturedProducerProps ) , EasyMock . capture ( capturedConsumerProps ) , EasyMock . capture ( capturedConsumedCallback ) , EasyMock . capture ( capturedNewTopic ) , EasyMock . capture ( capturedAdminProps ) ) . andReturn ( storeLog ) ; } private void expectStart ( final List < ConsumerRecord < byte [ ] , byte [ ] > > preexistingRecords ) throws Exception { storeLog . start ( ) ; PowerMock . expectLastCall ( ) . andAnswer ( new IAnswer < Object > ( ) { @ Override public Object answer ( ) throws Throwable { for ( ConsumerRecord < byte [ ] , byte [ ] > rec : preexistingRecords ) capturedConsumedCallback . getValue ( ) . onCompletion ( null , rec ) ; return null ; } } ) ; } private void expectStop ( ) { storeLog . stop ( ) ; PowerMock . expectLastCall ( ) ; } private static ByteBuffer buffer ( String v ) { return ByteBuffer . wrap ( v . getBytes ( ) ) ; } }",No
"public class AttributeInfo extends FeatureInfo { static final long serialVersionUID = - 2511626862303972143L ; protected String displayName = null ; protected String getMethod = null ; protected String setMethod = null ; protected boolean readable = true ; protected boolean writeable = true ; protected boolean is = false ; public String getDisplayName ( ) { return ( this . displayName ) ; } public void setDisplayName ( String displayName ) { this . displayName = displayName ; } public String getGetMethod ( ) { if ( getMethod == null ) getMethod = getMethodName ( getName ( ) , true , isIs ( ) ) ; return ( this . getMethod ) ; } public void setGetMethod ( String getMethod ) { this . getMethod = getMethod ; } public boolean isIs ( ) { return ( this . is ) ; } public void setIs ( boolean is ) { this . is = is ; } public boolean isReadable ( ) { return ( this . readable ) ; } public void setReadable ( boolean readable ) { this . readable = readable ; } public String getSetMethod ( ) { if ( setMethod == null ) setMethod = getMethodName ( getName ( ) , false , false ) ; return ( this . setMethod ) ; } public void setSetMethod ( String setMethod ) { this . setMethod = setMethod ; } public boolean isWriteable ( ) { return ( this . writeable ) ; } public void setWriteable ( boolean writeable ) { this . writeable = writeable ; } MBeanAttributeInfo createAttributeInfo ( ) { if ( info == null ) { info = new MBeanAttributeInfo ( getName ( ) , getType ( ) , getDescription ( ) , isReadable ( ) , isWriteable ( ) , false ) ; } return ( MBeanAttributeInfo ) info ; } private String getMethodName ( String name , boolean getter , boolean is ) { StringBuilder sb = new StringBuilder ( ) ; if ( getter ) { if ( is ) sb . append ( ""is"" ) ; else sb . append ( ""get"" ) ; } else sb . append ( ""set"" ) ; sb . append ( Character . toUpperCase ( name . charAt ( 0 ) ) ) ; sb . append ( name . substring ( 1 ) ) ; return ( sb . toString ( ) ) ; } }",Smelly
@ Alternative public class AlternativeComponent implements IAlternative { },No
"public class PolicyBasedChaosMonkey extends ChaosMonkey { private static final Logger LOG = LoggerFactory . getLogger ( PolicyBasedChaosMonkey . class ) ; private static final long ONE_SEC = 1000 ; private static final long FIVE_SEC = 5 * ONE_SEC ; private static final long ONE_MIN = 60 * ONE_SEC ; public static final long TIMEOUT = ONE_MIN ; final IntegrationTestingUtility util ; public PolicyBasedChaosMonkey ( IntegrationTestingUtility util , Policy ... policies ) { this . util = util ; this . policies = policies ; } public PolicyBasedChaosMonkey ( IntegrationTestingUtility util , Collection < Policy > policies ) { this . util = util ; this . policies = policies . toArray ( new Policy [ policies . size ( ) ] ) ; } public static < T > T selectRandomItem ( T [ ] items ) { return items [ RandomUtils . nextInt ( 0 , items . length ) ] ; } public static < T > T selectWeightedRandomItem ( List < Pair < T , Integer > > items ) { int totalWeight = 0 ; for ( Pair < T , Integer > pair : items ) { totalWeight += pair . getSecond ( ) ; } int cutoff = RandomUtils . nextInt ( 0 , totalWeight ) ; int cummulative = 0 ; T item = null ; for ( int i = 0 ; i < items . size ( ) ; i ++ ) { int curWeight = items . get ( i ) . getSecond ( ) ; if ( cutoff < cummulative + curWeight ) { item = items . get ( i ) . getFirst ( ) ; break ; } cummulative += curWeight ; } return item ; } public static < T > List < T > selectRandomItems ( T [ ] items , float ratio ) { int remaining = ( int ) Math . ceil ( items . length * ratio ) ; List < T > selectedItems = new ArrayList < > ( remaining ) ; for ( int i = 0 ; i < items . length && remaining > 0 ; i ++ ) { if ( RandomUtils . nextFloat ( ) < ( ( float ) remaining / ( items . length - i ) ) ) { selectedItems . add ( items [ i ] ) ; remaining -- ; } } return selectedItems ; } private Policy [ ] policies ; private Thread [ ] monkeyThreads ; @ Override public void start ( ) throws Exception { monkeyThreads = new Thread [ policies . length ] ; for ( int i = 0 ; i < policies . length ; i ++ ) { policies [ i ] . init ( new Policy . PolicyContext ( this . util ) ) ; Thread monkeyThread = new Thread ( policies [ i ] , ""ChaosMonkey"" ) ; monkeyThread . start ( ) ; monkeyThreads [ i ] = monkeyThread ; } } @ Override public void stop ( String why ) { if ( policies == null ) { return ; } for ( Policy policy : policies ) { policy . stop ( why ) ; } } @ Override public boolean isStopped ( ) { return policies [ 0 ] . isStopped ( ) ; } @ Override public void waitForStop ( ) throws InterruptedException { if ( monkeyThreads == null ) { return ; } for ( Thread monkeyThread : monkeyThreads ) { monkeyThread . join ( ) ; } } @ Override public boolean isDestructive ( ) { return true ; } }",No
"public class GatewayProfileResource extends AppCatAbstractResource { private final static Logger logger = LoggerFactory . getLogger ( GatewayProfileResource . class ) ; private String gatewayID ; private Timestamp createdTime ; private Timestamp updatedTime ; private String credentialStoreToken ; private String identityServerTenant ; private String identityServerPwdCredToken ; public Timestamp getCreatedTime ( ) { return createdTime ; } public void setCreatedTime ( Timestamp createdTime ) { this . createdTime = createdTime ; } public Timestamp getUpdatedTime ( ) { return updatedTime ; } public void setUpdatedTime ( Timestamp updatedTime ) { this . updatedTime = updatedTime ; } public String getCredentialStoreToken ( ) { return credentialStoreToken ; } public void setCredentialStoreToken ( String credentialStoreToken ) { this . credentialStoreToken = credentialStoreToken ; } public String getIdentityServerTenant ( ) { return identityServerTenant ; } public void setIdentityServerTenant ( String identityServerTenant ) { this . identityServerTenant = identityServerTenant ; } public String getIdentityServerPwdCredToken ( ) { return identityServerPwdCredToken ; } public void setIdentityServerPwdCredToken ( String identityServerPwdCredToken ) { this . identityServerPwdCredToken = identityServerPwdCredToken ; } public void remove ( Object identifier ) throws AppCatalogException { EntityManager em = null ; try { em = AppCatalogJPAUtils . getEntityManager ( ) ; em . getTransaction ( ) . begin ( ) ; AppCatalogQueryGenerator generator = new AppCatalogQueryGenerator ( GATEWAY_PROFILE ) ; generator . setParameter ( GatewayProfileConstants . GATEWAY_ID , identifier ) ; Query q = generator . deleteQuery ( em ) ; q . executeUpdate ( ) ; em . getTransaction ( ) . commit ( ) ; if ( em . isOpen ( ) ) { if ( em . getTransaction ( ) . isActive ( ) ) { em . getTransaction ( ) . rollback ( ) ; } em . close ( ) ; } } catch ( ApplicationSettingsException e ) { logger . error ( e . getMessage ( ) , e ) ; throw new AppCatalogException ( e ) ; } finally { if ( em != null && em . isOpen ( ) ) { if ( em . getTransaction ( ) . isActive ( ) ) { em . getTransaction ( ) . rollback ( ) ; } em . close ( ) ; } } } public AppCatalogResource get ( Object identifier ) throws AppCatalogException { EntityManager em = null ; try { em = AppCatalogJPAUtils . getEntityManager ( ) ; em . getTransaction ( ) . begin ( ) ; AppCatalogQueryGenerator generator = new AppCatalogQueryGenerator ( GATEWAY_PROFILE ) ; generator . setParameter ( GatewayProfileConstants . GATEWAY_ID , identifier ) ; Query q = generator . selectQuery ( em ) ; GatewayProfile gatewayProfile = ( GatewayProfile ) q . getSingleResult ( ) ; GatewayProfileResource gatewayProfileResource = ( GatewayProfileResource ) AppCatalogJPAUtils . getResource ( AppCatalogResourceType . GATEWAY_PROFILE , gatewayProfile ) ; em . getTransaction ( ) . commit ( ) ; if ( em . isOpen ( ) ) { if ( em . getTransaction ( ) . isActive ( ) ) { em . getTransaction ( ) . rollback ( ) ; } em . close ( ) ; } return gatewayProfileResource ; } catch ( ApplicationSettingsException e ) { logger . error ( e . getMessage ( ) , e ) ; throw new AppCatalogException ( e ) ; } finally { if ( em != null && em . isOpen ( ) ) { if ( em . getTransaction ( ) . isActive ( ) ) { em . getTransaction ( ) . rollback ( ) ; } em . close ( ) ; } } } public List < AppCatalogResource > get ( String fieldName , Object value ) throws AppCatalogException { List < AppCatalogResource > gatewayProfileResources = new ArrayList < AppCatalogResource > ( ) ; EntityManager em = null ; try { em = AppCatalogJPAUtils . getEntityManager ( ) ; em . getTransaction ( ) . begin ( ) ; Query q ; AppCatalogQueryGenerator generator = new AppCatalogQueryGenerator ( GATEWAY_PROFILE ) ; List results ; if ( fieldName . equals ( GatewayProfileConstants . GATEWAY_ID ) ) { generator . setParameter ( GatewayProfileConstants . GATEWAY_ID , value ) ; q = generator . selectQuery ( em ) ; results = q . getResultList ( ) ; if ( results . size ( ) != 0 ) { for ( Object result : results ) { GatewayProfile gatewayProfile = ( GatewayProfile ) result ; GatewayProfileResource gatewayProfileResource = ( GatewayProfileResource ) AppCatalogJPAUtils . getResource ( AppCatalogResourceType . GATEWAY_PROFILE , gatewayProfile ) ; gatewayProfileResources . add ( gatewayProfileResource ) ; } } } else { em . getTransaction ( ) . commit ( ) ; if ( em . isOpen ( ) ) { if ( em . getTransaction ( ) . isActive ( ) ) { em . getTransaction ( ) . rollback ( ) ; } em . close ( ) ; } logger . error ( ""Unsupported field name for Gateway Profile resource."" , new IllegalArgumentException ( ) ) ; throw new IllegalArgumentException ( ""Unsupported field name for Gateway Profile resource."" ) ; } em . getTransaction ( ) . commit ( ) ; if ( em . isOpen ( ) ) { if ( em . getTransaction ( ) . isActive ( ) ) { em . getTransaction ( ) . rollback ( ) ; } em . close ( ) ; } } catch ( Exception e ) { logger . error ( e . getMessage ( ) , e ) ; throw new AppCatalogException ( e ) ; } finally { if ( em != null && em . isOpen ( ) ) { if ( em . getTransaction ( ) . isActive ( ) ) { em . getTransaction ( ) . rollback ( ) ; } em . close ( ) ; } } return gatewayProfileResources ; } @ Override public List < AppCatalogResource > getAll ( ) throws AppCatalogException { List < AppCatalogResource > resourceList = new ArrayList < AppCatalogResource > ( ) ; EntityManager em = null ; try { em = AppCatalogJPAUtils . getEntityManager ( ) ; em . getTransaction ( ) . begin ( ) ; AppCatalogQueryGenerator generator = new AppCatalogQueryGenerator ( GATEWAY_PROFILE ) ; Query q = generator . selectQuery ( em ) ; List results = q . getResultList ( ) ; if ( results . size ( ) != 0 ) { for ( Object result : results ) { GatewayProfile gatewayProfile = ( GatewayProfile ) result ; GatewayProfileResource gatewayProfileResource = ( GatewayProfileResource ) AppCatalogJPAUtils . getResource ( AppCatalogResourceType . GATEWAY_PROFILE , gatewayProfile ) ; resourceList . add ( gatewayProfileResource ) ; } } em . getTransaction ( ) . commit ( ) ; if ( em . isOpen ( ) ) { if ( em . getTransaction ( ) . isActive ( ) ) { em . getTransaction ( ) . rollback ( ) ; } em . close ( ) ; } } catch ( Exception e ) { logger . error ( e . getMessage ( ) , e ) ; throw new AppCatalogException ( e ) ; } finally { if ( em != null && em . isOpen ( ) ) { if ( em . getTransaction ( ) . isActive ( ) ) { em . getTransaction ( ) . rollback ( ) ; } em . close ( ) ; } } return resourceList ; } @ Override public List < String > getAllIds ( ) throws AppCatalogException { return null ; } public List < String > getIds ( String fieldName , Object value ) throws AppCatalogException { List < String > gatewayProfileResourceIDs = new ArrayList < String > ( ) ; EntityManager em = null ; try { em = AppCatalogJPAUtils . getEntityManager ( ) ; em . getTransaction ( ) . begin ( ) ; Query q ; AppCatalogQueryGenerator generator = new AppCatalogQueryGenerator ( GATEWAY_PROFILE ) ; List results ; if ( fieldName . equals ( GatewayProfileConstants . GATEWAY_ID ) ) { generator . setParameter ( GatewayProfileConstants . GATEWAY_ID , value ) ; q = generator . selectQuery ( em ) ; results = q . getResultList ( ) ; if ( results . size ( ) != 0 ) { for ( Object result : results ) { GatewayProfile gatewayProfile = ( GatewayProfile ) result ; gatewayProfileResourceIDs . add ( gatewayProfile . getGatewayID ( ) ) ; } } } else { em . getTransaction ( ) . commit ( ) ; if ( em . isOpen ( ) ) { if ( em . getTransaction ( ) . isActive ( ) ) { em . getTransaction ( ) . rollback ( ) ; } em . close ( ) ; } logger . error ( ""Unsupported field name for Gateway Profile resource."" , new IllegalArgumentException ( ) ) ; throw new IllegalArgumentException ( ""Unsupported field name for Gateway Profile resource."" ) ; } em . getTransaction ( ) . commit ( ) ; if ( em . isOpen ( ) ) { if ( em . getTransaction ( ) . isActive ( ) ) { em . getTransaction ( ) . rollback ( ) ; } em . close ( ) ; } } catch ( Exception e ) { logger . error ( e . getMessage ( ) , e ) ; throw new AppCatalogException ( e ) ; } finally { if ( em != null && em . isOpen ( ) ) { if ( em . getTransaction ( ) . isActive ( ) ) { em . getTransaction ( ) . rollback ( ) ; } em . close ( ) ; } } return gatewayProfileResourceIDs ; } public void save ( ) throws AppCatalogException { EntityManager em = null ; try { em = AppCatalogJPAUtils . getEntityManager ( ) ; GatewayProfile existingGatewayProfile = em . find ( GatewayProfile . class , gatewayID ) ; if ( em . isOpen ( ) ) { if ( em . getTransaction ( ) . isActive ( ) ) { em . getTransaction ( ) . rollback ( ) ; } em . close ( ) ; } em = AppCatalogJPAUtils . getEntityManager ( ) ; em . getTransaction ( ) . begin ( ) ; if ( existingGatewayProfile != null ) { existingGatewayProfile . setUpdateTime ( AiravataUtils . getCurrentTimestamp ( ) ) ; if ( credentialStoreToken != null ) { existingGatewayProfile . setCredentialStoreToken ( credentialStoreToken ) ; } if ( identityServerTenant != null ) { existingGatewayProfile . setIdentityServerTenant ( identityServerTenant ) ; } if ( identityServerPwdCredToken != null ) { existingGatewayProfile . setIdentityServerPwdCredToken ( identityServerPwdCredToken ) ; } em . merge ( existingGatewayProfile ) ; } else { GatewayProfile gatewayProfile = new GatewayProfile ( ) ; gatewayProfile . setGatewayID ( gatewayID ) ; gatewayProfile . setCreationTime ( AiravataUtils . getCurrentTimestamp ( ) ) ; if ( credentialStoreToken != null ) { gatewayProfile . setCredentialStoreToken ( credentialStoreToken ) ; } if ( identityServerTenant != null ) { gatewayProfile . setIdentityServerTenant ( identityServerTenant ) ; } if ( identityServerPwdCredToken != null ) { gatewayProfile . setIdentityServerPwdCredToken ( identityServerPwdCredToken ) ; } em . persist ( gatewayProfile ) ; } em . getTransaction ( ) . commit ( ) ; if ( em . isOpen ( ) ) { if ( em . getTransaction ( ) . isActive ( ) ) { em . getTransaction ( ) . rollback ( ) ; } em . close ( ) ; } } catch ( Exception e ) { logger . error ( e . getMessage ( ) , e ) ; throw new AppCatalogException ( e ) ; } finally { if ( em != null && em . isOpen ( ) ) { if ( em . getTransaction ( ) . isActive ( ) ) { em . getTransaction ( ) . rollback ( ) ; } em . close ( ) ; } } } public boolean isExists ( Object identifier ) throws AppCatalogException { EntityManager em = null ; try { em = AppCatalogJPAUtils . getEntityManager ( ) ; GatewayProfile gatewayProfile = em . find ( GatewayProfile . class , identifier ) ; if ( em . isOpen ( ) ) { if ( em . getTransaction ( ) . isActive ( ) ) { em . getTransaction ( ) . rollback ( ) ; } em . close ( ) ; } return gatewayProfile != null ; } catch ( ApplicationSettingsException e ) { logger . error ( e . getMessage ( ) , e ) ; throw new AppCatalogException ( e ) ; } finally { if ( em != null && em . isOpen ( ) ) { if ( em . getTransaction ( ) . isActive ( ) ) { em . getTransaction ( ) . rollback ( ) ; } em . close ( ) ; } } } public String getGatewayID ( ) { return gatewayID ; } public void setGatewayID ( String gatewayID ) { this . gatewayID = gatewayID ; } }",Smelly
"public class ReleaseRollbackAction extends ContinuumActionSupport { private WorkingDirectoryService workingDirectoryService ; private int projectId ; private String releaseId ; private String projectGroupName = """" ; private String releaseGoal ; public String execute ( ) throws Exception { try { checkBuildProjectInGroupAuthorization ( getProjectGroupName ( ) ) ; } catch ( AuthorizationRequiredException e ) { return REQUIRES_AUTHORIZATION ; } if ( getContinuum ( ) . getConfiguration ( ) . isDistributedBuildEnabled ( ) ) { DistributedReleaseManager releaseManager = getContinuum ( ) . getDistributedReleaseManager ( ) ; try { releaseManager . releaseRollback ( releaseId , projectId ) ; } catch ( BuildAgentConfigurationException e ) { List < String > args = new ArrayList < String > ( ) ; args . add ( e . getMessage ( ) ) ; addActionError ( getText ( ""releaseRollback.error"" , args ) ) ; return ERROR ; } } else { ContinuumReleaseManager releaseManager = getContinuum ( ) . getReleaseManager ( ) ; ContinuumReleaseManagerListener listener = new DefaultReleaseManagerListener ( ) ; listener . setUsername ( getPrincipal ( ) ) ; Project project = getContinuum ( ) . getProject ( projectId ) ; releaseManager . rollback ( releaseId , workingDirectoryService . getWorkingDirectory ( project ) . getPath ( ) , listener ) ; while ( listener . getState ( ) != ContinuumReleaseManagerListener . FINISHED ) { try { Thread . sleep ( 1000 ) ; } catch ( InterruptedException e ) { } } AuditLog event = new AuditLog ( ""Release id="" + releaseId , AuditLogConstants . ROLLBACK_RELEASE ) ; event . setCategory ( AuditLogConstants . PROJECT ) ; event . setCurrentUser ( getPrincipal ( ) ) ; event . log ( ) ; releaseManager . getPreparedReleases ( ) . remove ( releaseId ) ; } return SUCCESS ; } public String warn ( ) throws Exception { try { checkBuildProjectInGroupAuthorization ( getProjectGroupName ( ) ) ; } catch ( AuthorizationRequiredException e ) { return REQUIRES_AUTHORIZATION ; } return SUCCESS ; } public int getProjectId ( ) { return projectId ; } public void setProjectId ( int projectId ) { this . projectId = projectId ; } public String getReleaseId ( ) { return releaseId ; } public void setReleaseId ( String releaseId ) { this . releaseId = releaseId ; } public String getProjectGroupName ( ) throws ContinuumException { if ( StringUtils . isEmpty ( projectGroupName ) ) { projectGroupName = getContinuum ( ) . getProjectGroupByProjectId ( projectId ) . getName ( ) ; } return projectGroupName ; } public String getReleaseGoal ( ) { return releaseGoal ; } public void setReleaseGoal ( String releaseGoal ) { this . releaseGoal = releaseGoal ; } }",Smelly
"@ Slf4j public class InMemoryDelayedDeliveryTracker implements DelayedDeliveryTracker , TimerTask { private final TripleLongPriorityQueue priorityQueue = new TripleLongPriorityQueue ( ) ; private final PersistentDispatcherMultipleConsumers dispatcher ; private final Timer timer ; private Timeout timeout ; private long currentTimeoutTarget ; private final long tickTimeMillis ; private final Clock clock ; InMemoryDelayedDeliveryTracker ( PersistentDispatcherMultipleConsumers dispatcher , Timer timer , long tickTimeMillis ) { this ( dispatcher , timer , tickTimeMillis , Clock . systemUTC ( ) ) ; } InMemoryDelayedDeliveryTracker ( PersistentDispatcherMultipleConsumers dispatcher , Timer timer , long tickTimeMillis , Clock clock ) { this . dispatcher = dispatcher ; this . timer = timer ; this . tickTimeMillis = tickTimeMillis ; this . clock = clock ; } @ Override public boolean addMessage ( long ledgerId , long entryId , long deliveryAt ) { long now = clock . millis ( ) ; if ( log . isDebugEnabled ( ) ) { log . debug ( ""[{}] Add message {}:{} -- Delivery in {} ms "" , dispatcher . getName ( ) , ledgerId , entryId , deliveryAt - now ) ; } if ( deliveryAt < now ) { return false ; } priorityQueue . add ( deliveryAt , ledgerId , entryId ) ; updateTimer ( ) ; return true ; } @ Override public boolean hasMessageAvailable ( ) { return ! priorityQueue . isEmpty ( ) && priorityQueue . peekN1 ( ) <= clock . millis ( ) ; } @ Override public Set < PositionImpl > getScheduledMessages ( int maxMessages ) { int n = maxMessages ; Set < PositionImpl > positions = new TreeSet < > ( ) ; long now = clock . millis ( ) ; long cutoffTime = now + tickTimeMillis ; while ( n > 0 && ! priorityQueue . isEmpty ( ) ) { long timestamp = priorityQueue . peekN1 ( ) ; if ( timestamp > cutoffTime ) { break ; } long ledgerId = priorityQueue . peekN2 ( ) ; long entryId = priorityQueue . peekN3 ( ) ; positions . add ( new PositionImpl ( ledgerId , entryId ) ) ; priorityQueue . pop ( ) ; -- n ; } if ( log . isDebugEnabled ( ) ) { log . debug ( ""[{}] Get scheduled messags - found {}"" , dispatcher . getName ( ) , positions . size ( ) ) ; } updateTimer ( ) ; return positions ; } @ Override public long getNumberOfDelayedMessages ( ) { return priorityQueue . size ( ) ; } private void updateTimer ( ) { if ( priorityQueue . isEmpty ( ) ) { if ( timeout != null ) { currentTimeoutTarget = - 1 ; timeout . cancel ( ) ; timeout = null ; } return ; } long timestamp = priorityQueue . peekN1 ( ) ; if ( timestamp == currentTimeoutTarget ) { return ; } if ( timeout != null ) { timeout . cancel ( ) ; } long delayMillis = timestamp - clock . millis ( ) ; if ( log . isDebugEnabled ( ) ) { log . debug ( ""[{}] Start timer in {} millis"" , dispatcher . getName ( ) , delayMillis ) ; } if ( delayMillis < 0 ) { return ; } currentTimeoutTarget = timestamp ; timeout = timer . newTimeout ( this , delayMillis , TimeUnit . MILLISECONDS ) ; } @ Override public void run ( Timeout timeout ) throws Exception { if ( log . isDebugEnabled ( ) ) { log . info ( ""[{}] Timer triggered"" , dispatcher . getName ( ) ) ; } if ( timeout . isCancelled ( ) ) { return ; } synchronized ( dispatcher ) { currentTimeoutTarget = - 1 ; timeout = null ; dispatcher . readMoreEntries ( ) ; } } @ Override public void close ( ) { priorityQueue . close ( ) ; if ( timeout != null ) { timeout . cancel ( ) ; } } }",No
"@ Entity @ NamedQueries ( { @ NamedQuery ( name = ""getMetaById"" , query = ""SELECT c FROM RecordingMetaData c WHERE c.id = :id"" ) , @ NamedQuery ( name = ""getMetaByRecording"" , query = ""SELECT c FROM RecordingMetaData c WHERE c.recording.id = :recordingId AND c.deleted = false"" ) , @ NamedQuery ( name = ""getAudioMetaByRecording"" , query = ""SELECT c FROM RecordingMetaData c WHERE c.recording.id = :recordingId "" + ""AND c.screenData = false AND c.streamStatus <> :none AND (c.audioOnly = true OR (c.audioOnly = false AND c.videoOnly = false))"" ) , @ NamedQuery ( name = ""getScreenMetaByRecording"" , query = ""SELECT c FROM RecordingMetaData c WHERE c.recording.id = :recordingId"" + "" AND c.screenData = true"" ) } ) @ Table ( name = ""recording_metadata"" ) @ Root ( name = ""flvrecordingmetadata"" ) public class RecordingMetaData extends HistoricalEntity { private static final long serialVersionUID = 1L ; @ XmlType ( namespace = ""org.apache.openmeetings.record.meta"" ) public enum Status { NONE , STARTED , STOPPING , STOPPED } @ Id @ GeneratedValue ( strategy = GenerationType . IDENTITY ) @ Column ( name = ""id"" ) @ Element ( name = ""flvRecordingMetaDataId"" , data = true , required = false ) private Long id ; @ ManyToOne ( fetch = FetchType . EAGER ) @ JoinColumn ( name = ""recording_id"" , nullable = true ) @ ForeignKey ( enabled = true ) private Recording recording ; @ Column ( name = ""record_start"" ) @ Element ( data = true ) private Date recordStart ; @ Column ( name = ""record_end"" ) @ Element ( data = true , required = false ) private Date recordEnd ; @ Column ( name = ""stream_name"" ) @ Element ( data = true ) private String streamName ; @ Column ( name = ""is_audio_only"" , nullable = false ) @ Element ( name = ""isAudioOnly"" , data = true ) private boolean audioOnly ; @ Column ( name = ""is_video_only"" , nullable = false ) @ Element ( name = ""isVideoOnly"" , data = true ) private boolean videoOnly ; @ Column ( name = ""is_screen_data"" , nullable = false ) @ Element ( name = ""isScreenData"" , data = true ) private boolean screenData ; @ Column ( name = ""full_wav_audio_data"" ) @ Element ( data = true , required = false ) private String fullWavAudioData ; @ Column ( name = ""audio_is_valid"" , nullable = false ) @ Element ( name = ""audioIsValid"" , data = true , required = false ) private boolean audioValid ; @ Column ( name = ""interiew_pod_id"" ) @ Element ( data = true , required = false ) private Integer interiewPodId ; @ Column ( name = ""stream_status"" ) @ Enumerated ( EnumType . STRING ) private Status streamStatus = Status . NONE ; @ Override public Long getId ( ) { return id ; } @ Override public void setId ( Long id ) { this . id = id ; } public Recording getRecording ( ) { return recording ; } public void setRecording ( Recording recording ) { this . recording = recording ; } public Date getRecordStart ( ) { return recordStart ; } public void setRecordStart ( Date recordStart ) { this . recordStart = recordStart ; } public Date getRecordEnd ( ) { return recordEnd ; } public void setRecordEnd ( Date recordEnd ) { this . recordEnd = recordEnd ; } public boolean isAudioOnly ( ) { return audioOnly ; } public void setAudioOnly ( boolean audioOnly ) { this . audioOnly = audioOnly ; } public boolean isVideoOnly ( ) { return videoOnly ; } public void setVideoOnly ( boolean videoOnly ) { this . videoOnly = videoOnly ; } public boolean isScreenData ( ) { return screenData ; } public void setScreenData ( boolean screenData ) { this . screenData = screenData ; } public String getStreamName ( ) { return streamName ; } public void setStreamName ( String streamName ) { this . streamName = streamName ; } public String getFullWavAudioData ( ) { return fullWavAudioData ; } public void setFullWavAudioData ( String fullWavAudioData ) { this . fullWavAudioData = fullWavAudioData ; } public boolean isAudioValid ( ) { return audioValid ; } public void setAudioValid ( boolean audioValid ) { this . audioValid = audioValid ; } public Integer getInteriewPodId ( ) { return interiewPodId ; } public void setInteriewPodId ( Integer interiewPodId ) { this . interiewPodId = interiewPodId ; } public Status getStreamStatus ( ) { return streamStatus ; } public void setStreamStatus ( Status status ) { this . streamStatus = status ; } }",Smelly
"public class TestAll extends TestCase { public static Test suite ( ) { TestSuite suite = new TestSuite ( ""javax.jcr.version tests"" ) ; suite . addTestSuite ( VersionTest . class ) ; suite . addTestSuite ( VersionHistoryTest . class ) ; suite . addTestSuite ( VersionStorageTest . class ) ; suite . addTestSuite ( VersionLabelTest . class ) ; suite . addTestSuite ( CheckoutTest . class ) ; suite . addTestSuite ( CheckinTest . class ) ; suite . addTestSuite ( CopyTest . class ) ; suite . addTestSuite ( VersionGraphTest . class ) ; suite . addTestSuite ( RemoveVersionTest . class ) ; suite . addTestSuite ( RestoreTest . class ) ; suite . addTestSuite ( WorkspaceRestoreTest . class ) ; suite . addTestSuite ( OnParentVersionAbortTest . class ) ; suite . addTestSuite ( OnParentVersionComputeTest . class ) ; suite . addTestSuite ( OnParentVersionCopyTest . class ) ; suite . addTestSuite ( OnParentVersionIgnoreTest . class ) ; suite . addTestSuite ( OnParentVersionInitializeTest . class ) ; suite . addTestSuite ( GetReferencesNodeTest . class ) ; suite . addTestSuite ( GetPredecessorsTest . class ) ; suite . addTestSuite ( GetCreatedTest . class ) ; suite . addTestSuite ( GetContainingHistoryTest . class ) ; suite . addTestSuite ( GetVersionableUUIDTest . class ) ; suite . addTestSuite ( SessionMoveVersionExceptionTest . class ) ; suite . addTestSuite ( WorkspaceMoveVersionExceptionTest . class ) ; suite . addTestSuite ( MergeCancelMergeTest . class ) ; suite . addTestSuite ( MergeCheckedoutSubNodeTest . class ) ; suite . addTestSuite ( MergeDoneMergeTest . class ) ; suite . addTestSuite ( MergeNodeIteratorTest . class ) ; suite . addTestSuite ( MergeNodeTest . class ) ; suite . addTestSuite ( MergeShallowTest . class ) ; suite . addTestSuite ( MergeActivityTest . class ) ; suite . addTestSuite ( MergeNonVersionableSubNodeTest . class ) ; suite . addTestSuite ( MergeSubNodeTest . class ) ; suite . addTestSuite ( ActivitiesTest . class ) ; suite . addTestSuite ( ConfigurationsTest . class ) ; return suite ; } }",No
"@ XmlRootElement ( name = ""instantiateTemplateRequestEntity"" ) public class InstantiateTemplateRequestEntity extends Entity { private Double originX ; private Double originY ; private String templateId ; private String encodingVersion ; private FlowSnippetDTO snippet ; private Boolean disconnectedNodeAcknowledged ; @ ApiModelProperty ( value = ""The identifier of the template."" ) public String getTemplateId ( ) { return templateId ; } public void setTemplateId ( String templateId ) { this . templateId = templateId ; } @ ApiModelProperty ( value = ""The x coordinate of the origin of the bounding box where the new components will be placed."" ) public Double getOriginX ( ) { return originX ; } public void setOriginX ( Double originX ) { this . originX = originX ; } @ ApiModelProperty ( value = ""The y coordinate of the origin of the bounding box where the new components will be placed."" ) public Double getOriginY ( ) { return originY ; } public void setOriginY ( Double originY ) { this . originY = originY ; } @ ApiModelProperty ( value = ""The encoding version of the flow snippet. If not specified, this is automatically "" + ""populated by the node receiving the user request. If the snippet is specified, the version "" + ""will be the latest. If the snippet is not specified, the version will come from the underlying "" + ""template. These details need to be replicated throughout the cluster to ensure consistency."" ) public String getEncodingVersion ( ) { return encodingVersion ; } public void setEncodingVersion ( String encodingVersion ) { this . encodingVersion = encodingVersion ; } @ ApiModelProperty ( value = ""A flow snippet of the template contents. If not specified, this is automatically "" + ""populated by the node receiving the user request. These details need to be replicated "" + ""throughout the cluster to ensure consistency."" ) public FlowSnippetDTO getSnippet ( ) { return snippet ; } public void setSnippet ( FlowSnippetDTO snippet ) { this . snippet = snippet ; } @ ApiModelProperty ( value = ""Acknowledges that this node is disconnected to allow for mutable requests to proceed."" ) public Boolean isDisconnectedNodeAcknowledged ( ) { return disconnectedNodeAcknowledged ; } public void setDisconnectedNodeAcknowledged ( Boolean disconnectedNodeAcknowledged ) { this . disconnectedNodeAcknowledged = disconnectedNodeAcknowledged ; } }",Smelly
" public static class GenDataProcessor extends SimpleMRProcessor { private static final Logger LOG = LoggerFactory . getLogger ( GenDataProcessor . class ) ; long streamOutputFileSize ; long hashOutputFileSize ; float overlapApprox = 0.2f ; public GenDataProcessor ( ProcessorContext context ) { super ( context ) ; } public static byte [ ] createConfiguration ( long streamOutputFileSize , long hashOutputFileSize ) throws IOException { NonSyncByteArrayOutputStream bos = new NonSyncByteArrayOutputStream ( ) ; NonSyncDataOutputStream dos = new NonSyncDataOutputStream ( bos ) ; dos . writeLong ( streamOutputFileSize ) ; dos . writeLong ( hashOutputFileSize ) ; dos . close ( ) ; bos . close ( ) ; return bos . toByteArray ( ) ; } @ Override public void initialize ( ) throws Exception { byte [ ] payload = getContext ( ) . getUserPayload ( ) . deepCopyAsArray ( ) ; NonSyncByteArrayInputStream bis = new NonSyncByteArrayInputStream ( payload ) ; DataInputStream dis = new DataInputStream ( bis ) ; streamOutputFileSize = dis . readLong ( ) ; hashOutputFileSize = dis . readLong ( ) ; LOG . info ( ""Initialized with largeFileTargetSize="" + streamOutputFileSize + "", smallFileTragetSize="" + hashOutputFileSize ) ; dis . close ( ) ; bis . close ( ) ; } @ Override public void run ( ) throws Exception { Preconditions . checkState ( getInputs ( ) . size ( ) == 0 ) ; Preconditions . checkState ( getOutputs ( ) . size ( ) == 3 ) ; KeyValueWriter streamOutputWriter = ( KeyValueWriter ) getOutputs ( ) . get ( STREAM_OUTPUT_NAME ) . getWriter ( ) ; KeyValueWriter hashOutputWriter = ( KeyValueWriter ) getOutputs ( ) . get ( HASH_OUTPUT_NAME ) . getWriter ( ) ; KeyValueWriter expectedOutputWriter = ( KeyValueWriter ) getOutputs ( ) . get ( EXPECTED_OUTPUT_NAME ) . getWriter ( ) ; float fileSizeFraction = hashOutputFileSize / ( float ) streamOutputFileSize ; Preconditions . checkState ( fileSizeFraction > 0.0f && fileSizeFraction <= 1.0f ) ; int mod = 1 ; int extraKeysMod = 0 ; if ( fileSizeFraction > overlapApprox ) { mod = ( int ) ( 1 / overlapApprox ) ; extraKeysMod = ( int ) ( 1 / ( fileSizeFraction - overlapApprox ) ) ; } else { mod = ( int ) ( 1 / fileSizeFraction ) ; } LOG . info ( ""Using mod="" + mod + "", extraKeysMod="" + extraKeysMod ) ; long count = 0 ; long sizeLarge = 0 ; long sizeSmall = 0 ; long numLargeFileKeys = 0 ; long numSmallFileKeys = 0 ; long numExpectedKeys = 0 ; while ( sizeLarge < streamOutputFileSize ) { String str = createOverlapString ( 13 , count ) ; Text text = new Text ( str ) ; int size = text . getLength ( ) ; streamOutputWriter . write ( text , NullWritable . get ( ) ) ; sizeLarge += size ; numLargeFileKeys ++ ; if ( count % mod == 0 ) { hashOutputWriter . write ( text , NullWritable . get ( ) ) ; sizeSmall += size ; numSmallFileKeys ++ ; expectedOutputWriter . write ( text , NullWritable . get ( ) ) ; numExpectedKeys ++ ; } if ( extraKeysMod != 0 && count % extraKeysMod == 0 ) { String nStr = createNonOverlaptring ( 13 , count ) ; Text nText = new Text ( nStr ) ; hashOutputWriter . write ( nText , NullWritable . get ( ) ) ; sizeSmall += nText . getLength ( ) ; numSmallFileKeys ++ ; } count ++ ; } LOG . info ( ""OutputStats: "" + ""largeFileNumKeys="" + numLargeFileKeys + "", smallFileNumKeys="" + numSmallFileKeys + "", expFileNumKeys="" + numExpectedKeys + "", largeFileSize="" + sizeLarge + "", smallFileSize="" + sizeSmall ) ; } private String createOverlapString ( int size , long count ) { StringBuilder sb = new StringBuilder ( ) ; Random random = new Random ( ) ; for ( int i = 0 ; i < size ; i ++ ) { int r = random . nextInt ( Integer . MAX_VALUE ) % 26 ; sb . append ( ( char ) ( 97 + r ) ) ; } sb . append ( ""_"" ) . append ( getContext ( ) . getTaskIndex ( ) ) . append ( ""_"" ) . append ( count ) ; return sb . toString ( ) ; } private String createNonOverlaptring ( int size , long count ) { StringBuilder sb = new StringBuilder ( ) ; Random random = new Random ( ) ; for ( int i = 0 ; i < size ; i ++ ) { int r = random . nextInt ( Integer . MAX_VALUE ) % 26 ; sb . append ( ( char ) ( 65 + r ) ) ; } sb . append ( ""_"" ) . append ( getContext ( ) . getTaskIndex ( ) ) . append ( ""_"" ) . append ( count ) ; return sb . toString ( ) ; } ",No
"public class Java2DPainter extends AbstractIFPainter < IFDocumentHandler > { protected IFContext ifContext ; protected FontInfo fontInfo ; private final GraphicsPainter graphicsPainter ; private final BorderPainter borderPainter ; protected Java2DGraphicsState g2dState ; private Stack < Java2DGraphicsState > g2dStateStack = new Stack < Java2DGraphicsState > ( ) ; public Java2DPainter ( Graphics2D g2d , IFContext context , FontInfo fontInfo ) { this ( g2d , context , fontInfo , new Java2DDocumentHandler ( ) ) ; } public Java2DPainter ( Graphics2D g2d , IFContext context , FontInfo fontInfo , IFDocumentHandler documentHandler ) { this ( g2d , context , fontInfo , null , documentHandler ) ; } public Java2DPainter ( Graphics2D g2d , IFContext context , FontInfo fontInfo , IFState state ) { this ( g2d , context , fontInfo , state , new Java2DDocumentHandler ( ) ) ; } public Java2DPainter ( Graphics2D g2d , IFContext context , FontInfo fontInfo , IFState state , IFDocumentHandler documentHandler ) { super ( documentHandler ) ; this . ifContext = context ; if ( state != null ) { this . state = state . push ( ) ; } else { this . state = IFState . create ( ) ; } this . fontInfo = fontInfo ; this . g2dState = new Java2DGraphicsState ( g2d , fontInfo , g2d . getTransform ( ) ) ; graphicsPainter = new Java2DGraphicsPainter ( this ) ; this . borderPainter = new BorderPainter ( graphicsPainter ) ; } public IFContext getContext ( ) { return this . ifContext ; } protected FontInfo getFontInfo ( ) { return this . fontInfo ; } protected Java2DGraphicsState getState ( ) { return this . g2dState ; } public void startViewport ( AffineTransform transform , Dimension size , Rectangle clipRect ) throws IFException { saveGraphicsState ( ) ; try { concatenateTransformationMatrix ( transform ) ; if ( clipRect != null ) { clipRect ( clipRect ) ; } } catch ( IOException ioe ) { throw new IFException ( ""I/O error in startViewport()"" , ioe ) ; } } public void endViewport ( ) throws IFException { restoreGraphicsState ( ) ; } public void startGroup ( AffineTransform transform , String layer ) throws IFException { saveGraphicsState ( ) ; try { concatenateTransformationMatrix ( transform ) ; } catch ( IOException ioe ) { throw new IFException ( ""I/O error in startGroup()"" , ioe ) ; } } public void endGroup ( ) throws IFException { restoreGraphicsState ( ) ; } public void drawImage ( String uri , Rectangle rect ) throws IFException { drawImageUsingURI ( uri , rect ) ; } protected RenderingContext createRenderingContext ( ) { Java2DRenderingContext java2dContext = new Java2DRenderingContext ( getUserAgent ( ) , g2dState . getGraph ( ) , getFontInfo ( ) ) ; return java2dContext ; } public void drawImage ( Document doc , Rectangle rect ) throws IFException { drawImageUsingDocument ( doc , rect ) ; } public void clipRect ( Rectangle rect ) throws IFException { getState ( ) . updateClip ( rect ) ; } public void clipBackground ( Rectangle rect , BorderProps bpsBefore , BorderProps bpsAfter , BorderProps bpsStart , BorderProps bpsEnd ) throws IFException { } public void fillRect ( Rectangle rect , Paint fill ) throws IFException { if ( fill == null ) { return ; } if ( rect . width != 0 && rect . height != 0 ) { g2dState . updatePaint ( fill ) ; g2dState . getGraph ( ) . fill ( rect ) ; } } public void drawBorderRect ( Rectangle rect , BorderProps top , BorderProps bottom , BorderProps left , BorderProps right ) throws IFException { if ( top != null || bottom != null || left != null || right != null ) { this . borderPainter . drawBorders ( rect , top , bottom , left , right , null ) ; } } public void drawLine ( Point start , Point end , int width , Color color , RuleStyle style ) throws IFException { try { this . graphicsPainter . drawLine ( start , end , width , color , style ) ; } catch ( IOException ioe ) { throw new IFException ( ""Unexpected error drawing line"" , ioe ) ; } } public void drawText ( int x , int y , int letterSpacing , int wordSpacing , int [ ] [ ] dp , String text ) throws IFException { g2dState . updateColor ( state . getTextColor ( ) ) ; FontTriplet triplet = new FontTriplet ( state . getFontFamily ( ) , state . getFontStyle ( ) , state . getFontWeight ( ) ) ; Font font = getFontInfo ( ) . getFontInstance ( triplet , state . getFontSize ( ) ) ; g2dState . updateFont ( font . getFontName ( ) , state . getFontSize ( ) * 1000 ) ; Graphics2D g2d = this . g2dState . getGraph ( ) ; GlyphVector gv = Java2DUtil . createGlyphVector ( text , g2d , font , fontInfo ) ; Point2D cursor = new Point2D . Float ( 0 , 0 ) ; int l = text . length ( ) ; if ( dp != null && dp [ 0 ] != null && ( dp [ 0 ] [ 0 ] != 0 || dp [ 0 ] [ 1 ] != 0 ) ) { cursor . setLocation ( cursor . getX ( ) + dp [ 0 ] [ 0 ] , cursor . getY ( ) - dp [ 0 ] [ 1 ] ) ; gv . setGlyphPosition ( 0 , cursor ) ; } int currentIdx = 0 ; for ( int i = 0 ; i < l ; i ++ ) { int orgChar = text . codePointAt ( i ) ; i += CharUtilities . incrementIfNonBMP ( orgChar ) ; float xGlyphAdjust = 0 ; float yGlyphAdjust = 0 ; int cw = font . getCharWidth ( orgChar ) ; if ( ( wordSpacing != 0 ) && CharUtilities . isAdjustableSpace ( orgChar ) ) { xGlyphAdjust += wordSpacing ; } xGlyphAdjust += letterSpacing ; if ( dp != null && i < dp . length && dp [ i ] != null ) { xGlyphAdjust += dp [ i ] [ 2 ] - dp [ i ] [ 0 ] ; yGlyphAdjust += dp [ i ] [ 3 ] - dp [ i ] [ 1 ] ; } if ( dp != null && i < dp . length - 1 && dp [ i + 1 ] != null ) { xGlyphAdjust += dp [ i + 1 ] [ 0 ] ; yGlyphAdjust += dp [ i + 1 ] [ 1 ] ; } cursor . setLocation ( cursor . getX ( ) + cw + xGlyphAdjust , cursor . getY ( ) - yGlyphAdjust ) ; gv . setGlyphPosition ( ++ currentIdx , cursor ) ; } g2d . drawGlyphVector ( gv , x , y ) ; } protected void saveGraphicsState ( ) { g2dStateStack . push ( g2dState ) ; g2dState = new Java2DGraphicsState ( g2dState ) ; } protected void restoreGraphicsState ( ) { g2dState . dispose ( ) ; g2dState = g2dStateStack . pop ( ) ; } private void concatenateTransformationMatrix ( AffineTransform transform ) throws IOException { g2dState . transform ( transform ) ; } }",No
 public class WorkImpl implements Work { private Runnable job ; public WorkImpl ( Runnable job ) { this . job = job ; } public void run ( ) { job . run ( ) ; } public void release ( ) { } ,No
" public static class NullableDateReader extends NullableConvertedReader < NullableDateVector > { NullableDateReader ( ParquetRecordReader parentReader , int allocateSize , ColumnDescriptor descriptor , ColumnChunkMetaData columnChunkMetaData , boolean fixedLength , NullableDateVector v , SchemaElement schemaElement ) throws ExecutionSetupException { super ( parentReader , allocateSize , descriptor , columnChunkMetaData , fixedLength , v , schemaElement ) ; } @ Override void addNext ( int start , int index ) { int intValue ; if ( usingDictionary ) { intValue = pageReader . dictionaryValueReader . readInteger ( ) ; } else { intValue = readIntLittleEndian ( bytebuf , start ) ; } valueVec . getMutator ( ) . set ( index , intValue * ( long ) DateTimeConstants . MILLIS_PER_DAY ) ; } ",No
"public class AddressingConstantsImpl implements AddressingConstants { private static final ResourceBundle BUNDLE = BundleUtils . getBundle ( AddressingConstantsImpl . class ) ; public AddressingConstantsImpl ( ) { } public String getNamespaceURI ( ) { return Names . WSA_NAMESPACE_NAME ; } public String getWSDLNamespaceURI ( ) { return Names . WSA_NAMESPACE_WSDL_NAME ; } public QName getWSDLExtensibilityQName ( ) { return Names . WSAW_USING_ADDRESSING_QNAME ; } public QName getWSDLActionQName ( ) { return Names . WSAW_ACTION_QNAME ; } public String getAnonymousURI ( ) { return Names . WSA_ANONYMOUS_ADDRESS ; } public String getNoneURI ( ) { return Names . WSA_NONE_ADDRESS ; } public QName getFromQName ( ) { return Names . WSA_FROM_QNAME ; } public QName getToQName ( ) { return Names . WSA_TO_QNAME ; } public QName getReplyToQName ( ) { return Names . WSA_REPLYTO_QNAME ; } public QName getFaultToQName ( ) { return Names . WSA_FAULTTO_QNAME ; } public QName getActionQName ( ) { return Names . WSA_ACTION_QNAME ; } public QName getMessageIDQName ( ) { return Names . WSA_MESSAGEID_QNAME ; } public String getRelationshipReply ( ) { return Names . WSA_RELATIONSHIP_REPLY ; } public QName getRelatesToQName ( ) { return Names . WSA_RELATESTO_QNAME ; } public QName getRelationshipTypeQName ( ) { return Names . WSA_RELATIONSHIPTYPE_QNAME ; } public QName getMetadataQName ( ) { return Names . WSA_METADATA_QNAME ; } public QName getAddressQName ( ) { return Names . WSA_ADDRESS_QNAME ; } public String getPackageName ( ) { return PackageUtils . getPackageName ( AddressingConstantsImpl . class ) ; } public QName getIsReferenceParameterQName ( ) { return Names . WSA_IS_REFERENCE_PARAMETER_QNAME ; } public QName getInvalidMapQName ( ) { return Names . INVALID_MAP_QNAME ; } public QName getMapRequiredQName ( ) { return Names . MAP_REQUIRED_QNAME ; } public QName getDestinationUnreachableQName ( ) { return Names . DESTINATION_UNREACHABLE_QNAME ; } public QName getActionNotSupportedQName ( ) { return Names . ACTION_NOT_SUPPORTED_QNAME ; } public QName getEndpointUnavailableQName ( ) { return Names . ENDPOINT_UNAVAILABLE_QNAME ; } public String getDefaultFaultAction ( ) { return Names . WSA_DEFAULT_FAULT_ACTION ; } public String getActionNotSupportedText ( ) { return BUNDLE . getString ( ""ACTION_NOT_SUPPORTED_MSG"" ) ; } public String getDestinationUnreachableText ( ) { return BUNDLE . getString ( ""DESTINATION_UNREACHABLE_MSG"" ) ; } public String getEndpointUnavailableText ( ) { return BUNDLE . getString ( ""ENDPOINT_UNAVAILABLE_MSG"" ) ; } public String getInvalidMapText ( ) { return BUNDLE . getString ( ""INVALID_MAP_MSG"" ) ; } public String getMapRequiredText ( ) { return BUNDLE . getString ( ""MAP_REQUIRED_MSG"" ) ; } public String getDuplicateMessageIDText ( ) { return BUNDLE . getString ( ""DUPLICATE_MESSAGE_ID_MSG"" ) ; } }",Smelly
"@ Entity @ Table ( name = ""\""entity c\"""" , schema = ""\""delim id\"""" ) @ SecondaryTable ( name = ""\""sec join table\"""" , schema = ""\""delim id\"""" , pkJoinColumns = @ PrimaryKeyJoinColumn ( name = ""\""entity c\"""" , referencedColumnName = ""\""c id\"""" ) ) public class EntityC { @ Id @ Column ( name = ""\""c id\"""" ) private int id ; private String name ; @ Column ( table = ""\""sec join table\"""" ) private String secName ; @ ManyToMany @ JoinTable ( name = ""\""c d\"""" , schema = ""\""delim id\"""" ) private Collection < EntityD > entityDs = new HashSet < EntityD > ( ) ; @ OneToOne @ JoinColumn ( name = ""\""entd2 id\"""" , referencedColumnName = ""\""entityD2 id\"""" ) private EntityD2 entityD2 ; @ ManyToMany @ JoinTable ( name = ""\""m jtbl\"""" , schema = ""\""delim id\"""" ) @ MapKeyJoinColumn ( name = ""map_ed3"" , referencedColumnName = ""\""entityD3 id\"""" ) Map < EntityD3 , EntityD4 > map = new HashMap < EntityD3 , EntityD4 > ( ) ; @ ManyToMany @ JoinTable ( name = ""\""m2 jtbl\"""" , schema = ""\""delim id\"""" ) @ MapKeyJoinColumn ( name = ""\""map ed4\"""" , referencedColumnName = ""\""entityD4 id\"""" ) Map < EntityD4 , EntityD3 > map2 = new HashMap < EntityD4 , EntityD3 > ( ) ; public EntityC ( ) { } public EntityC ( int id ) { this . id = id ; } public int getId ( ) { return id ; } public void setId ( int id ) { this . id = id ; } public String getName ( ) { return name ; } public void setName ( String name ) { this . name = name ; } public Collection < EntityD > getEntityDs ( ) { return entityDs ; } public void setEntityDs ( Collection < EntityD > entityDs ) { this . entityDs = entityDs ; } public void addEntityD ( EntityD entityD ) { entityDs . add ( entityD ) ; } public EntityD2 getEntityD2 ( ) { return entityD2 ; } public void setEntityD2 ( EntityD2 entityD2 ) { this . entityD2 = entityD2 ; } public Map < EntityD3 , EntityD4 > getMap ( ) { return map ; } public void setMap ( Map < EntityD3 , EntityD4 > map ) { this . map = map ; } public void addMapValues ( EntityD3 key , EntityD4 value ) { map . put ( key , value ) ; } public Map < EntityD4 , EntityD3 > getMap2 ( ) { return map2 ; } public void setMap2 ( Map < EntityD4 , EntityD3 > map2 ) { this . map2 = map2 ; } public void addMap2Values ( EntityD4 key , EntityD3 value ) { map2 . put ( key , value ) ; } public String getSecName ( ) { return secName ; } public void setSecName ( String secName ) { this . secName = secName ; } }",Smelly
"public final class TraversalUtil { private TraversalUtil ( ) { } public static final < S , E > E apply ( final Traverser . Admin < S > traverser , final Traversal . Admin < S , E > traversal ) { final Traverser . Admin < S > split = traverser . split ( ) ; split . setSideEffects ( traversal . getSideEffects ( ) ) ; split . setBulk ( 1l ) ; traversal . reset ( ) ; traversal . addStart ( split ) ; try { return traversal . next ( ) ; } catch ( final NoSuchElementException e ) { throw new IllegalArgumentException ( ""The provided traverser does not map to a value: "" + split + ""->"" + traversal ) ; } finally { CloseableIterator . closeIterator ( traversal ) ; } } public static final < S , E > Iterator < E > applyAll ( final Traverser . Admin < S > traverser , final Traversal . Admin < S , E > traversal ) { final Traverser . Admin < S > split = traverser . split ( ) ; split . setSideEffects ( traversal . getSideEffects ( ) ) ; split . setBulk ( 1l ) ; traversal . reset ( ) ; traversal . addStart ( split ) ; return traversal ; } public static final < S , E > boolean test ( final Traverser . Admin < S > traverser , final Traversal . Admin < S , E > traversal , E end ) { if ( null == end ) return TraversalUtil . test ( traverser , traversal ) ; final Traverser . Admin < S > split = traverser . split ( ) ; split . setSideEffects ( traversal . getSideEffects ( ) ) ; split . setBulk ( 1l ) ; traversal . reset ( ) ; traversal . addStart ( split ) ; final Step < ? , E > endStep = traversal . getEndStep ( ) ; boolean result = false ; while ( traversal . hasNext ( ) ) { if ( endStep . next ( ) . get ( ) . equals ( end ) ) { result = true ; break ; } } CloseableIterator . closeIterator ( traversal ) ; return result ; } public static final < S , E > E applyNullable ( final Traverser . Admin < S > traverser , final Traversal . Admin < S , E > traversal ) { return null == traversal ? ( E ) traverser . get ( ) : TraversalUtil . apply ( traverser , traversal ) ; } public static final < S , E > boolean test ( final Traverser . Admin < S > traverser , final Traversal . Admin < S , E > traversal ) { final Traverser . Admin < S > split = traverser . split ( ) ; split . setSideEffects ( traversal . getSideEffects ( ) ) ; split . setBulk ( 1l ) ; traversal . reset ( ) ; traversal . addStart ( split ) ; boolean val = traversal . hasNext ( ) ; CloseableIterator . closeIterator ( traversal ) ; return val ; } public static final < S , E > E apply ( final S start , final Traversal . Admin < S , E > traversal ) { traversal . reset ( ) ; traversal . addStart ( traversal . getTraverserGenerator ( ) . generate ( start , traversal . getStartStep ( ) , 1l ) ) ; try { return traversal . next ( ) ; } catch ( final NoSuchElementException e ) { throw new IllegalArgumentException ( ""The provided start does not map to a value: "" + start + ""->"" + traversal ) ; } finally { CloseableIterator . closeIterator ( traversal ) ; } } public static final < S , E > Iterator < E > applyAll ( final S start , final Traversal . Admin < S , E > traversal ) { traversal . reset ( ) ; traversal . addStart ( traversal . getTraverserGenerator ( ) . generate ( start , traversal . getStartStep ( ) , 1l ) ) ; return traversal ; } public static final < S , E > boolean test ( final S start , final Traversal . Admin < S , E > traversal , final E end ) { if ( null == end ) return TraversalUtil . test ( start , traversal ) ; traversal . reset ( ) ; traversal . addStart ( traversal . getTraverserGenerator ( ) . generate ( start , traversal . getStartStep ( ) , 1l ) ) ; final Step < ? , E > endStep = traversal . getEndStep ( ) ; boolean result = false ; while ( traversal . hasNext ( ) ) { if ( endStep . next ( ) . get ( ) . equals ( end ) ) { result = true ; break ; } } CloseableIterator . closeIterator ( traversal ) ; return result ; } public static final < S , E > E applyNullable ( final S start , final Traversal . Admin < S , E > traversal ) { return null == traversal ? ( E ) start : TraversalUtil . apply ( start , traversal ) ; } public static final < S , E > boolean test ( final S start , final Traversal . Admin < S , E > traversal ) { traversal . reset ( ) ; traversal . addStart ( traversal . getTraverserGenerator ( ) . generate ( start , traversal . getStartStep ( ) , 1l ) ) ; boolean result = traversal . hasNext ( ) ; CloseableIterator . closeIterator ( traversal ) ; return result ; } }",No
"public class MultiNamedAttributeEvaluator extends MultiAttributeEvaluator { private final List < String > attributeNames ; private final int evaluationType ; private int evaluationCount = 0 ; private List < String > matchingAttributeNames = null ; public MultiNamedAttributeEvaluator ( final List < String > attributeNames , final int evaluationType ) { this . attributeNames = attributeNames ; this . evaluationType = evaluationType ; } @ Override public QueryResult < String > evaluate ( final Map < String , String > attributes ) { matchingAttributeNames = new ArrayList < > ( attributeNames ) ; if ( matchingAttributeNames . size ( ) <= evaluationCount ) { return new StringQueryResult ( null ) ; } return new StringQueryResult ( attributes . get ( matchingAttributeNames . get ( evaluationCount ++ ) ) ) ; } @ Override public int getEvaluationsRemaining ( ) { return matchingAttributeNames . size ( ) - evaluationCount ; } @ Override public Evaluator < ? > getSubjectEvaluator ( ) { return null ; } @ Override public int getEvaluationType ( ) { return evaluationType ; } @ Override public Evaluator < ? > getLogicEvaluator ( ) { return this ; } public List < String > getAttributeNames ( ) { return attributeNames ; } }",Smelly
 public static class SegmentReaderStats { public long start = - 1L ; public long end = - 1L ; public long generated = - 1L ; public long fetched = - 1L ; public long fetchErrors = - 1L ; public long parsed = - 1L ; public long parseErrors = - 1L ; ,Smelly
"public class LiteralValuePath extends RecordPathSegment { private final FieldValue fieldValue ; LiteralValuePath ( final RecordPathSegment parentPath , final Object value , final boolean absolute ) { super ( String . valueOf ( value ) , parentPath , absolute ) ; this . fieldValue = new StandardFieldValue ( value , null , null ) ; } @ Override public Stream < FieldValue > evaluate ( final RecordPathEvaluationContext context ) { return Stream . of ( fieldValue ) ; } }",No
" public static class ContextWrapper implements ServletContext { ServletContext context ; File contextRoot ; public ContextWrapper ( ServletContext context , File contextRoot ) { this . context = context ; this . contextRoot = contextRoot ; } public ServletContext getContext ( String param ) { return this . context . getContext ( param ) ; } public int getMajorVersion ( ) { return this . context . getMajorVersion ( ) ; } public int getMinorVersion ( ) { return this . context . getMinorVersion ( ) ; } public String getMimeType ( String param ) { return this . context . getMimeType ( param ) ; } public URL getResource ( String path ) throws MalformedURLException { File file = new File ( this . contextRoot , path ) ; if ( file . exists ( ) ) { URL result = file . toURL ( ) ; return result ; } else { return null ; } } public InputStream getResourceAsStream ( String path ) { try { URL url = getResource ( path ) ; return ( url == null ) ? null : url . openStream ( ) ; } catch ( Exception e ) { this . context . log ( ""getResourceAsStream("" + path + "") failed"" , e ) ; return null ; } } public RequestDispatcher getRequestDispatcher ( String param ) { return this . context . getRequestDispatcher ( param ) ; } public RequestDispatcher getNamedDispatcher ( String param ) { return this . context . getNamedDispatcher ( param ) ; } public Servlet getServlet ( String param ) throws ServletException { return this . context . getServlet ( param ) ; } public Enumeration getServlets ( ) { return this . context . getServlets ( ) ; } public Enumeration getServletNames ( ) { return this . context . getServletNames ( ) ; } public void log ( String msg ) { this . context . log ( msg ) ; } public void log ( Exception ex , String msg ) { this . context . log ( ex , msg ) ; } public void log ( String msg , Throwable thr ) { this . context . log ( msg , thr ) ; } public String getRealPath ( String path ) { String result = this . contextRoot + path ; return result ; } public String getServerInfo ( ) { return this . context . getServerInfo ( ) ; } public String getInitParameter ( String param ) { return this . context . getInitParameter ( param ) ; } public Enumeration getInitParameterNames ( ) { return this . context . getInitParameterNames ( ) ; } public Object getAttribute ( String param ) { Object result = this . context . getAttribute ( param ) ; return result ; } public Enumeration getAttributeNames ( ) { return this . context . getAttributeNames ( ) ; } public void setAttribute ( String name , Object value ) { this . context . setAttribute ( name , value ) ; } public void removeAttribute ( String name ) { this . context . removeAttribute ( name ) ; } public Set getResourcePaths ( String param ) { return null ; } public String getServletContextName ( ) { return ""Cocoon context"" ; } } ",Smelly
 static class PDFVTElementMaker extends ElementMapping . Maker { public FONode make ( FONode parent ) { return new PDFVTElement ( parent ) ; } ,No
"public class SQLAnalyzer extends SQLParserBaseVisitor < Expr > { public Expr parse ( String sql ) throws SQLSyntaxError { final ANTLRInputStream input = new ANTLRInputStream ( sql ) ; final SQLLexer lexer = new SQLLexer ( input ) ; lexer . removeErrorListeners ( ) ; lexer . addErrorListener ( new SQLErrorListener ( ) ) ; final CommonTokenStream tokens = new CommonTokenStream ( lexer ) ; final SQLParser parser = new SQLParser ( tokens ) ; parser . removeErrorListeners ( ) ; parser . addErrorListener ( new SQLErrorListener ( ) ) ; parser . setBuildParseTree ( true ) ; SqlContext context ; try { context = parser . sql ( ) ; } catch ( SQLParseError e ) { throw new SQLSyntaxError ( e . getMessage ( ) ) ; } catch ( Throwable t ) { throw new TajoInternalError ( t . getMessage ( ) ) ; } return visitSql ( context ) ; } private static boolean checkIfExist ( Object obj ) { return obj != null ; } @ Override public Expr visitSql ( SqlContext ctx ) { Expr statement = visit ( ctx . statement ( ) ) ; if ( checkIfExist ( ctx . explain_clause ( ) ) ) { return new Explain ( statement , checkIfExist ( ctx . explain_clause ( ) . GLOBAL ( ) ) ) ; } else { return statement ; } } public Expr visitSession_statement ( @ NotNull Session_statementContext ctx ) { if ( checkIfExist ( ctx . CATALOG ( ) ) ) { return new SetSession ( SessionVars . CURRENT_DATABASE . name ( ) , ctx . dbname . getText ( ) ) ; } else if ( checkIfExist ( ctx . name ) ) { String value ; if ( checkIfExist ( ctx . boolean_literal ( ) ) ) { value = ctx . boolean_literal ( ) . getText ( ) ; } else if ( checkIfExist ( ctx . Character_String_Literal ( ) ) ) { value = stripQuote ( ctx . Character_String_Literal ( ) . getText ( ) ) ; } else if ( checkIfExist ( ctx . signed_numerical_literal ( ) ) ) { value = ctx . signed_numerical_literal ( ) . getText ( ) ; } else { value = null ; } return new SetSession ( ctx . name . getText ( ) . toUpperCase ( ) , value ) ; } else if ( checkIfExist ( ctx . TIME ( ) ) && checkIfExist ( ctx . ZONE ( ) ) ) { String value ; if ( checkIfExist ( ctx . Character_String_Literal ( ) ) ) { value = stripQuote ( ctx . Character_String_Literal ( ) . getText ( ) ) ; } else if ( checkIfExist ( ctx . signed_numerical_literal ( ) ) ) { value = ctx . signed_numerical_literal ( ) . getText ( ) ; } else { value = null ; } return new SetSession ( SessionVars . TIMEZONE . name ( ) , value ) ; } else { throw new TajoInternalError ( ""Invalid session statement"" ) ; } } @ Override public Expr visitNon_join_query_expression ( Non_join_query_expressionContext ctx ) { Expr current = visitNon_join_query_term ( ctx . non_join_query_term ( ) ) ; if ( ctx . getChildCount ( ) == 1 ) { return current ; } OpType operatorType ; Expr left ; for ( int i = 1 ; i < ctx . getChildCount ( ) ; i ++ ) { int idx = i ; boolean distinct = true ; if ( ctx . getChild ( idx ) instanceof TerminalNode ) { if ( ( ( TerminalNode ) ctx . getChild ( idx ) ) . getSymbol ( ) . getType ( ) == UNION ) { operatorType = OpType . Union ; } else { operatorType = OpType . Except ; } idx ++ ; if ( ctx . getChild ( idx ) instanceof TerminalNode ) { if ( ( ( TerminalNode ) ctx . getChild ( idx ) ) . getSymbol ( ) . getType ( ) == ALL ) { distinct = false ; } idx ++ ; } Query_termContext queryTermContext = ( Query_termContext ) ctx . getChild ( idx ) ; Expr right = visitQuery_term ( queryTermContext ) ; left = current ; current = new SetOperation ( operatorType , left , right , distinct ) ; i = idx ; } } return current ; } @ Override public Expr visitNon_join_query_term ( Non_join_query_termContext ctx ) { Expr current = visitNon_join_query_primary ( ctx . non_join_query_primary ( ) ) ; Expr left ; for ( int i = 1 ; i < ctx . getChildCount ( ) ; ) { int idx = i ; boolean distinct = true ; if ( ctx . getChild ( idx ) instanceof TerminalNode ) { if ( ( ( TerminalNode ) ctx . getChild ( idx ) ) . getSymbol ( ) . getType ( ) == INTERSECT ) { idx ++ ; } if ( ctx . getChild ( idx ) instanceof TerminalNode ) { if ( ( ( TerminalNode ) ctx . getChild ( idx ) ) . getSymbol ( ) . getType ( ) == ALL ) { distinct = false ; idx ++ ; } } Query_primaryContext queryPrimaryContext = ( Query_primaryContext ) ctx . getChild ( idx ) ; Expr right = visitQuery_primary ( queryPrimaryContext ) ; left = current ; current = new SetOperation ( OpType . Intersect , left , right , distinct ) ; i += idx ; } } return current ; } @ Override public Expr visitNon_join_query_primary ( Non_join_query_primaryContext ctx ) { if ( ctx . simple_table ( ) != null ) { return visitSimple_table ( ctx . simple_table ( ) ) ; } else if ( ctx . non_join_query_expression ( ) != null ) { return visitNon_join_query_expression ( ctx . non_join_query_expression ( ) ) ; } return visitChildren ( ctx ) ; } @ Override public Expr visitQuery_specification ( Query_specificationContext ctx ) { Expr current = null ; if ( ctx . table_expression ( ) != null ) { current = visitFrom_clause ( ctx . table_expression ( ) . from_clause ( ) ) ; if ( ctx . table_expression ( ) . where_clause ( ) != null ) { Selection selection = visitWhere_clause ( ctx . table_expression ( ) . where_clause ( ) ) ; selection . setChild ( current ) ; current = selection ; } if ( ctx . table_expression ( ) . groupby_clause ( ) != null ) { Aggregation aggregation = visitGroupby_clause ( ctx . table_expression ( ) . groupby_clause ( ) ) ; aggregation . setChild ( current ) ; current = aggregation ; if ( ctx . table_expression ( ) . having_clause ( ) != null ) { Expr havingCondition = visitBoolean_value_expression ( ctx . table_expression ( ) . having_clause ( ) . boolean_value_expression ( ) ) ; Having having = new Having ( havingCondition ) ; having . setChild ( current ) ; current = having ; } } if ( ctx . table_expression ( ) . orderby_clause ( ) != null ) { Sort sort = visitOrderby_clause ( ctx . table_expression ( ) . orderby_clause ( ) ) ; sort . setChild ( current ) ; current = sort ; } if ( checkIfExist ( ctx . table_expression ( ) . window_clause ( ) ) ) { Window window = visitWindow_clause ( ctx . table_expression ( ) . window_clause ( ) ) ; window . setChild ( current ) ; current = window ; } if ( ctx . table_expression ( ) . limit_clause ( ) != null ) { Limit limit = visitLimit_clause ( ctx . table_expression ( ) . limit_clause ( ) ) ; limit . setChild ( current ) ; current = limit ; } } Projection projection = visitSelect_list ( ctx . select_list ( ) ) ; if ( ctx . set_qualifier ( ) != null && ctx . set_qualifier ( ) . DISTINCT ( ) != null ) { projection . setDistinct ( ) ; } if ( current != null ) { projection . setChild ( current ) ; } current = projection ; return current ; } @ Override public Projection visitSelect_list ( Select_listContext ctx ) { Projection projection = new Projection ( ) ; NamedExpr [ ] targets = new NamedExpr [ ctx . select_sublist ( ) . size ( ) ] ; for ( int i = 0 ; i < targets . length ; i ++ ) { targets [ i ] = visitSelect_sublist ( ctx . select_sublist ( i ) ) ; } projection . setNamedExprs ( targets ) ; return projection ; } @ Override public NamedExpr visitSelect_sublist ( Select_sublistContext ctx ) { if ( ctx . qualified_asterisk ( ) != null ) { return visitQualified_asterisk ( ctx . qualified_asterisk ( ) ) ; } else { return visitDerived_column ( ctx . derived_column ( ) ) ; } } @ Override public RelationList visitFrom_clause ( From_clauseContext ctx ) { Expr [ ] relations = new Expr [ ctx . table_reference_list ( ) . table_reference ( ) . size ( ) ] ; for ( int i = 0 ; i < relations . length ; i ++ ) { relations [ i ] = visitTable_reference ( ctx . table_reference_list ( ) . table_reference ( i ) ) ; } return new RelationList ( relations ) ; } @ Override public Selection visitWhere_clause ( Where_clauseContext ctx ) { return new Selection ( visitSearch_condition ( ctx . search_condition ( ) ) ) ; } @ Override public Aggregation visitGroupby_clause ( Groupby_clauseContext ctx ) { Aggregation clause = new Aggregation ( ) ; if ( ctx . grouping_element_list ( ) . grouping_element ( ) . get ( 0 ) . empty_grouping_set ( ) == null ) { int elementSize = ctx . grouping_element_list ( ) . grouping_element ( ) . size ( ) ; ArrayList < GroupElement > groups = new ArrayList < GroupElement > ( elementSize + 1 ) ; ArrayList < Expr > ordinaryExprs = null ; int groupSize = 1 ; groups . add ( null ) ; for ( int i = 0 ; i < elementSize ; i ++ ) { Grouping_elementContext element = ctx . grouping_element_list ( ) . grouping_element ( ) . get ( i ) ; if ( element . ordinary_grouping_set ( ) != null ) { if ( ordinaryExprs == null ) { ordinaryExprs = new ArrayList < Expr > ( ) ; } Collections . addAll ( ordinaryExprs , getRowValuePredicandsFromOrdinaryGroupingSet ( element . ordinary_grouping_set ( ) ) ) ; } else if ( element . rollup_list ( ) != null ) { groupSize ++ ; groups . add ( new GroupElement ( GroupType . Rollup , getRowValuePredicandsFromOrdinaryGroupingSetList ( element . rollup_list ( ) . c ) ) ) ; } else if ( element . cube_list ( ) != null ) { groupSize ++ ; groups . add ( new GroupElement ( GroupType . Cube , getRowValuePredicandsFromOrdinaryGroupingSetList ( element . cube_list ( ) . c ) ) ) ; } } if ( ordinaryExprs != null ) { groups . set ( 0 , new GroupElement ( GroupType . OrdinaryGroup , ordinaryExprs . toArray ( new Expr [ ordinaryExprs . size ( ) ] ) ) ) ; clause . setGroups ( groups . subList ( 0 , groupSize ) . toArray ( new GroupElement [ groupSize ] ) ) ; } else if ( groupSize > 1 ) { clause . setGroups ( groups . subList ( 1 , groupSize ) . toArray ( new GroupElement [ groupSize - 1 ] ) ) ; } } return clause ; } @ Override public WindowFunctionExpr visitWindow_function ( @ NotNull Window_functionContext context ) { WindowFunctionExpr windowFunction = null ; Window_function_typeContext functionType = context . window_function_type ( ) ; GeneralSetFunctionExpr functionBody ; if ( checkIfExist ( functionType . rank_function_type ( ) ) ) { Rank_function_typeContext rankFunction = functionType . rank_function_type ( ) ; if ( checkIfExist ( rankFunction . RANK ( ) ) ) { functionBody = new GeneralSetFunctionExpr ( ""rank"" , false , new Expr [ ] { } ) ; } else if ( checkIfExist ( rankFunction . DENSE_RANK ( ) ) ) { functionBody = new GeneralSetFunctionExpr ( ""dense_rank"" , false , new Expr [ ] { } ) ; } else if ( checkIfExist ( rankFunction . PERCENT_RANK ( ) ) ) { functionBody = new GeneralSetFunctionExpr ( ""percent_rank"" , false , new Expr [ ] { } ) ; } else { functionBody = new GeneralSetFunctionExpr ( ""cume_dist"" , false , new Expr [ ] { } ) ; } } else if ( checkIfExist ( functionType . ROW_NUMBER ( ) ) ) { functionBody = new GeneralSetFunctionExpr ( ""row_number"" , false , new Expr [ ] { } ) ; } else if ( checkIfExist ( functionType . FIRST_VALUE ( ) ) ) { functionBody = new GeneralSetFunctionExpr ( ""first_value"" , false , new Expr [ ] { visitColumn_reference ( functionType . column_reference ( ) ) } ) ; } else if ( checkIfExist ( functionType . LAST_VALUE ( ) ) ) { functionBody = new GeneralSetFunctionExpr ( ""last_value"" , false , new Expr [ ] { visitColumn_reference ( functionType . column_reference ( ) ) } ) ; } else if ( checkIfExist ( functionType . LAG ( ) ) ) { if ( checkIfExist ( functionType . numeric_value_expression ( ) ) ) { if ( checkIfExist ( functionType . common_value_expression ( ) ) ) { functionBody = new GeneralSetFunctionExpr ( ""lag"" , false , new Expr [ ] { visitColumn_reference ( functionType . column_reference ( ) ) , visitNumeric_value_expression ( functionType . numeric_value_expression ( ) ) , visitCommon_value_expression ( functionType . common_value_expression ( ) ) } ) ; } else { functionBody = new GeneralSetFunctionExpr ( ""lag"" , false , new Expr [ ] { visitColumn_reference ( functionType . column_reference ( ) ) , visitNumeric_value_expression ( functionType . numeric_value_expression ( ) ) } ) ; } } else { functionBody = new GeneralSetFunctionExpr ( ""lag"" , false , new Expr [ ] { visitColumn_reference ( functionType . column_reference ( ) ) } ) ; } } else if ( checkIfExist ( functionType . LEAD ( ) ) ) { if ( checkIfExist ( functionType . numeric_value_expression ( ) ) ) { if ( checkIfExist ( functionType . common_value_expression ( ) ) ) { functionBody = new GeneralSetFunctionExpr ( ""lead"" , false , new Expr [ ] { visitColumn_reference ( functionType . column_reference ( ) ) , visitNumeric_value_expression ( functionType . numeric_value_expression ( ) ) , visitCommon_value_expression ( functionType . common_value_expression ( ) ) } ) ; } else { functionBody = new GeneralSetFunctionExpr ( ""lead"" , false , new Expr [ ] { visitColumn_reference ( functionType . column_reference ( ) ) , visitNumeric_value_expression ( functionType . numeric_value_expression ( ) ) } ) ; } } else { functionBody = new GeneralSetFunctionExpr ( ""lead"" , false , new Expr [ ] { visitColumn_reference ( functionType . column_reference ( ) ) } ) ; } } else { functionBody = visitAggregate_function ( functionType . aggregate_function ( ) ) ; } windowFunction = new WindowFunctionExpr ( functionBody ) ; Window_name_or_specificationContext windowNameOrSpec = context . window_name_or_specification ( ) ; if ( checkIfExist ( windowNameOrSpec . window_name ( ) ) ) { windowFunction . setWindowName ( windowNameOrSpec . window_name ( ) . getText ( ) ) ; } else { windowFunction . setWindowSpec ( buildWindowSpec ( windowNameOrSpec . window_specification ( ) ) ) ; } return windowFunction ; } @ Override public Window visitWindow_clause ( @ NotNull Window_clauseContext ctx ) { Window . WindowDefinition [ ] definitions = new Window . WindowDefinition [ ctx . window_definition_list ( ) . window_definition ( ) . size ( ) ] ; for ( int i = 0 ; i < definitions . length ; i ++ ) { Window_definitionContext windowDefinitionContext = ctx . window_definition_list ( ) . window_definition ( i ) ; String windowName = buildIdentifier ( windowDefinitionContext . window_name ( ) . identifier ( ) ) ; WindowSpec windowSpec = buildWindowSpec ( windowDefinitionContext . window_specification ( ) ) ; definitions [ i ] = new Window . WindowDefinition ( windowName , windowSpec ) ; } return new Window ( definitions ) ; } public WindowSpec buildWindowSpec ( Window_specificationContext ctx ) { WindowSpec windowSpec = new WindowSpec ( ) ; if ( checkIfExist ( ctx . window_specification_details ( ) ) ) { Window_specification_detailsContext windowSpecDetail = ctx . window_specification_details ( ) ; if ( checkIfExist ( windowSpecDetail . existing_window_name ( ) ) ) { windowSpec . setWindowName ( windowSpecDetail . existing_window_name ( ) . getText ( ) ) ; } if ( checkIfExist ( windowSpecDetail . window_partition_clause ( ) ) ) { windowSpec . setPartitionKeys ( buildRowValuePredicands ( windowSpecDetail . window_partition_clause ( ) . row_value_predicand_list ( ) ) ) ; } if ( checkIfExist ( windowSpecDetail . window_order_clause ( ) ) ) { windowSpec . setSortSpecs ( buildSortSpecs ( windowSpecDetail . window_order_clause ( ) . orderby_clause ( ) . sort_specifier_list ( ) ) ) ; } if ( checkIfExist ( windowSpecDetail . window_frame_clause ( ) ) ) { Window_frame_clauseContext frameContext = windowSpecDetail . window_frame_clause ( ) ; WindowSpec . WindowFrameUnit unit ; if ( checkIfExist ( frameContext . window_frame_units ( ) . RANGE ( ) ) ) { unit = WindowSpec . WindowFrameUnit . RANGE ; } else { unit = WindowSpec . WindowFrameUnit . ROW ; } WindowSpec . WindowFrame windowFrame ; if ( checkIfExist ( frameContext . window_frame_extent ( ) . window_frame_between ( ) ) ) { Window_frame_betweenContext between = frameContext . window_frame_extent ( ) . window_frame_between ( ) ; WindowSpec . WindowStartBound startBound = buildWindowStartBound ( between . window_frame_start_bound ( ) ) ; WindowSpec . WindowEndBound endBound = buildWindowEndBound ( between . window_frame_end_bound ( ) ) ; windowFrame = new WindowSpec . WindowFrame ( unit , startBound , endBound ) ; } else { WindowSpec . WindowStartBound startBound = buildWindowStartBound ( frameContext . window_frame_extent ( ) . window_frame_start_bound ( ) ) ; windowFrame = new WindowSpec . WindowFrame ( unit , startBound ) ; } windowSpec . setWindowFrame ( windowFrame ) ; } } return windowSpec ; } public WindowSpec . WindowStartBound buildWindowStartBound ( Window_frame_start_boundContext context ) { WindowFrameStartBoundType boundType = null ; if ( checkIfExist ( context . UNBOUNDED ( ) ) ) { boundType = WindowFrameStartBoundType . UNBOUNDED_PRECEDING ; } else if ( checkIfExist ( context . unsigned_value_specification ( ) ) ) { boundType = WindowFrameStartBoundType . PRECEDING ; } else { boundType = WindowFrameStartBoundType . CURRENT_ROW ; } WindowSpec . WindowStartBound bound = new WindowSpec . WindowStartBound ( boundType ) ; if ( boundType == WindowFrameStartBoundType . PRECEDING ) { bound . setNumber ( visitUnsigned_value_specification ( context . unsigned_value_specification ( ) ) ) ; } return bound ; } public WindowSpec . WindowEndBound buildWindowEndBound ( Window_frame_end_boundContext context ) { WindowFrameEndBoundType boundType ; if ( checkIfExist ( context . UNBOUNDED ( ) ) ) { boundType = WindowFrameEndBoundType . UNBOUNDED_FOLLOWING ; } else if ( checkIfExist ( context . unsigned_value_specification ( ) ) ) { boundType = WindowFrameEndBoundType . FOLLOWING ; } else { boundType = WindowFrameEndBoundType . CURRENT_ROW ; } WindowSpec . WindowEndBound endBound = new WindowSpec . WindowEndBound ( boundType ) ; if ( boundType == WindowFrameEndBoundType . FOLLOWING ) { endBound . setNumber ( visitUnsigned_value_specification ( context . unsigned_value_specification ( ) ) ) ; } return endBound ; } public Sort . SortSpec [ ] buildSortSpecs ( Sort_specifier_listContext context ) { int size = context . sort_specifier ( ) . size ( ) ; Sort . SortSpec specs [ ] = new Sort . SortSpec [ size ] ; for ( int i = 0 ; i < size ; i ++ ) { Sort_specifierContext specContext = context . sort_specifier ( i ) ; Expr sortKeyExpr = visitRow_value_predicand ( specContext . key ) ; specs [ i ] = new Sort . SortSpec ( sortKeyExpr ) ; if ( specContext . order_specification ( ) != null ) { if ( specContext . order . DESC ( ) != null ) { specs [ i ] . setDescending ( ) ; } } if ( specContext . null_ordering ( ) != null ) { if ( specContext . null_ordering ( ) . FIRST ( ) != null ) { specs [ i ] . setNullsFirst ( ) ; } else if ( specContext . null_ordering ( ) . LAST ( ) != null ) { specs [ i ] . setNullsLast ( ) ; } } } return specs ; } @ Override public Sort visitOrderby_clause ( Orderby_clauseContext ctx ) { return new Sort ( buildSortSpecs ( ctx . sort_specifier_list ( ) ) ) ; } @ Override public Limit visitLimit_clause ( Limit_clauseContext ctx ) { return new Limit ( visitNumeric_value_expression ( ctx . numeric_value_expression ( ) ) ) ; } @ Override public Expr visitJoined_table ( Joined_tableContext ctx ) { Expr top = visitTable_primary ( ctx . table_primary ( ) ) ; Join join ; for ( int i = 0 ; i < ctx . joined_table_primary ( ) . size ( ) ; i ++ ) { join = visitJoined_table_primary ( ctx . joined_table_primary ( i ) ) ; join . setLeft ( top ) ; top = join ; } return top ; } @ Override public Join visitJoined_table_primary ( Joined_table_primaryContext ctx ) { Join join ; if ( ctx . CROSS ( ) != null ) { join = new Join ( JoinType . CROSS ) ; } else if ( ctx . UNION ( ) != null ) { join = new Join ( JoinType . UNION ) ; } else { if ( ctx . join_type ( ) != null && ctx . join_type ( ) . outer_join_type ( ) != null ) { Outer_join_type_part2Context outer_join_typeContext = ctx . join_type ( ) . outer_join_type ( ) . outer_join_type_part2 ( ) ; if ( outer_join_typeContext . FULL ( ) != null ) { join = new Join ( JoinType . FULL_OUTER ) ; } else if ( outer_join_typeContext . LEFT ( ) != null ) { join = new Join ( JoinType . LEFT_OUTER ) ; } else { join = new Join ( JoinType . RIGHT_OUTER ) ; } } else { join = new Join ( JoinType . INNER ) ; } if ( ctx . NATURAL ( ) != null ) { join . setNatural ( ) ; } if ( ctx . join_specification ( ) != null ) { if ( ctx . join_specification ( ) . join_condition ( ) != null ) { Expr searchCondition = visitSearch_condition ( ctx . join_specification ( ) . join_condition ( ) . search_condition ( ) ) ; join . setQual ( searchCondition ) ; } else if ( ctx . join_specification ( ) . named_columns_join ( ) != null ) { ColumnReferenceExpr [ ] columns = buildColumnReferenceList ( ctx . join_specification ( ) . named_columns_join ( ) . column_reference_list ( ) ) ; join . setJoinColumns ( columns ) ; } } } join . setRight ( visitTable_primary ( ctx . right ) ) ; return join ; } private Expr [ ] getRowValuePredicandsFromOrdinaryGroupingSetList ( Ordinary_grouping_set_listContext ctx ) { ArrayList < Expr > rowValuePredicands = new ArrayList < Expr > ( ) ; for ( int i = 0 ; i < ctx . ordinary_grouping_set ( ) . size ( ) ; i ++ ) { Collections . addAll ( rowValuePredicands , getRowValuePredicandsFromOrdinaryGroupingSet ( ctx . ordinary_grouping_set ( i ) ) ) ; } return rowValuePredicands . toArray ( new Expr [ rowValuePredicands . size ( ) ] ) ; } private Expr [ ] getRowValuePredicandsFromOrdinaryGroupingSet ( Ordinary_grouping_setContext ctx ) { ArrayList < Expr > rowValuePredicands = new ArrayList < Expr > ( ) ; if ( ctx . row_value_predicand ( ) != null ) { rowValuePredicands . add ( visitRow_value_predicand ( ctx . row_value_predicand ( ) ) ) ; } if ( ctx . row_value_predicand_list ( ) != null ) { Collections . addAll ( rowValuePredicands , buildRowValuePredicands ( ctx . row_value_predicand_list ( ) ) ) ; } return rowValuePredicands . toArray ( new Expr [ rowValuePredicands . size ( ) ] ) ; } private Expr [ ] buildRowValuePredicands ( Row_value_predicand_listContext ctx ) { Expr [ ] rowValuePredicands = new Expr [ ctx . row_value_predicand ( ) . size ( ) ] ; for ( int i = 0 ; i < rowValuePredicands . length ; i ++ ) { rowValuePredicands [ i ] = visitRow_value_predicand ( ctx . row_value_predicand ( i ) ) ; } return rowValuePredicands ; } private ColumnReferenceExpr [ ] buildColumnReferenceList ( Column_reference_listContext ctx ) { ColumnReferenceExpr [ ] columnRefs = new ColumnReferenceExpr [ ctx . column_reference ( ) . size ( ) ] ; for ( int i = 0 ; i < columnRefs . length ; i ++ ) { columnRefs [ i ] = visitColumn_reference ( ctx . column_reference ( i ) ) ; } return columnRefs ; } @ Override public Expr visitTable_primary ( Table_primaryContext ctx ) { if ( ctx . table_or_query_name ( ) != null ) { Relation relation = new Relation ( ctx . table_or_query_name ( ) . getText ( ) ) ; if ( ctx . alias != null ) { relation . setAlias ( ctx . alias . getText ( ) ) ; } return relation ; } else if ( ctx . derived_table ( ) != null ) { return new TablePrimarySubQuery ( ctx . name . getText ( ) , visit ( ctx . derived_table ( ) . table_subquery ( ) ) ) ; } else { return null ; } } @ Override public Expr visitSubquery ( SubqueryContext ctx ) { return visitQuery_expression ( ctx . query_expression ( ) ) ; } @ Override public BetweenPredicate visitBetween_predicate ( Between_predicateContext ctx ) { Expr predicand = visitRow_value_predicand ( ctx . predicand ) ; Expr begin = visitRow_value_predicand ( ctx . between_predicate_part_2 ( ) . begin ) ; Expr end = visitRow_value_predicand ( ctx . between_predicate_part_2 ( ) . end ) ; return new BetweenPredicate ( checkIfExist ( ctx . between_predicate_part_2 ( ) . NOT ( ) ) , checkIfExist ( ctx . between_predicate_part_2 ( ) . SYMMETRIC ( ) ) , predicand , begin , end ) ; } @ Override public CaseWhenPredicate visitSimple_case ( Simple_caseContext ctx ) { Expr leftTerm = visitBoolean_value_expression ( ctx . boolean_value_expression ( ) ) ; CaseWhenPredicate caseWhen = new CaseWhenPredicate ( ) ; for ( int i = 0 ; i < ctx . simple_when_clause ( ) . size ( ) ; i ++ ) { Simple_when_clauseContext simpleWhenCtx = ctx . simple_when_clause ( i ) ; BinaryOperator bin = new BinaryOperator ( OpType . Equals , leftTerm , visitValue_expression ( simpleWhenCtx . search_condition ( ) . value_expression ( ) ) ) ; caseWhen . addWhen ( bin , buildCaseResult ( simpleWhenCtx . result ( ) ) ) ; } if ( ctx . else_clause ( ) != null ) { caseWhen . setElseResult ( buildCaseResult ( ctx . else_clause ( ) . result ( ) ) ) ; } return caseWhen ; } private Expr buildCaseResult ( ResultContext result ) { if ( result . NULL ( ) != null ) { return new NullLiteral ( ) ; } else { return visitValue_expression ( result . value_expression ( ) ) ; } } @ Override public CaseWhenPredicate visitSearched_case ( Searched_caseContext ctx ) { CaseWhenPredicate caseWhen = new CaseWhenPredicate ( ) ; for ( int i = 0 ; i < ctx . searched_when_clause ( ) . size ( ) ; i ++ ) { Searched_when_clauseContext searchedWhenCtx = ctx . searched_when_clause ( i ) ; caseWhen . addWhen ( visitSearch_condition ( searchedWhenCtx . search_condition ( ) ) , buildCaseResult ( searchedWhenCtx . result ( ) ) ) ; } if ( ctx . else_clause ( ) != null ) { caseWhen . setElseResult ( buildCaseResult ( ctx . else_clause ( ) . result ( ) ) ) ; } return caseWhen ; } @ Override public Expr visitCommon_value_expression ( Common_value_expressionContext ctx ) { if ( checkIfExist ( ctx . NULL ( ) ) ) { return new NullLiteral ( ) ; } else { return visitChildren ( ctx ) ; } } @ Override public Expr visitParenthesized_value_expression ( Parenthesized_value_expressionContext ctx ) { return visitValue_expression ( ctx . value_expression ( ) ) ; } @ Override public Expr visitBoolean_value_expression ( Boolean_value_expressionContext ctx ) { Expr current = visitOr_predicate ( ctx . or_predicate ( ) ) ; return current ; } @ Override public Expr visitOr_predicate ( Or_predicateContext ctx ) { Expr current = visitAnd_predicate ( ctx . and_predicate ( ) ) ; Expr left ; Expr right ; for ( int i = 0 ; i < ctx . or_predicate ( ) . size ( ) ; i ++ ) { left = current ; right = visitOr_predicate ( ctx . or_predicate ( i ) ) ; current = new BinaryOperator ( OpType . Or , left , right ) ; } return current ; } @ Override public Expr visitAnd_predicate ( And_predicateContext ctx ) { Expr current = visitBoolean_factor ( ctx . boolean_factor ( ) ) ; Expr left ; Expr right ; for ( int i = 0 ; i < ctx . and_predicate ( ) . size ( ) ; i ++ ) { left = current ; right = visitAnd_predicate ( ctx . and_predicate ( i ) ) ; current = new BinaryOperator ( OpType . And , left , right ) ; } return current ; } @ Override public Expr visitBoolean_factor ( Boolean_factorContext ctx ) { if ( ctx . NOT ( ) != null ) { return new NotExpr ( visitBoolean_test ( ctx . boolean_test ( ) ) ) ; } else { return visitBoolean_test ( ctx . boolean_test ( ) ) ; } } @ Override public Expr visitBoolean_test ( Boolean_testContext ctx ) { if ( checkIfExist ( ctx . is_clause ( ) ) ) { Is_clauseContext isClauseContext = ctx . is_clause ( ) ; if ( checkIfExist ( isClauseContext . NOT ( ) ) ) { if ( checkIfExist ( ctx . is_clause ( ) . truth_value ( ) . TRUE ( ) ) ) { return new NotExpr ( visitBoolean_primary ( ctx . boolean_primary ( ) ) ) ; } else { return visitBoolean_primary ( ctx . boolean_primary ( ) ) ; } } else { if ( checkIfExist ( ctx . is_clause ( ) . truth_value ( ) . TRUE ( ) ) ) { return visitBoolean_primary ( ctx . boolean_primary ( ) ) ; } else { return new NotExpr ( visitBoolean_primary ( ctx . boolean_primary ( ) ) ) ; } } } else { return visitBoolean_primary ( ctx . boolean_primary ( ) ) ; } } @ Override public Expr visitBoolean_primary ( Boolean_primaryContext ctx ) { if ( ctx . predicate ( ) != null ) { return visitPredicate ( ctx . predicate ( ) ) ; } else { return visitBoolean_predicand ( ctx . boolean_predicand ( ) ) ; } } @ Override public Expr visitBoolean_predicand ( Boolean_predicandContext ctx ) { if ( checkIfExist ( ctx . nonparenthesized_value_expression_primary ( ) ) ) { return visitNonparenthesized_value_expression_primary ( ctx . nonparenthesized_value_expression_primary ( ) ) ; } else { return visitBoolean_value_expression ( ctx . parenthesized_boolean_value_expression ( ) . boolean_value_expression ( ) ) ; } } @ Override public Expr visitNonparenthesized_value_expression_primary ( Nonparenthesized_value_expression_primaryContext ctx ) { return visitChildren ( ctx ) ; } @ Override public Expr visitRow_value_predicand ( Row_value_predicandContext ctx ) { if ( checkIfExist ( ctx . row_value_special_case ( ) ) ) { return visitRow_value_special_case ( ctx . row_value_special_case ( ) ) ; } else { return visitRow_value_constructor_predicand ( ctx . row_value_constructor_predicand ( ) ) ; } } @ Override public Expr visitRow_value_constructor_predicand ( Row_value_constructor_predicandContext ctx ) { if ( checkIfExist ( ctx . boolean_predicand ( ) ) ) { return visitBoolean_predicand ( ctx . boolean_predicand ( ) ) ; } else { return visitCommon_value_expression ( ctx . common_value_expression ( ) ) ; } } @ Override public BinaryOperator visitComparison_predicate ( Comparison_predicateContext ctx ) { TerminalNode operator = ( TerminalNode ) ctx . comp_op ( ) . getChild ( 0 ) ; return new BinaryOperator ( tokenToExprType ( operator . getSymbol ( ) . getType ( ) ) , visitRow_value_predicand ( ctx . left ) , visitRow_value_predicand ( ctx . right ) ) ; } @ Override public Expr visitNumeric_value_expression ( Numeric_value_expressionContext ctx ) { Expr current = visitTerm ( ctx . term ( 0 ) ) ; Expr left ; Expr right ; for ( int i = 1 ; i < ctx . getChildCount ( ) ; i ++ ) { left = current ; TerminalNode operator = ( TerminalNode ) ctx . getChild ( i ++ ) ; right = visitTerm ( ( TermContext ) ctx . getChild ( i ) ) ; if ( operator . getSymbol ( ) . getType ( ) == PLUS ) { current = new BinaryOperator ( OpType . Plus , left , right ) ; } else { current = new BinaryOperator ( OpType . Minus , left , right ) ; } } return current ; } @ Override public Expr visitTerm ( TermContext ctx ) { Expr current = visitFactor ( ctx . factor ( 0 ) ) ; Expr left ; Expr right ; for ( int i = 1 ; i < ctx . getChildCount ( ) ; i ++ ) { left = current ; TerminalNode operator = ( TerminalNode ) ctx . getChild ( i ++ ) ; right = visitFactor ( ( FactorContext ) ctx . getChild ( i ) ) ; if ( operator . getSymbol ( ) . getType ( ) == MULTIPLY ) { current = new BinaryOperator ( OpType . Multiply , left , right ) ; } else if ( operator . getSymbol ( ) . getType ( ) == DIVIDE ) { current = new BinaryOperator ( OpType . Divide , left , right ) ; } else { current = new BinaryOperator ( OpType . Modular , left , right ) ; } } return current ; } @ Override public Expr visitFactor ( FactorContext ctx ) { Expr current = visitNumeric_primary ( ctx . numeric_primary ( ) ) ; if ( checkIfExist ( ctx . sign ( ) ) && checkIfExist ( ctx . sign ( ) . MINUS ( ) ) ) { current = new SignedExpr ( true , current ) ; } return current ; } @ Override public Expr visitNumeric_primary ( Numeric_primaryContext ctx ) { Expr current = null ; if ( checkIfExist ( ctx . value_expression_primary ( ) ) ) { current = visitValue_expression_primary ( ctx . value_expression_primary ( ) ) ; for ( int i = 0 ; i < ctx . CAST_EXPRESSION ( ) . size ( ) ; i ++ ) { current = new CastExpr ( current , visitData_type ( ctx . cast_target ( i ) . data_type ( ) ) ) ; } } else if ( checkIfExist ( ctx . numeric_value_function ( ) ) ) { current = visitNumeric_value_function ( ctx . numeric_value_function ( ) ) ; } return current ; } public static OpType tokenToExprType ( int tokenId ) { switch ( tokenId ) { case UNION : return OpType . Union ; case EXCEPT : return OpType . Except ; case INTERSECT : return OpType . Intersect ; case AND : return OpType . And ; case OR : return OpType . Or ; case EQUAL : return OpType . Equals ; case NOT_EQUAL : return OpType . NotEquals ; case LTH : return OpType . LessThan ; case LEQ : return OpType . LessThanOrEquals ; case GTH : return OpType . GreaterThan ; case GEQ : return OpType . GreaterThanOrEquals ; case MULTIPLY : return OpType . Multiply ; case DIVIDE : return OpType . Divide ; case MODULAR : return OpType . Modular ; case PLUS : return OpType . Plus ; case MINUS : return OpType . Minus ; default : throw new TajoInternalError ( ""unknown Token Id: "" + tokenId ) ; } } @ Override public InPredicate visitIn_predicate ( In_predicateContext ctx ) { return new InPredicate ( visitChildren ( ctx . numeric_value_expression ( ) ) , visitIn_predicate_value ( ctx . in_predicate_value ( ) ) , ctx . NOT ( ) != null ) ; } @ Override public Expr visitIn_predicate_value ( In_predicate_valueContext ctx ) { if ( checkIfExist ( ctx . in_value_list ( ) ) ) { int size = ctx . in_value_list ( ) . row_value_predicand ( ) . size ( ) ; Expr [ ] exprs = new Expr [ size ] ; for ( int i = 0 ; i < size ; i ++ ) { exprs [ i ] = visitRow_value_predicand ( ctx . in_value_list ( ) . row_value_predicand ( i ) ) ; } return new ValueListExpr ( exprs ) ; } else { return new SimpleTableSubquery ( visitChildren ( ctx . table_subquery ( ) ) ) ; } } @ Override public Expr visitArray ( ArrayContext ctx ) { int size = ctx . numeric_value_expression ( ) . size ( ) ; Expr [ ] exprs = new Expr [ size ] ; for ( int i = 0 ; i < size ; i ++ ) { exprs [ i ] = visit ( ctx . numeric_value_expression ( i ) ) ; } return new ValueListExpr ( exprs ) ; } @ Override public Expr visitPattern_matching_predicate ( Pattern_matching_predicateContext ctx ) { Expr predicand = visitChildren ( ctx . row_value_predicand ( ) ) ; Expr pattern = new LiteralValue ( stripQuote ( ctx . Character_String_Literal ( ) . getText ( ) ) , LiteralType . String ) ; if ( checkIfExist ( ctx . pattern_matcher ( ) . negativable_matcher ( ) ) ) { boolean not = ctx . pattern_matcher ( ) . NOT ( ) != null ; Negativable_matcherContext matcher = ctx . pattern_matcher ( ) . negativable_matcher ( ) ; if ( checkIfExist ( matcher . LIKE ( ) ) ) { return new PatternMatchPredicate ( OpType . LikePredicate , not , predicand , pattern ) ; } else if ( checkIfExist ( matcher . ILIKE ( ) ) ) { return new PatternMatchPredicate ( OpType . LikePredicate , not , predicand , pattern , true ) ; } else if ( checkIfExist ( matcher . SIMILAR ( ) ) ) { return new PatternMatchPredicate ( OpType . SimilarToPredicate , not , predicand , pattern ) ; } else if ( checkIfExist ( matcher . REGEXP ( ) ) || checkIfExist ( matcher . RLIKE ( ) ) ) { return new PatternMatchPredicate ( OpType . Regexp , not , predicand , pattern ) ; } else { throw new TajoInternalError ( ""unknown pattern matching predicate: "" + matcher . getText ( ) ) ; } } else if ( checkIfExist ( ctx . pattern_matcher ( ) . regex_matcher ( ) ) ) { Regex_matcherContext matcher = ctx . pattern_matcher ( ) . regex_matcher ( ) ; if ( checkIfExist ( matcher . Similar_To ( ) ) ) { return new PatternMatchPredicate ( OpType . Regexp , false , predicand , pattern , false ) ; } else if ( checkIfExist ( matcher . Not_Similar_To ( ) ) ) { return new PatternMatchPredicate ( OpType . Regexp , true , predicand , pattern , false ) ; } else if ( checkIfExist ( matcher . Similar_To_Case_Insensitive ( ) ) ) { return new PatternMatchPredicate ( OpType . Regexp , false , predicand , pattern , true ) ; } else if ( checkIfExist ( matcher . Not_Similar_To_Case_Insensitive ( ) ) ) { return new PatternMatchPredicate ( OpType . Regexp , true , predicand , pattern , true ) ; } else { throw new TajoInternalError ( ""Unsupported predicate: "" + matcher . getText ( ) ) ; } } else { throw new TajoInternalError ( ""invalid pattern matching predicate: "" + ctx . pattern_matcher ( ) . getText ( ) ) ; } } @ Override public IsNullPredicate visitNull_predicate ( Null_predicateContext ctx ) { Expr predicand = visitRow_value_predicand ( ctx . row_value_predicand ( ) ) ; return new IsNullPredicate ( ctx . NOT ( ) != null , predicand ) ; } @ Override public ExistsPredicate visitExists_predicate ( Exists_predicateContext ctx ) { return new ExistsPredicate ( new SimpleTableSubquery ( visitTable_subquery ( ctx . table_subquery ( ) ) ) , ctx . NOT ( ) != null ) ; } @ Override public ColumnReferenceExpr visitColumn_reference ( Column_referenceContext ctx ) { String columnReferenceName = buildIdentifierChain ( ctx . identifier ( ) ) ; int lastDotIdx = columnReferenceName . lastIndexOf ( ""."" ) ; if ( lastDotIdx > 0 ) { String qualifier = columnReferenceName . substring ( 0 , lastDotIdx ) ; String name = columnReferenceName . substring ( lastDotIdx + 1 , columnReferenceName . length ( ) ) ; return new ColumnReferenceExpr ( qualifier , name ) ; } else { return new ColumnReferenceExpr ( ctx . getText ( ) ) ; } } @ Override public LiteralValue visitUnsigned_numeric_literal ( @ NotNull Unsigned_numeric_literalContext ctx ) { if ( ctx . NUMBER ( ) != null ) { long lValue = Long . parseLong ( ctx . getText ( ) ) ; if ( lValue >= Integer . MIN_VALUE && lValue <= Integer . MAX_VALUE ) { return new LiteralValue ( ctx . getText ( ) , LiteralType . Unsigned_Integer ) ; } else { return new LiteralValue ( ctx . getText ( ) , LiteralType . Unsigned_Large_Integer ) ; } } else { return new LiteralValue ( ctx . getText ( ) , LiteralType . Unsigned_Float ) ; } } @ Override public GeneralSetFunctionExpr visitAggregate_function ( Aggregate_functionContext ctx ) { if ( ctx . COUNT ( ) != null && ctx . MULTIPLY ( ) != null ) { return new CountRowsFunctionExpr ( ) ; } else { return visitGeneral_set_function ( ctx . general_set_function ( ) ) ; } } @ Override public GeneralSetFunctionExpr visitGeneral_set_function ( General_set_functionContext ctx ) { String signature = ctx . set_function_type ( ) . getText ( ) ; boolean distinct = checkIfExist ( ctx . set_qualifier ( ) ) && checkIfExist ( ctx . set_qualifier ( ) . DISTINCT ( ) ) ; Expr param = visitValue_expression ( ctx . value_expression ( ) ) ; return new GeneralSetFunctionExpr ( signature , distinct , new Expr [ ] { param } ) ; } @ Override public FunctionExpr visitRoutine_invocation ( Routine_invocationContext ctx ) { String signature = ctx . function_name ( ) . getText ( ) ; FunctionExpr function = new FunctionExpr ( signature ) ; if ( ctx . sql_argument_list ( ) != null ) { int numArgs = ctx . sql_argument_list ( ) . value_expression ( ) . size ( ) ; Expr [ ] argument_list = new Expr [ numArgs ] ; for ( int i = 0 ; i < numArgs ; i ++ ) { argument_list [ i ] = visitValue_expression ( ctx . sql_argument_list ( ) . value_expression ( ) . get ( i ) ) ; } function . setParams ( argument_list ) ; } return function ; } @ Override public NamedExpr visitDerived_column ( Derived_columnContext ctx ) { NamedExpr target = new NamedExpr ( visitValue_expression ( ctx . value_expression ( ) ) ) ; if ( ctx . as_clause ( ) != null ) { target . setAlias ( buildIdentifier ( ctx . as_clause ( ) . identifier ( ) ) ) ; } return target ; } @ Override public NamedExpr visitQualified_asterisk ( Qualified_asteriskContext ctx ) { QualifiedAsteriskExpr target = new QualifiedAsteriskExpr ( ) ; if ( ctx . tb_name != null ) { target . setQualifier ( ctx . tb_name . getText ( ) ) ; } return new NamedExpr ( target ) ; } @ Override public Expr visitCharacter_string_type ( Character_string_typeContext ctx ) { return new LiteralValue ( stripQuote ( ctx . getText ( ) ) , LiteralType . String ) ; } @ Override public Expr visitCharacter_value_expression ( Character_value_expressionContext ctx ) { Expr current = visitCharacter_factor ( ctx . character_factor ( 0 ) ) ; Expr left ; Expr right ; for ( int i = 1 ; i < ctx . getChildCount ( ) ; i ++ ) { left = current ; i ++ ; right = visitCharacter_factor ( ( Character_factorContext ) ctx . getChild ( i ) ) ; if ( left . getType ( ) == OpType . Literal && right . getType ( ) == OpType . Literal ) { current = new LiteralValue ( ( ( LiteralValue ) left ) . getValue ( ) + ( ( LiteralValue ) right ) . getValue ( ) , LiteralType . String ) ; } else { current = new BinaryOperator ( OpType . Concatenate , left , right ) ; } } return current ; } @ Override public Expr visitNumeric_value_function ( Numeric_value_functionContext ctx ) { if ( checkIfExist ( ctx . extract_expression ( ) ) ) { return visitExtract_expression ( ctx . extract_expression ( ) ) ; } if ( checkIfExist ( ctx . datetime_value_function ( ) ) ) { return visitDatetime_value_function ( ctx . datetime_value_function ( ) ) ; } return null ; } @ Override public Expr visitExtract_expression ( Extract_expressionContext ctx ) { Expr extractTarget = new LiteralValue ( ctx . extract_field_string . getText ( ) , LiteralType . String ) ; Expr extractSource = visitDatetime_value_expression ( ctx . extract_source ( ) . datetime_value_expression ( ) ) ; String functionName = ""date_part"" ; Expr [ ] params = new Expr [ ] { extractTarget , extractSource } ; return new FunctionExpr ( functionName , params ) ; } @ Override public Expr visitTrim_function ( Trim_functionContext ctx ) { Expr trimSource = visitChildren ( ctx . trim_operands ( ) . trim_source ) ; String functionName = ""trim"" ; if ( checkIfExist ( ctx . trim_operands ( ) . FROM ( ) ) ) { if ( checkIfExist ( ctx . trim_operands ( ) . trim_specification ( ) ) ) { Trim_specificationContext specification = ctx . trim_operands ( ) . trim_specification ( ) ; if ( checkIfExist ( specification . LEADING ( ) ) ) { functionName = ""ltrim"" ; } else if ( checkIfExist ( specification . TRAILING ( ) ) ) { functionName = ""rtrim"" ; } else { functionName = ""trim"" ; } } } Expr trimCharacters = null ; if ( checkIfExist ( ctx . trim_operands ( ) . trim_character ) ) { trimCharacters = visitCharacter_value_expression ( ctx . trim_operands ( ) . trim_character ) ; } Expr [ ] params ; if ( trimCharacters != null ) { params = new Expr [ ] { trimSource , trimCharacters } ; } else { params = new Expr [ ] { trimSource } ; } return new FunctionExpr ( functionName , params ) ; } @ Override public Expr visitCreate_index_statement ( Create_index_statementContext ctx ) { String indexName = ctx . index_name . getText ( ) ; String tableName = buildIdentifierChain ( ctx . table_name ( ) . identifier ( ) ) ; Relation relation = new Relation ( tableName ) ; SortSpec [ ] sortSpecs = buildSortSpecs ( ctx . sort_specifier_list ( ) ) ; NamedExpr [ ] targets = new NamedExpr [ sortSpecs . length ] ; Projection projection = new Projection ( ) ; int i = 0 ; for ( SortSpec sortSpec : sortSpecs ) { targets [ i ++ ] = new NamedExpr ( sortSpec . getKey ( ) ) ; } projection . setNamedExprs ( targets ) ; projection . setChild ( relation ) ; CreateIndex createIndex = new CreateIndex ( indexName , sortSpecs ) ; if ( checkIfExist ( ctx . UNIQUE ( ) ) ) { createIndex . setUnique ( true ) ; } if ( checkIfExist ( ctx . method_specifier ( ) ) ) { String methodName = buildIdentifier ( ctx . method_specifier ( ) . identifier ( ) ) ; createIndex . setMethodSpec ( new IndexMethodSpec ( methodName ) ) ; } if ( checkIfExist ( ctx . param_clause ( ) ) ) { Map < String , String > params = getParams ( ctx . param_clause ( ) ) ; createIndex . setParams ( params ) ; } if ( checkIfExist ( ctx . where_clause ( ) ) ) { Selection selection = visitWhere_clause ( ctx . where_clause ( ) ) ; selection . setChild ( relation ) ; projection . setChild ( selection ) ; } if ( checkIfExist ( ctx . LOCATION ( ) ) ) { createIndex . setIndexPath ( stripQuote ( ctx . path . getText ( ) ) ) ; } createIndex . setChild ( projection ) ; return createIndex ; } @ Override public Expr visitDrop_index_statement ( Drop_index_statementContext ctx ) { String indexName = buildIdentifier ( ctx . identifier ( ) ) ; return new DropIndex ( indexName ) ; } @ Override public Expr visitDatabase_definition ( @ NotNull Database_definitionContext ctx ) { return new CreateDatabase ( buildIdentifier ( ctx . identifier ( ) ) , null , checkIfExist ( ctx . if_not_exists ( ) ) ) ; } @ Override public Expr visitDrop_database_statement ( @ NotNull Drop_database_statementContext ctx ) { return new DropDatabase ( buildIdentifier ( ctx . identifier ( ) ) , checkIfExist ( ctx . if_exists ( ) ) ) ; } @ Override public Expr visitCreate_table_statement ( Create_table_statementContext ctx ) { String tableName = buildIdentifierChain ( ctx . table_name ( 0 ) . identifier ( ) ) ; CreateTable createTable = new CreateTable ( tableName , checkIfExist ( ctx . if_not_exists ( ) ) ) ; if ( checkIfExist ( ctx . LIKE ( ) ) ) { createTable . setLikeParentTable ( buildIdentifierChain ( ctx . like_table_name . identifier ( ) ) ) ; return createTable ; } if ( checkIfExist ( ctx . EXTERNAL ( ) ) ) { createTable . setExternal ( ) ; if ( checkIfExist ( ctx . table_elements ( ) . asterisk ( ) ) ) { createTable . setHasSelfDescSchema ( ) ; } else { ColumnDefinition [ ] elements = getDefinitions ( ctx . table_elements ( ) ) ; createTable . setTableElements ( elements ) ; } if ( checkIfExist ( ctx . TABLESPACE ( ) ) ) { throw new TajoRuntimeException ( new SQLSyntaxError ( ""Tablespace clause is not allowed for an external table."" ) ) ; } String storageType = ctx . storage_type . getText ( ) ; createTable . setStorageType ( storageType ) ; if ( checkIfExist ( ctx . LOCATION ( ) ) ) { String uri = stripQuote ( ctx . uri . getText ( ) ) ; createTable . setLocation ( uri ) ; } else { throw new TajoRuntimeException ( new SQLSyntaxError ( ""LOCATION clause must be required for an external table."" ) ) ; } } else { if ( checkIfExist ( ctx . table_elements ( ) ) ) { if ( checkIfExist ( ctx . table_elements ( ) . asterisk ( ) ) ) { createTable . setHasSelfDescSchema ( ) ; } else { ColumnDefinition [ ] elements = getDefinitions ( ctx . table_elements ( ) ) ; createTable . setTableElements ( elements ) ; } } if ( checkIfExist ( ctx . TABLESPACE ( ) ) ) { String spaceName = ctx . spacename . getText ( ) ; createTable . setTableSpaceName ( spaceName ) ; } if ( checkIfExist ( ctx . USING ( ) ) ) { String fileType = ctx . storage_type . getText ( ) ; createTable . setStorageType ( fileType ) ; } if ( checkIfExist ( ctx . query_expression ( ) ) ) { Expr subquery = visitQuery_expression ( ctx . query_expression ( ) ) ; createTable . setSubQuery ( subquery ) ; createTable . unsetHasSelfDescSchema ( ) ; } } if ( checkIfExist ( ctx . param_clause ( ) ) ) { Map < String , String > params = escapeTableMeta ( getParams ( ctx . param_clause ( ) ) ) ; createTable . setParams ( params ) ; } if ( checkIfExist ( ctx . table_partitioning_clauses ( ) ) ) { PartitionMethodDescExpr partitionMethodDesc = parseTablePartitioningClause ( ctx . table_partitioning_clauses ( ) ) ; createTable . setPartitionMethod ( partitionMethodDesc ) ; } return createTable ; } @ Override public Expr visitTruncate_table_statement ( @ NotNull Truncate_table_statementContext ctx ) { List < Table_nameContext > tableNameContexts = ctx . table_name ( ) ; List < String > tableNames = new ArrayList < String > ( ) ; for ( Table_nameContext eachTableNameContext : tableNameContexts ) { tableNames . add ( buildIdentifierChain ( eachTableNameContext . identifier ( ) ) ) ; } return new TruncateTable ( tableNames ) ; } private ColumnDefinition [ ] getDefinitions ( Table_elementsContext ctx ) { int size = ctx . field_element ( ) . size ( ) ; ColumnDefinition [ ] elements = new ColumnDefinition [ size ] ; for ( int i = 0 ; i < size ; i ++ ) { String name = ctx . field_element ( i ) . name . getText ( ) ; String dataTypeName = ctx . field_element ( i ) . field_type ( ) . data_type ( ) . getText ( ) ; DataTypeExpr typeDef = visitData_type ( ctx . field_element ( i ) . field_type ( ) . data_type ( ) ) ; Preconditions . checkNotNull ( typeDef , dataTypeName + "" is not handled correctly"" ) ; elements [ i ] = new ColumnDefinition ( name , typeDef ) ; } return elements ; } public PartitionMethodDescExpr parseTablePartitioningClause ( Table_partitioning_clausesContext ctx ) { if ( checkIfExist ( ctx . range_partitions ( ) ) ) { Range_partitionsContext rangePartitionsContext = ctx . range_partitions ( ) ; List < Range_value_clauseContext > rangeValueClause = rangePartitionsContext . range_value_clause_list ( ) . range_value_clause ( ) ; List < RangePartitionSpecifier > specifiers = Lists . newArrayList ( ) ; for ( Range_value_clauseContext rangeValue : rangeValueClause ) { if ( checkIfExist ( rangeValue . MAXVALUE ( ) ) ) { specifiers . add ( new RangePartitionSpecifier ( rangeValue . partition_name ( ) . getText ( ) ) ) ; } else { specifiers . add ( new RangePartitionSpecifier ( rangeValue . partition_name ( ) . getText ( ) , visitValue_expression ( rangeValue . value_expression ( ) ) ) ) ; } } return new CreateTable . RangePartition ( buildColumnReferenceList ( ctx . range_partitions ( ) . column_reference_list ( ) ) , specifiers ) ; } else if ( checkIfExist ( ctx . hash_partitions ( ) ) ) { Hash_partitionsContext hashPartitions = ctx . hash_partitions ( ) ; if ( checkIfExist ( hashPartitions . hash_partitions_by_quantity ( ) ) ) { return new HashPartition ( buildColumnReferenceList ( hashPartitions . column_reference_list ( ) ) , visitNumeric_value_expression ( hashPartitions . hash_partitions_by_quantity ( ) . quantity ) ) ; } else { List < CreateTable . PartitionSpecifier > specifiers = Lists . newArrayList ( ) ; for ( Individual_hash_partitionContext partition : hashPartitions . individual_hash_partitions ( ) . individual_hash_partition ( ) ) { specifiers . add ( new CreateTable . PartitionSpecifier ( partition . partition_name ( ) . getText ( ) ) ) ; } return new HashPartition ( buildColumnReferenceList ( hashPartitions . column_reference_list ( ) ) , specifiers ) ; } } else if ( checkIfExist ( ctx . list_partitions ( ) ) ) { List_partitionsContext listPartitions = ctx . list_partitions ( ) ; List < List_value_partitionContext > partitions = listPartitions . list_value_clause_list ( ) . list_value_partition ( ) ; List < ListPartitionSpecifier > specifiers = Lists . newArrayList ( ) ; for ( List_value_partitionContext listValuePartition : partitions ) { int size = listValuePartition . in_value_list ( ) . row_value_predicand ( ) . size ( ) ; Expr [ ] exprs = new Expr [ size ] ; for ( int i = 0 ; i < size ; i ++ ) { exprs [ i ] = visitRow_value_predicand ( listValuePartition . in_value_list ( ) . row_value_predicand ( i ) ) ; } specifiers . add ( new ListPartitionSpecifier ( listValuePartition . partition_name ( ) . getText ( ) , new ValueListExpr ( exprs ) ) ) ; } return new ListPartition ( buildColumnReferenceList ( ctx . list_partitions ( ) . column_reference_list ( ) ) , specifiers ) ; } else if ( checkIfExist ( ctx . column_partitions ( ) ) ) { return new CreateTable . ColumnPartition ( getDefinitions ( ctx . column_partitions ( ) . table_elements ( ) ) ) ; } else { throw new TajoInternalError ( ""invalid partition type: "" + ctx . toStringTree ( ) ) ; } } @ Override public DataTypeExpr visitData_type ( Data_typeContext ctx ) { Predefined_typeContext predefined_type = ctx . predefined_type ( ) ; DataTypeExpr typeDefinition = null ; if ( checkIfExist ( predefined_type . character_string_type ( ) ) ) { Character_string_typeContext character_string_type = predefined_type . character_string_type ( ) ; if ( ( checkIfExist ( character_string_type . CHARACTER ( ) ) || checkIfExist ( character_string_type . CHAR ( ) ) ) && ! checkIfExist ( character_string_type . VARYING ( ) ) ) { typeDefinition = new DataTypeExpr ( Type . CHAR . name ( ) ) ; if ( character_string_type . type_length ( ) != null ) { typeDefinition . setLengthOrPrecision ( Integer . parseInt ( character_string_type . type_length ( ) . NUMBER ( ) . getText ( ) ) ) ; } } else if ( checkIfExist ( character_string_type . VARCHAR ( ) ) || checkIfExist ( character_string_type . VARYING ( ) ) ) { typeDefinition = new DataTypeExpr ( Type . VARCHAR . name ( ) ) ; if ( character_string_type . type_length ( ) != null ) { typeDefinition . setLengthOrPrecision ( Integer . parseInt ( character_string_type . type_length ( ) . NUMBER ( ) . getText ( ) ) ) ; } } else if ( checkIfExist ( character_string_type . TEXT ( ) ) ) { typeDefinition = new DataTypeExpr ( Type . TEXT . name ( ) ) ; } } else if ( checkIfExist ( predefined_type . national_character_string_type ( ) ) ) { National_character_string_typeContext nchar_type = predefined_type . national_character_string_type ( ) ; if ( ( checkIfExist ( nchar_type . CHAR ( ) ) || checkIfExist ( nchar_type . CHARACTER ( ) ) || checkIfExist ( nchar_type . NCHAR ( ) ) && ! checkIfExist ( nchar_type . VARYING ( ) ) ) ) { typeDefinition = new DataTypeExpr ( Type . NCHAR . name ( ) ) ; } else if ( checkIfExist ( nchar_type . NVARCHAR ( ) ) || checkIfExist ( nchar_type . VARYING ( ) ) ) { typeDefinition = new DataTypeExpr ( Type . NVARCHAR . name ( ) ) ; } if ( checkIfExist ( nchar_type . type_length ( ) ) ) { typeDefinition . setLengthOrPrecision ( Integer . parseInt ( nchar_type . type_length ( ) . NUMBER ( ) . getText ( ) ) ) ; } } else if ( checkIfExist ( predefined_type . binary_large_object_string_type ( ) ) ) { Binary_large_object_string_typeContext blob_type = predefined_type . binary_large_object_string_type ( ) ; typeDefinition = new DataTypeExpr ( Type . BLOB . name ( ) ) ; if ( checkIfExist ( blob_type . type_length ( ) ) ) { typeDefinition . setLengthOrPrecision ( Integer . parseInt ( blob_type . type_length ( ) . NUMBER ( ) . getText ( ) ) ) ; } } else if ( checkIfExist ( predefined_type . numeric_type ( ) ) ) { if ( checkIfExist ( predefined_type . numeric_type ( ) . exact_numeric_type ( ) ) ) { Exact_numeric_typeContext exactType = predefined_type . numeric_type ( ) . exact_numeric_type ( ) ; if ( checkIfExist ( exactType . TINYINT ( ) ) || checkIfExist ( exactType . INT1 ( ) ) ) { typeDefinition = new DataTypeExpr ( Type . INT1 . name ( ) ) ; } else if ( checkIfExist ( exactType . INT2 ( ) ) || checkIfExist ( exactType . SMALLINT ( ) ) ) { typeDefinition = new DataTypeExpr ( Type . INT2 . name ( ) ) ; } else if ( checkIfExist ( exactType . INT4 ( ) ) || checkIfExist ( exactType . INTEGER ( ) ) || checkIfExist ( exactType . INT ( ) ) ) { typeDefinition = new DataTypeExpr ( Type . INT4 . name ( ) ) ; } else if ( checkIfExist ( exactType . INT8 ( ) ) || checkIfExist ( exactType . BIGINT ( ) ) ) { typeDefinition = new DataTypeExpr ( Type . INT8 . name ( ) ) ; } else if ( checkIfExist ( exactType . NUMERIC ( ) ) || checkIfExist ( exactType . DECIMAL ( ) ) || checkIfExist ( exactType . DEC ( ) ) ) { typeDefinition = new DataTypeExpr ( Type . NUMERIC . name ( ) ) ; if ( checkIfExist ( exactType . precision_param ( ) ) ) { typeDefinition . setLengthOrPrecision ( Integer . parseInt ( exactType . precision_param ( ) . precision . getText ( ) ) ) ; if ( checkIfExist ( exactType . precision_param ( ) . scale ) ) { typeDefinition . setScale ( Integer . parseInt ( exactType . precision_param ( ) . scale . getText ( ) ) ) ; } } } } else { Approximate_numeric_typeContext approximateType = predefined_type . numeric_type ( ) . approximate_numeric_type ( ) ; if ( checkIfExist ( approximateType . FLOAT ( ) ) || checkIfExist ( approximateType . FLOAT4 ( ) ) || checkIfExist ( approximateType . REAL ( ) ) ) { typeDefinition = new DataTypeExpr ( Type . FLOAT4 . name ( ) ) ; } else if ( checkIfExist ( approximateType . FLOAT8 ( ) ) || checkIfExist ( approximateType . DOUBLE ( ) ) ) { typeDefinition = new DataTypeExpr ( Type . FLOAT8 . name ( ) ) ; } } } else if ( checkIfExist ( predefined_type . boolean_type ( ) ) ) { typeDefinition = new DataTypeExpr ( Type . BOOLEAN . name ( ) ) ; } else if ( checkIfExist ( predefined_type . datetime_type ( ) ) ) { Datetime_typeContext dateTimeType = predefined_type . datetime_type ( ) ; if ( checkIfExist ( dateTimeType . DATE ( ) ) ) { typeDefinition = new DataTypeExpr ( Type . DATE . name ( ) ) ; } else if ( checkIfExist ( dateTimeType . TIME ( 0 ) ) ) { if ( checkIfExist ( dateTimeType . ZONE ( ) ) ) { typeDefinition = new DataTypeExpr ( Type . TIMEZ . name ( ) ) ; } else { typeDefinition = new DataTypeExpr ( Type . TIME . name ( ) ) ; } } else if ( checkIfExist ( dateTimeType . TIMETZ ( ) ) ) { typeDefinition = new DataTypeExpr ( Type . TIMEZ . name ( ) ) ; } else if ( checkIfExist ( dateTimeType . TIMESTAMP ( ) ) ) { if ( checkIfExist ( dateTimeType . ZONE ( ) ) ) { typeDefinition = new DataTypeExpr ( Type . TIMESTAMPZ . name ( ) ) ; } else { typeDefinition = new DataTypeExpr ( Type . TIMESTAMP . name ( ) ) ; } } else if ( checkIfExist ( dateTimeType . TIMESTAMPTZ ( ) ) ) { typeDefinition = new DataTypeExpr ( Type . TIMESTAMPZ . name ( ) ) ; } } else if ( predefined_type . bit_type ( ) != null ) { Bit_typeContext bitType = predefined_type . bit_type ( ) ; if ( checkIfExist ( bitType . VARBIT ( ) ) || checkIfExist ( bitType . VARYING ( ) ) ) { typeDefinition = new DataTypeExpr ( Type . VARBIT . name ( ) ) ; } else { typeDefinition = new DataTypeExpr ( Type . BIT . name ( ) ) ; } if ( checkIfExist ( bitType . type_length ( ) ) ) { typeDefinition . setLengthOrPrecision ( Integer . parseInt ( bitType . type_length ( ) . NUMBER ( ) . getText ( ) ) ) ; } } else if ( checkIfExist ( predefined_type . binary_type ( ) ) ) { Binary_typeContext binaryType = predefined_type . binary_type ( ) ; if ( checkIfExist ( binaryType . VARBINARY ( ) ) || checkIfExist ( binaryType . VARYING ( ) ) ) { typeDefinition = new DataTypeExpr ( Type . VARBINARY . name ( ) ) ; } else { typeDefinition = new DataTypeExpr ( Type . BINARY . name ( ) ) ; } if ( checkIfExist ( binaryType . type_length ( ) ) ) { typeDefinition . setLengthOrPrecision ( Integer . parseInt ( binaryType . type_length ( ) . NUMBER ( ) . getText ( ) ) ) ; } } else if ( checkIfExist ( predefined_type . network_type ( ) ) ) { typeDefinition = new DataTypeExpr ( Type . INET4 . name ( ) ) ; } else if ( checkIfExist ( predefined_type . record_type ( ) ) ) { ColumnDefinition [ ] nestedRecordDefine = getDefinitions ( predefined_type . record_type ( ) . table_elements ( ) ) ; typeDefinition = new DataTypeExpr ( new DataTypeExpr . RecordType ( nestedRecordDefine ) ) ; } else if ( checkIfExist ( predefined_type . map_type ( ) ) ) { Map_typeContext mapTypeContext = predefined_type . map_type ( ) ; typeDefinition = new DataTypeExpr ( new MapType ( visitData_type ( mapTypeContext . key_type ) , visitData_type ( mapTypeContext . value_type ) ) ) ; } return typeDefinition ; } @ Override public Expr visitInsert_statement ( Insert_statementContext ctx ) { Insert insertExpr = new Insert ( ) ; if ( ctx . OVERWRITE ( ) != null ) { insertExpr . setOverwrite ( ) ; } if ( ctx . table_name ( ) != null ) { insertExpr . setTableName ( buildIdentifierChain ( ctx . table_name ( ) . identifier ( ) ) ) ; if ( ctx . column_reference_list ( ) != null ) { ColumnReferenceExpr [ ] targetColumns = new ColumnReferenceExpr [ ctx . column_reference_list ( ) . column_reference ( ) . size ( ) ] ; for ( int i = 0 ; i < targetColumns . length ; i ++ ) { targetColumns [ i ] = visitColumn_reference ( ctx . column_reference_list ( ) . column_reference ( i ) ) ; } insertExpr . setTargetColumns ( targetColumns ) ; } } if ( ctx . LOCATION ( ) != null ) { insertExpr . setLocation ( stripQuote ( ctx . path . getText ( ) ) ) ; if ( ctx . USING ( ) != null ) { insertExpr . setStorageType ( ctx . storage_type . getText ( ) ) ; if ( ctx . param_clause ( ) != null ) { insertExpr . setParams ( escapeTableMeta ( getParams ( ctx . param_clause ( ) ) ) ) ; } } } insertExpr . setSubQuery ( visitQuery_expression ( ctx . query_expression ( ) ) ) ; Preconditions . checkState ( insertExpr . hasTableName ( ) || insertExpr . hasLocation ( ) , ""Either a table name or a location should be given."" ) ; Preconditions . checkState ( insertExpr . hasTableName ( ) ^ insertExpr . hasLocation ( ) , ""A table name and a location cannot coexist."" ) ; return insertExpr ; } @ Override public Expr visitDrop_table_statement ( Drop_table_statementContext ctx ) { return new DropTable ( buildIdentifierChain ( ctx . table_name ( ) . identifier ( ) ) , checkIfExist ( ctx . if_exists ( ) ) , checkIfExist ( ctx . PURGE ( ) ) ) ; } private Map < String , String > getParams ( Param_clauseContext ctx ) { Map < String , String > params = new HashMap < String , String > ( ) ; for ( int i = 0 ; i < ctx . param ( ) . size ( ) ; i ++ ) { params . put ( stripQuote ( ctx . param ( i ) . key . getText ( ) ) , stripQuote ( ctx . param ( i ) . value . getText ( ) ) ) ; } return params ; } public Map < String , String > escapeTableMeta ( Map < String , String > map ) { Map < String , String > params = new HashMap < String , String > ( ) ; for ( Map . Entry < String , String > entry : map . entrySet ( ) ) { if ( entry . getKey ( ) . equals ( StorageConstants . TEXT_DELIMITER ) ) { params . put ( StorageConstants . TEXT_DELIMITER , StringUtils . unicodeEscapedDelimiter ( entry . getValue ( ) ) ) ; } else if ( TimeZoneUtil . isTimezone ( entry . getKey ( ) ) ) { params . put ( StorageConstants . TIMEZONE , TimeZoneUtil . getValidTimezone ( entry . getValue ( ) ) ) ; } else { params . put ( entry . getKey ( ) , entry . getValue ( ) ) ; } } return params ; } private static String stripQuote ( String str ) { return str . substring ( 1 , str . length ( ) - 1 ) ; } @ Override public Expr visitCast_specification ( Cast_specificationContext ctx ) { Expr operand = visitChildren ( ctx . cast_operand ( ) ) ; DataTypeExpr castTarget = visitData_type ( ctx . cast_target ( ) . data_type ( ) ) ; return new CastExpr ( operand , castTarget ) ; } @ Override public Expr visitUnsigned_value_specification ( @ NotNull Unsigned_value_specificationContext ctx ) { return visitChildren ( ctx ) ; } @ Override public Expr visitUnsigned_literal ( @ NotNull Unsigned_literalContext ctx ) { if ( checkIfExist ( ctx . unsigned_numeric_literal ( ) ) ) { return visitUnsigned_numeric_literal ( ctx . unsigned_numeric_literal ( ) ) ; } else { return visitGeneral_literal ( ctx . general_literal ( ) ) ; } } @ Override public Expr visitGeneral_literal ( General_literalContext ctx ) { if ( checkIfExist ( ctx . Character_String_Literal ( ) ) ) { return new LiteralValue ( stripQuote ( ctx . Character_String_Literal ( ) . getText ( ) ) , LiteralType . String ) ; } else if ( checkIfExist ( ctx . datetime_literal ( ) ) ) { return visitDatetime_literal ( ctx . datetime_literal ( ) ) ; } else { return new BooleanLiteral ( checkIfExist ( ctx . boolean_literal ( ) . TRUE ( ) ) ) ; } } @ Override public Expr visitDatetime_literal ( @ NotNull Datetime_literalContext ctx ) { if ( checkIfExist ( ctx . time_literal ( ) ) ) { return visitTime_literal ( ctx . time_literal ( ) ) ; } else if ( checkIfExist ( ctx . date_literal ( ) ) ) { return visitDate_literal ( ctx . date_literal ( ) ) ; } else if ( checkIfExist ( ctx . interval_literal ( ) ) ) { return visitInterval_literal ( ctx . interval_literal ( ) ) ; } else { return visitTimestamp_literal ( ctx . timestamp_literal ( ) ) ; } } @ Override public Expr visitTime_literal ( Time_literalContext ctx ) { String timePart = stripQuote ( ctx . time_string . getText ( ) ) ; return new TimeLiteral ( parseTime ( timePart ) ) ; } @ Override public Expr visitDate_literal ( Date_literalContext ctx ) { String datePart = stripQuote ( ctx . date_string . getText ( ) ) ; return new DateLiteral ( parseDate ( datePart ) ) ; } @ Override public Expr visitTimestamp_literal ( Timestamp_literalContext ctx ) { String timestampStr = stripQuote ( ctx . timestamp_string . getText ( ) ) ; String [ ] parts = timestampStr . split ( "" "" ) ; String datePart = parts [ 0 ] ; String timePart = parts [ 1 ] ; return new TimestampLiteral ( parseDate ( datePart ) , parseTime ( timePart ) ) ; } @ Override public Expr visitInterval_literal ( @ NotNull Interval_literalContext ctx ) { String intervalStr = stripQuote ( ctx . interval_string . getText ( ) ) ; return new IntervalLiteral ( intervalStr ) ; } @ Override public Expr visitDatetime_value_expression ( @ NotNull Datetime_value_expressionContext ctx ) { return visitDatetime_term ( ctx . datetime_term ( ) ) ; } @ Override public Expr visitDatetime_term ( @ NotNull Datetime_termContext ctx ) { return visitDatetime_factor ( ctx . datetime_factor ( ) ) ; } @ Override public Expr visitDatetime_factor ( @ NotNull Datetime_factorContext ctx ) { return visitDatetime_primary ( ctx . datetime_primary ( ) ) ; } @ Override public Expr visitDatetime_primary ( @ NotNull Datetime_primaryContext ctx ) { if ( checkIfExist ( ctx . value_expression_primary ( ) ) ) { return visitValue_expression_primary ( ctx . value_expression_primary ( ) ) ; } else { return visitDatetime_value_function ( ctx . datetime_value_function ( ) ) ; } } @ Override public Expr visitDatetime_value_function ( @ NotNull Datetime_value_functionContext ctx ) { if ( checkIfExist ( ctx . current_date_value_function ( ) ) ) { return visitCurrent_date_value_function ( ctx . current_date_value_function ( ) ) ; } else if ( checkIfExist ( ctx . current_time_value_function ( ) ) ) { return visitCurrent_time_value_function ( ctx . current_time_value_function ( ) ) ; } else { return visitCurrent_timestamp_value_function ( ctx . current_timestamp_value_function ( ) ) ; } } @ Override public Expr visitCurrent_date_value_function ( @ NotNull Current_date_value_functionContext ctx ) { String functionName = ""current_date"" ; Expr [ ] params = new Expr [ ] { } ; return new FunctionExpr ( functionName , params ) ; } @ Override public Expr visitCurrent_time_value_function ( @ NotNull Current_time_value_functionContext ctx ) { String functionName = ""current_time"" ; Expr [ ] params = new Expr [ ] { } ; return new FunctionExpr ( functionName , params ) ; } @ Override public Expr visitCurrent_timestamp_value_function ( @ NotNull Current_timestamp_value_functionContext ctx ) { String functionName = ""now"" ; Expr [ ] params = new Expr [ ] { } ; return new FunctionExpr ( functionName , params ) ; } private DateValue parseDate ( String datePart ) { String [ ] parts = datePart . split ( ""-"" ) ; return new DateValue ( parts [ 0 ] , parts [ 1 ] , parts [ 2 ] ) ; } private TimeValue parseTime ( String timePart ) { String [ ] parts = timePart . split ( "":"" ) ; TimeValue time ; boolean hasFractionOfSeconds = ( parts . length > 2 && parts [ 2 ] . indexOf ( '.' ) > 0 ) ; if ( hasFractionOfSeconds ) { String [ ] secondsParts = parts [ 2 ] . split ( ""\\."" ) ; time = new TimeValue ( parts [ 0 ] , parts [ 1 ] , secondsParts [ 0 ] ) ; if ( secondsParts . length == 2 ) { time . setSecondsFraction ( secondsParts [ 1 ] ) ; } } else { time = new TimeValue ( parts [ 0 ] , ( parts . length > 1 ? parts [ 1 ] : ""0"" ) , ( parts . length > 2 ? parts [ 2 ] : ""0"" ) ) ; } return time ; } @ Override public Expr visitAlter_tablespace_statement ( @ NotNull Alter_tablespace_statementContext ctx ) { AlterTablespace alter = new AlterTablespace ( ctx . space_name . getText ( ) ) ; alter . setLocation ( stripQuote ( ctx . uri . getText ( ) ) ) ; return alter ; } @ Override public Expr visitAlter_table_statement ( Alter_table_statementContext ctx ) { final List < Table_nameContext > tables = ctx . table_name ( ) ; final AlterTable alterTable = new AlterTable ( buildIdentifierChain ( tables . get ( 0 ) . identifier ( ) ) ) ; if ( tables . size ( ) == 2 ) { alterTable . setNewTableName ( buildIdentifierChain ( tables . get ( 1 ) . identifier ( ) ) ) ; } if ( checkIfExist ( ctx . column_name ( ) ) && ctx . column_name ( ) . size ( ) == 2 ) { final List < Column_nameContext > columns = ctx . column_name ( ) ; alterTable . setColumnName ( buildIdentifier ( columns . get ( 0 ) . identifier ( ) ) ) ; alterTable . setNewColumnName ( buildIdentifier ( columns . get ( 1 ) . identifier ( ) ) ) ; } Field_elementContext field_elementContext = ctx . field_element ( ) ; if ( checkIfExist ( field_elementContext ) ) { final String name = field_elementContext . name . getText ( ) ; final DataTypeExpr typeDef = visitData_type ( field_elementContext . field_type ( ) . data_type ( ) ) ; final ColumnDefinition columnDefinition = new ColumnDefinition ( name , typeDef ) ; alterTable . setAddNewColumn ( columnDefinition ) ; } if ( checkIfExist ( ctx . partition_column_value_list ( ) ) ) { List < Partition_column_valueContext > columnValueList = ctx . partition_column_value_list ( ) . partition_column_value ( ) ; int size = columnValueList . size ( ) ; ColumnReferenceExpr [ ] columns = new ColumnReferenceExpr [ size ] ; Expr [ ] values = new Expr [ size ] ; for ( int i = 0 ; i < size ; i ++ ) { Partition_column_valueContext columnValue = columnValueList . get ( i ) ; columns [ i ] = new ColumnReferenceExpr ( buildIdentifier ( columnValue . identifier ( ) ) ) ; values [ i ] = visitRow_value_predicand ( columnValue . row_value_predicand ( ) ) ; } alterTable . setColumns ( columns ) ; alterTable . setValues ( values ) ; if ( ctx . LOCATION ( ) != null ) { String path = stripQuote ( ctx . path . getText ( ) ) ; alterTable . setLocation ( path ) ; } alterTable . setPurge ( checkIfExist ( ctx . PURGE ( ) ) ) ; alterTable . setIfNotExists ( checkIfExist ( ctx . if_not_exists ( ) ) ) ; alterTable . setIfExists ( checkIfExist ( ctx . if_exists ( ) ) ) ; } if ( checkIfExist ( ctx . property_list ( ) ) ) { alterTable . setParams ( getProperties ( ctx . property_list ( ) ) ) ; } alterTable . setAlterTableOpType ( determineAlterTableType ( ctx ) ) ; return alterTable ; } private Map < String , String > getProperties ( Property_listContext ctx ) { Map < String , String > params = new HashMap < String , String > ( ) ; for ( int i = 0 ; i < ctx . property ( ) . size ( ) ; i ++ ) { params . put ( stripQuote ( ctx . property ( i ) . key . getText ( ) ) , stripQuote ( ctx . property ( i ) . value . getText ( ) ) ) ; } return params ; } private AlterTableOpType determineAlterTableType ( Alter_table_statementContext ctx ) { final int RENAME_MASK = 00000001 ; final int COLUMN_MASK = 00000010 ; final int TO_MASK = 00000100 ; final int ADD_MASK = 00001000 ; final int DROP_MASK = 00001001 ; final int PARTITION_MASK = 00000020 ; final int SET_MASK = 00000002 ; final int PROPERTY_MASK = 00010000 ; final int REPAIR_MASK = 00000003 ; int val = 00000000 ; for ( int idx = 1 ; idx < ctx . getChildCount ( ) ; idx ++ ) { if ( ctx . getChild ( idx ) instanceof TerminalNode ) { switch ( ( ( TerminalNode ) ctx . getChild ( idx ) ) . getSymbol ( ) . getType ( ) ) { case RENAME : val = val | RENAME_MASK ; break ; case COLUMN : val = val | COLUMN_MASK ; break ; case TO : val = val | TO_MASK ; break ; case ADD : val = val | ADD_MASK ; break ; case DROP : val = val | DROP_MASK ; break ; case PARTITION : val = val | PARTITION_MASK ; break ; case SET : val = val | SET_MASK ; break ; case PROPERTY : val = val | PROPERTY_MASK ; break ; case REPAIR : val = val | REPAIR_MASK ; break ; default : break ; } } } return evaluateAlterTableOperationTye ( val ) ; } private AlterTableOpType evaluateAlterTableOperationTye ( final int value ) { switch ( value ) { case 19 : return AlterTableOpType . REPAIR_PARTITION ; case 65 : return AlterTableOpType . RENAME_TABLE ; case 73 : return AlterTableOpType . RENAME_COLUMN ; case 520 : return AlterTableOpType . ADD_COLUMN ; case 528 : return AlterTableOpType . ADD_PARTITION ; case 529 : return AlterTableOpType . DROP_PARTITION ; case 4098 : return AlterTableOpType . SET_PROPERTY ; default : return null ; } } private static String buildIdentifier ( IdentifierContext identifier ) { if ( checkIfExist ( identifier . nonreserved_keywords ( ) ) ) { return identifier . getText ( ) . toLowerCase ( ) ; } else { return identifier . getText ( ) ; } } private static String buildIdentifierChain ( final Collection < IdentifierContext > identifierChains ) { return Joiner . on ( ""."" ) . join ( Collections2 . transform ( identifierChains , new Function < IdentifierContext , String > ( ) { @ Override public String apply ( IdentifierContext identifierContext ) { return buildIdentifier ( identifierContext ) ; } } ) ) ; } }",No
" class MyAppContext implements AppContext { private final ApplicationAttemptId myAppAttemptID ; private final ApplicationId myApplicationID ; private final JobId myJobID ; private final Map < JobId , Job > allJobs ; MyAppContext ( int numberMaps , int numberReduces ) { myApplicationID = ApplicationId . newInstance ( clock . getTime ( ) , 1 ) ; myAppAttemptID = ApplicationAttemptId . newInstance ( myApplicationID , 0 ) ; myJobID = recordFactory . newRecordInstance ( JobId . class ) ; myJobID . setAppId ( myApplicationID ) ; Job myJob = new MyJobImpl ( myJobID , numberMaps , numberReduces ) ; allJobs = Collections . singletonMap ( myJobID , myJob ) ; } @ Override public ApplicationAttemptId getApplicationAttemptId ( ) { return myAppAttemptID ; } @ Override public ApplicationId getApplicationID ( ) { return myApplicationID ; } @ Override public Job getJob ( JobId jobID ) { return allJobs . get ( jobID ) ; } @ Override public Map < JobId , Job > getAllJobs ( ) { return allJobs ; } @ Override public EventHandler getEventHandler ( ) { return dispatcher . getEventHandler ( ) ; } @ Override public CharSequence getUser ( ) { throw new UnsupportedOperationException ( ""Not supported yet."" ) ; } @ Override public Clock getClock ( ) { return clock ; } @ Override public String getApplicationName ( ) { return null ; } @ Override public long getStartTime ( ) { return 0 ; } @ Override public ClusterInfo getClusterInfo ( ) { return new ClusterInfo ( ) ; } @ Override public Set < String > getBlacklistedNodes ( ) { return null ; } @ Override public ClientToAMTokenSecretManager getClientToAMTokenSecretManager ( ) { return null ; } @ Override public boolean isLastAMRetry ( ) { return false ; } @ Override public boolean hasSuccessfullyUnregistered ( ) { return true ; } } ",Smelly
"public class ServletSecurityElement extends HttpConstraintElement { private final Map < String , HttpMethodConstraintElement > methodConstraints = new HashMap < String , HttpMethodConstraintElement > ( ) ; public ServletSecurityElement ( ) { super ( ) ; } public ServletSecurityElement ( Collection < HttpMethodConstraintElement > httpMethodConstraints ) { super ( ) ; addHttpMethodConstraints ( httpMethodConstraints ) ; } public ServletSecurityElement ( HttpConstraintElement httpConstraintElement ) { this ( httpConstraintElement , null ) ; } public ServletSecurityElement ( HttpConstraintElement httpConstraintElement , Collection < HttpMethodConstraintElement > httpMethodConstraints ) { super ( httpConstraintElement . getEmptyRoleSemantic ( ) , httpConstraintElement . getTransportGuarantee ( ) , httpConstraintElement . getRolesAllowed ( ) ) ; addHttpMethodConstraints ( httpMethodConstraints ) ; } public ServletSecurityElement ( ServletSecurity annotation ) { this ( new HttpConstraintElement ( annotation . value ( ) . value ( ) , annotation . value ( ) . transportGuarantee ( ) , annotation . value ( ) . rolesAllowed ( ) ) ) ; List < HttpMethodConstraintElement > l = new ArrayList < HttpMethodConstraintElement > ( ) ; HttpMethodConstraint [ ] constraints = annotation . httpMethodConstraints ( ) ; if ( constraints != null ) { for ( int i = 0 ; i < constraints . length ; i ++ ) { HttpMethodConstraintElement e = new HttpMethodConstraintElement ( constraints [ i ] . value ( ) , new HttpConstraintElement ( constraints [ i ] . emptyRoleSemantic ( ) , constraints [ i ] . transportGuarantee ( ) , constraints [ i ] . rolesAllowed ( ) ) ) ; l . add ( e ) ; } } addHttpMethodConstraints ( l ) ; } public Collection < HttpMethodConstraintElement > getHttpMethodConstraints ( ) { Collection < HttpMethodConstraintElement > result = new HashSet < HttpMethodConstraintElement > ( ) ; result . addAll ( methodConstraints . values ( ) ) ; return result ; } public Collection < String > getMethodNames ( ) { Collection < String > result = new HashSet < String > ( ) ; result . addAll ( methodConstraints . keySet ( ) ) ; return result ; } private void addHttpMethodConstraints ( Collection < HttpMethodConstraintElement > httpMethodConstraints ) { if ( httpMethodConstraints == null ) { return ; } for ( HttpMethodConstraintElement constraint : httpMethodConstraints ) { String method = constraint . getMethodName ( ) ; if ( methodConstraints . containsKey ( method ) ) { throw new IllegalArgumentException ( ""Duplicate method name: "" + method ) ; } methodConstraints . put ( method , constraint ) ; } } }",No
"public abstract class PortletRequest implements Request { private String servletPath ; private String pathInfo ; private final javax . portlet . PortletRequest request ; private final PortletEnvironment environment ; private String form_encoding ; private String container_encoding ; private PortletSession session ; private Cookie [ ] wrappedCookies ; private Map wrappedCookieMap ; protected String portletRequestURI ; protected PortletRequest ( String servletPath , String pathInfo , javax . portlet . PortletRequest request , PortletEnvironment environment ) { super ( ) ; this . servletPath = servletPath ; this . pathInfo = pathInfo ; this . request = request ; this . environment = environment ; } public Object get ( String name ) { if ( request instanceof MultipartActionRequest ) { return ( ( MultipartActionRequest ) request ) . get ( name ) ; } else { String [ ] values = request . getParameterValues ( name ) ; if ( values == null ) { return null ; } if ( values . length == 1 ) { return values [ 0 ] ; } if ( values . length > 1 ) { Vector vect = new Vector ( values . length ) ; for ( int i = 0 ; i < values . length ; i ++ ) { vect . add ( values [ i ] ) ; } return vect ; } return null ; } } public String getAuthType ( ) { return this . request . getAuthType ( ) ; } private synchronized void wrapCookies ( ) { this . wrappedCookieMap = new HashMap ( ) ; PortletPreferences cookies = this . request . getPreferences ( ) ; if ( cookies != null ) { this . wrappedCookies = new Cookie [ cookies . getMap ( ) . size ( ) ] ; int i = 0 ; for ( Enumeration e = cookies . getNames ( ) ; e . hasMoreElements ( ) ; i ++ ) { String name = ( String ) e . nextElement ( ) ; PortletCookie cookie = new PortletCookie ( name , cookies . getValue ( name , null ) ) ; this . wrappedCookies [ i ] = cookie ; this . wrappedCookieMap . put ( cookie . getName ( ) , cookie ) ; } } this . wrappedCookieMap = Collections . unmodifiableMap ( this . wrappedCookieMap ) ; } public Cookie [ ] getCookies ( ) { if ( this . wrappedCookieMap == null ) { wrapCookies ( ) ; } return this . wrappedCookies ; } public Map getCookieMap ( ) { if ( this . wrappedCookieMap == null ) { wrapCookies ( ) ; } return this . wrappedCookieMap ; } public long getDateHeader ( String name ) { return Long . parseLong ( this . request . getProperty ( name ) ) ; } public String getHeader ( String name ) { if ( PortletEnvironment . HEADER_PORTLET_MODE . equals ( name ) ) { return this . request . getPortletMode ( ) . toString ( ) ; } else if ( PortletEnvironment . HEADER_WINDOW_STATE . equals ( name ) ) { return this . request . getWindowState ( ) . toString ( ) ; } else { return this . request . getProperty ( name ) ; } } public Enumeration getHeaders ( String name ) { return this . request . getProperties ( name ) ; } public Enumeration getHeaderNames ( ) { final Enumeration names = this . request . getPropertyNames ( ) ; return new Enumeration ( ) { int position ; public boolean hasMoreElements ( ) { return names . hasMoreElements ( ) || position < 2 ; } public Object nextElement ( ) throws NoSuchElementException { if ( names . hasMoreElements ( ) ) { return names . nextElement ( ) ; } if ( position == 0 ) { position ++ ; return PortletEnvironment . HEADER_PORTLET_MODE ; } else if ( position == 1 ) { position ++ ; return PortletEnvironment . HEADER_WINDOW_STATE ; } else { throw new NoSuchElementException ( ) ; } } } ; } public abstract String getMethod ( ) ; public String getPathInfo ( ) { return this . pathInfo ; } public String getPathTranslated ( ) { return null ; } public String getContextPath ( ) { return this . request . getContextPath ( ) ; } public String getQueryString ( ) { return """" ; } public String getRemoteUser ( ) { return this . request . getRemoteUser ( ) ; } public boolean isUserInRole ( String role ) { return this . request . isUserInRole ( role ) ; } public java . security . Principal getUserPrincipal ( ) { return this . request . getUserPrincipal ( ) ; } public String getRequestedSessionId ( ) { return this . request . getRequestedSessionId ( ) ; } public String getRequestURI ( ) { if ( this . portletRequestURI == null ) { final StringBuffer buffer = new StringBuffer ( ) ; buffer . append ( this . request . getContextPath ( ) ) ; if ( getServletPath ( ) != null ) { if ( buffer . charAt ( buffer . length ( ) - 1 ) != '/' ) { buffer . append ( '/' ) ; } buffer . append ( getServletPath ( ) ) ; } if ( getPathInfo ( ) != null ) { if ( buffer . charAt ( buffer . length ( ) - 1 ) != '/' ) { buffer . append ( '/' ) ; } buffer . append ( getPathInfo ( ) ) ; } this . portletRequestURI = buffer . toString ( ) ; } return this . portletRequestURI ; } public String getSitemapURI ( ) { return this . environment . getURI ( ) ; } public String getServletPath ( ) { return this . servletPath ; } public Session getSession ( boolean create ) { javax . portlet . PortletSession serverSession = this . request . getPortletSession ( create ) ; if ( null != serverSession ) { if ( null != this . session ) { if ( this . session . session != serverSession ) { this . session . session = serverSession ; } } else { this . session = new PortletSession ( serverSession , this . environment . getDefaultSessionScope ( ) ) ; } } else { this . session = null ; } return this . session ; } public Session getSession ( ) { return this . getSession ( true ) ; } public boolean isRequestedSessionIdValid ( ) { return this . request . isRequestedSessionIdValid ( ) ; } public boolean isRequestedSessionIdFromCookie ( ) { return false ; } public boolean isRequestedSessionIdFromURL ( ) { return true ; } public Object getAttribute ( String name ) { return this . request . getAttribute ( name ) ; } public Enumeration getAttributeNames ( ) { return this . request . getAttributeNames ( ) ; } public String getCharacterEncoding ( ) { return this . form_encoding ; } public void setCharacterEncoding ( String form_encoding ) throws java . io . UnsupportedEncodingException { this . form_encoding = form_encoding ; } public void setContainerEncoding ( String container_encoding ) { this . container_encoding = container_encoding ; } public int getContentLength ( ) { return - 1 ; } public String getContentType ( ) { return null ; } public String getParameter ( String name ) { String value = this . request . getParameter ( name ) ; if ( this . form_encoding == null || value == null ) { return value ; } return decode ( value ) ; } private String decode ( String str ) { if ( str == null ) { return null ; } try { if ( this . container_encoding == null ) { this . container_encoding = ""ISO-8859-1"" ; } byte [ ] bytes = str . getBytes ( this . container_encoding ) ; return new String ( bytes , form_encoding ) ; } catch ( java . io . UnsupportedEncodingException uee ) { throw new CascadingRuntimeException ( ""Unsupported Encoding Exception"" , uee ) ; } } public Enumeration getParameterNames ( ) { return this . request . getParameterNames ( ) ; } public String [ ] getParameterValues ( String name ) { String [ ] values = this . request . getParameterValues ( name ) ; if ( values == null ) { return null ; } else if ( this . form_encoding == null ) { return values ; } String [ ] decoded_values = new String [ values . length ] ; for ( int i = 0 ; i < values . length ; ++ i ) { decoded_values [ i ] = decode ( values [ i ] ) ; } return decoded_values ; } public String getProtocol ( ) { return ""JSR168"" ; } public String getScheme ( ) { return this . request . getScheme ( ) ; } public String getServerName ( ) { return this . request . getServerName ( ) ; } public int getServerPort ( ) { return this . request . getServerPort ( ) ; } public String getRemoteAddr ( ) { return null ; } public String getRemoteHost ( ) { return null ; } public void setAttribute ( String name , Object o ) { this . request . setAttribute ( name , o ) ; } public void removeAttribute ( String name ) { this . request . removeAttribute ( name ) ; } public Locale getLocale ( ) { return this . request . getLocale ( ) ; } public Enumeration getLocales ( ) { return this . request . getLocales ( ) ; } public boolean isSecure ( ) { return this . request . isSecure ( ) ; } public javax . portlet . PortletRequest getPortletRequest ( ) { return request ; } public Map getParameterMap ( ) { return this . request . getParameterMap ( ) ; } public PortalContext getPortalContext ( ) { return this . request . getPortalContext ( ) ; } public PortletMode getPortletMode ( ) { return this . request . getPortletMode ( ) ; } public javax . portlet . PortletSession getPortletSession ( ) { return this . request . getPortletSession ( ) ; } public javax . portlet . PortletSession getPortletSession ( boolean create ) { return this . request . getPortletSession ( create ) ; } public PortletPreferences getPreferences ( ) { return this . request . getPreferences ( ) ; } public Enumeration getProperties ( String name ) { return this . request . getProperties ( name ) ; } public String getProperty ( String name ) { return this . request . getProperty ( name ) ; } public Enumeration getPropertyNames ( ) { return this . request . getPropertyNames ( ) ; } public String getResponseContentType ( ) { return this . request . getResponseContentType ( ) ; } public Enumeration getResponseContentTypes ( ) { return this . request . getResponseContentTypes ( ) ; } public WindowState getWindowState ( ) { return this . request . getWindowState ( ) ; } public boolean isPortletModeAllowed ( PortletMode mode ) { return this . request . isPortletModeAllowed ( mode ) ; } public boolean isWindowStateAllowed ( WindowState state ) { return this . request . isWindowStateAllowed ( state ) ; } }",No
"public class JspCalendar { Calendar calendar = null ; public JspCalendar ( ) { calendar = Calendar . getInstance ( ) ; Date trialTime = new Date ( ) ; calendar . setTime ( trialTime ) ; } public int getYear ( ) { return calendar . get ( Calendar . YEAR ) ; } public String getMonth ( ) { int m = getMonthInt ( ) ; String [ ] months = new String [ ] { ""January"" , ""February"" , ""March"" , ""April"" , ""May"" , ""June"" , ""July"" , ""August"" , ""September"" , ""October"" , ""November"" , ""December"" } ; if ( m > 12 ) return ""Unknown to Man"" ; return months [ m - 1 ] ; } public String getDay ( ) { int x = getDayOfWeek ( ) ; String [ ] days = new String [ ] { ""Sunday"" , ""Monday"" , ""Tuesday"" , ""Wednesday"" , ""Thursday"" , ""Friday"" , ""Saturday"" } ; if ( x > 7 ) return ""Unknown to Man"" ; return days [ x - 1 ] ; } public int getMonthInt ( ) { return 1 + calendar . get ( Calendar . MONTH ) ; } public String getDate ( ) { return getMonthInt ( ) + ""/"" + getDayOfMonth ( ) + ""/"" + getYear ( ) ; } public String getTime ( ) { return getHour ( ) + "":"" + getMinute ( ) + "":"" + getSecond ( ) ; } public int getDayOfMonth ( ) { return calendar . get ( Calendar . DAY_OF_MONTH ) ; } public int getDayOfYear ( ) { return calendar . get ( Calendar . DAY_OF_YEAR ) ; } public int getWeekOfYear ( ) { return calendar . get ( Calendar . WEEK_OF_YEAR ) ; } public int getWeekOfMonth ( ) { return calendar . get ( Calendar . WEEK_OF_MONTH ) ; } public int getDayOfWeek ( ) { return calendar . get ( Calendar . DAY_OF_WEEK ) ; } public int getHour ( ) { return calendar . get ( Calendar . HOUR_OF_DAY ) ; } public int getMinute ( ) { return calendar . get ( Calendar . MINUTE ) ; } public int getSecond ( ) { return calendar . get ( Calendar . SECOND ) ; } public static void main ( String args [ ] ) { JspCalendar db = new JspCalendar ( ) ; p ( ""date: "" + db . getDayOfMonth ( ) ) ; p ( ""year: "" + db . getYear ( ) ) ; p ( ""month: "" + db . getMonth ( ) ) ; p ( ""time: "" + db . getTime ( ) ) ; p ( ""date: "" + db . getDate ( ) ) ; p ( ""Day: "" + db . getDay ( ) ) ; p ( ""DayOfYear: "" + db . getDayOfYear ( ) ) ; p ( ""WeekOfYear: "" + db . getWeekOfYear ( ) ) ; p ( ""era: "" + db . getEra ( ) ) ; p ( ""ampm: "" + db . getAMPM ( ) ) ; p ( ""DST: "" + db . getDSTOffset ( ) ) ; p ( ""ZONE Offset: "" + db . getZoneOffset ( ) ) ; p ( ""TIMEZONE: "" + db . getUSTimeZone ( ) ) ; } private static void p ( String x ) { System . out . println ( x ) ; } public int getEra ( ) { return calendar . get ( Calendar . ERA ) ; } public String getUSTimeZone ( ) { String [ ] zones = new String [ ] { ""Hawaii"" , ""Alaskan"" , ""Pacific"" , ""Mountain"" , ""Central"" , ""Eastern"" } ; return zones [ 10 + getZoneOffset ( ) ] ; } public int getZoneOffset ( ) { return calendar . get ( Calendar . ZONE_OFFSET ) / ( 60 * 60 * 1000 ) ; } public int getDSTOffset ( ) { return calendar . get ( Calendar . DST_OFFSET ) / ( 60 * 60 * 1000 ) ; } public int getAMPM ( ) { return calendar . get ( Calendar . AM_PM ) ; } }",Smelly
"public class ActiveMQTopicMarshaller extends ActiveMQDestinationMarshaller { public byte getDataStructureType ( ) { return ActiveMQTopic . DATA_STRUCTURE_TYPE ; } public DataStructure createObject ( ) { return new ActiveMQTopic ( ) ; } public void tightUnmarshal ( OpenWireFormat wireFormat , Object o , DataInput dataIn , BooleanStream bs ) throws IOException { super . tightUnmarshal ( wireFormat , o , dataIn , bs ) ; } public int tightMarshal1 ( OpenWireFormat wireFormat , Object o , BooleanStream bs ) throws IOException { int rc = super . tightMarshal1 ( wireFormat , o , bs ) ; return rc + 0 ; } public void tightMarshal2 ( OpenWireFormat wireFormat , Object o , DataOutput dataOut , BooleanStream bs ) throws IOException { super . tightMarshal2 ( wireFormat , o , dataOut , bs ) ; } public void looseUnmarshal ( OpenWireFormat wireFormat , Object o , DataInput dataIn ) throws IOException { super . looseUnmarshal ( wireFormat , o , dataIn ) ; } public void looseMarshal ( OpenWireFormat wireFormat , Object o , DataOutput dataOut ) throws IOException { super . looseMarshal ( wireFormat , o , dataOut ) ; } }",No
"@ Entity @ DiscriminatorValue ( ""ATTACH_C"" ) @ FetchGroups ( { @ FetchGroup ( name = ""all"" , attributes = { @ FetchAttribute ( name = ""es"" , recursionDepth = 0 ) } ) } ) public class AttachC extends AttachB { private String cstr ; private int cint ; private double cdbl ; @ ManyToMany ( cascade = { CascadeType . PERSIST , CascadeType . MERGE } ) private List < AttachE > es = new LinkedList ( ) ; public void setCstr ( String cstr ) { this . cstr = cstr ; } public String getCstr ( ) { return this . cstr ; } public void setCint ( int cint ) { this . cint = cint ; } public int getCint ( ) { return this . cint ; } public void setCdbl ( double cdbl ) { this . cdbl = cdbl ; } public double getCdbl ( ) { return this . cdbl ; } public void setEs ( List es ) { this . es = es ; } public List getEs ( ) { return this . es ; } }",Smelly
" public class TestTableCFsUpdater extends ReplicationPeerConfigUpgrader { @ ClassRule public static final HBaseClassTestRule CLASS_RULE = HBaseClassTestRule . forClass ( TestTableCFsUpdater . class ) ; private static final Logger LOG = LoggerFactory . getLogger ( TestTableCFsUpdater . class ) ; private final static HBaseTestingUtility TEST_UTIL = new HBaseTestingUtility ( ) ; private static ZKWatcher zkw = null ; private static Abortable abortable = null ; private static ZKStorageUtil zkStorageUtil = null ; private static class ZKStorageUtil extends ZKReplicationPeerStorage { public ZKStorageUtil ( ZKWatcher zookeeper , Configuration conf ) { super ( zookeeper , conf ) ; } } @ Rule public TestName name = new TestName ( ) ; public TestTableCFsUpdater ( ) { super ( zkw , TEST_UTIL . getConfiguration ( ) ) ; } @ BeforeClass public static void setUpBeforeClass ( ) throws Exception { TEST_UTIL . startMiniZKCluster ( ) ; Configuration conf = TEST_UTIL . getConfiguration ( ) ; abortable = new Abortable ( ) { @ Override public void abort ( String why , Throwable e ) { LOG . info ( why , e ) ; } @ Override public boolean isAborted ( ) { return false ; } } ; zkw = new ZKWatcher ( conf , ""TableCFs"" , abortable , true ) ; zkStorageUtil = new ZKStorageUtil ( zkw , conf ) ; } @ AfterClass public static void tearDownAfterClass ( ) throws Exception { TEST_UTIL . shutdownMiniZKCluster ( ) ; } @ Test public void testUpgrade ( ) throws Exception { String peerId = ""1"" ; final TableName tableName1 = TableName . valueOf ( name . getMethodName ( ) + ""1"" ) ; final TableName tableName2 = TableName . valueOf ( name . getMethodName ( ) + ""2"" ) ; final TableName tableName3 = TableName . valueOf ( name . getMethodName ( ) + ""3"" ) ; ReplicationPeerConfig rpc = new ReplicationPeerConfig ( ) ; rpc . setClusterKey ( zkw . getQuorum ( ) ) ; String peerNode = zkStorageUtil . getPeerNode ( peerId ) ; ZKUtil . createWithParents ( zkw , peerNode , ReplicationPeerConfigUtil . toByteArray ( rpc ) ) ; String tableCFs = tableName1 + "":cf1,cf2;"" + tableName2 + "":cf3;"" + tableName3 ; String tableCFsNode = getTableCFsNode ( peerId ) ; LOG . info ( ""create tableCFs :"" + tableCFsNode + "" for peerId="" + peerId ) ; ZKUtil . createWithParents ( zkw , tableCFsNode , Bytes . toBytes ( tableCFs ) ) ; ReplicationPeerConfig actualRpc = ReplicationPeerConfigUtil . parsePeerFrom ( ZKUtil . getData ( zkw , peerNode ) ) ; String actualTableCfs = Bytes . toString ( ZKUtil . getData ( zkw , tableCFsNode ) ) ; assertEquals ( rpc . getClusterKey ( ) , actualRpc . getClusterKey ( ) ) ; assertNull ( actualRpc . getTableCFsMap ( ) ) ; assertEquals ( tableCFs , actualTableCfs ) ; peerId = ""2"" ; rpc = new ReplicationPeerConfig ( ) ; rpc . setClusterKey ( zkw . getQuorum ( ) ) ; peerNode = zkStorageUtil . getPeerNode ( peerId ) ; ZKUtil . createWithParents ( zkw , peerNode , ReplicationPeerConfigUtil . toByteArray ( rpc ) ) ; tableCFs = tableName1 + "":cf1,cf3;"" + tableName2 + "":cf2"" ; tableCFsNode = getTableCFsNode ( peerId ) ; LOG . info ( ""create tableCFs :"" + tableCFsNode + "" for peerId="" + peerId ) ; ZKUtil . createWithParents ( zkw , tableCFsNode , Bytes . toBytes ( tableCFs ) ) ; actualRpc = ReplicationPeerConfigUtil . parsePeerFrom ( ZKUtil . getData ( zkw , peerNode ) ) ; actualTableCfs = Bytes . toString ( ZKUtil . getData ( zkw , tableCFsNode ) ) ; assertEquals ( rpc . getClusterKey ( ) , actualRpc . getClusterKey ( ) ) ; assertNull ( actualRpc . getTableCFsMap ( ) ) ; assertEquals ( tableCFs , actualTableCfs ) ; peerId = ""3"" ; rpc = new ReplicationPeerConfig ( ) ; rpc . setClusterKey ( zkw . getQuorum ( ) ) ; peerNode = zkStorageUtil . getPeerNode ( peerId ) ; ZKUtil . createWithParents ( zkw , peerNode , ReplicationPeerConfigUtil . toByteArray ( rpc ) ) ; tableCFs = """" ; tableCFsNode = getTableCFsNode ( peerId ) ; LOG . info ( ""create tableCFs :"" + tableCFsNode + "" for peerId="" + peerId ) ; ZKUtil . createWithParents ( zkw , tableCFsNode , Bytes . toBytes ( tableCFs ) ) ; actualRpc = ReplicationPeerConfigUtil . parsePeerFrom ( ZKUtil . getData ( zkw , peerNode ) ) ; actualTableCfs = Bytes . toString ( ZKUtil . getData ( zkw , tableCFsNode ) ) ; assertEquals ( rpc . getClusterKey ( ) , actualRpc . getClusterKey ( ) ) ; assertNull ( actualRpc . getTableCFsMap ( ) ) ; assertEquals ( tableCFs , actualTableCfs ) ; peerId = ""4"" ; rpc = new ReplicationPeerConfig ( ) ; rpc . setClusterKey ( zkw . getQuorum ( ) ) ; peerNode = zkStorageUtil . getPeerNode ( peerId ) ; ZKUtil . createWithParents ( zkw , peerNode , ReplicationPeerConfigUtil . toByteArray ( rpc ) ) ; tableCFsNode = getTableCFsNode ( peerId ) ; actualRpc = ReplicationPeerConfigUtil . parsePeerFrom ( ZKUtil . getData ( zkw , peerNode ) ) ; actualTableCfs = Bytes . toString ( ZKUtil . getData ( zkw , tableCFsNode ) ) ; assertEquals ( rpc . getClusterKey ( ) , actualRpc . getClusterKey ( ) ) ; assertNull ( actualRpc . getTableCFsMap ( ) ) ; assertNull ( actualTableCfs ) ; copyTableCFs ( ) ; peerId = ""1"" ; peerNode = zkStorageUtil . getPeerNode ( peerId ) ; actualRpc = ReplicationPeerConfigUtil . parsePeerFrom ( ZKUtil . getData ( zkw , peerNode ) ) ; assertEquals ( rpc . getClusterKey ( ) , actualRpc . getClusterKey ( ) ) ; Map < TableName , List < String > > tableNameListMap = actualRpc . getTableCFsMap ( ) ; assertEquals ( 3 , tableNameListMap . size ( ) ) ; assertTrue ( tableNameListMap . containsKey ( tableName1 ) ) ; assertTrue ( tableNameListMap . containsKey ( tableName2 ) ) ; assertTrue ( tableNameListMap . containsKey ( tableName3 ) ) ; assertEquals ( 2 , tableNameListMap . get ( tableName1 ) . size ( ) ) ; assertEquals ( ""cf1"" , tableNameListMap . get ( tableName1 ) . get ( 0 ) ) ; assertEquals ( ""cf2"" , tableNameListMap . get ( tableName1 ) . get ( 1 ) ) ; assertEquals ( 1 , tableNameListMap . get ( tableName2 ) . size ( ) ) ; assertEquals ( ""cf3"" , tableNameListMap . get ( tableName2 ) . get ( 0 ) ) ; assertNull ( tableNameListMap . get ( tableName3 ) ) ; peerId = ""2"" ; peerNode = zkStorageUtil . getPeerNode ( peerId ) ; actualRpc = ReplicationPeerConfigUtil . parsePeerFrom ( ZKUtil . getData ( zkw , peerNode ) ) ; assertEquals ( rpc . getClusterKey ( ) , actualRpc . getClusterKey ( ) ) ; tableNameListMap = actualRpc . getTableCFsMap ( ) ; assertEquals ( 2 , tableNameListMap . size ( ) ) ; assertTrue ( tableNameListMap . containsKey ( tableName1 ) ) ; assertTrue ( tableNameListMap . containsKey ( tableName2 ) ) ; assertEquals ( 2 , tableNameListMap . get ( tableName1 ) . size ( ) ) ; assertEquals ( ""cf1"" , tableNameListMap . get ( tableName1 ) . get ( 0 ) ) ; assertEquals ( ""cf3"" , tableNameListMap . get ( tableName1 ) . get ( 1 ) ) ; assertEquals ( 1 , tableNameListMap . get ( tableName2 ) . size ( ) ) ; assertEquals ( ""cf2"" , tableNameListMap . get ( tableName2 ) . get ( 0 ) ) ; peerId = ""3"" ; peerNode = zkStorageUtil . getPeerNode ( peerId ) ; actualRpc = ReplicationPeerConfigUtil . parsePeerFrom ( ZKUtil . getData ( zkw , peerNode ) ) ; assertEquals ( rpc . getClusterKey ( ) , actualRpc . getClusterKey ( ) ) ; tableNameListMap = actualRpc . getTableCFsMap ( ) ; assertNull ( tableNameListMap ) ; peerId = ""4"" ; peerNode = zkStorageUtil . getPeerNode ( peerId ) ; actualRpc = ReplicationPeerConfigUtil . parsePeerFrom ( ZKUtil . getData ( zkw , peerNode ) ) ; assertEquals ( rpc . getClusterKey ( ) , actualRpc . getClusterKey ( ) ) ; tableNameListMap = actualRpc . getTableCFsMap ( ) ; assertNull ( tableNameListMap ) ; } ",No
" public static class StringArrayPage extends WebPage implements IMarkupResourceStreamProvider { private static final long serialVersionUID = 1L ; public String [ ] array = new String [ 0 ] ; public Form < Void > form ; public StringArrayPage ( ) { form = new Form < Void > ( ""form"" ) ; add ( form ) ; form . add ( new TextField < String [ ] > ( ""array"" , new PropertyModel < String [ ] > ( this , ""array"" ) ) { private static final long serialVersionUID = 1L ; @ Override @ SuppressWarnings ( ""unchecked"" ) public < C > IConverter < C > getConverter ( Class < C > type ) { return ( IConverter < C > ) new StringArrayConverter ( ) ; } } . setConvertEmptyInputStringToNull ( false ) ) ; } private class StringArrayConverter implements IConverter < String [ ] > { private static final long serialVersionUID = 1L ; @ Override public String [ ] convertToObject ( String value , Locale locale ) { return Strings . split ( value , ',' ) ; } @ Override public String convertToString ( String [ ] value , Locale locale ) { return Strings . join ( "","" , value ) ; } } @ Override public IResourceStream getMarkupResourceStream ( MarkupContainer container , Class < ? > containerClass ) { return new StringResourceStream ( ""<html><body><form wicket:id='form'><input type='text' wicket:id='array'/></form></body></html>"" ) ; } } ",No
" private static class SimpleCaseExpState extends ExpState { public ExpState [ ] states ; public SimpleCaseExpState ( Joins joins , ExpState [ ] states ) { super ( joins ) ; this . states = states ; } ",No
"@ SuppressWarnings ( ""serial"" ) public class TableRef implements Serializable { final transient private DataModelDesc model ; final private String alias ; final private TableDesc table ; final private Map < String , TblColRef > columns ; final private String modelName ; TableRef ( DataModelDesc model , String alias , TableDesc table , boolean filterOutComputedColumns ) { this . model = model ; this . modelName = model . getName ( ) ; this . alias = alias ; this . table = table ; this . columns = Maps . newLinkedHashMap ( ) ; for ( ColumnDesc col : table . getColumns ( ) ) { if ( ! filterOutComputedColumns || ! col . isComputedColumn ( ) ) { columns . put ( col . getName ( ) , new TblColRef ( this , col ) ) ; } } } public DataModelDesc getModel ( ) { return model ; } public String getAlias ( ) { return alias ; } public TableDesc getTableDesc ( ) { return table ; } public String getTableName ( ) { return table . getName ( ) ; } public String getTableIdentity ( ) { return table . getIdentity ( ) ; } public TblColRef getColumn ( String name ) { return columns . get ( name ) ; } public Collection < TblColRef > getColumns ( ) { return Collections . unmodifiableCollection ( columns . values ( ) ) ; } @ Deprecated public TblColRef makeFakeColumn ( String name ) { ColumnDesc colDesc = new ColumnDesc ( ) ; colDesc . setName ( name ) ; colDesc . setTable ( table ) ; return new TblColRef ( this , colDesc ) ; } @ Deprecated public TblColRef makeFakeColumn ( ColumnDesc colDesc ) { return new TblColRef ( this , colDesc ) ; } @ Override public boolean equals ( Object o ) { if ( this == o ) return true ; if ( o == null || getClass ( ) != o . getClass ( ) ) return false ; TableRef t = ( TableRef ) o ; if ( ( modelName == null ? t . modelName != null : modelName . equals ( t . modelName ) ) == false ) return false ; if ( ( alias == null ? t . alias == null : alias . equals ( t . alias ) ) == false ) return false ; if ( ! table . getIdentity ( ) . equals ( t . table . getIdentity ( ) ) ) return false ; return true ; } @ Override public int hashCode ( ) { int result = 0 ; result = 31 * result + modelName . hashCode ( ) ; result = 31 * result + alias . hashCode ( ) ; result = 31 * result + table . getIdentity ( ) . hashCode ( ) ; return result ; } @ Override public String toString ( ) { if ( alias . equals ( table . getName ( ) ) ) return ""TableRef["" + table . getName ( ) + ""]"" ; else return ""TableRef["" + alias + "":"" + table . getName ( ) + ""]"" ; } }",No
"public abstract class AbstractLegacyRepositoryContentTestCase extends AbstractRepositoryLayerTestCase { @ Test public void testBadPathArtifactIdMissingA ( ) { assertBadPath ( ""groupId/jars/-1.0.jar"" , ""artifactId is missing"" ) ; } @ Test public void testBadPathArtifactIdMissingB ( ) { assertBadPath ( ""groupId/jars/1.0.jar"" , ""artifactId is missing"" ) ; } @ Test public void testBadPathMissingType ( ) { assertBadPath ( ""invalid/invalid/1/invalid-1"" , ""missing type"" ) ; } @ Test public void testBadPathTooShort ( ) { assertBadPath ( ""invalid/invalid-1.0.jar"" , ""path is too short"" ) ; } @ Test public void testBadPathWrongPackageExtension ( ) { assertBadPath ( ""org.apache.maven.test/jars/artifactId-1.0.war"" , ""wrong package extension"" ) ; } @ Test public void testGoodButOddVersionSpecGanymedSsh2 ( ) throws LayoutException { String groupId = ""ch.ethz.ganymed"" ; String artifactId = ""ganymed-ssh2"" ; String version = ""build210"" ; String type = ""jar"" ; String path = ""ch.ethz.ganymed/jars/ganymed-ssh2-build210.jar"" ; assertLayout ( path , groupId , artifactId , version , null , type ) ; } @ Test public void testGoodButOddVersionSpecJavaxComm ( ) throws LayoutException { String groupId = ""javax"" ; String artifactId = ""comm"" ; String version = ""3.0-u1"" ; String type = ""jar"" ; String path = ""javax/jars/comm-3.0-u1.jar"" ; assertLayout ( path , groupId , artifactId , version , null , type ) ; } @ Test public void testGoodButOddVersionSpecJavaxPersistence ( ) throws LayoutException { String groupId = ""javax.persistence"" ; String artifactId = ""ejb"" ; String version = ""3.0-public_review"" ; String type = ""jar"" ; String path = ""javax.persistence/jars/ejb-3.0-public_review.jar"" ; assertLayout ( path , groupId , artifactId , version , null , type ) ; } @ Test public void testGoodCommonsLang ( ) throws LayoutException { String groupId = ""commons-lang"" ; String artifactId = ""commons-lang"" ; String version = ""2.1"" ; String type = ""jar"" ; String path = ""commons-lang/jars/commons-lang-2.1.jar"" ; assertLayout ( path , groupId , artifactId , version , null , type ) ; } @ Test public void testGoodDerby ( ) throws LayoutException { String groupId = ""org.apache.derby"" ; String artifactId = ""derby"" ; String version = ""10.2.2.0"" ; String type = ""jar"" ; String path = ""org.apache.derby/jars/derby-10.2.2.0.jar"" ; assertLayout ( path , groupId , artifactId , version , null , type ) ; } @ Test public void testGoodFooLibJavadoc ( ) throws LayoutException { String groupId = ""com.foo.lib"" ; String artifactId = ""foo-lib"" ; String version = ""2.1-alpha-1"" ; String type = ""javadoc"" ; String classifier = ""javadoc"" ; String path = ""com.foo.lib/javadoc.jars/foo-lib-2.1-alpha-1-javadoc.jar"" ; assertLayout ( path , groupId , artifactId , version , classifier , type ) ; } @ Test public void testGoodFooLibSources ( ) throws LayoutException { String groupId = ""com.foo.lib"" ; String artifactId = ""foo-lib"" ; String version = ""2.1-alpha-1"" ; String type = ""java-source"" ; String classifier = ""sources"" ; String path = ""com.foo.lib/java-sources/foo-lib-2.1-alpha-1-sources.jar"" ; assertLayout ( path , groupId , artifactId , version , classifier , type ) ; } @ Test public void testGoodFooTool ( ) throws LayoutException { String groupId = ""com.foo"" ; String artifactId = ""foo-tool"" ; String version = ""1.0"" ; String type = ""jar"" ; String path = ""com.foo/jars/foo-tool-1.0.jar"" ; assertLayout ( path , groupId , artifactId , version , null , type ) ; } @ Test public void testGoodGeronimoEjbSpec ( ) throws LayoutException { String groupId = ""org.apache.geronimo.specs"" ; String artifactId = ""geronimo-ejb_2.1_spec"" ; String version = ""1.0.1"" ; String type = ""jar"" ; String path = ""org.apache.geronimo.specs/jars/geronimo-ejb_2.1_spec-1.0.1.jar"" ; assertLayout ( path , groupId , artifactId , version , null , type ) ; } @ Test public void testGoodLdapClientsPom ( ) throws LayoutException { String groupId = ""directory-clients"" ; String artifactId = ""ldap-clients"" ; String version = ""0.9.1-SNAPSHOT"" ; String type = ""pom"" ; String path = ""directory-clients/poms/ldap-clients-0.9.1-SNAPSHOT.pom"" ; assertLayout ( path , groupId , artifactId , version , null , type ) ; } @ Test public void testGoodSnapshotMavenTest ( ) throws LayoutException { String groupId = ""org.apache.archiva.test"" ; String artifactId = ""redonkulous"" ; String version = ""3.1-beta-1-20050831.101112-42"" ; String type = ""jar"" ; String path = ""org.apache.archiva.test/jars/redonkulous-3.1-beta-1-20050831.101112-42.jar"" ; assertLayout ( path , groupId , artifactId , version , null , type ) ; } @ Test public void testGoodVersionKeywordInArtifactId ( ) throws LayoutException { String groupId = ""maven"" ; String artifactId = ""maven-test-plugin"" ; String version = ""1.8.2"" ; String type = ""pom"" ; String path = ""maven/poms/maven-test-plugin-1.8.2.pom"" ; assertLayout ( path , groupId , artifactId , version , null , type ) ; } @ Test public void testGoodDetectPluginMavenTest ( ) throws LayoutException { String groupId = ""maven"" ; String artifactId = ""maven-test-plugin"" ; String version = ""1.8.2"" ; String type = ""maven-one-plugin"" ; String path = ""maven/plugins/maven-test-plugin-1.8.2.jar"" ; assertLayout ( path , groupId , artifactId , version , null , type ) ; } @ Test public void testGoodDetectPluginAvalonMeta ( ) throws LayoutException { String groupId = ""avalon-meta"" ; String artifactId = ""avalon-meta-plugin"" ; String version = ""1.1"" ; String type = ""maven-one-plugin"" ; String path = ""avalon-meta/plugins/avalon-meta-plugin-1.1.jar"" ; assertLayout ( path , groupId , artifactId , version , null , type ) ; } @ Test public void testGoodDetectPluginCactusMaven ( ) throws LayoutException { String groupId = ""cactus"" ; String artifactId = ""cactus-maven"" ; String version = ""1.7dev-20040815"" ; String type = ""maven-one-plugin"" ; String path = ""cactus/plugins/cactus-maven-1.7dev-20040815.jar"" ; assertLayout ( path , groupId , artifactId , version , null , type ) ; } @ Test public void testGoodDetectPluginGeronimoPackaging ( ) throws LayoutException { String groupId = ""geronimo"" ; String artifactId = ""geronimo-packaging-plugin"" ; String version = ""1.0.1"" ; String type = ""maven-one-plugin"" ; String path = ""geronimo/plugins/geronimo-packaging-plugin-1.0.1.jar"" ; assertLayout ( path , groupId , artifactId , version , null , type ) ; } @ Test public void testMaven1Maven2PluginTypeDistinc ( ) throws Exception { String groupId = ""com.sun.tools.xjc.maven2"" ; String artifactId = ""maven-jaxb-plugin"" ; String version = ""1.1"" ; String type = ""maven-plugin"" ; String path = ""com.sun.tools.xjc.maven2/maven-plugins/maven-jaxb-plugin-1.1.jar"" ; assertLayout ( path , groupId , artifactId , version , null , type ) ; } private void assertLayout ( String path , String groupId , String artifactId , String version , String classifier , String type ) throws LayoutException { ArtifactReference expectedArtifact = createArtifact ( groupId , artifactId , version , classifier , type ) ; assertEquals ( ""Artifact <"" + expectedArtifact + ""> to path:"" , path , toPath ( expectedArtifact ) ) ; ArtifactReference testReference = toArtifactReference ( path ) ; assertArtifactReference ( testReference , groupId , artifactId , version , classifier , type ) ; assertEquals ( ""Artifact <"" + expectedArtifact + ""> to path:"" , path , toPath ( testReference ) ) ; } private void assertArtifactReference ( ArtifactReference actualReference , String groupId , String artifactId , String version , String classifier , String type ) { String expectedId = ""ArtifactReference - "" + groupId + "":"" + artifactId + "":"" + version + "":"" + type ; assertNotNull ( expectedId + "" - Should not be null."" , actualReference ) ; assertEquals ( expectedId + "" - Group ID"" , groupId , actualReference . getGroupId ( ) ) ; assertEquals ( expectedId + "" - Artifact ID"" , artifactId , actualReference . getArtifactId ( ) ) ; assertEquals ( expectedId + "" - Version ID"" , version , actualReference . getVersion ( ) ) ; assertEquals ( expectedId + "" - classifier"" , classifier , actualReference . getClassifier ( ) ) ; assertEquals ( expectedId + "" - Type"" , type , actualReference . getType ( ) ) ; } protected ArtifactReference createArtifact ( String groupId , String artifactId , String version , String classifier , String type ) { ArtifactReference artifact = new ArtifactReference ( ) ; artifact . setGroupId ( groupId ) ; artifact . setArtifactId ( artifactId ) ; artifact . setVersion ( version ) ; artifact . setClassifier ( classifier ) ; artifact . setType ( type ) ; assertNotNull ( artifact ) ; return artifact ; } private void assertBadPath ( String path , String reason ) { try { toArtifactReference ( path ) ; fail ( ""Should have thrown a LayoutException on the invalid path ["" + path + ""] because of ["" + reason + ""]"" ) ; } catch ( LayoutException e ) { } } protected abstract ArtifactReference toArtifactReference ( String path ) throws LayoutException ; protected abstract String toPath ( ArtifactReference reference ) ; }",No
"public class CoordinatorStreamStoreTestUtil { private final CoordinatorStreamStore coordinatorStreamStore ; private final MockCoordinatorStreamSystemFactory systemFactory ; private final Config config ; public CoordinatorStreamStoreTestUtil ( Config config ) { this ( config , ""test-kafka"" ) ; } public CoordinatorStreamStoreTestUtil ( Config config , String systemName ) { this . config = config ; this . systemFactory = new MockCoordinatorStreamSystemFactory ( ) ; MockCoordinatorStreamSystemFactory . enableMockConsumerCache ( ) ; SystemConsumer systemConsumer = systemFactory . getConsumer ( systemName , config , new NoOpMetricsRegistry ( ) ) ; SystemProducer systemProducer = systemFactory . getProducer ( systemName , config , new NoOpMetricsRegistry ( ) ) ; SystemAdmin systemAdmin = systemFactory . getAdmin ( systemName , config ) ; this . coordinatorStreamStore = new CoordinatorStreamStore ( config , systemProducer , systemConsumer , systemAdmin ) ; this . coordinatorStreamStore . init ( ) ; } public CoordinatorStreamStore getCoordinatorStreamStore ( ) { return coordinatorStreamStore ; } public MockCoordinatorStreamSystemFactory . MockCoordinatorStreamSystemProducer getMockCoordinatorStreamSystemProducer ( ) { return systemFactory . getCoordinatorStreamSystemProducer ( config , null ) ; } public MockCoordinatorStreamSystemFactory . MockCoordinatorStreamSystemConsumer getMockCoordinatorStreamSystemConsumer ( ) { return systemFactory . getCoordinatorStreamSystemConsumer ( config , null ) ; } }",No
 public static class Record { public String getName ( int index ) { return null ; } public final JCO . Field getField ( int index ) { return null ; } public final JCO . Field getField ( String name ) { return null ; } public String getString ( int index ) { return null ; } public JCO . Structure getStructure ( int index ) { return null ; } public JCO . Structure getStructure ( String name ) { return null ; } public JCO . Table getTable ( int index ) { return null ; } public JCO . Table getTable ( String name ) { return null ; } public int getFieldCount ( ) { return - 1 ; } ,Smelly
"public class OpenSearchServerDelete extends OpenSearchServerConnection { public OpenSearchServerDelete ( String documentURI , OpenSearchServerConfig config ) throws ManifoldCFException { super ( config ) ; StringBuffer url = getApiUrl ( ""delete"" ) ; url . append ( ""&uniq="" ) ; url . append ( urlEncode ( documentURI ) ) ; HttpGet method = new HttpGet ( url . toString ( ) ) ; call ( method ) ; if ( ""OK"" . equals ( checkXPath ( xPathStatus ) ) ) return ; setResult ( Result . ERROR , checkXPath ( xPathException ) ) ; } }",No
"public class BlobStoreBackedInputStreamImpl extends BackedInputStream { private static final Logger log = LoggerFactory . getLogger ( BlobStoreBackedInputStreamImpl . class ) ; private final BlobStore blobStore ; private final String bucket ; private final String key ; private final VersionCheck versionCheck ; private final ByteBuf buffer ; private final long objectLen ; private final int bufferSize ; private long cursor ; private long bufferOffsetStart ; private long bufferOffsetEnd ; public BlobStoreBackedInputStreamImpl ( BlobStore blobStore , String bucket , String key , VersionCheck versionCheck , long objectLen , int bufferSize ) { this . blobStore = blobStore ; this . bucket = bucket ; this . key = key ; this . versionCheck = versionCheck ; this . buffer = PulsarByteBufAllocator . DEFAULT . buffer ( bufferSize , bufferSize ) ; this . objectLen = objectLen ; this . bufferSize = bufferSize ; this . cursor = 0 ; this . bufferOffsetStart = this . bufferOffsetEnd = - 1 ; } private boolean refillBufferIfNeeded ( ) throws IOException { if ( buffer . readableBytes ( ) == 0 ) { if ( cursor >= objectLen ) { return false ; } long startRange = cursor ; long endRange = Math . min ( cursor + bufferSize - 1 , objectLen - 1 ) ; try { Blob blob = blobStore . getBlob ( bucket , key , new GetOptions ( ) . range ( startRange , endRange ) ) ; versionCheck . check ( key , blob ) ; try ( InputStream stream = blob . getPayload ( ) . openStream ( ) ) { buffer . clear ( ) ; bufferOffsetStart = startRange ; bufferOffsetEnd = endRange ; long bytesRead = endRange - startRange + 1 ; int bytesToCopy = ( int ) bytesRead ; while ( bytesToCopy > 0 ) { bytesToCopy -= buffer . writeBytes ( stream , bytesToCopy ) ; } cursor += buffer . readableBytes ( ) ; } } catch ( Throwable e ) { throw new IOException ( ""Error reading from BlobStore"" , e ) ; } } return true ; } @ Override public int read ( ) throws IOException { if ( refillBufferIfNeeded ( ) ) { return buffer . readUnsignedByte ( ) ; } else { return - 1 ; } } @ Override public int read ( byte [ ] b , int off , int len ) throws IOException { if ( refillBufferIfNeeded ( ) ) { int bytesToRead = Math . min ( len , buffer . readableBytes ( ) ) ; buffer . readBytes ( b , off , bytesToRead ) ; return bytesToRead ; } else { return - 1 ; } } @ Override public void seek ( long position ) { log . debug ( ""Seeking to {} on {}/{}, current position {}"" , position , bucket , key , cursor ) ; if ( position >= bufferOffsetStart && position <= bufferOffsetEnd ) { long newIndex = position - bufferOffsetStart ; buffer . readerIndex ( ( int ) newIndex ) ; } else { this . cursor = position ; buffer . clear ( ) ; } } @ Override public void seekForward ( long position ) throws IOException { if ( position >= cursor ) { seek ( position ) ; } else { throw new IOException ( String . format ( ""Error seeking, new position %d < current position %d"" , position , cursor ) ) ; } } @ Override public void close ( ) { buffer . release ( ) ; } }",No
"public class BooleanAnnotationExpression extends AbstractBooleanExpression { private final IAnnotationExpression e1 ; private final String op ; private final IAnnotationExpression e2 ; public BooleanAnnotationExpression ( IAnnotationExpression e1 , String op , IAnnotationExpression e2 ) { super ( ) ; this . e1 = e1 ; this . op = op ; this . e2 = e2 ; } @ Override public boolean getBooleanValue ( MatchContext context , RutaStream stream ) { AnnotationFS first = getFristExpression ( ) . getAnnotation ( context , stream ) ; AnnotationFS second = getSecondExpression ( ) . getAnnotation ( context , stream ) ; return eval ( first , getOperator ( ) , second ) ; } private boolean eval ( AnnotationFS t1 , String op , AnnotationFS t2 ) { if ( ""=="" . equals ( op ) ) { if ( t1 == null ) { return t2 == null ; } return t1 . equals ( t2 ) ; } else if ( ""!="" . equals ( op ) ) { if ( t1 == null ) { return t2 != null ; } return ! t1 . equals ( t2 ) ; } return false ; } public IAnnotationExpression getFristExpression ( ) { return e1 ; } public String getOperator ( ) { return op ; } public IAnnotationExpression getSecondExpression ( ) { return e2 ; } @ Override public String getStringValue ( MatchContext context , RutaStream stream ) { return e1 . getStringValue ( context , stream ) + "" "" + op + "" "" + e2 . getStringValue ( context , stream ) ; } }",Smelly
"public class DestinationInfoMarshaller extends BaseCommandMarshaller { public byte getDataStructureType ( ) { return DestinationInfo . DATA_STRUCTURE_TYPE ; } public DataStructure createObject ( ) { return new DestinationInfo ( ) ; } public void tightUnmarshal ( OpenWireFormat wireFormat , Object o , DataInput dataIn , BooleanStream bs ) throws IOException { super . tightUnmarshal ( wireFormat , o , dataIn , bs ) ; DestinationInfo info = ( DestinationInfo ) o ; info . setConnectionId ( ( org . apache . activemq . command . ConnectionId ) tightUnmarsalCachedObject ( wireFormat , dataIn , bs ) ) ; info . setDestination ( ( org . apache . activemq . command . ActiveMQDestination ) tightUnmarsalCachedObject ( wireFormat , dataIn , bs ) ) ; info . setOperationType ( dataIn . readByte ( ) ) ; info . setTimeout ( tightUnmarshalLong ( wireFormat , dataIn , bs ) ) ; if ( bs . readBoolean ( ) ) { short size = dataIn . readShort ( ) ; org . apache . activemq . command . BrokerId value [ ] = new org . apache . activemq . command . BrokerId [ size ] ; for ( int i = 0 ; i < size ; i ++ ) { value [ i ] = ( org . apache . activemq . command . BrokerId ) tightUnmarsalNestedObject ( wireFormat , dataIn , bs ) ; } info . setBrokerPath ( value ) ; } else { info . setBrokerPath ( null ) ; } } public int tightMarshal1 ( OpenWireFormat wireFormat , Object o , BooleanStream bs ) throws IOException { DestinationInfo info = ( DestinationInfo ) o ; int rc = super . tightMarshal1 ( wireFormat , o , bs ) ; rc += tightMarshalCachedObject1 ( wireFormat , ( DataStructure ) info . getConnectionId ( ) , bs ) ; rc += tightMarshalCachedObject1 ( wireFormat , ( DataStructure ) info . getDestination ( ) , bs ) ; rc += tightMarshalLong1 ( wireFormat , info . getTimeout ( ) , bs ) ; rc += tightMarshalObjectArray1 ( wireFormat , info . getBrokerPath ( ) , bs ) ; return rc + 1 ; } public void tightMarshal2 ( OpenWireFormat wireFormat , Object o , DataOutput dataOut , BooleanStream bs ) throws IOException { super . tightMarshal2 ( wireFormat , o , dataOut , bs ) ; DestinationInfo info = ( DestinationInfo ) o ; tightMarshalCachedObject2 ( wireFormat , ( DataStructure ) info . getConnectionId ( ) , dataOut , bs ) ; tightMarshalCachedObject2 ( wireFormat , ( DataStructure ) info . getDestination ( ) , dataOut , bs ) ; dataOut . writeByte ( info . getOperationType ( ) ) ; tightMarshalLong2 ( wireFormat , info . getTimeout ( ) , dataOut , bs ) ; tightMarshalObjectArray2 ( wireFormat , info . getBrokerPath ( ) , dataOut , bs ) ; } public void looseUnmarshal ( OpenWireFormat wireFormat , Object o , DataInput dataIn ) throws IOException { super . looseUnmarshal ( wireFormat , o , dataIn ) ; DestinationInfo info = ( DestinationInfo ) o ; info . setConnectionId ( ( org . apache . activemq . command . ConnectionId ) looseUnmarsalCachedObject ( wireFormat , dataIn ) ) ; info . setDestination ( ( org . apache . activemq . command . ActiveMQDestination ) looseUnmarsalCachedObject ( wireFormat , dataIn ) ) ; info . setOperationType ( dataIn . readByte ( ) ) ; info . setTimeout ( looseUnmarshalLong ( wireFormat , dataIn ) ) ; if ( dataIn . readBoolean ( ) ) { short size = dataIn . readShort ( ) ; org . apache . activemq . command . BrokerId value [ ] = new org . apache . activemq . command . BrokerId [ size ] ; for ( int i = 0 ; i < size ; i ++ ) { value [ i ] = ( org . apache . activemq . command . BrokerId ) looseUnmarsalNestedObject ( wireFormat , dataIn ) ; } info . setBrokerPath ( value ) ; } else { info . setBrokerPath ( null ) ; } } public void looseMarshal ( OpenWireFormat wireFormat , Object o , DataOutput dataOut ) throws IOException { DestinationInfo info = ( DestinationInfo ) o ; super . looseMarshal ( wireFormat , o , dataOut ) ; looseMarshalCachedObject ( wireFormat , ( DataStructure ) info . getConnectionId ( ) , dataOut ) ; looseMarshalCachedObject ( wireFormat , ( DataStructure ) info . getDestination ( ) , dataOut ) ; dataOut . writeByte ( info . getOperationType ( ) ) ; looseMarshalLong ( wireFormat , info . getTimeout ( ) , dataOut ) ; looseMarshalObjectArray ( wireFormat , info . getBrokerPath ( ) , dataOut ) ; } }",No
"public class CamelTransportFactory extends AbstractTransportFactory implements ConduitInitiator , DestinationFactory { public static final String TRANSPORT_ID = ""http://cxf.apache.org/transports/camel"" ; private static final Set < String > URI_PREFIXES = new HashSet < String > ( ) ; private Collection < String > activationNamespaces ; private HeaderFilterStrategy headerFilterStrategy = new CxfHeaderFilterStrategy ( ) ; static { URI_PREFIXES . add ( ""camel://"" ) ; } private Bus bus ; private CamelContext camelContext ; @ Resource ( name = ""bus"" ) public void setBus ( Bus b ) { bus = b ; } public Bus getBus ( ) { return bus ; } @ Resource public void setActivationNamespaces ( Collection < String > ans ) { activationNamespaces = ans ; } public CamelContext getCamelContext ( ) { return camelContext ; } @ Resource ( name = ""camelContext"" ) public void setCamelContext ( CamelContext camelContext ) { this . camelContext = camelContext ; } public Conduit getConduit ( EndpointInfo targetInfo ) throws IOException { return getConduit ( targetInfo , null ) ; } public Conduit getConduit ( EndpointInfo endpointInfo , EndpointReferenceType target ) throws IOException { return new CamelConduit ( camelContext , bus , endpointInfo , target , headerFilterStrategy ) ; } public Destination getDestination ( EndpointInfo endpointInfo ) throws IOException { return new CamelDestination ( camelContext , bus , this , endpointInfo , headerFilterStrategy ) ; } public Set < String > getUriPrefixes ( ) { return URI_PREFIXES ; } @ PostConstruct void registerWithBindingManager ( ) { if ( null == bus ) { return ; } ConduitInitiatorManager cim = bus . getExtension ( ConduitInitiatorManager . class ) ; if ( null != cim && null != activationNamespaces ) { for ( String ns : activationNamespaces ) { cim . registerConduitInitiator ( ns , this ) ; } } DestinationFactoryManager dfm = bus . getExtension ( DestinationFactoryManager . class ) ; if ( null != dfm && null != activationNamespaces ) { for ( String ns : activationNamespaces ) { dfm . registerDestinationFactory ( ns , this ) ; } } } public HeaderFilterStrategy getHeaderFilterStrategy ( ) { return headerFilterStrategy ; } public void setHeaderFilterStrategy ( HeaderFilterStrategy headerFilterStrategy ) { this . headerFilterStrategy = headerFilterStrategy ; } }",Smelly
"public class EntryValueEditor extends CellEditor implements IValueEditor { private Object value ; private Composite parent ; private String name ; private ImageDescriptor imageDescriptor ; protected ValueEditorManager valueEditorManager ; public EntryValueEditor ( Composite parent , ValueEditorManager valueEditorManager ) { super ( parent ) ; this . parent = parent ; this . valueEditorManager = valueEditorManager ; } protected Control createControl ( Composite parent ) { return null ; } protected final Object doGetValue ( ) { return value ; } protected void doSetFocus ( ) { } protected void doSetValue ( Object value ) { this . value = value ; } public void activate ( ) { Object value = getValue ( ) ; if ( value instanceof IEntry ) { IEntry entry = ( IEntry ) value ; if ( entry != null ) { EditEntryWizard wizard = new EditEntryWizard ( entry ) ; WizardDialog dialog = new WizardDialog ( parent . getShell ( ) , wizard ) ; dialog . setBlockOnOpen ( true ) ; dialog . create ( ) ; dialog . open ( ) ; } } fireCancelEditor ( ) ; } public CellEditor getCellEditor ( ) { return this ; } public String getDisplayValue ( AttributeHierarchy attributeHierarchy ) { List < IValue > valueList = new ArrayList < IValue > ( ) ; for ( IAttribute attribute : attributeHierarchy ) { valueList . addAll ( Arrays . asList ( attribute . getValues ( ) ) ) ; } StringBuffer sb = new StringBuffer ( ) ; if ( valueList . size ( ) > 1 ) { sb . append ( NLS . bind ( Messages . getString ( ""EntryValueEditor.n_values"" ) , valueList . size ( ) ) ) ; } boolean isFirst = true ; for ( IValue value : valueList ) { if ( isFirst ) { isFirst = false ; } else { sb . append ( "", "" ) ; } IValueEditor vp = getValueEditor ( value ) ; sb . append ( vp . getDisplayValue ( value ) ) ; } return sb . toString ( ) ; } public String getDisplayValue ( IValue value ) { IValueEditor vp = getValueEditor ( value ) ; return vp . getDisplayValue ( value ) ; } private IValueEditor getValueEditor ( IValue value ) { IValueEditor vp = valueEditorManager . getCurrentValueEditor ( value . getAttribute ( ) . getEntry ( ) , value . getAttribute ( ) . getDescription ( ) ) ; if ( vp instanceof EntryValueEditor ) { IValueEditor userSelectedValueEditor = valueEditorManager . getUserSelectedValueEditor ( ) ; valueEditorManager . setUserSelectedValueEditor ( null ) ; vp = valueEditorManager . getCurrentValueEditor ( value . getAttribute ( ) . getEntry ( ) , value . getAttribute ( ) . getDescription ( ) ) ; valueEditorManager . setUserSelectedValueEditor ( userSelectedValueEditor ) ; } return vp ; } public Object getRawValue ( AttributeHierarchy attributeHierarchy ) { return attributeHierarchy . getEntry ( ) ; } public boolean hasValue ( IValue value ) { return value . getAttribute ( ) . getEntry ( ) != null ; } public Object getRawValue ( IValue value ) { return value . getAttribute ( ) . getEntry ( ) ; } public Object getStringOrBinaryValue ( Object rawValue ) { return null ; } public void setValueEditorName ( String name ) { this . name = name ; } public String getValueEditorName ( ) { return name ; } public void setValueEditorImageDescriptor ( ImageDescriptor imageDescriptor ) { this . imageDescriptor = imageDescriptor ; } public ImageDescriptor getValueEditorImageDescriptor ( ) { return imageDescriptor ; } }",Smelly
"public class RegionBody extends Region { private CommonMarginBlock commonMarginBlock ; private Numeric columnCount ; private Length columnGap ; public RegionBody ( FONode parent ) { super ( parent ) ; } public void bind ( PropertyList pList ) throws FOPException { super . bind ( pList ) ; commonMarginBlock = pList . getMarginBlockProps ( ) ; columnCount = pList . get ( PR_COLUMN_COUNT ) . getNumeric ( ) ; columnGap = pList . get ( PR_COLUMN_GAP ) . getLength ( ) ; if ( ( getColumnCount ( ) > 1 ) && ( getOverflow ( ) == EN_SCROLL ) ) { getFOValidationEventProducer ( ) . columnCountErrorOnRegionBodyOverflowScroll ( this , getName ( ) , getLocator ( ) ) ; } } public CommonMarginBlock getCommonMarginBlock ( ) { return commonMarginBlock ; } public int getColumnCount ( ) { return columnCount . getValue ( ) ; } public int getColumnGap ( ) { return columnGap . getValue ( ) ; } public Rectangle getViewportRectangle ( FODimension reldims ) { PercentBaseContext pageWidthContext = getPageWidthContext ( LengthBase . CONTAINING_BLOCK_WIDTH ) ; PercentBaseContext pageHeightContext = getPageHeightContext ( LengthBase . CONTAINING_BLOCK_WIDTH ) ; int start ; int end ; switch ( getWritingMode ( ) . getEnumValue ( ) ) { case Constants . EN_RL_TB : start = commonMarginBlock . marginRight . getValue ( pageWidthContext ) ; end = commonMarginBlock . marginLeft . getValue ( pageWidthContext ) ; break ; case Constants . EN_TB_LR : case Constants . EN_TB_RL : start = commonMarginBlock . marginTop . getValue ( pageWidthContext ) ; end = commonMarginBlock . marginBottom . getValue ( pageWidthContext ) ; break ; case Constants . EN_LR_TB : default : start = commonMarginBlock . marginLeft . getValue ( pageWidthContext ) ; end = commonMarginBlock . marginRight . getValue ( pageWidthContext ) ; break ; } int before = commonMarginBlock . spaceBefore . getOptimum ( pageHeightContext ) . getLength ( ) . getValue ( pageHeightContext ) ; int after = commonMarginBlock . spaceAfter . getOptimum ( pageHeightContext ) . getLength ( ) . getValue ( pageHeightContext ) ; return new Rectangle ( start , before , reldims . ipd - start - end , reldims . bpd - before - after ) ; } public String getDefaultRegionName ( ) { return ""xsl-region-body"" ; } public String getLocalName ( ) { return ""region-body"" ; } public int getNameId ( ) { return FO_REGION_BODY ; } }",Smelly
"public class CurrencyValidatorTest extends TestCase { private static final char CURRENCY_SYMBOL = '\u00A4' ; private String US_DOLLAR ; private String UK_POUND ; public CurrencyValidatorTest ( String name ) { super ( name ) ; } @ Override protected void setUp ( ) throws Exception { super . setUp ( ) ; US_DOLLAR = ( new DecimalFormatSymbols ( Locale . US ) ) . getCurrencySymbol ( ) ; UK_POUND = ( new DecimalFormatSymbols ( Locale . UK ) ) . getCurrencySymbol ( ) ; } @ Override protected void tearDown ( ) throws Exception { super . tearDown ( ) ; } public void testFormatType ( ) { assertEquals ( ""Format Type A"" , 1 , CurrencyValidator . getInstance ( ) . getFormatType ( ) ) ; assertEquals ( ""Format Type B"" , AbstractNumberValidator . CURRENCY_FORMAT , CurrencyValidator . getInstance ( ) . getFormatType ( ) ) ; } public void testValid ( ) { Locale origDefault = Locale . getDefault ( ) ; Locale . setDefault ( Locale . UK ) ; BigDecimalValidator validator = CurrencyValidator . getInstance ( ) ; BigDecimal expected = new BigDecimal ( ""1234.56"" ) ; BigDecimal negative = new BigDecimal ( ""-1234.56"" ) ; BigDecimal noDecimal = new BigDecimal ( ""1234.00"" ) ; BigDecimal oneDecimal = new BigDecimal ( ""1234.50"" ) ; assertEquals ( ""Default locale"" , expected , validator . validate ( UK_POUND + ""1,234.56"" ) ) ; assertEquals ( ""UK locale"" , expected , validator . validate ( UK_POUND + ""1,234.56"" , Locale . UK ) ) ; assertEquals ( ""UK negative"" , negative , validator . validate ( ""-"" + UK_POUND + ""1,234.56"" , Locale . UK ) ) ; assertEquals ( ""UK no decimal"" , noDecimal , validator . validate ( UK_POUND + ""1,234"" , Locale . UK ) ) ; assertEquals ( ""UK 1 decimal"" , oneDecimal , validator . validate ( UK_POUND + ""1,234.5"" , Locale . UK ) ) ; assertEquals ( ""UK 3 decimal"" , expected , validator . validate ( UK_POUND + ""1,234.567"" , Locale . UK ) ) ; assertEquals ( ""UK no symbol"" , expected , validator . validate ( ""1,234.56"" , Locale . UK ) ) ; assertEquals ( ""US locale"" , expected , validator . validate ( US_DOLLAR + ""1,234.56"" , Locale . US ) ) ; assertEquals ( ""US negative"" , negative , validator . validate ( ""("" + US_DOLLAR + ""1,234.56)"" , Locale . US ) ) ; assertEquals ( ""US no decimal"" , noDecimal , validator . validate ( US_DOLLAR + ""1,234"" , Locale . US ) ) ; assertEquals ( ""US 1 decimal"" , oneDecimal , validator . validate ( US_DOLLAR + ""1,234.5"" , Locale . US ) ) ; assertEquals ( ""US 3 decimal"" , expected , validator . validate ( US_DOLLAR + ""1,234.567"" , Locale . US ) ) ; assertEquals ( ""US no symbol"" , expected , validator . validate ( ""1,234.56"" , Locale . US ) ) ; Locale . setDefault ( origDefault ) ; } public void testInvalid ( ) { BigDecimalValidator validator = CurrencyValidator . getInstance ( ) ; assertFalse ( ""isValid() Null Value"" , validator . isValid ( null ) ) ; assertFalse ( ""isValid() Empty Value"" , validator . isValid ( """" ) ) ; assertNull ( ""validate() Null Value"" , validator . validate ( null ) ) ; assertNull ( ""validate() Empty Value"" , validator . validate ( """" ) ) ; assertFalse ( ""UK wrong symbol"" , validator . isValid ( US_DOLLAR + ""1,234.56"" , Locale . UK ) ) ; assertFalse ( ""UK wrong negative"" , validator . isValid ( ""("" + UK_POUND + ""1,234.56)"" , Locale . UK ) ) ; assertFalse ( ""US wrong symbol"" , validator . isValid ( UK_POUND + ""1,234.56"" , Locale . US ) ) ; assertFalse ( ""US wrong negative"" , validator . isValid ( ""-"" + US_DOLLAR + ""1,234.56"" , Locale . US ) ) ; } public void testIntegerValid ( ) { Locale origDefault = Locale . getDefault ( ) ; Locale . setDefault ( Locale . UK ) ; CurrencyValidator validator = new CurrencyValidator ( ) ; BigDecimal expected = new BigDecimal ( ""1234.00"" ) ; BigDecimal negative = new BigDecimal ( ""-1234.00"" ) ; assertEquals ( ""Default locale"" , expected , validator . validate ( UK_POUND + ""1,234"" ) ) ; assertEquals ( ""UK locale"" , expected , validator . validate ( UK_POUND + ""1,234"" , Locale . UK ) ) ; assertEquals ( ""UK negative"" , negative , validator . validate ( ""-"" + UK_POUND + ""1,234"" , Locale . UK ) ) ; assertEquals ( ""US locale"" , expected , validator . validate ( US_DOLLAR + ""1,234"" , Locale . US ) ) ; assertEquals ( ""US negative"" , negative , validator . validate ( ""("" + US_DOLLAR + ""1,234)"" , Locale . US ) ) ; Locale . setDefault ( origDefault ) ; } public void testIntegerInvalid ( ) { CurrencyValidator validator = new CurrencyValidator ( true , false ) ; assertFalse ( ""UK positive"" , validator . isValid ( UK_POUND + ""1,234.56"" , Locale . UK ) ) ; assertFalse ( ""UK negative"" , validator . isValid ( ""-"" + UK_POUND + ""1,234.56"" , Locale . UK ) ) ; assertFalse ( ""US positive"" , validator . isValid ( US_DOLLAR + ""1,234.56"" , Locale . US ) ) ; assertFalse ( ""US negative"" , validator . isValid ( ""("" + US_DOLLAR + ""1,234.56)"" , Locale . US ) ) ; } public void testPattern ( ) { Locale origDefault = Locale . getDefault ( ) ; Locale . setDefault ( Locale . UK ) ; BigDecimalValidator validator = CurrencyValidator . getInstance ( ) ; String basicPattern = CURRENCY_SYMBOL + ""#,##0.000"" ; String pattern = basicPattern + "";["" + basicPattern + ""]"" ; BigDecimal expected = new BigDecimal ( ""1234.567"" ) ; BigDecimal negative = new BigDecimal ( ""-1234.567"" ) ; assertEquals ( ""default"" , expected , validator . validate ( UK_POUND + ""1,234.567"" , pattern ) ) ; assertEquals ( ""negative"" , negative , validator . validate ( ""["" + UK_POUND + ""1,234.567]"" , pattern ) ) ; assertEquals ( ""no symbol +ve"" , expected , validator . validate ( ""1,234.567"" , pattern ) ) ; assertEquals ( ""no symbol -ve"" , negative , validator . validate ( ""[1,234.567]"" , pattern ) ) ; assertEquals ( ""default"" , expected , validator . validate ( US_DOLLAR + ""1,234.567"" , pattern , Locale . US ) ) ; assertEquals ( ""negative"" , negative , validator . validate ( ""["" + US_DOLLAR + ""1,234.567]"" , pattern , Locale . US ) ) ; assertEquals ( ""no symbol +ve"" , expected , validator . validate ( ""1,234.567"" , pattern , Locale . US ) ) ; assertEquals ( ""no symbol -ve"" , negative , validator . validate ( ""[1,234.567]"" , pattern , Locale . US ) ) ; assertFalse ( ""invalid symbol"" , validator . isValid ( US_DOLLAR + ""1,234.567"" , pattern ) ) ; assertFalse ( ""invalid symbol"" , validator . isValid ( UK_POUND + ""1,234.567"" , pattern , Locale . US ) ) ; Locale . setDefault ( origDefault ) ; } }",No
"@ SuppressWarnings ( ""serial"" ) @ JsonAutoDetect ( fieldVisibility = Visibility . NONE , getterVisibility = Visibility . NONE , isGetterVisibility = Visibility . NONE , setterVisibility = Visibility . NONE ) public class ColumnDesc implements Serializable { @ JsonProperty ( ""id"" ) private String id ; @ JsonProperty ( ""name"" ) private String name ; @ JsonProperty ( ""datatype"" ) private String datatype ; @ JsonProperty ( ""comment"" ) @ JsonInclude ( JsonInclude . Include . NON_NULL ) private String comment ; @ JsonProperty ( ""data_gen"" ) @ JsonInclude ( JsonInclude . Include . NON_NULL ) private String dataGen ; @ JsonProperty ( ""index"" ) @ JsonInclude ( JsonInclude . Include . NON_NULL ) private String index ; @ JsonProperty ( ""cc_expr"" ) @ JsonInclude ( JsonInclude . Include . NON_NULL ) private String computedColumnExpr = null ; private DataType type ; private TableDesc table ; private int zeroBasedIndex = - 1 ; private boolean isNullable = true ; private TblColRef ref ; public ColumnDesc ( ) { } public ColumnDesc ( ColumnDesc other ) { this . id = other . id ; this . name = other . name ; this . datatype = other . datatype ; this . dataGen = other . datatype ; this . comment = other . comment ; this . dataGen = other . dataGen ; this . index = other . index ; this . computedColumnExpr = other . computedColumnExpr ; } public ColumnDesc ( String id , String name , String datatype , String comment , String dataGen , String index , String computedColumnExpr ) { this . id = id ; this . name = name ; this . datatype = datatype ; this . comment = comment ; this . dataGen = dataGen ; this . index = index ; this . computedColumnExpr = computedColumnExpr ; } @ Deprecated public TblColRef getRef ( ) { if ( ref == null ) { ref = new TblColRef ( this ) ; } return ref ; } public int getZeroBasedIndex ( ) { return zeroBasedIndex ; } public String getDatatype ( ) { return datatype ; } public void setDatatype ( String datatype ) { this . datatype = datatype ; type = DataType . getType ( datatype ) ; } public DataType getUpgradedType ( ) { return this . type ; } public String getId ( ) { return id ; } public void setId ( String id ) { this . id = id ; if ( id != null ) zeroBasedIndex = Integer . parseInt ( id ) - 1 ; } public String getName ( ) { return name ; } public void setName ( String name ) { this . name = name ; } public TableDesc getTable ( ) { return table ; } public void setTable ( TableDesc table ) { this . table = table ; } public String getComment ( ) { return comment ; } public void setComment ( String comment ) { this . comment = comment ; } public DataType getType ( ) { return type ; } public String getTypeName ( ) { return type . getName ( ) ; } public int getTypePrecision ( ) { return type . getPrecision ( ) ; } public int getTypeScale ( ) { return type . getScale ( ) ; } public boolean isNullable ( ) { return this . isNullable ; } public void setNullable ( boolean nullable ) { this . isNullable = nullable ; } public String getDataGen ( ) { return dataGen ; } public String getIndex ( ) { return index ; } public String getComputedColumnExpr ( ) { Preconditions . checkState ( computedColumnExpr != null ) ; return computedColumnExpr ; } public boolean isComputedColumn ( ) { return computedColumnExpr != null ; } public void init ( TableDesc table ) { this . table = table ; if ( name != null ) name = name . toUpperCase ( ) ; if ( id != null ) zeroBasedIndex = Integer . parseInt ( id ) - 1 ; DataType normalized = DataType . getType ( datatype ) ; if ( normalized == null ) { this . setDatatype ( null ) ; } else { this . setDatatype ( normalized . toString ( ) ) ; } } public static ColumnDesc mockup ( TableDesc table , int oneBasedColumnIndex , String name , String datatype ) { ColumnDesc desc = new ColumnDesc ( ) ; String id = """" + oneBasedColumnIndex ; desc . setId ( id ) ; desc . setName ( name ) ; desc . setDatatype ( datatype ) ; desc . init ( table ) ; return desc ; } @ Override public int hashCode ( ) { final int prime = 31 ; int result = 1 ; result = prime * result + ( ( name == null ) ? 0 : name . hashCode ( ) ) ; result = prime * result + ( ( table == null ) ? 0 : table . hashCode ( ) ) ; return result ; } @ Override public boolean equals ( Object obj ) { if ( this == obj ) return true ; if ( obj == null ) return false ; if ( getClass ( ) != obj . getClass ( ) ) return false ; ColumnDesc other = ( ColumnDesc ) obj ; if ( name == null ) { if ( other . name != null ) return false ; } else if ( ! name . equals ( other . name ) ) return false ; if ( table == null ) { if ( other . table != null ) return false ; } else if ( ! table . getIdentity ( ) . equals ( other . table . getIdentity ( ) ) ) return false ; return true ; } @ Override public String toString ( ) { return ""ColumnDesc{"" + ""id='"" + id + '\'' + "", name='"" + name + '\'' + "", datatype='"" + datatype + '\'' + "", comment='"" + comment + '\'' + '}' ; } }",Smelly
" private static class Edge { private final Vertex start ; private final Vertex end ; private final Line line ; private BSPTree < Euclidean2D > node ; public Edge ( final Vertex start , final Vertex end , final Line line ) { this . start = start ; this . end = end ; this . line = line ; this . node = null ; start . setOutgoing ( this ) ; end . setIncoming ( this ) ; } public Vertex getStart ( ) { return start ; } public Vertex getEnd ( ) { return end ; } public Line getLine ( ) { return line ; } public void setNode ( final BSPTree < Euclidean2D > node ) { this . node = node ; } public BSPTree < Euclidean2D > getNode ( ) { return node ; } public Vertex split ( final Line splitLine ) { final Vertex splitVertex = new Vertex ( line . intersection ( splitLine ) ) ; splitVertex . bindWith ( splitLine ) ; final Edge startHalf = new Edge ( start , splitVertex , line ) ; final Edge endHalf = new Edge ( splitVertex , end , line ) ; startHalf . node = node ; endHalf . node = node ; return splitVertex ; } ",Smelly
" public static class NoBackoffPolicy implements ClientBackoffPolicy { public NoBackoffPolicy ( Configuration conf ) { } @ Override public long getBackoffTime ( ServerName serverName , byte [ ] region , ServerStatistics stats ) { return 0 ; } } ",No
"public class TestTaskLogProcessor { private final List < File > toBeDeletedList = new LinkedList < File > ( ) ; @ After public void after ( ) { for ( File f : toBeDeletedList ) { f . delete ( ) ; } toBeDeletedList . clear ( ) ; } private File writeTestLog ( String id , String content ) throws IOException { File scriptFile = File . createTempFile ( getClass ( ) . getName ( ) + ""-"" + id + ""-"" , "".log"" ) ; scriptFile . deleteOnExit ( ) ; toBeDeletedList . add ( scriptFile ) ; PrintStream os = new PrintStream ( new FileOutputStream ( scriptFile ) ) ; try { os . print ( content ) ; } finally { os . close ( ) ; } return scriptFile ; } private String toString ( Throwable t ) { StringWriter sw = new StringWriter ( ) ; PrintWriter pw = new PrintWriter ( sw , false ) ; t . printStackTrace ( pw ) ; pw . close ( ) ; return sw . toString ( ) ; } private String writeThrowableAsFile ( String before , Throwable t , String after , String fileSuffix , TaskLogProcessor taskLogProcessor ) throws IOException { StringBuilder sb = new StringBuilder ( ) ; if ( before != null ) { sb . append ( before ) ; } final String stackTraceStr = toString ( t ) ; sb . append ( stackTraceStr ) ; if ( after != null ) { sb . append ( after ) ; } File file = writeTestLog ( fileSuffix , sb . toString ( ) ) ; taskLogProcessor . addTaskAttemptLogUrl ( file . toURI ( ) . toURL ( ) . toString ( ) ) ; return stackTraceStr ; } @ Test public void testGetStackTraces ( ) throws Exception { JobConf jobConf = new JobConf ( ) ; jobConf . set ( HiveConf . ConfVars . HIVEQUERYSTRING . varname , ""select * from foo group by moo;"" ) ; final TaskLogProcessor taskLogProcessor = new TaskLogProcessor ( jobConf ) ; Throwable oome = new OutOfMemoryError ( ""java heap space"" ) ; String oomeStr = writeThrowableAsFile ( ""Some line in the beginning\n"" , oome , null , ""1"" , taskLogProcessor ) ; Throwable compositeException = new InvocationTargetException ( new IOException ( new NullPointerException ( ) ) ) ; String compositeStr = writeThrowableAsFile ( null , compositeException , ""Some line in the end.\n"" , ""2"" , taskLogProcessor ) ; Throwable eofe = new EOFException ( ) ; String eofeStr = writeThrowableAsFile ( ""line a\nlineb\n"" , eofe , "" line c\nlineD\n"" , ""3"" , taskLogProcessor ) ; List < List < String > > stackTraces = taskLogProcessor . getStackTraces ( ) ; assertEquals ( 3 , stackTraces . size ( ) ) ; checkException ( oomeStr , stackTraces . get ( 0 ) ) ; checkException ( compositeStr , stackTraces . get ( 1 ) ) ; checkException ( eofeStr , stackTraces . get ( 2 ) ) ; } private void checkException ( String writenText , List < String > actualTrace ) throws IOException { List < String > expectedLines = getLines ( writenText ) ; String expected , actual ; for ( int i = 0 ; i < expectedLines . size ( ) ; i ++ ) { expected = expectedLines . get ( i ) ; actual = actualTrace . get ( i ) ; assertEquals ( expected , actual ) ; } } private List < String > getLines ( String text ) throws IOException { BufferedReader br = new BufferedReader ( new StringReader ( text ) ) ; List < String > list = new ArrayList < String > ( 48 ) ; String string ; while ( true ) { string = br . readLine ( ) ; if ( string == null ) { break ; } else { list . add ( string ) ; } } br . close ( ) ; return list ; } @ Test public void testScriptErrorHeuristic ( ) throws Exception { JobConf jobConf = new JobConf ( ) ; jobConf . set ( HiveConf . ConfVars . HIVEQUERYSTRING . varname , ""select * from foo group by moo;"" ) ; final TaskLogProcessor taskLogProcessor = new TaskLogProcessor ( jobConf ) ; String errorCode = ""7874"" ; String content = ""line a\nlineb\n"" + ""Script failed with code "" + errorCode + "" line c\nlineD\n"" ; File log3File = writeTestLog ( ""1"" , content ) ; taskLogProcessor . addTaskAttemptLogUrl ( log3File . toURI ( ) . toURL ( ) . toString ( ) ) ; List < ErrorAndSolution > errList = taskLogProcessor . getErrors ( ) ; assertEquals ( 1 , errList . size ( ) ) ; final ErrorAndSolution eas = errList . get ( 0 ) ; String error = eas . getError ( ) ; assertNotNull ( error ) ; assertTrue ( error . indexOf ( errorCode ) >= 0 ) ; String solution = eas . getSolution ( ) ; assertNotNull ( solution ) ; assertTrue ( solution . length ( ) > 0 ) ; } @ Test public void testDataCorruptErrorHeuristic ( ) throws Exception { JobConf jobConf = new JobConf ( ) ; jobConf . set ( HiveConf . ConfVars . HIVEQUERYSTRING . varname , ""select * from foo group by moo;"" ) ; final TaskLogProcessor taskLogProcessor = new TaskLogProcessor ( jobConf ) ; String badFile1 = ""hdfs://localhost/foo1/moo1/zoo1"" ; String badFile2 = ""hdfs://localhost/foo2/moo2/zoo2"" ; String content = ""line a\nlineb\n"" + ""split: "" + badFile1 + "" is very bad.\n"" + "" line c\nlineD\n"" + ""split: "" + badFile2 + "" is also very bad.\n"" + "" java.io.EOFException: null \n"" + ""line E\n"" ; File log3File = writeTestLog ( ""1"" , content ) ; taskLogProcessor . addTaskAttemptLogUrl ( log3File . toURI ( ) . toURL ( ) . toString ( ) ) ; List < ErrorAndSolution > errList = taskLogProcessor . getErrors ( ) ; assertEquals ( 1 , errList . size ( ) ) ; final ErrorAndSolution eas = errList . get ( 0 ) ; String error = eas . getError ( ) ; assertNotNull ( error ) ; assertTrue ( error . contains ( badFile1 ) || error . contains ( badFile2 ) ) ; String solution = eas . getSolution ( ) ; assertNotNull ( solution ) ; assertTrue ( solution . length ( ) > 0 ) ; } @ Test public void testMapAggrMemErrorHeuristic ( ) throws Exception { JobConf jobConf = new JobConf ( ) ; jobConf . set ( HiveConf . ConfVars . HIVEQUERYSTRING . varname , ""select * from foo group by moo;"" ) ; final TaskLogProcessor taskLogProcessor = new TaskLogProcessor ( jobConf ) ; Throwable oome = new OutOfMemoryError ( ""java heap space"" ) ; File log1File = writeTestLog ( ""1"" , toString ( oome ) ) ; taskLogProcessor . addTaskAttemptLogUrl ( log1File . toURI ( ) . toURL ( ) . toString ( ) ) ; List < ErrorAndSolution > errList = taskLogProcessor . getErrors ( ) ; assertEquals ( 1 , errList . size ( ) ) ; final ErrorAndSolution eas = errList . get ( 0 ) ; String error = eas . getError ( ) ; assertNotNull ( error ) ; assertTrue ( error . contains ( ""memory"" ) ) ; String solution = eas . getSolution ( ) ; assertNotNull ( solution ) ; assertTrue ( solution . length ( ) > 0 ) ; String confName = HiveConf . ConfVars . HIVEMAPAGGRHASHMEMORY . toString ( ) ; assertTrue ( solution . contains ( confName ) ) ; } }",No
"@ Explain ( displayName = ""Join Operator"" ) public class JoinDesc extends AbstractOperatorDesc { private static final long serialVersionUID = 1L ; public static final int INNER_JOIN = 0 ; public static final int LEFT_OUTER_JOIN = 1 ; public static final int RIGHT_OUTER_JOIN = 2 ; public static final int FULL_OUTER_JOIN = 3 ; public static final int UNIQUE_JOIN = 4 ; public static final int LEFT_SEMI_JOIN = 5 ; private boolean handleSkewJoin = false ; private int skewKeyDefinition = - 1 ; private Map < Byte , Path > bigKeysDirMap ; private Map < Byte , Map < Byte , Path > > smallKeysDirMap ; private Map < Byte , TableDesc > skewKeysValuesTables ; private Map < Byte , List < ExprNodeDesc > > exprs ; private Map < Byte , List < ExprNodeDesc > > filters ; private int [ ] [ ] filterMap ; private boolean [ ] nullsafes ; protected List < String > outputColumnNames ; private transient Map < String , Byte > reversedExprs ; protected boolean noOuterJoin ; protected JoinCondDesc [ ] conds ; protected Byte [ ] tagOrder ; private TableDesc keyTableDesc ; private boolean fixedAsSorted ; public JoinDesc ( ) { } public JoinDesc ( final Map < Byte , List < ExprNodeDesc > > exprs , List < String > outputColumnNames , final boolean noOuterJoin , final JoinCondDesc [ ] conds , final Map < Byte , List < ExprNodeDesc > > filters ) { this . exprs = exprs ; this . outputColumnNames = outputColumnNames ; this . noOuterJoin = noOuterJoin ; this . conds = conds ; this . filters = filters ; resetOrder ( ) ; } public void resetOrder ( ) { tagOrder = new Byte [ exprs . size ( ) ] ; for ( int i = 0 ; i < tagOrder . length ; i ++ ) { tagOrder [ i ] = ( byte ) i ; } } @ Override public Object clone ( ) { JoinDesc ret = new JoinDesc ( ) ; Map < Byte , List < ExprNodeDesc > > cloneExprs = new HashMap < Byte , List < ExprNodeDesc > > ( ) ; cloneExprs . putAll ( getExprs ( ) ) ; ret . setExprs ( cloneExprs ) ; Map < Byte , List < ExprNodeDesc > > cloneFilters = new HashMap < Byte , List < ExprNodeDesc > > ( ) ; cloneFilters . putAll ( getFilters ( ) ) ; ret . setFilters ( cloneFilters ) ; ret . setConds ( getConds ( ) . clone ( ) ) ; ret . setNoOuterJoin ( getNoOuterJoin ( ) ) ; ret . setNullSafes ( getNullSafes ( ) ) ; ret . setHandleSkewJoin ( handleSkewJoin ) ; ret . setSkewKeyDefinition ( getSkewKeyDefinition ( ) ) ; ret . setTagOrder ( getTagOrder ( ) . clone ( ) ) ; if ( getKeyTableDesc ( ) != null ) { ret . setKeyTableDesc ( ( TableDesc ) getKeyTableDesc ( ) . clone ( ) ) ; } if ( getBigKeysDirMap ( ) != null ) { Map < Byte , Path > cloneBigKeysDirMap = new HashMap < Byte , Path > ( ) ; cloneBigKeysDirMap . putAll ( getBigKeysDirMap ( ) ) ; ret . setBigKeysDirMap ( cloneBigKeysDirMap ) ; } if ( getSmallKeysDirMap ( ) != null ) { Map < Byte , Map < Byte , Path > > cloneSmallKeysDirMap = new HashMap < Byte , Map < Byte , Path > > ( ) ; cloneSmallKeysDirMap . putAll ( getSmallKeysDirMap ( ) ) ; ret . setSmallKeysDirMap ( cloneSmallKeysDirMap ) ; } if ( getSkewKeysValuesTables ( ) != null ) { Map < Byte , TableDesc > cloneSkewKeysValuesTables = new HashMap < Byte , TableDesc > ( ) ; cloneSkewKeysValuesTables . putAll ( getSkewKeysValuesTables ( ) ) ; ret . setSkewKeysValuesTables ( cloneSkewKeysValuesTables ) ; } if ( getOutputColumnNames ( ) != null ) { List < String > cloneOutputColumnNames = new ArrayList < String > ( ) ; cloneOutputColumnNames . addAll ( getOutputColumnNames ( ) ) ; ret . setOutputColumnNames ( cloneOutputColumnNames ) ; } if ( getReversedExprs ( ) != null ) { Map < String , Byte > cloneReversedExprs = new HashMap < String , Byte > ( ) ; cloneReversedExprs . putAll ( getReversedExprs ( ) ) ; ret . setReversedExprs ( cloneReversedExprs ) ; } return ret ; } public JoinDesc ( final Map < Byte , List < ExprNodeDesc > > exprs , List < String > outputColumnNames , final boolean noOuterJoin , final JoinCondDesc [ ] conds ) { this ( exprs , outputColumnNames , noOuterJoin , conds , null ) ; } public JoinDesc ( final Map < Byte , List < ExprNodeDesc > > exprs , List < String > outputColumnNames ) { this ( exprs , outputColumnNames , true , null ) ; } public JoinDesc ( final Map < Byte , List < ExprNodeDesc > > exprs , List < String > outputColumnNames , final JoinCondDesc [ ] conds ) { this ( exprs , outputColumnNames , true , conds , null ) ; } public JoinDesc ( JoinDesc clone ) { this . bigKeysDirMap = clone . bigKeysDirMap ; this . conds = clone . conds ; this . exprs = clone . exprs ; this . nullsafes = clone . nullsafes ; this . handleSkewJoin = clone . handleSkewJoin ; this . keyTableDesc = clone . keyTableDesc ; this . noOuterJoin = clone . noOuterJoin ; this . outputColumnNames = clone . outputColumnNames ; this . reversedExprs = clone . reversedExprs ; this . skewKeyDefinition = clone . skewKeyDefinition ; this . skewKeysValuesTables = clone . skewKeysValuesTables ; this . smallKeysDirMap = clone . smallKeysDirMap ; this . tagOrder = clone . tagOrder ; this . filters = clone . filters ; this . filterMap = clone . filterMap ; this . statistics = clone . statistics ; } public Map < Byte , List < ExprNodeDesc > > getExprs ( ) { return exprs ; } public Map < String , Byte > getReversedExprs ( ) { return reversedExprs ; } public void setReversedExprs ( Map < String , Byte > reversedExprs ) { this . reversedExprs = reversedExprs ; } @ Explain ( displayName = ""condition expressions"" ) public Map < Byte , String > getExprsStringMap ( ) { if ( getExprs ( ) == null ) { return null ; } LinkedHashMap < Byte , String > ret = new LinkedHashMap < Byte , String > ( ) ; for ( Map . Entry < Byte , List < ExprNodeDesc > > ent : getExprs ( ) . entrySet ( ) ) { StringBuilder sb = new StringBuilder ( ) ; boolean first = true ; if ( ent . getValue ( ) != null ) { for ( ExprNodeDesc expr : ent . getValue ( ) ) { if ( ! first ) { sb . append ( "" "" ) ; } first = false ; sb . append ( ""{"" ) ; sb . append ( expr . getExprString ( ) ) ; sb . append ( ""}"" ) ; } } ret . put ( ent . getKey ( ) , sb . toString ( ) ) ; } return ret ; } public void setExprs ( final Map < Byte , List < ExprNodeDesc > > exprs ) { this . exprs = exprs ; } @ Explain ( displayName = ""filter predicates"" ) public Map < Byte , String > getFiltersStringMap ( ) { if ( getFilters ( ) == null || getFilters ( ) . size ( ) == 0 ) { return null ; } LinkedHashMap < Byte , String > ret = new LinkedHashMap < Byte , String > ( ) ; boolean filtersPresent = false ; for ( Map . Entry < Byte , List < ExprNodeDesc > > ent : getFilters ( ) . entrySet ( ) ) { StringBuilder sb = new StringBuilder ( ) ; boolean first = true ; if ( ent . getValue ( ) != null ) { if ( ent . getValue ( ) . size ( ) != 0 ) { filtersPresent = true ; } for ( ExprNodeDesc expr : ent . getValue ( ) ) { if ( ! first ) { sb . append ( "" "" ) ; } first = false ; sb . append ( ""{"" ) ; sb . append ( expr . getExprString ( ) ) ; sb . append ( ""}"" ) ; } } ret . put ( ent . getKey ( ) , sb . toString ( ) ) ; } if ( filtersPresent ) { return ret ; } else { return null ; } } public Map < Byte , List < ExprNodeDesc > > getFilters ( ) { return filters ; } public void setFilters ( Map < Byte , List < ExprNodeDesc > > filters ) { this . filters = filters ; } @ Explain ( displayName = ""outputColumnNames"" ) public List < String > getOutputColumnNames ( ) { return outputColumnNames ; } public void setOutputColumnNames ( List < String > outputColumnNames ) { this . outputColumnNames = outputColumnNames ; } public boolean getNoOuterJoin ( ) { return noOuterJoin ; } public void setNoOuterJoin ( final boolean noOuterJoin ) { this . noOuterJoin = noOuterJoin ; } @ Explain ( displayName = ""condition map"" ) public List < JoinCondDesc > getCondsList ( ) { if ( conds == null ) { return null ; } ArrayList < JoinCondDesc > l = new ArrayList < JoinCondDesc > ( ) ; for ( JoinCondDesc cond : conds ) { l . add ( cond ) ; } return l ; } public JoinCondDesc [ ] getConds ( ) { return conds ; } public void setConds ( final JoinCondDesc [ ] conds ) { this . conds = conds ; } public Byte [ ] getTagOrder ( ) { return tagOrder ; } public void setTagOrder ( Byte [ ] tagOrder ) { this . tagOrder = tagOrder ; } @ Explain ( displayName = ""handleSkewJoin"" , displayOnlyOnTrue = true ) public boolean getHandleSkewJoin ( ) { return handleSkewJoin ; } public void setHandleSkewJoin ( boolean handleSkewJoin ) { this . handleSkewJoin = handleSkewJoin ; } public Map < Byte , Path > getBigKeysDirMap ( ) { return bigKeysDirMap ; } public void setBigKeysDirMap ( Map < Byte , Path > bigKeysDirMap ) { this . bigKeysDirMap = bigKeysDirMap ; } public Map < Byte , Map < Byte , Path > > getSmallKeysDirMap ( ) { return smallKeysDirMap ; } public void setSmallKeysDirMap ( Map < Byte , Map < Byte , Path > > smallKeysDirMap ) { this . smallKeysDirMap = smallKeysDirMap ; } public int getSkewKeyDefinition ( ) { return skewKeyDefinition ; } public void setSkewKeyDefinition ( int skewKeyDefinition ) { this . skewKeyDefinition = skewKeyDefinition ; } public Map < Byte , TableDesc > getSkewKeysValuesTables ( ) { return skewKeysValuesTables ; } public void setSkewKeysValuesTables ( Map < Byte , TableDesc > skewKeysValuesTables ) { this . skewKeysValuesTables = skewKeysValuesTables ; } public boolean isNoOuterJoin ( ) { return noOuterJoin ; } public void setKeyTableDesc ( TableDesc keyTblDesc ) { keyTableDesc = keyTblDesc ; } public TableDesc getKeyTableDesc ( ) { return keyTableDesc ; } public boolean [ ] getNullSafes ( ) { return nullsafes ; } public void setNullSafes ( boolean [ ] nullSafes ) { this . nullsafes = nullSafes ; } @ Explain ( displayName = ""nullSafes"" ) public String getNullSafeString ( ) { if ( nullsafes == null ) { return null ; } boolean hasNS = false ; for ( boolean ns : nullsafes ) { hasNS |= ns ; } return hasNS ? Arrays . toString ( nullsafes ) : null ; } public int [ ] [ ] getFilterMap ( ) { return filterMap ; } public void setFilterMap ( int [ ] [ ] filterMap ) { this . filterMap = filterMap ; } @ Explain ( displayName = ""filter mappings"" , normalExplain = false ) public Map < Integer , String > getFilterMapString ( ) { return toCompactString ( filterMap ) ; } protected Map < Integer , String > toCompactString ( int [ ] [ ] filterMap ) { if ( filterMap == null ) { return null ; } filterMap = compactFilter ( filterMap ) ; Map < Integer , String > result = new LinkedHashMap < Integer , String > ( ) ; for ( int i = 0 ; i < filterMap . length ; i ++ ) { if ( filterMap [ i ] == null ) { continue ; } result . put ( i , Arrays . toString ( filterMap [ i ] ) ) ; } return result . isEmpty ( ) ? null : result ; } private int [ ] [ ] compactFilter ( int [ ] [ ] filterMap ) { if ( filterMap == null ) { return null ; } for ( int i = 0 ; i < filterMap . length ; i ++ ) { if ( filterMap [ i ] != null ) { boolean noFilter = true ; for ( int j = 1 ; j < filterMap [ i ] . length ; j += 2 ) { if ( filterMap [ i ] [ j ] > 0 ) { noFilter = false ; break ; } } if ( noFilter ) { filterMap [ i ] = null ; } } } for ( int [ ] mapping : filterMap ) { if ( mapping != null ) { return filterMap ; } } return null ; } public int getTagLength ( ) { int tagLength = - 1 ; for ( byte tag : getExprs ( ) . keySet ( ) ) { tagLength = Math . max ( tagLength , tag + 1 ) ; } return tagLength ; } @ SuppressWarnings ( ""unchecked"" ) public < T > T [ ] convertToArray ( Map < Byte , T > source , Class < T > compType ) { T [ ] result = ( T [ ] ) Array . newInstance ( compType , getTagLength ( ) ) ; for ( Map . Entry < Byte , T > entry : source . entrySet ( ) ) { result [ entry . getKey ( ) ] = entry . getValue ( ) ; } return result ; } public boolean isFixedAsSorted ( ) { return fixedAsSorted ; } public void setFixedAsSorted ( boolean fixedAsSorted ) { this . fixedAsSorted = fixedAsSorted ; } }",Smelly
public class PersistenceAdapterView implements PersistenceAdapterViewMBean { private final String name ; private final PersistenceAdapter persistenceAdapter ; private Callable < String > inflightTransactionViewCallable ; private Callable < String > dataViewCallable ; public PersistenceAdapterView ( PersistenceAdapter adapter ) { this . name = adapter . toString ( ) ; this . persistenceAdapter = adapter ; } @ Override public String getName ( ) { return name ; } @ Override public String getTransactions ( ) { return invoke ( inflightTransactionViewCallable ) ; } @ Override public String getData ( ) { return invoke ( dataViewCallable ) ; } @ Override public long getSize ( ) { return persistenceAdapter . size ( ) ; } private String invoke ( Callable < String > callable ) { String result = null ; if ( callable != null ) { try { result = callable . call ( ) ; } catch ( Exception e ) { result = e . toString ( ) ; } } return result ; } public void setDataViewCallable ( Callable < String > dataViewCallable ) { this . dataViewCallable = dataViewCallable ; } public void setInflightTransactionViewCallable ( Callable < String > inflightTransactionViewCallable ) { this . inflightTransactionViewCallable = inflightTransactionViewCallable ; } },Smelly
"public abstract class AbstractSAML2SPServlet extends HttpServlet { private static final long serialVersionUID = 7969539245875799817L ; protected static final Logger LOG = LoggerFactory . getLogger ( AbstractSAML2SPServlet . class ) ; protected void prepare ( final HttpServletResponse response , final SAML2RequestTO requestTO ) throws IOException { response . setHeader ( HttpHeaders . CACHE_CONTROL , ""no-cache, no-store"" ) ; response . setHeader ( ""Pragma"" , ""no-cache"" ) ; switch ( requestTO . getBindingType ( ) ) { case REDIRECT : UriBuilder ub = UriBuilder . fromUri ( requestTO . getIdpServiceAddress ( ) ) ; ub . queryParam ( SSOConstants . SAML_REQUEST , requestTO . getContent ( ) ) ; ub . queryParam ( SSOConstants . RELAY_STATE , requestTO . getRelayState ( ) ) ; ub . queryParam ( SSOConstants . SIG_ALG , requestTO . getSignAlg ( ) ) ; ub . queryParam ( SSOConstants . SIGNATURE , requestTO . getSignature ( ) ) ; response . setStatus ( HttpServletResponse . SC_SEE_OTHER ) ; response . setHeader ( ""Location"" , ub . build ( ) . toASCIIString ( ) ) ; break ; case POST : default : response . setContentType ( MediaType . TEXT_HTML ) ; response . getWriter ( ) . write ( """" + ""<html xmlns=\""http://www.w3.org/1999/xhtml\"">"" + "" <body onLoad=\""document.forms[0].submit();\"">"" + ""  <form action=\"""" + requestTO . getIdpServiceAddress ( ) + ""\"" method=\""POST\"">"" + ""   <input type=\""hidden\"" name=\"""" + SSOConstants . SAML_REQUEST + ""\"""" + ""          value=\"""" + requestTO . getContent ( ) + ""\""/>"" + ""   <input type=\""hidden\"" name=\"""" + SSOConstants . RELAY_STATE + ""\"""" + ""          value=\"""" + requestTO . getRelayState ( ) + ""\""/>"" + ""   <input type=\""submit\"" style=\""visibility: hidden;\""/>"" + ""  </form>"" + "" </body>"" + ""</html>"" ) ; } } protected SAML2ReceivedResponseTO extract ( final InputStream response ) throws IOException { String strForm = IOUtils . toString ( response ) ; MultivaluedMap < String , String > params = JAXRSUtils . getStructuredParams ( strForm , ""&"" , false , false ) ; String samlResponse = params . getFirst ( SSOConstants . SAML_RESPONSE ) ; if ( StringUtils . isNotBlank ( samlResponse ) ) { samlResponse = URLDecoder . decode ( samlResponse , StandardCharsets . UTF_8 . name ( ) ) ; LOG . debug ( ""Received SAML Response: {}"" , samlResponse ) ; } String relayState = params . getFirst ( SSOConstants . RELAY_STATE ) ; LOG . debug ( ""Received Relay State: {}"" , relayState ) ; SAML2ReceivedResponseTO receivedResponseTO = new SAML2ReceivedResponseTO ( ) ; receivedResponseTO . setSamlResponse ( samlResponse ) ; receivedResponseTO . setRelayState ( relayState ) ; return receivedResponseTO ; } }",No
"public class SessionStateConfigUserAuthenticator implements HiveAuthenticationProvider { private final List < String > groupNames = new ArrayList < String > ( ) ; protected Configuration conf ; private SessionState sessionState ; @ Override public List < String > getGroupNames ( ) { return groupNames ; } @ Override public String getUserName ( ) { String newUserName = sessionState . getConf ( ) . get ( ""user.name"" , """" ) . trim ( ) ; if ( newUserName . isEmpty ( ) ) { return System . getProperty ( ""user.name"" ) ; } else { return newUserName ; } } @ Override public void destroy ( ) throws HiveException { return ; } @ Override public Configuration getConf ( ) { return null ; } @ Override public void setConf ( Configuration arg0 ) { } @ Override public void setSessionState ( SessionState sessionState ) { this . sessionState = sessionState ; } }",Smelly
public class SchemaPopUpMenu extends RootPopUpMenu { public SchemaPopUpMenu ( ) { rename . setVisible ( true ) ; delete . setVisible ( true ) ; addSchema . setVisible ( false ) ; addCatalog . setVisible ( false ) ; } },No
"public class PageModel implements Model { private static Log log = LogFactory . getLog ( PageModel . class ) ; private WeblogPageRequest pageRequest = null ; private URLStrategy urlStrategy = null ; private WeblogEntryCommentForm commentForm = null ; private Map requestParameters = null ; private Weblog weblog = null ; private DeviceType deviceType = null ; public PageModel ( ) { } public String getModelName ( ) { return ""model"" ; } public void init ( Map initData ) throws WebloggerException { WeblogRequest weblogRequest = ( WeblogRequest ) initData . get ( ""parsedRequest"" ) ; if ( weblogRequest == null ) { throw new WebloggerException ( ""expected weblogRequest from init data"" ) ; } if ( weblogRequest instanceof WeblogPageRequest ) { this . pageRequest = ( WeblogPageRequest ) weblogRequest ; } else { throw new WebloggerException ( ""weblogRequest is not a WeblogPageRequest."" + ""  PageModel only supports page requests."" ) ; } this . commentForm = ( WeblogEntryCommentForm ) initData . get ( ""commentForm"" ) ; this . requestParameters = ( Map ) initData . get ( ""requestParameters"" ) ; urlStrategy = ( URLStrategy ) initData . get ( ""urlStrategy"" ) ; if ( urlStrategy == null ) { urlStrategy = WebloggerFactory . getWeblogger ( ) . getUrlStrategy ( ) ; } weblog = pageRequest . getWeblog ( ) ; this . deviceType = weblogRequest . getDeviceType ( ) ; } public String getLocale ( ) { return pageRequest . getLocale ( ) ; } public WeblogWrapper getWeblog ( ) { return WeblogWrapper . wrap ( weblog , urlStrategy ) ; } public boolean isPermalink ( ) { return ( pageRequest . getWeblogAnchor ( ) != null ) ; } public boolean isSearchResults ( ) { return false ; } public WeblogEntryWrapper getWeblogEntry ( ) { if ( pageRequest . getWeblogEntry ( ) != null ) { return WeblogEntryWrapper . wrap ( pageRequest . getWeblogEntry ( ) , urlStrategy ) ; } return null ; } public ThemeTemplateWrapper getWeblogPage ( ) { if ( pageRequest . getWeblogPageName ( ) != null ) { return ThemeTemplateWrapper . wrap ( pageRequest . getWeblogPage ( ) ) ; } else { try { return ThemeTemplateWrapper . wrap ( weblog . getTheme ( ) . getDefaultTemplate ( ) ) ; } catch ( WebloggerException ex ) { log . error ( ""Error getting default page"" , ex ) ; } } return null ; } public WeblogCategoryWrapper getWeblogCategory ( ) { if ( pageRequest . getWeblogCategory ( ) != null ) { return WeblogCategoryWrapper . wrap ( pageRequest . getWeblogCategory ( ) , urlStrategy ) ; } return null ; } public List getTags ( ) { return pageRequest . getTags ( ) ; } public String getDeviceType ( ) { return deviceType . toString ( ) ; } public WeblogEntriesPager getWeblogEntriesPager ( ) { return getWeblogEntriesPager ( null ) ; } public WeblogEntriesPager getWeblogEntriesPager ( String catArgument ) { return getWeblogEntriesPager ( catArgument , null ) ; } public WeblogEntriesPager getWeblogEntriesPagerByTag ( String tagArgument ) { return getWeblogEntriesPager ( null , tagArgument ) ; } private WeblogEntriesPager getWeblogEntriesPager ( String catArgument , String tagArgument ) { String cat = pageRequest . getWeblogCategoryName ( ) ; if ( catArgument != null && ! StringUtils . isEmpty ( catArgument ) && ! ""nil"" . equals ( catArgument ) ) { cat = catArgument ; } List tags = pageRequest . getTags ( ) ; if ( tagArgument != null && ! StringUtils . isEmpty ( tagArgument ) && ! ""nil"" . equals ( tagArgument ) ) { tags = new ArrayList ( ) ; tags . add ( tagArgument ) ; } String dateString = pageRequest . getWeblogDate ( ) ; if ( pageRequest . getWeblogAnchor ( ) != null ) { return new WeblogEntriesPermalinkPager ( urlStrategy , weblog , pageRequest . getLocale ( ) , pageRequest . getWeblogPageName ( ) , pageRequest . getWeblogAnchor ( ) , pageRequest . getWeblogDate ( ) , cat , tags , pageRequest . getPageNum ( ) ) ; } else if ( dateString != null && dateString . length ( ) == 8 ) { return new WeblogEntriesDayPager ( urlStrategy , weblog , pageRequest . getLocale ( ) , pageRequest . getWeblogPageName ( ) , pageRequest . getWeblogAnchor ( ) , pageRequest . getWeblogDate ( ) , cat , tags , pageRequest . getPageNum ( ) ) ; } else if ( dateString != null && dateString . length ( ) == 6 ) { return new WeblogEntriesMonthPager ( urlStrategy , weblog , pageRequest . getLocale ( ) , pageRequest . getWeblogPageName ( ) , pageRequest . getWeblogAnchor ( ) , pageRequest . getWeblogDate ( ) , cat , tags , pageRequest . getPageNum ( ) ) ; } else { return new WeblogEntriesLatestPager ( urlStrategy , weblog , pageRequest . getLocale ( ) , pageRequest . getWeblogPageName ( ) , pageRequest . getWeblogAnchor ( ) , pageRequest . getWeblogDate ( ) , cat , tags , pageRequest . getPageNum ( ) ) ; } } public WeblogEntryCommentForm getCommentForm ( ) { if ( commentForm == null ) { commentForm = new WeblogEntryCommentForm ( ) ; } return commentForm ; } public String getRequestParameter ( String paramName ) { if ( requestParameters != null ) { String [ ] values = ( String [ ] ) requestParameters . get ( paramName ) ; if ( values != null && values . length > 0 ) { return values [ 0 ] ; } } return null ; } }",Smelly
"public class X509AuthenticationRequestToken extends NiFiAuthenticationRequestToken { private final String proxiedEntitiesChain ; private final X509PrincipalExtractor principalExtractor ; private final X509Certificate [ ] certificates ; public X509AuthenticationRequestToken ( final String proxiedEntitiesChain , final X509PrincipalExtractor principalExtractor , final X509Certificate [ ] certificates , final String clientAddress ) { super ( clientAddress ) ; setAuthenticated ( false ) ; this . proxiedEntitiesChain = proxiedEntitiesChain ; this . principalExtractor = principalExtractor ; this . certificates = certificates ; } @ Override public Object getCredentials ( ) { return null ; } @ Override public Object getPrincipal ( ) { if ( StringUtils . isBlank ( proxiedEntitiesChain ) ) { return principalExtractor . extractPrincipal ( certificates [ 0 ] ) ; } else { return String . format ( ""%s<%s>"" , proxiedEntitiesChain , principalExtractor . extractPrincipal ( certificates [ 0 ] ) ) ; } } public String getProxiedEntitiesChain ( ) { return proxiedEntitiesChain ; } public X509Certificate [ ] getCertificates ( ) { return certificates ; } @ Override public String toString ( ) { return getName ( ) ; } }",No
" private static class DCounter { double total ; int count , recordCount ; ",No
"public class UpsertSelectIT extends BaseClientManagedTimeIT { @ BeforeClass @ Shadower ( classBeingShadowed = BaseClientManagedTimeIT . class ) public static void doSetup ( ) throws Exception { Map < String , String > props = getDefaultProps ( ) ; props . put ( QueryServices . QUEUE_SIZE_ATTRIB , Integer . toString ( 500 ) ) ; props . put ( QueryServices . THREAD_POOL_SIZE_ATTRIB , Integer . toString ( 64 ) ) ; setUpTestDriver ( new ReadOnlyProps ( props . entrySet ( ) . iterator ( ) ) ) ; } @ Test public void testUpsertSelectWithNoIndex ( ) throws Exception { testUpsertSelect ( false ) ; } @ Test public void testUpsertSelecWithIndex ( ) throws Exception { testUpsertSelect ( true ) ; } private void testUpsertSelect ( boolean createIndex ) throws Exception { long ts = nextTimestamp ( ) ; String tenantId = getOrganizationId ( ) ; initATableValues ( tenantId , getDefaultSplits ( tenantId ) , null , ts - 1 ) ; ensureTableCreated ( getUrl ( ) , CUSTOM_ENTITY_DATA_FULL_NAME , ts - 1 ) ; String indexName = ""IDX1"" ; if ( createIndex ) { Properties props = new Properties ( ) ; props . setProperty ( PhoenixRuntime . CURRENT_SCN_ATTRIB , Long . toString ( ts ) ) ; Connection conn = DriverManager . getConnection ( getUrl ( ) , props ) ; conn . createStatement ( ) . execute ( ""CREATE INDEX IF NOT EXISTS "" + indexName + "" ON "" + TestUtil . ATABLE_NAME + ""(a_string)"" ) ; conn . close ( ) ; } PreparedStatement upsertStmt ; Properties props = new Properties ( ) ; props . setProperty ( PhoenixRuntime . CURRENT_SCN_ATTRIB , Long . toString ( ts + 2 ) ) ; props . setProperty ( UPSERT_BATCH_SIZE_ATTRIB , Integer . toString ( 3 ) ) ; Connection conn = DriverManager . getConnection ( getUrl ( ) , props ) ; conn . setAutoCommit ( true ) ; String upsert = ""UPSERT INTO "" + CUSTOM_ENTITY_DATA_FULL_NAME + ""(custom_entity_data_id, key_prefix, organization_id, created_by) "" + ""SELECT substr(entity_id, 4), substr(entity_id, 1, 3), organization_id, a_string  FROM ATABLE WHERE ?=a_string"" ; if ( createIndex ) { upsertStmt = conn . prepareStatement ( ""EXPLAIN "" + upsert ) ; upsertStmt . setString ( 1 , tenantId ) ; ResultSet ers = upsertStmt . executeQuery ( ) ; assertTrue ( ers . next ( ) ) ; String explainPlan = QueryUtil . getExplainPlan ( ers ) ; assertTrue ( explainPlan . contains ( "" SCAN OVER "" + indexName ) ) ; } upsertStmt = conn . prepareStatement ( upsert ) ; upsertStmt . setString ( 1 , A_VALUE ) ; int rowsInserted = upsertStmt . executeUpdate ( ) ; assertEquals ( 4 , rowsInserted ) ; conn . commit ( ) ; conn . close ( ) ; String query = ""SELECT key_prefix, substr(custom_entity_data_id, 1, 1), created_by FROM "" + CUSTOM_ENTITY_DATA_FULL_NAME + "" WHERE organization_id = ? "" ; props . setProperty ( PhoenixRuntime . CURRENT_SCN_ATTRIB , Long . toString ( ts + 3 ) ) ; conn = DriverManager . getConnection ( getUrl ( ) , props ) ; PreparedStatement statement = conn . prepareStatement ( query ) ; statement . setString ( 1 , tenantId ) ; ResultSet rs = statement . executeQuery ( ) ; assertTrue ( rs . next ( ) ) ; assertEquals ( ""00A"" , rs . getString ( 1 ) ) ; assertEquals ( ""1"" , rs . getString ( 2 ) ) ; assertEquals ( A_VALUE , rs . getString ( 3 ) ) ; assertTrue ( rs . next ( ) ) ; assertEquals ( ""00A"" , rs . getString ( 1 ) ) ; assertEquals ( ""2"" , rs . getString ( 2 ) ) ; assertEquals ( A_VALUE , rs . getString ( 3 ) ) ; assertTrue ( rs . next ( ) ) ; assertEquals ( ""00A"" , rs . getString ( 1 ) ) ; assertEquals ( ""3"" , rs . getString ( 2 ) ) ; assertEquals ( A_VALUE , rs . getString ( 3 ) ) ; assertTrue ( rs . next ( ) ) ; assertEquals ( ""00A"" , rs . getString ( 1 ) ) ; assertEquals ( ""4"" , rs . getString ( 2 ) ) ; assertEquals ( A_VALUE , rs . getString ( 3 ) ) ; assertFalse ( rs . next ( ) ) ; conn . close ( ) ; props . setProperty ( PhoenixRuntime . CURRENT_SCN_ATTRIB , Long . toString ( ts + 4 ) ) ; conn = DriverManager . getConnection ( getUrl ( ) , props ) ; conn . setAutoCommit ( true ) ; upsert = ""UPSERT INTO "" + CUSTOM_ENTITY_DATA_FULL_NAME + ""(custom_entity_data_id, key_prefix, organization_id, last_update_by, division) "" + ""SELECT custom_entity_data_id, key_prefix, organization_id, created_by, 1.0  FROM "" + CUSTOM_ENTITY_DATA_FULL_NAME + "" WHERE organization_id = ? and created_by >= 'a'"" ; upsertStmt = conn . prepareStatement ( upsert ) ; upsertStmt . setString ( 1 , tenantId ) ; assertEquals ( 4 , upsertStmt . executeUpdate ( ) ) ; conn . commit ( ) ; query = ""SELECT key_prefix, substr(custom_entity_data_id, 1, 1), created_by, last_update_by, division FROM "" + CUSTOM_ENTITY_DATA_FULL_NAME + "" WHERE organization_id = ?"" ; props . setProperty ( PhoenixRuntime . CURRENT_SCN_ATTRIB , Long . toString ( ts + 5 ) ) ; conn = DriverManager . getConnection ( getUrl ( ) , props ) ; statement = conn . prepareStatement ( query ) ; statement . setString ( 1 , tenantId ) ; rs = statement . executeQuery ( ) ; assertTrue ( rs . next ( ) ) ; assertEquals ( ""00A"" , rs . getString ( 1 ) ) ; assertEquals ( ""1"" , rs . getString ( 2 ) ) ; assertEquals ( A_VALUE , rs . getString ( 3 ) ) ; assertEquals ( A_VALUE , rs . getString ( 4 ) ) ; assertTrue ( BigDecimal . valueOf ( 1.0 ) . compareTo ( rs . getBigDecimal ( 5 ) ) == 0 ) ; assertTrue ( rs . next ( ) ) ; assertEquals ( ""00A"" , rs . getString ( 1 ) ) ; assertEquals ( ""2"" , rs . getString ( 2 ) ) ; assertEquals ( A_VALUE , rs . getString ( 3 ) ) ; assertEquals ( A_VALUE , rs . getString ( 4 ) ) ; assertTrue ( BigDecimal . valueOf ( 1.0 ) . compareTo ( rs . getBigDecimal ( 5 ) ) == 0 ) ; assertTrue ( rs . next ( ) ) ; assertEquals ( ""00A"" , rs . getString ( 1 ) ) ; assertEquals ( ""3"" , rs . getString ( 2 ) ) ; assertEquals ( A_VALUE , rs . getString ( 3 ) ) ; assertEquals ( A_VALUE , rs . getString ( 4 ) ) ; assertTrue ( BigDecimal . valueOf ( 1.0 ) . compareTo ( rs . getBigDecimal ( 5 ) ) == 0 ) ; assertTrue ( rs . next ( ) ) ; assertEquals ( ""00A"" , rs . getString ( 1 ) ) ; assertEquals ( ""4"" , rs . getString ( 2 ) ) ; assertEquals ( A_VALUE , rs . getString ( 3 ) ) ; assertEquals ( A_VALUE , rs . getString ( 4 ) ) ; assertTrue ( BigDecimal . valueOf ( 1.0 ) . compareTo ( rs . getBigDecimal ( 5 ) ) == 0 ) ; assertFalse ( rs . next ( ) ) ; conn . close ( ) ; } @ Test public void testUpsertSelectEmptyPKColumn ( ) throws Exception { long ts = nextTimestamp ( ) ; String tenantId = getOrganizationId ( ) ; initATableValues ( tenantId , getDefaultSplits ( tenantId ) , null , ts - 1 ) ; ensureTableCreated ( getUrl ( ) , PTSDB_NAME , ts - 1 ) ; Properties props = new Properties ( ) ; props . setProperty ( PhoenixRuntime . CURRENT_SCN_ATTRIB , Long . toString ( ts + 1 ) ) ; Connection conn = DriverManager . getConnection ( getUrl ( ) , props ) ; conn . setAutoCommit ( false ) ; String upsert = ""UPSERT INTO "" + PTSDB_NAME + ""(date, val, host) "" + ""SELECT current_date(), x_integer+2, entity_id FROM ATABLE WHERE a_integer >= ?"" ; PreparedStatement upsertStmt = conn . prepareStatement ( upsert ) ; upsertStmt . setInt ( 1 , 6 ) ; int rowsInserted = upsertStmt . executeUpdate ( ) ; assertEquals ( 4 , rowsInserted ) ; conn . commit ( ) ; conn . close ( ) ; String query = ""SELECT inst,host,date,val FROM "" + PTSDB_NAME ; props . setProperty ( PhoenixRuntime . CURRENT_SCN_ATTRIB , Long . toString ( ts + 2 ) ) ; conn = DriverManager . getConnection ( getUrl ( ) , props ) ; PreparedStatement statement = conn . prepareStatement ( query ) ; ResultSet rs = statement . executeQuery ( ) ; Date now = new Date ( System . currentTimeMillis ( ) ) ; assertTrue ( rs . next ( ) ) ; assertEquals ( null , rs . getString ( 1 ) ) ; assertEquals ( ROW6 , rs . getString ( 2 ) ) ; assertTrue ( rs . getDate ( 3 ) . before ( now ) ) ; assertEquals ( null , rs . getBigDecimal ( 4 ) ) ; assertTrue ( rs . next ( ) ) ; assertEquals ( null , rs . getString ( 1 ) ) ; assertEquals ( ROW7 , rs . getString ( 2 ) ) ; assertTrue ( rs . getDate ( 3 ) . before ( now ) ) ; assertTrue ( BigDecimal . valueOf ( 7 ) . compareTo ( rs . getBigDecimal ( 4 ) ) == 0 ) ; assertTrue ( rs . next ( ) ) ; assertEquals ( null , rs . getString ( 1 ) ) ; assertEquals ( ROW8 , rs . getString ( 2 ) ) ; assertTrue ( rs . getDate ( 3 ) . before ( now ) ) ; assertTrue ( BigDecimal . valueOf ( 6 ) . compareTo ( rs . getBigDecimal ( 4 ) ) == 0 ) ; assertTrue ( rs . next ( ) ) ; assertEquals ( null , rs . getString ( 1 ) ) ; assertEquals ( ROW9 , rs . getString ( 2 ) ) ; assertTrue ( rs . getDate ( 3 ) . before ( now ) ) ; assertTrue ( BigDecimal . valueOf ( 5 ) . compareTo ( rs . getBigDecimal ( 4 ) ) == 0 ) ; assertFalse ( rs . next ( ) ) ; conn . close ( ) ; props . setProperty ( PhoenixRuntime . CURRENT_SCN_ATTRIB , Long . toString ( ts + 3 ) ) ; conn = DriverManager . getConnection ( getUrl ( ) , props ) ; conn . setAutoCommit ( true ) ; upsert = ""UPSERT INTO "" + PTSDB_NAME + ""(date, val, inst) "" + ""SELECT date+1, val*10, host FROM "" + PTSDB_NAME ; upsertStmt = conn . prepareStatement ( upsert ) ; rowsInserted = upsertStmt . executeUpdate ( ) ; assertEquals ( 4 , rowsInserted ) ; conn . commit ( ) ; conn . close ( ) ; Date then = new Date ( now . getTime ( ) + QueryConstants . MILLIS_IN_DAY ) ; query = ""SELECT host,inst, date,val FROM "" + PTSDB_NAME + "" where inst is not null"" ; props . setProperty ( PhoenixRuntime . CURRENT_SCN_ATTRIB , Long . toString ( ts + 4 ) ) ; conn = DriverManager . getConnection ( getUrl ( ) , props ) ; statement = conn . prepareStatement ( query ) ; rs = statement . executeQuery ( ) ; assertTrue ( rs . next ( ) ) ; assertEquals ( null , rs . getString ( 1 ) ) ; assertEquals ( ROW6 , rs . getString ( 2 ) ) ; assertTrue ( rs . getDate ( 3 ) . after ( now ) && rs . getDate ( 3 ) . before ( then ) ) ; assertEquals ( null , rs . getBigDecimal ( 4 ) ) ; assertTrue ( rs . next ( ) ) ; assertEquals ( null , rs . getString ( 1 ) ) ; assertEquals ( ROW7 , rs . getString ( 2 ) ) ; assertTrue ( rs . getDate ( 3 ) . after ( now ) && rs . getDate ( 3 ) . before ( then ) ) ; assertTrue ( BigDecimal . valueOf ( 70 ) . compareTo ( rs . getBigDecimal ( 4 ) ) == 0 ) ; assertTrue ( rs . next ( ) ) ; assertEquals ( null , rs . getString ( 1 ) ) ; assertEquals ( ROW8 , rs . getString ( 2 ) ) ; assertTrue ( rs . getDate ( 3 ) . after ( now ) && rs . getDate ( 3 ) . before ( then ) ) ; assertTrue ( BigDecimal . valueOf ( 60 ) . compareTo ( rs . getBigDecimal ( 4 ) ) == 0 ) ; assertTrue ( rs . next ( ) ) ; assertEquals ( null , rs . getString ( 1 ) ) ; assertEquals ( ROW9 , rs . getString ( 2 ) ) ; assertTrue ( rs . getDate ( 3 ) . after ( now ) && rs . getDate ( 3 ) . before ( then ) ) ; assertTrue ( BigDecimal . valueOf ( 50 ) . compareTo ( rs . getBigDecimal ( 4 ) ) == 0 ) ; assertFalse ( rs . next ( ) ) ; conn . close ( ) ; props . setProperty ( PhoenixRuntime . CURRENT_SCN_ATTRIB , Long . toString ( ts + 4 ) ) ; conn = DriverManager . getConnection ( getUrl ( ) , props ) ; conn . setAutoCommit ( true ) ; upsert = ""UPSERT INTO "" + PTSDB_NAME + "" SELECT * FROM "" + PTSDB_NAME ; upsertStmt = conn . prepareStatement ( upsert ) ; rowsInserted = upsertStmt . executeUpdate ( ) ; assertEquals ( 8 , rowsInserted ) ; conn . commit ( ) ; conn . close ( ) ; query = ""SELECT * FROM "" + PTSDB_NAME ; props . setProperty ( PhoenixRuntime . CURRENT_SCN_ATTRIB , Long . toString ( ts + 4 ) ) ; conn = DriverManager . getConnection ( getUrl ( ) , props ) ; statement = conn . prepareStatement ( query ) ; rs = statement . executeQuery ( ) ; assertTrue ( rs . next ( ) ) ; assertEquals ( null , rs . getString ( 1 ) ) ; assertEquals ( ROW6 , rs . getString ( 2 ) ) ; assertTrue ( rs . getDate ( 3 ) . before ( now ) ) ; assertEquals ( null , rs . getBigDecimal ( 4 ) ) ; assertTrue ( rs . next ( ) ) ; assertEquals ( null , rs . getString ( 1 ) ) ; assertEquals ( ROW7 , rs . getString ( 2 ) ) ; assertTrue ( rs . getDate ( 3 ) . before ( now ) ) ; assertTrue ( BigDecimal . valueOf ( 7 ) . compareTo ( rs . getBigDecimal ( 4 ) ) == 0 ) ; assertTrue ( rs . next ( ) ) ; assertEquals ( null , rs . getString ( 1 ) ) ; assertEquals ( ROW8 , rs . getString ( 2 ) ) ; assertTrue ( rs . getDate ( 3 ) . before ( now ) ) ; assertTrue ( BigDecimal . valueOf ( 6 ) . compareTo ( rs . getBigDecimal ( 4 ) ) == 0 ) ; assertTrue ( rs . next ( ) ) ; assertEquals ( null , rs . getString ( 1 ) ) ; assertEquals ( ROW9 , rs . getString ( 2 ) ) ; assertTrue ( rs . getDate ( 3 ) . before ( now ) ) ; assertTrue ( BigDecimal . valueOf ( 5 ) . compareTo ( rs . getBigDecimal ( 4 ) ) == 0 ) ; assertTrue ( rs . next ( ) ) ; assertEquals ( ROW6 , rs . getString ( 1 ) ) ; assertEquals ( null , rs . getString ( 2 ) ) ; assertTrue ( rs . getDate ( 3 ) . after ( now ) && rs . getDate ( 3 ) . before ( then ) ) ; assertEquals ( null , rs . getBigDecimal ( 4 ) ) ; assertTrue ( rs . next ( ) ) ; assertEquals ( ROW7 , rs . getString ( 1 ) ) ; assertEquals ( null , rs . getString ( 2 ) ) ; assertTrue ( rs . getDate ( 3 ) . after ( now ) && rs . getDate ( 3 ) . before ( then ) ) ; assertTrue ( BigDecimal . valueOf ( 70 ) . compareTo ( rs . getBigDecimal ( 4 ) ) == 0 ) ; assertTrue ( rs . next ( ) ) ; assertEquals ( ROW8 , rs . getString ( 1 ) ) ; assertEquals ( null , rs . getString ( 2 ) ) ; assertTrue ( rs . getDate ( 3 ) . after ( now ) && rs . getDate ( 3 ) . before ( then ) ) ; assertTrue ( BigDecimal . valueOf ( 60 ) . compareTo ( rs . getBigDecimal ( 4 ) ) == 0 ) ; assertTrue ( rs . next ( ) ) ; assertEquals ( ROW9 , rs . getString ( 1 ) ) ; assertEquals ( null , rs . getString ( 2 ) ) ; assertTrue ( rs . getDate ( 3 ) . after ( now ) && rs . getDate ( 3 ) . before ( then ) ) ; assertTrue ( BigDecimal . valueOf ( 50 ) . compareTo ( rs . getBigDecimal ( 4 ) ) == 0 ) ; assertFalse ( rs . next ( ) ) ; conn . close ( ) ; } @ Test public void testUpsertSelectForAggAutoCommit ( ) throws Exception { testUpsertSelectForAgg ( true ) ; } @ Test public void testUpsertSelectForAgg ( ) throws Exception { testUpsertSelectForAgg ( false ) ; } private void testUpsertSelectForAgg ( boolean autoCommit ) throws Exception { long ts = nextTimestamp ( ) ; String tenantId = getOrganizationId ( ) ; initATableValues ( tenantId , getDefaultSplits ( tenantId ) , null , ts - 1 ) ; ensureTableCreated ( getUrl ( ) , PTSDB_NAME , ts - 1 ) ; Properties props = new Properties ( ) ; props . setProperty ( PhoenixRuntime . CURRENT_SCN_ATTRIB , Long . toString ( ts + 1 ) ) ; Connection conn = DriverManager . getConnection ( getUrl ( ) , props ) ; conn . setAutoCommit ( autoCommit ) ; String upsert = ""UPSERT INTO "" + PTSDB_NAME + ""(date, val, host) "" + ""SELECT current_date(), sum(a_integer), a_string FROM ATABLE GROUP BY a_string"" ; PreparedStatement upsertStmt = conn . prepareStatement ( upsert ) ; int rowsInserted = upsertStmt . executeUpdate ( ) ; assertEquals ( 3 , rowsInserted ) ; if ( ! autoCommit ) { conn . commit ( ) ; } conn . close ( ) ; String query = ""SELECT inst,host,date,val FROM "" + PTSDB_NAME ; props . setProperty ( PhoenixRuntime . CURRENT_SCN_ATTRIB , Long . toString ( ts + 2 ) ) ; conn = DriverManager . getConnection ( getUrl ( ) , props ) ; PreparedStatement statement = conn . prepareStatement ( query ) ; ResultSet rs = statement . executeQuery ( ) ; Date now = new Date ( System . currentTimeMillis ( ) ) ; assertTrue ( rs . next ( ) ) ; assertEquals ( null , rs . getString ( 1 ) ) ; assertEquals ( A_VALUE , rs . getString ( 2 ) ) ; assertTrue ( rs . getDate ( 3 ) . before ( now ) ) ; assertTrue ( BigDecimal . valueOf ( 10 ) . compareTo ( rs . getBigDecimal ( 4 ) ) == 0 ) ; assertTrue ( rs . next ( ) ) ; assertEquals ( null , rs . getString ( 1 ) ) ; assertEquals ( B_VALUE , rs . getString ( 2 ) ) ; assertTrue ( rs . getDate ( 3 ) . before ( now ) ) ; assertTrue ( BigDecimal . valueOf ( 26 ) . compareTo ( rs . getBigDecimal ( 4 ) ) == 0 ) ; assertTrue ( rs . next ( ) ) ; assertEquals ( null , rs . getString ( 1 ) ) ; assertEquals ( C_VALUE , rs . getString ( 2 ) ) ; assertTrue ( rs . getDate ( 3 ) . before ( now ) ) ; assertTrue ( BigDecimal . valueOf ( 9 ) . compareTo ( rs . getBigDecimal ( 4 ) ) == 0 ) ; assertFalse ( rs . next ( ) ) ; props . setProperty ( PhoenixRuntime . CURRENT_SCN_ATTRIB , Long . toString ( ts + 3 ) ) ; conn = DriverManager . getConnection ( getUrl ( ) , props ) ; conn . setAutoCommit ( true ) ; upsert = ""UPSERT INTO "" + PTSDB_NAME + ""(date, val, host, inst) "" + ""SELECT current_date(), max(val), max(host), 'x' FROM "" + PTSDB_NAME ; upsertStmt = conn . prepareStatement ( upsert ) ; rowsInserted = upsertStmt . executeUpdate ( ) ; assertEquals ( 1 , rowsInserted ) ; if ( ! autoCommit ) { conn . commit ( ) ; } conn . close ( ) ; query = ""SELECT inst,host,date,val FROM "" + PTSDB_NAME + "" WHERE inst='x'"" ; props . setProperty ( PhoenixRuntime . CURRENT_SCN_ATTRIB , Long . toString ( ts + 4 ) ) ; conn = DriverManager . getConnection ( getUrl ( ) , props ) ; statement = conn . prepareStatement ( query ) ; rs = statement . executeQuery ( ) ; now = new Date ( System . currentTimeMillis ( ) ) ; assertTrue ( rs . next ( ) ) ; assertEquals ( ""x"" , rs . getString ( 1 ) ) ; assertEquals ( C_VALUE , rs . getString ( 2 ) ) ; assertTrue ( rs . getDate ( 3 ) . before ( now ) ) ; assertTrue ( BigDecimal . valueOf ( 26 ) . compareTo ( rs . getBigDecimal ( 4 ) ) == 0 ) ; assertFalse ( rs . next ( ) ) ; } @ Test public void testUpsertSelectLongToInt ( ) throws Exception { byte [ ] [ ] splits = new byte [ ] [ ] { PInteger . INSTANCE . toBytes ( 1 ) , PInteger . INSTANCE . toBytes ( 2 ) , PInteger . INSTANCE . toBytes ( 3 ) , PInteger . INSTANCE . toBytes ( 4 ) } ; long ts = nextTimestamp ( ) ; ensureTableCreated ( getUrl ( ) , ""IntKeyTest"" , splits , ts - 2 ) ; Properties props = new Properties ( ) ; props . setProperty ( PhoenixRuntime . CURRENT_SCN_ATTRIB , Long . toString ( ts + 1 ) ) ; Connection conn = DriverManager . getConnection ( getUrl ( ) , props ) ; String upsert = ""UPSERT INTO IntKeyTest VALUES(1)"" ; PreparedStatement upsertStmt = conn . prepareStatement ( upsert ) ; int rowsInserted = upsertStmt . executeUpdate ( ) ; assertEquals ( 1 , rowsInserted ) ; conn . commit ( ) ; conn . close ( ) ; props . setProperty ( PhoenixRuntime . CURRENT_SCN_ATTRIB , Long . toString ( ts + 5 ) ) ; conn = DriverManager . getConnection ( getUrl ( ) , props ) ; upsert = ""UPSERT INTO IntKeyTest select i+1 from IntKeyTest"" ; upsertStmt = conn . prepareStatement ( upsert ) ; rowsInserted = upsertStmt . executeUpdate ( ) ; assertEquals ( 1 , rowsInserted ) ; conn . commit ( ) ; conn . close ( ) ; props . setProperty ( PhoenixRuntime . CURRENT_SCN_ATTRIB , Long . toString ( ts + 10 ) ) ; conn = DriverManager . getConnection ( getUrl ( ) , props ) ; String select = ""SELECT i FROM IntKeyTest"" ; ResultSet rs = conn . createStatement ( ) . executeQuery ( select ) ; assertTrue ( rs . next ( ) ) ; assertEquals ( 1 , rs . getInt ( 1 ) ) ; assertTrue ( rs . next ( ) ) ; assertEquals ( 2 , rs . getInt ( 1 ) ) ; assertFalse ( rs . next ( ) ) ; conn . close ( ) ; } @ Test public void testUpsertSelectRunOnServer ( ) throws Exception { byte [ ] [ ] splits = new byte [ ] [ ] { PInteger . INSTANCE . toBytes ( 1 ) , PInteger . INSTANCE . toBytes ( 2 ) , PInteger . INSTANCE . toBytes ( 3 ) , PInteger . INSTANCE . toBytes ( 4 ) } ; long ts = nextTimestamp ( ) ; createTestTable ( getUrl ( ) , ""create table IntKeyTest (i integer not null primary key desc, j integer)"" , splits , ts - 2 ) ; Properties props = new Properties ( ) ; props . setProperty ( PhoenixRuntime . CURRENT_SCN_ATTRIB , Long . toString ( ts + 1 ) ) ; Connection conn = DriverManager . getConnection ( getUrl ( ) , props ) ; String upsert = ""UPSERT INTO IntKeyTest VALUES(1, 1)"" ; PreparedStatement upsertStmt = conn . prepareStatement ( upsert ) ; int rowsInserted = upsertStmt . executeUpdate ( ) ; assertEquals ( 1 , rowsInserted ) ; conn . commit ( ) ; conn . close ( ) ; props . setProperty ( PhoenixRuntime . CURRENT_SCN_ATTRIB , Long . toString ( ts + 3 ) ) ; conn = DriverManager . getConnection ( getUrl ( ) , props ) ; String select = ""SELECT i,j+1 FROM IntKeyTest"" ; ResultSet rs = conn . createStatement ( ) . executeQuery ( select ) ; assertTrue ( rs . next ( ) ) ; assertEquals ( 1 , rs . getInt ( 1 ) ) ; assertEquals ( 2 , rs . getInt ( 2 ) ) ; assertFalse ( rs . next ( ) ) ; conn . close ( ) ; props . setProperty ( PhoenixRuntime . CURRENT_SCN_ATTRIB , Long . toString ( ts + 5 ) ) ; conn = DriverManager . getConnection ( getUrl ( ) , props ) ; conn . setAutoCommit ( true ) ; upsert = ""UPSERT INTO IntKeyTest(i,j) select i, j+1 from IntKeyTest"" ; upsertStmt = conn . prepareStatement ( upsert ) ; rowsInserted = upsertStmt . executeUpdate ( ) ; assertEquals ( 1 , rowsInserted ) ; conn . close ( ) ; props . setProperty ( PhoenixRuntime . CURRENT_SCN_ATTRIB , Long . toString ( ts + 10 ) ) ; conn = DriverManager . getConnection ( getUrl ( ) , props ) ; select = ""SELECT j FROM IntKeyTest"" ; rs = conn . createStatement ( ) . executeQuery ( select ) ; assertTrue ( rs . next ( ) ) ; assertEquals ( 2 , rs . getInt ( 1 ) ) ; assertFalse ( rs . next ( ) ) ; conn . close ( ) ; props . setProperty ( PhoenixRuntime . CURRENT_SCN_ATTRIB , Long . toString ( ts + 15 ) ) ; conn = DriverManager . getConnection ( getUrl ( ) , props ) ; conn . setAutoCommit ( true ) ; upsert = ""UPSERT INTO IntKeyTest(i,j) select i, i from IntKeyTest"" ; upsertStmt = conn . prepareStatement ( upsert ) ; rowsInserted = upsertStmt . executeUpdate ( ) ; assertEquals ( 1 , rowsInserted ) ; conn . close ( ) ; props . setProperty ( PhoenixRuntime . CURRENT_SCN_ATTRIB , Long . toString ( ts + 20 ) ) ; conn = DriverManager . getConnection ( getUrl ( ) , props ) ; select = ""SELECT j FROM IntKeyTest"" ; rs = conn . createStatement ( ) . executeQuery ( select ) ; assertTrue ( rs . next ( ) ) ; assertEquals ( 1 , rs . getInt ( 1 ) ) ; assertFalse ( rs . next ( ) ) ; conn . close ( ) ; } @ Test public void testUpsertSelectOnDescToAsc ( ) throws Exception { byte [ ] [ ] splits = new byte [ ] [ ] { PInteger . INSTANCE . toBytes ( 1 ) , PInteger . INSTANCE . toBytes ( 2 ) , PInteger . INSTANCE . toBytes ( 3 ) , PInteger . INSTANCE . toBytes ( 4 ) } ; long ts = nextTimestamp ( ) ; createTestTable ( getUrl ( ) , ""create table IntKeyTest (i integer not null primary key desc, j integer)"" , splits , ts - 2 ) ; Properties props = new Properties ( ) ; props . setProperty ( PhoenixRuntime . CURRENT_SCN_ATTRIB , Long . toString ( ts + 1 ) ) ; Connection conn = DriverManager . getConnection ( getUrl ( ) , props ) ; String upsert = ""UPSERT INTO IntKeyTest VALUES(1, 1)"" ; PreparedStatement upsertStmt = conn . prepareStatement ( upsert ) ; int rowsInserted = upsertStmt . executeUpdate ( ) ; assertEquals ( 1 , rowsInserted ) ; conn . commit ( ) ; conn . close ( ) ; props . setProperty ( PhoenixRuntime . CURRENT_SCN_ATTRIB , Long . toString ( ts + 5 ) ) ; conn = DriverManager . getConnection ( getUrl ( ) , props ) ; conn . setAutoCommit ( true ) ; upsert = ""UPSERT INTO IntKeyTest(i,j) select i+1, j+1 from IntKeyTest"" ; upsertStmt = conn . prepareStatement ( upsert ) ; rowsInserted = upsertStmt . executeUpdate ( ) ; assertEquals ( 1 , rowsInserted ) ; conn . commit ( ) ; conn . close ( ) ; props . setProperty ( PhoenixRuntime . CURRENT_SCN_ATTRIB , Long . toString ( ts + 10 ) ) ; conn = DriverManager . getConnection ( getUrl ( ) , props ) ; String select = ""SELECT i,j FROM IntKeyTest"" ; ResultSet rs = conn . createStatement ( ) . executeQuery ( select ) ; assertTrue ( rs . next ( ) ) ; assertEquals ( 2 , rs . getInt ( 1 ) ) ; assertEquals ( 2 , rs . getInt ( 2 ) ) ; assertTrue ( rs . next ( ) ) ; assertEquals ( 1 , rs . getInt ( 1 ) ) ; assertEquals ( 1 , rs . getInt ( 2 ) ) ; assertFalse ( rs . next ( ) ) ; conn . close ( ) ; } @ Test public void testUpsertSelectRowKeyMutationOnSplitedTable ( ) throws Exception { byte [ ] [ ] splits = new byte [ ] [ ] { PInteger . INSTANCE . toBytes ( 1 ) , PInteger . INSTANCE . toBytes ( 2 ) , PInteger . INSTANCE . toBytes ( 3 ) , PInteger . INSTANCE . toBytes ( 4 ) } ; long ts = nextTimestamp ( ) ; ensureTableCreated ( getUrl ( ) , ""IntKeyTest"" , splits , ts - 2 ) ; Properties props = new Properties ( ) ; props . setProperty ( PhoenixRuntime . CURRENT_SCN_ATTRIB , Long . toString ( ts + 1 ) ) ; Connection conn = DriverManager . getConnection ( getUrl ( ) , props ) ; String upsert = ""UPSERT INTO IntKeyTest VALUES(?)"" ; PreparedStatement upsertStmt = conn . prepareStatement ( upsert ) ; upsertStmt . setInt ( 1 , 1 ) ; upsertStmt . executeUpdate ( ) ; upsertStmt . setInt ( 1 , 3 ) ; upsertStmt . executeUpdate ( ) ; conn . commit ( ) ; conn . close ( ) ; props . setProperty ( PhoenixRuntime . CURRENT_SCN_ATTRIB , Long . toString ( ts + 5 ) ) ; conn = DriverManager . getConnection ( getUrl ( ) , props ) ; conn . setAutoCommit ( true ) ; upsert = ""UPSERT INTO IntKeyTest(i) SELECT i+1 from IntKeyTest"" ; upsertStmt = conn . prepareStatement ( upsert ) ; int rowsInserted = upsertStmt . executeUpdate ( ) ; assertEquals ( 2 , rowsInserted ) ; conn . commit ( ) ; conn . close ( ) ; props . setProperty ( PhoenixRuntime . CURRENT_SCN_ATTRIB , Long . toString ( ts + 10 ) ) ; conn = DriverManager . getConnection ( getUrl ( ) , props ) ; String select = ""SELECT i FROM IntKeyTest"" ; ResultSet rs = conn . createStatement ( ) . executeQuery ( select ) ; assertTrue ( rs . next ( ) ) ; assertEquals ( 1 , rs . getInt ( 1 ) ) ; assertTrue ( rs . next ( ) ) ; assertTrue ( rs . next ( ) ) ; assertTrue ( rs . next ( ) ) ; assertEquals ( 4 , rs . getInt ( 1 ) ) ; assertFalse ( rs . next ( ) ) ; conn . close ( ) ; } @ Test public void testUpsertSelectWithLimit ( ) throws Exception { long ts = nextTimestamp ( ) ; Properties props = new Properties ( ) ; props . setProperty ( PhoenixRuntime . CURRENT_SCN_ATTRIB , Long . toString ( ts ) ) ; Connection conn = DriverManager . getConnection ( getUrl ( ) , props ) ; conn . createStatement ( ) . execute ( ""create table phoenix_test (id varchar(10) not null primary key, val varchar(10), ts timestamp)"" ) ; conn . close ( ) ; props . setProperty ( PhoenixRuntime . CURRENT_SCN_ATTRIB , Long . toString ( ts + 10 ) ) ; conn = DriverManager . getConnection ( getUrl ( ) , props ) ; conn . createStatement ( ) . execute ( ""upsert into phoenix_test values ('aaa', 'abc', current_date())"" ) ; conn . createStatement ( ) . execute ( ""upsert into phoenix_test values ('bbb', 'bcd', current_date())"" ) ; conn . createStatement ( ) . execute ( ""upsert into phoenix_test values ('ccc', 'cde', current_date())"" ) ; conn . commit ( ) ; props . setProperty ( PhoenixRuntime . CURRENT_SCN_ATTRIB , Long . toString ( ts + 20 ) ) ; conn = DriverManager . getConnection ( getUrl ( ) , props ) ; ResultSet rs = conn . createStatement ( ) . executeQuery ( ""select * from phoenix_test"" ) ; assertTrue ( rs . next ( ) ) ; assertEquals ( ""aaa"" , rs . getString ( 1 ) ) ; assertEquals ( ""abc"" , rs . getString ( 2 ) ) ; assertNotNull ( rs . getDate ( 3 ) ) ; assertTrue ( rs . next ( ) ) ; assertEquals ( ""bbb"" , rs . getString ( 1 ) ) ; assertEquals ( ""bcd"" , rs . getString ( 2 ) ) ; assertNotNull ( rs . getDate ( 3 ) ) ; assertTrue ( rs . next ( ) ) ; assertEquals ( ""ccc"" , rs . getString ( 1 ) ) ; assertEquals ( ""cde"" , rs . getString ( 2 ) ) ; assertNotNull ( rs . getDate ( 3 ) ) ; assertFalse ( rs . next ( ) ) ; conn . close ( ) ; props . setProperty ( PhoenixRuntime . CURRENT_SCN_ATTRIB , Long . toString ( ts + 30 ) ) ; conn = DriverManager . getConnection ( getUrl ( ) , props ) ; conn . createStatement ( ) . execute ( ""upsert into phoenix_test (id, ts) select id, null from phoenix_test where id <= 'bbb' limit 1"" ) ; conn . commit ( ) ; conn . close ( ) ; props . setProperty ( PhoenixRuntime . CURRENT_SCN_ATTRIB , Long . toString ( ts + 40 ) ) ; conn = DriverManager . getConnection ( getUrl ( ) , props ) ; rs = conn . createStatement ( ) . executeQuery ( ""select * from phoenix_test"" ) ; assertTrue ( rs . next ( ) ) ; assertEquals ( ""aaa"" , rs . getString ( 1 ) ) ; assertEquals ( ""abc"" , rs . getString ( 2 ) ) ; assertNull ( rs . getDate ( 3 ) ) ; assertTrue ( rs . next ( ) ) ; assertEquals ( ""bbb"" , rs . getString ( 1 ) ) ; assertEquals ( ""bcd"" , rs . getString ( 2 ) ) ; assertNotNull ( rs . getDate ( 3 ) ) ; assertTrue ( rs . next ( ) ) ; assertEquals ( ""ccc"" , rs . getString ( 1 ) ) ; assertEquals ( ""cde"" , rs . getString ( 2 ) ) ; assertNotNull ( rs . getDate ( 3 ) ) ; assertFalse ( rs . next ( ) ) ; conn . close ( ) ; } @ Test public void testUpsertSelectWithSequence ( ) throws Exception { long ts = nextTimestamp ( ) ; Properties props = new Properties ( ) ; props . setProperty ( PhoenixRuntime . CURRENT_SCN_ATTRIB , Long . toString ( ts ) ) ; Connection conn = DriverManager . getConnection ( getUrl ( ) , props ) ; conn . createStatement ( ) . execute ( ""create table t1 (id bigint not null primary key, v varchar)"" ) ; conn . createStatement ( ) . execute ( ""create table t2 (k varchar primary key)"" ) ; conn . createStatement ( ) . execute ( ""create sequence s"" ) ; conn . close ( ) ; props . setProperty ( PhoenixRuntime . CURRENT_SCN_ATTRIB , Long . toString ( ts + 10 ) ) ; conn = DriverManager . getConnection ( getUrl ( ) , props ) ; conn . createStatement ( ) . execute ( ""upsert into t2 values ('a')"" ) ; conn . createStatement ( ) . execute ( ""upsert into t2 values ('b')"" ) ; conn . createStatement ( ) . execute ( ""upsert into t2 values ('c')"" ) ; conn . commit ( ) ; props . setProperty ( PhoenixRuntime . CURRENT_SCN_ATTRIB , Long . toString ( ts + 15 ) ) ; conn = DriverManager . getConnection ( getUrl ( ) , props ) ; conn . createStatement ( ) . execute ( ""upsert into t1 select next value for s, k from t2"" ) ; conn . commit ( ) ; props . setProperty ( PhoenixRuntime . CURRENT_SCN_ATTRIB , Long . toString ( ts + 20 ) ) ; conn = DriverManager . getConnection ( getUrl ( ) , props ) ; ResultSet rs = conn . createStatement ( ) . executeQuery ( ""select * from t1"" ) ; assertTrue ( rs . next ( ) ) ; assertEquals ( 1 , rs . getLong ( 1 ) ) ; assertEquals ( ""a"" , rs . getString ( 2 ) ) ; assertTrue ( rs . next ( ) ) ; assertEquals ( 2 , rs . getLong ( 1 ) ) ; assertEquals ( ""b"" , rs . getString ( 2 ) ) ; assertTrue ( rs . next ( ) ) ; assertEquals ( 3 , rs . getLong ( 1 ) ) ; assertEquals ( ""c"" , rs . getString ( 2 ) ) ; assertFalse ( rs . next ( ) ) ; conn . close ( ) ; } @ Test public void testUpsertSelectWithSequenceAndOrderByWithSalting ( ) throws Exception { int numOfRecords = 200 ; long ts = nextTimestamp ( ) ; Properties props = PropertiesUtil . deepCopy ( TEST_PROPERTIES ) ; props . setProperty ( PhoenixRuntime . CURRENT_SCN_ATTRIB , Long . toString ( ts ) ) ; Connection conn = DriverManager . getConnection ( getUrl ( ) , props ) ; String ddl = ""CREATE TABLE IF NOT EXISTS DUMMY_CURSOR_STORAGE ("" + ""ORGANIZATION_ID CHAR(15) NOT NULL, QUERY_ID CHAR(15) NOT NULL, CURSOR_ORDER BIGINT NOT NULL, K1 INTEGER, V1 INTEGER "" + ""CONSTRAINT MAIN_PK PRIMARY KEY (ORGANIZATION_ID, QUERY_ID, CURSOR_ORDER) "" + "") SALT_BUCKETS = 4"" ; conn . createStatement ( ) . execute ( ddl ) ; conn . createStatement ( ) . execute ( ""CREATE TABLE DUMMY_SEQ_TEST_DATA "" + ""(ORGANIZATION_ID CHAR(15) NOT NULL, k1 integer NOT NULL, v1 integer NOT NULL "" + ""CONSTRAINT PK PRIMARY KEY (ORGANIZATION_ID, k1, v1) ) VERSIONS=1, SALT_BUCKETS = 4"" ) ; conn . createStatement ( ) . execute ( ""create sequence s cache "" + Integer . MAX_VALUE ) ; conn . close ( ) ; props . setProperty ( PhoenixRuntime . CURRENT_SCN_ATTRIB , Long . toString ( ts + 10 ) ) ; conn = DriverManager . getConnection ( getUrl ( ) , props ) ; for ( int i = 0 ; i < numOfRecords ; i ++ ) { conn . createStatement ( ) . execute ( ""UPSERT INTO DUMMY_SEQ_TEST_DATA values ('00Dxx0000001gEH',"" + i + "","" + ( i + 2 ) + "")"" ) ; } conn . commit ( ) ; conn . close ( ) ; props . setProperty ( PhoenixRuntime . CURRENT_SCN_ATTRIB , Long . toString ( ts + 15 ) ) ; conn = DriverManager . getConnection ( getUrl ( ) , props ) ; conn . setAutoCommit ( true ) ; conn . createStatement ( ) . execute ( ""UPSERT INTO DUMMY_CURSOR_STORAGE SELECT '00Dxx0000001gEH', 'MyQueryId', NEXT VALUE FOR S, k1, v1  FROM DUMMY_SEQ_TEST_DATA ORDER BY K1, V1"" ) ; props . setProperty ( PhoenixRuntime . CURRENT_SCN_ATTRIB , Long . toString ( ts + 20 ) ) ; conn = DriverManager . getConnection ( getUrl ( ) , props ) ; ResultSet rs = conn . createStatement ( ) . executeQuery ( ""select count(*) from DUMMY_CURSOR_STORAGE"" ) ; assertTrue ( rs . next ( ) ) ; assertEquals ( numOfRecords , rs . getLong ( 1 ) ) ; conn . close ( ) ; props . setProperty ( PhoenixRuntime . CURRENT_SCN_ATTRIB , Long . toString ( ts + 25 ) ) ; ResultSet rs2 = conn . createStatement ( ) . executeQuery ( ""select cursor_order, k1, v1 from DUMMY_CURSOR_STORAGE order by cursor_order"" ) ; long seq = 1 ; while ( rs2 . next ( ) ) { assertEquals ( seq , rs2 . getLong ( ""cursor_order"" ) ) ; assertEquals ( seq - 1 , rs2 . getLong ( ""k1"" ) ) ; seq ++ ; } conn . close ( ) ; } @ Test public void testUpsertSelectWithRowtimeStampColumn ( ) throws Exception { long ts = nextTimestamp ( ) ; try ( Connection conn = getConnection ( ts ) ) { conn . createStatement ( ) . execute ( ""CREATE TABLE T1 (PK1 VARCHAR NOT NULL, PK2 DATE NOT NULL, KV1 VARCHAR CONSTRAINT PK PRIMARY KEY(PK1, PK2 DESC ROW_TIMESTAMP "" + "")) "" ) ; conn . createStatement ( ) . execute ( ""CREATE TABLE T2 (PK1 VARCHAR NOT NULL, PK2 DATE NOT NULL, KV1 VARCHAR CONSTRAINT PK PRIMARY KEY(PK1, PK2 ROW_TIMESTAMP)) "" ) ; conn . createStatement ( ) . execute ( ""CREATE TABLE T3 (PK1 VARCHAR NOT NULL, PK2 DATE NOT NULL, KV1 VARCHAR CONSTRAINT PK PRIMARY KEY(PK1, PK2 DESC ROW_TIMESTAMP "" + "")) "" ) ; } ts = nextTimestamp ( ) ; long rowTimestamp = 1000000 ; Date rowTimestampDate = new Date ( rowTimestamp ) ; try ( Connection conn = getConnection ( ts ) ) { PreparedStatement stmt = conn . prepareStatement ( ""UPSERT INTO T1 (PK1, PK2, KV1) VALUES(?, ?, ?)"" ) ; stmt . setString ( 1 , ""PK1"" ) ; stmt . setDate ( 2 , rowTimestampDate ) ; stmt . setString ( 3 , ""KV1"" ) ; stmt . executeUpdate ( ) ; conn . commit ( ) ; } try ( Connection conn = getConnection ( rowTimestamp + 5 ) ) { conn . createStatement ( ) . executeUpdate ( ""UPSERT INTO T2 SELECT * FROM T1"" ) ; conn . commit ( ) ; PreparedStatement stmt = conn . prepareStatement ( ""SELECT * FROM T2 WHERE PK1 = ? AND PK2 = ?"" ) ; stmt . setString ( 1 , ""PK1"" ) ; stmt . setDate ( 2 , rowTimestampDate ) ; ResultSet rs = stmt . executeQuery ( ) ; assertTrue ( rs . next ( ) ) ; assertEquals ( ""PK1"" , rs . getString ( ""PK1"" ) ) ; assertEquals ( rowTimestampDate , rs . getDate ( ""PK2"" ) ) ; assertEquals ( ""KV1"" , rs . getString ( ""KV1"" ) ) ; } try ( Connection conn = getConnection ( nextTimestamp ( ) ) ) { PreparedStatement stmt = conn . prepareStatement ( ""SELECT * FROM T2 WHERE PK1 = ? AND PK2 = ?"" ) ; stmt . setString ( 1 , ""PK1"" ) ; stmt . setDate ( 2 , rowTimestampDate ) ; ResultSet rs = stmt . executeQuery ( ) ; assertFalse ( rs . next ( ) ) ; } try ( Connection conn = getConnection ( rowTimestamp + 5 ) ) { conn . createStatement ( ) . executeUpdate ( ""UPSERT INTO T3 SELECT * FROM T2"" ) ; conn . commit ( ) ; PreparedStatement stmt = conn . prepareStatement ( ""SELECT * FROM T3 WHERE PK1 = ? AND PK2 = ?"" ) ; stmt . setString ( 1 , ""PK1"" ) ; stmt . setDate ( 2 , rowTimestampDate ) ; ResultSet rs = stmt . executeQuery ( ) ; assertTrue ( rs . next ( ) ) ; assertEquals ( ""PK1"" , rs . getString ( ""PK1"" ) ) ; assertEquals ( rowTimestampDate , rs . getDate ( ""PK2"" ) ) ; assertEquals ( ""KV1"" , rs . getString ( ""KV1"" ) ) ; } try ( Connection conn = getConnection ( nextTimestamp ( ) ) ) { PreparedStatement stmt = conn . prepareStatement ( ""SELECT * FROM T3 WHERE PK1 = ? AND PK2 = ?"" ) ; stmt . setString ( 1 , ""PK1"" ) ; stmt . setDate ( 2 , rowTimestampDate ) ; ResultSet rs = stmt . executeQuery ( ) ; assertFalse ( rs . next ( ) ) ; } } @ Test public void testUpsertSelectSameTableWithRowTimestampColumn ( ) throws Exception { String tableName = ""testUpsertSelectSameTableWithRowTimestampColumn"" . toUpperCase ( ) ; long ts = nextTimestamp ( ) ; try ( Connection conn = getConnection ( ts ) ) { conn . createStatement ( ) . execute ( ""CREATE TABLE "" + tableName + "" (PK1 INTEGER NOT NULL, PK2 DATE NOT NULL, KV1 VARCHAR CONSTRAINT PK PRIMARY KEY(PK1, PK2 ROW_TIMESTAMP)) "" ) ; } ts = nextTimestamp ( ) ; long rowTimestamp = ts + 100000 ; Date rowTimestampDate = new Date ( rowTimestamp ) ; try ( Connection conn = getConnection ( ts ) ) { PreparedStatement stmt = conn . prepareStatement ( ""UPSERT INTO  "" + tableName + "" (PK1, PK2, KV1) VALUES(?, ?, ?)"" ) ; stmt . setInt ( 1 , 1 ) ; stmt . setDate ( 2 , rowTimestampDate ) ; stmt . setString ( 3 , ""KV1"" ) ; stmt . executeUpdate ( ) ; conn . commit ( ) ; } try ( Connection conn = getConnection ( nextTimestamp ( ) ) ) { conn . createStatement ( ) . execute ( ""CREATE SEQUENCE T_SEQ"" ) ; } try ( Connection conn = getConnection ( rowTimestamp + 5 ) ) { conn . createStatement ( ) . executeUpdate ( ""UPSERT INTO  "" + tableName + ""  SELECT NEXT VALUE FOR T_SEQ, PK2 FROM  "" + tableName ) ; conn . commit ( ) ; } try ( Connection conn = getConnection ( rowTimestamp + 5 ) ) { conn . setAutoCommit ( true ) ; for ( int i = 0 ; i < 10 ; i ++ ) { int count = conn . createStatement ( ) . executeUpdate ( ""UPSERT INTO  "" + tableName + ""  SELECT NEXT VALUE FOR T_SEQ, PK2 FROM  "" + tableName ) ; assertEquals ( ( int ) Math . pow ( 2 , i ) , count ) ; } } } @ Test public void testAutomaticallySettingRowtimestamp ( ) throws Exception { String table1 = ""testAutomaticallySettingRowtimestamp1"" . toUpperCase ( ) ; String table2 = ""testAutomaticallySettingRowtimestamp2"" . toUpperCase ( ) ; String table3 = ""testAutomaticallySettingRowtimestamp3"" . toUpperCase ( ) ; long ts = nextTimestamp ( ) ; try ( Connection conn = getConnection ( ts ) ) { conn . createStatement ( ) . execute ( ""CREATE TABLE "" + table1 + "" (T1PK1 VARCHAR NOT NULL, T1PK2 DATE NOT NULL, T1KV1 VARCHAR, T1KV2 VARCHAR CONSTRAINT PK PRIMARY KEY(T1PK1, T1PK2 DESC ROW_TIMESTAMP)) "" ) ; conn . createStatement ( ) . execute ( ""CREATE TABLE "" + table2 + "" (T2PK1 VARCHAR NOT NULL, T2PK2 DATE NOT NULL, T2KV1 VARCHAR, T2KV2 VARCHAR CONSTRAINT PK PRIMARY KEY(T2PK1, T2PK2 ROW_TIMESTAMP)) "" ) ; conn . createStatement ( ) . execute ( ""CREATE TABLE "" + table3 + "" (T3PK1 VARCHAR NOT NULL, T3PK2 DATE NOT NULL, T3KV1 VARCHAR, T3KV2 VARCHAR CONSTRAINT PK PRIMARY KEY(T3PK1, T3PK2 DESC ROW_TIMESTAMP)) "" ) ; } ts = nextTimestamp ( ) ; try ( Connection conn = getConnection ( ts ) ) { PreparedStatement stmt = conn . prepareStatement ( ""UPSERT INTO  "" + table1 + "" (T1PK1, T1KV1, T1KV2) VALUES (?, ?, ?)"" ) ; stmt . setString ( 1 , ""PK1"" ) ; stmt . setString ( 2 , ""KV1"" ) ; stmt . setString ( 3 , ""KV2"" ) ; stmt . executeUpdate ( ) ; conn . commit ( ) ; } Date upsertedDate = new Date ( ts ) ; ts = nextTimestamp ( ) ; try ( Connection conn = getConnection ( ts ) ) { PreparedStatement stmt = conn . prepareStatement ( ""SELECT T1KV1, T1KV2 FROM "" + table1 + "" WHERE T1PK1 = ? AND T1PK2 = ?"" ) ; stmt . setString ( 1 , ""PK1"" ) ; stmt . setDate ( 2 , upsertedDate ) ; ResultSet rs = stmt . executeQuery ( ) ; assertTrue ( rs . next ( ) ) ; assertEquals ( ""KV1"" , rs . getString ( 1 ) ) ; assertEquals ( ""KV2"" , rs . getString ( 2 ) ) ; assertFalse ( rs . next ( ) ) ; } ts = nextTimestamp ( ) ; try ( Connection conn = getConnection ( ts ) ) { PreparedStatement stmt = conn . prepareStatement ( ""UPSERT INTO  "" + table2 + "" (T2PK1, T2KV1, T2KV2) SELECT T1PK1, T1KV1, T1KV2 FROM "" + table1 ) ; stmt . executeUpdate ( ) ; conn . commit ( ) ; } upsertedDate = new Date ( ts ) ; ts = nextTimestamp ( ) ; try ( Connection conn = getConnection ( ts ) ) { PreparedStatement stmt = conn . prepareStatement ( ""SELECT T2KV1, T2KV2 FROM "" + table2 + "" WHERE T2PK1 = ? AND T2PK2 = ?"" ) ; stmt . setString ( 1 , ""PK1"" ) ; stmt . setDate ( 2 , upsertedDate ) ; ResultSet rs = stmt . executeQuery ( ) ; assertTrue ( rs . next ( ) ) ; assertEquals ( ""KV1"" , rs . getString ( 1 ) ) ; assertEquals ( ""KV2"" , rs . getString ( 2 ) ) ; assertFalse ( rs . next ( ) ) ; } ts = nextTimestamp ( ) ; try ( Connection conn = getConnection ( ts ) ) { PreparedStatement stmt = conn . prepareStatement ( ""UPSERT INTO  "" + table3 + "" (T3PK1, T3KV1, T3KV2) SELECT T2PK1, T2KV1, T2KV2 FROM "" + table2 ) ; stmt . executeUpdate ( ) ; conn . commit ( ) ; } upsertedDate = new Date ( ts ) ; ts = nextTimestamp ( ) ; try ( Connection conn = getConnection ( ts ) ) { PreparedStatement stmt = conn . prepareStatement ( ""SELECT T3KV1, T3KV2 FROM "" + table3 + "" WHERE T3PK1 = ? AND T3PK2 = ?"" ) ; stmt . setString ( 1 , ""PK1"" ) ; stmt . setDate ( 2 , upsertedDate ) ; ResultSet rs = stmt . executeQuery ( ) ; assertTrue ( rs . next ( ) ) ; assertEquals ( ""KV1"" , rs . getString ( 1 ) ) ; assertEquals ( ""KV2"" , rs . getString ( 2 ) ) ; assertFalse ( rs . next ( ) ) ; } } @ Test public void testUpsertSelectAutoCommitWithRowTimestampColumn ( ) throws Exception { String tableName1 = ""testUpsertSelectServerSideWithRowTimestampColumn"" . toUpperCase ( ) ; String tableName2 = ""testUpsertSelectServerSideWithRowTimestampColumn2"" . toUpperCase ( ) ; long ts = 10 ; try ( Connection conn = getConnection ( ts ) ) { conn . createStatement ( ) . execute ( ""CREATE TABLE "" + tableName1 + "" (PK1 INTEGER NOT NULL, PK2 DATE NOT NULL, PK3 INTEGER NOT NULL, KV1 VARCHAR CONSTRAINT PK PRIMARY KEY(PK1, PK2 ROW_TIMESTAMP, PK3)) "" ) ; conn . createStatement ( ) . execute ( ""CREATE TABLE "" + tableName2 + "" (PK1 INTEGER NOT NULL, PK2 DATE NOT NULL, PK3 INTEGER NOT NULL, KV1 VARCHAR CONSTRAINT PK PRIMARY KEY(PK1, PK2 DESC ROW_TIMESTAMP, PK3)) "" ) ; } String [ ] tableNames = { tableName1 , tableName2 } ; for ( String tableName : tableNames ) { long rowTimestamp1 = 100 ; Date rowTimestampDate = new Date ( rowTimestamp1 ) ; try ( Connection conn = getConnection ( ts ) ) { PreparedStatement stmt = conn . prepareStatement ( ""UPSERT INTO  "" + tableName + "" (PK1, PK2, PK3, KV1) VALUES(?, ?, ?, ?)"" ) ; stmt . setInt ( 1 , 1 ) ; stmt . setDate ( 2 , rowTimestampDate ) ; stmt . setInt ( 3 , 3 ) ; stmt . setString ( 4 , ""KV1"" ) ; stmt . executeUpdate ( ) ; conn . commit ( ) ; } long rowTimestamp2 = 2 * rowTimestamp1 ; try ( Connection conn = getConnection ( rowTimestamp2 ) ) { conn . setAutoCommit ( true ) ; conn . createStatement ( ) . executeUpdate ( ""UPSERT INTO  "" + tableName + "" (PK1, PK3, KV1) SELECT PK1, PK3, KV1 FROM  "" + tableName ) ; } try ( Connection conn = getConnection ( 3 * rowTimestamp1 ) ) { PreparedStatement stmt = conn . prepareStatement ( ""SELECT * FROM  "" + tableName + "" WHERE PK1 = ? AND PK2 = ? AND PK3 = ?"" ) ; stmt . setInt ( 1 , 1 ) ; stmt . setDate ( 2 , new Date ( rowTimestamp2 ) ) ; stmt . setInt ( 3 , 3 ) ; ResultSet rs = stmt . executeQuery ( ) ; assertTrue ( rs . next ( ) ) ; assertEquals ( 1 , rs . getInt ( ""PK1"" ) ) ; assertEquals ( 3 , rs . getInt ( ""PK3"" ) ) ; assertEquals ( ""KV1"" , rs . getString ( ""KV1"" ) ) ; assertEquals ( new Date ( rowTimestamp2 ) , rs . getDate ( ""PK2"" ) ) ; assertFalse ( rs . next ( ) ) ; rs = conn . createStatement ( ) . executeQuery ( ""SELECT COUNT(*) FROM "" + tableName ) ; assertTrue ( rs . next ( ) ) ; assertEquals ( 2 , rs . getInt ( 1 ) ) ; } ts = 5 * rowTimestamp1 ; try ( Connection conn = getConnection ( ts ) ) { conn . setAutoCommit ( true ) ; conn . createStatement ( ) . executeUpdate ( ""UPSERT INTO  "" + tableName + "" (PK1, PK2, PK3, KV1) SELECT PK1, PK2, PK3, KV1 FROM  "" + tableName ) ; } ts = 6 * rowTimestamp1 ; try ( Connection conn = getConnection ( ts ) ) { ResultSet rs = conn . createStatement ( ) . executeQuery ( ""SELECT COUNT(*) FROM "" + tableName ) ; assertTrue ( rs . next ( ) ) ; assertEquals ( 2 , rs . getInt ( 1 ) ) ; assertFalse ( rs . next ( ) ) ; } } } @ Test public void testRowTimestampColWithViewsIndexesAndSaltedTables ( ) throws Exception { String baseTable = ""testRowTimestampColWithViewsIndexesAndSaltedTables"" . toUpperCase ( ) ; String tenantView = ""tenatView"" . toUpperCase ( ) ; String globalView = ""globalView"" . toUpperCase ( ) ; String baseTableIdx = ""table_idx"" . toUpperCase ( ) ; String tenantViewIdx = ""tenantView_idx"" . toUpperCase ( ) ; long ts = nextTimestamp ( ) ; try ( Connection conn = getConnection ( ts ) ) { conn . createStatement ( ) . execute ( ""CREATE TABLE "" + baseTable + "" (TENANT_ID CHAR(15) NOT NULL, PK2 DATE NOT NULL, PK3 INTEGER NOT NULL, KV1 VARCHAR, KV2 VARCHAR, KV3 VARCHAR CONSTRAINT PK PRIMARY KEY(TENANT_ID, PK2 ROW_TIMESTAMP, PK3)) MULTI_TENANT = true, SALT_BUCKETS = 8"" ) ; } ts = nextTimestamp ( ) ; try ( Connection conn = getConnection ( ts ) ) { conn . createStatement ( ) . execute ( ""CREATE INDEX "" + baseTableIdx + "" ON "" + baseTable + "" (PK2, KV3) INCLUDE (KV1)"" ) ; } ts = nextTimestamp ( ) ; try ( Connection conn = getConnection ( ts ) ) { conn . createStatement ( ) . execute ( ""CREATE VIEW "" + globalView + "" AS SELECT * FROM "" + baseTable + "" WHERE KV1 = 'KV1'"" ) ; } String tenantId = ""tenant1"" ; ts = nextTimestamp ( ) ; try ( Connection conn = getTenantConnection ( tenantId , ts ) ) { conn . createStatement ( ) . execute ( ""CREATE VIEW "" + tenantView + "" AS SELECT * FROM "" + baseTable ) ; } ts = nextTimestamp ( ) ; try ( Connection conn = getTenantConnection ( tenantId , ts ) ) { conn . createStatement ( ) . execute ( ""CREATE INDEX "" + tenantViewIdx + "" ON "" + tenantView + "" (PK2, KV2) INCLUDE (KV1)"" ) ; } long upsertedTs = nextTimestamp ( ) ; try ( Connection conn = getConnection ( upsertedTs ) ) { PreparedStatement stmt = conn . prepareStatement ( ""UPSERT INTO  "" + baseTable + "" (TENANT_ID, PK3, KV1, KV2, KV3) VALUES (?, ?, ?, ?, ?)"" ) ; stmt . setString ( 1 , tenantId ) ; stmt . setInt ( 2 , 3 ) ; stmt . setString ( 3 , ""KV1"" ) ; stmt . setString ( 4 , ""KV2"" ) ; stmt . setString ( 5 , ""KV3"" ) ; stmt . executeUpdate ( ) ; conn . commit ( ) ; } try ( Connection conn = getConnection ( nextTimestamp ( ) ) ) { PreparedStatement stmt = conn . prepareStatement ( ""SELECT * FROM  "" + baseTable + "" WHERE TENANT_ID = ? AND PK2 = ? AND PK3 = ?"" ) ; stmt . setString ( 1 , tenantId ) ; stmt . setDate ( 2 , new Date ( upsertedTs ) ) ; stmt . setInt ( 3 , 3 ) ; ResultSet rs = stmt . executeQuery ( ) ; assertTrue ( rs . next ( ) ) ; assertEquals ( tenantId , rs . getString ( ""TENANT_ID"" ) ) ; assertEquals ( ""KV1"" , rs . getString ( ""KV1"" ) ) ; assertEquals ( ""KV2"" , rs . getString ( ""KV2"" ) ) ; assertEquals ( ""KV3"" , rs . getString ( ""KV3"" ) ) ; assertEquals ( new Date ( upsertedTs ) , rs . getDate ( ""PK2"" ) ) ; assertFalse ( rs . next ( ) ) ; stmt = conn . prepareStatement ( ""SELECT * FROM  "" + globalView + "" WHERE TENANT_ID = ? AND PK2 = ? AND PK3 = ?"" ) ; stmt . setString ( 1 , tenantId ) ; stmt . setDate ( 2 , new Date ( upsertedTs ) ) ; stmt . setInt ( 3 , 3 ) ; rs = stmt . executeQuery ( ) ; assertTrue ( rs . next ( ) ) ; assertEquals ( tenantId , rs . getString ( ""TENANT_ID"" ) ) ; assertEquals ( ""KV1"" , rs . getString ( ""KV1"" ) ) ; assertEquals ( ""KV2"" , rs . getString ( ""KV2"" ) ) ; assertEquals ( ""KV3"" , rs . getString ( ""KV3"" ) ) ; assertEquals ( new Date ( upsertedTs ) , rs . getDate ( ""PK2"" ) ) ; assertFalse ( rs . next ( ) ) ; stmt = conn . prepareStatement ( ""SELECT KV1 FROM  "" + baseTable + "" WHERE PK2 = ? AND KV3 = ?"" ) ; stmt . setDate ( 1 , new Date ( upsertedTs ) ) ; stmt . setString ( 2 , ""KV3"" ) ; rs = stmt . executeQuery ( ) ; QueryPlan plan = stmt . unwrap ( PhoenixStatement . class ) . getQueryPlan ( ) ; assertTrue ( plan . getTableRef ( ) . getTable ( ) . getName ( ) . getString ( ) . equals ( baseTableIdx ) ) ; assertTrue ( rs . next ( ) ) ; assertEquals ( ""KV1"" , rs . getString ( ""KV1"" ) ) ; assertFalse ( rs . next ( ) ) ; } try ( Connection tenantConn = getTenantConnection ( tenantId , nextTimestamp ( ) ) ) { PreparedStatement stmt = tenantConn . prepareStatement ( ""SELECT * FROM  "" + tenantView + "" WHERE PK2 = ? AND PK3 = ?"" ) ; stmt . setDate ( 1 , new Date ( upsertedTs ) ) ; stmt . setInt ( 2 , 3 ) ; ResultSet rs = stmt . executeQuery ( ) ; assertTrue ( rs . next ( ) ) ; assertEquals ( ""KV1"" , rs . getString ( ""KV1"" ) ) ; assertEquals ( ""KV2"" , rs . getString ( ""KV2"" ) ) ; assertEquals ( ""KV3"" , rs . getString ( ""KV3"" ) ) ; assertEquals ( new Date ( upsertedTs ) , rs . getDate ( ""PK2"" ) ) ; assertFalse ( rs . next ( ) ) ; } upsertedTs = nextTimestamp ( ) ; try ( Connection tenantConn = getTenantConnection ( tenantId , upsertedTs ) ) { PreparedStatement stmt = tenantConn . prepareStatement ( ""UPSERT INTO  "" + tenantView + "" (PK3, KV1, KV2, KV3) VALUES (?, ?, ?, ?)"" ) ; stmt . setInt ( 1 , 33 ) ; stmt . setString ( 2 , ""KV13"" ) ; stmt . setString ( 3 , ""KV23"" ) ; stmt . setString ( 4 , ""KV33"" ) ; stmt . executeUpdate ( ) ; tenantConn . commit ( ) ; stmt = tenantConn . prepareStatement ( ""UPSERT INTO  "" + tenantView + "" (PK2, PK3, KV1, KV2, KV3) VALUES (?, ?, ?, ?, ?)"" ) ; stmt . setDate ( 1 , new Date ( upsertedTs ) ) ; stmt . setInt ( 2 , 44 ) ; stmt . setString ( 3 , ""KV14"" ) ; stmt . setString ( 4 , ""KV24"" ) ; stmt . setString ( 5 , ""KV34"" ) ; stmt . executeUpdate ( ) ; tenantConn . commit ( ) ; } try ( Connection conn = getConnection ( upsertedTs + 10000 ) ) { PreparedStatement stmt = conn . prepareStatement ( ""SELECT * FROM  "" + baseTable + "" WHERE TENANT_ID = ? AND PK2 = ? AND PK3 = ? "" ) ; stmt . setString ( 1 , tenantId ) ; stmt . setDate ( 2 , new Date ( upsertedTs ) ) ; stmt . setInt ( 3 , 33 ) ; ResultSet rs = stmt . executeQuery ( ) ; assertTrue ( rs . next ( ) ) ; assertEquals ( tenantId , rs . getString ( ""TENANT_ID"" ) ) ; assertEquals ( ""KV13"" , rs . getString ( ""KV1"" ) ) ; assertEquals ( ""KV23"" , rs . getString ( ""KV2"" ) ) ; assertEquals ( ""KV33"" , rs . getString ( ""KV3"" ) ) ; assertFalse ( rs . next ( ) ) ; stmt = conn . prepareStatement ( ""SELECT * FROM  "" + baseTable + "" WHERE TENANT_ID = ? AND PK2 = ? AND PK3 = ? "" ) ; stmt . setString ( 1 , tenantId ) ; stmt . setDate ( 2 , new Date ( upsertedTs ) ) ; stmt . setInt ( 3 , 44 ) ; rs = stmt . executeQuery ( ) ; assertTrue ( rs . next ( ) ) ; assertEquals ( tenantId , rs . getString ( ""TENANT_ID"" ) ) ; assertEquals ( ""KV14"" , rs . getString ( ""KV1"" ) ) ; assertEquals ( ""KV24"" , rs . getString ( ""KV2"" ) ) ; assertEquals ( ""KV34"" , rs . getString ( ""KV3"" ) ) ; assertFalse ( rs . next ( ) ) ; stmt = conn . prepareStatement ( ""SELECT KV1 FROM  "" + baseTable + "" WHERE (PK2, KV3) IN ((?, ?), (?, ?)) ORDER BY KV1"" ) ; stmt . setDate ( 1 , new Date ( upsertedTs ) ) ; stmt . setString ( 2 , ""KV33"" ) ; stmt . setDate ( 3 , new Date ( upsertedTs ) ) ; stmt . setString ( 4 , ""KV34"" ) ; rs = stmt . executeQuery ( ) ; QueryPlan plan = stmt . unwrap ( PhoenixStatement . class ) . getQueryPlan ( ) ; assertTrue ( plan . getTableRef ( ) . getTable ( ) . getName ( ) . getString ( ) . equals ( baseTableIdx ) ) ; assertTrue ( rs . next ( ) ) ; assertEquals ( ""KV13"" , rs . getString ( ""KV1"" ) ) ; assertTrue ( rs . next ( ) ) ; assertEquals ( ""KV14"" , rs . getString ( ""KV1"" ) ) ; assertFalse ( rs . next ( ) ) ; } try ( Connection tenantConn = getTenantConnection ( tenantId , upsertedTs + 10000 ) ) { PreparedStatement stmt = tenantConn . prepareStatement ( ""SELECT * FROM  "" + tenantView + "" WHERE (PK2, PK3) IN ((?, ?), (?, ?)) ORDER BY KV1"" ) ; stmt . setDate ( 1 , new Date ( upsertedTs ) ) ; stmt . setInt ( 2 , 33 ) ; stmt . setDate ( 3 , new Date ( upsertedTs ) ) ; stmt . setInt ( 4 , 44 ) ; ResultSet rs = stmt . executeQuery ( ) ; assertTrue ( rs . next ( ) ) ; assertEquals ( ""KV13"" , rs . getString ( ""KV1"" ) ) ; assertTrue ( rs . next ( ) ) ; assertEquals ( ""KV14"" , rs . getString ( ""KV1"" ) ) ; assertFalse ( rs . next ( ) ) ; } } @ Test public void testDisallowNegativeValuesForRowTsColumn ( ) throws Exception { String tableName = ""testDisallowNegativeValuesForRowTsColumn"" . toUpperCase ( ) ; String tableName2 = ""testDisallowNegativeValuesForRowTsColumn2"" . toUpperCase ( ) ; long ts = nextTimestamp ( ) ; try ( Connection conn = getConnection ( ts ) ) { conn . createStatement ( ) . execute ( ""CREATE TABLE "" + tableName + "" (PK1 BIGINT NOT NULL PRIMARY KEY ROW_TIMESTAMP, KV1 VARCHAR)"" ) ; conn . createStatement ( ) . execute ( ""CREATE TABLE "" + tableName2 + "" (PK1 BIGINT NOT NULL PRIMARY KEY ROW_TIMESTAMP, KV1 VARCHAR)"" ) ; } ts = nextTimestamp ( ) ; try ( Connection conn = getConnection ( ts ) ) { long upsertedTs = 100 ; PreparedStatement stmt = conn . prepareStatement ( ""UPSERT INTO "" + tableName + "" VALUES (?, ?)"" ) ; stmt . setLong ( 1 , upsertedTs ) ; stmt . setString ( 2 , ""KV1"" ) ; stmt . executeUpdate ( ) ; conn . commit ( ) ; } ts = nextTimestamp ( ) ; try ( Connection conn = getConnection ( ts ) ) { PreparedStatement stmt = conn . prepareStatement ( ""UPSERT INTO "" + tableName2 + "" SELECT (PK1 - 500), KV1 FROM "" + tableName ) ; stmt . executeUpdate ( ) ; fail ( ) ; } catch ( SQLException e ) { assertEquals ( SQLExceptionCode . ILLEGAL_DATA . getErrorCode ( ) , e . getErrorCode ( ) ) ; } } @ Test public void testUpsertSelectWithFixedWidthNullByteSizeArray ( ) throws Exception { long ts = nextTimestamp ( ) ; Properties props = new Properties ( ) ; props . setProperty ( PhoenixRuntime . CURRENT_SCN_ATTRIB , Long . toString ( ts ) ) ; Connection conn = DriverManager . getConnection ( getUrl ( ) , props ) ; conn . createStatement ( ) . execute ( ""create table t1 (id bigint not null primary key, ca char(3)[])"" ) ; conn . close ( ) ; props . setProperty ( PhoenixRuntime . CURRENT_SCN_ATTRIB , Long . toString ( ts + 10 ) ) ; conn = DriverManager . getConnection ( getUrl ( ) , props ) ; conn . createStatement ( ) . execute ( ""upsert into t1 values (1, ARRAY['aaa', 'bbb'])"" ) ; conn . commit ( ) ; props . setProperty ( PhoenixRuntime . CURRENT_SCN_ATTRIB , Long . toString ( ts + 15 ) ) ; conn = DriverManager . getConnection ( getUrl ( ) , props ) ; conn . createStatement ( ) . execute ( ""upsert into t1(id, ca) select id, ARRAY['ccc', 'ddd'] from t1 WHERE id = 1"" ) ; conn . commit ( ) ; props . setProperty ( PhoenixRuntime . CURRENT_SCN_ATTRIB , Long . toString ( ts + 20 ) ) ; conn = DriverManager . getConnection ( getUrl ( ) , props ) ; ResultSet rs = conn . createStatement ( ) . executeQuery ( ""select * from t1"" ) ; assertTrue ( rs . next ( ) ) ; assertEquals ( 1 , rs . getLong ( 1 ) ) ; assertEquals ( ""['ccc', 'ddd']"" , rs . getArray ( 2 ) . toString ( ) ) ; props . setProperty ( PhoenixRuntime . CURRENT_SCN_ATTRIB , Long . toString ( ts + 25 ) ) ; conn = DriverManager . getConnection ( getUrl ( ) , props ) ; conn . createStatement ( ) . execute ( ""create table t2 (id bigint not null primary key, ba binary(4)[])"" ) ; conn . close ( ) ; props . setProperty ( PhoenixRuntime . CURRENT_SCN_ATTRIB , Long . toString ( ts + 30 ) ) ; conn = DriverManager . getConnection ( getUrl ( ) , props ) ; conn . createStatement ( ) . execute ( ""upsert into t2 values (2, ARRAY[1, 27])"" ) ; conn . commit ( ) ; props . setProperty ( PhoenixRuntime . CURRENT_SCN_ATTRIB , Long . toString ( ts + 35 ) ) ; conn = DriverManager . getConnection ( getUrl ( ) , props ) ; conn . createStatement ( ) . execute ( ""upsert into t2(id, ba) select id, ARRAY[54, 1024] from t2 WHERE id = 2"" ) ; conn . commit ( ) ; props . setProperty ( PhoenixRuntime . CURRENT_SCN_ATTRIB , Long . toString ( ts + 40 ) ) ; conn = DriverManager . getConnection ( getUrl ( ) , props ) ; rs = conn . createStatement ( ) . executeQuery ( ""select * from t2"" ) ; assertTrue ( rs . next ( ) ) ; assertEquals ( 2 , rs . getLong ( 1 ) ) ; assertEquals ( ""[[128,0,0,54], [128,0,4,0]]"" , rs . getArray ( 2 ) . toString ( ) ) ; } @ Test public void testParallelUpsertSelect ( ) throws Exception { long ts = nextTimestamp ( ) ; Properties props = PropertiesUtil . deepCopy ( TEST_PROPERTIES ) ; props . setProperty ( PhoenixRuntime . CURRENT_SCN_ATTRIB , Long . toString ( ts ) ) ; props . setProperty ( QueryServices . MUTATE_BATCH_SIZE_ATTRIB , Integer . toString ( 3 ) ) ; props . setProperty ( QueryServices . SCAN_CACHE_SIZE_ATTRIB , Integer . toString ( 3 ) ) ; props . setProperty ( QueryServices . SCAN_RESULT_CHUNK_SIZE , Integer . toString ( 3 ) ) ; Connection conn = DriverManager . getConnection ( getUrl ( ) , props ) ; conn . setAutoCommit ( false ) ; conn . createStatement ( ) . execute ( ""CREATE SEQUENCE S1"" ) ; conn . createStatement ( ) . execute ( ""CREATE TABLE SALTEDT1 (pk INTEGER PRIMARY KEY, val INTEGER) SALT_BUCKETS=4"" ) ; conn . createStatement ( ) . execute ( ""CREATE TABLE T2 (pk INTEGER PRIMARY KEY, val INTEGER)"" ) ; conn . close ( ) ; props . setProperty ( PhoenixRuntime . CURRENT_SCN_ATTRIB , Long . toString ( ts + 10 ) ) ; conn = DriverManager . getConnection ( getUrl ( ) , props ) ; for ( int i = 0 ; i < 100 ; i ++ ) { conn . createStatement ( ) . execute ( ""UPSERT INTO SALTEDT1 VALUES (NEXT VALUE FOR S1, "" + ( i % 10 ) + "")"" ) ; } conn . commit ( ) ; conn . close ( ) ; props . setProperty ( PhoenixRuntime . CURRENT_SCN_ATTRIB , Long . toString ( ts + 20 ) ) ; conn = DriverManager . getConnection ( getUrl ( ) , props ) ; conn . setAutoCommit ( true ) ; int upsertCount = conn . createStatement ( ) . executeUpdate ( ""UPSERT INTO T2 SELECT pk, val FROM SALTEDT1"" ) ; assertEquals ( 100 , upsertCount ) ; conn . close ( ) ; } private static Connection getConnection ( long ts ) throws SQLException { Properties props = PropertiesUtil . deepCopy ( TestUtil . TEST_PROPERTIES ) ; props . setProperty ( PhoenixRuntime . CURRENT_SCN_ATTRIB , Long . toString ( ts ) ) ; return DriverManager . getConnection ( getUrl ( ) , props ) ; } private static Connection getTenantConnection ( String tenantId , long ts ) throws Exception { Properties props = PropertiesUtil . deepCopy ( TestUtil . TEST_PROPERTIES ) ; props . setProperty ( PhoenixRuntime . CURRENT_SCN_ATTRIB , Long . toString ( ts ) ) ; props . setProperty ( TENANT_ID_ATTRIB , tenantId ) ; return DriverManager . getConnection ( getUrl ( ) , props ) ; } }",No
"@ Entity @ DataCache public class PartBase extends Part { double cost ; double mass ; int backOrder ; @ ManyToMany ( mappedBy = ""supplies"" ) protected List < Supplier > suppliers = new ArrayList < Supplier > ( ) ; public PartBase ( ) { } public PartBase ( int partno , String name , double cost , double mass ) { this . partno = partno ; this . name = name ; this . cost = cost ; this . mass = mass ; this . backOrder = 0 ; this . inventory = 0 ; } public double getCost ( ) { return cost ; } public void setCost ( double cost ) { this . cost = cost ; } public double getMass ( ) { return mass ; } public void setMass ( double mass ) { this . mass = mass ; } public Collection < Supplier > getSuppliers ( ) { return suppliers ; } public void setSuppliers ( List < Supplier > suppliers ) { this . suppliers = suppliers ; } public String toString ( ) { String sup = """" ; if ( getSuppliers ( ) != null ) for ( Supplier s : getSuppliers ( ) ) { sup = sup + s . sid + "","" ; } return ""PartBase:"" + partno + "" name:+"" + name + "" cost:"" + cost + "" mass:"" + mass + "" supplies=["" + sup + ""]"" ; } public int getBackOrder ( ) { return backOrder ; } public void setBackOrder ( int backOrder ) { this . backOrder = backOrder ; } }",Smelly
"class Param extends Val implements Parameter { private Object _key = null ; private Class _type = null ; private int _index = - 1 ; public Param ( Object key , Class type ) { _key = key ; _type = type ; } public Object getParameterKey ( ) { return _key ; } public Class getType ( ) { return _type ; } public void setImplicitType ( Class type ) { _type = type ; } public void setIndex ( int index ) { _index = index ; } public Object getValue ( Object [ ] params ) { return params [ _index ] ; } protected Object eval ( Object candidate , Object orig , StoreContext ctx , Object [ ] params ) { return getValue ( params ) ; } }",Smelly
" private class EJBServicePropertiesMonitorWorker extends CXFWorkAdapter implements Work { private long previousModificationTime ; private final int pollIntervalSeconds ; private final File propsFile ; private volatile boolean continuing = true ; EJBServicePropertiesMonitorWorker ( int pollInterval ) throws ResourceException { pollIntervalSeconds = pollInterval ; propsFile = new File ( mcf . getEJBServicePropertiesURLInstance ( ) . getPath ( ) ) ; } public void run ( ) { do { try { if ( isPropertiesFileModified ( ) ) { LOG . info ( ""ejbServicePropertiesFile modified, initializing/updating servants"" ) ; initializeServantsFromProperties ( loadProperties ( propsFile . toURI ( ) . toURL ( ) ) ) ; } Thread . sleep ( ( long ) pollIntervalSeconds * 1000L ) ; } catch ( Exception e ) { LOG . info ( ""MonitorThread: failed to initialiseServantsFromProperties "" + ""with properties absolute path="" + propsFile . getAbsolutePath ( ) ) ; } } while ( continuing ) ; } public void release ( ) { this . continuing = false ; } protected boolean isPropertiesFileModified ( ) { boolean fileModified = false ; if ( propsFile . exists ( ) ) { long currentModificationTime = propsFile . lastModified ( ) ; if ( currentModificationTime > previousModificationTime ) { previousModificationTime = currentModificationTime ; fileModified = true ; } } return fileModified ; } ",No
"public class ImageSegment extends AbstractNamedAFPObject { private ImageContent imageContent ; private final Factory factory ; public ImageSegment ( Factory factory , String name ) { super ( name ) ; this . factory = factory ; } public ImageContent getImageContent ( ) { if ( imageContent == null ) { this . imageContent = factory . createImageContent ( ) ; } return imageContent ; } public void setImageSize ( int hsize , int vsize , int hresol , int vresol ) { ImageSizeParameter imageSizeParameter = factory . createImageSizeParameter ( hsize , vsize , hresol , vresol ) ; getImageContent ( ) . setImageSizeParameter ( imageSizeParameter ) ; } public void setEncoding ( byte encoding ) { getImageContent ( ) . setImageEncoding ( encoding ) ; } public void setCompression ( byte compression ) { getImageContent ( ) . setImageCompression ( compression ) ; } public void setIDESize ( byte size ) { getImageContent ( ) . setImageIDESize ( size ) ; } public void setIDEColorModel ( byte colorModel ) { getImageContent ( ) . setImageIDEColorModel ( colorModel ) ; } public void setSubtractive ( boolean subtractive ) { getImageContent ( ) . setSubtractive ( subtractive ) ; } public void setData ( byte [ ] imageData ) { getImageContent ( ) . setImageData ( imageData ) ; } public void writeContent ( OutputStream os ) throws IOException { if ( imageContent != null ) { imageContent . writeToStream ( os ) ; } } private static final int NAME_LENGTH = 4 ; protected int getNameLength ( ) { return NAME_LENGTH ; } protected void writeStart ( OutputStream os ) throws IOException { byte [ ] data = new byte [ ] { 0x70 , 0x00 , } ; os . write ( data ) ; } protected void writeEnd ( OutputStream os ) throws IOException { byte [ ] data = new byte [ ] { 0x71 , 0x00 , } ; os . write ( data ) ; } public void setTileTOC ( ) { TileTOC toc = factory . createTileTOC ( ) ; getImageContent ( ) . setTileTOC ( toc ) ; } public void addTile ( Tile tile ) { getImageContent ( ) . addTile ( tile ) ; } }",Smelly
"public class MultiReaderTest { VolumeManager fs ; TemporaryFolder root = new TemporaryFolder ( new File ( System . getProperty ( ""user.dir"" ) + ""/target"" ) ) ; @ Before public void setUp ( ) throws Exception { root . create ( ) ; String path = root . getRoot ( ) . getAbsolutePath ( ) + ""/manyMaps"" ; fs = VolumeManagerImpl . getLocal ( path ) ; Path root = new Path ( ""file://"" + path ) ; fs . mkdirs ( root ) ; fs . create ( new Path ( root , ""finished"" ) ) . close ( ) ; FileSystem ns = fs . getVolumeByPath ( root ) . getFileSystem ( ) ; Writer oddWriter = new Writer ( ns . getConf ( ) , ns . makeQualified ( new Path ( root , ""odd"" ) ) , Writer . keyClass ( IntWritable . class ) , Writer . valueClass ( BytesWritable . class ) ) ; BytesWritable value = new BytesWritable ( ""someValue"" . getBytes ( ) ) ; for ( int i = 1 ; i < 1000 ; i += 2 ) { oddWriter . append ( new IntWritable ( i ) , value ) ; } oddWriter . close ( ) ; Writer evenWriter = new Writer ( ns . getConf ( ) , ns . makeQualified ( new Path ( root , ""even"" ) ) , Writer . keyClass ( IntWritable . class ) , Writer . valueClass ( BytesWritable . class ) ) ; for ( int i = 0 ; i < 1000 ; i += 2 ) { if ( i == 10 ) continue ; evenWriter . append ( new IntWritable ( i ) , value ) ; } evenWriter . close ( ) ; } @ After public void tearDown ( ) throws Exception { root . create ( ) ; } private void scan ( MultiReader reader , int start ) throws IOException { IntWritable key = new IntWritable ( ) ; BytesWritable value = new BytesWritable ( ) ; for ( int i = start + 1 ; i < 1000 ; i ++ ) { if ( i == 10 ) continue ; assertTrue ( reader . next ( key , value ) ) ; assertEquals ( i , key . get ( ) ) ; } } private void scanOdd ( MultiReader reader , int start ) throws IOException { IntWritable key = new IntWritable ( ) ; BytesWritable value = new BytesWritable ( ) ; for ( int i = start + 2 ; i < 1000 ; i += 2 ) { assertTrue ( reader . next ( key , value ) ) ; assertEquals ( i , key . get ( ) ) ; } } @ Test public void testMultiReader ( ) throws IOException { Path manyMaps = new Path ( ""file://"" + root . getRoot ( ) . getAbsolutePath ( ) + ""/manyMaps"" ) ; MultiReader reader = new MultiReader ( fs , manyMaps ) ; IntWritable key = new IntWritable ( ) ; BytesWritable value = new BytesWritable ( ) ; for ( int i = 0 ; i < 1000 ; i ++ ) { if ( i == 10 ) continue ; assertTrue ( reader . next ( key , value ) ) ; assertEquals ( i , key . get ( ) ) ; } assertEquals ( value . compareTo ( new BytesWritable ( ""someValue"" . getBytes ( ) ) ) , 0 ) ; assertFalse ( reader . next ( key , value ) ) ; key . set ( 500 ) ; assertTrue ( reader . seek ( key ) ) ; scan ( reader , 500 ) ; key . set ( 10 ) ; assertFalse ( reader . seek ( key ) ) ; scan ( reader , 10 ) ; key . set ( 1000 ) ; assertFalse ( reader . seek ( key ) ) ; assertFalse ( reader . next ( key , value ) ) ; key . set ( - 1 ) ; assertFalse ( reader . seek ( key ) ) ; key . set ( 0 ) ; assertTrue ( reader . next ( key , value ) ) ; assertEquals ( 0 , key . get ( ) ) ; reader . close ( ) ; fs . deleteRecursively ( new Path ( manyMaps , ""even"" ) ) ; reader = new MultiReader ( fs , manyMaps ) ; key . set ( 501 ) ; assertTrue ( reader . seek ( key ) ) ; scanOdd ( reader , 501 ) ; key . set ( 1000 ) ; assertFalse ( reader . seek ( key ) ) ; assertFalse ( reader . next ( key , value ) ) ; key . set ( - 1 ) ; assertFalse ( reader . seek ( key ) ) ; key . set ( 1 ) ; assertTrue ( reader . next ( key , value ) ) ; assertEquals ( 1 , key . get ( ) ) ; reader . close ( ) ; } }",No
"public class OrderManagerEvents { public static final String module = OrderManagerEvents . class . getName ( ) ; public static final String resource_error = ""OrderErrorUiLabels"" ; public static String processOfflinePayments ( HttpServletRequest request , HttpServletResponse response ) { HttpSession session = request . getSession ( ) ; LocalDispatcher dispatcher = ( LocalDispatcher ) request . getAttribute ( ""dispatcher"" ) ; Delegator delegator = ( Delegator ) request . getAttribute ( ""delegator"" ) ; GenericValue userLogin = ( GenericValue ) session . getAttribute ( ""userLogin"" ) ; Locale locale = UtilHttp . getLocale ( request ) ; if ( session . getAttribute ( ""OFFLINE_PAYMENTS"" ) != null ) { String orderId = ( String ) request . getAttribute ( ""orderId"" ) ; List < GenericValue > toBeStored = FastList . newInstance ( ) ; List < GenericValue > paymentPrefs = null ; GenericValue placingCustomer = null ; try { paymentPrefs = delegator . findByAnd ( ""OrderPaymentPreference"" , UtilMisc . toMap ( ""orderId"" , orderId ) , null , false ) ; List < GenericValue > pRoles = delegator . findByAnd ( ""OrderRole"" , UtilMisc . toMap ( ""orderId"" , orderId , ""roleTypeId"" , ""PLACING_CUSTOMER"" ) , null , false ) ; if ( UtilValidate . isNotEmpty ( pRoles ) ) placingCustomer = EntityUtil . getFirst ( pRoles ) ; } catch ( GenericEntityException e ) { Debug . logError ( e , ""Problems looking up order payment preferences"" , module ) ; request . setAttribute ( ""_ERROR_MESSAGE_"" , UtilProperties . getMessage ( resource_error , ""OrderErrorProcessingOfflinePayments"" , locale ) ) ; return ""error"" ; } if ( paymentPrefs != null ) { for ( GenericValue ppref : paymentPrefs ) { ppref . set ( ""statusId"" , ""PAYMENT_RECEIVED"" ) ; ppref . set ( ""authDate"" , UtilDateTime . nowTimestamp ( ) ) ; toBeStored . add ( ppref ) ; Map < String , Object > results = null ; try { results = dispatcher . runSync ( ""createPaymentFromPreference"" , UtilMisc . toMap ( ""orderPaymentPreferenceId"" , ppref . get ( ""orderPaymentPreferenceId"" ) , ""paymentFromId"" , placingCustomer . getString ( ""partyId"" ) , ""comments"" , ""Payment received offline and manually entered."" ) ) ; } catch ( GenericServiceException e ) { Debug . logError ( e , ""Failed to execute service createPaymentFromPreference"" , module ) ; request . setAttribute ( ""_ERROR_MESSAGE_"" , e . getMessage ( ) ) ; return ""error"" ; } if ( ( results == null ) || ( results . get ( ModelService . RESPONSE_MESSAGE ) . equals ( ModelService . RESPOND_ERROR ) ) ) { Debug . logError ( ( String ) results . get ( ModelService . ERROR_MESSAGE ) , module ) ; request . setAttribute ( ""_ERROR_MESSAGE_"" , results . get ( ModelService . ERROR_MESSAGE ) ) ; return ""error"" ; } } try { delegator . storeAll ( toBeStored ) ; } catch ( GenericEntityException e ) { Debug . logError ( e , ""Problems storing payment information"" , module ) ; request . setAttribute ( ""_ERROR_MESSAGE_"" , UtilProperties . getMessage ( resource_error , ""OrderProblemStoringReceivedPaymentInformation"" , locale ) ) ; return ""error"" ; } OrderChangeHelper . approveOrder ( dispatcher , userLogin , orderId ) ; } } return ""success"" ; } public static String receiveOfflinePayment ( HttpServletRequest request , HttpServletResponse response ) { HttpSession session = request . getSession ( ) ; LocalDispatcher dispatcher = ( LocalDispatcher ) request . getAttribute ( ""dispatcher"" ) ; Delegator delegator = ( Delegator ) request . getAttribute ( ""delegator"" ) ; GenericValue userLogin = ( GenericValue ) session . getAttribute ( ""userLogin"" ) ; Locale locale = UtilHttp . getLocale ( request ) ; String orderId = request . getParameter ( ""orderId"" ) ; String partyId = request . getParameter ( ""partyId"" ) ; GenericValue orderHeader = null ; List < GenericValue > orderRoles = null ; try { orderHeader = delegator . findOne ( ""OrderHeader"" , UtilMisc . toMap ( ""orderId"" , orderId ) , false ) ; orderRoles = delegator . findList ( ""OrderRole"" , EntityCondition . makeCondition ( ""orderId"" , EntityOperator . EQUALS , orderId ) , null , null , null , false ) ; } catch ( GenericEntityException e ) { Debug . logError ( e , ""Problems reading order header from datasource."" , module ) ; request . setAttribute ( ""_ERROR_MESSAGE_"" , UtilProperties . getMessage ( resource_error , ""OrderProblemsReadingOrderHeaderInformation"" , locale ) ) ; return ""error"" ; } BigDecimal grandTotal = BigDecimal . ZERO ; if ( orderHeader != null ) { grandTotal = orderHeader . getBigDecimal ( ""grandTotal"" ) ; } List < GenericValue > paymentMethodTypes = null ; try { EntityExpr ee = EntityCondition . makeCondition ( ""paymentMethodTypeId"" , EntityOperator . NOT_EQUAL , ""EXT_OFFLINE"" ) ; paymentMethodTypes = delegator . findList ( ""PaymentMethodType"" , ee , null , null , null , false ) ; } catch ( GenericEntityException e ) { Debug . logError ( e , ""Problems getting payment types"" , module ) ; request . setAttribute ( ""_ERROR_MESSAGE_"" , UtilProperties . getMessage ( resource_error , ""OrderProblemsWithPaymentTypeLookup"" , locale ) ) ; return ""error"" ; } if ( paymentMethodTypes == null ) { request . setAttribute ( ""_ERROR_MESSAGE_"" , UtilProperties . getMessage ( resource_error , ""OrderProblemsWithPaymentTypeLookup"" , locale ) ) ; return ""error"" ; } List < GenericValue > paymentMethods = null ; try { EntityExpr ee = EntityCondition . makeCondition ( ""partyId"" , EntityOperator . EQUALS , partyId ) ; paymentMethods = delegator . findList ( ""PaymentMethod"" , ee , null , null , null , false ) ; } catch ( GenericEntityException e ) { Debug . logError ( e , ""Problems getting payment methods"" , module ) ; request . setAttribute ( ""_ERROR_MESSAGE_"" , UtilProperties . getMessage ( resource_error , ""OrderProblemsWithPaymentMethodLookup"" , locale ) ) ; return ""error"" ; } GenericValue placingCustomer = null ; try { List < GenericValue > pRoles = delegator . findByAnd ( ""OrderRole"" , UtilMisc . toMap ( ""orderId"" , orderId , ""roleTypeId"" , ""PLACING_CUSTOMER"" ) , null , false ) ; if ( UtilValidate . isNotEmpty ( pRoles ) ) placingCustomer = EntityUtil . getFirst ( pRoles ) ; } catch ( GenericEntityException e ) { Debug . logError ( e , ""Problems looking up order payment preferences"" , module ) ; request . setAttribute ( ""_ERROR_MESSAGE_"" , UtilProperties . getMessage ( resource_error , ""OrderErrorProcessingOfflinePayments"" , locale ) ) ; return ""error"" ; } for ( GenericValue paymentMethod : paymentMethods ) { String paymentMethodId = paymentMethod . getString ( ""paymentMethodId"" ) ; String paymentMethodAmountStr = request . getParameter ( paymentMethodId + ""_amount"" ) ; String paymentMethodReference = request . getParameter ( paymentMethodId + ""_reference"" ) ; if ( ! UtilValidate . isEmpty ( paymentMethodAmountStr ) ) { BigDecimal paymentMethodAmount = BigDecimal . ZERO ; try { paymentMethodAmount = ( BigDecimal ) ObjectType . simpleTypeConvert ( paymentMethodAmountStr , ""BigDecimal"" , null , locale ) ; } catch ( GeneralException e ) { request . setAttribute ( ""_ERROR_MESSAGE_"" , UtilProperties . getMessage ( resource_error , ""OrderProblemsPaymentParsingAmount"" , locale ) ) ; return ""error"" ; } if ( paymentMethodAmount . compareTo ( BigDecimal . ZERO ) > 0 ) { Map < String , Object > results = null ; try { results = dispatcher . runSync ( ""createPaymentFromOrder"" , UtilMisc . toMap ( ""orderId"" , orderId , ""paymentMethodId"" , paymentMethodId , ""paymentRefNum"" , paymentMethodReference , ""comments"" , ""Payment received offline and manually entered."" , ""userLogin"" , userLogin ) ) ; } catch ( GenericServiceException e ) { Debug . logError ( e , ""Failed to execute service createPaymentFromOrder"" , module ) ; request . setAttribute ( ""_ERROR_MESSAGE_"" , e . getMessage ( ) ) ; return ""error"" ; } if ( ( results == null ) || ( results . get ( ModelService . RESPONSE_MESSAGE ) . equals ( ModelService . RESPOND_ERROR ) ) ) { Debug . logError ( ( String ) results . get ( ModelService . ERROR_MESSAGE ) , module ) ; request . setAttribute ( ""_ERROR_MESSAGE_"" , results . get ( ModelService . ERROR_MESSAGE ) ) ; return ""error"" ; } } OrderChangeHelper . approveOrder ( dispatcher , userLogin , orderId ) ; return ""success"" ; } } List < GenericValue > toBeStored = FastList . newInstance ( ) ; for ( GenericValue paymentMethodType : paymentMethodTypes ) { String paymentMethodTypeId = paymentMethodType . getString ( ""paymentMethodTypeId"" ) ; String amountStr = request . getParameter ( paymentMethodTypeId + ""_amount"" ) ; String paymentReference = request . getParameter ( paymentMethodTypeId + ""_reference"" ) ; if ( ! UtilValidate . isEmpty ( amountStr ) ) { BigDecimal paymentTypeAmount = BigDecimal . ZERO ; try { paymentTypeAmount = ( BigDecimal ) ObjectType . simpleTypeConvert ( amountStr , ""BigDecimal"" , null , locale ) ; } catch ( GeneralException e ) { request . setAttribute ( ""_ERROR_MESSAGE_"" , UtilProperties . getMessage ( resource_error , ""OrderProblemsPaymentParsingAmount"" , locale ) ) ; return ""error"" ; } if ( paymentTypeAmount . compareTo ( BigDecimal . ZERO ) > 0 ) { Map < String , String > prefFields = UtilMisc . < String , String > toMap ( ""orderPaymentPreferenceId"" , delegator . getNextSeqId ( ""OrderPaymentPreference"" ) ) ; GenericValue paymentPreference = delegator . makeValue ( ""OrderPaymentPreference"" , prefFields ) ; paymentPreference . set ( ""paymentMethodTypeId"" , paymentMethodType . getString ( ""paymentMethodTypeId"" ) ) ; paymentPreference . set ( ""maxAmount"" , paymentTypeAmount ) ; paymentPreference . set ( ""statusId"" , ""PAYMENT_RECEIVED"" ) ; paymentPreference . set ( ""orderId"" , orderId ) ; paymentPreference . set ( ""createdDate"" , UtilDateTime . nowTimestamp ( ) ) ; if ( userLogin != null ) { paymentPreference . set ( ""createdByUserLogin"" , userLogin . getString ( ""userLoginId"" ) ) ; } try { delegator . create ( paymentPreference ) ; } catch ( GenericEntityException ex ) { Debug . logError ( ex , ""Cannot create a new OrderPaymentPreference"" , module ) ; request . setAttribute ( ""_ERROR_MESSAGE_"" , ex . getMessage ( ) ) ; return ""error"" ; } Map < String , Object > results = null ; try { results = dispatcher . runSync ( ""createPaymentFromPreference"" , UtilMisc . toMap ( ""userLogin"" , userLogin , ""orderPaymentPreferenceId"" , paymentPreference . get ( ""orderPaymentPreferenceId"" ) , ""paymentRefNum"" , paymentReference , ""paymentFromId"" , placingCustomer . getString ( ""partyId"" ) , ""comments"" , ""Payment received offline and manually entered."" ) ) ; } catch ( GenericServiceException e ) { Debug . logError ( e , ""Failed to execute service createPaymentFromPreference"" , module ) ; request . setAttribute ( ""_ERROR_MESSAGE_"" , e . getMessage ( ) ) ; return ""error"" ; } if ( ( results == null ) || ( results . get ( ModelService . RESPONSE_MESSAGE ) . equals ( ModelService . RESPOND_ERROR ) ) ) { Debug . logError ( ( String ) results . get ( ModelService . ERROR_MESSAGE ) , module ) ; request . setAttribute ( ""_ERROR_MESSAGE_"" , results . get ( ModelService . ERROR_MESSAGE ) ) ; return ""error"" ; } } } } GenericValue offlineValue = null ; List < GenericValue > currentPrefs = null ; BigDecimal paymentTally = BigDecimal . ZERO ; try { EntityConditionList < EntityExpr > ecl = EntityCondition . makeCondition ( UtilMisc . toList ( EntityCondition . makeCondition ( ""orderId"" , EntityOperator . EQUALS , orderId ) , EntityCondition . makeCondition ( ""statusId"" , EntityOperator . NOT_EQUAL , ""PAYMENT_CANCELLED"" ) ) , EntityOperator . AND ) ; currentPrefs = delegator . findList ( ""OrderPaymentPreference"" , ecl , null , null , null , false ) ; } catch ( GenericEntityException e ) { Debug . logError ( e , ""ERROR: Unable to get existing payment preferences from order"" , module ) ; } if ( UtilValidate . isNotEmpty ( currentPrefs ) ) { for ( GenericValue cp : currentPrefs ) { String paymentMethodType = cp . getString ( ""paymentMethodTypeId"" ) ; if ( ""EXT_OFFLINE"" . equals ( paymentMethodType ) ) { offlineValue = cp ; } else { BigDecimal cpAmt = cp . getBigDecimal ( ""maxAmount"" ) ; if ( cpAmt != null ) { paymentTally = paymentTally . add ( cpAmt ) ; } } } } boolean okayToApprove = false ; if ( paymentTally . compareTo ( grandTotal ) >= 0 ) { okayToApprove = true ; if ( offlineValue != null ) { offlineValue . set ( ""statusId"" , ""PAYMENT_CANCELLED"" ) ; toBeStored . add ( offlineValue ) ; } } try { delegator . storeAll ( toBeStored ) ; } catch ( GenericEntityException e ) { Debug . logError ( e , ""Problems storing payment information"" , module ) ; request . setAttribute ( ""_ERROR_MESSAGE_"" , UtilProperties . getMessage ( resource_error , ""OrderProblemStoringReceivedPaymentInformation"" , locale ) ) ; return ""error"" ; } if ( okayToApprove ) { OrderChangeHelper . approveOrder ( dispatcher , userLogin , orderId ) ; } return ""success"" ; } }",No
"@ Service ( ""repositoriesService#rest"" ) public class DefaultRepositoriesService extends AbstractRestService implements RepositoriesService { private Logger log = LoggerFactory . getLogger ( getClass ( ) ) ; @ Inject @ Named ( value = ""taskExecutor#indexing"" ) private ArchivaIndexingTaskExecutor archivaIndexingTaskExecutor ; @ Inject private ManagedRepositoryAdmin managedRepositoryAdmin ; @ Inject private PlexusSisuBridge plexusSisuBridge ; @ Inject private MavenIndexerUtils mavenIndexerUtils ; @ Inject private SecuritySystem securitySystem ; @ Inject private RepositoryContentFactory repositoryFactory ; @ Inject @ Named ( value = ""archivaTaskScheduler#repository"" ) private ArchivaTaskScheduler scheduler ; @ Inject private DownloadRemoteIndexScheduler downloadRemoteIndexScheduler ; @ Inject @ Named ( value = ""repositorySessionFactory"" ) protected RepositorySessionFactory repositorySessionFactory ; @ Inject protected List < RepositoryListener > listeners = new ArrayList < RepositoryListener > ( ) ; @ Inject private RepositoryScanner repoScanner ; private ChecksumAlgorithm [ ] algorithms = new ChecksumAlgorithm [ ] { ChecksumAlgorithm . SHA1 , ChecksumAlgorithm . MD5 } ; public Boolean scanRepository ( String repositoryId , boolean fullScan ) { return doScanRepository ( repositoryId , fullScan ) ; } public Boolean alreadyScanning ( String repositoryId ) { return repositoryTaskScheduler . isProcessingRepositoryTask ( repositoryId ) ; } public Boolean removeScanningTaskFromQueue ( String repositoryId ) { RepositoryTask task = new RepositoryTask ( ) ; task . setRepositoryId ( repositoryId ) ; try { return repositoryTaskScheduler . unQueueTask ( task ) ; } catch ( TaskQueueException e ) { log . error ( ""failed to unschedule scanning of repo with id {}"" , repositoryId , e ) ; return false ; } } public Boolean scanRepositoryNow ( String repositoryId , boolean fullScan ) throws ArchivaRestServiceException { try { ManagedRepository repository = managedRepositoryAdmin . getManagedRepository ( repositoryId ) ; IndexingContext context = managedRepositoryAdmin . createIndexContext ( repository ) ; ArtifactIndexingTask task = new ArtifactIndexingTask ( repository , null , ArtifactIndexingTask . Action . FINISH , context ) ; task . setExecuteOnEntireRepo ( true ) ; task . setOnlyUpdate ( ! fullScan ) ; archivaIndexingTaskExecutor . executeTask ( task ) ; return Boolean . TRUE ; } catch ( Exception e ) { log . error ( e . getMessage ( ) , e ) ; throw new ArchivaRestServiceException ( e . getMessage ( ) , e ) ; } } public Boolean scheduleDownloadRemoteIndex ( String repositoryId , boolean now , boolean fullDownload ) throws ArchivaRestServiceException { try { downloadRemoteIndexScheduler . scheduleDownloadRemote ( repositoryId , now , fullDownload ) ; } catch ( DownloadRemoteIndexException e ) { log . error ( e . getMessage ( ) , e ) ; throw new ArchivaRestServiceException ( e . getMessage ( ) , e ) ; } return Boolean . TRUE ; } public Boolean copyArtifact ( ArtifactTransferRequest artifactTransferRequest ) throws ArchivaRestServiceException { String userName = getAuditInformation ( ) . getUser ( ) . getUsername ( ) ; if ( StringUtils . isBlank ( userName ) ) { throw new ArchivaRestServiceException ( ""copyArtifact call: userName not found"" , null ) ; } if ( StringUtils . isBlank ( artifactTransferRequest . getRepositoryId ( ) ) ) { throw new ArchivaRestServiceException ( ""copyArtifact call: sourceRepositoryId cannot be null"" , null ) ; } if ( StringUtils . isBlank ( artifactTransferRequest . getTargetRepositoryId ( ) ) ) { throw new ArchivaRestServiceException ( ""copyArtifact call: targetRepositoryId cannot be null"" , null ) ; } ManagedRepository source = null ; try { source = managedRepositoryAdmin . getManagedRepository ( artifactTransferRequest . getRepositoryId ( ) ) ; } catch ( RepositoryAdminException e ) { throw new ArchivaRestServiceException ( e . getMessage ( ) , e ) ; } if ( source == null ) { throw new ArchivaRestServiceException ( ""cannot find repository with id "" + artifactTransferRequest . getRepositoryId ( ) , null ) ; } ManagedRepository target = null ; try { target = managedRepositoryAdmin . getManagedRepository ( artifactTransferRequest . getTargetRepositoryId ( ) ) ; } catch ( RepositoryAdminException e ) { throw new ArchivaRestServiceException ( e . getMessage ( ) , e ) ; } if ( target == null ) { throw new ArchivaRestServiceException ( ""cannot find repository with id "" + artifactTransferRequest . getTargetRepositoryId ( ) , null ) ; } if ( StringUtils . isBlank ( artifactTransferRequest . getGroupId ( ) ) ) { throw new ArchivaRestServiceException ( ""groupId is mandatory"" , null ) ; } if ( StringUtils . isBlank ( artifactTransferRequest . getArtifactId ( ) ) ) { throw new ArchivaRestServiceException ( ""artifactId is mandatory"" , null ) ; } if ( StringUtils . isBlank ( artifactTransferRequest . getVersion ( ) ) ) { throw new ArchivaRestServiceException ( ""version is mandatory"" , null ) ; } if ( VersionUtil . isSnapshot ( artifactTransferRequest . getVersion ( ) ) ) { throw new ArchivaRestServiceException ( ""copy of SNAPSHOT not supported"" , null ) ; } User user = null ; try { user = securitySystem . getUserManager ( ) . findUser ( userName ) ; } catch ( UserNotFoundException e ) { throw new ArchivaRestServiceException ( ""user "" + userName + "" not found"" , e ) ; } AuthenticationResult authn = new AuthenticationResult ( true , userName , null ) ; SecuritySession securitySession = new DefaultSecuritySession ( authn , user ) ; try { boolean authz = securitySystem . isAuthorized ( securitySession , ArchivaRoleConstants . OPERATION_REPOSITORY_ACCESS , artifactTransferRequest . getRepositoryId ( ) ) ; if ( ! authz ) { throw new ArchivaRestServiceException ( ""not authorized to access repo:"" + artifactTransferRequest . getRepositoryId ( ) , null ) ; } } catch ( AuthorizationException e ) { log . error ( ""error reading permission: "" + e . getMessage ( ) , e ) ; throw new ArchivaRestServiceException ( e . getMessage ( ) , e ) ; } try { boolean authz = securitySystem . isAuthorized ( securitySession , ArchivaRoleConstants . OPERATION_REPOSITORY_UPLOAD , artifactTransferRequest . getTargetRepositoryId ( ) ) ; if ( ! authz ) { throw new ArchivaRestServiceException ( ""not authorized to write to repo:"" + artifactTransferRequest . getTargetRepositoryId ( ) , null ) ; } } catch ( AuthorizationException e ) { log . error ( ""error reading permission: "" + e . getMessage ( ) , e ) ; throw new ArchivaRestServiceException ( e . getMessage ( ) , e ) ; } ArtifactReference artifactReference = new ArtifactReference ( ) ; artifactReference . setArtifactId ( artifactTransferRequest . getArtifactId ( ) ) ; artifactReference . setGroupId ( artifactTransferRequest . getGroupId ( ) ) ; artifactReference . setVersion ( artifactTransferRequest . getVersion ( ) ) ; artifactReference . setClassifier ( artifactTransferRequest . getClassifier ( ) ) ; String packaging = StringUtils . trim ( artifactTransferRequest . getPackaging ( ) ) ; artifactReference . setType ( StringUtils . isEmpty ( packaging ) ? ""jar"" : packaging ) ; try { ManagedRepositoryContent sourceRepository = repositoryFactory . getManagedRepositoryContent ( artifactTransferRequest . getRepositoryId ( ) ) ; String artifactSourcePath = sourceRepository . toPath ( artifactReference ) ; if ( StringUtils . isEmpty ( artifactSourcePath ) ) { log . error ( ""cannot find artifact "" + artifactTransferRequest . toString ( ) ) ; throw new ArchivaRestServiceException ( ""cannot find artifact "" + artifactTransferRequest . toString ( ) , null ) ; } File artifactFile = new File ( source . getLocation ( ) , artifactSourcePath ) ; if ( ! artifactFile . exists ( ) ) { log . error ( ""cannot find artifact "" + artifactTransferRequest . toString ( ) ) ; throw new ArchivaRestServiceException ( ""cannot find artifact "" + artifactTransferRequest . toString ( ) , null ) ; } ManagedRepositoryContent targetRepository = repositoryFactory . getManagedRepositoryContent ( artifactTransferRequest . getTargetRepositoryId ( ) ) ; String artifactPath = targetRepository . toPath ( artifactReference ) ; int lastIndex = artifactPath . lastIndexOf ( '/' ) ; String path = artifactPath . substring ( 0 , lastIndex ) ; File targetPath = new File ( target . getLocation ( ) , path ) ; Date lastUpdatedTimestamp = Calendar . getInstance ( ) . getTime ( ) ; int newBuildNumber = 1 ; String timestamp = null ; File versionMetadataFile = new File ( targetPath , MetadataTools . MAVEN_METADATA ) ; ArchivaRepositoryMetadata versionMetadata = getMetadata ( versionMetadataFile ) ; if ( ! targetPath . exists ( ) ) { targetPath . mkdirs ( ) ; } String filename = artifactPath . substring ( lastIndex + 1 ) ; boolean fixChecksums = ! ( archivaAdministration . getKnownContentConsumers ( ) . contains ( ""create-missing-checksums"" ) ) ; File targetFile = new File ( targetPath , filename ) ; if ( targetFile . exists ( ) && target . isBlockRedeployments ( ) ) { throw new ArchivaRestServiceException ( ""artifact already exists in target repo: "" + artifactTransferRequest . getTargetRepositoryId ( ) + "" and redeployment blocked"" , null ) ; } else { copyFile ( artifactFile , targetPath , filename , fixChecksums ) ; queueRepositoryTask ( target . getId ( ) , targetFile ) ; } String pomFilename = filename ; if ( StringUtils . isNotBlank ( artifactTransferRequest . getClassifier ( ) ) ) { pomFilename = StringUtils . remove ( pomFilename , ""-"" + artifactTransferRequest . getClassifier ( ) ) ; } pomFilename = FilenameUtils . removeExtension ( pomFilename ) + "".pom"" ; File pomFile = new File ( new File ( source . getLocation ( ) , artifactSourcePath . substring ( 0 , artifactPath . lastIndexOf ( '/' ) ) ) , pomFilename ) ; if ( pomFile != null && pomFile . length ( ) > 0 ) { copyFile ( pomFile , targetPath , pomFilename , fixChecksums ) ; queueRepositoryTask ( target . getId ( ) , new File ( targetPath , pomFilename ) ) ; } if ( ! archivaAdministration . getKnownContentConsumers ( ) . contains ( ""metadata-updater"" ) ) { updateProjectMetadata ( targetPath . getAbsolutePath ( ) , lastUpdatedTimestamp , timestamp , newBuildNumber , fixChecksums , artifactTransferRequest ) ; } String msg = ""Artifact \'"" + artifactTransferRequest . getGroupId ( ) + "":"" + artifactTransferRequest . getArtifactId ( ) + "":"" + artifactTransferRequest . getVersion ( ) + ""\' was successfully deployed to repository \'"" + artifactTransferRequest . getTargetRepositoryId ( ) + ""\'"" ; } catch ( RepositoryException e ) { log . error ( ""RepositoryException: "" + e . getMessage ( ) , e ) ; throw new ArchivaRestServiceException ( e . getMessage ( ) , e ) ; } catch ( RepositoryAdminException e ) { log . error ( ""RepositoryAdminException: "" + e . getMessage ( ) , e ) ; throw new ArchivaRestServiceException ( e . getMessage ( ) , e ) ; } catch ( IOException e ) { log . error ( ""IOException: "" + e . getMessage ( ) , e ) ; throw new ArchivaRestServiceException ( e . getMessage ( ) , e ) ; } return true ; } private void queueRepositoryTask ( String repositoryId , File localFile ) { RepositoryTask task = new RepositoryTask ( ) ; task . setRepositoryId ( repositoryId ) ; task . setResourceFile ( localFile ) ; task . setUpdateRelatedArtifacts ( true ) ; try { scheduler . queueTask ( task ) ; } catch ( TaskQueueException e ) { log . error ( ""Unable to queue repository task to execute consumers on resource file ['"" + localFile . getName ( ) + ""']."" ) ; } } private ArchivaRepositoryMetadata getMetadata ( File metadataFile ) throws RepositoryMetadataException { ArchivaRepositoryMetadata metadata = new ArchivaRepositoryMetadata ( ) ; if ( metadataFile . exists ( ) ) { try { metadata = MavenMetadataReader . read ( metadataFile ) ; } catch ( XMLException e ) { throw new RepositoryMetadataException ( e . getMessage ( ) , e ) ; } } return metadata ; } private File getMetadata ( String targetPath ) { String artifactPath = targetPath . substring ( 0 , targetPath . lastIndexOf ( File . separatorChar ) ) ; return new File ( artifactPath , MetadataTools . MAVEN_METADATA ) ; } private void copyFile ( File sourceFile , File targetPath , String targetFilename , boolean fixChecksums ) throws IOException { FileOutputStream out = new FileOutputStream ( new File ( targetPath , targetFilename ) ) ; FileInputStream input = new FileInputStream ( sourceFile ) ; try { IOUtils . copy ( input , out ) ; } finally { IOUtils . closeQuietly ( out ) ; IOUtils . closeQuietly ( input ) ; } if ( fixChecksums ) { fixChecksums ( new File ( targetPath , targetFilename ) ) ; } } private void fixChecksums ( File file ) { ChecksummedFile checksum = new ChecksummedFile ( file ) ; checksum . fixChecksums ( algorithms ) ; } private void updateProjectMetadata ( String targetPath , Date lastUpdatedTimestamp , String timestamp , int buildNumber , boolean fixChecksums , ArtifactTransferRequest artifactTransferRequest ) throws RepositoryMetadataException { List < String > availableVersions = new ArrayList < String > ( ) ; String latestVersion = artifactTransferRequest . getVersion ( ) ; File projectDir = new File ( targetPath ) . getParentFile ( ) ; File projectMetadataFile = new File ( projectDir , MetadataTools . MAVEN_METADATA ) ; ArchivaRepositoryMetadata projectMetadata = getMetadata ( projectMetadataFile ) ; if ( projectMetadataFile . exists ( ) ) { availableVersions = projectMetadata . getAvailableVersions ( ) ; Collections . sort ( availableVersions , VersionComparator . getInstance ( ) ) ; if ( ! availableVersions . contains ( artifactTransferRequest . getVersion ( ) ) ) { availableVersions . add ( artifactTransferRequest . getVersion ( ) ) ; } latestVersion = availableVersions . get ( availableVersions . size ( ) - 1 ) ; } else { availableVersions . add ( artifactTransferRequest . getVersion ( ) ) ; projectMetadata . setGroupId ( artifactTransferRequest . getGroupId ( ) ) ; projectMetadata . setArtifactId ( artifactTransferRequest . getArtifactId ( ) ) ; } if ( projectMetadata . getGroupId ( ) == null ) { projectMetadata . setGroupId ( artifactTransferRequest . getGroupId ( ) ) ; } if ( projectMetadata . getArtifactId ( ) == null ) { projectMetadata . setArtifactId ( artifactTransferRequest . getArtifactId ( ) ) ; } projectMetadata . setLatestVersion ( latestVersion ) ; projectMetadata . setLastUpdatedTimestamp ( lastUpdatedTimestamp ) ; projectMetadata . setAvailableVersions ( availableVersions ) ; if ( ! VersionUtil . isSnapshot ( artifactTransferRequest . getVersion ( ) ) ) { projectMetadata . setReleasedVersion ( latestVersion ) ; } RepositoryMetadataWriter . write ( projectMetadata , projectMetadataFile ) ; if ( fixChecksums ) { fixChecksums ( projectMetadataFile ) ; } } public Boolean deleteArtifact ( Artifact artifact ) throws ArchivaRestServiceException { String repositoryId = artifact . getContext ( ) ; if ( StringUtils . isEmpty ( repositoryId ) ) { throw new ArchivaRestServiceException ( ""repositoryId cannot be null"" , 400 , null ) ; } if ( ! isAuthorizedToDeleteArtifacts ( repositoryId ) ) { throw new ArchivaRestServiceException ( ""not authorized to delete artifacts"" , 403 , null ) ; } if ( artifact == null ) { throw new ArchivaRestServiceException ( ""artifact cannot be null"" , 400 , null ) ; } if ( StringUtils . isEmpty ( artifact . getGroupId ( ) ) ) { throw new ArchivaRestServiceException ( ""artifact.groupId cannot be null"" , 400 , null ) ; } if ( StringUtils . isEmpty ( artifact . getArtifactId ( ) ) ) { throw new ArchivaRestServiceException ( ""artifact.artifactId cannot be null"" , 400 , null ) ; } boolean snapshotVersion = VersionUtil . isSnapshot ( artifact . getVersion ( ) ) ; RepositorySession repositorySession = repositorySessionFactory . createSession ( ) ; try { Date lastUpdatedTimestamp = Calendar . getInstance ( ) . getTime ( ) ; TimeZone timezone = TimeZone . getTimeZone ( ""UTC"" ) ; DateFormat fmt = new SimpleDateFormat ( ""yyyyMMdd.HHmmss"" ) ; fmt . setTimeZone ( timezone ) ; ManagedRepository repoConfig = managedRepositoryAdmin . getManagedRepository ( repositoryId ) ; VersionedReference ref = new VersionedReference ( ) ; ref . setArtifactId ( artifact . getArtifactId ( ) ) ; ref . setGroupId ( artifact . getGroupId ( ) ) ; ref . setVersion ( artifact . getVersion ( ) ) ; ManagedRepositoryContent repository = repositoryFactory . getManagedRepositoryContent ( repositoryId ) ; ArtifactReference artifactReference = new ArtifactReference ( ) ; artifactReference . setArtifactId ( artifact . getArtifactId ( ) ) ; artifactReference . setGroupId ( artifact . getGroupId ( ) ) ; artifactReference . setVersion ( artifact . getVersion ( ) ) ; artifactReference . setClassifier ( artifact . getClassifier ( ) ) ; artifactReference . setType ( artifact . getPackaging ( ) ) ; MetadataRepository metadataRepository = repositorySession . getRepository ( ) ; String path = repository . toMetadataPath ( ref ) ; if ( StringUtils . isNotBlank ( artifact . getClassifier ( ) ) ) { if ( StringUtils . isBlank ( artifact . getPackaging ( ) ) ) { throw new ArchivaRestServiceException ( ""You must configure a type/packaging when using classifier"" , 400 , null ) ; } repository . deleteArtifact ( artifactReference ) ; } else { int index = path . lastIndexOf ( '/' ) ; path = path . substring ( 0 , index ) ; File targetPath = new File ( repoConfig . getLocation ( ) , path ) ; if ( ! targetPath . exists ( ) ) { throw new ContentNotFoundException ( artifact . getGroupId ( ) + "":"" + artifact . getArtifactId ( ) + "":"" + artifact . getVersion ( ) ) ; } if ( ! snapshotVersion ) { repository . deleteVersion ( ref ) ; } else { Set < ArtifactReference > related = repository . getRelatedArtifacts ( artifactReference ) ; log . debug ( ""related: {}"" , related ) ; for ( ArtifactReference artifactRef : related ) { repository . deleteArtifact ( artifactRef ) ; } } File metadataFile = getMetadata ( targetPath . getAbsolutePath ( ) ) ; ArchivaRepositoryMetadata metadata = getMetadata ( metadataFile ) ; updateMetadata ( metadata , metadataFile , lastUpdatedTimestamp , artifact ) ; } Collection < ArtifactMetadata > artifacts = Collections . emptyList ( ) ; if ( snapshotVersion ) { String baseVersion = VersionUtil . getBaseVersion ( artifact . getVersion ( ) ) ; artifacts = metadataRepository . getArtifacts ( repositoryId , artifact . getGroupId ( ) , artifact . getArtifactId ( ) , baseVersion ) ; } else { artifacts = metadataRepository . getArtifacts ( repositoryId , artifact . getGroupId ( ) , artifact . getArtifactId ( ) , artifact . getVersion ( ) ) ; } log . debug ( ""artifacts: {}"" , artifacts ) ; for ( ArtifactMetadata artifactMetadata : artifacts ) { if ( artifactMetadata . getVersion ( ) . equals ( artifact . getVersion ( ) ) ) { if ( StringUtils . isNotBlank ( artifact . getClassifier ( ) ) ) { if ( StringUtils . isBlank ( artifact . getPackaging ( ) ) ) { throw new ArchivaRestServiceException ( ""You must configure a type/packaging when using classifier"" , 400 , null ) ; } MavenArtifactFacet mavenArtifactFacet = ( MavenArtifactFacet ) artifactMetadata . getFacet ( MavenArtifactFacet . FACET_ID ) ; if ( StringUtils . equals ( artifact . getClassifier ( ) , mavenArtifactFacet . getClassifier ( ) ) ) { artifactMetadata . removeFacet ( MavenArtifactFacet . FACET_ID ) ; String groupId = artifact . getGroupId ( ) , artifactId = artifact . getArtifactId ( ) , version = artifact . getVersion ( ) ; MavenArtifactFacet mavenArtifactFacetToCompare = new MavenArtifactFacet ( ) ; mavenArtifactFacetToCompare . setClassifier ( artifact . getClassifier ( ) ) ; metadataRepository . removeArtifact ( repositoryId , groupId , artifactId , version , mavenArtifactFacetToCompare ) ; metadataRepository . save ( ) ; } } else { if ( snapshotVersion ) { metadataRepository . removeArtifact ( artifactMetadata , VersionUtil . getBaseVersion ( artifact . getVersion ( ) ) ) ; } else { metadataRepository . removeArtifact ( artifactMetadata . getRepositoryId ( ) , artifactMetadata . getNamespace ( ) , artifactMetadata . getProject ( ) , artifact . getVersion ( ) , artifactMetadata . getId ( ) ) ; } } for ( RepositoryListener listener : listeners ) { listener . deleteArtifact ( metadataRepository , repository . getId ( ) , artifactMetadata . getNamespace ( ) , artifactMetadata . getProject ( ) , artifactMetadata . getVersion ( ) , artifactMetadata . getId ( ) ) ; } triggerAuditEvent ( repositoryId , path , AuditEvent . REMOVE_FILE ) ; } } } catch ( ContentNotFoundException e ) { throw new ArchivaRestServiceException ( ""Artifact does not exist: "" + e . getMessage ( ) , 400 , e ) ; } catch ( RepositoryNotFoundException e ) { throw new ArchivaRestServiceException ( ""Target repository cannot be found: "" + e . getMessage ( ) , 400 , e ) ; } catch ( RepositoryException e ) { throw new ArchivaRestServiceException ( ""Repository exception: "" + e . getMessage ( ) , 500 , e ) ; } catch ( MetadataResolutionException e ) { throw new ArchivaRestServiceException ( ""Repository exception: "" + e . getMessage ( ) , 500 , e ) ; } catch ( MetadataRepositoryException e ) { throw new ArchivaRestServiceException ( ""Repository exception: "" + e . getMessage ( ) , 500 , e ) ; } catch ( RepositoryAdminException e ) { throw new ArchivaRestServiceException ( ""RepositoryAdmin exception: "" + e . getMessage ( ) , 500 , e ) ; } finally { repositorySession . save ( ) ; repositorySession . close ( ) ; } return Boolean . TRUE ; } public Boolean deleteGroupId ( String groupId , String repositoryId ) throws ArchivaRestServiceException { if ( StringUtils . isEmpty ( repositoryId ) ) { throw new ArchivaRestServiceException ( ""repositoryId cannot be null"" , 400 , null ) ; } if ( ! isAuthorizedToDeleteArtifacts ( repositoryId ) ) { throw new ArchivaRestServiceException ( ""not authorized to delete artifacts"" , 403 , null ) ; } if ( StringUtils . isEmpty ( groupId ) ) { throw new ArchivaRestServiceException ( ""artifact.groupId cannot be null"" , 400 , null ) ; } RepositorySession repositorySession = repositorySessionFactory . createSession ( ) ; try { ManagedRepositoryContent repository = repositoryFactory . getManagedRepositoryContent ( repositoryId ) ; repository . deleteGroupId ( groupId ) ; MetadataRepository metadataRepository = repositorySession . getRepository ( ) ; metadataRepository . removeNamespace ( repositoryId , groupId ) ; metadataRepository . save ( ) ; } catch ( MetadataRepositoryException e ) { log . error ( e . getMessage ( ) , e ) ; throw new ArchivaRestServiceException ( ""Repository exception: "" + e . getMessage ( ) , 500 , e ) ; } catch ( RepositoryException e ) { log . error ( e . getMessage ( ) , e ) ; throw new ArchivaRestServiceException ( ""Repository exception: "" + e . getMessage ( ) , 500 , e ) ; } finally { repositorySession . close ( ) ; } return true ; } public Boolean isAuthorizedToDeleteArtifacts ( String repoId ) throws ArchivaRestServiceException { String userName = getAuditInformation ( ) . getUser ( ) == null ? ""guest"" : getAuditInformation ( ) . getUser ( ) . getUsername ( ) ; try { boolean res = userRepositories . isAuthorizedToDeleteArtifacts ( userName , repoId ) ; return res ; } catch ( ArchivaSecurityException e ) { throw new ArchivaRestServiceException ( e . getMessage ( ) , Response . Status . INTERNAL_SERVER_ERROR . getStatusCode ( ) , e ) ; } } public RepositoryScanStatistics scanRepositoryDirectoriesNow ( String repositoryId ) throws ArchivaRestServiceException { long sinceWhen = RepositoryScanner . FRESH_SCAN ; try { return repoScanner . scan ( getManagedRepositoryAdmin ( ) . getManagedRepository ( repositoryId ) , sinceWhen ) ; } catch ( RepositoryScannerException e ) { log . error ( e . getMessage ( ) , e ) ; throw new ArchivaRestServiceException ( ""RepositoryScannerException exception: "" + e . getMessage ( ) , 500 , e ) ; } catch ( RepositoryAdminException e ) { log . error ( e . getMessage ( ) , e ) ; throw new ArchivaRestServiceException ( ""RepositoryScannerException exception: "" + e . getMessage ( ) , 500 , e ) ; } } private void updateMetadata ( ArchivaRepositoryMetadata metadata , File metadataFile , Date lastUpdatedTimestamp , Artifact artifact ) throws RepositoryMetadataException { List < String > availableVersions = new ArrayList < String > ( ) ; String latestVersion = """" ; if ( metadataFile . exists ( ) ) { if ( metadata . getAvailableVersions ( ) != null ) { availableVersions = metadata . getAvailableVersions ( ) ; if ( availableVersions . size ( ) > 0 ) { Collections . sort ( availableVersions , VersionComparator . getInstance ( ) ) ; if ( availableVersions . contains ( artifact . getVersion ( ) ) ) { availableVersions . remove ( availableVersions . indexOf ( artifact . getVersion ( ) ) ) ; } if ( availableVersions . size ( ) > 0 ) { latestVersion = availableVersions . get ( availableVersions . size ( ) - 1 ) ; } } } } if ( metadata . getGroupId ( ) == null ) { metadata . setGroupId ( artifact . getGroupId ( ) ) ; } if ( metadata . getArtifactId ( ) == null ) { metadata . setArtifactId ( artifact . getArtifactId ( ) ) ; } if ( ! VersionUtil . isSnapshot ( artifact . getVersion ( ) ) ) { if ( metadata . getReleasedVersion ( ) != null && metadata . getReleasedVersion ( ) . equals ( artifact . getVersion ( ) ) ) { metadata . setReleasedVersion ( latestVersion ) ; } } metadata . setLatestVersion ( latestVersion ) ; metadata . setLastUpdatedTimestamp ( lastUpdatedTimestamp ) ; metadata . setAvailableVersions ( availableVersions ) ; RepositoryMetadataWriter . write ( metadata , metadataFile ) ; ChecksummedFile checksum = new ChecksummedFile ( metadataFile ) ; checksum . fixChecksums ( algorithms ) ; } public ManagedRepositoryAdmin getManagedRepositoryAdmin ( ) { return managedRepositoryAdmin ; } public void setManagedRepositoryAdmin ( ManagedRepositoryAdmin managedRepositoryAdmin ) { this . managedRepositoryAdmin = managedRepositoryAdmin ; } public RepositoryContentFactory getRepositoryFactory ( ) { return repositoryFactory ; } public void setRepositoryFactory ( RepositoryContentFactory repositoryFactory ) { this . repositoryFactory = repositoryFactory ; } public RepositorySessionFactory getRepositorySessionFactory ( ) { return repositorySessionFactory ; } public void setRepositorySessionFactory ( RepositorySessionFactory repositorySessionFactory ) { this . repositorySessionFactory = repositorySessionFactory ; } public List < RepositoryListener > getListeners ( ) { return listeners ; } public void setListeners ( List < RepositoryListener > listeners ) { this . listeners = listeners ; } public ArchivaAdministration getArchivaAdministration ( ) { return archivaAdministration ; } public void setArchivaAdministration ( ArchivaAdministration archivaAdministration ) { this . archivaAdministration = archivaAdministration ; } }",No
"public class SelectOneRadioTag extends UIComponentTag { private String converter ; private String immediate ; private String required ; private String validator ; private String value ; private String valueChangeListener ; private String accesskey ; private String border ; private String dir ; private String disabled ; private String disabledClass ; private String enabledClass ; private String lang ; private String layout ; private String onblur ; private String onchange ; private String onclick ; private String ondblclick ; private String onfocus ; private String onkeydown ; private String onkeypress ; private String onkeyup ; private String onmousedown ; private String onmousemove ; private String onmouseout ; private String onmouseover ; private String onmouseup ; private String onselect ; private String readonly ; private String style ; private String styleClass ; private String tabindex ; private String title ; public void setConverter ( String converter ) { this . converter = converter ; } public void setImmediate ( String immediate ) { this . immediate = immediate ; } public void setRequired ( String required ) { this . required = required ; } public void setValidator ( String validator ) { this . validator = validator ; } public void setValue ( String value ) { this . value = value ; } public void setValueChangeListener ( String valueChangeListener ) { this . valueChangeListener = valueChangeListener ; } public void setAccesskey ( String accesskey ) { this . accesskey = accesskey ; } public void setBorder ( String border ) { this . border = border ; } public void setDir ( String dir ) { this . dir = dir ; } public void setDisabled ( String disabled ) { this . disabled = disabled ; } public void setDisabledClass ( String disabledClass ) { this . disabledClass = disabledClass ; } public void setEnabledClass ( String enabledClass ) { this . enabledClass = enabledClass ; } public void setLang ( String lang ) { this . lang = lang ; } public void setLayout ( String layout ) { this . layout = layout ; } public void setOnblur ( String onblur ) { this . onblur = onblur ; } public void setOnchange ( String onchange ) { this . onchange = onchange ; } public void setOnclick ( String onclick ) { this . onclick = onclick ; } public void setOndblclick ( String ondblclick ) { this . ondblclick = ondblclick ; } public void setOnfocus ( String onfocus ) { this . onfocus = onfocus ; } public void setOnkeydown ( String onkeydown ) { this . onkeydown = onkeydown ; } public void setOnkeypress ( String onkeypress ) { this . onkeypress = onkeypress ; } public void setOnkeyup ( String onkeyup ) { this . onkeyup = onkeyup ; } public void setOnmousedown ( String onmousedown ) { this . onmousedown = onmousedown ; } public void setOnmousemove ( String onmousemove ) { this . onmousemove = onmousemove ; } public void setOnmouseout ( String onmouseout ) { this . onmouseout = onmouseout ; } public void setOnmouseover ( String onmouseover ) { this . onmouseover = onmouseover ; } public void setOnmouseup ( String onmouseup ) { this . onmouseup = onmouseup ; } public void setOnselect ( String onselect ) { this . onselect = onselect ; } public void setReadonly ( String readonly ) { this . readonly = readonly ; } public void setStyle ( String style ) { this . style = style ; } public void setStyleClass ( String styleClass ) { this . styleClass = styleClass ; } public void setTabindex ( String tabindex ) { this . tabindex = tabindex ; } public void setTitle ( String title ) { this . title = title ; } public String getRendererType ( ) { return ""javax.faces.Radio"" ; } public String getComponentType ( ) { return ""javax.faces.HtmlSelectOneRadio"" ; } protected void setProperties ( UIComponent component ) { super . setProperties ( component ) ; UISelectOne select ; try { select = ( UISelectOne ) component ; } catch ( ClassCastException cce ) { throw new FacesException ( ""Tag <"" + getClass ( ) . getName ( ) + ""> expected UISelectOne. "" + ""Got <"" + component . getClass ( ) . getName ( ) + "">"" ) ; } if ( converter != null ) { if ( FacesUtils . isExpression ( converter ) ) { select . setValueBinding ( ""converter"" , createValueBinding ( converter ) ) ; } else { select . setConverter ( getApplication ( ) . createConverter ( converter ) ) ; } } if ( immediate != null ) { if ( FacesUtils . isExpression ( immediate ) ) { select . setValueBinding ( ""immediate"" , createValueBinding ( immediate ) ) ; } else { select . setImmediate ( BooleanUtils . toBoolean ( immediate ) ) ; } } if ( required != null ) { if ( FacesUtils . isExpression ( required ) ) { select . setValueBinding ( ""required"" , createValueBinding ( required ) ) ; } else { select . setRequired ( BooleanUtils . toBoolean ( required ) ) ; } } if ( validator != null ) { if ( FacesUtils . isExpression ( validator ) ) { MethodBinding vb = getApplication ( ) . createMethodBinding ( validator , new Class [ ] { FacesContext . class , UIComponent . class , Object . class } ) ; select . setValidator ( vb ) ; } else { throw new FacesException ( ""Tag <"" + getClass ( ) . getName ( ) + ""> validator must be an expression. "" + ""Got <"" + validator + "">"" ) ; } } if ( value != null ) { if ( FacesUtils . isExpression ( value ) ) { select . setValueBinding ( ""value"" , createValueBinding ( value ) ) ; } else { select . setValue ( value ) ; } } if ( valueChangeListener != null ) { if ( FacesUtils . isExpression ( valueChangeListener ) ) { MethodBinding vb = getApplication ( ) . createMethodBinding ( valueChangeListener , new Class [ ] { ValueChangeEvent . class } ) ; select . setValueChangeListener ( vb ) ; } else { throw new FacesException ( ""Tag <"" + getClass ( ) . getName ( ) + ""> valueChangeListener must be an expression. "" + ""Got <"" + valueChangeListener + "">"" ) ; } } setProperty ( component , ""accesskey"" , accesskey ) ; setIntegerProperty ( component , ""border"" , border ) ; setProperty ( component , ""dir"" , dir ) ; setBooleanProperty ( component , ""disabled"" , disabled ) ; setProperty ( component , ""disabledClass"" , disabledClass ) ; setProperty ( component , ""enabledClass"" , enabledClass ) ; setProperty ( component , ""lang"" , lang ) ; setProperty ( component , ""layout"" , layout ) ; setProperty ( component , ""onblur"" , onblur ) ; setProperty ( component , ""onchange"" , onchange ) ; setProperty ( component , ""onclick"" , onclick ) ; setProperty ( component , ""ondblclick"" , ondblclick ) ; setProperty ( component , ""onfocus"" , onfocus ) ; setProperty ( component , ""onkeydown"" , onkeydown ) ; setProperty ( component , ""onkeypress"" , onkeypress ) ; setProperty ( component , ""onkeyup"" , onkeyup ) ; setProperty ( component , ""onmousedown"" , onmousedown ) ; setProperty ( component , ""onmousemove"" , onmousemove ) ; setProperty ( component , ""onmouseout"" , onmouseout ) ; setProperty ( component , ""onmouseover"" , onmouseover ) ; setProperty ( component , ""onmouseup"" , onmouseup ) ; setProperty ( component , ""onselect"" , onselect ) ; setBooleanProperty ( component , ""readonly"" , readonly ) ; setProperty ( component , ""style"" , style ) ; setProperty ( component , ""styleClass"" , styleClass ) ; setProperty ( component , ""tabindex"" , tabindex ) ; setProperty ( component , ""title"" , title ) ; } public void recycle ( ) { super . recycle ( ) ; converter = null ; immediate = null ; required = null ; validator = null ; value = null ; valueChangeListener = null ; accesskey = null ; dir = null ; disabled = null ; disabledClass = null ; enabledClass = null ; lang = null ; layout = null ; onblur = null ; onchange = null ; onclick = null ; ondblclick = null ; onfocus = null ; onkeydown = null ; onkeypress = null ; onkeyup = null ; onmousedown = null ; onmousemove = null ; onmouseout = null ; onmouseover = null ; onmouseup = null ; onselect = null ; readonly = null ; style = null ; styleClass = null ; tabindex = null ; title = null ; } }",Smelly
"public class LdifModificationLogger implements IJndiLogger { private String id ; private String name ; private String description ; private Map < String , FileHandler > fileHandlers = new HashMap < String , FileHandler > ( ) ; private Map < String , Logger > loggers = new HashMap < String , Logger > ( ) ; public LdifModificationLogger ( ) { ConnectionCorePlugin . getDefault ( ) . getPluginPreferences ( ) . addPropertyChangeListener ( new IPropertyChangeListener ( ) { public void propertyChange ( PropertyChangeEvent event ) { if ( ConnectionCoreConstants . PREFERENCE_MODIFICATIONLOGS_FILE_COUNT . equals ( event . getProperty ( ) ) || ConnectionCoreConstants . PREFERENCE_MODIFICATIONLOGS_FILE_SIZE . equals ( event . getProperty ( ) ) ) { for ( Logger logger : loggers . values ( ) ) { for ( Handler handler : logger . getHandlers ( ) ) { handler . close ( ) ; } } for ( FileHandler fh : fileHandlers . values ( ) ) { try { File [ ] logFiles = getLogFiles ( fh ) ; for ( int i = getFileCount ( ) ; i < logFiles . length ; i ++ ) { if ( logFiles [ i ] != null && logFiles [ i ] . exists ( ) ) { logFiles [ i ] . delete ( ) ; } } } catch ( Exception e ) { } } loggers . clear ( ) ; } } } ) ; } private void initModificationLogger ( Connection connection ) { Logger logger = Logger . getAnonymousLogger ( ) ; loggers . put ( connection . getId ( ) , logger ) ; logger . setLevel ( Level . ALL ) ; String logfileName = ConnectionManager . getModificationLogFileName ( connection ) ; try { FileHandler fileHandler = new FileHandler ( logfileName , getFileSizeInKb ( ) * 1000 , getFileCount ( ) , true ) ; fileHandlers . put ( connection . getId ( ) , fileHandler ) ; fileHandler . setFormatter ( new Formatter ( ) { public String format ( LogRecord record ) { return record . getMessage ( ) ; } } ) ; logger . addHandler ( fileHandler ) ; } catch ( SecurityException e ) { e . printStackTrace ( ) ; } catch ( IOException e ) { e . printStackTrace ( ) ; } } public void dispose ( Connection connection ) { String id = connection . getId ( ) ; if ( loggers . containsKey ( id ) ) { Handler [ ] handlers = loggers . get ( id ) . getHandlers ( ) ; for ( Handler handler : handlers ) { handler . close ( ) ; } loggers . remove ( id ) ; } } private void log ( String text , NamingException ex , Connection connection ) { String id = connection . getId ( ) ; if ( ! loggers . containsKey ( id ) ) { if ( connection . getName ( ) != null ) { initModificationLogger ( connection ) ; } } if ( loggers . containsKey ( id ) ) { Logger logger = loggers . get ( id ) ; DateFormat df = new SimpleDateFormat ( ConnectionCoreConstants . DATEFORMAT ) ; df . setTimeZone ( ConnectionCoreConstants . UTC_TIME_ZONE ) ; if ( ex != null ) { logger . log ( Level . ALL , LdifCommentLine . create ( ""#!RESULT ERROR"" ) . toFormattedString ( LdifFormatParameters . DEFAULT ) ) ; } else { logger . log ( Level . ALL , LdifCommentLine . create ( ""#!RESULT OK"" ) . toFormattedString ( LdifFormatParameters . DEFAULT ) ) ; } logger . log ( Level . ALL , LdifCommentLine . create ( ""#!CONNECTION ldap://"" + connection . getHost ( ) + "":"" + connection . getPort ( ) ) . toFormattedString ( LdifFormatParameters . DEFAULT ) ) ; logger . log ( Level . ALL , LdifCommentLine . create ( ""#!DATE "" + df . format ( new Date ( ) ) ) . toFormattedString ( LdifFormatParameters . DEFAULT ) ) ; if ( ex != null ) { String errorComment = ""#!ERROR "" + ex . getMessage ( ) ; errorComment = errorComment . replaceAll ( ""\r"" , "" "" ) ; errorComment = errorComment . replaceAll ( ""\n"" , "" "" ) ; LdifCommentLine errorCommentLine = LdifCommentLine . create ( errorComment ) ; logger . log ( Level . ALL , errorCommentLine . toFormattedString ( LdifFormatParameters . DEFAULT ) ) ; } logger . log ( Level . ALL , text ) ; } } public void logChangetypeAdd ( Connection connection , final String dn , final Attributes attributes , final Control [ ] controls , NamingException ex ) { if ( ! isModificationLogEnabled ( ) ) { return ; } try { Set < String > maskedAttributes = getMaskedAttributes ( ) ; LdifChangeAddRecord record = new LdifChangeAddRecord ( LdifDnLine . create ( dn ) ) ; addControlLines ( record , controls ) ; record . setChangeType ( LdifChangeTypeLine . createAdd ( ) ) ; NamingEnumeration < ? extends Attribute > attributeEnumeration = attributes . getAll ( ) ; while ( attributeEnumeration . hasMore ( ) ) { Attribute attribute = attributeEnumeration . next ( ) ; String attributeName = attribute . getID ( ) ; NamingEnumeration < ? > valueEnumeration = attribute . getAll ( ) ; while ( valueEnumeration . hasMore ( ) ) { Object o = valueEnumeration . next ( ) ; if ( maskedAttributes . contains ( Strings . toLowerCase ( attributeName ) ) ) { record . addAttrVal ( LdifAttrValLine . create ( attributeName , ""**********"" ) ) ; } else { if ( o instanceof String ) { record . addAttrVal ( LdifAttrValLine . create ( attributeName , ( String ) o ) ) ; } if ( o instanceof byte [ ] ) { record . addAttrVal ( LdifAttrValLine . create ( attributeName , ( byte [ ] ) o ) ) ; } } } } record . finish ( LdifSepLine . create ( ) ) ; String formattedString = record . toFormattedString ( LdifFormatParameters . DEFAULT ) ; log ( formattedString , ex , connection ) ; } catch ( NamingException e ) { } } public void logChangetypeDelete ( Connection connection , final String dn , final Control [ ] controls , NamingException ex ) { if ( ! isModificationLogEnabled ( ) ) { return ; } LdifChangeDeleteRecord record = new LdifChangeDeleteRecord ( LdifDnLine . create ( dn ) ) ; addControlLines ( record , controls ) ; record . setChangeType ( LdifChangeTypeLine . createDelete ( ) ) ; record . finish ( LdifSepLine . create ( ) ) ; String formattedString = record . toFormattedString ( LdifFormatParameters . DEFAULT ) ; log ( formattedString , ex , connection ) ; } public void logChangetypeModify ( Connection connection , final String dn , final ModificationItem [ ] modificationItems , final Control [ ] controls , NamingException ex ) { if ( ! isModificationLogEnabled ( ) ) { return ; } try { Set < String > maskedAttributes = getMaskedAttributes ( ) ; LdifChangeModifyRecord record = new LdifChangeModifyRecord ( LdifDnLine . create ( dn ) ) ; addControlLines ( record , controls ) ; record . setChangeType ( LdifChangeTypeLine . createModify ( ) ) ; for ( ModificationItem item : modificationItems ) { Attribute attribute = item . getAttribute ( ) ; String attributeDescription = attribute . getID ( ) ; LdifModSpec modSpec ; switch ( item . getModificationOp ( ) ) { case DirContext . ADD_ATTRIBUTE : modSpec = LdifModSpec . createAdd ( attributeDescription ) ; break ; case DirContext . REMOVE_ATTRIBUTE : modSpec = LdifModSpec . createDelete ( attributeDescription ) ; break ; case DirContext . REPLACE_ATTRIBUTE : modSpec = LdifModSpec . createReplace ( attributeDescription ) ; break ; default : continue ; } NamingEnumeration < ? > valueEnumeration = attribute . getAll ( ) ; while ( valueEnumeration . hasMore ( ) ) { Object o = valueEnumeration . next ( ) ; if ( maskedAttributes . contains ( Strings . toLowerCase ( attributeDescription ) ) ) { modSpec . addAttrVal ( LdifAttrValLine . create ( attributeDescription , ""**********"" ) ) ; } else { if ( o instanceof String ) { modSpec . addAttrVal ( LdifAttrValLine . create ( attributeDescription , ( String ) o ) ) ; } if ( o instanceof byte [ ] ) { modSpec . addAttrVal ( LdifAttrValLine . create ( attributeDescription , ( byte [ ] ) o ) ) ; } } } modSpec . finish ( LdifModSpecSepLine . create ( ) ) ; record . addModSpec ( modSpec ) ; } record . finish ( LdifSepLine . create ( ) ) ; String formattedString = record . toFormattedString ( LdifFormatParameters . DEFAULT ) ; log ( formattedString , ex , connection ) ; } catch ( NamingException e ) { } } public void logChangetypeModDn ( Connection connection , final String oldDn , final String newDn , final boolean deleteOldRdn , final Control [ ] controls , NamingException ex ) { if ( ! isModificationLogEnabled ( ) ) { return ; } try { Dn dn = new Dn ( newDn ) ; Rdn newrdn = dn . getRdn ( ) ; Dn newsuperior = dn . getParent ( ) ; LdifChangeModDnRecord record = new LdifChangeModDnRecord ( LdifDnLine . create ( oldDn ) ) ; addControlLines ( record , controls ) ; record . setChangeType ( LdifChangeTypeLine . createModDn ( ) ) ; record . setNewrdn ( LdifNewrdnLine . create ( newrdn . getName ( ) ) ) ; record . setDeloldrdn ( deleteOldRdn ? LdifDeloldrdnLine . create1 ( ) : LdifDeloldrdnLine . create0 ( ) ) ; record . setNewsuperior ( LdifNewsuperiorLine . create ( newsuperior . getName ( ) ) ) ; record . finish ( LdifSepLine . create ( ) ) ; String formattedString = record . toFormattedString ( LdifFormatParameters . DEFAULT ) ; log ( formattedString , ex , connection ) ; } catch ( LdapInvalidDnException e ) { } } public void logSearchRequest ( Connection connection , String searchBase , String filter , SearchControls searchControls , AliasDereferencingMethod aliasesDereferencingMethod , Control [ ] controls , long requestNum , NamingException ex ) { } public void logSearchResultEntry ( Connection connection , StudioSearchResult studioSearchResult , long requestNum , NamingException ex ) { } public void logSearchResultReference ( Connection connection , Referral referral , ReferralsInfo referralsInfo , long requestNum , NamingException ex ) { } public void logSearchResultDone ( Connection connection , long count , long requestNum , NamingException ex ) { } private static void addControlLines ( LdifChangeRecord record , Control [ ] controls ) { if ( controls != null ) { for ( Control control : controls ) { String oid = control . getID ( ) ; boolean isCritical = control . isCritical ( ) ; byte [ ] controlValue = control . getEncodedValue ( ) ; LdifControlLine controlLine = LdifControlLine . create ( oid , isCritical , controlValue ) ; record . addControl ( controlLine ) ; } } } public File [ ] getFiles ( Connection connection ) { String id = connection . getId ( ) ; if ( ! loggers . containsKey ( id ) ) { if ( connection . getName ( ) != null ) { initModificationLogger ( connection ) ; } } try { return getLogFiles ( fileHandlers . get ( id ) ) ; } catch ( Exception e ) { return new File [ 0 ] ; } } private static File [ ] getLogFiles ( FileHandler fileHandler ) throws Exception { Field field = getFieldFromClass ( ""java.util.logging.FileHandler"" , ""files"" ) ; field . setAccessible ( true ) ; File [ ] files = ( File [ ] ) field . get ( fileHandler ) ; return files ; } private static Field getFieldFromClass ( String className , String fieldName ) throws Exception { Class < ? > clazz = Class . forName ( className ) ; Field [ ] fields = clazz . getDeclaredFields ( ) ; for ( int i = 0 ; i < fields . length ; i ++ ) { if ( fields [ i ] . getName ( ) . equals ( fieldName ) ) return fields [ i ] ; } return null ; } private boolean isModificationLogEnabled ( ) { return ConnectionCorePlugin . getDefault ( ) . getPluginPreferences ( ) . getBoolean ( ConnectionCoreConstants . PREFERENCE_MODIFICATIONLOGS_ENABLE ) ; } private int getFileCount ( ) { return ConnectionCorePlugin . getDefault ( ) . getPluginPreferences ( ) . getInt ( ConnectionCoreConstants . PREFERENCE_MODIFICATIONLOGS_FILE_COUNT ) ; } private int getFileSizeInKb ( ) { return ConnectionCorePlugin . getDefault ( ) . getPluginPreferences ( ) . getInt ( ConnectionCoreConstants . PREFERENCE_MODIFICATIONLOGS_FILE_SIZE ) ; } private Set < String > getMaskedAttributes ( ) { Set < String > maskedAttributes = new HashSet < String > ( ) ; String maskedAttributeString = ConnectionCorePlugin . getDefault ( ) . getPluginPreferences ( ) . getString ( ConnectionCoreConstants . PREFERENCE_MODIFICATIONLOGS_MASKED_ATTRIBUTES ) ; String [ ] splitted = maskedAttributeString . split ( "","" ) ; for ( String s : splitted ) { maskedAttributes . add ( Strings . toLowerCase ( s ) ) ; } return maskedAttributes ; } public String getId ( ) { return id ; } public void setId ( String id ) { this . id = id ; } public String getName ( ) { return name ; } public void setName ( String name ) { this . name = name ; } public String getDescription ( ) { return description ; } public void setDescription ( String description ) { this . description = description ; } }",No
"public class AMContainerEventLaunchRequest extends AMContainerEvent { private final TezVertexID vertexId ; private final ContainerContext containerContext ; private final int launcherId ; private final int taskCommId ; public AMContainerEventLaunchRequest ( ContainerId containerId , TezVertexID vertexId , ContainerContext containerContext , int launcherId , int taskCommId ) { super ( containerId , AMContainerEventType . C_LAUNCH_REQUEST ) ; this . vertexId = vertexId ; this . containerContext = containerContext ; this . launcherId = launcherId ; this . taskCommId = taskCommId ; } public TezDAGID getDAGId ( ) { return this . vertexId . getDAGId ( ) ; } public TezVertexID getVertexId ( ) { return this . vertexId ; } public ContainerContext getContainerContext ( ) { return this . containerContext ; } public int getLauncherId ( ) { return launcherId ; } public int getTaskCommId ( ) { return taskCommId ; } }",Smelly
"public class EntitlementSearchByRole extends AbstractEntitlementCommand { private static final Logger LOG = LoggerFactory . getLogger ( EntitlementSearchByRole . class ) ; private static final String READ_HELP_MESSAGE = ""entitlement --search-by-role {ROLE-KEY}"" ; private final Input input ; public EntitlementSearchByRole ( final Input input ) { this . input = input ; } public void search ( ) { if ( input . getParameters ( ) . length == 1 ) { try { entitlementResultManager . toView ( entitlementSyncopeOperations . entitlementsPerRole ( input . firstParameter ( ) ) ) ; } catch ( final SyncopeClientException | WebServiceException ex ) { LOG . error ( ""Error searching entitlement"" , ex ) ; if ( ex . getMessage ( ) . startsWith ( ""NotFound"" ) ) { entitlementResultManager . notFoundError ( ""User"" , input . firstParameter ( ) ) ; } else { entitlementResultManager . genericError ( ex . getMessage ( ) ) ; } } catch ( final NumberFormatException ex ) { LOG . error ( ""Error searching entitlement"" , ex ) ; entitlementResultManager . numberFormatException ( ""user"" , input . firstParameter ( ) ) ; } } else { entitlementResultManager . commandOptionError ( READ_HELP_MESSAGE ) ; } } }",No
"public class ActiveCompactionImpl extends ActiveCompaction { private org . apache . accumulo . core . tabletserver . thrift . ActiveCompaction tac ; private Instance instance ; ActiveCompactionImpl ( Instance instance , org . apache . accumulo . core . tabletserver . thrift . ActiveCompaction tac ) { this . tac = tac ; this . instance = instance ; } @ Override public String getTable ( ) throws TableNotFoundException { return Tables . getTableName ( instance , new KeyExtent ( tac . getExtent ( ) ) . getTableId ( ) . toString ( ) ) ; } @ Override @ Deprecated public org . apache . accumulo . core . data . KeyExtent getExtent ( ) { KeyExtent ke = new KeyExtent ( tac . getExtent ( ) ) ; org . apache . accumulo . core . data . KeyExtent oke = new org . apache . accumulo . core . data . KeyExtent ( ke . getTableId ( ) , ke . getEndRow ( ) , ke . getPrevEndRow ( ) ) ; return oke ; } @ Override public TabletId getTablet ( ) { return new TabletIdImpl ( new KeyExtent ( tac . getExtent ( ) ) ) ; } @ Override public long getAge ( ) { return tac . getAge ( ) ; } @ Override public List < String > getInputFiles ( ) { return tac . getInputFiles ( ) ; } @ Override public String getOutputFile ( ) { return tac . getOutputFile ( ) ; } @ Override public CompactionType getType ( ) { return CompactionType . valueOf ( tac . getType ( ) . name ( ) ) ; } @ Override public CompactionReason getReason ( ) { return CompactionReason . valueOf ( tac . getReason ( ) . name ( ) ) ; } @ Override public String getLocalityGroup ( ) { return tac . getLocalityGroup ( ) ; } @ Override public long getEntriesRead ( ) { return tac . getEntriesRead ( ) ; } @ Override public long getEntriesWritten ( ) { return tac . getEntriesWritten ( ) ; } @ Override public List < IteratorSetting > getIterators ( ) { ArrayList < IteratorSetting > ret = new ArrayList < > ( ) ; for ( IterInfo ii : tac . getSsiList ( ) ) { IteratorSetting settings = new IteratorSetting ( ii . getPriority ( ) , ii . getIterName ( ) , ii . getClassName ( ) ) ; Map < String , String > options = tac . getSsio ( ) . get ( ii . getIterName ( ) ) ; settings . addOptions ( options ) ; ret . add ( settings ) ; } return ret ; } }",Smelly
"public class MapIds implements ObjectGraphWalker . NodeProcessor { final Map < Id , Id > idToNewIdMap ; public MapIds ( Map < Id , Id > idToNewIdMap ) { this . idToNewIdMap = idToNewIdMap ; } @ Override public void processNode ( ObjectGraphWalker . Node nd ) throws AtlasException { IReferenceableInstance ref = null ; Id id = null ; if ( nd . attributeName == null ) { ref = ( IReferenceableInstance ) nd . instance ; Id newId = idToNewIdMap . get ( ref . getId ( ) ) ; if ( newId != null ) { ( ( ReferenceableInstance ) ref ) . replaceWithNewId ( newId ) ; } } else if ( nd . aInfo . dataType ( ) . getTypeCategory ( ) == DataTypes . TypeCategory . CLASS ) { if ( nd . value != null && nd . value instanceof IReferenceableInstance ) { Id oldId = ( ( IReferenceableInstance ) nd . value ) . getId ( ) ; Id newId = idToNewIdMap . get ( oldId ) ; newId = newId == null ? oldId : newId ; nd . instance . set ( nd . attributeName , newId ) ; } } else if ( nd . aInfo . dataType ( ) . getTypeCategory ( ) == DataTypes . TypeCategory . ARRAY ) { DataTypes . ArrayType aT = ( DataTypes . ArrayType ) nd . aInfo . dataType ( ) ; Object v = aT . mapIds ( ( ImmutableCollection ) nd . value , nd . aInfo . multiplicity , idToNewIdMap ) ; nd . instance . set ( nd . attributeName , v ) ; } else if ( nd . aInfo . dataType ( ) . getTypeCategory ( ) == DataTypes . TypeCategory . MAP ) { DataTypes . MapType mT = ( DataTypes . MapType ) nd . aInfo . dataType ( ) ; Object v = mT . mapIds ( ( ImmutableMap ) nd . value , nd . aInfo . multiplicity , idToNewIdMap ) ; nd . instance . set ( nd . attributeName , v ) ; } } }",No
"public class JAXRSClientFactoryBean extends AbstractJAXRSFactoryBean { private static final Logger LOG = LogUtils . getL7dLogger ( JAXRSClientFactoryBean . class ) ; private String username ; private String password ; private boolean inheritHeaders ; private MultivaluedMap < String , String > headers ; private ClientState initialState ; private boolean threadSafe ; private long timeToKeepState ; private Class < ? > serviceClass ; private ClassLoader proxyLoader ; public JAXRSClientFactoryBean ( ) { this ( new JAXRSServiceFactoryBean ( ) ) ; } public JAXRSClientFactoryBean ( JAXRSServiceFactoryBean serviceFactory ) { super ( serviceFactory ) ; serviceFactory . setEnableStaticResolution ( true ) ; } public void setClassLoader ( ClassLoader loader ) { proxyLoader = loader ; } public void setThreadSafe ( boolean threadSafe ) { this . threadSafe = threadSafe ; } public void setSecondsToKeepState ( long time ) { this . timeToKeepState = time ; } public String getUsername ( ) { return username ; } public void setUsername ( String username ) { this . username = username ; } public String getPassword ( ) { return password ; } public void setPassword ( String password ) { this . password = password ; } public void setInheritHeaders ( boolean ih ) { inheritHeaders = ih ; } public void setResourceClass ( Class < ? > cls ) { setServiceClass ( cls ) ; } public void setServiceClass ( Class < ? > cls ) { this . serviceClass = cls ; serviceFactory . setResourceClass ( cls ) ; } public Class < ? > getServiceClass ( ) { return serviceClass ; } public void setHeaders ( Map < String , String > map ) { headers = new MetadataMap < String , String > ( ) ; for ( Map . Entry < String , String > entry : map . entrySet ( ) ) { String [ ] values = entry . getValue ( ) . split ( "","" ) ; for ( String v : values ) { if ( v . length ( ) != 0 ) { headers . add ( entry . getKey ( ) , v ) ; } } } } public Map < String , List < String > > getHeaders ( ) { return headers ; } public WebClient createWebClient ( ) { Service service = new JAXRSServiceImpl ( getAddress ( ) , getServiceName ( ) ) ; getServiceFactory ( ) . setService ( service ) ; try { Endpoint ep = createEndpoint ( ) ; ClientState actualState = getActualState ( ) ; WebClient client = actualState == null ? new WebClient ( getAddress ( ) ) : new WebClient ( actualState ) ; initClient ( client , ep , actualState == null ) ; this . getServiceFactory ( ) . sendEvent ( FactoryBeanListener . Event . CLIENT_CREATED , client , ep ) ; return client ; } catch ( Exception ex ) { LOG . severe ( ex . getClass ( ) . getName ( ) + "" : "" + ex . getLocalizedMessage ( ) ) ; throw new RuntimeException ( ex ) ; } } private ClientState getActualState ( ) { if ( threadSafe ) { initialState = new ThreadLocalClientState ( getAddress ( ) , timeToKeepState ) ; } if ( initialState != null ) { return headers != null ? initialState . newState ( URI . create ( getAddress ( ) ) , headers , null ) : initialState ; } else { return null ; } } public < T > T create ( Class < T > cls , Object ... varValues ) { return cls . cast ( createWithValues ( varValues ) ) ; } public Client create ( ) { return createWithValues ( ) ; } public Client createWithValues ( Object ... varValues ) { serviceFactory . setBus ( getBus ( ) ) ; checkResources ( false ) ; ClassResourceInfo cri = null ; try { Endpoint ep = createEndpoint ( ) ; if ( getServiceClass ( ) != null ) { for ( ClassResourceInfo info : serviceFactory . getClassResourceInfo ( ) ) { if ( info . getServiceClass ( ) . isAssignableFrom ( getServiceClass ( ) ) || getServiceClass ( ) . isAssignableFrom ( info . getServiceClass ( ) ) ) { cri = info ; break ; } } if ( cri == null ) { throw new RuntimeException ( ""Service class "" + getServiceClass ( ) . getName ( ) + "" is not recognized"" ) ; } } else { cri = serviceFactory . getClassResourceInfo ( ) . get ( 0 ) ; } boolean isRoot = cri . getURITemplate ( ) != null ; ClientProxyImpl proxyImpl = null ; ClientState actualState = getActualState ( ) ; if ( actualState == null ) { proxyImpl = new ClientProxyImpl ( URI . create ( getAddress ( ) ) , proxyLoader , cri , isRoot , inheritHeaders , varValues ) ; } else { proxyImpl = new ClientProxyImpl ( actualState , proxyLoader , cri , isRoot , inheritHeaders , varValues ) ; } initClient ( proxyImpl , ep , actualState == null ) ; Client actualClient = null ; try { ClassLoader theLoader = proxyLoader == null ? cri . getServiceClass ( ) . getClassLoader ( ) : proxyLoader ; actualClient = ( Client ) ProxyHelper . getProxy ( theLoader , new Class [ ] { cri . getServiceClass ( ) , Client . class , InvocationHandlerAware . class } , proxyImpl ) ; } catch ( Exception ex ) { actualClient = ( Client ) ProxyHelper . getProxy ( Thread . currentThread ( ) . getContextClassLoader ( ) , new Class [ ] { cri . getServiceClass ( ) , Client . class , InvocationHandlerAware . class } , proxyImpl ) ; } this . getServiceFactory ( ) . sendEvent ( FactoryBeanListener . Event . CLIENT_CREATED , actualClient , ep ) ; return actualClient ; } catch ( IllegalArgumentException ex ) { String message = ex . getLocalizedMessage ( ) ; if ( cri != null ) { String expected = cri . getServiceClass ( ) . getSimpleName ( ) ; if ( ( expected + "" is not an interface"" ) . equals ( message ) ) { message += ""; make sure CGLIB is on the classpath"" ; } } LOG . severe ( ex . getClass ( ) . getName ( ) + "" : "" + message ) ; throw ex ; } catch ( Exception ex ) { LOG . severe ( ex . getClass ( ) . getName ( ) + "" : "" + ex . getLocalizedMessage ( ) ) ; throw new RuntimeException ( ex ) ; } } protected ConduitSelector getConduitSelector ( Endpoint ep ) { ConduitSelector cs = getConduitSelector ( ) ; if ( cs == null ) { cs = new UpfrontConduitSelector ( ) ; } cs . setEndpoint ( ep ) ; return cs ; } protected void initClient ( AbstractClient client , Endpoint ep , boolean addHeaders ) { if ( username != null ) { AuthorizationPolicy authPolicy = new AuthorizationPolicy ( ) ; authPolicy . setUserName ( username ) ; authPolicy . setPassword ( password ) ; ep . getEndpointInfo ( ) . addExtensor ( authPolicy ) ; } client . getConfiguration ( ) . setConduitSelector ( getConduitSelector ( ep ) ) ; client . getConfiguration ( ) . setBus ( getBus ( ) ) ; client . getConfiguration ( ) . getOutInterceptors ( ) . addAll ( getOutInterceptors ( ) ) ; client . getConfiguration ( ) . getOutInterceptors ( ) . addAll ( ep . getOutInterceptors ( ) ) ; client . getConfiguration ( ) . getInInterceptors ( ) . addAll ( getInInterceptors ( ) ) ; client . getConfiguration ( ) . getInInterceptors ( ) . addAll ( ep . getInInterceptors ( ) ) ; applyFeatures ( client ) ; if ( headers != null && addHeaders ) { client . headers ( headers ) ; } setupFactory ( ep ) ; } protected void applyFeatures ( AbstractClient client ) { if ( getFeatures ( ) != null ) { for ( Feature feature : getFeatures ( ) ) { feature . initialize ( client . getConfiguration ( ) , getBus ( ) ) ; } } } public void setInitialState ( ClientState initialState ) { this . initialState = initialState ; } }",Smelly
"public class Parser { private static final Pattern VERSION_FILE_PATTERN = Pattern . compile ( ""^(.*)-([0-9]{8}\\.[0-9]{6})-([0-9]+)$"" ) ; public static final String VERSION_LATEST = ""LATEST"" ; private static final String SYNTAX = ""mvn:[repository_url!]groupId/artifactId[/[version]/[type]]"" ; private static final String REPOSITORY_SEPARATOR = ""!"" ; private static final String ARTIFACT_SEPARATOR = ""/"" ; private static final String VERSION_SNAPSHOT = ""SNAPSHOT"" ; private static final String TYPE_JAR = ""jar"" ; public static final String FILE_SEPARATOR = ""/"" ; private static final String GROUP_SEPARATOR = ""\\."" ; private static final String VERSION_SEPARATOR = ""-"" ; private static final String TYPE_SEPARATOR = ""."" ; private static final String CLASSIFIER_SEPARATOR = ""-"" ; private static final String METADATA_FILE = ""maven-metadata.xml"" ; private static final String METADATA_FILE_LOCAL = ""maven-metadata-local.xml"" ; private String m_repositoryURL ; private String m_group ; private String m_artifact ; private String m_version ; private String m_type ; private String m_classifier ; private String m_fullClassifier ; public Parser ( final String path ) throws MalformedURLException { if ( path == null ) { throw new MalformedURLException ( ""Path cannot be null. Syntax "" + SYNTAX ) ; } if ( path . startsWith ( REPOSITORY_SEPARATOR ) || path . endsWith ( REPOSITORY_SEPARATOR ) ) { throw new MalformedURLException ( ""Path cannot start or end with "" + REPOSITORY_SEPARATOR + "". Syntax "" + SYNTAX ) ; } if ( path . contains ( REPOSITORY_SEPARATOR ) ) { int pos = path . lastIndexOf ( REPOSITORY_SEPARATOR ) ; parseArtifactPart ( path . substring ( pos + 1 ) ) ; m_repositoryURL = path . substring ( 0 , pos ) + ""@snapshots"" ; } else { parseArtifactPart ( path ) ; } } public static String pathFromMaven ( String uri ) throws MalformedURLException { return pathFromMaven ( uri , null ) ; } public static String pathFromMaven ( String uri , String resolved ) throws MalformedURLException { if ( ! uri . startsWith ( ""mvn:"" ) ) { return uri ; } Parser parser = new Parser ( uri . substring ( ""mvn:"" . length ( ) ) ) ; if ( resolved != null ) { String grp = FILE_SEPARATOR + parser . getGroup ( ) . replaceAll ( GROUP_SEPARATOR , FILE_SEPARATOR ) + FILE_SEPARATOR + parser . getArtifact ( ) + FILE_SEPARATOR ; int idx = resolved . indexOf ( grp ) ; if ( idx >= 0 ) { String version = resolved . substring ( idx + grp . length ( ) , resolved . indexOf ( '/' , idx + grp . length ( ) ) ) ; return parser . getArtifactPath ( version ) ; } } return parser . getArtifactPath ( ) ; } public static String pathToMaven ( String location , Map parts ) { String [ ] p = location . split ( ""/"" ) ; if ( p . length >= 4 && p [ p . length - 1 ] . startsWith ( p [ p . length - 3 ] + ""-"" + p [ p . length - 2 ] ) ) { String artifactId = p [ p . length - 3 ] ; String version = p [ p . length - 2 ] ; String classifier ; String type ; String artifactIdVersion = artifactId + ""-"" + version ; StringBuilder sb = new StringBuilder ( ) ; if ( p [ p . length - 1 ] . charAt ( artifactIdVersion . length ( ) ) == '-' ) { classifier = p [ p . length - 1 ] . substring ( artifactIdVersion . length ( ) + 1 , p [ p . length - 1 ] . lastIndexOf ( '.' ) ) ; } else { classifier = null ; } type = p [ p . length - 1 ] . substring ( p [ p . length - 1 ] . lastIndexOf ( '.' ) + 1 ) ; sb . append ( ""mvn:"" ) ; if ( parts != null ) { parts . put ( ""artifactId"" , artifactId ) ; parts . put ( ""version"" , version ) ; parts . put ( ""classifier"" , classifier ) ; parts . put ( ""type"" , type ) ; } for ( int j = 0 ; j < p . length - 3 ; j ++ ) { if ( j > 0 ) { sb . append ( '.' ) ; } sb . append ( p [ j ] ) ; } sb . append ( '/' ) . append ( artifactId ) . append ( '/' ) . append ( version ) ; if ( ! ""jar"" . equals ( type ) || classifier != null ) { sb . append ( '/' ) ; if ( ! ""jar"" . equals ( type ) ) { sb . append ( type ) ; } if ( classifier != null ) { sb . append ( '/' ) . append ( classifier ) ; } } return sb . toString ( ) ; } return location ; } public static String pathToMaven ( String location ) { return pathToMaven ( location , null ) ; } private void parseArtifactPart ( final String part ) throws MalformedURLException { String [ ] segments = part . split ( ARTIFACT_SEPARATOR ) ; if ( segments . length < 2 ) { throw new MalformedURLException ( ""Invalid path. Syntax "" + SYNTAX ) ; } m_group = segments [ 0 ] ; if ( m_group . trim ( ) . length ( ) == 0 ) { throw new MalformedURLException ( ""Invalid groupId. Syntax "" + SYNTAX ) ; } m_artifact = segments [ 1 ] ; if ( m_artifact . trim ( ) . length ( ) == 0 ) { throw new MalformedURLException ( ""Invalid artifactId. Syntax "" + SYNTAX ) ; } m_version = VERSION_LATEST ; if ( segments . length >= 3 && segments [ 2 ] . trim ( ) . length ( ) > 0 ) { m_version = segments [ 2 ] ; } m_type = TYPE_JAR ; if ( segments . length >= 4 && segments [ 3 ] . trim ( ) . length ( ) > 0 ) { m_type = segments [ 3 ] ; } m_fullClassifier = """" ; if ( segments . length >= 5 && segments [ 4 ] . trim ( ) . length ( ) > 0 ) { m_classifier = segments [ 4 ] ; m_fullClassifier = CLASSIFIER_SEPARATOR + m_classifier ; } } public String getRepositoryURL ( ) { return m_repositoryURL ; } public String toMvnURI ( ) { StringBuilder sb = new StringBuilder ( ) ; sb . append ( m_group ) . append ( ARTIFACT_SEPARATOR ) . append ( m_artifact ) . append ( ARTIFACT_SEPARATOR ) . append ( m_version ) ; if ( ! TYPE_JAR . equals ( m_type ) ) { sb . append ( ARTIFACT_SEPARATOR ) . append ( m_type ) ; } if ( m_classifier != null && ! """" . equals ( m_classifier ) ) { if ( TYPE_JAR . equals ( m_type ) ) { sb . append ( ARTIFACT_SEPARATOR ) . append ( m_type ) ; } sb . append ( ARTIFACT_SEPARATOR ) . append ( m_classifier ) ; } return sb . toString ( ) ; } public String getGroup ( ) { return m_group ; } public String getArtifact ( ) { return m_artifact ; } public String getVersion ( ) { return m_version ; } public String getType ( ) { return m_type ; } public String getClassifier ( ) { return m_classifier ; } public void setGroup ( String m_group ) { this . m_group = m_group ; } public void setArtifact ( String m_artifact ) { this . m_artifact = m_artifact ; } public void setVersion ( String m_version ) { this . m_version = m_version ; } public void setType ( String m_type ) { this . m_type = m_type ; } public void setClassifier ( String m_classifier ) { this . m_classifier = m_classifier ; } public String getArtifactPath ( ) { return getArtifactPath ( m_version ) ; } public String getArtifactPath ( final String version ) { Matcher m = VERSION_FILE_PATTERN . matcher ( version ) ; if ( m . matches ( ) ) { this . m_version = m . group ( 1 ) + ""-"" + ""SNAPSHOT"" ; String ret = new StringBuilder ( ) . append ( m_group . replaceAll ( GROUP_SEPARATOR , FILE_SEPARATOR ) ) . append ( FILE_SEPARATOR ) . append ( m_artifact ) . append ( FILE_SEPARATOR ) . append ( m_version ) . append ( FILE_SEPARATOR ) . append ( m_artifact ) . append ( VERSION_SEPARATOR ) . append ( m_version ) . append ( m_fullClassifier ) . append ( TYPE_SEPARATOR ) . append ( m_type ) . toString ( ) ; return ret ; } else { return new StringBuilder ( ) . append ( m_group . replaceAll ( GROUP_SEPARATOR , FILE_SEPARATOR ) ) . append ( FILE_SEPARATOR ) . append ( m_artifact ) . append ( FILE_SEPARATOR ) . append ( version ) . append ( FILE_SEPARATOR ) . append ( m_artifact ) . append ( VERSION_SEPARATOR ) . append ( version ) . append ( m_fullClassifier ) . append ( TYPE_SEPARATOR ) . append ( m_type ) . toString ( ) ; } } public String getSnapshotVersion ( final String version , final String timestamp , final String buildnumber ) { return version . replace ( VERSION_SNAPSHOT , timestamp ) + VERSION_SEPARATOR + buildnumber ; } public String getSnapshotPath ( final String version , final String timestamp , final String buildnumber ) { return new StringBuilder ( ) . append ( m_group . replaceAll ( GROUP_SEPARATOR , FILE_SEPARATOR ) ) . append ( FILE_SEPARATOR ) . append ( m_artifact ) . append ( FILE_SEPARATOR ) . append ( version ) . append ( FILE_SEPARATOR ) . append ( m_artifact ) . append ( VERSION_SEPARATOR ) . append ( getSnapshotVersion ( version , timestamp , buildnumber ) ) . append ( m_fullClassifier ) . append ( TYPE_SEPARATOR ) . append ( m_type ) . toString ( ) ; } public String getVersionMetadataPath ( final String version ) { return new StringBuilder ( ) . append ( m_group . replaceAll ( GROUP_SEPARATOR , FILE_SEPARATOR ) ) . append ( FILE_SEPARATOR ) . append ( m_artifact ) . append ( FILE_SEPARATOR ) . append ( version ) . append ( FILE_SEPARATOR ) . append ( METADATA_FILE ) . toString ( ) ; } public String getVersionLocalMetadataPath ( final String version ) { return new StringBuilder ( ) . append ( m_group . replaceAll ( GROUP_SEPARATOR , FILE_SEPARATOR ) ) . append ( FILE_SEPARATOR ) . append ( m_artifact ) . append ( FILE_SEPARATOR ) . append ( version ) . append ( FILE_SEPARATOR ) . append ( METADATA_FILE_LOCAL ) . toString ( ) ; } public String getArtifactLocalMetdataPath ( ) { return new StringBuilder ( ) . append ( m_group . replaceAll ( GROUP_SEPARATOR , FILE_SEPARATOR ) ) . append ( FILE_SEPARATOR ) . append ( m_artifact ) . append ( FILE_SEPARATOR ) . append ( METADATA_FILE_LOCAL ) . toString ( ) ; } public String getArtifactMetdataPath ( ) { return new StringBuilder ( ) . append ( m_group . replaceAll ( GROUP_SEPARATOR , FILE_SEPARATOR ) ) . append ( FILE_SEPARATOR ) . append ( m_artifact ) . append ( FILE_SEPARATOR ) . append ( METADATA_FILE ) . toString ( ) ; } }",Smelly
"public class InlineRun { private InlineArea inline ; private int [ ] levels ; private int minLevel ; private int maxLevel ; private int reversals ; public InlineRun ( InlineArea inline , int [ ] levels ) { assert inline != null ; assert levels != null ; this . inline = inline ; this . levels = levels ; setMinMax ( levels ) ; } public InlineRun ( InlineArea inline , int level , int count ) { this ( inline , makeLevels ( level , count ) ) ; } public InlineArea getInline ( ) { return inline ; } public int getMinLevel ( ) { return minLevel ; } public int getMaxLevel ( ) { return maxLevel ; } private void setMinMax ( int [ ] levels ) { int mn = Integer . MAX_VALUE ; int mx = Integer . MIN_VALUE ; if ( ( levels != null ) && ( levels . length > 0 ) ) { for ( int l : levels ) { if ( l < mn ) { mn = l ; } if ( l > mx ) { mx = l ; } } } else { mn = mx = - 1 ; } this . minLevel = mn ; this . maxLevel = mx ; } public boolean isHomogenous ( ) { return minLevel == maxLevel ; } public List split ( ) { List runs = new Vector ( ) ; for ( int i = 0 , n = levels . length ; i < n ; ) { int l = levels [ i ] ; int s = i ; int e = s ; while ( e < n ) { if ( levels [ e ] != l ) { break ; } else { e ++ ; } } if ( s < e ) { runs . add ( new InlineRun ( inline , l , e - s ) ) ; } i = e ; } assert runs . size ( ) < 2 : ""heterogeneous inlines not yet supported!!"" ; return runs ; } public void updateMinMax ( int [ ] mm ) { if ( minLevel < mm [ 0 ] ) { mm [ 0 ] = minLevel ; } if ( maxLevel > mm [ 1 ] ) { mm [ 1 ] = maxLevel ; } } public boolean maybeNeedsMirroring ( ) { return ( minLevel == maxLevel ) && ( minLevel > 0 ) && ( ( minLevel & 1 ) != 0 ) ; } public void reverse ( ) { reversals ++ ; } public void maybeReverseWord ( boolean mirror ) { if ( inline instanceof WordArea ) { WordArea w = ( WordArea ) inline ; if ( ! w . isReversed ( ) ) { if ( ( reversals & 1 ) != 0 ) { w . reverse ( mirror ) ; } else if ( mirror && maybeNeedsMirroring ( ) ) { w . mirror ( ) ; } } } } @ Override public boolean equals ( Object o ) { if ( o instanceof InlineRun ) { InlineRun ir = ( InlineRun ) o ; if ( ir . inline != inline ) { return false ; } else if ( ir . minLevel != minLevel ) { return false ; } else if ( ir . maxLevel != maxLevel ) { return false ; } else if ( ( ir . levels != null ) && ( levels != null ) ) { if ( ir . levels . length != levels . length ) { return false ; } else { for ( int i = 0 , n = levels . length ; i < n ; i ++ ) { if ( ir . levels [ i ] != levels [ i ] ) { return false ; } } return true ; } } else { return ( ir . levels == null ) && ( levels == null ) ; } } else { return false ; } } @ Override public int hashCode ( ) { int l = ( inline != null ) ? inline . hashCode ( ) : 0 ; l = ( l ^ minLevel ) + ( l < < 19 ) ; l = ( l ^ maxLevel ) + ( l < < 11 ) ; return l ; } @ Override public String toString ( ) { StringBuffer sb = new StringBuffer ( ""RR: { type = \'"" ) ; char c ; String content = null ; if ( inline instanceof WordArea ) { c = 'W' ; content = ( ( WordArea ) inline ) . getWord ( ) ; } else if ( inline instanceof SpaceArea ) { c = 'S' ; content = ( ( SpaceArea ) inline ) . getSpace ( ) ; } else if ( inline instanceof Anchor ) { c = 'A' ; } else if ( inline instanceof Leader ) { c = 'L' ; } else if ( inline instanceof Space ) { c = 'S' ; } else if ( inline instanceof UnresolvedPageNumber ) { c = '#' ; content = ( ( UnresolvedPageNumber ) inline ) . getText ( ) ; } else if ( inline instanceof InlineBlockParent ) { c = 'B' ; } else if ( inline instanceof InlineViewport ) { c = 'V' ; } else if ( inline instanceof InlineParent ) { c = 'I' ; } else { c = '?' ; } sb . append ( c ) ; sb . append ( ""\', levels = \'"" ) ; sb . append ( generateLevels ( levels ) ) ; sb . append ( ""\', min = "" ) ; sb . append ( minLevel ) ; sb . append ( "", max = "" ) ; sb . append ( maxLevel ) ; sb . append ( "", reversals = "" ) ; sb . append ( reversals ) ; sb . append ( "", content = <"" ) ; sb . append ( CharUtilities . toNCRefs ( content ) ) ; sb . append ( ""> }"" ) ; return sb . toString ( ) ; } private String generateLevels ( int [ ] levels ) { StringBuffer lb = new StringBuffer ( ) ; int maxLevel = - 1 ; int numLevels = levels . length ; for ( int l : levels ) { if ( l > maxLevel ) { maxLevel = l ; } } if ( maxLevel < 0 ) { } else if ( maxLevel < 10 ) { for ( int level : levels ) { lb . append ( ( char ) ( '0' + level ) ) ; } } else { boolean first = true ; for ( int level : levels ) { if ( first ) { first = false ; } else { lb . append ( ',' ) ; } lb . append ( level ) ; } } return lb . toString ( ) ; } private static int [ ] makeLevels ( int level , int count ) { int [ ] levels = new int [ count > 0 ? count : 1 ] ; Arrays . fill ( levels , level ) ; return levels ; } }",No
"public class SearchCriteria { Logger logger = Logger . getLogger ( SearchCriteria . class ) ; int startIndex = 0 ; int maxRows = Integer . MAX_VALUE ; String sortBy = null ; String sortType = null ; boolean getCount = true ; Number ownerId = null ; boolean familyOnly = false ; boolean getChildren = false ; boolean isDistinct = false ; HashMap < String , Object > paramList = new HashMap < String , Object > ( ) ; Set < String > nullParamList = new HashSet < String > ( ) ; Set < String > notNullParamList = new HashSet < String > ( ) ; List < SearchGroup > searchGroups = new ArrayList < SearchGroup > ( ) ; public int getStartIndex ( ) { return startIndex ; } public void setStartIndex ( int startIndex ) { this . startIndex = startIndex ; } public int getMaxRows ( ) { return maxRows ; } public void setMaxRows ( int maxRows ) { this . maxRows = maxRows ; } public String getSortBy ( ) { return sortBy ; } public void setSortBy ( String sortBy ) { this . sortBy = sortBy ; } public String getSortType ( ) { return sortType ; } public void setSortType ( String sortType ) { this . sortType = sortType ; } public boolean isGetCount ( ) { return getCount ; } public void setGetCount ( boolean getCount ) { this . getCount = getCount ; } public Number getOwnerId ( ) { return ownerId ; } public void setOwnerId ( Number ownerId ) { this . ownerId = ownerId ; } public boolean isGetChildren ( ) { return getChildren ; } public void setGetChildren ( boolean getChildren ) { this . getChildren = getChildren ; } public HashMap < String , Object > getParamList ( ) { return paramList ; } public void addParam ( String name , Object value ) { paramList . put ( name , value ) ; } public Object getParamValue ( String name ) { return paramList . get ( name ) ; } public Set < String > getNullParamList ( ) { return nullParamList ; } public Set < String > getNotNullParamList ( ) { return notNullParamList ; } public List < SearchGroup > getSearchGroups ( ) { return searchGroups ; } public boolean isDistinct ( ) { return isDistinct ; } public void setDistinct ( boolean isDistinct ) { int dbFlavor = RangerBizUtil . getDBFlavor ( ) ; if ( isDistinct && dbFlavor == AppConstants . DB_FLAVOR_ORACLE ) { isDistinct = false ; logger . debug ( ""Database flavor is `ORACLE` so ignoring DISTINCT "" + ""clause from select statement."" ) ; } this . isDistinct = isDistinct ; } }",Smelly
"@ XmlRootElement ( name = ""portEntity"" ) public class PortEntity extends ComponentEntity implements Permissible < PortDTO > , OperationPermissible { private PortDTO component ; private PortStatusDTO status ; private String portType ; private PermissionsDTO operatePermissions ; @ Override public PortDTO getComponent ( ) { return component ; } @ Override public void setComponent ( PortDTO component ) { this . component = component ; } @ ApiModelProperty ( value = ""The status of the port."" ) public PortStatusDTO getStatus ( ) { return status ; } public void setStatus ( PortStatusDTO status ) { this . status = status ; } public String getPortType ( ) { return portType ; } public void setPortType ( String portType ) { this . portType = portType ; } @ ApiModelProperty ( value = ""The permissions for this component operations."" ) @ Override public PermissionsDTO getOperatePermissions ( ) { return operatePermissions ; } @ Override public void setOperatePermissions ( PermissionsDTO permissions ) { this . operatePermissions = permissions ; } }",Smelly
"public class RedisUtils { public static final AllowableValue REDIS_MODE_STANDALONE = new AllowableValue ( RedisType . STANDALONE . getDisplayName ( ) , RedisType . STANDALONE . getDisplayName ( ) , RedisType . STANDALONE . getDescription ( ) ) ; public static final AllowableValue REDIS_MODE_SENTINEL = new AllowableValue ( RedisType . SENTINEL . getDisplayName ( ) , RedisType . SENTINEL . getDisplayName ( ) , RedisType . SENTINEL . getDescription ( ) ) ; public static final AllowableValue REDIS_MODE_CLUSTER = new AllowableValue ( RedisType . CLUSTER . getDisplayName ( ) , RedisType . CLUSTER . getDisplayName ( ) , RedisType . CLUSTER . getDescription ( ) ) ; public static final PropertyDescriptor REDIS_MODE = new PropertyDescriptor . Builder ( ) . name ( ""Redis Mode"" ) . displayName ( ""Redis Mode"" ) . description ( ""The type of Redis being communicated with - standalone, sentinel, or clustered."" ) . allowableValues ( REDIS_MODE_STANDALONE , REDIS_MODE_SENTINEL , REDIS_MODE_CLUSTER ) . defaultValue ( REDIS_MODE_STANDALONE . getValue ( ) ) . addValidator ( StandardValidators . NON_EMPTY_VALIDATOR ) . required ( true ) . build ( ) ; public static final PropertyDescriptor CONNECTION_STRING = new PropertyDescriptor . Builder ( ) . name ( ""Connection String"" ) . displayName ( ""Connection String"" ) . description ( ""The connection string for Redis. In a standalone instance this value will be of the form hostname:port. "" + ""In a sentinel instance this value will be the comma-separated list of sentinels, such as host1:port1,host2:port2,host3:port3. "" + ""In a clustered instance this value will be the comma-separated list of cluster masters, such as host1:port,host2:port,host3:port."" ) . required ( true ) . addValidator ( StandardValidators . NON_BLANK_VALIDATOR ) . expressionLanguageSupported ( ExpressionLanguageScope . VARIABLE_REGISTRY ) . build ( ) ; public static final PropertyDescriptor DATABASE = new PropertyDescriptor . Builder ( ) . name ( ""Database Index"" ) . displayName ( ""Database Index"" ) . description ( ""The database index to be used by connections created from this connection pool. "" + ""See the databases property in redis.conf, by default databases 0-15 will be available."" ) . addValidator ( StandardValidators . NON_NEGATIVE_INTEGER_VALIDATOR ) . defaultValue ( ""0"" ) . expressionLanguageSupported ( ExpressionLanguageScope . VARIABLE_REGISTRY ) . required ( true ) . build ( ) ; public static final PropertyDescriptor COMMUNICATION_TIMEOUT = new PropertyDescriptor . Builder ( ) . name ( ""Communication Timeout"" ) . displayName ( ""Communication Timeout"" ) . description ( ""The timeout to use when attempting to communicate with Redis."" ) . addValidator ( StandardValidators . TIME_PERIOD_VALIDATOR ) . defaultValue ( ""10 seconds"" ) . required ( true ) . build ( ) ; public static final PropertyDescriptor CLUSTER_MAX_REDIRECTS = new PropertyDescriptor . Builder ( ) . name ( ""Cluster Max Redirects"" ) . displayName ( ""Cluster Max Redirects"" ) . description ( ""The maximum number of redirects that can be performed when clustered."" ) . addValidator ( StandardValidators . NON_NEGATIVE_INTEGER_VALIDATOR ) . defaultValue ( ""5"" ) . required ( true ) . build ( ) ; public static final PropertyDescriptor SENTINEL_MASTER = new PropertyDescriptor . Builder ( ) . name ( ""Sentinel Master"" ) . displayName ( ""Sentinel Master"" ) . description ( ""The name of the sentinel master, require when Mode is set to Sentinel"" ) . addValidator ( StandardValidators . NON_BLANK_VALIDATOR ) . expressionLanguageSupported ( ExpressionLanguageScope . VARIABLE_REGISTRY ) . build ( ) ; public static final PropertyDescriptor PASSWORD = new PropertyDescriptor . Builder ( ) . name ( ""Password"" ) . displayName ( ""Password"" ) . description ( ""The password used to authenticate to the Redis server. See the requirepass property in redis.conf."" ) . addValidator ( StandardValidators . NON_BLANK_VALIDATOR ) . expressionLanguageSupported ( ExpressionLanguageScope . VARIABLE_REGISTRY ) . sensitive ( true ) . build ( ) ; public static final PropertyDescriptor POOL_MAX_TOTAL = new PropertyDescriptor . Builder ( ) . name ( ""Pool - Max Total"" ) . displayName ( ""Pool - Max Total"" ) . description ( ""The maximum number of connections that can be allocated by the pool (checked out to clients, or idle awaiting checkout). "" + ""A negative value indicates that there is no limit."" ) . addValidator ( StandardValidators . INTEGER_VALIDATOR ) . defaultValue ( ""8"" ) . required ( true ) . build ( ) ; public static final PropertyDescriptor POOL_MAX_IDLE = new PropertyDescriptor . Builder ( ) . name ( ""Pool - Max Idle"" ) . displayName ( ""Pool - Max Idle"" ) . description ( ""The maximum number of idle connections that can be held in the pool, or a negative value if there is no limit."" ) . addValidator ( StandardValidators . INTEGER_VALIDATOR ) . defaultValue ( ""8"" ) . required ( true ) . build ( ) ; public static final PropertyDescriptor POOL_MIN_IDLE = new PropertyDescriptor . Builder ( ) . name ( ""Pool - Min Idle"" ) . displayName ( ""Pool - Min Idle"" ) . description ( ""The target for the minimum number of idle connections to maintain in the pool. If the configured value of Min Idle is "" + ""greater than the configured value for Max Idle, then the value of Max Idle will be used instead."" ) . addValidator ( StandardValidators . INTEGER_VALIDATOR ) . defaultValue ( ""0"" ) . required ( true ) . build ( ) ; public static final PropertyDescriptor POOL_BLOCK_WHEN_EXHAUSTED = new PropertyDescriptor . Builder ( ) . name ( ""Pool - Block When Exhausted"" ) . displayName ( ""Pool - Block When Exhausted"" ) . description ( ""Whether or not clients should block and wait when trying to obtain a connection from the pool when the pool has no available connections. "" + ""Setting this to false means an error will occur immediately when a client requests a connection and none are available."" ) . addValidator ( StandardValidators . NON_EMPTY_VALIDATOR ) . allowableValues ( ""true"" , ""false"" ) . defaultValue ( ""true"" ) . required ( true ) . build ( ) ; public static final PropertyDescriptor POOL_MAX_WAIT_TIME = new PropertyDescriptor . Builder ( ) . name ( ""Pool - Max Wait Time"" ) . displayName ( ""Pool - Max Wait Time"" ) . description ( ""The amount of time to wait for an available connection when Block When Exhausted is set to true."" ) . addValidator ( StandardValidators . TIME_PERIOD_VALIDATOR ) . defaultValue ( ""10 seconds"" ) . required ( true ) . build ( ) ; public static final PropertyDescriptor POOL_MIN_EVICTABLE_IDLE_TIME = new PropertyDescriptor . Builder ( ) . name ( ""Pool - Min Evictable Idle Time"" ) . displayName ( ""Pool - Min Evictable Idle Time"" ) . description ( ""The minimum amount of time an object may sit idle in the pool before it is eligible for eviction."" ) . addValidator ( StandardValidators . TIME_PERIOD_VALIDATOR ) . defaultValue ( ""60 seconds"" ) . required ( true ) . build ( ) ; public static final PropertyDescriptor POOL_TIME_BETWEEN_EVICTION_RUNS = new PropertyDescriptor . Builder ( ) . name ( ""Pool - Time Between Eviction Runs"" ) . displayName ( ""Pool - Time Between Eviction Runs"" ) . description ( ""The amount of time between attempting to evict idle connections from the pool."" ) . addValidator ( StandardValidators . TIME_PERIOD_VALIDATOR ) . defaultValue ( ""30 seconds"" ) . required ( true ) . build ( ) ; public static final PropertyDescriptor POOL_NUM_TESTS_PER_EVICTION_RUN = new PropertyDescriptor . Builder ( ) . name ( ""Pool - Num Tests Per Eviction Run"" ) . displayName ( ""Pool - Num Tests Per Eviction Run"" ) . description ( ""The number of connections to tests per eviction attempt. A negative value indicates to test all connections."" ) . addValidator ( StandardValidators . INTEGER_VALIDATOR ) . defaultValue ( ""-1"" ) . required ( true ) . build ( ) ; public static final PropertyDescriptor POOL_TEST_ON_CREATE = new PropertyDescriptor . Builder ( ) . name ( ""Pool - Test On Create"" ) . displayName ( ""Pool - Test On Create"" ) . description ( ""Whether or not connections should be tested upon creation."" ) . addValidator ( StandardValidators . NON_EMPTY_VALIDATOR ) . allowableValues ( ""true"" , ""false"" ) . defaultValue ( ""false"" ) . required ( true ) . build ( ) ; public static final PropertyDescriptor POOL_TEST_ON_BORROW = new PropertyDescriptor . Builder ( ) . name ( ""Pool - Test On Borrow"" ) . displayName ( ""Pool - Test On Borrow"" ) . description ( ""Whether or not connections should be tested upon borrowing from the pool."" ) . addValidator ( StandardValidators . NON_EMPTY_VALIDATOR ) . allowableValues ( ""true"" , ""false"" ) . defaultValue ( ""false"" ) . required ( true ) . build ( ) ; public static final PropertyDescriptor POOL_TEST_ON_RETURN = new PropertyDescriptor . Builder ( ) . name ( ""Pool - Test On Return"" ) . displayName ( ""Pool - Test On Return"" ) . description ( ""Whether or not connections should be tested upon returning to the pool."" ) . addValidator ( StandardValidators . NON_EMPTY_VALIDATOR ) . allowableValues ( ""true"" , ""false"" ) . defaultValue ( ""false"" ) . required ( true ) . build ( ) ; public static final PropertyDescriptor POOL_TEST_WHILE_IDLE = new PropertyDescriptor . Builder ( ) . name ( ""Pool - Test While Idle"" ) . displayName ( ""Pool - Test While Idle"" ) . description ( ""Whether or not connections should be tested while idle."" ) . addValidator ( StandardValidators . NON_EMPTY_VALIDATOR ) . allowableValues ( ""true"" , ""false"" ) . defaultValue ( ""true"" ) . required ( true ) . build ( ) ; public static final List < PropertyDescriptor > REDIS_CONNECTION_PROPERTY_DESCRIPTORS ; static { final List < PropertyDescriptor > props = new ArrayList < > ( ) ; props . add ( RedisUtils . REDIS_MODE ) ; props . add ( RedisUtils . CONNECTION_STRING ) ; props . add ( RedisUtils . DATABASE ) ; props . add ( RedisUtils . COMMUNICATION_TIMEOUT ) ; props . add ( RedisUtils . CLUSTER_MAX_REDIRECTS ) ; props . add ( RedisUtils . SENTINEL_MASTER ) ; props . add ( RedisUtils . PASSWORD ) ; props . add ( RedisUtils . POOL_MAX_TOTAL ) ; props . add ( RedisUtils . POOL_MAX_IDLE ) ; props . add ( RedisUtils . POOL_MIN_IDLE ) ; props . add ( RedisUtils . POOL_BLOCK_WHEN_EXHAUSTED ) ; props . add ( RedisUtils . POOL_MAX_WAIT_TIME ) ; props . add ( RedisUtils . POOL_MIN_EVICTABLE_IDLE_TIME ) ; props . add ( RedisUtils . POOL_TIME_BETWEEN_EVICTION_RUNS ) ; props . add ( RedisUtils . POOL_NUM_TESTS_PER_EVICTION_RUN ) ; props . add ( RedisUtils . POOL_TEST_ON_CREATE ) ; props . add ( RedisUtils . POOL_TEST_ON_BORROW ) ; props . add ( RedisUtils . POOL_TEST_ON_RETURN ) ; props . add ( RedisUtils . POOL_TEST_WHILE_IDLE ) ; REDIS_CONNECTION_PROPERTY_DESCRIPTORS = Collections . unmodifiableList ( props ) ; } public static JedisConnectionFactory createConnectionFactory ( final PropertyContext context , final ComponentLog logger ) { final String redisMode = context . getProperty ( RedisUtils . REDIS_MODE ) . getValue ( ) ; final String connectionString = context . getProperty ( RedisUtils . CONNECTION_STRING ) . evaluateAttributeExpressions ( ) . getValue ( ) ; final Integer dbIndex = context . getProperty ( RedisUtils . DATABASE ) . evaluateAttributeExpressions ( ) . asInteger ( ) ; final String password = context . getProperty ( RedisUtils . PASSWORD ) . evaluateAttributeExpressions ( ) . getValue ( ) ; final Integer timeout = context . getProperty ( RedisUtils . COMMUNICATION_TIMEOUT ) . asTimePeriod ( TimeUnit . MILLISECONDS ) . intValue ( ) ; final JedisPoolConfig poolConfig = createJedisPoolConfig ( context ) ; final JedisClientConfiguration jedisClientConfiguration = JedisClientConfiguration . builder ( ) . connectTimeout ( Duration . ofMillis ( timeout ) ) . readTimeout ( Duration . ofMillis ( timeout ) ) . usePooling ( ) . poolConfig ( poolConfig ) . build ( ) ; JedisConnectionFactory connectionFactory ; if ( RedisUtils . REDIS_MODE_STANDALONE . getValue ( ) . equals ( redisMode ) ) { logger . info ( ""Connecting to Redis in standalone mode at "" + connectionString ) ; final String [ ] hostAndPortSplit = connectionString . split ( ""[:]"" ) ; final String host = hostAndPortSplit [ 0 ] . trim ( ) ; final Integer port = Integer . parseInt ( hostAndPortSplit [ 1 ] . trim ( ) ) ; final RedisStandaloneConfiguration redisStandaloneConfiguration = new RedisStandaloneConfiguration ( host , port ) ; enrichRedisConfiguration ( redisStandaloneConfiguration , dbIndex , password ) ; connectionFactory = new JedisConnectionFactory ( redisStandaloneConfiguration , jedisClientConfiguration ) ; } else if ( RedisUtils . REDIS_MODE_SENTINEL . getValue ( ) . equals ( redisMode ) ) { final String [ ] sentinels = connectionString . split ( ""[,]"" ) ; final String sentinelMaster = context . getProperty ( RedisUtils . SENTINEL_MASTER ) . evaluateAttributeExpressions ( ) . getValue ( ) ; final RedisSentinelConfiguration sentinelConfiguration = new RedisSentinelConfiguration ( sentinelMaster , new HashSet < > ( getTrimmedValues ( sentinels ) ) ) ; enrichRedisConfiguration ( sentinelConfiguration , dbIndex , password ) ; logger . info ( ""Connecting to Redis in sentinel mode..."" ) ; logger . info ( ""Redis master = "" + sentinelMaster ) ; for ( final String sentinel : sentinels ) { logger . info ( ""Redis sentinel at "" + sentinel ) ; } connectionFactory = new JedisConnectionFactory ( sentinelConfiguration , jedisClientConfiguration ) ; } else { final String [ ] clusterNodes = connectionString . split ( ""[,]"" ) ; final Integer maxRedirects = context . getProperty ( RedisUtils . CLUSTER_MAX_REDIRECTS ) . asInteger ( ) ; final RedisClusterConfiguration clusterConfiguration = new RedisClusterConfiguration ( getTrimmedValues ( clusterNodes ) ) ; enrichRedisConfiguration ( clusterConfiguration , dbIndex , password ) ; clusterConfiguration . setMaxRedirects ( maxRedirects ) ; logger . info ( ""Connecting to Redis in clustered mode..."" ) ; for ( final String clusterNode : clusterNodes ) { logger . info ( ""Redis cluster node at "" + clusterNode ) ; } connectionFactory = new JedisConnectionFactory ( clusterConfiguration , jedisClientConfiguration ) ; } connectionFactory . afterPropertiesSet ( ) ; return connectionFactory ; } private static List < String > getTrimmedValues ( final String [ ] values ) { final List < String > trimmedValues = new ArrayList < > ( ) ; for ( final String value : values ) { trimmedValues . add ( value . trim ( ) ) ; } return trimmedValues ; } private static void enrichRedisConfiguration ( final RedisConfiguration redisConfiguration , final Integer dbIndex , final String password ) { if ( redisConfiguration instanceof RedisConfiguration . WithDatabaseIndex ) { ( ( RedisConfiguration . WithDatabaseIndex ) redisConfiguration ) . setDatabase ( dbIndex ) ; } if ( redisConfiguration instanceof RedisConfiguration . WithPassword ) { ( ( RedisConfiguration . WithPassword ) redisConfiguration ) . setPassword ( RedisPassword . of ( password ) ) ; } } private static JedisPoolConfig createJedisPoolConfig ( final PropertyContext context ) { final JedisPoolConfig poolConfig = new JedisPoolConfig ( ) ; poolConfig . setMaxTotal ( context . getProperty ( RedisUtils . POOL_MAX_TOTAL ) . asInteger ( ) ) ; poolConfig . setMaxIdle ( context . getProperty ( RedisUtils . POOL_MAX_IDLE ) . asInteger ( ) ) ; poolConfig . setMinIdle ( context . getProperty ( RedisUtils . POOL_MIN_IDLE ) . asInteger ( ) ) ; poolConfig . setBlockWhenExhausted ( context . getProperty ( RedisUtils . POOL_BLOCK_WHEN_EXHAUSTED ) . asBoolean ( ) ) ; poolConfig . setMaxWaitMillis ( context . getProperty ( RedisUtils . POOL_MAX_WAIT_TIME ) . asTimePeriod ( TimeUnit . MILLISECONDS ) ) ; poolConfig . setMinEvictableIdleTimeMillis ( context . getProperty ( RedisUtils . POOL_MIN_EVICTABLE_IDLE_TIME ) . asTimePeriod ( TimeUnit . MILLISECONDS ) ) ; poolConfig . setTimeBetweenEvictionRunsMillis ( context . getProperty ( RedisUtils . POOL_TIME_BETWEEN_EVICTION_RUNS ) . asTimePeriod ( TimeUnit . MILLISECONDS ) ) ; poolConfig . setNumTestsPerEvictionRun ( context . getProperty ( RedisUtils . POOL_NUM_TESTS_PER_EVICTION_RUN ) . asInteger ( ) ) ; poolConfig . setTestOnCreate ( context . getProperty ( RedisUtils . POOL_TEST_ON_CREATE ) . asBoolean ( ) ) ; poolConfig . setTestOnBorrow ( context . getProperty ( RedisUtils . POOL_TEST_ON_BORROW ) . asBoolean ( ) ) ; poolConfig . setTestOnReturn ( context . getProperty ( RedisUtils . POOL_TEST_ON_RETURN ) . asBoolean ( ) ) ; poolConfig . setTestWhileIdle ( context . getProperty ( RedisUtils . POOL_TEST_WHILE_IDLE ) . asBoolean ( ) ) ; return poolConfig ; } public static List < ValidationResult > validate ( ValidationContext validationContext ) { final List < ValidationResult > results = new ArrayList < > ( ) ; final String redisMode = validationContext . getProperty ( RedisUtils . REDIS_MODE ) . getValue ( ) ; final String connectionString = validationContext . getProperty ( RedisUtils . CONNECTION_STRING ) . evaluateAttributeExpressions ( ) . getValue ( ) ; final Integer dbIndex = validationContext . getProperty ( RedisUtils . DATABASE ) . evaluateAttributeExpressions ( ) . asInteger ( ) ; if ( StringUtils . isBlank ( connectionString ) ) { results . add ( new ValidationResult . Builder ( ) . subject ( RedisUtils . CONNECTION_STRING . getDisplayName ( ) ) . valid ( false ) . explanation ( ""Connection String cannot be blank"" ) . build ( ) ) ; } else if ( RedisUtils . REDIS_MODE_STANDALONE . getValue ( ) . equals ( redisMode ) ) { final String [ ] hostAndPort = connectionString . split ( ""[:]"" ) ; if ( hostAndPort == null || hostAndPort . length != 2 || StringUtils . isBlank ( hostAndPort [ 0 ] ) || StringUtils . isBlank ( hostAndPort [ 1 ] ) || ! isInteger ( hostAndPort [ 1 ] ) ) { results . add ( new ValidationResult . Builder ( ) . subject ( RedisUtils . CONNECTION_STRING . getDisplayName ( ) ) . input ( connectionString ) . valid ( false ) . explanation ( ""Standalone Connection String must be in the form host:port"" ) . build ( ) ) ; } } else { for ( final String connection : connectionString . split ( ""[,]"" ) ) { final String [ ] hostAndPort = connection . split ( ""[:]"" ) ; if ( hostAndPort == null || hostAndPort . length != 2 || StringUtils . isBlank ( hostAndPort [ 0 ] ) || StringUtils . isBlank ( hostAndPort [ 1 ] ) || ! isInteger ( hostAndPort [ 1 ] ) ) { results . add ( new ValidationResult . Builder ( ) . subject ( RedisUtils . CONNECTION_STRING . getDisplayName ( ) ) . input ( connection ) . valid ( false ) . explanation ( ""Connection String must be in the form host:port,host:port,host:port,etc."" ) . build ( ) ) ; } } } if ( RedisUtils . REDIS_MODE_CLUSTER . getValue ( ) . equals ( redisMode ) && dbIndex > 0 ) { results . add ( new ValidationResult . Builder ( ) . subject ( RedisUtils . DATABASE . getDisplayName ( ) ) . valid ( false ) . explanation ( ""Database Index must be 0 when using clustered Redis"" ) . build ( ) ) ; } if ( RedisUtils . REDIS_MODE_SENTINEL . getValue ( ) . equals ( redisMode ) ) { final String sentinelMaster = validationContext . getProperty ( RedisUtils . SENTINEL_MASTER ) . evaluateAttributeExpressions ( ) . getValue ( ) ; if ( StringUtils . isEmpty ( sentinelMaster ) ) { results . add ( new ValidationResult . Builder ( ) . subject ( RedisUtils . SENTINEL_MASTER . getDisplayName ( ) ) . valid ( false ) . explanation ( ""Sentinel Master must be provided when Mode is Sentinel"" ) . build ( ) ) ; } } return results ; } private static boolean isInteger ( final String number ) { try { Integer . parseInt ( number ) ; return true ; } catch ( Exception e ) { return false ; } } }",No
"public class ControlCommandMarshaller extends BaseCommandMarshaller { public byte getDataStructureType ( ) { return ControlCommand . DATA_STRUCTURE_TYPE ; } public DataStructure createObject ( ) { return new ControlCommand ( ) ; } public void tightUnmarshal ( OpenWireFormat wireFormat , Object o , DataInput dataIn , BooleanStream bs ) throws IOException { super . tightUnmarshal ( wireFormat , o , dataIn , bs ) ; ControlCommand info = ( ControlCommand ) o ; info . setCommand ( tightUnmarshalString ( dataIn , bs ) ) ; } public int tightMarshal1 ( OpenWireFormat wireFormat , Object o , BooleanStream bs ) throws IOException { ControlCommand info = ( ControlCommand ) o ; int rc = super . tightMarshal1 ( wireFormat , o , bs ) ; rc += tightMarshalString1 ( info . getCommand ( ) , bs ) ; return rc + 0 ; } public void tightMarshal2 ( OpenWireFormat wireFormat , Object o , DataOutput dataOut , BooleanStream bs ) throws IOException { super . tightMarshal2 ( wireFormat , o , dataOut , bs ) ; ControlCommand info = ( ControlCommand ) o ; tightMarshalString2 ( info . getCommand ( ) , dataOut , bs ) ; } public void looseUnmarshal ( OpenWireFormat wireFormat , Object o , DataInput dataIn ) throws IOException { super . looseUnmarshal ( wireFormat , o , dataIn ) ; ControlCommand info = ( ControlCommand ) o ; info . setCommand ( looseUnmarshalString ( dataIn ) ) ; } public void looseMarshal ( OpenWireFormat wireFormat , Object o , DataOutput dataOut ) throws IOException { ControlCommand info = ( ControlCommand ) o ; super . looseMarshal ( wireFormat , o , dataOut ) ; looseMarshalString ( info . getCommand ( ) , dataOut ) ; } }",No
" static class MyOutputFormat implements OutputFormat { static class MyRecordWriter implements RecordWriter < Object , Object > { public MyRecordWriter ( Path outputFile , JobConf job ) throws IOException { } public void write ( Object key , Object value ) throws IOException { return ; } public void close ( Reporter reporter ) throws IOException { } } public RecordWriter getRecordWriter ( FileSystem ignored , JobConf job , String name , Progressable progress ) throws IOException { return new MyRecordWriter ( new Path ( job . get ( ""non.std.out"" ) ) , job ) ; } public void checkOutputSpecs ( FileSystem ignored , JobConf job ) throws IOException { } } ",No
" public class LocationFilterReader extends StreamReaderDelegate implements XMLStreamReader { boolean isImport ; boolean isInclude ; int locIdx = - 1 ; OASISCatalogManager catalog ; LocationFilterReader ( XMLStreamReader read , OASISCatalogManager catalog ) { super ( read ) ; this . catalog = catalog ; } public int next ( ) throws XMLStreamException { int i = super . next ( ) ; if ( i == XMLStreamReader . START_ELEMENT ) { QName qn = super . getName ( ) ; isInclude = qn . equals ( WSDLConstants . QNAME_SCHEMA_INCLUDE ) ; isImport = qn . equals ( WSDLConstants . QNAME_SCHEMA_IMPORT ) ; if ( isImport ) { findLocation ( ) ; } else { locIdx = - 1 ; } } else { isImport = false ; locIdx = - 1 ; } return i ; } public int nextTag ( ) throws XMLStreamException { int i = super . nextTag ( ) ; if ( i == XMLStreamReader . START_ELEMENT ) { QName qn = super . getName ( ) ; isInclude = qn . equals ( WSDLConstants . QNAME_SCHEMA_INCLUDE ) ; isImport = qn . equals ( WSDLConstants . QNAME_SCHEMA_IMPORT ) ; if ( isImport ) { findLocation ( ) ; } else { locIdx = - 1 ; } } else { isImport = false ; locIdx = - 1 ; } return i ; } private void findLocation ( ) { locIdx = - 1 ; for ( int x = super . getAttributeCount ( ) ; x > 0 ; -- x ) { String nm = super . getAttributeLocalName ( x - 1 ) ; if ( ""schemaLocation"" . equals ( nm ) ) { locIdx = x - 1 ; } } } public int getAttributeCount ( ) { int i = super . getAttributeCount ( ) ; if ( locIdx != - 1 ) { -- i ; } return i ; } private int mapIdx ( int index ) { if ( locIdx != - 1 && index >= locIdx ) { ++ index ; } return index ; } private String mapSchemaLocation ( String target ) { return DynamicClientFactory . mapSchemaLocation ( target , this . getLocation ( ) . getSystemId ( ) , catalog ) ; } public String getAttributeValue ( String namespaceURI , String localName ) { if ( isInclude && ""schemaLocation"" . equals ( localName ) ) { return mapSchemaLocation ( super . getAttributeValue ( namespaceURI , localName ) ) ; } return super . getAttributeValue ( namespaceURI , localName ) ; } public String getAttributeValue ( int index ) { if ( isInclude ) { String n = getAttributeLocalName ( index ) ; if ( ""schemaLocation"" . equals ( n ) ) { return mapSchemaLocation ( super . getAttributeValue ( index ) ) ; } } return super . getAttributeValue ( mapIdx ( index ) ) ; } public QName getAttributeName ( int index ) { return super . getAttributeName ( mapIdx ( index ) ) ; } public String getAttributePrefix ( int index ) { return super . getAttributePrefix ( mapIdx ( index ) ) ; } public String getAttributeNamespace ( int index ) { return super . getAttributeNamespace ( mapIdx ( index ) ) ; } public String getAttributeLocalName ( int index ) { return super . getAttributeLocalName ( mapIdx ( index ) ) ; } public String getAttributeType ( int index ) { return super . getAttributeType ( mapIdx ( index ) ) ; } public boolean isAttributeSpecified ( int index ) { return super . isAttributeSpecified ( mapIdx ( index ) ) ; } } ",Smelly
"public class DefaultCryptoCoverageChecker extends CryptoCoverageChecker { public static final String SOAP_NS = WSConstants . URI_SOAP11_ENV ; public static final String SOAP12_NS = WSConstants . URI_SOAP12_ENV ; public static final String WSU_NS = WSConstants . WSU_NS ; public static final String WSSE_NS = WSConstants . WSSE_NS ; public static final String WSA_NS = Names . WSA_NAMESPACE_NAME ; private boolean signBody ; private boolean signTimestamp ; private boolean encryptBody ; private boolean signAddressingHeaders ; public DefaultCryptoCoverageChecker ( ) { super ( null , null ) ; prefixMap . put ( ""soapenv"" , SOAP_NS ) ; prefixMap . put ( ""soapenv12"" , SOAP12_NS ) ; prefixMap . put ( ""wsu"" , WSU_NS ) ; prefixMap . put ( ""wsse"" , WSSE_NS ) ; prefixMap . put ( ""wsa"" , WSA_NS ) ; setSignBody ( true ) ; setSignTimestamp ( true ) ; setSignAddressingHeaders ( true ) ; } public boolean isSignBody ( ) { return signBody ; } public final void setSignBody ( boolean signBody ) { this . signBody = signBody ; XPathExpression soap11Expression = new XPathExpression ( ""/soapenv:Envelope/soapenv:Body"" , CoverageType . SIGNED ) ; XPathExpression soap12Expression = new XPathExpression ( ""/soapenv12:Envelope/soapenv12:Body"" , CoverageType . SIGNED ) ; if ( signBody ) { if ( ! xPaths . contains ( soap11Expression ) ) { xPaths . add ( soap11Expression ) ; } if ( ! xPaths . contains ( soap12Expression ) ) { xPaths . add ( soap12Expression ) ; } } else { if ( xPaths . contains ( soap11Expression ) ) { xPaths . remove ( soap11Expression ) ; } if ( xPaths . contains ( soap12Expression ) ) { xPaths . remove ( soap12Expression ) ; } } } public boolean isSignTimestamp ( ) { return signTimestamp ; } public final void setSignTimestamp ( boolean signTimestamp ) { this . signTimestamp = signTimestamp ; XPathExpression soap11Expression = new XPathExpression ( ""/soapenv:Envelope/soapenv:Header/wsse:Security/wsu:Timestamp"" , CoverageType . SIGNED ) ; XPathExpression soap12Expression = new XPathExpression ( ""/soapenv12:Envelope/soapenv12:Header/wsse:Security/wsu:Timestamp"" , CoverageType . SIGNED ) ; if ( signTimestamp ) { if ( ! xPaths . contains ( soap11Expression ) ) { xPaths . add ( soap11Expression ) ; } if ( ! xPaths . contains ( soap12Expression ) ) { xPaths . add ( soap12Expression ) ; } } else { if ( xPaths . contains ( soap11Expression ) ) { xPaths . remove ( soap11Expression ) ; } if ( xPaths . contains ( soap12Expression ) ) { xPaths . remove ( soap12Expression ) ; } } } public boolean isEncryptBody ( ) { return encryptBody ; } public final void setEncryptBody ( boolean encryptBody ) { this . encryptBody = encryptBody ; XPathExpression soap11Expression = new XPathExpression ( ""/soapenv:Envelope/soapenv:Body"" , CoverageType . ENCRYPTED , CoverageScope . CONTENT ) ; XPathExpression soap12Expression = new XPathExpression ( ""/soapenv12:Envelope/soapenv12:Body"" , CoverageType . ENCRYPTED , CoverageScope . CONTENT ) ; if ( encryptBody ) { if ( ! xPaths . contains ( soap11Expression ) ) { xPaths . add ( soap11Expression ) ; } if ( ! xPaths . contains ( soap12Expression ) ) { xPaths . add ( soap12Expression ) ; } } else { if ( xPaths . contains ( soap11Expression ) ) { xPaths . remove ( soap11Expression ) ; } if ( xPaths . contains ( soap12Expression ) ) { xPaths . remove ( soap12Expression ) ; } } } public boolean isSignAddressingHeaders ( ) { return signAddressingHeaders ; } public final void setSignAddressingHeaders ( boolean signAddressingHeaders ) { this . signAddressingHeaders = signAddressingHeaders ; XPathExpression soap11Expression = new XPathExpression ( ""/soapenv:Envelope/soapenv:Header/wsa:ReplyTo"" , CoverageType . SIGNED ) ; XPathExpression soap11Expression2 = new XPathExpression ( ""/soapenv:Envelope/soapenv:Header/wsa:FaultTo"" , CoverageType . SIGNED ) ; XPathExpression soap12Expression = new XPathExpression ( ""/soapenv12:Envelope/soapenv12:Header/wsa:ReplyTo"" , CoverageType . SIGNED ) ; XPathExpression soap12Expression2 = new XPathExpression ( ""/soapenv12:Envelope/soapenv12:Header/wsa:FaultTo"" , CoverageType . SIGNED ) ; if ( signAddressingHeaders ) { if ( ! xPaths . contains ( soap11Expression ) ) { xPaths . add ( soap11Expression ) ; } if ( ! xPaths . contains ( soap11Expression2 ) ) { xPaths . add ( soap11Expression2 ) ; } if ( ! xPaths . contains ( soap12Expression ) ) { xPaths . add ( soap12Expression ) ; } if ( ! xPaths . contains ( soap12Expression2 ) ) { xPaths . add ( soap12Expression2 ) ; } } else { if ( xPaths . contains ( soap11Expression ) ) { xPaths . remove ( soap11Expression ) ; } if ( xPaths . contains ( soap11Expression2 ) ) { xPaths . remove ( soap11Expression2 ) ; } if ( xPaths . contains ( soap12Expression ) ) { xPaths . remove ( soap12Expression ) ; } if ( xPaths . contains ( soap12Expression2 ) ) { xPaths . remove ( soap12Expression2 ) ; } } } }",No
"@ SuppressWarnings ( ""serial"" ) @ JsonAutoDetect ( fieldVisibility = JsonAutoDetect . Visibility . NONE , getterVisibility = JsonAutoDetect . Visibility . NONE , isGetterVisibility = JsonAutoDetect . Visibility . NONE , setterVisibility = JsonAutoDetect . Visibility . NONE ) public class HybridInstance extends RootPersistentEntity implements IRealization { private final static Logger logger = LoggerFactory . getLogger ( HybridInstance . class ) ; public static HybridInstance create ( KylinConfig config , String name , List < RealizationEntry > realizationEntries ) { HybridInstance hybridInstance = new HybridInstance ( ) ; hybridInstance . setConfig ( config ) ; hybridInstance . setName ( name ) ; hybridInstance . setRealizationEntries ( realizationEntries ) ; hybridInstance . updateRandomUuid ( ) ; return hybridInstance ; } @ JsonIgnore private KylinConfig config ; @ JsonProperty ( ""name"" ) private String name ; @ JsonProperty ( ""realizations"" ) private List < RealizationEntry > realizationEntries ; @ JsonProperty ( ""cost"" ) private int cost = 50 ; private volatile IRealization [ ] realizations = null ; private List < TblColRef > allDimensions = null ; private Set < TblColRef > allColumns = null ; private Set < ColumnDesc > allColumnDescs = null ; private List < MeasureDesc > allMeasures = null ; private long dateRangeStart ; private long dateRangeEnd ; private boolean isReady = false ; @ Override public String resourceName ( ) { return name ; } public List < RealizationEntry > getRealizationEntries ( ) { return realizationEntries ; } public void setRealizationEntries ( List < RealizationEntry > realizationEntries ) { this . realizationEntries = realizationEntries ; } private void init ( ) { if ( realizations != null ) return ; synchronized ( this ) { if ( realizations != null ) return ; if ( realizationEntries == null || realizationEntries . size ( ) == 0 ) throw new IllegalArgumentException ( ) ; RealizationRegistry registry = RealizationRegistry . getInstance ( config ) ; List < IRealization > realizationList = Lists . newArrayList ( ) ; for ( int i = 0 ; i < realizationEntries . size ( ) ; i ++ ) { IRealization realization = registry . getRealization ( realizationEntries . get ( i ) . getType ( ) , realizationEntries . get ( i ) . getRealization ( ) ) ; if ( realization == null ) { logger . error ( ""Realization '"" + realizationEntries . get ( i ) + "" is not found, remove from Hybrid '"" + this . getName ( ) + ""'"" ) ; continue ; } if ( realization . isReady ( ) == false ) { logger . error ( ""Realization '"" + realization . getName ( ) + "" is disabled, remove from Hybrid '"" + this . getName ( ) + ""'"" ) ; continue ; } realizationList . add ( realization ) ; } LinkedHashSet < TblColRef > columns = new LinkedHashSet < TblColRef > ( ) ; LinkedHashSet < TblColRef > dimensions = new LinkedHashSet < TblColRef > ( ) ; LinkedHashSet < MeasureDesc > measures = new LinkedHashSet < MeasureDesc > ( ) ; dateRangeStart = 0 ; dateRangeEnd = Long . MAX_VALUE ; for ( IRealization realization : realizationList ) { columns . addAll ( realization . getAllColumns ( ) ) ; dimensions . addAll ( realization . getAllDimensions ( ) ) ; measures . addAll ( realization . getMeasures ( ) ) ; if ( realization . isReady ( ) ) isReady = true ; if ( dateRangeStart == 0 || realization . getDateRangeStart ( ) < dateRangeStart ) dateRangeStart = realization . getDateRangeStart ( ) ; if ( dateRangeStart == Long . MAX_VALUE || realization . getDateRangeEnd ( ) > dateRangeEnd ) dateRangeEnd = realization . getDateRangeEnd ( ) ; } allDimensions = Lists . newArrayList ( dimensions ) ; allColumns = columns ; allColumnDescs = asColumnDescs ( allColumns ) ; allMeasures = Lists . newArrayList ( measures ) ; Collections . sort ( realizationList , new Comparator < IRealization > ( ) { @ Override public int compare ( IRealization o1 , IRealization o2 ) { long i1 = o1 . getDateRangeStart ( ) ; long i2 = o2 . getDateRangeStart ( ) ; long comp = i1 - i2 ; if ( comp != 0 ) { return comp > 0 ? 1 : - 1 ; } i1 = o1 . getDateRangeEnd ( ) ; i2 = o2 . getDateRangeEnd ( ) ; comp = i1 - i2 ; if ( comp != 0 ) { return comp > 0 ? 1 : - 1 ; } return 0 ; } } ) ; this . realizations = realizationList . toArray ( new IRealization [ realizationList . size ( ) ] ) ; } } private Set < ColumnDesc > asColumnDescs ( Set < TblColRef > columns ) { LinkedHashSet < ColumnDesc > result = new LinkedHashSet < > ( ) ; for ( TblColRef col : columns ) { result . add ( col . getColumnDesc ( ) ) ; } return result ; } @ Override public CapabilityResult isCapable ( SQLDigest digest ) { CapabilityResult result = new CapabilityResult ( ) ; result . cost = Integer . MAX_VALUE ; for ( IRealization realization : getRealizations ( ) ) { CapabilityResult child = realization . isCapable ( digest ) ; if ( child . capable ) { result . capable = true ; result . cost = Math . min ( result . cost , child . cost ) ; result . influences . addAll ( child . influences ) ; } else { result . incapableCause = child . incapableCause ; } } if ( result . cost > 0 ) result . cost -- ; return result ; } @ Override public int getCost ( ) { int c = Integer . MAX_VALUE ; for ( IRealization realization : getRealizations ( ) ) { c = Math . min ( realization . getCost ( ) , c ) ; } return c ; } @ Override public RealizationType getType ( ) { return RealizationType . HYBRID ; } @ Override public DataModelDesc getModel ( ) { if ( this . getLatestRealization ( ) != null ) return this . getLatestRealization ( ) . getModel ( ) ; return null ; } @ Override public Set < TblColRef > getAllColumns ( ) { init ( ) ; return allColumns ; } @ Override public Set < ColumnDesc > getAllColumnDescs ( ) { init ( ) ; return allColumnDescs ; } @ Override public List < MeasureDesc > getMeasures ( ) { init ( ) ; return allMeasures ; } @ Override public boolean isReady ( ) { return isReady ; } @ Override public String getName ( ) { return name ; } public void setName ( String name ) { this . name = name ; } @ Override public String toString ( ) { return getCanonicalName ( ) ; } @ Override public String getCanonicalName ( ) { return getType ( ) + ""[name="" + name + ""]"" ; } @ Override public KylinConfig getConfig ( ) { return config ; } public void setConfig ( KylinConfig config ) { this . config = config ; } @ Override public long getDateRangeStart ( ) { return dateRangeStart ; } @ Override public long getDateRangeEnd ( ) { return dateRangeEnd ; } @ Override public boolean supportsLimitPushDown ( ) { return false ; } @ Override public List < TblColRef > getAllDimensions ( ) { init ( ) ; return allDimensions ; } public IRealization [ ] getRealizations ( ) { init ( ) ; return realizations ; } public String getResourcePath ( ) { return concatResourcePath ( name ) ; } public static String concatResourcePath ( String hybridName ) { return ResourceStore . HYBRID_RESOURCE_ROOT + ""/"" + hybridName + "".json"" ; } public void setCost ( int cost ) { this . cost = cost ; } public IRealization getLatestRealization ( ) { if ( getRealizations ( ) . length > 0 ) { return realizations [ realizations . length - 1 ] ; } return null ; } @ Override public int getStorageType ( ) { return ID_HYBRID ; } }",Smelly
"public abstract class StructObjectInspector implements ObjectInspector { public abstract List < ? extends StructField > getAllStructFieldRefs ( ) ; public abstract StructField getStructFieldRef ( String fieldName ) ; public abstract Object getStructFieldData ( Object data , StructField fieldRef ) ; public abstract List < Object > getStructFieldsDataAsList ( Object data ) ; public boolean isSettable ( ) { return false ; } @ Override public String toString ( ) { StringBuilder sb = new StringBuilder ( ) ; List < ? extends StructField > fields = getAllStructFieldRefs ( ) ; sb . append ( getClass ( ) . getName ( ) ) ; sb . append ( ""<"" ) ; for ( int i = 0 ; i < fields . size ( ) ; i ++ ) { if ( i > 0 ) { sb . append ( "","" ) ; } sb . append ( fields . get ( i ) . getFieldObjectInspector ( ) . toString ( ) ) ; } sb . append ( "">"" ) ; return sb . toString ( ) ; } }",No
 private class MyCommitPoint extends IndexCommit { IndexCommit cp ; MyCommitPoint ( IndexCommit cp ) { this . cp = cp ; } public String getSegmentsFileName ( ) { return cp . getSegmentsFileName ( ) ; } public Collection getFileNames ( ) throws IOException { return cp . getFileNames ( ) ; } public Directory getDirectory ( ) { return cp . getDirectory ( ) ; } public void delete ( ) { synchronized ( SnapshotDeletionPolicy . this ) { if ( snapshot == null || ! snapshot . equals ( getSegmentsFileName ( ) ) ) cp . delete ( ) ; } } public boolean isDeleted ( ) { return cp . isDeleted ( ) ; } public long getVersion ( ) { return cp . getVersion ( ) ; } public long getGeneration ( ) { return cp . getGeneration ( ) ; } ,Smelly
"public class Proxy { public static final String PROXY_SOCKS5 = ""SOCKS_5"" ; public static final String PROXY_SOCKS4 = ""SOCKS4"" ; public static final String PROXY_HTTP = ""HTTP"" ; private String host ; private String userName ; private String password ; private int port ; private String protocol ; private String nonProxyHosts ; private String ntlmHost ; private String ntlmDomain ; public String getHost ( ) { return host ; } public void setHost ( String host ) { this . host = host ; } public String getPassword ( ) { return password ; } public void setPassword ( String password ) { this . password = password ; } public int getPort ( ) { return port ; } public void setPort ( int port ) { this . port = port ; } public String getUserName ( ) { return userName ; } public void setUserName ( String userName ) { this . userName = userName ; } public String getProtocol ( ) { return protocol ; } public void setProtocol ( String protocol ) { this . protocol = protocol ; } public String getNonProxyHosts ( ) { return nonProxyHosts ; } public void setNonProxyHosts ( String nonProxyHosts ) { this . nonProxyHosts = nonProxyHosts ; } public String getNtlmHost ( ) { return ntlmHost ; } public void setNtlmHost ( String ntlmHost ) { this . ntlmHost = ntlmHost ; } public void setNtlmDomain ( String ntlmDomain ) { this . ntlmDomain = ntlmDomain ; } public String getNtlmDomain ( ) { return ntlmDomain ; } }",Smelly
"public final class ByteKeyRangeTracker implements RangeTracker < ByteKey > { private static final Logger LOG = LoggerFactory . getLogger ( ByteKeyRangeTracker . class ) ; public static ByteKeyRangeTracker of ( ByteKeyRange range ) { return new ByteKeyRangeTracker ( range ) ; } public synchronized boolean isDone ( ) { return done ; } @ Override public synchronized ByteKey getStartPosition ( ) { return range . getStartKey ( ) ; } @ Override public synchronized ByteKey getStopPosition ( ) { return range . getEndKey ( ) ; } public synchronized ByteKeyRange getRange ( ) { return range ; } @ Override public synchronized boolean tryReturnRecordAt ( boolean isAtSplitPoint , ByteKey recordStart ) { if ( done ) { return false ; } checkState ( ! ( position == null && ! isAtSplitPoint ) , ""The first record must be at a split point"" ) ; checkState ( ! ( recordStart . compareTo ( range . getStartKey ( ) ) < 0 ) , ""Trying to return record which is before the start key"" ) ; checkState ( ! ( position != null && recordStart . compareTo ( position ) < 0 ) , ""Trying to return record which is before the last-returned record"" ) ; if ( position == null ) { LOG . info ( ""Adjusting range start from {} to {} as position of first returned record"" , range . getStartKey ( ) , recordStart ) ; range = range . withStartKey ( recordStart ) ; } position = recordStart ; if ( isAtSplitPoint ) { if ( ! range . containsKey ( recordStart ) ) { done = true ; return false ; } ++ splitPointsSeen ; } return true ; } @ Override public synchronized boolean trySplitAtPosition ( ByteKey splitPosition ) { if ( ! range . containsKey ( splitPosition ) ) { LOG . warn ( ""{}: Rejecting split request at {} because it is not within the range."" , this , splitPosition ) ; return false ; } if ( position == null ) { LOG . warn ( ""{}: Rejecting split request at {} because no records have been returned."" , this , splitPosition ) ; return false ; } if ( splitPosition . compareTo ( position ) <= 0 ) { LOG . warn ( ""{}: Rejecting split request at {} because it is not after current position {}."" , this , splitPosition , position ) ; return false ; } range = range . withEndKey ( splitPosition ) ; return true ; } @ Override public synchronized double getFractionConsumed ( ) { if ( position == null ) { return 0 ; } else if ( done ) { return 1.0 ; } else if ( position . compareTo ( range . getEndKey ( ) ) >= 0 ) { return 1.0 ; } return range . estimateFractionForKey ( position ) ; } public synchronized long getSplitPointsConsumed ( ) { if ( position == null ) { return 0 ; } else if ( isDone ( ) ) { return splitPointsSeen ; } else { checkState ( splitPointsSeen > 0 , ""A started rangeTracker should have seen > 0 split points (is %s)"" , splitPointsSeen ) ; return splitPointsSeen - 1 ; } } private ByteKeyRange range ; @ Nullable private ByteKey position ; private long splitPointsSeen ; private boolean done ; private ByteKeyRangeTracker ( ByteKeyRange range ) { this . range = range ; position = null ; splitPointsSeen = 0L ; done = false ; } public synchronized boolean markDone ( ) { done = true ; return false ; } @ Override public synchronized String toString ( ) { return toStringHelper ( ByteKeyRangeTracker . class ) . add ( ""range"" , range ) . add ( ""position"" , position ) . toString ( ) ; } }",No
"public class MavenSession implements Cloneable { private MavenExecutionRequest request ; private MavenExecutionResult result ; private RepositorySystemSession repositorySession ; private Properties executionProperties ; private MavenProject currentProject ; private List < MavenProject > projects ; private List < MavenProject > allProjects ; private MavenProject topLevelProject ; private ProjectDependencyGraph projectDependencyGraph ; private boolean parallel ; private final Map < String , Map < String , Map < String , Object > > > pluginContextsByProjectAndPluginKey = new ConcurrentHashMap < > ( ) ; public void setProjects ( List < MavenProject > projects ) { if ( ! projects . isEmpty ( ) ) { this . currentProject = projects . get ( 0 ) ; this . topLevelProject = currentProject ; for ( MavenProject project : projects ) { if ( project . isExecutionRoot ( ) ) { topLevelProject = project ; break ; } } } else { this . currentProject = null ; this . topLevelProject = null ; } this . projects = projects ; } public ArtifactRepository getLocalRepository ( ) { return request . getLocalRepository ( ) ; } public List < String > getGoals ( ) { return request . getGoals ( ) ; } public Properties getUserProperties ( ) { return request . getUserProperties ( ) ; } public Properties getSystemProperties ( ) { return request . getSystemProperties ( ) ; } public Settings getSettings ( ) { return settings ; } public List < MavenProject > getProjects ( ) { return projects ; } public String getExecutionRootDirectory ( ) { return request . getBaseDirectory ( ) ; } public MavenExecutionRequest getRequest ( ) { return request ; } public void setCurrentProject ( MavenProject currentProject ) { this . currentProject = currentProject ; } public MavenProject getCurrentProject ( ) { return currentProject ; } public ProjectBuildingRequest getProjectBuildingRequest ( ) { return request . getProjectBuildingRequest ( ) . setRepositorySession ( getRepositorySession ( ) ) ; } public List < String > getPluginGroups ( ) { return request . getPluginGroups ( ) ; } public boolean isOffline ( ) { return request . isOffline ( ) ; } public MavenProject getTopLevelProject ( ) { return topLevelProject ; } public MavenExecutionResult getResult ( ) { return result ; } public Map < String , Object > getPluginContext ( PluginDescriptor plugin , MavenProject project ) { String projectKey = project . getId ( ) ; Map < String , Map < String , Object > > pluginContextsByKey = pluginContextsByProjectAndPluginKey . get ( projectKey ) ; if ( pluginContextsByKey == null ) { pluginContextsByKey = new ConcurrentHashMap < > ( ) ; pluginContextsByProjectAndPluginKey . put ( projectKey , pluginContextsByKey ) ; } String pluginKey = plugin . getPluginLookupKey ( ) ; Map < String , Object > pluginContext = pluginContextsByKey . get ( pluginKey ) ; if ( pluginContext == null ) { pluginContext = new ConcurrentHashMap < > ( ) ; pluginContextsByKey . put ( pluginKey , pluginContext ) ; } return pluginContext ; } public ProjectDependencyGraph getProjectDependencyGraph ( ) { return projectDependencyGraph ; } public void setProjectDependencyGraph ( ProjectDependencyGraph projectDependencyGraph ) { this . projectDependencyGraph = projectDependencyGraph ; } public String getReactorFailureBehavior ( ) { return request . getReactorFailureBehavior ( ) ; } @ Override public MavenSession clone ( ) { try { return ( MavenSession ) super . clone ( ) ; } catch ( CloneNotSupportedException e ) { throw new RuntimeException ( ""Bug"" , e ) ; } } public Date getStartTime ( ) { return request . getStartTime ( ) ; } public boolean isParallel ( ) { return parallel ; } public void setParallel ( boolean parallel ) { this . parallel = parallel ; } public RepositorySystemSession getRepositorySession ( ) { return repositorySession ; } private Map < String , MavenProject > projectMap ; public void setProjectMap ( Map < String , MavenProject > projectMap ) { this . projectMap = projectMap ; } public List < MavenProject > getAllProjects ( ) { return allProjects ; } public void setAllProjects ( List < MavenProject > allProjects ) { this . allProjects = allProjects ; } private PlexusContainer container ; private final Settings settings ; @ Deprecated public Map < String , MavenProject > getProjectMap ( ) { return projectMap ; } @ Deprecated public MavenSession ( PlexusContainer container , RepositorySystemSession repositorySession , MavenExecutionRequest request , MavenExecutionResult result ) { this . container = container ; this . request = request ; this . result = result ; this . settings = new SettingsAdapter ( request ) ; this . repositorySession = repositorySession ; } @ Deprecated public MavenSession ( PlexusContainer container , MavenExecutionRequest request , MavenExecutionResult result , MavenProject project ) { this ( container , request , result , Arrays . asList ( new MavenProject [ ] { project } ) ) ; } @ Deprecated public MavenSession ( PlexusContainer container , Settings settings , ArtifactRepository localRepository , EventDispatcher eventDispatcher , ReactorManager unused , List < String > goals , String executionRootDir , Properties executionProperties , Date startTime ) { this ( container , settings , localRepository , eventDispatcher , unused , goals , executionRootDir , executionProperties , null , startTime ) ; } @ Deprecated public MavenSession ( PlexusContainer container , Settings settings , ArtifactRepository localRepository , EventDispatcher eventDispatcher , ReactorManager unused , List < String > goals , String executionRootDir , Properties executionProperties , Properties userProperties , Date startTime ) { this . container = container ; this . settings = settings ; this . executionProperties = executionProperties ; this . request = new DefaultMavenExecutionRequest ( ) ; this . request . setUserProperties ( userProperties ) ; this . request . setLocalRepository ( localRepository ) ; this . request . setGoals ( goals ) ; this . request . setBaseDirectory ( ( executionRootDir != null ) ? new File ( executionRootDir ) : null ) ; this . request . setStartTime ( startTime ) ; } @ Deprecated public MavenSession ( PlexusContainer container , MavenExecutionRequest request , MavenExecutionResult result , List < MavenProject > projects ) { this . container = container ; this . request = request ; this . result = result ; this . settings = new SettingsAdapter ( request ) ; setProjects ( projects ) ; } @ Deprecated public List < MavenProject > getSortedProjects ( ) { return getProjects ( ) ; } @ Deprecated public RepositoryCache getRepositoryCache ( ) { return null ; } @ Deprecated public EventDispatcher getEventDispatcher ( ) { return null ; } @ Deprecated public boolean isUsingPOMsFromFilesystem ( ) { return request . isProjectPresent ( ) ; } @ Deprecated public Properties getExecutionProperties ( ) { if ( executionProperties == null ) { executionProperties = new Properties ( ) ; executionProperties . putAll ( request . getSystemProperties ( ) ) ; executionProperties . putAll ( request . getUserProperties ( ) ) ; } return executionProperties ; } @ Deprecated public PlexusContainer getContainer ( ) { return container ; } @ Deprecated public Object lookup ( String role ) throws ComponentLookupException { return container . lookup ( role ) ; } @ Deprecated public Object lookup ( String role , String roleHint ) throws ComponentLookupException { return container . lookup ( role , roleHint ) ; } @ Deprecated public List < Object > lookupList ( String role ) throws ComponentLookupException { return container . lookupList ( role ) ; } @ Deprecated public Map < String , Object > lookupMap ( String role ) throws ComponentLookupException { return container . lookupMap ( role ) ; } }",Smelly
"@ SuppressWarnings ( ""serial"" ) public class Sequence extends ReferenceCounter implements Comparable < Sequence > , SourceTracker { private DBIdentifier _name = DBIdentifier . NULL ; private Schema _schema = null ; private DBIdentifier _schemaName = DBIdentifier . NULL ; private int _initial = 1 ; private int _increment = 1 ; private int _cache = 0 ; private int _lineNum = 0 ; private int _colNum = 0 ; private QualifiedDBIdentifier _fullPath = null ; private File _source = null ; private int _srcType = SRC_OTHER ; public Sequence ( ) { } public Sequence ( String name , Schema schema ) { this ( DBIdentifier . newSequence ( name ) , schema ) ; } public Sequence ( DBIdentifier name , Schema schema ) { setIdentifier ( name ) ; if ( schema != null ) setSchemaIdentifier ( schema . getIdentifier ( ) ) ; _schema = schema ; } void remove ( ) { _schema = null ; _fullPath = null ; } public Schema getSchema ( ) { return _schema ; } public String getSchemaName ( ) { return getSchemaIdentifier ( ) . getName ( ) ; } public DBIdentifier getSchemaIdentifier ( ) { return _schemaName == null ? DBIdentifier . NULL : _schemaName ; } public void setSchemaName ( String name ) { setSchemaIdentifier ( DBIdentifier . newSchema ( name ) ) ; } public void setSchemaIdentifier ( DBIdentifier name ) { if ( getSchema ( ) != null ) throw new IllegalStateException ( ) ; _schemaName = name ; _fullPath = null ; } public String getName ( ) { return getIdentifier ( ) . getName ( ) ; } public DBIdentifier getIdentifier ( ) { return _name == null ? DBIdentifier . NULL : _name ; } public void setName ( String name ) { setIdentifier ( DBIdentifier . newSequence ( name ) ) ; } public void setIdentifier ( DBIdentifier name ) { if ( getSchema ( ) != null ) throw new IllegalStateException ( ) ; _name = name ; _fullPath = null ; } public String getFullName ( ) { return getFullIdentifier ( ) . getName ( ) ; } public DBIdentifier getFullIdentifier ( ) { return getQualifiedPath ( ) . getIdentifier ( ) ; } public QualifiedDBIdentifier getQualifiedPath ( ) { if ( _fullPath == null ) { _fullPath = QualifiedDBIdentifier . newPath ( _schemaName , _name ) ; } return _fullPath ; } public int getInitialValue ( ) { return _initial ; } public void setInitialValue ( int initial ) { _initial = initial ; } public int getIncrement ( ) { return _increment ; } public void setIncrement ( int increment ) { _increment = increment ; } public int getAllocate ( ) { return _cache ; } public void setAllocate ( int cache ) { _cache = cache ; } public File getSourceFile ( ) { return _source ; } public Object getSourceScope ( ) { return null ; } public int getSourceType ( ) { return _srcType ; } public void setSource ( File source , int srcType ) { _source = source ; _srcType = srcType ; } public String getResourceName ( ) { return getFullIdentifier ( ) . getName ( ) ; } public int compareTo ( Sequence other ) { DBIdentifier name = getIdentifier ( ) ; DBIdentifier otherName = other . getIdentifier ( ) ; if ( DBIdentifier . isNull ( name ) && DBIdentifier . isNull ( otherName ) ) { return 0 ; } if ( DBIdentifier . isNull ( name ) ) return 1 ; if ( DBIdentifier . isNull ( otherName ) ) return - 1 ; return name . compareTo ( otherName ) ; } public String toString ( ) { return getFullIdentifier ( ) . getName ( ) ; } public int getLineNumber ( ) { return _lineNum ; } public void setLineNumber ( int lineNum ) { _lineNum = lineNum ; } public int getColNumber ( ) { return _colNum ; } public void setColNumber ( int colNum ) { _colNum = colNum ; } }",Smelly
"public class ColumnFileReader implements Closeable { private Input file ; private long rowCount ; private int columnCount ; private ColumnFileMetaData metaData ; private ColumnDescriptor [ ] columns ; private Map < String , ColumnDescriptor > columnsByName ; public ColumnFileReader ( File file ) throws IOException { this ( new InputFile ( file ) ) ; } public ColumnFileReader ( Input file ) throws IOException { this . file = file ; readHeader ( ) ; } public long getRowCount ( ) { return rowCount ; } public long getColumnCount ( ) { return columnCount ; } public ColumnFileMetaData getMetaData ( ) { return metaData ; } public ColumnMetaData [ ] getColumnMetaData ( ) { ColumnMetaData [ ] result = new ColumnMetaData [ columnCount ] ; for ( int i = 0 ; i < columnCount ; i ++ ) result [ i ] = columns [ i ] . metaData ; return result ; } public List < ColumnMetaData > getRoots ( ) { List < ColumnMetaData > result = new ArrayList < > ( ) ; for ( int i = 0 ; i < columnCount ; i ++ ) if ( columns [ i ] . metaData . getParent ( ) == null ) result . add ( columns [ i ] . metaData ) ; return result ; } public ColumnMetaData getColumnMetaData ( int number ) { return columns [ number ] . metaData ; } public ColumnMetaData getColumnMetaData ( String name ) { return getColumn ( name ) . metaData ; } private < T extends Comparable > ColumnDescriptor < T > getColumn ( String name ) { ColumnDescriptor column = columnsByName . get ( name ) ; if ( column == null ) throw new TrevniRuntimeException ( ""No column named: "" + name ) ; return ( ColumnDescriptor < T > ) column ; } private void readHeader ( ) throws IOException { InputBuffer in = new InputBuffer ( file , 0 ) ; readMagic ( in ) ; this . rowCount = in . readFixed64 ( ) ; this . columnCount = in . readFixed32 ( ) ; this . metaData = ColumnFileMetaData . read ( in ) ; this . columnsByName = new HashMap < > ( columnCount ) ; columns = new ColumnDescriptor [ columnCount ] ; readColumnMetaData ( in ) ; readColumnStarts ( in ) ; } private void readMagic ( InputBuffer in ) throws IOException { byte [ ] magic = new byte [ ColumnFileWriter . MAGIC . length ] ; try { in . readFully ( magic ) ; } catch ( IOException e ) { throw new IOException ( ""Not a data file."" ) ; } if ( ! ( Arrays . equals ( ColumnFileWriter . MAGIC , magic ) || ! Arrays . equals ( ColumnFileWriter . MAGIC_1 , magic ) || ! Arrays . equals ( ColumnFileWriter . MAGIC_0 , magic ) ) ) throw new IOException ( ""Not a data file."" ) ; } private void readColumnMetaData ( InputBuffer in ) throws IOException { for ( int i = 0 ; i < columnCount ; i ++ ) { ColumnMetaData meta = ColumnMetaData . read ( in , this ) ; meta . setDefaults ( this . metaData ) ; ColumnDescriptor column = new ColumnDescriptor ( file , meta ) ; columns [ i ] = column ; meta . setNumber ( i ) ; columnsByName . put ( meta . getName ( ) , column ) ; } } private void readColumnStarts ( InputBuffer in ) throws IOException { for ( int i = 0 ; i < columnCount ; i ++ ) columns [ i ] . start = in . readFixed64 ( ) ; } public < T extends Comparable > ColumnValues < T > getValues ( String columnName ) throws IOException { return new ColumnValues < > ( getColumn ( columnName ) ) ; } public < T extends Comparable > ColumnValues < T > getValues ( int column ) throws IOException { return new ColumnValues < > ( columns [ column ] ) ; } @ Override public void close ( ) throws IOException { file . close ( ) ; } }",Smelly
" protected class Endpoint { public final String className ; public final String methodName ; public final String path ; public final String httpMethod ; public final List < String > produces ; protected Endpoint ( Class < ? > endpoint , Method method , String path , String httpMethod , String [ ] produces ) { this . className = endpoint . getCanonicalName ( ) ; this . methodName = method . getName ( ) ; this . path = path ; this . httpMethod = httpMethod ; this . produces = Collections . unmodifiableList ( Arrays . asList ( produces ) ) ; } } ",Smelly
"public abstract class AbstractAttributedInterceptorProvider extends HashMap < String , Object > implements InterceptorProvider { private static final long serialVersionUID = - 1915876045710441978L ; private List < Interceptor < ? extends Message > > in = new ModCountCopyOnWriteArrayList < Interceptor < ? extends Message > > ( ) ; private List < Interceptor < ? extends Message > > out = new ModCountCopyOnWriteArrayList < Interceptor < ? extends Message > > ( ) ; private List < Interceptor < ? extends Message > > outFault = new ModCountCopyOnWriteArrayList < Interceptor < ? extends Message > > ( ) ; private List < Interceptor < ? extends Message > > inFault = new ModCountCopyOnWriteArrayList < Interceptor < ? extends Message > > ( ) ; public List < Interceptor < ? extends Message > > getOutFaultInterceptors ( ) { return outFault ; } public List < Interceptor < ? extends Message > > getInFaultInterceptors ( ) { return inFault ; } public List < Interceptor < ? extends Message > > getInInterceptors ( ) { return in ; } public List < Interceptor < ? extends Message > > getOutInterceptors ( ) { return out ; } public void setInInterceptors ( List < Interceptor < ? extends Message > > interceptors ) { in = interceptors ; } public void setInFaultInterceptors ( List < Interceptor < ? extends Message > > interceptors ) { inFault = interceptors ; } public void setOutInterceptors ( List < Interceptor < ? extends Message > > interceptors ) { out = interceptors ; } public void setOutFaultInterceptors ( List < Interceptor < ? extends Message > > interceptors ) { outFault = interceptors ; } @ Override public boolean equals ( Object o ) { return o == this ; } @ Override public int hashCode ( ) { return super . hashCode ( ) ; } }",Smelly
"public class PartitionedWriteAheadEventStore extends PartitionedEventStore { private final BlockingQueue < File > filesToCompress ; private final List < WriteAheadStorePartition > partitions ; private final RepositoryConfiguration repoConfig ; private final ExecutorService compressionExecutor ; private final List < EventFileCompressor > fileCompressors = Collections . synchronizedList ( new ArrayList < > ( ) ) ; private final EventReporter eventReporter ; private final EventFileManager fileManager ; public PartitionedWriteAheadEventStore ( final RepositoryConfiguration repoConfig , final RecordWriterFactory recordWriterFactory , final RecordReaderFactory recordReaderFactory , final EventReporter eventReporter , final EventFileManager fileManager ) { super ( repoConfig , eventReporter ) ; this . repoConfig = repoConfig ; this . eventReporter = eventReporter ; this . filesToCompress = new LinkedBlockingQueue < > ( 100 ) ; final AtomicLong idGenerator = new AtomicLong ( 0L ) ; this . partitions = createPartitions ( repoConfig , recordWriterFactory , recordReaderFactory , idGenerator ) ; this . fileManager = fileManager ; if ( repoConfig . isCompressOnRollover ( ) ) { compressionExecutor = Executors . newFixedThreadPool ( repoConfig . getIndexThreadPoolSize ( ) , new NamedThreadFactory ( ""Compress Provenance Logs"" ) ) ; } else { compressionExecutor = null ; } } private List < WriteAheadStorePartition > createPartitions ( final RepositoryConfiguration repoConfig , final RecordWriterFactory recordWriterFactory , final RecordReaderFactory recordReaderFactory , final AtomicLong idGenerator ) { final Map < String , File > storageDirectories = repoConfig . getStorageDirectories ( ) ; final List < WriteAheadStorePartition > partitions = new ArrayList < > ( storageDirectories . size ( ) ) ; for ( final Map . Entry < String , File > entry : storageDirectories . entrySet ( ) ) { final String partitionName = entry . getKey ( ) ; final File storageDirectory = entry . getValue ( ) ; partitions . add ( new WriteAheadStorePartition ( storageDirectory , partitionName , repoConfig , recordWriterFactory , recordReaderFactory , filesToCompress , idGenerator , eventReporter ) ) ; } return partitions ; } @ Override public void initialize ( ) throws IOException { if ( repoConfig . isCompressOnRollover ( ) ) { for ( int i = 0 ; i < repoConfig . getIndexThreadPoolSize ( ) ; i ++ ) { final EventFileCompressor compressor = new EventFileCompressor ( filesToCompress , fileManager ) ; compressionExecutor . submit ( compressor ) ; fileCompressors . add ( compressor ) ; } } super . initialize ( ) ; } @ Override public void close ( ) throws IOException { super . close ( ) ; for ( final EventFileCompressor compressor : fileCompressors ) { compressor . shutdown ( ) ; } if ( compressionExecutor != null ) { compressionExecutor . shutdown ( ) ; } } @ Override public void reindexLatestEvents ( final EventIndex eventIndex ) { final List < WriteAheadStorePartition > partitions = getPartitions ( ) ; final int numPartitions = partitions . size ( ) ; final List < Future < ? > > futures = new ArrayList < > ( numPartitions ) ; final ExecutorService executor = Executors . newFixedThreadPool ( numPartitions ) ; for ( final WriteAheadStorePartition partition : partitions ) { futures . add ( executor . submit ( ( ) -> partition . reindexLatestEvents ( eventIndex ) ) ) ; } executor . shutdown ( ) ; for ( final Future < ? > future : futures ) { try { future . get ( ) ; } catch ( InterruptedException e ) { Thread . currentThread ( ) . interrupt ( ) ; throw new RuntimeException ( ""Failed to re-index events because Thread was interrupted"" , e ) ; } catch ( ExecutionException e ) { throw new RuntimeException ( ""Failed to re-index events"" , e ) ; } } } @ Override protected List < WriteAheadStorePartition > getPartitions ( ) { return partitions ; } }",No
"public class VersionIT extends TCKBase { public static Test suite ( ) { return new VersionIT ( ) ; } public VersionIT ( ) { super ( ""JCR version tests"" ) ; } @ Override protected void addTests ( ) { addTest ( org . apache . jackrabbit . test . api . version . TestAll . suite ( ) ) ; addTest ( org . apache . jackrabbit . test . api . version . simple . TestAll . suite ( ) ) ; } }",No
"class portugueseStemmer extends opennlp . tools . stemmer . snowball . AbstractSnowballStemmer { private static final long serialVersionUID = 1L ; private final static portugueseStemmer methodObject = new portugueseStemmer ( ) ; private final static Among a_0 [ ] = { new Among ( """" , - 1 , 3 , """" , methodObject ) , new Among ( ""\u00E3"" , 0 , 1 , """" , methodObject ) , new Among ( ""\u00F5"" , 0 , 2 , """" , methodObject ) } ; private final static Among a_1 [ ] = { new Among ( """" , - 1 , 3 , """" , methodObject ) , new Among ( ""a~"" , 0 , 1 , """" , methodObject ) , new Among ( ""o~"" , 0 , 2 , """" , methodObject ) } ; private final static Among a_2 [ ] = { new Among ( ""ic"" , - 1 , - 1 , """" , methodObject ) , new Among ( ""ad"" , - 1 , - 1 , """" , methodObject ) , new Among ( ""os"" , - 1 , - 1 , """" , methodObject ) , new Among ( ""iv"" , - 1 , 1 , """" , methodObject ) } ; private final static Among a_3 [ ] = { new Among ( ""ante"" , - 1 , 1 , """" , methodObject ) , new Among ( ""avel"" , - 1 , 1 , """" , methodObject ) , new Among ( ""\u00EDvel"" , - 1 , 1 , """" , methodObject ) } ; private final static Among a_4 [ ] = { new Among ( ""ic"" , - 1 , 1 , """" , methodObject ) , new Among ( ""abil"" , - 1 , 1 , """" , methodObject ) , new Among ( ""iv"" , - 1 , 1 , """" , methodObject ) } ; private final static Among a_5 [ ] = { new Among ( ""ica"" , - 1 , 1 , """" , methodObject ) , new Among ( ""\u00E2ncia"" , - 1 , 1 , """" , methodObject ) , new Among ( ""\u00EAncia"" , - 1 , 4 , """" , methodObject ) , new Among ( ""ira"" , - 1 , 9 , """" , methodObject ) , new Among ( ""adora"" , - 1 , 1 , """" , methodObject ) , new Among ( ""osa"" , - 1 , 1 , """" , methodObject ) , new Among ( ""ista"" , - 1 , 1 , """" , methodObject ) , new Among ( ""iva"" , - 1 , 8 , """" , methodObject ) , new Among ( ""eza"" , - 1 , 1 , """" , methodObject ) , new Among ( ""log\u00EDa"" , - 1 , 2 , """" , methodObject ) , new Among ( ""idade"" , - 1 , 7 , """" , methodObject ) , new Among ( ""ante"" , - 1 , 1 , """" , methodObject ) , new Among ( ""mente"" , - 1 , 6 , """" , methodObject ) , new Among ( ""amente"" , 12 , 5 , """" , methodObject ) , new Among ( ""\u00E1vel"" , - 1 , 1 , """" , methodObject ) , new Among ( ""\u00EDvel"" , - 1 , 1 , """" , methodObject ) , new Among ( ""uci\u00F3n"" , - 1 , 3 , """" , methodObject ) , new Among ( ""ico"" , - 1 , 1 , """" , methodObject ) , new Among ( ""ismo"" , - 1 , 1 , """" , methodObject ) , new Among ( ""oso"" , - 1 , 1 , """" , methodObject ) , new Among ( ""amento"" , - 1 , 1 , """" , methodObject ) , new Among ( ""imento"" , - 1 , 1 , """" , methodObject ) , new Among ( ""ivo"" , - 1 , 8 , """" , methodObject ) , new Among ( ""a\u00E7a~o"" , - 1 , 1 , """" , methodObject ) , new Among ( ""ador"" , - 1 , 1 , """" , methodObject ) , new Among ( ""icas"" , - 1 , 1 , """" , methodObject ) , new Among ( ""\u00EAncias"" , - 1 , 4 , """" , methodObject ) , new Among ( ""iras"" , - 1 , 9 , """" , methodObject ) , new Among ( ""adoras"" , - 1 , 1 , """" , methodObject ) , new Among ( ""osas"" , - 1 , 1 , """" , methodObject ) , new Among ( ""istas"" , - 1 , 1 , """" , methodObject ) , new Among ( ""ivas"" , - 1 , 8 , """" , methodObject ) , new Among ( ""ezas"" , - 1 , 1 , """" , methodObject ) , new Among ( ""log\u00EDas"" , - 1 , 2 , """" , methodObject ) , new Among ( ""idades"" , - 1 , 7 , """" , methodObject ) , new Among ( ""uciones"" , - 1 , 3 , """" , methodObject ) , new Among ( ""adores"" , - 1 , 1 , """" , methodObject ) , new Among ( ""antes"" , - 1 , 1 , """" , methodObject ) , new Among ( ""a\u00E7o~es"" , - 1 , 1 , """" , methodObject ) , new Among ( ""icos"" , - 1 , 1 , """" , methodObject ) , new Among ( ""ismos"" , - 1 , 1 , """" , methodObject ) , new Among ( ""osos"" , - 1 , 1 , """" , methodObject ) , new Among ( ""amentos"" , - 1 , 1 , """" , methodObject ) , new Among ( ""imentos"" , - 1 , 1 , """" , methodObject ) , new Among ( ""ivos"" , - 1 , 8 , """" , methodObject ) } ; private final static Among a_6 [ ] = { new Among ( ""ada"" , - 1 , 1 , """" , methodObject ) , new Among ( ""ida"" , - 1 , 1 , """" , methodObject ) , new Among ( ""ia"" , - 1 , 1 , """" , methodObject ) , new Among ( ""aria"" , 2 , 1 , """" , methodObject ) , new Among ( ""eria"" , 2 , 1 , """" , methodObject ) , new Among ( ""iria"" , 2 , 1 , """" , methodObject ) , new Among ( ""ara"" , - 1 , 1 , """" , methodObject ) , new Among ( ""era"" , - 1 , 1 , """" , methodObject ) , new Among ( ""ira"" , - 1 , 1 , """" , methodObject ) , new Among ( ""ava"" , - 1 , 1 , """" , methodObject ) , new Among ( ""asse"" , - 1 , 1 , """" , methodObject ) , new Among ( ""esse"" , - 1 , 1 , """" , methodObject ) , new Among ( ""isse"" , - 1 , 1 , """" , methodObject ) , new Among ( ""aste"" , - 1 , 1 , """" , methodObject ) , new Among ( ""este"" , - 1 , 1 , """" , methodObject ) , new Among ( ""iste"" , - 1 , 1 , """" , methodObject ) , new Among ( ""ei"" , - 1 , 1 , """" , methodObject ) , new Among ( ""arei"" , 16 , 1 , """" , methodObject ) , new Among ( ""erei"" , 16 , 1 , """" , methodObject ) , new Among ( ""irei"" , 16 , 1 , """" , methodObject ) , new Among ( ""am"" , - 1 , 1 , """" , methodObject ) , new Among ( ""iam"" , 20 , 1 , """" , methodObject ) , new Among ( ""ariam"" , 21 , 1 , """" , methodObject ) , new Among ( ""eriam"" , 21 , 1 , """" , methodObject ) , new Among ( ""iriam"" , 21 , 1 , """" , methodObject ) , new Among ( ""aram"" , 20 , 1 , """" , methodObject ) , new Among ( ""eram"" , 20 , 1 , """" , methodObject ) , new Among ( ""iram"" , 20 , 1 , """" , methodObject ) , new Among ( ""avam"" , 20 , 1 , """" , methodObject ) , new Among ( ""em"" , - 1 , 1 , """" , methodObject ) , new Among ( ""arem"" , 29 , 1 , """" , methodObject ) , new Among ( ""erem"" , 29 , 1 , """" , methodObject ) , new Among ( ""irem"" , 29 , 1 , """" , methodObject ) , new Among ( ""assem"" , 29 , 1 , """" , methodObject ) , new Among ( ""essem"" , 29 , 1 , """" , methodObject ) , new Among ( ""issem"" , 29 , 1 , """" , methodObject ) , new Among ( ""ado"" , - 1 , 1 , """" , methodObject ) , new Among ( ""ido"" , - 1 , 1 , """" , methodObject ) , new Among ( ""ando"" , - 1 , 1 , """" , methodObject ) , new Among ( ""endo"" , - 1 , 1 , """" , methodObject ) , new Among ( ""indo"" , - 1 , 1 , """" , methodObject ) , new Among ( ""ara~o"" , - 1 , 1 , """" , methodObject ) , new Among ( ""era~o"" , - 1 , 1 , """" , methodObject ) , new Among ( ""ira~o"" , - 1 , 1 , """" , methodObject ) , new Among ( ""ar"" , - 1 , 1 , """" , methodObject ) , new Among ( ""er"" , - 1 , 1 , """" , methodObject ) , new Among ( ""ir"" , - 1 , 1 , """" , methodObject ) , new Among ( ""as"" , - 1 , 1 , """" , methodObject ) , new Among ( ""adas"" , 47 , 1 , """" , methodObject ) , new Among ( ""idas"" , 47 , 1 , """" , methodObject ) , new Among ( ""ias"" , 47 , 1 , """" , methodObject ) , new Among ( ""arias"" , 50 , 1 , """" , methodObject ) , new Among ( ""erias"" , 50 , 1 , """" , methodObject ) , new Among ( ""irias"" , 50 , 1 , """" , methodObject ) , new Among ( ""aras"" , 47 , 1 , """" , methodObject ) , new Among ( ""eras"" , 47 , 1 , """" , methodObject ) , new Among ( ""iras"" , 47 , 1 , """" , methodObject ) , new Among ( ""avas"" , 47 , 1 , """" , methodObject ) , new Among ( ""es"" , - 1 , 1 , """" , methodObject ) , new Among ( ""ardes"" , 58 , 1 , """" , methodObject ) , new Among ( ""erdes"" , 58 , 1 , """" , methodObject ) , new Among ( ""irdes"" , 58 , 1 , """" , methodObject ) , new Among ( ""ares"" , 58 , 1 , """" , methodObject ) , new Among ( ""eres"" , 58 , 1 , """" , methodObject ) , new Among ( ""ires"" , 58 , 1 , """" , methodObject ) , new Among ( ""asses"" , 58 , 1 , """" , methodObject ) , new Among ( ""esses"" , 58 , 1 , """" , methodObject ) , new Among ( ""isses"" , 58 , 1 , """" , methodObject ) , new Among ( ""astes"" , 58 , 1 , """" , methodObject ) , new Among ( ""estes"" , 58 , 1 , """" , methodObject ) , new Among ( ""istes"" , 58 , 1 , """" , methodObject ) , new Among ( ""is"" , - 1 , 1 , """" , methodObject ) , new Among ( ""ais"" , 71 , 1 , """" , methodObject ) , new Among ( ""eis"" , 71 , 1 , """" , methodObject ) , new Among ( ""areis"" , 73 , 1 , """" , methodObject ) , new Among ( ""ereis"" , 73 , 1 , """" , methodObject ) , new Among ( ""ireis"" , 73 , 1 , """" , methodObject ) , new Among ( ""\u00E1reis"" , 73 , 1 , """" , methodObject ) , new Among ( ""\u00E9reis"" , 73 , 1 , """" , methodObject ) , new Among ( ""\u00EDreis"" , 73 , 1 , """" , methodObject ) , new Among ( ""\u00E1sseis"" , 73 , 1 , """" , methodObject ) , new Among ( ""\u00E9sseis"" , 73 , 1 , """" , methodObject ) , new Among ( ""\u00EDsseis"" , 73 , 1 , """" , methodObject ) , new Among ( ""\u00E1veis"" , 73 , 1 , """" , methodObject ) , new Among ( ""\u00EDeis"" , 73 , 1 , """" , methodObject ) , new Among ( ""ar\u00EDeis"" , 84 , 1 , """" , methodObject ) , new Among ( ""er\u00EDeis"" , 84 , 1 , """" , methodObject ) , new Among ( ""ir\u00EDeis"" , 84 , 1 , """" , methodObject ) , new Among ( ""ados"" , - 1 , 1 , """" , methodObject ) , new Among ( ""idos"" , - 1 , 1 , """" , methodObject ) , new Among ( ""amos"" , - 1 , 1 , """" , methodObject ) , new Among ( ""\u00E1ramos"" , 90 , 1 , """" , methodObject ) , new Among ( ""\u00E9ramos"" , 90 , 1 , """" , methodObject ) , new Among ( ""\u00EDramos"" , 90 , 1 , """" , methodObject ) , new Among ( ""\u00E1vamos"" , 90 , 1 , """" , methodObject ) , new Among ( ""\u00EDamos"" , 90 , 1 , """" , methodObject ) , new Among ( ""ar\u00EDamos"" , 95 , 1 , """" , methodObject ) , new Among ( ""er\u00EDamos"" , 95 , 1 , """" , methodObject ) , new Among ( ""ir\u00EDamos"" , 95 , 1 , """" , methodObject ) , new Among ( ""emos"" , - 1 , 1 , """" , methodObject ) , new Among ( ""aremos"" , 99 , 1 , """" , methodObject ) , new Among ( ""eremos"" , 99 , 1 , """" , methodObject ) , new Among ( ""iremos"" , 99 , 1 , """" , methodObject ) , new Among ( ""\u00E1ssemos"" , 99 , 1 , """" , methodObject ) , new Among ( ""\u00EAssemos"" , 99 , 1 , """" , methodObject ) , new Among ( ""\u00EDssemos"" , 99 , 1 , """" , methodObject ) , new Among ( ""imos"" , - 1 , 1 , """" , methodObject ) , new Among ( ""armos"" , - 1 , 1 , """" , methodObject ) , new Among ( ""ermos"" , - 1 , 1 , """" , methodObject ) , new Among ( ""irmos"" , - 1 , 1 , """" , methodObject ) , new Among ( ""\u00E1mos"" , - 1 , 1 , """" , methodObject ) , new Among ( ""ar\u00E1s"" , - 1 , 1 , """" , methodObject ) , new Among ( ""er\u00E1s"" , - 1 , 1 , """" , methodObject ) , new Among ( ""ir\u00E1s"" , - 1 , 1 , """" , methodObject ) , new Among ( ""eu"" , - 1 , 1 , """" , methodObject ) , new Among ( ""iu"" , - 1 , 1 , """" , methodObject ) , new Among ( ""ou"" , - 1 , 1 , """" , methodObject ) , new Among ( ""ar\u00E1"" , - 1 , 1 , """" , methodObject ) , new Among ( ""er\u00E1"" , - 1 , 1 , """" , methodObject ) , new Among ( ""ir\u00E1"" , - 1 , 1 , """" , methodObject ) } ; private final static Among a_7 [ ] = { new Among ( ""a"" , - 1 , 1 , """" , methodObject ) , new Among ( ""i"" , - 1 , 1 , """" , methodObject ) , new Among ( ""o"" , - 1 , 1 , """" , methodObject ) , new Among ( ""os"" , - 1 , 1 , """" , methodObject ) , new Among ( ""\u00E1"" , - 1 , 1 , """" , methodObject ) , new Among ( ""\u00ED"" , - 1 , 1 , """" , methodObject ) , new Among ( ""\u00F3"" , - 1 , 1 , """" , methodObject ) } ; private final static Among a_8 [ ] = { new Among ( ""e"" , - 1 , 1 , """" , methodObject ) , new Among ( ""\u00E7"" , - 1 , 2 , """" , methodObject ) , new Among ( ""\u00E9"" , - 1 , 1 , """" , methodObject ) , new Among ( ""\u00EA"" , - 1 , 1 , """" , methodObject ) } ; private static final char g_v [ ] = { 17 , 65 , 16 , 0 , 0 , 0 , 0 , 0 , 0 , 0 , 0 , 0 , 0 , 0 , 0 , 0 , 3 , 19 , 12 , 2 } ; private int I_p2 ; private int I_p1 ; private int I_pV ; private void copy_from ( portugueseStemmer other ) { I_p2 = other . I_p2 ; I_p1 = other . I_p1 ; I_pV = other . I_pV ; super . copy_from ( other ) ; } private boolean r_prelude ( ) { int among_var ; int v_1 ; replab0 : while ( true ) { v_1 = cursor ; lab1 : do { bra = cursor ; among_var = find_among ( a_0 , 3 ) ; if ( among_var == 0 ) { break lab1 ; } ket = cursor ; switch ( among_var ) { case 0 : break lab1 ; case 1 : slice_from ( ""a~"" ) ; break ; case 2 : slice_from ( ""o~"" ) ; break ; case 3 : if ( cursor >= limit ) { break lab1 ; } cursor ++ ; break ; } continue replab0 ; } while ( false ) ; cursor = v_1 ; break replab0 ; } return true ; } private boolean r_mark_regions ( ) { int v_1 ; int v_2 ; int v_3 ; int v_6 ; int v_8 ; I_pV = limit ; I_p1 = limit ; I_p2 = limit ; v_1 = cursor ; lab0 : do { lab1 : do { v_2 = cursor ; lab2 : do { if ( ! ( in_grouping ( g_v , 97 , 250 ) ) ) { break lab2 ; } lab3 : do { v_3 = cursor ; lab4 : do { if ( ! ( out_grouping ( g_v , 97 , 250 ) ) ) { break lab4 ; } golab5 : while ( true ) { lab6 : do { if ( ! ( in_grouping ( g_v , 97 , 250 ) ) ) { break lab6 ; } break golab5 ; } while ( false ) ; if ( cursor >= limit ) { break lab4 ; } cursor ++ ; } break lab3 ; } while ( false ) ; cursor = v_3 ; if ( ! ( in_grouping ( g_v , 97 , 250 ) ) ) { break lab2 ; } golab7 : while ( true ) { lab8 : do { if ( ! ( out_grouping ( g_v , 97 , 250 ) ) ) { break lab8 ; } break golab7 ; } while ( false ) ; if ( cursor >= limit ) { break lab2 ; } cursor ++ ; } } while ( false ) ; break lab1 ; } while ( false ) ; cursor = v_2 ; if ( ! ( out_grouping ( g_v , 97 , 250 ) ) ) { break lab0 ; } lab9 : do { v_6 = cursor ; lab10 : do { if ( ! ( out_grouping ( g_v , 97 , 250 ) ) ) { break lab10 ; } golab11 : while ( true ) { lab12 : do { if ( ! ( in_grouping ( g_v , 97 , 250 ) ) ) { break lab12 ; } break golab11 ; } while ( false ) ; if ( cursor >= limit ) { break lab10 ; } cursor ++ ; } break lab9 ; } while ( false ) ; cursor = v_6 ; if ( ! ( in_grouping ( g_v , 97 , 250 ) ) ) { break lab0 ; } if ( cursor >= limit ) { break lab0 ; } cursor ++ ; } while ( false ) ; } while ( false ) ; I_pV = cursor ; } while ( false ) ; cursor = v_1 ; v_8 = cursor ; lab13 : do { golab14 : while ( true ) { lab15 : do { if ( ! ( in_grouping ( g_v , 97 , 250 ) ) ) { break lab15 ; } break golab14 ; } while ( false ) ; if ( cursor >= limit ) { break lab13 ; } cursor ++ ; } golab16 : while ( true ) { lab17 : do { if ( ! ( out_grouping ( g_v , 97 , 250 ) ) ) { break lab17 ; } break golab16 ; } while ( false ) ; if ( cursor >= limit ) { break lab13 ; } cursor ++ ; } I_p1 = cursor ; golab18 : while ( true ) { lab19 : do { if ( ! ( in_grouping ( g_v , 97 , 250 ) ) ) { break lab19 ; } break golab18 ; } while ( false ) ; if ( cursor >= limit ) { break lab13 ; } cursor ++ ; } golab20 : while ( true ) { lab21 : do { if ( ! ( out_grouping ( g_v , 97 , 250 ) ) ) { break lab21 ; } break golab20 ; } while ( false ) ; if ( cursor >= limit ) { break lab13 ; } cursor ++ ; } I_p2 = cursor ; } while ( false ) ; cursor = v_8 ; return true ; } private boolean r_postlude ( ) { int among_var ; int v_1 ; replab0 : while ( true ) { v_1 = cursor ; lab1 : do { bra = cursor ; among_var = find_among ( a_1 , 3 ) ; if ( among_var == 0 ) { break lab1 ; } ket = cursor ; switch ( among_var ) { case 0 : break lab1 ; case 1 : slice_from ( ""\u00E3"" ) ; break ; case 2 : slice_from ( ""\u00F5"" ) ; break ; case 3 : if ( cursor >= limit ) { break lab1 ; } cursor ++ ; break ; } continue replab0 ; } while ( false ) ; cursor = v_1 ; break replab0 ; } return true ; } private boolean r_RV ( ) { if ( ! ( I_pV <= cursor ) ) { return false ; } return true ; } private boolean r_R1 ( ) { if ( ! ( I_p1 <= cursor ) ) { return false ; } return true ; } private boolean r_R2 ( ) { if ( ! ( I_p2 <= cursor ) ) { return false ; } return true ; } private boolean r_standard_suffix ( ) { int among_var ; int v_1 ; int v_2 ; int v_3 ; int v_4 ; ket = cursor ; among_var = find_among_b ( a_5 , 45 ) ; if ( among_var == 0 ) { return false ; } bra = cursor ; switch ( among_var ) { case 0 : return false ; case 1 : if ( ! r_R2 ( ) ) { return false ; } slice_del ( ) ; break ; case 2 : if ( ! r_R2 ( ) ) { return false ; } slice_from ( ""log"" ) ; break ; case 3 : if ( ! r_R2 ( ) ) { return false ; } slice_from ( ""u"" ) ; break ; case 4 : if ( ! r_R2 ( ) ) { return false ; } slice_from ( ""ente"" ) ; break ; case 5 : if ( ! r_R1 ( ) ) { return false ; } slice_del ( ) ; v_1 = limit - cursor ; lab0 : do { ket = cursor ; among_var = find_among_b ( a_2 , 4 ) ; if ( among_var == 0 ) { cursor = limit - v_1 ; break lab0 ; } bra = cursor ; if ( ! r_R2 ( ) ) { cursor = limit - v_1 ; break lab0 ; } slice_del ( ) ; switch ( among_var ) { case 0 : cursor = limit - v_1 ; break lab0 ; case 1 : ket = cursor ; if ( ! ( eq_s_b ( 2 , ""at"" ) ) ) { cursor = limit - v_1 ; break lab0 ; } bra = cursor ; if ( ! r_R2 ( ) ) { cursor = limit - v_1 ; break lab0 ; } slice_del ( ) ; break ; } } while ( false ) ; break ; case 6 : if ( ! r_R2 ( ) ) { return false ; } slice_del ( ) ; v_2 = limit - cursor ; lab1 : do { ket = cursor ; among_var = find_among_b ( a_3 , 3 ) ; if ( among_var == 0 ) { cursor = limit - v_2 ; break lab1 ; } bra = cursor ; switch ( among_var ) { case 0 : cursor = limit - v_2 ; break lab1 ; case 1 : if ( ! r_R2 ( ) ) { cursor = limit - v_2 ; break lab1 ; } slice_del ( ) ; break ; } } while ( false ) ; break ; case 7 : if ( ! r_R2 ( ) ) { return false ; } slice_del ( ) ; v_3 = limit - cursor ; lab2 : do { ket = cursor ; among_var = find_among_b ( a_4 , 3 ) ; if ( among_var == 0 ) { cursor = limit - v_3 ; break lab2 ; } bra = cursor ; switch ( among_var ) { case 0 : cursor = limit - v_3 ; break lab2 ; case 1 : if ( ! r_R2 ( ) ) { cursor = limit - v_3 ; break lab2 ; } slice_del ( ) ; break ; } } while ( false ) ; break ; case 8 : if ( ! r_R2 ( ) ) { return false ; } slice_del ( ) ; v_4 = limit - cursor ; lab3 : do { ket = cursor ; if ( ! ( eq_s_b ( 2 , ""at"" ) ) ) { cursor = limit - v_4 ; break lab3 ; } bra = cursor ; if ( ! r_R2 ( ) ) { cursor = limit - v_4 ; break lab3 ; } slice_del ( ) ; } while ( false ) ; break ; case 9 : if ( ! r_RV ( ) ) { return false ; } if ( ! ( eq_s_b ( 1 , ""e"" ) ) ) { return false ; } slice_from ( ""ir"" ) ; break ; } return true ; } private boolean r_verb_suffix ( ) { int among_var ; int v_1 ; int v_2 ; v_1 = limit - cursor ; if ( cursor < I_pV ) { return false ; } cursor = I_pV ; v_2 = limit_backward ; limit_backward = cursor ; cursor = limit - v_1 ; ket = cursor ; among_var = find_among_b ( a_6 , 120 ) ; if ( among_var == 0 ) { limit_backward = v_2 ; return false ; } bra = cursor ; switch ( among_var ) { case 0 : limit_backward = v_2 ; return false ; case 1 : slice_del ( ) ; break ; } limit_backward = v_2 ; return true ; } private boolean r_residual_suffix ( ) { int among_var ; ket = cursor ; among_var = find_among_b ( a_7 , 7 ) ; if ( among_var == 0 ) { return false ; } bra = cursor ; switch ( among_var ) { case 0 : return false ; case 1 : if ( ! r_RV ( ) ) { return false ; } slice_del ( ) ; break ; } return true ; } private boolean r_residual_form ( ) { int among_var ; int v_1 ; int v_2 ; int v_3 ; ket = cursor ; among_var = find_among_b ( a_8 , 4 ) ; if ( among_var == 0 ) { return false ; } bra = cursor ; switch ( among_var ) { case 0 : return false ; case 1 : if ( ! r_RV ( ) ) { return false ; } slice_del ( ) ; ket = cursor ; lab0 : do { v_1 = limit - cursor ; lab1 : do { if ( ! ( eq_s_b ( 1 , ""u"" ) ) ) { break lab1 ; } bra = cursor ; v_2 = limit - cursor ; if ( ! ( eq_s_b ( 1 , ""g"" ) ) ) { break lab1 ; } cursor = limit - v_2 ; break lab0 ; } while ( false ) ; cursor = limit - v_1 ; if ( ! ( eq_s_b ( 1 , ""i"" ) ) ) { return false ; } bra = cursor ; v_3 = limit - cursor ; if ( ! ( eq_s_b ( 1 , ""c"" ) ) ) { return false ; } cursor = limit - v_3 ; } while ( false ) ; if ( ! r_RV ( ) ) { return false ; } slice_del ( ) ; break ; case 2 : slice_from ( ""c"" ) ; break ; } return true ; } public boolean stem ( ) { int v_1 ; int v_2 ; int v_3 ; int v_4 ; int v_5 ; int v_6 ; int v_7 ; int v_8 ; int v_9 ; int v_10 ; v_1 = cursor ; lab0 : do { if ( ! r_prelude ( ) ) { break lab0 ; } } while ( false ) ; cursor = v_1 ; v_2 = cursor ; lab1 : do { if ( ! r_mark_regions ( ) ) { break lab1 ; } } while ( false ) ; cursor = v_2 ; limit_backward = cursor ; cursor = limit ; v_3 = limit - cursor ; lab2 : do { lab3 : do { v_4 = limit - cursor ; lab4 : do { v_5 = limit - cursor ; lab5 : do { v_6 = limit - cursor ; lab6 : do { if ( ! r_standard_suffix ( ) ) { break lab6 ; } break lab5 ; } while ( false ) ; cursor = limit - v_6 ; if ( ! r_verb_suffix ( ) ) { break lab4 ; } } while ( false ) ; cursor = limit - v_5 ; v_7 = limit - cursor ; lab7 : do { ket = cursor ; if ( ! ( eq_s_b ( 1 , ""i"" ) ) ) { break lab7 ; } bra = cursor ; v_8 = limit - cursor ; if ( ! ( eq_s_b ( 1 , ""c"" ) ) ) { break lab7 ; } cursor = limit - v_8 ; if ( ! r_RV ( ) ) { break lab7 ; } slice_del ( ) ; } while ( false ) ; cursor = limit - v_7 ; break lab3 ; } while ( false ) ; cursor = limit - v_4 ; if ( ! r_residual_suffix ( ) ) { break lab2 ; } } while ( false ) ; } while ( false ) ; cursor = limit - v_3 ; v_9 = limit - cursor ; lab8 : do { if ( ! r_residual_form ( ) ) { break lab8 ; } } while ( false ) ; cursor = limit - v_9 ; cursor = limit_backward ; v_10 = cursor ; lab9 : do { if ( ! r_postlude ( ) ) { break lab9 ; } } while ( false ) ; cursor = v_10 ; return true ; } public boolean equals ( Object o ) { return o instanceof portugueseStemmer ; } public int hashCode ( ) { return portugueseStemmer . class . getName ( ) . hashCode ( ) ; } }",No
"public class SpecificMain { public static void main ( String [ ] args ) throws IOException { User user1 = new User ( ) ; user1 . setName ( ""Alyssa"" ) ; user1 . setFavoriteNumber ( 256 ) ; User user2 = new User ( ""Ben"" , 7 , ""red"" ) ; User user3 = User . newBuilder ( ) . setName ( ""Charlie"" ) . setFavoriteColor ( ""blue"" ) . setFavoriteNumber ( null ) . build ( ) ; File file = new File ( ""users.avro"" ) ; DatumWriter < User > userDatumWriter = new SpecificDatumWriter < User > ( User . class ) ; DataFileWriter < User > dataFileWriter = new DataFileWriter < User > ( userDatumWriter ) ; dataFileWriter . create ( user1 . getSchema ( ) , file ) ; dataFileWriter . append ( user1 ) ; dataFileWriter . append ( user2 ) ; dataFileWriter . append ( user3 ) ; dataFileWriter . close ( ) ; DatumReader < User > userDatumReader = new SpecificDatumReader < User > ( User . class ) ; DataFileReader < User > dataFileReader = new DataFileReader < User > ( file , userDatumReader ) ; User user = null ; while ( dataFileReader . hasNext ( ) ) { user = dataFileReader . next ( user ) ; System . out . println ( user ) ; } } }",No
"final class REEFExecutors { private final Map < String , REEFExecutor > executors = new ConcurrentHashMap < > ( ) ; @ Inject REEFExecutors ( ) { } public void add ( final String id , final int memory , final EventHandler < EvaluatorControl > evaluatorControlHandler ) { executors . put ( id , new REEFExecutor ( memory , evaluatorControlHandler ) ) ; } public void remove ( final String id ) { this . executors . remove ( id ) ; } public Set < String > getExecutorIds ( ) { return executors . keySet ( ) ; } public int getMemory ( final String id ) { return executors . get ( id ) . getMemory ( ) ; } public void launchEvaluator ( final EvaluatorLaunch evaluatorLaunch ) { executors . get ( evaluatorLaunch . getIdentifier ( ) . toString ( ) ) . launchEvaluator ( evaluatorLaunch ) ; } public void releaseEvaluator ( final EvaluatorRelease evaluatorRelease ) { executors . get ( evaluatorRelease . getIdentifier ( ) . toString ( ) ) . releaseEvaluator ( evaluatorRelease ) ; } }",No
" public static class TwoTupleMap extends PMap < Node , PersistentSet < Node > , TwoTupleMap > { private TwoTupleMap ( final com . github . andrewoma . dexx . collection . Map < Node , PersistentSet < Node > > wrappedMap ) { super ( wrappedMap ) ; } public TwoTupleMap ( ) { super ( ) ; } @ Override protected TwoTupleMap wrap ( final Map < Node , PersistentSet < Node > > wrappedMap ) { return new TwoTupleMap ( wrappedMap ) ; } } ",No
" private static class DelegateStructType implements RelDataType { private RelDataType delegate ; private StructKind structKind ; DelegateStructType ( RelDataType delegate , StructKind structKind ) { assert delegate . isStruct ( ) ; this . delegate = delegate ; this . structKind = structKind ; } public boolean isStruct ( ) { return delegate . isStruct ( ) ; } public boolean isDynamicStruct ( ) { return delegate . isDynamicStruct ( ) ; } public List < RelDataTypeField > getFieldList ( ) { return delegate . getFieldList ( ) ; } public List < String > getFieldNames ( ) { return delegate . getFieldNames ( ) ; } public int getFieldCount ( ) { return delegate . getFieldCount ( ) ; } public StructKind getStructKind ( ) { return structKind ; } public RelDataTypeField getField ( String fieldName , boolean caseSensitive , boolean elideRecord ) { return delegate . getField ( fieldName , caseSensitive , elideRecord ) ; } public boolean isNullable ( ) { return delegate . isNullable ( ) ; } public RelDataType getComponentType ( ) { return delegate . getComponentType ( ) ; } public RelDataType getKeyType ( ) { return delegate . getKeyType ( ) ; } public RelDataType getValueType ( ) { return delegate . getValueType ( ) ; } public Charset getCharset ( ) { return delegate . getCharset ( ) ; } public SqlCollation getCollation ( ) { return delegate . getCollation ( ) ; } public SqlIntervalQualifier getIntervalQualifier ( ) { return delegate . getIntervalQualifier ( ) ; } public int getPrecision ( ) { return delegate . getPrecision ( ) ; } public int getScale ( ) { return delegate . getScale ( ) ; } public SqlTypeName getSqlTypeName ( ) { return delegate . getSqlTypeName ( ) ; } public SqlIdentifier getSqlIdentifier ( ) { return delegate . getSqlIdentifier ( ) ; } public String getFullTypeString ( ) { return delegate . getFullTypeString ( ) ; } public RelDataTypeFamily getFamily ( ) { return delegate . getFamily ( ) ; } public RelDataTypePrecedenceList getPrecedenceList ( ) { return delegate . getPrecedenceList ( ) ; } public RelDataTypeComparability getComparability ( ) { return delegate . getComparability ( ) ; } ",Smelly
"public class CustomerXml { protected int id ; protected String name ; protected Set < OrderXml > orders = new HashSet < OrderXml > ( ) ; public int getId ( ) { return id ; } public void setId ( int id ) { this . id = id ; } public String getName ( ) { return name ; } public void setName ( String name ) { this . name = name ; } public Set < OrderXml > getOrders ( ) { return orders ; } public void setOrders ( Set < OrderXml > orders ) { this . orders = orders ; } public void addOrder ( OrderXml order ) { orders . add ( order ) ; } public boolean equals ( Object obj ) { CustomerXml c0 = ( CustomerXml ) obj ; if ( c0 == null ) return false ; if ( c0 . getId ( ) != id ) return false ; if ( ! c0 . getName ( ) . equals ( name ) ) return false ; Set < OrderXml > orders0 = c0 . getOrders ( ) ; if ( orders0 . size ( ) != orders . size ( ) ) return false ; for ( OrderXml o : orders ) { if ( ! contains ( orders0 , o ) ) return false ; } return true ; } private boolean contains ( Set < OrderXml > orders0 , OrderXml o ) { int id = o . getId ( ) ; for ( OrderXml o0 : orders0 ) { if ( o0 . getId ( ) == id ) return true ; } return false ; } }",Smelly
public class TestTransactionLifecycle extends AbstractTestTxn { @ Test public void txn_read_end_RW ( ) { unit . begin ( ReadWrite . READ ) ; unit . end ( ) ; checkClear ( ) ; } @ Test public void txn_read_end ( ) { unit . begin ( TxnType . READ ) ; unit . end ( ) ; checkClear ( ) ; } @ Test public void txn_read_end_end ( ) { unit . begin ( TxnType . READ ) ; unit . end ( ) ; unit . end ( ) ; checkClear ( ) ; } @ Test public void txn_read_abort ( ) { unit . begin ( TxnType . READ ) ; unit . abort ( ) ; checkClear ( ) ; } @ Test public void txn_read_commit ( ) { unit . begin ( TxnType . READ ) ; unit . commit ( ) ; checkClear ( ) ; } @ Test public void txn_read_abort_end ( ) { unit . begin ( TxnType . READ ) ; unit . abort ( ) ; unit . end ( ) ; checkClear ( ) ; } @ Test public void txn_read_commit_end ( ) { unit . begin ( TxnType . READ ) ; unit . commit ( ) ; unit . end ( ) ; checkClear ( ) ; } @ Test public void txn_read_commit_abort ( ) { unit . begin ( TxnType . READ ) ; unit . commit ( ) ; try { unit . abort ( ) ; fail ( ) ; } catch ( TransactionException ex ) { } unit . end ( ) ; checkClear ( ) ; } @ Test public void txn_read_commit_commit ( ) { unit . begin ( TxnType . READ ) ; unit . commit ( ) ; try { unit . commit ( ) ; fail ( ) ; } catch ( TransactionException ex ) { } unit . end ( ) ; checkClear ( ) ; } @ Test public void txn_read_abort_commit ( ) { unit . begin ( TxnType . READ ) ; unit . abort ( ) ; try { unit . commit ( ) ; fail ( ) ; } catch ( TransactionException ex ) { } unit . end ( ) ; checkClear ( ) ; } @ Test public void txn_read_abort_abort ( ) { unit . begin ( TxnType . READ ) ; unit . abort ( ) ; try { unit . abort ( ) ; fail ( ) ; } catch ( TransactionException ex ) { } unit . end ( ) ; checkClear ( ) ; } @ Test ( expected = TransactionException . class ) public void txn_begin_read_begin_read ( ) { unit . begin ( TxnType . READ ) ; unit . begin ( TxnType . READ ) ; } @ Test ( expected = TransactionException . class ) public void txn_begin_read_begin_write ( ) { unit . begin ( TxnType . READ ) ; unit . begin ( TxnType . WRITE ) ; } @ Test ( expected = TransactionException . class ) public void txn_begin_write_begin_read ( ) { unit . begin ( TxnType . WRITE ) ; unit . begin ( TxnType . READ ) ; } @ Test ( expected = TransactionException . class ) public void txn_begin_write_begin_write ( ) { unit . begin ( TxnType . WRITE ) ; unit . begin ( TxnType . WRITE ) ; } @ Test ( expected = TransactionException . class ) public void txn_write_begin_end ( ) { unit . begin ( TxnType . WRITE ) ; unit . end ( ) ; checkClear ( ) ; } @ Test public void txn_write_abort ( ) { unit . begin ( TxnType . WRITE ) ; unit . abort ( ) ; checkClear ( ) ; } @ Test public void txn_write_commit ( ) { unit . begin ( TxnType . WRITE ) ; unit . commit ( ) ; checkClear ( ) ; } @ Test public void txn_write_abort_end ( ) { unit . begin ( TxnType . WRITE ) ; unit . abort ( ) ; unit . end ( ) ; checkClear ( ) ; } @ Test public void txn_write_abort_end_end ( ) { unit . begin ( TxnType . WRITE ) ; unit . abort ( ) ; unit . end ( ) ; unit . end ( ) ; checkClear ( ) ; } @ Test public void txn_write_commit_end_RW ( ) { unit . begin ( ReadWrite . WRITE ) ; unit . commit ( ) ; unit . end ( ) ; checkClear ( ) ; } @ Test public void txn_write_commit_end ( ) { unit . begin ( TxnType . WRITE ) ; unit . commit ( ) ; unit . end ( ) ; checkClear ( ) ; } @ Test public void txn_write_commit_end_end ( ) { unit . begin ( TxnType . WRITE ) ; unit . commit ( ) ; unit . end ( ) ; unit . end ( ) ; checkClear ( ) ; } @ Test public void txn_write_commit_abort ( ) { unit . begin ( TxnType . WRITE ) ; unit . commit ( ) ; try { unit . abort ( ) ; fail ( ) ; } catch ( TransactionException ex ) { } unit . end ( ) ; checkClear ( ) ; } @ Test public void txn_write_commit_commit ( ) { unit . begin ( TxnType . WRITE ) ; unit . commit ( ) ; try { unit . commit ( ) ; fail ( ) ; } catch ( TransactionException ex ) { } unit . end ( ) ; checkClear ( ) ; } @ Test public void txn_write_abort_commit ( ) { unit . begin ( TxnType . WRITE ) ; unit . abort ( ) ; try { unit . commit ( ) ; fail ( ) ; } catch ( TransactionException ex ) { } unit . end ( ) ; checkClear ( ) ; } @ Test public void txn_write_abort_abort ( ) { unit . begin ( TxnType . WRITE ) ; unit . abort ( ) ; try { unit . abort ( ) ; fail ( ) ; } catch ( TransactionException ex ) { } unit . end ( ) ; checkClear ( ) ; } @ Test public void txn_read_promote_commit ( ) { unit . begin ( TxnType . READ ) ; boolean b = unit . promote ( ) ; assertFalse ( b ) ; unit . end ( ) ; checkClear ( ) ; } @ Test public void txn_readpromote_promote_commit ( ) { unit . begin ( TxnType . READ_PROMOTE ) ; boolean b = unit . promote ( ) ; assertTrue ( b ) ; unit . commit ( ) ; unit . end ( ) ; checkClear ( ) ; } @ Test public void txn_readpromote_promote_promote_commit ( ) { unit . begin ( TxnType . READ_PROMOTE ) ; boolean b = unit . promote ( ) ; assertTrue ( b ) ; unit . commit ( ) ; unit . end ( ) ; checkClear ( ) ; } @ Test public void txn_readpromote_promote_abort ( ) { unit . begin ( TxnType . READ_PROMOTE ) ; boolean b = unit . promote ( ) ; assertTrue ( b ) ; unit . abort ( ) ; unit . end ( ) ; checkClear ( ) ; } @ Test public void txn_readcomittedpromote_promote_commit ( ) { unit . begin ( TxnType . READ_COMMITTED_PROMOTE ) ; boolean b = unit . promote ( ) ; assertTrue ( b ) ; unit . commit ( ) ; unit . end ( ) ; checkClear ( ) ; } @ Test public void txn_readcomittedpromote_promote_abort ( ) { unit . begin ( TxnType . READ_COMMITTED_PROMOTE ) ; boolean b = unit . promote ( ) ; assertTrue ( b ) ; unit . abort ( ) ; unit . end ( ) ; checkClear ( ) ; } @ Test public void txn_readpromote_promote_end ( ) { unit . begin ( TxnType . READ_PROMOTE ) ; boolean b = unit . promote ( ) ; assertTrue ( b ) ; try { unit . end ( ) ; } catch ( TransactionException ex ) { } checkClear ( ) ; } @ Test public void txn_readcomittedpromote_promote_end ( ) { unit . begin ( TxnType . READ_COMMITTED_PROMOTE ) ; boolean b = unit . promote ( ) ; assertTrue ( b ) ; try { unit . end ( ) ; } catch ( TransactionException ex ) { } checkClear ( ) ; } @ Test public void txn_readpromote_commit_promote ( ) { unit . begin ( TxnType . READ_PROMOTE ) ; unit . commit ( ) ; try { unit . promote ( ) ; } catch ( TransactionException ex ) { } checkClear ( ) ; } @ Test public void txn_readpromote_abort_promote ( ) { unit . begin ( TxnType . READ_PROMOTE ) ; unit . abort ( ) ; try { unit . promote ( ) ; } catch ( TransactionException ex ) { } checkClear ( ) ; } @ Test public void txn_readpromote_end_promote ( ) { unit . begin ( TxnType . READ_PROMOTE ) ; unit . end ( ) ; try { unit . promote ( ) ; } catch ( TransactionException ex ) { } checkClear ( ) ; } private void read ( ) { unit . begin ( TxnType . READ ) ; unit . end ( ) ; checkClear ( ) ; } private void write ( ) { unit . begin ( TxnType . WRITE ) ; unit . commit ( ) ; unit . end ( ) ; checkClear ( ) ; } @ Test public void txn_read_read ( ) { read ( ) ; read ( ) ; } @ Test public void txn_write_read ( ) { write ( ) ; read ( ) ; } @ Test public void txn_read_write ( ) { read ( ) ; write ( ) ; } @ Test public void txn_write_write ( ) { write ( ) ; write ( ) ; } @ Test public void txn_www ( ) { write ( ) ; write ( ) ; write ( ) ; checkClear ( ) ; } },No
"public class XMLMessageOutInterceptor extends AbstractOutDatabindingInterceptor { private static final ResourceBundle BUNDLE = BundleUtils . getBundle ( XMLMessageOutInterceptor . class ) ; public XMLMessageOutInterceptor ( ) { this ( Phase . MARSHAL ) ; } public XMLMessageOutInterceptor ( String phase ) { super ( phase ) ; addAfter ( WrappedOutInterceptor . class . getName ( ) ) ; } public void handleMessage ( Message message ) throws Fault { BindingOperationInfo boi = message . getExchange ( ) . get ( BindingOperationInfo . class ) ; MessageInfo mi ; BindingMessageInfo bmi ; if ( isRequestor ( message ) ) { mi = boi . getOperationInfo ( ) . getInput ( ) ; bmi = boi . getInput ( ) ; } else { mi = boi . getOperationInfo ( ) . getOutput ( ) ; bmi = boi . getOutput ( ) ; } XMLBindingMessageFormat xmf = bmi . getExtensor ( XMLBindingMessageFormat . class ) ; QName rootInModel = null ; if ( xmf != null ) { rootInModel = xmf . getRootNode ( ) ; } if ( boi . isUnwrapped ( ) || mi . getMessageParts ( ) . size ( ) == 1 ) { new BareOutInterceptor ( ) . handleMessage ( message ) ; } else { if ( rootInModel == null ) { rootInModel = boi . getName ( ) ; } if ( mi . getMessageParts ( ) . size ( ) == 0 && ! boi . isUnwrapped ( ) ) { writeMessage ( message , rootInModel , false ) ; } else { writeMessage ( message , rootInModel , true ) ; } } XMLStreamWriter writer = message . getContent ( XMLStreamWriter . class ) ; try { writer . flush ( ) ; } catch ( XMLStreamException e ) { throw new Fault ( new org . apache . cxf . common . i18n . Message ( ""STAX_WRITE_EXC"" , BUNDLE , e ) ) ; } } private void writeMessage ( Message message , QName name , boolean executeBare ) { XMLStreamWriter xmlWriter = message . getContent ( XMLStreamWriter . class ) ; try { String pfx = name . getPrefix ( ) ; if ( StringUtils . isEmpty ( pfx ) ) { pfx = ""ns1"" ; } StaxUtils . writeStartElement ( xmlWriter , pfx , name . getLocalPart ( ) , name . getNamespaceURI ( ) ) ; if ( executeBare ) { new BareOutInterceptor ( ) . handleMessage ( message ) ; } xmlWriter . writeEndElement ( ) ; } catch ( XMLStreamException e ) { throw new Fault ( new org . apache . cxf . common . i18n . Message ( ""STAX_WRITE_EXC"" , BUNDLE , e ) ) ; } } }",No
"@ MappedSuperclass @ XmlRootElement public abstract class XXPolicyBase extends XXDBBase { private static final long serialVersionUID = 1L ; @ Column ( name = ""guid"" , unique = true , nullable = false , length = 512 ) protected String guid ; @ Version @ Column ( name = ""version"" ) protected Long version ; @ Column ( name = ""service"" ) protected Long service ; @ Column ( name = ""name"" ) protected String name ; @ Column ( name = ""policy_type"" ) protected Integer policyType ; @ Column ( name = ""description"" ) protected String description ; @ Column ( name = ""resource_signature"" ) protected String resourceSignature ; @ Column ( name = ""is_enabled"" ) protected boolean isEnabled ; @ Column ( name = ""is_audit_enabled"" ) protected boolean isAuditEnabled ; public String getGuid ( ) { return guid ; } public void setGuid ( String gUID ) { guid = gUID ; } public void setVersion ( Long version ) { this . version = version ; } public Long getVersion ( ) { return this . version ; } public void setService ( Long service ) { this . service = service ; } public Long getService ( ) { return this . service ; } public void setName ( String name ) { this . name = name ; } public String getName ( ) { return this . name ; } public void setDescription ( String description ) { this . description = description ; } public String getDescription ( ) { return this . description ; } public String getResourceSignature ( ) { return resourceSignature ; } public void setResourceSignature ( String resourceSignature ) { this . resourceSignature = resourceSignature ; } public void setIsEnabled ( boolean isEnabled ) { this . isEnabled = isEnabled ; } public boolean getIsEnabled ( ) { return this . isEnabled ; } public void setIsAuditEnabled ( boolean isAuditEnabled ) { this . isAuditEnabled = isAuditEnabled ; } public boolean getIsAuditEnabled ( ) { return this . isAuditEnabled ; } public Integer getPolicyType ( ) { return policyType ; } public void setPolicyType ( Integer policyType ) { this . policyType = policyType ; } @ Override public boolean equals ( Object obj ) { if ( ! super . equals ( obj ) ) { return false ; } if ( this == obj ) { return true ; } if ( ! super . equals ( obj ) ) { return false ; } if ( getClass ( ) != obj . getClass ( ) ) { return false ; } XXPolicyBase other = ( XXPolicyBase ) obj ; if ( guid == null ) { if ( other . guid != null ) { return false ; } } else if ( ! guid . equals ( other . guid ) ) { return false ; } if ( description == null ) { if ( other . description != null ) { return false ; } } else if ( ! description . equals ( other . description ) ) { return false ; } if ( resourceSignature == null ) { if ( other . resourceSignature != null ) { return false ; } } else if ( ! resourceSignature . equals ( other . resourceSignature ) ) { return false ; } if ( isAuditEnabled != other . isAuditEnabled ) { return false ; } if ( isEnabled != other . isEnabled ) { return false ; } if ( name == null ) { if ( other . name != null ) { return false ; } } else if ( ! name . equals ( other . name ) ) { return false ; } if ( service == null ) { if ( other . service != null ) { return false ; } } else if ( ! service . equals ( other . service ) ) { return false ; } if ( version == null ) { if ( other . version != null ) { return false ; } } else if ( ! version . equals ( other . version ) ) { return false ; } if ( policyType == null ) { if ( other . policyType != null ) { return false ; } } else if ( ! policyType . equals ( other . policyType ) ) { return false ; } return true ; } @ Override public String toString ( ) { String str = ""XXPolicyBase={"" ; str += super . toString ( ) ; str += "" [guid="" + guid + "", version="" + version + "", service="" + service + "", name="" + name + "", policyType="" + policyType + "", description="" + description + "", resourceSignature="" + resourceSignature + "", isEnabled="" + isEnabled + "", isAuditEnabled="" + isAuditEnabled + ""]"" ; str += ""}"" ; return str ; } }",Smelly
"public class PluginIncompatibleException extends PluginManagerException { public PluginIncompatibleException ( Plugin plugin , String message ) { super ( plugin , message , ( Throwable ) null ) ; } }",No
"public class TaskAttemptFinishedEvent implements HistoryEvent { private static final Logger LOG = LoggerFactory . getLogger ( TaskAttemptFinishedEvent . class ) ; private TezTaskAttemptID taskAttemptId ; private String vertexName ; private long creationTime ; private long allocationTime ; private long startTime ; private long finishTime ; private TezTaskAttemptID creationCausalTA ; private TaskAttemptState state ; private TaskFailureType taskFailureType ; private String diagnostics ; private TezCounters tezCounters ; private TaskAttemptTerminationCause error ; private List < DataEventDependencyInfo > dataEvents ; private List < TezEvent > taGeneratedEvents ; private ContainerId containerId ; private NodeId nodeId ; private String inProgressLogsUrl ; private String completedLogsUrl ; private String nodeHttpAddress ; public TaskAttemptFinishedEvent ( TezTaskAttemptID taId , String vertexName , long startTime , long finishTime , TaskAttemptState state , @ Nullable TaskFailureType taskFailureType , TaskAttemptTerminationCause error , String diagnostics , TezCounters counters , List < DataEventDependencyInfo > dataEvents , List < TezEvent > taGeneratedEvents , long creationTime , TezTaskAttemptID creationCausalTA , long allocationTime , ContainerId containerId , NodeId nodeId , String inProgressLogsUrl , String completedLogsUrl , String nodeHttpAddress ) { this . taskAttemptId = taId ; this . vertexName = vertexName ; this . creationCausalTA = creationCausalTA ; this . creationTime = creationTime ; this . allocationTime = allocationTime ; this . startTime = startTime ; this . finishTime = finishTime ; this . state = state ; this . taskFailureType = taskFailureType ; this . diagnostics = diagnostics ; this . tezCounters = counters ; this . error = error ; this . dataEvents = dataEvents ; this . taGeneratedEvents = taGeneratedEvents ; this . containerId = containerId ; this . nodeId = nodeId ; this . inProgressLogsUrl = inProgressLogsUrl ; this . completedLogsUrl = completedLogsUrl ; this . nodeHttpAddress = nodeHttpAddress ; } public TaskAttemptFinishedEvent ( ) { } @ Override public HistoryEventType getEventType ( ) { return HistoryEventType . TASK_ATTEMPT_FINISHED ; } @ Override public boolean isRecoveryEvent ( ) { return true ; } @ Override public boolean isHistoryEvent ( ) { return true ; } public List < DataEventDependencyInfo > getDataEvents ( ) { return dataEvents ; } public TaskAttemptFinishedProto toProto ( ) throws IOException { TaskAttemptFinishedProto . Builder builder = TaskAttemptFinishedProto . newBuilder ( ) ; builder . setTaskAttemptId ( taskAttemptId . toString ( ) ) . setState ( state . ordinal ( ) ) . setCreationTime ( creationTime ) . setAllocationTime ( allocationTime ) . setStartTime ( startTime ) . setFinishTime ( finishTime ) ; if ( taskFailureType != null ) { builder . setTaskFailureType ( TezConverterUtils . failureTypeToProto ( taskFailureType ) ) ; } if ( creationCausalTA != null ) { builder . setCreationCausalTA ( creationCausalTA . toString ( ) ) ; } if ( diagnostics != null ) { builder . setDiagnostics ( diagnostics ) ; } if ( error != null ) { builder . setErrorEnum ( error . name ( ) ) ; } if ( tezCounters != null ) { builder . setCounters ( DagTypeConverters . convertTezCountersToProto ( tezCounters ) ) ; } if ( dataEvents != null && ! dataEvents . isEmpty ( ) ) { for ( DataEventDependencyInfo info : dataEvents ) { builder . addDataEvents ( DataEventDependencyInfo . toProto ( info ) ) ; } } if ( taGeneratedEvents != null && ! taGeneratedEvents . isEmpty ( ) ) { for ( TezEvent event : taGeneratedEvents ) { builder . addTaGeneratedEvents ( TezEventUtils . toProto ( event ) ) ; } } if ( containerId != null ) { builder . setContainerId ( containerId . toString ( ) ) ; } if ( nodeId != null ) { builder . setNodeId ( nodeId . toString ( ) ) ; } if ( nodeHttpAddress != null ) { builder . setNodeHttpAddress ( nodeHttpAddress ) ; } return builder . build ( ) ; } public void fromProto ( TaskAttemptFinishedProto proto ) throws IOException { this . taskAttemptId = TezTaskAttemptID . fromString ( proto . getTaskAttemptId ( ) ) ; this . state = TaskAttemptState . values ( ) [ proto . getState ( ) ] ; this . creationTime = proto . getCreationTime ( ) ; this . allocationTime = proto . getAllocationTime ( ) ; this . startTime = proto . getStartTime ( ) ; this . finishTime = proto . getFinishTime ( ) ; if ( proto . hasTaskFailureType ( ) ) { this . taskFailureType = TezConverterUtils . failureTypeFromProto ( proto . getTaskFailureType ( ) ) ; } if ( proto . hasCreationCausalTA ( ) ) { this . creationCausalTA = TezTaskAttemptID . fromString ( proto . getCreationCausalTA ( ) ) ; } if ( proto . hasDiagnostics ( ) ) { this . diagnostics = proto . getDiagnostics ( ) ; } if ( proto . hasErrorEnum ( ) ) { this . error = TaskAttemptTerminationCause . valueOf ( proto . getErrorEnum ( ) ) ; } if ( proto . hasCounters ( ) ) { this . tezCounters = DagTypeConverters . convertTezCountersFromProto ( proto . getCounters ( ) ) ; } if ( proto . getDataEventsCount ( ) > 0 ) { this . dataEvents = Lists . newArrayListWithCapacity ( proto . getDataEventsCount ( ) ) ; for ( DataEventDependencyInfoProto protoEvent : proto . getDataEventsList ( ) ) { this . dataEvents . add ( DataEventDependencyInfo . fromProto ( protoEvent ) ) ; } } if ( proto . getTaGeneratedEventsCount ( ) > 0 ) { this . taGeneratedEvents = Lists . newArrayListWithCapacity ( proto . getTaGeneratedEventsCount ( ) ) ; for ( TezEventProto eventProto : proto . getTaGeneratedEventsList ( ) ) { this . taGeneratedEvents . add ( TezEventUtils . fromProto ( eventProto ) ) ; } } if ( proto . hasContainerId ( ) ) { this . containerId = ConverterUtils . toContainerId ( proto . getContainerId ( ) ) ; } if ( proto . hasNodeId ( ) ) { this . nodeId = ConverterUtils . toNodeId ( proto . getNodeId ( ) ) ; } if ( proto . hasNodeHttpAddress ( ) ) { this . nodeHttpAddress = proto . getNodeHttpAddress ( ) ; } } @ Override public void toProtoStream ( OutputStream outputStream ) throws IOException { toProto ( ) . writeDelimitedTo ( outputStream ) ; } @ Override public void fromProtoStream ( InputStream inputStream ) throws IOException { TaskAttemptFinishedProto proto = TaskAttemptFinishedProto . parseDelimitedFrom ( inputStream ) ; if ( proto == null ) { throw new IOException ( ""No data found in stream"" ) ; } fromProto ( proto ) ; } @ Override public String toString ( ) { String counterStr = """" ; if ( state != TaskAttemptState . SUCCEEDED ) { counterStr = "", counters="" + ( tezCounters == null ? ""null"" : tezCounters . toString ( ) . replaceAll ( ""\\n"" , "", "" ) . replaceAll ( ""\\s+"" , "" "" ) ) ; } return ""vertexName="" + vertexName + "", taskAttemptId="" + taskAttemptId + "", creationTime="" + creationTime + "", allocationTime="" + allocationTime + "", startTime="" + startTime + "", finishTime="" + finishTime + "", timeTaken="" + ( finishTime - startTime ) + "", status="" + state . name ( ) + ( taskFailureType != null ? "", taskFailureType="" + taskFailureType : """" ) + ( error != null ? "", errorEnum="" + error . name ( ) : """" ) + ( diagnostics != null ? "", diagnostics="" + diagnostics : """" ) + ( containerId != null ? "", containerId="" + containerId . toString ( ) : """" ) + ( nodeId != null ? "", nodeId="" + nodeId . toString ( ) : """" ) + ( nodeHttpAddress != null ? "", nodeHttpAddress="" + nodeHttpAddress : """" ) + counterStr ; } public TezTaskAttemptID getTaskAttemptID ( ) { return taskAttemptId ; } public TezCounters getCounters ( ) { return tezCounters ; } public String getDiagnostics ( ) { return diagnostics ; } public TaskAttemptTerminationCause getTaskAttemptError ( ) { return error ; } public long getFinishTime ( ) { return finishTime ; } public TaskAttemptState getState ( ) { return state ; } public TaskFailureType getTaskFailureType ( ) { return taskFailureType ; } public long getStartTime ( ) { return startTime ; } public long getCreationTime ( ) { return creationTime ; } public long getAllocationTime ( ) { return allocationTime ; } public TezTaskAttemptID getCreationCausalTA ( ) { return creationCausalTA ; } public List < TezEvent > getTAGeneratedEvents ( ) { return taGeneratedEvents ; } public ContainerId getContainerId ( ) { return containerId ; } public NodeId getNodeId ( ) { return nodeId ; } public String getInProgressLogsUrl ( ) { return inProgressLogsUrl ; } public String getCompletedLogsUrl ( ) { return completedLogsUrl ; } public String getNodeHttpAddress ( ) { return nodeHttpAddress ; } }",Smelly
"public class PerformanceTest { @ Test public void test ( ) { } public static void main ( String [ ] args ) { long now = System . currentTimeMillis ( ) ; for ( long i = 0 ; i < 1000 * 1000 ; i ++ ) { Long . valueOf ( i ) ; } System . out . println ( String . format ( ""Trivial took %d millis"" , System . currentTimeMillis ( ) - now ) ) ; now = System . currentTimeMillis ( ) ; for ( long i = 0 ; i < 1000 * 1000 ; i ++ ) { Span s = Trace . start ( ""perf"" ) ; s . stop ( ) ; } System . out . println ( String . format ( ""Span Loop took %d millis"" , System . currentTimeMillis ( ) - now ) ) ; now = System . currentTimeMillis ( ) ; Trace . on ( ""test"" ) ; for ( long i = 0 ; i < 1000 * 1000 ; i ++ ) { Span s = Trace . start ( ""perf"" ) ; s . stop ( ) ; } Trace . off ( ) ; System . out . println ( String . format ( ""Trace took %d millis"" , System . currentTimeMillis ( ) - now ) ) ; } }",No
public class MasterKeyPBImpl extends ProtoBase < MasterKeyProto > implements MasterKey { MasterKeyProto proto = MasterKeyProto . getDefaultInstance ( ) ; MasterKeyProto . Builder builder = null ; boolean viaProto = false ; public MasterKeyPBImpl ( ) { builder = MasterKeyProto . newBuilder ( ) ; } public MasterKeyPBImpl ( MasterKeyProto proto ) { this . proto = proto ; viaProto = true ; } public synchronized MasterKeyProto getProto ( ) { proto = viaProto ? proto : builder . build ( ) ; viaProto = true ; return proto ; } private synchronized void maybeInitBuilder ( ) { if ( viaProto || builder == null ) { builder = MasterKeyProto . newBuilder ( proto ) ; } viaProto = false ; } @ Override public synchronized int getKeyId ( ) { MasterKeyProtoOrBuilder p = viaProto ? proto : builder ; return ( p . getKeyId ( ) ) ; } @ Override public synchronized void setKeyId ( int id ) { maybeInitBuilder ( ) ; builder . setKeyId ( ( id ) ) ; } @ Override public synchronized ByteBuffer getBytes ( ) { MasterKeyProtoOrBuilder p = viaProto ? proto : builder ; return convertFromProtoFormat ( p . getBytes ( ) ) ; } @ Override public synchronized void setBytes ( ByteBuffer bytes ) { maybeInitBuilder ( ) ; builder . setBytes ( convertToProtoFormat ( bytes ) ) ; } @ Override public int hashCode ( ) { return getKeyId ( ) ; } @ Override public boolean equals ( Object obj ) { if ( this == obj ) return true ; if ( ! ( obj instanceof MasterKey ) ) { return false ; } MasterKey other = ( MasterKey ) obj ; if ( this . getKeyId ( ) != other . getKeyId ( ) ) { return false ; } if ( ! this . getBytes ( ) . equals ( other . getBytes ( ) ) ) { return false ; } return true ; } },No
 static class ConverterRules extends HepInstruction { boolean guaranteed ; Set < RelOptRule > ruleSet ; void execute ( HepPlanner planner ) { planner . executeInstruction ( this ) ; } ,No
"public class DbAttribute extends Attribute implements ConfigurationNode { protected int type = TypesMapping . NOT_DEFINED ; protected boolean mandatory ; protected boolean primaryKey ; protected boolean generated ; protected int maxLength = - 1 ; protected int scale = - 1 ; protected int attributePrecision = - 1 ; public DbAttribute ( ) { super ( ) ; } public DbAttribute ( String name ) { super ( name ) ; } public DbAttribute ( String name , int type , DbEntity entity ) { this . setName ( name ) ; this . setType ( type ) ; this . setEntity ( entity ) ; } @ Override public DbEntity getEntity ( ) { return ( DbEntity ) super . getEntity ( ) ; } public < T > T acceptVisitor ( ConfigurationNodeVisitor < T > visitor ) { return visitor . visitDbAttribute ( this ) ; } @ Override public void encodeAsXML ( XMLEncoder encoder , ConfigurationNodeVisitor delegate ) { encoder . start ( ""db-attribute"" ) . attribute ( ""name"" , getName ( ) ) ; String type = TypesMapping . getSqlNameByType ( getType ( ) ) ; encoder . attribute ( ""type"" , type ) ; if ( isPrimaryKey ( ) ) { encoder . attribute ( ""isPrimaryKey"" , true ) ; if ( isGenerated ( ) ) { encoder . attribute ( ""isGenerated"" , true ) ; } } if ( isMandatory ( ) ) { encoder . attribute ( ""isMandatory"" , true ) ; } if ( getMaxLength ( ) > 0 ) { encoder . attribute ( ""length"" , getMaxLength ( ) ) ; } if ( getScale ( ) > 0 ) { encoder . attribute ( ""scale"" , getScale ( ) ) ; } if ( getAttributePrecision ( ) > 0 ) { encoder . attribute ( ""attributePrecision"" , getAttributePrecision ( ) ) ; } delegate . visitDbAttribute ( this ) ; encoder . end ( ) ; } public String getAliasedName ( String alias ) { return ( alias != null ) ? alias + '.' + this . getName ( ) : this . getName ( ) ; } public int getType ( ) { return type ; } public void setType ( int type ) { this . type = type ; } public boolean isPrimaryKey ( ) { return primaryKey ; } public boolean isForeignKey ( ) { String name = getName ( ) ; if ( name == null ) { return false ; } for ( DbRelationship relationship : getEntity ( ) . getRelationships ( ) ) { for ( DbJoin join : relationship . getJoins ( ) ) { if ( name . equals ( join . getSourceName ( ) ) ) { DbAttribute target = join . getTarget ( ) ; if ( target != null && target . isPrimaryKey ( ) ) { return true ; } } } } return false ; } public void setPrimaryKey ( boolean primaryKey ) { if ( this . primaryKey != primaryKey ) { this . primaryKey = primaryKey ; Entity e = this . getEntity ( ) ; if ( e instanceof DbAttributeListener ) { ( ( DbAttributeListener ) e ) . dbAttributeChanged ( new AttributeEvent ( this , this , e ) ) ; } } } public boolean isMandatory ( ) { return mandatory ; } public void setMandatory ( boolean mandatory ) { this . mandatory = mandatory ; } public int getMaxLength ( ) { return maxLength ; } public void setMaxLength ( int maxLength ) { this . maxLength = maxLength ; } public boolean isGenerated ( ) { return generated ; } public void setGenerated ( boolean generated ) { if ( this . generated != generated ) { this . generated = generated ; Entity e = this . getEntity ( ) ; if ( e instanceof DbAttributeListener ) { ( ( DbAttributeListener ) e ) . dbAttributeChanged ( new AttributeEvent ( this , this , e ) ) ; } } } public int getAttributePrecision ( ) { return attributePrecision ; } public void setAttributePrecision ( int attributePrecision ) { this . attributePrecision = attributePrecision ; } public int getScale ( ) { return scale ; } public void setScale ( int scale ) { this . scale = scale ; } @ Override public String toString ( ) { String res = ""DbAttr: "" ; String type = TypesMapping . getSqlNameByType ( getType ( ) ) ; res += type != null ? type : ""type("" + getType ( ) + "")"" ; res += "" "" + name ; if ( scale > - 1 || attributePrecision > - 1 ) { res += ""["" + scale + "", "" + attributePrecision + ""]"" ; } if ( maxLength > - 1 ) { res += ""["" + maxLength + ""]"" ; } if ( primaryKey ) { res += "" Primary Key "" ; } else if ( mandatory ) { res += "" Mandatory "" ; } return res ; } }",No
"@ Deprecated @ InterfaceAudience . Public @ InterfaceStability . Stable public class ParseException extends Exception { public ParseException ( Token currentTokenVal , int [ ] [ ] expectedTokenSequencesVal , String [ ] tokenImageVal ) { super ( """" ) ; specialConstructor = true ; currentToken = currentTokenVal ; expectedTokenSequences = expectedTokenSequencesVal ; tokenImage = tokenImageVal ; } public ParseException ( ) { super ( ) ; specialConstructor = false ; } public ParseException ( String message ) { super ( message ) ; specialConstructor = false ; } protected boolean specialConstructor ; public Token currentToken ; public int [ ] [ ] expectedTokenSequences ; public String [ ] tokenImage ; @ Override public String getMessage ( ) { if ( ! specialConstructor ) { return super . getMessage ( ) ; } StringBuffer expected = new StringBuffer ( ) ; int maxSize = 0 ; for ( int i = 0 ; i < expectedTokenSequences . length ; i ++ ) { if ( maxSize < expectedTokenSequences [ i ] . length ) { maxSize = expectedTokenSequences [ i ] . length ; } for ( int j = 0 ; j < expectedTokenSequences [ i ] . length ; j ++ ) { expected . append ( tokenImage [ expectedTokenSequences [ i ] [ j ] ] ) . append ( "" "" ) ; } if ( expectedTokenSequences [ i ] [ expectedTokenSequences [ i ] . length - 1 ] != 0 ) { expected . append ( ""..."" ) ; } expected . append ( eol ) . append ( ""    "" ) ; } String retval = ""Encountered \"""" ; Token tok = currentToken . next ; for ( int i = 0 ; i < maxSize ; i ++ ) { if ( i != 0 ) retval += "" "" ; if ( tok . kind == 0 ) { retval += tokenImage [ 0 ] ; break ; } retval += add_escapes ( tok . image ) ; tok = tok . next ; } retval += ""\"" at line "" + currentToken . next . beginLine + "", column "" + currentToken . next . beginColumn ; retval += ""."" + eol ; if ( expectedTokenSequences . length == 1 ) { retval += ""Was expecting:"" + eol + ""    "" ; } else { retval += ""Was expecting one of:"" + eol + ""    "" ; } retval += expected . toString ( ) ; return retval ; } protected String eol = System . getProperty ( ""line.separator"" , ""\n"" ) ; protected String add_escapes ( String str ) { StringBuffer retval = new StringBuffer ( ) ; char ch ; for ( int i = 0 ; i < str . length ( ) ; i ++ ) { switch ( str . charAt ( i ) ) { case 0 : continue ; case '\b' : retval . append ( ""\\b"" ) ; continue ; case '\t' : retval . append ( ""\\t"" ) ; continue ; case '\n' : retval . append ( ""\\n"" ) ; continue ; case '\f' : retval . append ( ""\\f"" ) ; continue ; case '\r' : retval . append ( ""\\r"" ) ; continue ; case '\""' : retval . append ( ""\\\"""" ) ; continue ; case '\'' : retval . append ( ""\\\'"" ) ; continue ; case '\\' : retval . append ( ""\\\\"" ) ; continue ; default : if ( ( ch = str . charAt ( i ) ) < 0x20 || ch > 0x7e ) { String s = ""0000"" + Integer . toString ( ch , 16 ) ; retval . append ( ""\\u"" + s . substring ( s . length ( ) - 4 , s . length ( ) ) ) ; } else { retval . append ( ch ) ; } continue ; } } return retval . toString ( ) ; } }",No
"public abstract class EasyFormatPlugin < T extends FormatPluginConfig > implements FormatPlugin { @ SuppressWarnings ( ""unused"" ) private static final org . slf4j . Logger logger = org . slf4j . LoggerFactory . getLogger ( EasyFormatPlugin . class ) ; private final BasicFormatMatcher matcher ; private final DrillbitContext context ; private final boolean readable ; private final boolean writable ; private final boolean blockSplittable ; private final Configuration fsConf ; private final StoragePluginConfig storageConfig ; protected final T formatConfig ; private final String name ; private final boolean compressible ; protected EasyFormatPlugin ( String name , DrillbitContext context , Configuration fsConf , StoragePluginConfig storageConfig , T formatConfig , boolean readable , boolean writable , boolean blockSplittable , boolean compressible , List < String > extensions , String defaultName ) { this . matcher = new BasicFormatMatcher ( this , fsConf , extensions , compressible ) ; this . readable = readable ; this . writable = writable ; this . context = context ; this . blockSplittable = blockSplittable ; this . compressible = compressible ; this . fsConf = fsConf ; this . storageConfig = storageConfig ; this . formatConfig = formatConfig ; this . name = name == null ? defaultName : name ; } @ Override public Configuration getFsConf ( ) { return fsConf ; } @ Override public DrillbitContext getContext ( ) { return context ; } @ Override public String getName ( ) { return name ; } public abstract boolean supportsPushDown ( ) ; public boolean isBlockSplittable ( ) { return blockSplittable ; } public boolean isCompressible ( ) { return compressible ; } public abstract RecordReader getRecordReader ( FragmentContext context , DrillFileSystem dfs , FileWork fileWork , List < SchemaPath > columns , String userName ) throws ExecutionSetupException ; @ SuppressWarnings ( ""resource"" ) CloseableRecordBatch getReaderBatch ( FragmentContext context , EasySubScan scan ) throws ExecutionSetupException { final ImplicitColumnExplorer columnExplorer = new ImplicitColumnExplorer ( context , scan . getColumns ( ) ) ; if ( ! columnExplorer . isStarQuery ( ) ) { scan = new EasySubScan ( scan . getUserName ( ) , scan . getWorkUnits ( ) , scan . getFormatPlugin ( ) , columnExplorer . getTableColumns ( ) , scan . getSelectionRoot ( ) ) ; scan . setOperatorId ( scan . getOperatorId ( ) ) ; } OperatorContext oContext = context . newOperatorContext ( scan ) ; final DrillFileSystem dfs ; try { dfs = oContext . newFileSystem ( fsConf ) ; } catch ( IOException e ) { throw new ExecutionSetupException ( String . format ( ""Failed to create FileSystem: %s"" , e . getMessage ( ) ) , e ) ; } List < RecordReader > readers = Lists . newArrayList ( ) ; List < Map < String , String > > implicitColumns = Lists . newArrayList ( ) ; Map < String , String > mapWithMaxColumns = Maps . newLinkedHashMap ( ) ; for ( FileWork work : scan . getWorkUnits ( ) ) { RecordReader recordReader = getRecordReader ( context , dfs , work , scan . getColumns ( ) , scan . getUserName ( ) ) ; readers . add ( recordReader ) ; Map < String , String > implicitValues = columnExplorer . populateImplicitColumns ( work , scan . getSelectionRoot ( ) ) ; implicitColumns . add ( implicitValues ) ; if ( implicitValues . size ( ) > mapWithMaxColumns . size ( ) ) { mapWithMaxColumns = implicitValues ; } } Map < String , String > diff = Maps . transformValues ( mapWithMaxColumns , Functions . constant ( ( String ) null ) ) ; for ( Map < String , String > map : implicitColumns ) { map . putAll ( Maps . difference ( map , diff ) . entriesOnlyOnRight ( ) ) ; } return new ScanBatch ( scan , context , oContext , readers . iterator ( ) , implicitColumns ) ; } public abstract RecordWriter getRecordWriter ( FragmentContext context , EasyWriter writer ) throws IOException ; public CloseableRecordBatch getWriterBatch ( FragmentContext context , RecordBatch incoming , EasyWriter writer ) throws ExecutionSetupException { try { return new WriterRecordBatch ( writer , incoming , context , getRecordWriter ( context , writer ) ) ; } catch ( IOException e ) { throw new ExecutionSetupException ( String . format ( ""Failed to create the WriterRecordBatch. %s"" , e . getMessage ( ) ) , e ) ; } } protected ScanStats getScanStats ( final PlannerSettings settings , final EasyGroupScan scan ) { long data = 0 ; for ( final CompleteFileWork work : scan . getWorkIterable ( ) ) { data += work . getTotalBytes ( ) ; } final long estRowCount = data / 1024 ; return new ScanStats ( GroupScanProperty . NO_EXACT_ROW_COUNT , estRowCount , 1 , data ) ; } @ Override public AbstractWriter getWriter ( PhysicalOperator child , String location , List < String > partitionColumns ) throws IOException { return new EasyWriter ( child , location , partitionColumns , this ) ; } @ Override public AbstractGroupScan getGroupScan ( String userName , FileSelection selection , List < SchemaPath > columns ) throws IOException { return new EasyGroupScan ( userName , selection , this , columns , selection . selectionRoot ) ; } @ Override public T getConfig ( ) { return formatConfig ; } @ Override public StoragePluginConfig getStorageConfig ( ) { return storageConfig ; } @ Override public boolean supportsRead ( ) { return readable ; } @ Override public boolean supportsWrite ( ) { return writable ; } @ Override public boolean supportsAutoPartitioning ( ) { return false ; } @ Override public FormatMatcher getMatcher ( ) { return matcher ; } @ Override public Set < StoragePluginOptimizerRule > getOptimizerRules ( ) { return ImmutableSet . of ( ) ; } public abstract int getReaderOperatorType ( ) ; public abstract int getWriterOperatorType ( ) ; }",Smelly
@ Private @ Unstable public class GetApplicationReportResponsePBImpl extends GetApplicationReportResponse { GetApplicationReportResponseProto proto = GetApplicationReportResponseProto . getDefaultInstance ( ) ; GetApplicationReportResponseProto . Builder builder = null ; boolean viaProto = false ; private ApplicationReport applicationReport = null ; public GetApplicationReportResponsePBImpl ( ) { builder = GetApplicationReportResponseProto . newBuilder ( ) ; } public GetApplicationReportResponsePBImpl ( GetApplicationReportResponseProto proto ) { this . proto = proto ; viaProto = true ; } public GetApplicationReportResponseProto getProto ( ) { mergeLocalToProto ( ) ; proto = viaProto ? proto : builder . build ( ) ; viaProto = true ; return proto ; } @ Override public int hashCode ( ) { return getProto ( ) . hashCode ( ) ; } @ Override public boolean equals ( Object other ) { if ( other == null ) return false ; if ( other . getClass ( ) . isAssignableFrom ( this . getClass ( ) ) ) { return this . getProto ( ) . equals ( this . getClass ( ) . cast ( other ) . getProto ( ) ) ; } return false ; } @ Override public String toString ( ) { return TextFormat . shortDebugString ( getProto ( ) ) ; } private void mergeLocalToBuilder ( ) { if ( this . applicationReport != null ) { builder . setApplicationReport ( convertToProtoFormat ( this . applicationReport ) ) ; } } private void mergeLocalToProto ( ) { if ( viaProto ) maybeInitBuilder ( ) ; mergeLocalToBuilder ( ) ; proto = builder . build ( ) ; viaProto = true ; } private void maybeInitBuilder ( ) { if ( viaProto || builder == null ) { builder = GetApplicationReportResponseProto . newBuilder ( proto ) ; } viaProto = false ; } @ Override public ApplicationReport getApplicationReport ( ) { GetApplicationReportResponseProtoOrBuilder p = viaProto ? proto : builder ; if ( this . applicationReport != null ) { return this . applicationReport ; } if ( ! p . hasApplicationReport ( ) ) { return null ; } this . applicationReport = convertFromProtoFormat ( p . getApplicationReport ( ) ) ; return this . applicationReport ; } @ Override public void setApplicationReport ( ApplicationReport applicationMaster ) { maybeInitBuilder ( ) ; if ( applicationMaster == null ) builder . clearApplicationReport ( ) ; this . applicationReport = applicationMaster ; } private ApplicationReportPBImpl convertFromProtoFormat ( ApplicationReportProto p ) { return new ApplicationReportPBImpl ( p ) ; } private ApplicationReportProto convertToProtoFormat ( ApplicationReport t ) { return ( ( ApplicationReportPBImpl ) t ) . getProto ( ) ; } },No
"class SQLiteBigDecimalType implements ExtendedType < BigDecimal > { @ Override public String getClassName ( ) { return BigDecimal . class . getName ( ) ; } @ Override public BigDecimal materializeObject ( CallableStatement rs , int index , int type ) throws Exception { String string = rs . getString ( index ) ; return string == null ? null : new BigDecimal ( string ) ; } @ Override public BigDecimal materializeObject ( ResultSet rs , int index , int type ) throws Exception { String string = rs . getString ( index ) ; return string == null ? null : new BigDecimal ( string ) ; } @ Override public void setJdbcObject ( PreparedStatement st , BigDecimal val , int pos , int type , int scale ) throws Exception { if ( scale != - 1 ) { st . setObject ( pos , val , type , scale ) ; } else { st . setObject ( pos , val , type ) ; } } @ Override public String toString ( BigDecimal value ) { if ( value == null ) { return ""NULL"" ; } return value . toString ( ) ; } }",No
"public class ShapeDetails { String serdeClassName ; Map < String , String > serdeProps ; List < String > columnNames ; transient StructObjectInspector OI ; transient SerDe serde ; transient RowResolver rr ; transient TypeCheckCtx typeCheckCtx ; static { PTFUtils . makeTransient ( ShapeDetails . class , ""OI"" , ""serde"" , ""rr"" , ""typeCheckCtx"" ) ; } public String getSerdeClassName ( ) { return serdeClassName ; } public void setSerdeClassName ( String serdeClassName ) { this . serdeClassName = serdeClassName ; } public Map < String , String > getSerdeProps ( ) { return serdeProps ; } public void setSerdeProps ( Map < String , String > serdeProps ) { this . serdeProps = serdeProps ; } public List < String > getColumnNames ( ) { return columnNames ; } public void setColumnNames ( List < String > columnNames ) { this . columnNames = columnNames ; } public StructObjectInspector getOI ( ) { return OI ; } public void setOI ( StructObjectInspector oI ) { OI = oI ; } public SerDe getSerde ( ) { return serde ; } public void setSerde ( SerDe serde ) { this . serde = serde ; } public RowResolver getRr ( ) { return rr ; } public void setRr ( RowResolver rr ) { this . rr = rr ; } public TypeCheckCtx getTypeCheckCtx ( ) { return typeCheckCtx ; } public void setTypeCheckCtx ( TypeCheckCtx typeCheckCtx ) { this . typeCheckCtx = typeCheckCtx ; } }",Smelly
"public class ExtendFuseki_AddService_2 { static { LogCtl . setLog4j ( ) ; } static int PORT = WebLib . choosePort ( ) ; static String SERVER_URL = ""http://localhost:"" + PORT + ""/"" ; static String DATASET = ""dataset"" ; public static void main ( String ... args ) { Operation myOperation = Operation . alloc ( ""http://example/special2"" , ""special2"" , ""Custom operation"" ) ; String queryEndpoint = ""q"" ; String customEndpoint = ""x"" ; DatasetGraph dsg = DatasetGraphFactory . createTxnMem ( ) ; DataService dataService = new DataService ( dsg ) ; FusekiConfig . addServiceEP ( dataService , myOperation , customEndpoint ) ; FusekiConfig . addServiceEP ( dataService , Operation . Query , queryEndpoint ) ; ActionService customHandler = new ExampleService ( ) ; FusekiServer server = FusekiServer . create ( ) . port ( PORT ) . verbose ( true ) . registerOperation ( myOperation , customHandler ) . add ( DATASET , dataService ) . build ( ) ; server . start ( ) ; String customOperationURL = SERVER_URL + DATASET + ""/"" + customEndpoint ; String queryOperationURL = SERVER_URL + DATASET + ""/"" + queryEndpoint ; Query query = QueryFactory . create ( ""ASK{}"" ) ; try { try ( QueryExecution qExec = QueryExecutionFactory . sparqlService ( queryOperationURL , query ) ) { qExec . execAsk ( ) ; } try ( QueryExecution qExec = QueryExecutionFactory . sparqlService ( SERVER_URL + DATASET + ""/sparql"" , query ) ) { qExec . execAsk ( ) ; throw new RuntimeException ( ""Didn't fail"" ) ; } catch ( QueryExceptionHTTP ex ) { if ( ex . getStatusCode ( ) != HttpSC . NOT_FOUND_404 ) { throw new RuntimeException ( ""Not a 404"" , ex ) ; } } String s1 = HttpOp . execHttpGetString ( customOperationURL ) ; if ( s1 == null ) throw new RuntimeException ( ""Failed: "" + customOperationURL ) ; } finally { server . stop ( ) ; } } }",No
"public class TestManualCheckpoint extends BspCase { public TestManualCheckpoint ( ) { super ( TestManualCheckpoint . class . getName ( ) ) ; } @ Test public void testBspCheckpoint ( ) throws IOException , InterruptedException , ClassNotFoundException { Path checkpointsDir = getTempPath ( ""checkPointsForTesting"" ) ; Path outputPath = getTempPath ( getCallingMethodName ( ) ) ; GiraphConfiguration conf = new GiraphConfiguration ( ) ; conf . setComputationClass ( SimpleCheckpoint . SimpleCheckpointComputation . class ) ; conf . setWorkerContextClass ( SimpleCheckpoint . SimpleCheckpointVertexWorkerContext . class ) ; conf . setMasterComputeClass ( SimpleCheckpoint . SimpleCheckpointVertexMasterCompute . class ) ; conf . setVertexInputFormatClass ( SimpleSuperstepVertexInputFormat . class ) ; conf . setVertexOutputFormatClass ( SimpleSuperstepVertexOutputFormat . class ) ; GiraphJob job = prepareJob ( getCallingMethodName ( ) , conf , outputPath ) ; GiraphConfiguration configuration = job . getConfiguration ( ) ; GiraphConstants . CHECKPOINT_DIRECTORY . set ( configuration , checkpointsDir . toString ( ) ) ; GiraphConstants . CLEANUP_CHECKPOINTS_AFTER_SUCCESS . set ( configuration , false ) ; configuration . setCheckpointFrequency ( 2 ) ; assertTrue ( job . run ( true ) ) ; long idSum = 0 ; if ( ! runningInDistributedMode ( ) ) { FileStatus fileStatus = getSinglePartFileStatus ( job . getConfiguration ( ) , outputPath ) ; idSum = SimpleCheckpoint . SimpleCheckpointVertexWorkerContext . getFinalSum ( ) ; System . out . println ( ""testBspCheckpoint: idSum = "" + idSum + "" fileLen = "" + fileStatus . getLen ( ) ) ; } System . out . println ( ""testBspCheckpoint: Restarting from superstep 2"" + "" with checkpoint path = "" + checkpointsDir ) ; outputPath = getTempPath ( getCallingMethodName ( ) + ""Restarted"" ) ; conf = new GiraphConfiguration ( ) ; conf . setComputationClass ( SimpleCheckpoint . SimpleCheckpointComputation . class ) ; conf . setWorkerContextClass ( SimpleCheckpoint . SimpleCheckpointVertexWorkerContext . class ) ; conf . setMasterComputeClass ( SimpleCheckpoint . SimpleCheckpointVertexMasterCompute . class ) ; conf . setVertexInputFormatClass ( SimpleSuperstepVertexInputFormat . class ) ; conf . setVertexOutputFormatClass ( SimpleSuperstepVertexOutputFormat . class ) ; GiraphJob restartedJob = prepareJob ( getCallingMethodName ( ) + ""Restarted"" , conf , outputPath ) ; configuration . setMasterComputeClass ( SimpleCheckpoint . SimpleCheckpointVertexMasterCompute . class ) ; GiraphConstants . CHECKPOINT_DIRECTORY . set ( restartedJob . getConfiguration ( ) , checkpointsDir . toString ( ) ) ; assertTrue ( restartedJob . run ( true ) ) ; if ( ! runningInDistributedMode ( ) ) { long idSumRestarted = SimpleCheckpoint . SimpleCheckpointVertexWorkerContext . getFinalSum ( ) ; System . out . println ( ""testBspCheckpoint: idSumRestarted = "" + idSumRestarted ) ; assertEquals ( idSum , idSumRestarted ) ; } } }",No
@ Entity public class M21UniEmployee { @ Id public String empid ; @ Version private int version ; @ ManyToOne M21UniDepartment department ; public M21UniDepartment getDepartment ( ) { return department ; } public void setDepartment ( M21UniDepartment department ) { this . department = department ; } public String getEmpid ( ) { return empid ; } public void setEmpid ( String empid ) { this . empid = empid ; } public int getVersion ( ) { return version ; } public void setVersion ( int version ) { this . version = version ; } public String getName ( ) { return name ; } public void setName ( String name ) { this . name = name ; } public String name ; public float salary ; public float getSalary ( ) { return salary ; } public void setSalary ( float salary ) { this . salary = salary ; } },Smelly
"@ InterfaceAudience . Private public class FSTableDescriptors implements TableDescriptors { private static final Logger LOG = LoggerFactory . getLogger ( FSTableDescriptors . class ) ; private final FileSystem fs ; private final Path rootdir ; private final boolean fsreadonly ; private volatile boolean usecache ; private volatile boolean fsvisited ; @ VisibleForTesting long cachehits = 0 ; @ VisibleForTesting long invocations = 0 ; static final String TABLEINFO_FILE_PREFIX = "".tableinfo"" ; static final String TABLEINFO_DIR = "".tabledesc"" ; static final String TMP_DIR = "".tmp"" ; private final Map < TableName , TableDescriptor > cache = new ConcurrentHashMap < > ( ) ; private final TableDescriptor metaTableDescriptor ; public FSTableDescriptors ( final Configuration conf ) throws IOException { this ( conf , FSUtils . getCurrentFileSystem ( conf ) , FSUtils . getRootDir ( conf ) ) ; } public FSTableDescriptors ( final Configuration conf , final FileSystem fs , final Path rootdir ) throws IOException { this ( conf , fs , rootdir , false , true ) ; } public FSTableDescriptors ( final Configuration conf , final FileSystem fs , final Path rootdir , final boolean fsreadonly , final boolean usecache ) throws IOException { this ( conf , fs , rootdir , fsreadonly , usecache , null ) ; } public FSTableDescriptors ( final Configuration conf , final FileSystem fs , final Path rootdir , final boolean fsreadonly , final boolean usecache , Function < TableDescriptorBuilder , TableDescriptorBuilder > metaObserver ) throws IOException { this . fs = fs ; this . rootdir = rootdir ; this . fsreadonly = fsreadonly ; this . usecache = usecache ; this . metaTableDescriptor = metaObserver == null ? createMetaTableDescriptor ( conf ) : metaObserver . apply ( createMetaTableDescriptorBuilder ( conf ) ) . build ( ) ; } @ VisibleForTesting public static TableDescriptorBuilder createMetaTableDescriptorBuilder ( final Configuration conf ) throws IOException { return TableDescriptorBuilder . newBuilder ( TableName . META_TABLE_NAME ) . setColumnFamily ( ColumnFamilyDescriptorBuilder . newBuilder ( HConstants . CATALOG_FAMILY ) . setMaxVersions ( conf . getInt ( HConstants . HBASE_META_VERSIONS , HConstants . DEFAULT_HBASE_META_VERSIONS ) ) . setInMemory ( true ) . setBlocksize ( conf . getInt ( HConstants . HBASE_META_BLOCK_SIZE , HConstants . DEFAULT_HBASE_META_BLOCK_SIZE ) ) . setScope ( HConstants . REPLICATION_SCOPE_LOCAL ) . setBloomFilterType ( BloomType . NONE ) . build ( ) ) . setColumnFamily ( ColumnFamilyDescriptorBuilder . newBuilder ( HConstants . TABLE_FAMILY ) . setMaxVersions ( conf . getInt ( HConstants . HBASE_META_VERSIONS , HConstants . DEFAULT_HBASE_META_VERSIONS ) ) . setInMemory ( true ) . setBlocksize ( 8 * 1024 ) . setScope ( HConstants . REPLICATION_SCOPE_LOCAL ) . setBloomFilterType ( BloomType . NONE ) . build ( ) ) . setColumnFamily ( ColumnFamilyDescriptorBuilder . newBuilder ( HConstants . REPLICATION_BARRIER_FAMILY ) . setMaxVersions ( HConstants . ALL_VERSIONS ) . setInMemory ( true ) . setScope ( HConstants . REPLICATION_SCOPE_LOCAL ) . setBloomFilterType ( BloomType . NONE ) . build ( ) ) . setCoprocessor ( CoprocessorDescriptorBuilder . newBuilder ( MultiRowMutationEndpoint . class . getName ( ) ) . setPriority ( Coprocessor . PRIORITY_SYSTEM ) . build ( ) ) ; } @ VisibleForTesting public static TableDescriptor createMetaTableDescriptor ( final Configuration conf ) throws IOException { return createMetaTableDescriptorBuilder ( conf ) . build ( ) ; } @ Override public void setCacheOn ( ) throws IOException { this . cache . clear ( ) ; this . usecache = true ; } @ Override public void setCacheOff ( ) throws IOException { this . usecache = false ; this . cache . clear ( ) ; } @ VisibleForTesting public boolean isUsecache ( ) { return this . usecache ; } @ Override @ Nullable public TableDescriptor get ( final TableName tablename ) throws IOException { invocations ++ ; if ( TableName . META_TABLE_NAME . equals ( tablename ) ) { cachehits ++ ; return metaTableDescriptor ; } if ( HConstants . HBASE_NON_USER_TABLE_DIRS . contains ( tablename . getNameAsString ( ) ) ) { throw new IOException ( ""No descriptor found for non table = "" + tablename ) ; } if ( usecache ) { TableDescriptor cachedtdm = this . cache . get ( tablename ) ; if ( cachedtdm != null ) { cachehits ++ ; return cachedtdm ; } } TableDescriptor tdmt = null ; try { tdmt = getTableDescriptorFromFs ( fs , rootdir , tablename ) ; } catch ( NullPointerException e ) { LOG . debug ( ""Exception during readTableDecriptor. Current table name = "" + tablename , e ) ; } catch ( TableInfoMissingException e ) { } catch ( IOException ioe ) { LOG . debug ( ""Exception during readTableDecriptor. Current table name = "" + tablename , ioe ) ; } if ( usecache && tdmt != null ) { this . cache . put ( tablename , tdmt ) ; } return tdmt ; } @ Override public Map < String , TableDescriptor > getAll ( ) throws IOException { Map < String , TableDescriptor > tds = new TreeMap < > ( ) ; if ( fsvisited && usecache ) { for ( Map . Entry < TableName , TableDescriptor > entry : this . cache . entrySet ( ) ) { tds . put ( entry . getKey ( ) . getNameWithNamespaceInclAsString ( ) , entry . getValue ( ) ) ; } tds . put ( this . metaTableDescriptor . getTableName ( ) . getNameAsString ( ) , metaTableDescriptor ) ; } else { LOG . trace ( ""Fetching table descriptors from the filesystem."" ) ; boolean allvisited = true ; for ( Path d : FSUtils . getTableDirs ( fs , rootdir ) ) { TableDescriptor htd = null ; try { htd = get ( FSUtils . getTableName ( d ) ) ; } catch ( FileNotFoundException fnfe ) { LOG . warn ( ""Trouble retrieving htd"" , fnfe ) ; } if ( htd == null ) { allvisited = false ; continue ; } else { tds . put ( htd . getTableName ( ) . getNameWithNamespaceInclAsString ( ) , htd ) ; } fsvisited = allvisited ; } } return tds ; } @ Override public Map < String , TableDescriptor > getByNamespace ( String name ) throws IOException { Map < String , TableDescriptor > htds = new TreeMap < > ( ) ; List < Path > tableDirs = FSUtils . getLocalTableDirs ( fs , FSUtils . getNamespaceDir ( rootdir , name ) ) ; for ( Path d : tableDirs ) { TableDescriptor htd = null ; try { htd = get ( FSUtils . getTableName ( d ) ) ; } catch ( FileNotFoundException fnfe ) { LOG . warn ( ""Trouble retrieving htd"" , fnfe ) ; } if ( htd == null ) continue ; htds . put ( FSUtils . getTableName ( d ) . getNameAsString ( ) , htd ) ; } return htds ; } @ Override public void add ( TableDescriptor htd ) throws IOException { if ( fsreadonly ) { throw new NotImplementedException ( ""Cannot add a table descriptor - in read only mode"" ) ; } TableName tableName = htd . getTableName ( ) ; if ( TableName . META_TABLE_NAME . equals ( tableName ) ) { throw new NotImplementedException ( HConstants . NOT_IMPLEMENTED ) ; } if ( HConstants . HBASE_NON_USER_TABLE_DIRS . contains ( tableName . getNameAsString ( ) ) ) { throw new NotImplementedException ( ""Cannot add a table descriptor for a reserved subdirectory name: "" + htd . getTableName ( ) . getNameAsString ( ) ) ; } updateTableDescriptor ( htd ) ; } @ Override public TableDescriptor remove ( final TableName tablename ) throws IOException { if ( fsreadonly ) { throw new NotImplementedException ( ""Cannot remove a table descriptor - in read only mode"" ) ; } Path tabledir = getTableDir ( tablename ) ; if ( this . fs . exists ( tabledir ) ) { if ( ! this . fs . delete ( tabledir , true ) ) { throw new IOException ( ""Failed delete of "" + tabledir . toString ( ) ) ; } } TableDescriptor descriptor = this . cache . remove ( tablename ) ; return descriptor ; } public boolean isTableInfoExists ( TableName tableName ) throws IOException { return getTableInfoPath ( tableName ) != null ; } private FileStatus getTableInfoPath ( final TableName tableName ) throws IOException { Path tableDir = getTableDir ( tableName ) ; return getTableInfoPath ( tableDir ) ; } private FileStatus getTableInfoPath ( Path tableDir ) throws IOException { return getTableInfoPath ( fs , tableDir , ! fsreadonly ) ; } public static FileStatus getTableInfoPath ( FileSystem fs , Path tableDir ) throws IOException { return getTableInfoPath ( fs , tableDir , false ) ; } private static FileStatus getTableInfoPath ( FileSystem fs , Path tableDir , boolean removeOldFiles ) throws IOException { Path tableInfoDir = new Path ( tableDir , TABLEINFO_DIR ) ; return getCurrentTableInfoStatus ( fs , tableInfoDir , removeOldFiles ) ; } static FileStatus getCurrentTableInfoStatus ( FileSystem fs , Path dir , boolean removeOldFiles ) throws IOException { FileStatus [ ] status = FSUtils . listStatus ( fs , dir , TABLEINFO_PATHFILTER ) ; if ( status == null || status . length < 1 ) return null ; FileStatus mostCurrent = null ; for ( FileStatus file : status ) { if ( mostCurrent == null || TABLEINFO_FILESTATUS_COMPARATOR . compare ( file , mostCurrent ) < 0 ) { mostCurrent = file ; } } if ( removeOldFiles && status . length > 1 ) { for ( FileStatus file : status ) { Path path = file . getPath ( ) ; if ( ! file . equals ( mostCurrent ) ) { if ( ! fs . delete ( file . getPath ( ) , false ) ) { LOG . warn ( ""Failed cleanup of "" + path ) ; } else { LOG . debug ( ""Cleaned up old tableinfo file "" + path ) ; } } } } return mostCurrent ; } @ VisibleForTesting static final Comparator < FileStatus > TABLEINFO_FILESTATUS_COMPARATOR = new Comparator < FileStatus > ( ) { @ Override public int compare ( FileStatus left , FileStatus right ) { return right . compareTo ( left ) ; } } ; @ VisibleForTesting Path getTableDir ( final TableName tableName ) { return FSUtils . getTableDir ( rootdir , tableName ) ; } private static final PathFilter TABLEINFO_PATHFILTER = new PathFilter ( ) { @ Override public boolean accept ( Path p ) { return p . getName ( ) . startsWith ( TABLEINFO_FILE_PREFIX ) ; } } ; @ VisibleForTesting static final int WIDTH_OF_SEQUENCE_ID = 10 ; private static String formatTableInfoSequenceId ( final int number ) { byte [ ] b = new byte [ WIDTH_OF_SEQUENCE_ID ] ; int d = Math . abs ( number ) ; for ( int i = b . length - 1 ; i >= 0 ; i -- ) { b [ i ] = ( byte ) ( ( d % 10 ) + '0' ) ; d /= 10 ; } return Bytes . toString ( b ) ; } private static final Pattern TABLEINFO_FILE_REGEX = Pattern . compile ( TABLEINFO_FILE_PREFIX + ""(\\.([0-9]{"" + WIDTH_OF_SEQUENCE_ID + ""}))?$"" ) ; @ VisibleForTesting static int getTableInfoSequenceId ( final Path p ) { if ( p == null ) return 0 ; Matcher m = TABLEINFO_FILE_REGEX . matcher ( p . getName ( ) ) ; if ( ! m . matches ( ) ) throw new IllegalArgumentException ( p . toString ( ) ) ; String suffix = m . group ( 2 ) ; if ( suffix == null || suffix . length ( ) <= 0 ) return 0 ; return Integer . parseInt ( m . group ( 2 ) ) ; } @ VisibleForTesting static String getTableInfoFileName ( final int sequenceid ) { return TABLEINFO_FILE_PREFIX + ""."" + formatTableInfoSequenceId ( sequenceid ) ; } public static TableDescriptor getTableDescriptorFromFs ( FileSystem fs , Path hbaseRootDir , TableName tableName ) throws IOException { Path tableDir = FSUtils . getTableDir ( hbaseRootDir , tableName ) ; return getTableDescriptorFromFs ( fs , tableDir ) ; } public static TableDescriptor getTableDescriptorFromFs ( FileSystem fs , Path tableDir ) throws IOException { FileStatus status = getTableInfoPath ( fs , tableDir , false ) ; if ( status == null ) { throw new TableInfoMissingException ( ""No table descriptor file under "" + tableDir ) ; } return readTableDescriptor ( fs , status ) ; } private static TableDescriptor readTableDescriptor ( FileSystem fs , FileStatus status ) throws IOException { int len = Ints . checkedCast ( status . getLen ( ) ) ; byte [ ] content = new byte [ len ] ; FSDataInputStream fsDataInputStream = fs . open ( status . getPath ( ) ) ; try { fsDataInputStream . readFully ( content ) ; } finally { fsDataInputStream . close ( ) ; } TableDescriptor htd = null ; try { htd = TableDescriptorBuilder . parseFrom ( content ) ; } catch ( DeserializationException e ) { throw new IOException ( ""content="" + Bytes . toShort ( content ) , e ) ; } return htd ; } @ VisibleForTesting Path updateTableDescriptor ( TableDescriptor td ) throws IOException { if ( fsreadonly ) { throw new NotImplementedException ( ""Cannot update a table descriptor - in read only mode"" ) ; } TableName tableName = td . getTableName ( ) ; Path tableDir = getTableDir ( tableName ) ; Path p = writeTableDescriptor ( fs , td , tableDir , getTableInfoPath ( tableDir ) ) ; if ( p == null ) throw new IOException ( ""Failed update"" ) ; LOG . info ( ""Updated tableinfo="" + p ) ; if ( usecache ) { this . cache . put ( td . getTableName ( ) , td ) ; } return p ; } public void deleteTableDescriptorIfExists ( TableName tableName ) throws IOException { if ( fsreadonly ) { throw new NotImplementedException ( ""Cannot delete a table descriptor - in read only mode"" ) ; } Path tableDir = getTableDir ( tableName ) ; Path tableInfoDir = new Path ( tableDir , TABLEINFO_DIR ) ; deleteTableDescriptorFiles ( fs , tableInfoDir , Integer . MAX_VALUE ) ; } private static void deleteTableDescriptorFiles ( FileSystem fs , Path dir , int maxSequenceId ) throws IOException { FileStatus [ ] status = FSUtils . listStatus ( fs , dir , TABLEINFO_PATHFILTER ) ; for ( FileStatus file : status ) { Path path = file . getPath ( ) ; int sequenceId = getTableInfoSequenceId ( path ) ; if ( sequenceId <= maxSequenceId ) { boolean success = FSUtils . delete ( fs , path , false ) ; if ( success ) { LOG . debug ( ""Deleted "" + path ) ; } else { LOG . error ( ""Failed to delete table descriptor at "" + path ) ; } } } } private static Path writeTableDescriptor ( final FileSystem fs , final TableDescriptor htd , final Path tableDir , final FileStatus currentDescriptorFile ) throws IOException { Path tmpTableDir = new Path ( tableDir , TMP_DIR ) ; Path tableInfoDir = new Path ( tableDir , TABLEINFO_DIR ) ; int currentSequenceId = currentDescriptorFile == null ? 0 : getTableInfoSequenceId ( currentDescriptorFile . getPath ( ) ) ; int newSequenceId = currentSequenceId ; int retries = 10 ; int retrymax = currentSequenceId + retries ; Path tableInfoDirPath = null ; do { newSequenceId += 1 ; String filename = getTableInfoFileName ( newSequenceId ) ; Path tempPath = new Path ( tmpTableDir , filename ) ; if ( fs . exists ( tempPath ) ) { LOG . debug ( tempPath + "" exists; retrying up to "" + retries + "" times"" ) ; continue ; } tableInfoDirPath = new Path ( tableInfoDir , filename ) ; try { writeTD ( fs , tempPath , htd ) ; fs . mkdirs ( tableInfoDirPath . getParent ( ) ) ; if ( ! fs . rename ( tempPath , tableInfoDirPath ) ) { throw new IOException ( ""Failed rename of "" + tempPath + "" to "" + tableInfoDirPath ) ; } LOG . debug ( ""Wrote into "" + tableInfoDirPath ) ; } catch ( IOException ioe ) { LOG . debug ( ""Failed write and/or rename; retrying"" , ioe ) ; if ( ! FSUtils . deleteDirectory ( fs , tempPath ) ) { LOG . warn ( ""Failed cleanup of "" + tempPath ) ; } tableInfoDirPath = null ; continue ; } break ; } while ( newSequenceId < retrymax ) ; if ( tableInfoDirPath != null ) { deleteTableDescriptorFiles ( fs , tableInfoDir , newSequenceId - 1 ) ; } return tableInfoDirPath ; } private static void writeTD ( final FileSystem fs , final Path p , final TableDescriptor htd ) throws IOException { FSDataOutputStream out = fs . create ( p , false ) ; try { out . write ( TableDescriptorBuilder . toByteArray ( htd ) ) ; } finally { out . close ( ) ; } } public boolean createTableDescriptor ( TableDescriptor htd ) throws IOException { return createTableDescriptor ( htd , false ) ; } public boolean createTableDescriptor ( TableDescriptor htd , boolean forceCreation ) throws IOException { Path tableDir = getTableDir ( htd . getTableName ( ) ) ; return createTableDescriptorForTableDirectory ( tableDir , htd , forceCreation ) ; } public boolean createTableDescriptorForTableDirectory ( Path tableDir , TableDescriptor htd , boolean forceCreation ) throws IOException { if ( fsreadonly ) { throw new NotImplementedException ( ""Cannot create a table descriptor - in read only mode"" ) ; } FileStatus status = getTableInfoPath ( fs , tableDir ) ; if ( status != null ) { LOG . debug ( ""Current path="" + status . getPath ( ) ) ; if ( ! forceCreation ) { if ( fs . exists ( status . getPath ( ) ) && status . getLen ( ) > 0 ) { if ( readTableDescriptor ( fs , status ) . equals ( htd ) ) { LOG . trace ( ""TableInfo already exists.. Skipping creation"" ) ; return false ; } } } } Path p = writeTableDescriptor ( fs , htd , tableDir , status ) ; return p != null ; } }",No
"public abstract class _IvImpl extends IvBase { private static final long serialVersionUID = 1L ; public static final String ID_PK_COLUMN = ""ID"" ; public static final Property < String > ATTR1 = Property . create ( ""attr1"" , String . class ) ; public static final Property < String > ATTR2 = Property . create ( ""attr2"" , String . class ) ; public static final Property < IvOther > OTHER1 = Property . create ( ""other1"" , IvOther . class ) ; public static final Property < IvOther > OTHER2 = Property . create ( ""other2"" , IvOther . class ) ; protected String attr1 ; protected String attr2 ; protected Object other1 ; protected Object other2 ; public void setAttr1 ( String attr1 ) { beforePropertyWrite ( ""attr1"" , this . attr1 , attr1 ) ; this . attr1 = attr1 ; } public String getAttr1 ( ) { beforePropertyRead ( ""attr1"" ) ; return this . attr1 ; } public void setAttr2 ( String attr2 ) { beforePropertyWrite ( ""attr2"" , this . attr2 , attr2 ) ; this . attr2 = attr2 ; } public String getAttr2 ( ) { beforePropertyRead ( ""attr2"" ) ; return this . attr2 ; } public void setOther1 ( IvOther other1 ) { setToOneTarget ( ""other1"" , other1 , true ) ; } public IvOther getOther1 ( ) { return ( IvOther ) readProperty ( ""other1"" ) ; } public void setOther2 ( IvOther other2 ) { setToOneTarget ( ""other2"" , other2 , true ) ; } public IvOther getOther2 ( ) { return ( IvOther ) readProperty ( ""other2"" ) ; } @ Override public Object readPropertyDirectly ( String propName ) { if ( propName == null ) { throw new IllegalArgumentException ( ) ; } switch ( propName ) { case ""attr1"" : return this . attr1 ; case ""attr2"" : return this . attr2 ; case ""other1"" : return this . other1 ; case ""other2"" : return this . other2 ; default : return super . readPropertyDirectly ( propName ) ; } } @ Override public void writePropertyDirectly ( String propName , Object val ) { if ( propName == null ) { throw new IllegalArgumentException ( ) ; } switch ( propName ) { case ""attr1"" : this . attr1 = ( String ) val ; break ; case ""attr2"" : this . attr2 = ( String ) val ; break ; case ""other1"" : this . other1 = val ; break ; case ""other2"" : this . other2 = val ; break ; default : super . writePropertyDirectly ( propName , val ) ; } } private void writeObject ( ObjectOutputStream out ) throws IOException { writeSerialized ( out ) ; } private void readObject ( ObjectInputStream in ) throws IOException , ClassNotFoundException { readSerialized ( in ) ; } @ Override protected void writeState ( ObjectOutputStream out ) throws IOException { super . writeState ( out ) ; out . writeObject ( this . attr1 ) ; out . writeObject ( this . attr2 ) ; out . writeObject ( this . other1 ) ; out . writeObject ( this . other2 ) ; } @ Override protected void readState ( ObjectInputStream in ) throws IOException , ClassNotFoundException { super . readState ( in ) ; this . attr1 = ( String ) in . readObject ( ) ; this . attr2 = ( String ) in . readObject ( ) ; this . other1 = in . readObject ( ) ; this . other2 = in . readObject ( ) ; } }",Smelly
 private static class RemoteInterpreterResultTupleSchemeFactory implements SchemeFactory { public RemoteInterpreterResultTupleScheme getScheme ( ) { return new RemoteInterpreterResultTupleScheme ( ) ; } ,No
"public class HTMLTokenRenderer implements TokenRenderer { private String stylesheet = ""java.css"" ; private boolean showLineNumber = true ; private boolean anchorLineNumber = false ; private boolean addLineBreak = true ; private boolean addExplicitSpace = true ; private String lineNumberFormat = ""%04d"" ; public static final String CSS_CUSTOM = ""custom"" ; public static final String CSS_KEYWORD = ""keyword"" ; public static final String CSS_ANNOTATION = ""annotation"" ; public static final String CSS_ENUM = ""enum"" ; public static final String CSS_COMMENT = ""comment"" ; public static final String CSS_LITERAL = ""literal"" ; public static final String CSS_DECIMAL = ""decimal"" ; public static final String CSS_LINE_NO = ""lineno"" ; private Set < String > customIdentifiers = new HashSet < String > ( ) ; public static final String NEW_LINE = ""\r\n"" ; public static final String HTML_BR_TAG = ""<br>"" ; public static final String HTML_SPACE = ""&nbsp;"" ; public String endLine ( int line ) { return addLineBreak ? HTML_BR_TAG + NEW_LINE : NEW_LINE ; } public String newLine ( int line ) { String result = """" ; if ( showLineNumber ) { result = span ( CSS_LINE_NO , String . format ( lineNumberFormat , line ) + fillWhiteSpace ( ""    "" ) ) ; } if ( anchorLineNumber ) { result = ""<A name="" + quote ( ""line."" + line ) + "">"" + result + ""</A>"" ; } return result ; } @ Override public String render ( int decision , Token token ) { String text = token . getText ( ) ; String result = """" ; int type = token . getType ( ) ; switch ( type ) { case JavaParser . Identifier : case 73 : if ( customIdentifiers . contains ( text ) ) { result = span ( CSS_CUSTOM , text ) ; } else if ( decision == 66 || decision == 14 ) { result = span ( CSS_ANNOTATION , text ) ; } else if ( decision == 28 ) { result = span ( CSS_ENUM , text ) ; } else { result = text ; } break ; case JavaParser . COMMENT : case JavaParser . LINE_COMMENT : result = span ( CSS_COMMENT , TextProcessingUtility . replaceHTMLSpecialCharacters ( text ) ) ; break ; case JavaParser . StringLiteral : case JavaParser . CharacterLiteral : result = span ( CSS_LITERAL , text ) ; break ; case JavaParser . DecimalLiteral : case JavaParser . HexDigit : case JavaParser . HexLiteral : result = span ( CSS_DECIMAL , text ) ; break ; default : if ( isWhiteSpace ( text ) ) { result = fillWhiteSpace ( text ) ; } else if ( text . length ( ) == 1 ) { if ( text . charAt ( 0 ) == '>' ) { result = ""&gt;"" ; } else if ( text . charAt ( 0 ) == '<' ) { result = ""&lt;"" ; } else { result = text ; } } else { result = span ( CSS_KEYWORD , text ) ; } } return result ; } String span ( String id , String txt ) { return ""<span id="" + quote ( id ) + "">"" + txt + ""</span>"" ; } String quote ( String s ) { return ""\"""" + s + ""\"""" ; } boolean isWhiteSpace ( String txt ) { for ( int i = 0 ; i < txt . length ( ) ; i ++ ) { if ( ! Character . isWhitespace ( txt . charAt ( i ) ) ) return false ; } return true ; } String fillWhiteSpace ( String txt ) { StringBuilder space = new StringBuilder ( ) ; for ( int i = 0 ; i < txt . length ( ) ; i ++ ) { char ch = txt . charAt ( i ) ; if ( ch != '\r' && ch != '\n' ) space . append ( addExplicitSpace ? HTML_SPACE : ch ) ; } return space . toString ( ) ; } public String getPrologue ( ) { return insertLines ( ""<HTML>"" , ""<HEAD>"" , ""<link rel="" + quote ( ""stylesheet"" ) + "" type="" + quote ( ""text/css"" ) + "" href="" + quote ( stylesheet ) + "">"" , ""</HEAD>"" , ""<BODY>"" ) ; } public String getEpilogue ( ) { return insertLines ( "" "" , ""</BODY>"" , ""</HTML>"" ) ; } private String insertLines ( String ... lines ) { StringBuilder buf = new StringBuilder ( ) ; for ( String line : lines ) { if ( buf . length ( ) != 0 ) buf . append ( NEW_LINE ) ; buf . append ( line ) ; } return buf . toString ( ) ; } public String getStylesheet ( ) { return stylesheet ; } public void setStylesheet ( String stylesheet ) { this . stylesheet = stylesheet ; } public boolean getShowLineNumber ( ) { return showLineNumber ; } public void setShowLineNumber ( boolean showLineNumber ) { this . showLineNumber = showLineNumber ; } public boolean getAnchorLineNumber ( ) { return anchorLineNumber ; } public void setAnchorLineNumber ( boolean anchorLineNumber ) { this . anchorLineNumber = anchorLineNumber ; } public boolean getAddLineBreak ( ) { return addLineBreak ; } public void setAddLineBreak ( boolean addLineBreak ) { this . addLineBreak = addLineBreak ; } public boolean getAddExplicitSpace ( ) { return addExplicitSpace ; } public void setAddExplicitSpace ( boolean addSpace ) { this . addExplicitSpace = addSpace ; } public String getLineNumberFormat ( ) { return lineNumberFormat ; } public void setLineNumberFormat ( String lineNumberFormat ) { this . lineNumberFormat = lineNumberFormat ; } }",Smelly
"public class RangerAccessRequestImpl implements RangerAccessRequest { private static final Logger LOG = Logger . getLogger ( RangerAccessRequestImpl . class ) ; private RangerAccessResource resource ; private String accessType ; private String user ; private Set < String > userGroups ; private Date accessTime ; private String clientIPAddress ; private List < String > forwardedAddresses ; private String remoteIPAddress ; private String clientType ; private String action ; private String requestData ; private String sessionId ; private Map < String , Object > context ; private String clusterName ; private boolean isAccessTypeAny ; private boolean isAccessTypeDelegatedAdmin ; private ResourceMatchingScope resourceMatchingScope = ResourceMatchingScope . SELF ; public RangerAccessRequestImpl ( ) { this ( null , null , null , null ) ; } public RangerAccessRequestImpl ( RangerAccessResource resource , String accessType , String user , Set < String > userGroups ) { setResource ( resource ) ; setAccessType ( accessType ) ; setUser ( user ) ; setUserGroups ( userGroups ) ; setForwardedAddresses ( null ) ; setAccessTime ( null ) ; setRemoteIPAddress ( null ) ; setClientType ( null ) ; setAction ( null ) ; setRequestData ( null ) ; setSessionId ( null ) ; setContext ( null ) ; setClusterName ( null ) ; } @ Override public RangerAccessResource getResource ( ) { return resource ; } @ Override public String getAccessType ( ) { return accessType ; } @ Override public String getUser ( ) { return user ; } @ Override public Set < String > getUserGroups ( ) { return userGroups ; } @ Override public Date getAccessTime ( ) { return accessTime ; } @ Override public String getClientIPAddress ( ) { return clientIPAddress ; } @ Override public String getRemoteIPAddress ( ) { return remoteIPAddress ; } @ Override public List < String > getForwardedAddresses ( ) { return forwardedAddresses ; } @ Override public String getClientType ( ) { return clientType ; } @ Override public String getAction ( ) { return action ; } @ Override public String getRequestData ( ) { return requestData ; } @ Override public String getSessionId ( ) { return sessionId ; } @ Override public Map < String , Object > getContext ( ) { return context ; } @ Override public ResourceMatchingScope getResourceMatchingScope ( ) { return resourceMatchingScope ; } @ Override public boolean isAccessTypeAny ( ) { return isAccessTypeAny ; } @ Override public boolean isAccessTypeDelegatedAdmin ( ) { return isAccessTypeDelegatedAdmin ; } public void setResource ( RangerAccessResource resource ) { this . resource = resource ; } public void setAccessType ( String accessType ) { if ( StringUtils . isEmpty ( accessType ) ) { accessType = RangerPolicyEngine . ANY_ACCESS ; } this . accessType = accessType ; isAccessTypeAny = StringUtils . equals ( accessType , RangerPolicyEngine . ANY_ACCESS ) ; isAccessTypeDelegatedAdmin = StringUtils . equals ( accessType , RangerPolicyEngine . ADMIN_ACCESS ) ; } public void setUser ( String user ) { this . user = user ; } public void setUserGroups ( Set < String > userGroups ) { this . userGroups = ( userGroups == null ) ? new HashSet < String > ( ) : userGroups ; } public void setAccessTime ( Date accessTime ) { this . accessTime = ( accessTime == null ) ? new Date ( ) : accessTime ; } public void setClientIPAddress ( String ipAddress ) { this . clientIPAddress = ipAddress ; } public void setForwardedAddresses ( List < String > forwardedAddresses ) { this . forwardedAddresses = ( forwardedAddresses == null ) ? new ArrayList < String > ( ) : forwardedAddresses ; } public void setRemoteIPAddress ( String remoteIPAddress ) { this . remoteIPAddress = remoteIPAddress ; } public void setClientType ( String clientType ) { this . clientType = clientType ; } public void setAction ( String action ) { this . action = action ; } public void setRequestData ( String requestData ) { this . requestData = requestData ; } public void setSessionId ( String sessionId ) { this . sessionId = sessionId ; } public String getClusterName ( ) { return clusterName ; } public void setClusterName ( String clusterName ) { this . clusterName = clusterName ; } public void setResourceMatchingScope ( ResourceMatchingScope scope ) { this . resourceMatchingScope = scope ; } public void setContext ( Map < String , Object > context ) { this . context = ( context == null ) ? new HashMap < String , Object > ( ) : context ; } protected void extractAndSetClientIPAddress ( boolean useForwardedIPAddress , String [ ] trustedProxyAddresses ) { String ip = getRemoteIPAddress ( ) ; if ( ip == null ) { ip = getClientIPAddress ( ) ; } String newIp = ip ; if ( useForwardedIPAddress ) { if ( LOG . isDebugEnabled ( ) ) { LOG . debug ( ""Using X-Forward-For..."" ) ; } if ( CollectionUtils . isNotEmpty ( getForwardedAddresses ( ) ) ) { if ( trustedProxyAddresses != null && trustedProxyAddresses . length > 0 ) { if ( StringUtils . isNotEmpty ( ip ) ) { for ( String trustedProxyAddress : trustedProxyAddresses ) { if ( StringUtils . equals ( ip , trustedProxyAddress ) ) { newIp = getForwardedAddresses ( ) . get ( 0 ) ; break ; } } } } else { newIp = getForwardedAddresses ( ) . get ( 0 ) ; } } else { if ( LOG . isDebugEnabled ( ) ) { LOG . debug ( ""No X-Forwarded-For addresses in the access-request"" ) ; } } } if ( LOG . isDebugEnabled ( ) ) { LOG . debug ( ""Old Remote/Client IP Address="" + ip + "", new IP Address="" + newIp ) ; } setClientIPAddress ( newIp ) ; } @ Override public String toString ( ) { StringBuilder sb = new StringBuilder ( ) ; toString ( sb ) ; return sb . toString ( ) ; } public StringBuilder toString ( StringBuilder sb ) { sb . append ( ""RangerAccessRequestImpl={"" ) ; sb . append ( ""resource={"" ) . append ( resource ) . append ( ""} "" ) ; sb . append ( ""accessType={"" ) . append ( accessType ) . append ( ""} "" ) ; sb . append ( ""user={"" ) . append ( user ) . append ( ""} "" ) ; sb . append ( ""userGroups={"" ) ; if ( userGroups != null ) { for ( String userGroup : userGroups ) { sb . append ( userGroup ) . append ( "" "" ) ; } } sb . append ( ""} "" ) ; sb . append ( ""accessTime={"" ) . append ( accessTime ) . append ( ""} "" ) ; sb . append ( ""clientIPAddress={"" ) . append ( getClientIPAddress ( ) ) . append ( ""} "" ) ; sb . append ( ""forwardedAddresses={"" ) . append ( StringUtils . join ( forwardedAddresses , "" "" ) ) . append ( ""} "" ) ; sb . append ( ""remoteIPAddress={"" ) . append ( remoteIPAddress ) . append ( ""} "" ) ; sb . append ( ""clientType={"" ) . append ( clientType ) . append ( ""} "" ) ; sb . append ( ""action={"" ) . append ( action ) . append ( ""} "" ) ; sb . append ( ""requestData={"" ) . append ( requestData ) . append ( ""} "" ) ; sb . append ( ""sessionId={"" ) . append ( sessionId ) . append ( ""} "" ) ; sb . append ( ""resourceMatchingScope={"" ) . append ( resourceMatchingScope ) . append ( ""} "" ) ; sb . append ( ""clusterName={"" ) . append ( clusterName ) . append ( ""} "" ) ; sb . append ( ""context={"" ) ; if ( context != null ) { for ( Map . Entry < String , Object > e : context . entrySet ( ) ) { sb . append ( e . getKey ( ) ) . append ( ""={"" ) . append ( e . getValue ( ) ) . append ( ""} "" ) ; } } sb . append ( ""} "" ) ; sb . append ( ""}"" ) ; return sb ; } @ Override public RangerAccessRequest getReadOnlyCopy ( ) { return new RangerAccessRequestReadOnly ( this ) ; } }",Smelly
 private class InputStreamCache extends ByteArrayInputStream implements StreamCache { public InputStreamCache ( byte [ ] data ) { super ( data ) ; } ,No
public class CompactionInfo { public long id ; public String dbname ; public String tableName ; public String partName ; public CompactionType type ; public String runAs ; public boolean tooManyAborts = false ; private String fullPartitionName = null ; private String fullTableName = null ; public String getFullPartitionName ( ) { if ( fullPartitionName == null ) { StringBuffer buf = new StringBuffer ( dbname ) ; buf . append ( '.' ) ; buf . append ( tableName ) ; if ( partName != null ) { buf . append ( '.' ) ; buf . append ( partName ) ; } fullPartitionName = buf . toString ( ) ; } return fullPartitionName ; } public String getFullTableName ( ) { if ( fullTableName == null ) { StringBuffer buf = new StringBuffer ( dbname ) ; buf . append ( '.' ) ; buf . append ( tableName ) ; fullTableName = buf . toString ( ) ; } return fullTableName ; } },Smelly
"public class PlanetRequest extends ParsedRequest { private static Log log = LogFactory . getLog ( PlanetRequest . class ) ; private String context = null ; private String type = null ; private String flavor = null ; private boolean excerpts = false ; private String language = null ; private String group = null ; public PlanetRequest ( HttpServletRequest request ) throws InvalidRequestException { super ( request ) ; log . debug ( ""parsing url "" + request . getRequestURL ( ) ) ; String servlet = request . getServletPath ( ) ; if ( servlet != null ) { servlet = servlet . substring ( 1 ) ; if ( servlet . equals ( ""planet.do"" ) ) { this . context = ""planet"" ; this . type = ""page"" ; } else if ( servlet . equals ( ""planetrss"" ) ) { this . context = ""planet"" ; this . type = ""feed"" ; this . flavor = ""rss"" ; } else { throw new InvalidRequestException ( ""not a planet request, "" + request . getRequestURL ( ) ) ; } } else { throw new InvalidRequestException ( ""not a planet request, "" + request . getRequestURL ( ) ) ; } if ( request . getParameter ( ""excerpts"" ) != null ) { this . excerpts = Boolean . valueOf ( request . getParameter ( ""excerpts"" ) ) ; } if ( request . getParameter ( ""group"" ) != null ) { this . group = request . getParameter ( ""group"" ) ; } language = request . getLocale ( ) . getLanguage ( ) ; } public String getContext ( ) { return context ; } public String getType ( ) { return type ; } public String getFlavor ( ) { return flavor ; } public boolean isExcerpts ( ) { return excerpts ; } public String getLanguage ( ) { return language ; } public void setLanguage ( String language ) { this . language = language ; } public String getGroup ( ) { return group ; } }",Smelly
" private static abstract class VectorExpressionWriterBytes extends VectorExpressionWriterBase { @ Override public Object writeValue ( ColumnVector column , int row ) throws HiveException { BytesColumnVector bcv = ( BytesColumnVector ) column ; if ( bcv . noNulls && ! bcv . isRepeating ) { return writeValue ( bcv . vector [ row ] , bcv . start [ row ] , bcv . length [ row ] ) ; } else if ( bcv . noNulls && bcv . isRepeating ) { return writeValue ( bcv . vector [ 0 ] , bcv . start [ 0 ] , bcv . length [ 0 ] ) ; } else if ( ! bcv . noNulls && ! bcv . isRepeating && ! bcv . isNull [ row ] ) { return writeValue ( bcv . vector [ row ] , bcv . start [ row ] , bcv . length [ row ] ) ; } else if ( ! bcv . noNulls && ! bcv . isRepeating && bcv . isNull [ row ] ) { return null ; } else if ( ! bcv . noNulls && bcv . isRepeating && ! bcv . isNull [ 0 ] ) { return writeValue ( bcv . vector [ 0 ] , bcv . start [ 0 ] , bcv . length [ 0 ] ) ; } else if ( ! bcv . noNulls && bcv . isRepeating && bcv . isNull [ 0 ] ) { return null ; } throw new HiveException ( String . format ( ""Incorrect null/repeating: row:%d noNulls:%b isRepeating:%b isNull[row]:%b isNull[0]:%b"" , row , bcv . noNulls , bcv . isRepeating , bcv . isNull [ row ] , bcv . isNull [ 0 ] ) ) ; } @ Override public Object setValue ( Object field , ColumnVector column , int row ) throws HiveException { BytesColumnVector bcv = ( BytesColumnVector ) column ; if ( bcv . noNulls && ! bcv . isRepeating ) { return setValue ( field , bcv . vector [ row ] , bcv . start [ row ] , bcv . length [ row ] ) ; } else if ( bcv . noNulls && bcv . isRepeating ) { return setValue ( field , bcv . vector [ 0 ] , bcv . start [ 0 ] , bcv . length [ 0 ] ) ; } else if ( ! bcv . noNulls && ! bcv . isRepeating && ! bcv . isNull [ row ] ) { return setValue ( field , bcv . vector [ row ] , bcv . start [ row ] , bcv . length [ row ] ) ; } else if ( ! bcv . noNulls && ! bcv . isRepeating && bcv . isNull [ row ] ) { return null ; } else if ( ! bcv . noNulls && bcv . isRepeating && ! bcv . isNull [ 0 ] ) { return setValue ( field , bcv . vector [ 0 ] , bcv . start [ 0 ] , bcv . length [ 0 ] ) ; } else if ( ! bcv . noNulls && bcv . isRepeating && bcv . isNull [ 0 ] ) { return null ; } throw new HiveException ( String . format ( ""Incorrect null/repeating: row:%d noNulls:%b isRepeating:%b isNull[row]:%b isNull[0]:%b"" , row , bcv . noNulls , bcv . isRepeating , bcv . isNull [ row ] , bcv . isNull [ 0 ] ) ) ; } ",No
"public class AFPGraphicsObjectInfo extends AFPDataObjectInfo { private Graphics2DImagePainter painter ; private Rectangle2D area ; private AFPGraphics2D g2d ; public Graphics2DImagePainter getPainter ( ) { return this . painter ; } public void setPainter ( Graphics2DImagePainter graphicsPainter ) { this . painter = graphicsPainter ; } public Rectangle2D getArea ( ) { AFPObjectAreaInfo objectAreaInfo = getObjectAreaInfo ( ) ; int width = objectAreaInfo . getWidth ( ) ; int height = objectAreaInfo . getHeight ( ) ; return new Rectangle ( width , height ) ; } public void setArea ( Rectangle2D area ) { this . area = area ; } public void setGraphics2D ( AFPGraphics2D g2d ) { this . g2d = g2d ; } public AFPGraphics2D getGraphics2D ( ) { return this . g2d ; } public String toString ( ) { return ""GraphicsObjectInfo{"" + super . toString ( ) + ""}"" ; } public String getMimeType ( ) { return MimeConstants . MIME_SVG ; } }",Smelly
"public abstract class AbstractOAuthService { private MessageContext mc ; private OAuthDataProvider dataProvider ; private OAuthValidator validator = new DefaultOAuthValidator ( ) ; @ Context public void setMessageContext ( MessageContext context ) { this . mc = context ; } public MessageContext getMessageContext ( ) { return mc ; } public void setDataProvider ( OAuthDataProvider dataProvider ) { this . dataProvider = dataProvider ; } protected OAuthDataProvider getDataProvider ( ) { return OAuthUtils . getOAuthDataProvider ( dataProvider , mc . getServletContext ( ) ) ; } public OAuthValidator getValidator ( ) { return validator ; } public void setValidator ( OAuthValidator validator ) { this . validator = validator ; } }",Smelly
"@ JsonTypeName ( ""fs-writer"" ) public class EasyWriter extends AbstractWriter { static final org . slf4j . Logger logger = org . slf4j . LoggerFactory . getLogger ( EasyWriter . class ) ; private final String location ; private final List < String > partitionColumns ; private final EasyFormatPlugin < ? > formatPlugin ; @ JsonCreator public EasyWriter ( @ JsonProperty ( ""child"" ) PhysicalOperator child , @ JsonProperty ( ""location"" ) String location , @ JsonProperty ( ""partitionColumns"" ) List < String > partitionColumns , @ JsonProperty ( ""storageStrategy"" ) StorageStrategy storageStrategy , @ JsonProperty ( ""storage"" ) StoragePluginConfig storageConfig , @ JsonProperty ( ""format"" ) FormatPluginConfig formatConfig , @ JacksonInject StoragePluginRegistry engineRegistry ) throws IOException , ExecutionSetupException { super ( child ) ; this . formatPlugin = ( EasyFormatPlugin < ? > ) engineRegistry . getFormatPlugin ( storageConfig , formatConfig ) ; Preconditions . checkNotNull ( formatPlugin , ""Unable to load format plugin for provided format config."" ) ; this . location = location ; this . partitionColumns = partitionColumns ; setStorageStrategy ( storageStrategy ) ; } public EasyWriter ( PhysicalOperator child , String location , List < String > partitionColumns , EasyFormatPlugin < ? > formatPlugin ) { super ( child ) ; this . formatPlugin = formatPlugin ; this . location = location ; this . partitionColumns = partitionColumns ; } @ JsonProperty ( ""location"" ) public String getLocation ( ) { return location ; } @ JsonProperty ( ""storage"" ) public StoragePluginConfig getStorageConfig ( ) { return formatPlugin . getStorageConfig ( ) ; } @ JsonProperty ( ""format"" ) public FormatPluginConfig getFormatConfig ( ) { return formatPlugin . getConfig ( ) ; } @ JsonIgnore public EasyFormatPlugin < ? > getFormatPlugin ( ) { return formatPlugin ; } @ Override protected PhysicalOperator getNewWithChild ( PhysicalOperator child ) { EasyWriter writer = new EasyWriter ( child , location , partitionColumns , formatPlugin ) ; writer . setStorageStrategy ( getStorageStrategy ( ) ) ; return writer ; } @ Override public int getOperatorType ( ) { return formatPlugin . getReaderOperatorType ( ) ; } }",Smelly
 private static class getOrchestratorCPIVersion_resultTupleSchemeFactory implements SchemeFactory { public getOrchestratorCPIVersion_resultTupleScheme getScheme ( ) { return new getOrchestratorCPIVersion_resultTupleScheme ( ) ; } ,No
public class SQLConversionOverflowException extends SQLConversionException { private static final long serialVersionUID = 2015_04_07L ; public SQLConversionOverflowException ( String message ) { super ( message ) ; } },No
