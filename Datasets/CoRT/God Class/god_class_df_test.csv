Code,Smelly
"public class TestClusterManagementWebapp extends AdminTestBase { @ Test public void testInvocation ( ) throws Exception { verifyAddCluster ( ) ; verifyAddStateModel ( ) ; verifyAddHostedEntity ( ) ; verifyAddInstance ( ) ; verifyRebalance ( ) ; verifyEnableInstance ( ) ; verifyAlterIdealState ( ) ; verifyConfigAccessor ( ) ; verifyEnableCluster ( ) ; System . out . println ( ""Test passed!!"" ) ; } String clusterName = ""cluster-12345"" ; String resourceGroupName = ""new-entity-12345"" ; String instance1 = ""test-1"" ; String statemodel = ""state_model"" ; int instancePort = 9999 ; int partitions = 10 ; int replicas = 3 ; void verifyAddStateModel ( ) throws JsonGenerationException , JsonMappingException , IOException { String httpUrlBase = ""http://localhost:"" + ADMIN_PORT + ""/clusters/"" + clusterName + ""/StateModelDefs/MasterSlave"" ; Reference resourceRef = new Reference ( httpUrlBase ) ; Request request = new Request ( Method . GET , resourceRef ) ; Response response = _gClient . handle ( request ) ; Representation result = response . getEntity ( ) ; StringWriter sw = new StringWriter ( ) ; result . write ( sw ) ; ObjectMapper mapper = new ObjectMapper ( ) ; ZNRecord zn = mapper . readValue ( new StringReader ( sw . toString ( ) ) , ZNRecord . class ) ; Map < String , String > paraMap = new HashMap < String , String > ( ) ; paraMap . put ( JsonParameters . MANAGEMENT_COMMAND , ClusterSetup . addStateModelDef ) ; ZNRecord r = new ZNRecord ( ""Test"" ) ; r . merge ( zn ) ; httpUrlBase = ""http://localhost:"" + ADMIN_PORT + ""/clusters/"" + clusterName + ""/StateModelDefs"" ; resourceRef = new Reference ( httpUrlBase ) ; request = new Request ( Method . POST , resourceRef ) ; request . setEntity ( JsonParameters . JSON_PARAMETERS + ""="" + ClusterRepresentationUtil . ObjectToJson ( paraMap ) + ""&"" + JsonParameters . NEW_STATE_MODEL_DEF + ""="" + ClusterRepresentationUtil . ZNRecordToJson ( r ) , MediaType . APPLICATION_ALL ) ; response = _gClient . handle ( request ) ; result = response . getEntity ( ) ; sw = new StringWriter ( ) ; result . write ( sw ) ; AssertJUnit . assertTrue ( sw . toString ( ) . contains ( ""Test"" ) ) ; } void verifyAddCluster ( ) throws IOException , InterruptedException { String httpUrlBase = ""http://localhost:"" + ADMIN_PORT + ""/clusters"" ; Map < String , String > paraMap = new HashMap < String , String > ( ) ; paraMap . put ( JsonParameters . CLUSTER_NAME , clusterName ) ; paraMap . put ( JsonParameters . MANAGEMENT_COMMAND , ClusterSetup . addCluster ) ; Reference resourceRef = new Reference ( httpUrlBase ) ; Request request = new Request ( Method . POST , resourceRef ) ; request . setEntity ( JsonParameters . JSON_PARAMETERS + ""="" + ClusterRepresentationUtil . ObjectToJson ( paraMap ) , MediaType . APPLICATION_ALL ) ; Response response = _gClient . handle ( request ) ; Representation result = response . getEntity ( ) ; StringWriter sw = new StringWriter ( ) ; result . write ( sw ) ; ObjectMapper mapper = new ObjectMapper ( ) ; ZNRecord zn = mapper . readValue ( new StringReader ( sw . toString ( ) ) , ZNRecord . class ) ; AssertJUnit . assertTrue ( zn . getListField ( ""clusters"" ) . contains ( clusterName ) ) ; } void verifyAddHostedEntity ( ) throws JsonGenerationException , JsonMappingException , IOException { String httpUrlBase = ""http://localhost:"" + ADMIN_PORT + ""/clusters/"" + clusterName + ""/resourceGroups"" ; Map < String , String > paraMap = new HashMap < String , String > ( ) ; paraMap . put ( JsonParameters . RESOURCE_GROUP_NAME , resourceGroupName ) ; paraMap . put ( JsonParameters . PARTITIONS , """" + partitions ) ; paraMap . put ( JsonParameters . STATE_MODEL_DEF_REF , ""MasterSlave"" ) ; paraMap . put ( JsonParameters . MANAGEMENT_COMMAND , ClusterSetup . addResource ) ; Reference resourceRef = new Reference ( httpUrlBase ) ; Request request = new Request ( Method . POST , resourceRef ) ; request . setEntity ( JsonParameters . JSON_PARAMETERS + ""="" + ClusterRepresentationUtil . ObjectToJson ( paraMap ) , MediaType . APPLICATION_ALL ) ; Response response = _gClient . handle ( request ) ; Representation result = response . getEntity ( ) ; StringWriter sw = new StringWriter ( ) ; result . write ( sw ) ; ObjectMapper mapper = new ObjectMapper ( ) ; ZNRecord zn = mapper . readValue ( new StringReader ( sw . toString ( ) ) , ZNRecord . class ) ; AssertJUnit . assertTrue ( zn . getListField ( ""ResourceGroups"" ) . contains ( resourceGroupName ) ) ; httpUrlBase = ""http://localhost:"" + ADMIN_PORT + ""/clusters/"" + clusterName + ""/resourceGroups/"" + resourceGroupName ; resourceRef = new Reference ( httpUrlBase ) ; request = new Request ( Method . GET , resourceRef ) ; response = _gClient . handle ( request ) ; result = response . getEntity ( ) ; sw = new StringWriter ( ) ; result . write ( sw ) ; } void verifyAddInstance ( ) throws JsonGenerationException , JsonMappingException , IOException { String httpUrlBase = ""http://localhost:"" + ADMIN_PORT + ""/clusters/"" + clusterName + ""/instances"" ; Map < String , String > paraMap = new HashMap < String , String > ( ) ; paraMap . put ( JsonParameters . INSTANCE_NAME , instance1 + "":"" + instancePort ) ; paraMap . put ( JsonParameters . MANAGEMENT_COMMAND , ClusterSetup . addInstance ) ; Reference resourceRef = new Reference ( httpUrlBase ) ; Request request = new Request ( Method . POST , resourceRef ) ; request . setEntity ( JsonParameters . JSON_PARAMETERS + ""="" + ClusterRepresentationUtil . ObjectToJson ( paraMap ) , MediaType . APPLICATION_ALL ) ; Response response = _gClient . handle ( request ) ; Representation result = response . getEntity ( ) ; StringWriter sw = new StringWriter ( ) ; result . write ( sw ) ; ObjectMapper mapper = new ObjectMapper ( ) ; TypeReference < ListInstancesWrapper > typeRef = new TypeReference < ListInstancesWrapper > ( ) { } ; ListInstancesWrapper wrapper = mapper . readValue ( new StringReader ( sw . toString ( ) ) , typeRef ) ; List < ZNRecord > znList = wrapper . instanceInfo ; AssertJUnit . assertTrue ( znList . get ( 0 ) . getId ( ) . equals ( instance1 + ""_"" + instancePort ) ) ; paraMap . clear ( ) ; paraMap . put ( JsonParameters . MANAGEMENT_COMMAND , ClusterSetup . addInstance ) ; String [ ] instances = { ""test2"" , ""test3"" , ""test4"" , ""test5"" } ; String instanceNames = """" ; boolean first = true ; for ( String instance : instances ) { if ( first == true ) { first = false ; } else { instanceNames += "";"" ; } instanceNames += ( instance + "":"" + instancePort ) ; } paraMap . put ( JsonParameters . INSTANCE_NAMES , instanceNames ) ; request = new Request ( Method . POST , resourceRef ) ; request . setEntity ( JsonParameters . JSON_PARAMETERS + ""="" + ClusterRepresentationUtil . ObjectToJson ( paraMap ) , MediaType . APPLICATION_ALL ) ; response = _gClient . handle ( request ) ; result = response . getEntity ( ) ; sw = new StringWriter ( ) ; result . write ( sw ) ; mapper = new ObjectMapper ( ) ; wrapper = mapper . readValue ( new StringReader ( sw . toString ( ) ) , typeRef ) ; znList = wrapper . instanceInfo ; for ( String instance : instances ) { boolean found = false ; for ( ZNRecord r : znList ) { String instanceId = instance + ""_"" + instancePort ; if ( r . getId ( ) . equals ( instanceId ) ) { found = true ; break ; } } AssertJUnit . assertTrue ( found ) ; } } void verifyRebalance ( ) throws JsonGenerationException , JsonMappingException , IOException { String httpUrlBase = ""http://localhost:"" + ADMIN_PORT + ""/clusters/"" + clusterName + ""/resourceGroups/"" + resourceGroupName + ""/idealState"" ; Map < String , String > paraMap = new HashMap < String , String > ( ) ; paraMap . put ( JsonParameters . REPLICAS , """" + replicas ) ; paraMap . put ( JsonParameters . MANAGEMENT_COMMAND , ClusterSetup . rebalance ) ; Reference resourceRef = new Reference ( httpUrlBase ) ; Request request = new Request ( Method . POST , resourceRef ) ; request . setEntity ( JsonParameters . JSON_PARAMETERS + ""="" + ClusterRepresentationUtil . ObjectToJson ( paraMap ) , MediaType . APPLICATION_ALL ) ; Response response = _gClient . handle ( request ) ; Representation result = response . getEntity ( ) ; StringWriter sw = new StringWriter ( ) ; result . write ( sw ) ; ObjectMapper mapper = new ObjectMapper ( ) ; ZNRecord r = mapper . readValue ( new StringReader ( sw . toString ( ) ) , ZNRecord . class ) ; for ( int i = 0 ; i < partitions ; i ++ ) { String partitionName = resourceGroupName + ""_"" + i ; assert ( r . getMapField ( partitionName ) . size ( ) == replicas ) ; } httpUrlBase = ""http://localhost:"" + ADMIN_PORT + ""/clusters/"" + clusterName ; resourceRef = new Reference ( httpUrlBase ) ; request = new Request ( Method . GET , resourceRef ) ; response = _gClient . handle ( request ) ; result = response . getEntity ( ) ; sw = new StringWriter ( ) ; result . write ( sw ) ; } void verifyEnableInstance ( ) throws JsonGenerationException , JsonMappingException , IOException { String httpUrlBase = ""http://localhost:"" + ADMIN_PORT + ""/clusters/"" + clusterName + ""/instances/"" + instance1 + ""_"" + instancePort ; Map < String , String > paraMap = new HashMap < String , String > ( ) ; paraMap . put ( JsonParameters . ENABLED , """" + false ) ; paraMap . put ( JsonParameters . MANAGEMENT_COMMAND , ClusterSetup . enableInstance ) ; Reference resourceRef = new Reference ( httpUrlBase ) ; Request request = new Request ( Method . POST , resourceRef ) ; request . setEntity ( JsonParameters . JSON_PARAMETERS + ""="" + ClusterRepresentationUtil . ObjectToJson ( paraMap ) , MediaType . APPLICATION_ALL ) ; Response response = _gClient . handle ( request ) ; Representation result = response . getEntity ( ) ; StringWriter sw = new StringWriter ( ) ; result . write ( sw ) ; ObjectMapper mapper = new ObjectMapper ( ) ; ZNRecord r = mapper . readValue ( new StringReader ( sw . toString ( ) ) , ZNRecord . class ) ; AssertJUnit . assertTrue ( r . getSimpleField ( InstanceConfigProperty . HELIX_ENABLED . toString ( ) ) . equals ( """" + false ) ) ; paraMap . put ( JsonParameters . ENABLED , """" + true ) ; request = new Request ( Method . POST , resourceRef ) ; request . setEntity ( JsonParameters . JSON_PARAMETERS + ""="" + ClusterRepresentationUtil . ObjectToJson ( paraMap ) , MediaType . APPLICATION_ALL ) ; response = _gClient . handle ( request ) ; result = response . getEntity ( ) ; sw = new StringWriter ( ) ; result . write ( sw ) ; mapper = new ObjectMapper ( ) ; r = mapper . readValue ( new StringReader ( sw . toString ( ) ) , ZNRecord . class ) ; AssertJUnit . assertTrue ( r . getSimpleField ( InstanceConfigProperty . HELIX_ENABLED . toString ( ) ) . equals ( """" + true ) ) ; } void verifyAlterIdealState ( ) throws IOException { String httpUrlBase = ""http://localhost:"" + ADMIN_PORT + ""/clusters/"" + clusterName + ""/resourceGroups/"" + resourceGroupName + ""/idealState"" ; Reference resourceRef = new Reference ( httpUrlBase ) ; Request request = new Request ( Method . GET , resourceRef ) ; Response response = _gClient . handle ( request ) ; Representation result = response . getEntity ( ) ; StringWriter sw = new StringWriter ( ) ; result . write ( sw ) ; ObjectMapper mapper = new ObjectMapper ( ) ; ZNRecord r = mapper . readValue ( new StringReader ( sw . toString ( ) ) , ZNRecord . class ) ; String partitionName = ""new-entity-12345_3"" ; r . getMapFields ( ) . remove ( partitionName ) ; Map < String , String > paraMap = new HashMap < String , String > ( ) ; paraMap . put ( JsonParameters . MANAGEMENT_COMMAND , ClusterSetup . addIdealState ) ; resourceRef = new Reference ( httpUrlBase ) ; request = new Request ( Method . POST , resourceRef ) ; request . setEntity ( JsonParameters . JSON_PARAMETERS + ""="" + ClusterRepresentationUtil . ObjectToJson ( paraMap ) + ""&"" + JsonParameters . NEW_IDEAL_STATE + ""="" + ClusterRepresentationUtil . ZNRecordToJson ( r ) , MediaType . APPLICATION_ALL ) ; response = _gClient . handle ( request ) ; result = response . getEntity ( ) ; sw = new StringWriter ( ) ; result . write ( sw ) ; mapper = new ObjectMapper ( ) ; ZNRecord r2 = mapper . readValue ( new StringReader ( sw . toString ( ) ) , ZNRecord . class ) ; AssertJUnit . assertTrue ( ! r2 . getMapFields ( ) . containsKey ( partitionName ) ) ; for ( String key : r2 . getMapFields ( ) . keySet ( ) ) { AssertJUnit . assertTrue ( r . getMapFields ( ) . containsKey ( key ) ) ; } } void verifyConfigAccessor ( ) throws Exception { ObjectMapper mapper = new ObjectMapper ( ) ; String url = ""http://localhost:"" + ADMIN_PORT + ""/clusters/"" + clusterName + ""/configs/cluster/"" + clusterName ; postConfig ( _gClient , url , mapper , ClusterSetup . setConfig , ""key1=value1,key2=value2"" ) ; ZNRecord record = get ( _gClient , url , mapper ) ; Assert . assertEquals ( record . getSimpleFields ( ) . size ( ) , 2 ) ; Assert . assertEquals ( record . getSimpleField ( ""key1"" ) , ""value1"" ) ; Assert . assertEquals ( record . getSimpleField ( ""key2"" ) , ""value2"" ) ; String participantName = ""test2_9999"" ; url = ""http://localhost:"" + ADMIN_PORT + ""/clusters/"" + clusterName + ""/configs/participant/"" + participantName ; postConfig ( _gClient , url , mapper , ClusterSetup . setConfig , ""key3=value3,key4=value4"" ) ; record = get ( _gClient , url , mapper ) ; Assert . assertTrue ( record . getSimpleFields ( ) . size ( ) >= 2 , ""Should at least contains 2 keys"" ) ; Assert . assertEquals ( record . getSimpleField ( ""key3"" ) , ""value3"" ) ; Assert . assertEquals ( record . getSimpleField ( ""key4"" ) , ""value4"" ) ; url = ""http://localhost:"" + ADMIN_PORT + ""/clusters/"" + clusterName + ""/configs/resource/testResource"" ; postConfig ( _gClient , url , mapper , ClusterSetup . setConfig , ""key5=value5,key6=value6"" ) ; record = get ( _gClient , url , mapper ) ; Assert . assertEquals ( record . getSimpleFields ( ) . size ( ) , 2 ) ; Assert . assertEquals ( record . getSimpleField ( ""key5"" ) , ""value5"" ) ; Assert . assertEquals ( record . getSimpleField ( ""key6"" ) , ""value6"" ) ; url = ""http://localhost:"" + ADMIN_PORT + ""/clusters/"" + clusterName + ""/configs/partition/testResource/testPartition"" ; postConfig ( _gClient , url , mapper , ClusterSetup . setConfig , ""key7=value7,key8=value8"" ) ; record = get ( _gClient , url , mapper ) ; Assert . assertEquals ( record . getSimpleFields ( ) . size ( ) , 2 ) ; Assert . assertEquals ( record . getSimpleField ( ""key7"" ) , ""value7"" ) ; Assert . assertEquals ( record . getSimpleField ( ""key8"" ) , ""value8"" ) ; url = ""http://localhost:"" + ADMIN_PORT + ""/clusters/"" + clusterName + ""/configs"" ; record = get ( _gClient , url , mapper ) ; Assert . assertEquals ( record . getListFields ( ) . size ( ) , 1 ) ; Assert . assertTrue ( record . getListFields ( ) . containsKey ( ""scopes"" ) ) ; Assert . assertTrue ( contains ( record . getListField ( ""scopes"" ) , ""CLUSTER"" , ""PARTICIPANT"" , ""RESOURCE"" , ""PARTITION"" ) ) ; url = ""http://localhost:"" + ADMIN_PORT + ""/clusters/"" + clusterName + ""/configs/participant"" ; record = get ( _gClient , url , mapper ) ; Assert . assertTrue ( record . getListFields ( ) . containsKey ( ""PARTICIPANT"" ) ) ; Assert . assertTrue ( contains ( record . getListField ( ""PARTICIPANT"" ) , participantName ) ) ; url = ""http://localhost:"" + ADMIN_PORT + ""/clusters/"" + clusterName + ""/configs/resource"" ; record = get ( _gClient , url , mapper ) ; Assert . assertEquals ( record . getListFields ( ) . size ( ) , 1 ) ; Assert . assertTrue ( record . getListFields ( ) . containsKey ( ""RESOURCE"" ) ) ; Assert . assertTrue ( contains ( record . getListField ( ""RESOURCE"" ) , ""testResource"" ) ) ; url = ""http://localhost:"" + ADMIN_PORT + ""/clusters/"" + clusterName + ""/configs/partition/testResource"" ; record = get ( _gClient , url , mapper ) ; Assert . assertEquals ( record . getListFields ( ) . size ( ) , 1 ) ; Assert . assertTrue ( record . getListFields ( ) . containsKey ( ""PARTITION"" ) ) ; Assert . assertTrue ( contains ( record . getListField ( ""PARTITION"" ) , ""testPartition"" ) ) ; } private ZNRecord get ( Client client , String url , ObjectMapper mapper ) throws Exception { Request request = new Request ( Method . GET , new Reference ( url ) ) ; Response response = client . handle ( request ) ; Representation result = response . getEntity ( ) ; StringWriter sw = new StringWriter ( ) ; result . write ( sw ) ; String responseStr = sw . toString ( ) ; Assert . assertTrue ( responseStr . toLowerCase ( ) . indexOf ( ""error"" ) == - 1 ) ; Assert . assertTrue ( responseStr . toLowerCase ( ) . indexOf ( ""exception"" ) == - 1 ) ; ZNRecord record = mapper . readValue ( new StringReader ( responseStr ) , ZNRecord . class ) ; return record ; } private void postConfig ( Client client , String url , ObjectMapper mapper , String command , String configs ) throws Exception { Map < String , String > params = new HashMap < String , String > ( ) ; params . put ( JsonParameters . MANAGEMENT_COMMAND , command ) ; params . put ( JsonParameters . CONFIGS , configs ) ; Request request = new Request ( Method . POST , new Reference ( url ) ) ; request . setEntity ( JsonParameters . JSON_PARAMETERS + ""="" + ClusterRepresentationUtil . ObjectToJson ( params ) , MediaType . APPLICATION_ALL ) ; Response response = client . handle ( request ) ; Representation result = response . getEntity ( ) ; StringWriter sw = new StringWriter ( ) ; result . write ( sw ) ; String responseStr = sw . toString ( ) ; Assert . assertTrue ( responseStr . toLowerCase ( ) . indexOf ( ""error"" ) == - 1 ) ; Assert . assertTrue ( responseStr . toLowerCase ( ) . indexOf ( ""exception"" ) == - 1 ) ; } void verifyEnableCluster ( ) throws Exception { System . out . println ( ""START: verifyEnableCluster()"" ) ; String httpUrlBase = ""http://localhost:"" + ADMIN_PORT + ""/clusters/"" + clusterName + ""/Controller"" ; Map < String , String > paramMap = new HashMap < String , String > ( ) ; paramMap . put ( JsonParameters . MANAGEMENT_COMMAND , ClusterSetup . enableCluster ) ; paramMap . put ( JsonParameters . ENABLED , """" + false ) ; Reference resourceRef = new Reference ( httpUrlBase ) ; Request request = new Request ( Method . POST , resourceRef ) ; request . setEntity ( JsonParameters . JSON_PARAMETERS + ""="" + ClusterRepresentationUtil . ObjectToJson ( paramMap ) , MediaType . APPLICATION_ALL ) ; Response response = _gClient . handle ( request ) ; Representation result = response . getEntity ( ) ; StringWriter sw = new StringWriter ( ) ; result . write ( sw ) ; System . out . println ( sw . toString ( ) ) ; String pausePath = PropertyPathConfig . getPath ( PropertyType . PAUSE , clusterName ) ; System . out . println ( ""pausePath: "" + pausePath ) ; boolean exists = _zkclient . exists ( pausePath ) ; Assert . assertTrue ( exists , pausePath + "" should exist"" ) ; paramMap . put ( JsonParameters . ENABLED , """" + true ) ; request = new Request ( Method . POST , resourceRef ) ; request . setEntity ( JsonParameters . JSON_PARAMETERS + ""="" + ClusterRepresentationUtil . ObjectToJson ( paramMap ) , MediaType . APPLICATION_ALL ) ; response = _gClient . handle ( request ) ; result = response . getEntity ( ) ; sw = new StringWriter ( ) ; result . write ( sw ) ; System . out . println ( sw . toString ( ) ) ; exists = _zkclient . exists ( pausePath ) ; Assert . assertFalse ( exists , pausePath + "" should be removed"" ) ; System . out . println ( ""END: verifyEnableCluster()"" ) ; } private boolean contains ( List < String > list , String ... items ) { for ( String item : items ) { if ( ! list . contains ( item ) ) { return false ; } } return true ; } }",Smelly
"public class MappingGeneratorImpl implements MappingGenerator { private final MapperConfig config ; private final JsonGenerator generator ; private final Mappings mappings ; private final Boolean isDeduplicateObjects ; private Map < Object , String > jsonPointers ; MappingGeneratorImpl ( MapperConfig config , JsonGenerator jsonGenerator , final Mappings mappings , Boolean isDeduplicateObjects ) { this . config = config ; this . generator = jsonGenerator ; this . mappings = mappings ; this . isDeduplicateObjects = isDeduplicateObjects ; this . jsonPointers = isDeduplicateObjects ? new HashMap < > ( ) : Collections . emptyMap ( ) ; } @ Override public JsonGenerator getJsonGenerator ( ) { return generator ; } @ Override public MappingGenerator writeObject ( final String key , final Object object , final JsonGenerator generator ) { if ( object == null ) { return this ; } else if ( object instanceof JsonValue ) { generator . write ( key , JsonValue . class . cast ( object ) ) ; } else { final Class < ? > objectClass = object . getClass ( ) ; try { if ( Map . class . isInstance ( object ) ) { writeValue ( Map . class , false , false , false , false , true , null , key , object , null , emptyList ( ) , isDeduplicateObjects ? new JsonPointerTracker ( null , ""/"" ) : null , generator ) ; } else if ( writePrimitives ( key , objectClass , object , generator ) ) { } else if ( objectClass . isEnum ( ) ) { final Adapter adapter = config . findAdapter ( objectClass ) ; final String adaptedValue = adapter . from ( object ) . toString ( ) ; generator . write ( key , adaptedValue ) ; } else if ( objectClass . isArray ( ) ) { writeValue ( Map . class , false , false , true , false , false , null , key , object , null , emptyList ( ) , isDeduplicateObjects ? new JsonPointerTracker ( null , ""/"" ) : null , generator ) ; } else if ( Iterable . class . isInstance ( object ) ) { writeValue ( Map . class , false , false , false , true , false , null , key , object , null , emptyList ( ) , isDeduplicateObjects ? new JsonPointerTracker ( null , ""/"" ) : null , generator ) ; } else { final ObjectConverter . Writer objectConverter = config . findObjectConverterWriter ( objectClass ) ; if ( objectConverter != null ) { final DynamicMappingGenerator dynamicMappingGenerator = new DynamicMappingGenerator ( this , generator :: writeStartObject , generator :: writeEnd , null ) ; objectConverter . writeJson ( object , dynamicMappingGenerator ) ; dynamicMappingGenerator . flushIfNeeded ( ) ; } else { writeValue ( objectClass , false , false , false , false , false , null , key , object , null , emptyList ( ) , isDeduplicateObjects ? new JsonPointerTracker ( null , ""/"" ) : null , generator ) ; } } } catch ( final InvocationTargetException | IllegalAccessException e ) { throw new MapperException ( e ) ; } } return this ; } @ Override public MappingGenerator writeObject ( final Object object , final JsonGenerator generator ) { if ( object == null ) { return this ; } else if ( object instanceof JsonValue ) { generator . write ( ( JsonValue ) object ) ; } else { doWriteObject ( object , generator , false , null , isDeduplicateObjects ? new JsonPointerTracker ( null , ""/"" ) : null ) ; } return this ; } public void doWriteObject ( Object object , JsonGenerator generator , boolean writeBody , final Collection < String > ignoredProperties , JsonPointerTracker jsonPointer ) { try { if ( object instanceof Map ) { if ( writeBody ) { generator . writeStartObject ( ) ; } writeMapBody ( ( Map < ? , ? > ) object , null ) ; if ( writeBody ) { generator . writeEnd ( ) ; } return ; } if ( writePrimitives ( object ) ) { return ; } final Class < ? > objectClass = object . getClass ( ) ; if ( objectClass . isEnum ( ) ) { final Adapter adapter = config . findAdapter ( objectClass ) ; final String adaptedValue = adapter . from ( object ) . toString ( ) ; generator . write ( adaptedValue ) ; return ; } if ( objectClass . isArray ( ) ) { final Adapter adapter = config . findAdapter ( objectClass ) ; writeArray ( objectClass , adapter , null , object , ignoredProperties , jsonPointer ) ; return ; } if ( object instanceof Iterable ) { doWriteIterable ( ( Iterable ) object , ignoredProperties , jsonPointer ) ; return ; } ObjectConverter . Writer objectConverter = config . findObjectConverterWriter ( objectClass ) ; if ( writeBody && objectConverter != null ) { if ( ! writeBody ) { objectConverter . writeJson ( object , this ) ; } else { final DynamicMappingGenerator dynamicMappingGenerator = new DynamicMappingGenerator ( this , generator :: writeStartObject , generator :: writeEnd , null ) ; objectConverter . writeJson ( object , dynamicMappingGenerator ) ; dynamicMappingGenerator . flushIfNeeded ( ) ; } } else { if ( writeBody ) { generator . writeStartObject ( ) ; } doWriteObjectBody ( object , ignoredProperties , jsonPointer , generator ) ; if ( writeBody ) { generator . writeEnd ( ) ; } } } catch ( final InvocationTargetException | IllegalAccessException e ) { throw new MapperException ( e ) ; } } private JsonGenerator writeMapBody ( final Map < ? , ? > object , final Adapter itemConverter ) throws InvocationTargetException , IllegalAccessException { for ( final Map . Entry < ? , ? > entry : ( ( Map < ? , ? > ) object ) . entrySet ( ) ) { final Object value = entry . getValue ( ) ; final Object key = entry . getKey ( ) ; if ( value == null ) { if ( config . isSkipNull ( ) ) { continue ; } else { generator . writeNull ( key == null ? ""null"" : key . toString ( ) ) ; continue ; } } final Class < ? > valueClass = value . getClass ( ) ; writeValue ( valueClass , true , false , false , false , false , itemConverter , key == null ? ""null"" : key . toString ( ) , value , null , null , null , generator ) ; } return generator ; } private boolean writePrimitives ( final Object value ) { boolean handled = false ; if ( value == null ) { return true ; } final Class < ? > type = value . getClass ( ) ; if ( type == String . class ) { generator . write ( value . toString ( ) ) ; handled = true ; } else if ( type == long . class || type == Long . class ) { generator . write ( Long . class . cast ( value ) . longValue ( ) ) ; handled = true ; } else if ( isInt ( type ) ) { generator . write ( Number . class . cast ( value ) . intValue ( ) ) ; handled = true ; } else if ( isFloat ( type ) ) { final double doubleValue = Number . class . cast ( value ) . doubleValue ( ) ; if ( ! Double . isNaN ( doubleValue ) ) { generator . write ( doubleValue ) ; } handled = true ; } else if ( type == boolean . class || type == Boolean . class ) { generator . write ( Boolean . class . cast ( value ) ) ; return true ; } else if ( type == BigDecimal . class ) { generator . write ( BigDecimal . class . cast ( value ) ) ; handled = true ; } else if ( type == BigInteger . class ) { generator . write ( BigInteger . class . cast ( value ) ) ; handled = true ; } else if ( type == char . class || type == Character . class ) { generator . write ( Character . class . cast ( value ) . toString ( ) ) ; handled = true ; } return handled ; } private boolean writePrimitives ( final String key , final Class < ? > type , final Object value , final JsonGenerator generator ) { boolean handled = false ; if ( type == String . class ) { generator . write ( key , value . toString ( ) ) ; handled = true ; } else if ( type == long . class || type == Long . class ) { generator . write ( key , Long . class . cast ( value ) . longValue ( ) ) ; handled = true ; } else if ( isInt ( type ) ) { generator . write ( key , Number . class . cast ( value ) . intValue ( ) ) ; handled = true ; } else if ( isFloat ( type ) ) { final double doubleValue = Number . class . cast ( value ) . doubleValue ( ) ; if ( ! Double . isNaN ( doubleValue ) ) { generator . write ( key , doubleValue ) ; } handled = true ; } else if ( type == boolean . class || type == Boolean . class ) { generator . write ( key , Boolean . class . cast ( value ) ) ; handled = true ; } else if ( type == BigDecimal . class ) { generator . write ( key , BigDecimal . class . cast ( value ) ) ; handled = true ; } else if ( type == BigInteger . class ) { generator . write ( key , BigInteger . class . cast ( value ) ) ; handled = true ; } else if ( type == char . class || type == Character . class ) { generator . write ( key , Character . class . cast ( value ) . toString ( ) ) ; handled = true ; } return handled ; } private static boolean isInt ( final Class < ? > type ) { return type == int . class || type == Integer . class || type == byte . class || type == Byte . class || type == short . class || type == Short . class ; } private static boolean isFloat ( final Class < ? > type ) { return type == double . class || type == Double . class || type == float . class || type == Float . class ; } private void doWriteObjectBody ( final Object object , final Collection < String > ignored , final JsonPointerTracker jsonPointer , final JsonGenerator generator ) throws IllegalAccessException , InvocationTargetException { if ( jsonPointer != null ) { jsonPointers . put ( object , jsonPointer . toString ( ) ) ; } final Class < ? > objectClass = object . getClass ( ) ; final Mappings . ClassMapping classMapping = mappings . findOrCreateClassMapping ( objectClass ) ; if ( classMapping == null ) { throw new MapperException ( ""No mapping for "" + objectClass . getName ( ) ) ; } if ( classMapping . writer != null ) { classMapping . writer . writeJson ( object , this ) ; return ; } if ( classMapping . adapter != null ) { doWriteObjectBody ( classMapping . adapter . to ( object ) , ignored , jsonPointer , generator ) ; return ; } for ( final Map . Entry < String , Mappings . Getter > getterEntry : classMapping . getters . entrySet ( ) ) { final Mappings . Getter getter = getterEntry . getValue ( ) ; if ( ignored != null && ignored . contains ( getterEntry . getKey ( ) ) ) { continue ; } if ( getter . version >= 0 && config . getVersion ( ) >= 0 && config . getVersion ( ) < getter . version ) { continue ; } final Object value = getter . reader . read ( object ) ; if ( JsonValue . class . isInstance ( value ) ) { generator . write ( getterEntry . getKey ( ) , JsonValue . class . cast ( value ) ) ; continue ; } if ( value == null ) { if ( config . isSkipNull ( ) && ! getter . reader . isNillable ( ) ) { continue ; } else { generator . writeNull ( getterEntry . getKey ( ) ) ; continue ; } } final Object val = getter . converter == null ? value : getter . converter . from ( value ) ; String valJsonPointer = jsonPointers . get ( val ) ; if ( valJsonPointer != null ) { generator . write ( getterEntry . getKey ( ) , valJsonPointer ) ; } else { writeValue ( val . getClass ( ) , getter . dynamic , getter . primitive , getter . array , getter . collection , getter . map , getter . itemConverter , getterEntry . getKey ( ) , val , getter . objectConverter , getter . ignoreNested , isDeduplicateObjects ? new JsonPointerTracker ( jsonPointer , getterEntry . getKey ( ) ) : null , generator ) ; } } if ( classMapping . anyGetter != null ) { final Map < String , Object > any = Map . class . cast ( classMapping . anyGetter . reader . read ( object ) ) ; if ( any != null ) { writeMapBody ( any , null ) ; } } } private void writeValue ( final Class < ? > type , final boolean dynamic , final boolean primitive , final boolean array , final boolean collection , final boolean map , final Adapter itemConverter , final String key , final Object value , final ObjectConverter . Writer objectConverter , final Collection < String > ignoredProperties , final JsonPointerTracker jsonPointer , final JsonGenerator generator ) throws InvocationTargetException , IllegalAccessException { if ( config . getSerializeValueFilter ( ) . shouldIgnore ( key , value ) ) { return ; } if ( array || ( dynamic && type . isArray ( ) ) ) { writeArray ( type , itemConverter , key , value , ignoredProperties , jsonPointer ) ; } else if ( collection || ( dynamic && Collection . class . isAssignableFrom ( type ) ) ) { generator . writeStartArray ( key ) ; int i = 0 ; for ( final Object o : Collection . class . cast ( value ) ) { String valJsonPointer = jsonPointers . get ( o ) ; if ( valJsonPointer != null ) { writePrimitives ( valJsonPointer ) ; } else { ObjectConverter . Writer objectConverterToUse = objectConverter ; if ( o != null && objectConverterToUse == null ) { objectConverterToUse = config . findObjectConverterWriter ( o . getClass ( ) ) ; } if ( objectConverterToUse != null ) { final DynamicMappingGenerator dynamicMappingGenerator = new DynamicMappingGenerator ( this , generator :: writeStartObject , generator :: writeEnd , null ) ; objectConverterToUse . writeJson ( o , dynamicMappingGenerator ) ; dynamicMappingGenerator . flushIfNeeded ( ) ; } else { writeItem ( itemConverter != null ? itemConverter . from ( o ) : o , ignoredProperties , isDeduplicateObjects ? new JsonPointerTracker ( jsonPointer , i ) : null ) ; } } i ++ ; } generator . writeEnd ( ) ; } else if ( map || ( dynamic && Map . class . isAssignableFrom ( type ) ) ) { generator . writeStartObject ( key ) ; writeMapBody ( ( Map < ? , ? > ) value , itemConverter ) ; generator . writeEnd ( ) ; } else if ( primitive || ( dynamic && Mappings . isPrimitive ( type ) ) ) { if ( objectConverter != null ) { final DynamicMappingGenerator dynamicMappingGenerator = new DynamicMappingGenerator ( this , ( ) -> this . generator . writeStartObject ( key ) , this . generator :: writeEnd , key ) ; objectConverter . writeJson ( value , dynamicMappingGenerator ) ; dynamicMappingGenerator . flushIfNeeded ( ) ; } else { writePrimitives ( key , type , value , generator ) ; } } else { if ( objectConverter != null ) { final DynamicMappingGenerator dynamicMappingGenerator = new DynamicMappingGenerator ( this , ( ) -> this . generator . writeStartObject ( key ) , this . generator :: writeEnd , key ) ; objectConverter . writeJson ( value , dynamicMappingGenerator ) ; dynamicMappingGenerator . flushIfNeeded ( ) ; return ; } final Adapter converter = config . findAdapter ( type ) ; if ( converter != null ) { final Object adapted = doConvertFrom ( value , converter ) ; if ( writePrimitives ( key , adapted . getClass ( ) , adapted , generator ) ) { return ; } writeValue ( String . class , true , true , false , false , false , null , key , adapted , null , ignoredProperties , jsonPointer , generator ) ; return ; } else { ObjectConverter . Writer objectConverterToUse = objectConverter ; if ( objectConverterToUse == null ) { objectConverterToUse = config . findObjectConverterWriter ( type ) ; } if ( objectConverterToUse != null ) { final DynamicMappingGenerator dynamicMappingGenerator = new DynamicMappingGenerator ( this , ( ) -> this . generator . writeStartObject ( key ) , this . generator :: writeEnd , key ) ; objectConverterToUse . writeJson ( value , dynamicMappingGenerator ) ; dynamicMappingGenerator . flushIfNeeded ( ) ; return ; } } if ( writePrimitives ( key , type , value , generator ) ) { return ; } generator . writeStartObject ( key ) ; doWriteObjectBody ( value , ignoredProperties , jsonPointer , generator ) ; generator . writeEnd ( ) ; } } private void writeArray ( Class < ? > type , Adapter itemConverter , String key , Object arrayValue , Collection < String > ignoredProperties , JsonPointerTracker jsonPointer ) { final int length = Array . getLength ( arrayValue ) ; if ( length == 0 && config . isSkipEmptyArray ( ) ) { return ; } if ( config . isTreatByteArrayAsBase64 ( ) && ( type == byte [ ] . class ) ) { String base64EncodedByteArray = Base64 . getEncoder ( ) . encodeToString ( ( byte [ ] ) arrayValue ) ; if ( key != null ) { generator . write ( key , base64EncodedByteArray ) ; } else { generator . write ( base64EncodedByteArray ) ; } return ; } if ( config . isTreatByteArrayAsBase64URL ( ) && ( type == byte [ ] . class ) ) { if ( key != null ) { generator . write ( key , Base64 . getUrlEncoder ( ) . encodeToString ( ( byte [ ] ) arrayValue ) ) ; } else { generator . write ( Base64 . getUrlEncoder ( ) . encodeToString ( ( byte [ ] ) arrayValue ) ) ; } return ; } if ( key != null ) { generator . writeStartArray ( key ) ; } else { generator . writeStartArray ( ) ; } if ( type == byte [ ] . class ) { byte [ ] tArrayValue = ( byte [ ] ) arrayValue ; for ( int i = 0 ; i < length ; i ++ ) { final byte o = tArrayValue [ i ] ; generator . write ( o ) ; } } else if ( type == short [ ] . class ) { short [ ] tArrayValue = ( short [ ] ) arrayValue ; for ( int i = 0 ; i < length ; i ++ ) { final short o = tArrayValue [ i ] ; generator . write ( o ) ; } } else if ( type == int [ ] . class ) { int [ ] tArrayValue = ( int [ ] ) arrayValue ; for ( int i = 0 ; i < length ; i ++ ) { final int o = tArrayValue [ i ] ; generator . write ( o ) ; } } else if ( type == long [ ] . class ) { long [ ] tArrayValue = ( long [ ] ) arrayValue ; for ( int i = 0 ; i < length ; i ++ ) { final long o = tArrayValue [ i ] ; generator . write ( o ) ; } } else if ( type == float [ ] . class ) { float [ ] tArrayValue = ( float [ ] ) arrayValue ; for ( int i = 0 ; i < length ; i ++ ) { final float o = tArrayValue [ i ] ; generator . write ( o ) ; } } else if ( type == double [ ] . class ) { double [ ] tArrayValue = ( double [ ] ) arrayValue ; for ( int i = 0 ; i < length ; i ++ ) { final double o = tArrayValue [ i ] ; generator . write ( o ) ; } } else if ( type == char [ ] . class ) { char [ ] tArrayValue = ( char [ ] ) arrayValue ; for ( int i = 0 ; i < length ; i ++ ) { final char o = tArrayValue [ i ] ; generator . write ( String . valueOf ( o ) ) ; } } else if ( type == boolean [ ] . class ) { boolean [ ] tArrayValue = ( boolean [ ] ) arrayValue ; for ( int i = 0 ; i < length ; i ++ ) { final boolean o = tArrayValue [ i ] ; generator . write ( o ) ; } } else if ( type == Byte [ ] . class || type == Short [ ] . class || type == Integer [ ] . class || type == Long [ ] . class || type == Float [ ] . class || type == Double [ ] . class || type == Character [ ] . class || type == Boolean [ ] . class ) { Object [ ] oArrayValue = ( Object [ ] ) arrayValue ; for ( int i = 0 ; i < length ; i ++ ) { final Object o = oArrayValue [ i ] ; writeItem ( itemConverter != null ? itemConverter . from ( o ) : o , ignoredProperties , null ) ; } } else { for ( int i = 0 ; i < length ; i ++ ) { Object [ ] oArrayValue = ( Object [ ] ) arrayValue ; final Object o = oArrayValue [ i ] ; String valJsonPointer = jsonPointers . get ( o ) ; if ( valJsonPointer != null ) { generator . write ( valJsonPointer ) ; } else { writeItem ( itemConverter != null ? itemConverter . from ( o ) : o , ignoredProperties , isDeduplicateObjects ? new JsonPointerTracker ( jsonPointer , i ) : null ) ; } } } generator . writeEnd ( ) ; } private void writeItem ( final Object o , final Collection < String > ignoredProperties , JsonPointerTracker jsonPointer ) { if ( o == null ) { generator . writeNull ( ) ; } else if ( ! writePrimitives ( o ) ) { if ( Collection . class . isInstance ( o ) ) { doWriteIterable ( Collection . class . cast ( o ) , ignoredProperties , jsonPointer ) ; } else if ( o . getClass ( ) . isArray ( ) ) { final int length = Array . getLength ( o ) ; if ( length > 0 || ! config . isSkipEmptyArray ( ) ) { writeArray ( o . getClass ( ) , null , null , o , ignoredProperties , jsonPointer ) ; } } else { String valJsonPointer = jsonPointers . get ( o ) ; if ( valJsonPointer != null ) { generator . write ( valJsonPointer ) ; } else { doWriteObject ( o , generator , true , ignoredProperties , jsonPointer ) ; } } } } private < T > void doWriteIterable ( final Iterable < T > object , final Collection < String > ignoredProperties , JsonPointerTracker jsonPointer ) { if ( object == null ) { generator . writeStartArray ( ) . writeEnd ( ) ; } else { generator . writeStartArray ( ) ; int i = 0 ; for ( final T t : object ) { if ( JsonValue . class . isInstance ( t ) ) { generator . write ( JsonValue . class . cast ( t ) ) ; } else { if ( t == null ) { generator . writeNull ( ) ; } else { writeItem ( t , ignoredProperties , isDeduplicateObjects ? new JsonPointerTracker ( jsonPointer , i ) : null ) ; } } i ++ ; } generator . writeEnd ( ) ; } } private < T > Object doConvertFrom ( final T value , final Adapter < T , Object > converter ) { if ( converter == null ) { throw new MapperException ( ""can't convert "" + value + "" to String"" ) ; } return converter . from ( value ) ; } }",Smelly
"public class Rapier extends TextRulerBasicLearner { public final static String COMPRESSION_FAIL_MAX_COUNT_KEY = ""compressionFailMaxCount"" ; public final static String RULELIST_SIZE_KEY = ""ruleListSize"" ; public final static String PAIR_COUNT_KEY = ""pairCount"" ; public final static String LIM_NO_IMPROVEMENTS_KEY = ""limNoImprovements"" ; public final static String NOISE_THESHOLD_KEY = ""noiseThreshold"" ; public final static String POSTAG_ROOTTYPE_KEY = ""posTagRootType"" ; public final static String MIN_COVERED_POSITIVES_KEY = ""minCoveredPositives"" ; public final static String USE_ALL_GENSETS_AT_SPECIALIZATION_KEY = ""useAllGenSetsAtSpecialization"" ; public final static int STANDARD_COMPRESSION_FAIL_MAX_COUNT = 3 ; public final static int STANDARD_RULELIST_SIZE = 50 ; public final static int STANDARD_PAIR_COUNT = 4 ; public final static int STANDARD_LIM_NO_IMPROVEMENTS = 3 ; public final static float STANDARD_NOISE_THREHSOLD = 0.9f ; public final static String STANDARD_POSTAG_ROOTTYPE = ""org.apache.uima.ml.ML.postag"" ; public final static int STANDARD_MIN_COVERED_POSITIVES = 1 ; public final static boolean STANDARD_USE_ALL_GENSETS_AT_SPECIALIZATION = true ; private int compressionFailMaxCount = STANDARD_COMPRESSION_FAIL_MAX_COUNT ; private int ruleListSize = STANDARD_RULELIST_SIZE ; private int pairCount = STANDARD_PAIR_COUNT ; private int limNoImprovements = STANDARD_LIM_NO_IMPROVEMENTS ; private float noiseThreshold = STANDARD_NOISE_THREHSOLD ; private String posTagRootTypeName = STANDARD_POSTAG_ROOTTYPE ; private int minCoveredPositives = STANDARD_MIN_COVERED_POSITIVES ; private boolean useAllGenSetsAtSpecialization = STANDARD_USE_ALL_GENSETS_AT_SPECIALIZATION ; private Map < String , TextRulerStatisticsCollector > cachedTestedRuleStatistics = new HashMap < String , TextRulerStatisticsCollector > ( ) ; private int initialRuleBaseSize ; private List < TextRulerExample > examples ; private TextRulerRuleList slotRules ; private RapierRulePriorityQueue ruleList ; private String currentSlotName ; public Rapier ( String inputDir , String prePropTMFile , String tmpDir , String [ ] slotNames , Set < String > filterSet , boolean skip , TextRulerLearnerDelegate delegate ) { super ( inputDir , prePropTMFile , tmpDir , slotNames , filterSet , skip , delegate ) ; } @ Override protected void doRun ( ) { for ( int i = 0 ; i < slotNames . length ; i ++ ) { int compressionFailCount = 0 ; currentSlotName = slotNames [ i ] ; cachedTestedRuleStatistics . clear ( ) ; exampleDocuments . createExamplesForTarget ( new TextRulerTarget ( currentSlotName , this ) ) ; examples = exampleDocuments . getAllPositiveExamples ( ) ; if ( shouldAbort ( ) ) return ; slotRules = new TextRulerRuleList ( ) ; ruleList = new RapierRulePriorityQueue ( ruleListSize ) ; TextRulerToolkit . log ( ""--- RAPIER START for Slot "" + currentSlotName ) ; sendStatusUpdateToDelegate ( ""Creating initial rule base..."" , TextRulerLearnerState . ML_INITIALIZING , false ) ; fillSlotRulesWithMostSpecificRules ( ) ; updateCompressionStatusString ( ) ; if ( TextRulerToolkit . DEBUG ) { slotRules . saveToRulesFile ( getIntermediateRulesFileName ( ) , getFileHeaderString ( true ) ) ; } while ( compressionFailCount < compressionFailMaxCount ) { TextRulerToolkit . log ( ""***** NEW COMPRESSION ROUND; FailCount = "" + compressionFailCount ) ; if ( shouldAbort ( ) ) { return ; } RapierRule bestRule = findNewRule ( ) ; if ( bestRule != null && ( bestRule . getCoveringStatistics ( ) . getCoveredPositivesCount ( ) >= minCoveredPositives ) && ( bestRule . noiseValue ( ) >= noiseThreshold ) && ( ! slotRules . contains ( bestRule ) ) ) { addRuleAndRemoveEmpiricallySubsumedRules ( bestRule ) ; if ( TextRulerToolkit . DEBUG ) slotRules . saveToRulesFile ( getIntermediateRulesFileName ( ) , getFileHeaderString ( true ) ) ; } else { compressionFailCount ++ ; } } if ( TextRulerToolkit . DEBUG ) { slotRules . saveToRulesFile ( getIntermediateRulesFileName ( ) , getFileHeaderString ( true ) ) ; } } sendStatusUpdateToDelegate ( ""Done"" , TextRulerLearnerState . ML_DONE , true ) ; cachedTestedRuleStatistics . clear ( ) ; TextRulerToolkit . log ( ""--- RAPIER END"" ) ; } private void updateCompressionStatusString ( ) { double percent = Math . round ( ( slotRules . size ( ) / ( double ) initialRuleBaseSize ) * 100.0 ) ; sendStatusUpdateToDelegate ( ""Compressing... (Rules = "" + slotRules . size ( ) + ""/"" + initialRuleBaseSize + ""  = "" + percent + "" % ratio)"" , TextRulerLearnerState . ML_RUNNING , true ) ; } private void addAvailablePosTagConstraintToItem ( RapierRuleItem item , AnnotationFS tokenAnnotation , TextRulerExample example ) { if ( posTagRootTypeName != null && posTagRootTypeName . length ( ) > 0 ) { CAS cas = example . getDocumentCAS ( ) ; TypeSystem ts = cas . getTypeSystem ( ) ; Type posTagsRootType = ts . getType ( posTagRootTypeName ) ; if ( ts != null ) { List < AnnotationFS > posTagAnnotations = TextRulerToolkit . getAnnotationsWithinBounds ( cas , tokenAnnotation . getBegin ( ) , tokenAnnotation . getEnd ( ) , null , posTagsRootType ) ; if ( posTagAnnotations . size ( ) > 0 ) { AnnotationFS posTag = posTagAnnotations . get ( 0 ) ; if ( posTag . getBegin ( ) == tokenAnnotation . getBegin ( ) && posTag . getEnd ( ) == tokenAnnotation . getEnd ( ) ) item . addTagConstraint ( posTag . getType ( ) . getShortName ( ) ) ; } } } } private void fillSlotRulesWithMostSpecificRules ( ) { slotRules . clear ( ) ; for ( TextRulerExample example : examples ) { RapierRule rule = new RapierRule ( this , example . getTarget ( ) ) ; TextRulerAnnotation slotAnnotation = example . getAnnotation ( ) ; CAS docCas = example . getDocumentCAS ( ) ; TypeSystem ts = docCas . getTypeSystem ( ) ; Type tokensRootType = ts . getType ( TextRulerToolkit . RUTA_ANY_TYPE_NAME ) ; List < AnnotationFS > before = TextRulerToolkit . getAnnotationsBeforePosition ( example . getDocumentCAS ( ) , slotAnnotation . getBegin ( ) , - 1 , TextRulerToolkit . getFilterSetWithSlotNames ( slotNames , filterSet ) , tokensRootType ) ; List < AnnotationFS > after = TextRulerToolkit . getAnnotationsAfterPosition ( example . getDocumentCAS ( ) , slotAnnotation . getEnd ( ) , - 1 , TextRulerToolkit . getFilterSetWithSlotNames ( slotNames , filterSet ) , tokensRootType ) ; List < AnnotationFS > inside = TextRulerToolkit . getAnnotationsWithinBounds ( example . getDocumentCAS ( ) , slotAnnotation . getBegin ( ) , slotAnnotation . getEnd ( ) , TextRulerToolkit . getFilterSetWithSlotNames ( slotNames , filterSet ) , tokensRootType ) ; for ( int i = before . size ( ) - 1 ; i >= 0 ; i -- ) { AnnotationFS afs = before . get ( i ) ; RapierRuleItem ruleItem = new RapierRuleItem ( ) ; ruleItem . addWordConstraint ( new TextRulerWordConstraint ( new TextRulerAnnotation ( afs , example . getDocument ( ) ) ) ) ; addAvailablePosTagConstraintToItem ( ruleItem , afs , example ) ; rule . addPreFillerItem ( ruleItem ) ; } for ( AnnotationFS afs : inside ) { RapierRuleItem ruleItem = new RapierRuleItem ( ) ; ruleItem . addWordConstraint ( new TextRulerWordConstraint ( new TextRulerAnnotation ( afs , example . getDocument ( ) ) ) ) ; addAvailablePosTagConstraintToItem ( ruleItem , afs , example ) ; rule . addFillerItem ( ruleItem ) ; } for ( AnnotationFS afs : after ) { RapierRuleItem ruleItem = new RapierRuleItem ( ) ; ruleItem . addWordConstraint ( new TextRulerWordConstraint ( new TextRulerAnnotation ( afs , example . getDocument ( ) ) ) ) ; addAvailablePosTagConstraintToItem ( ruleItem , afs , example ) ; rule . addPostFillerItem ( ruleItem ) ; } TextRulerStatisticsCollector c = new TextRulerStatisticsCollector ( ) ; c . addCoveredPositive ( example ) ; rule . setCoveringStatistics ( c ) ; slotRules . add ( rule ) ; } initialRuleBaseSize = slotRules . size ( ) ; } protected void addRuleAndRemoveEmpiricallySubsumedRules ( RapierRule rule ) { if ( ! slotRules . contains ( rule ) ) { List < TextRulerRule > rulesToRemove = new ArrayList < TextRulerRule > ( ) ; Set < TextRulerExample > coveredExamples = rule . getCoveringStatistics ( ) . getCoveredPositiveExamples ( ) ; for ( TextRulerRule r : slotRules ) { if ( coveredExamples . containsAll ( r . getCoveringStatistics ( ) . getCoveredPositiveExamples ( ) ) ) rulesToRemove . add ( r ) ; } for ( TextRulerRule removeR : rulesToRemove ) slotRules . remove ( removeR ) ; slotRules . add ( rule ) ; updateCompressionStatusString ( ) ; } } protected RapierRule findNewRule ( ) { Random rand = new Random ( System . currentTimeMillis ( ) ) ; Set < RapierRule > generalizations = new HashSet < RapierRule > ( ) ; ruleList . clear ( ) ; if ( slotRules . size ( ) <= 1 ) return null ; List < RapierRule > uncompressedRules = new ArrayList < RapierRule > ( ) ; for ( TextRulerRule r : slotRules ) { if ( ( ( RapierRule ) r ) . isInitialRule ( ) ) uncompressedRules . add ( ( RapierRule ) r ) ; } int pairsLeft = pairCount ; if ( uncompressedRules . size ( ) == 1 ) { RapierRule rule1 = uncompressedRules . get ( 0 ) ; RapierRule rule2 = null ; while ( rule2 == null || rule1 == rule2 ) { rule2 = ( RapierRule ) slotRules . get ( rand . nextInt ( slotRules . size ( ) ) ) ; } generalizations . addAll ( getFillerGeneralizationsForRulePair ( rule1 , rule2 ) ) ; if ( shouldAbort ( ) ) return null ; pairsLeft -- ; } else if ( uncompressedRules . size ( ) == 2 ) { RapierRule rule1 = uncompressedRules . get ( 0 ) ; RapierRule rule2 = uncompressedRules . get ( 1 ) ; generalizations . addAll ( getFillerGeneralizationsForRulePair ( rule1 , rule2 ) ) ; if ( shouldAbort ( ) ) return null ; pairsLeft -- ; } else if ( uncompressedRules . size ( ) > 2 ) { int uPairCount = pairCount ; if ( uPairCount > uncompressedRules . size ( ) ) uPairCount /= 2 ; for ( int i = 0 ; i < uPairCount ; i ++ ) { RapierRule rule1 = uncompressedRules . get ( rand . nextInt ( uncompressedRules . size ( ) ) ) ; RapierRule rule2 = null ; while ( rule2 == null || rule1 == rule2 ) { rule2 = uncompressedRules . get ( rand . nextInt ( uncompressedRules . size ( ) ) ) ; } generalizations . addAll ( getFillerGeneralizationsForRulePair ( rule1 , rule2 ) ) ; pairsLeft -- ; } } for ( int i = 0 ; i < pairsLeft ; i ++ ) { RapierRule rule1 = ( RapierRule ) slotRules . get ( rand . nextInt ( slotRules . size ( ) ) ) ; RapierRule rule2 = null ; while ( rule2 == null || rule1 == rule2 ) { rule2 = ( RapierRule ) slotRules . get ( rand . nextInt ( slotRules . size ( ) ) ) ; } generalizations . addAll ( getFillerGeneralizationsForRulePair ( rule1 , rule2 ) ) ; if ( shouldAbort ( ) ) return null ; } List < RapierRule > testRules = new ArrayList < RapierRule > ( generalizations ) ; for ( RapierRule r : testRules ) { r . combineSenselessPatternListItems ( ) ; } testRulesIfNotCached ( testRules ) ; if ( shouldAbort ( ) ) return null ; for ( RapierRule newRule : generalizations ) { if ( TextRulerToolkit . DEBUG ) { if ( ! RapierDebugHelper . debugCheckIfRuleCoversItsSeedRuleCoverings ( newRule ) ) { TextRulerToolkit . log ( ""------------------------------------------------------------------------------------------"" ) ; TextRulerToolkit . log ( ""ERROR, A RULE HAS TO COVER AT LEAST EVERY POSITIVE EXAMPLE OF ITS TWO SEED RULES!!!"" ) ; TextRulerToolkit . log ( ""\t RULE: "" + newRule . getRuleString ( ) ) ; TextRulerToolkit . log ( ""\t Parent1: "" + newRule . getParent1 ( ) . getRuleString ( ) ) ; TextRulerToolkit . log ( ""\t Parent2: "" + newRule . getParent2 ( ) . getRuleString ( ) ) ; TextRulerToolkit . log ( ""--------"" ) ; TextRulerToolkit . log ( ""+RuleCovering: "" + newRule . getCoveringStatistics ( ) . getCoveredPositiveExamples ( ) ) ; TextRulerToolkit . log ( ""+P1Covering  : "" + newRule . getParent1 ( ) . getCoveringStatistics ( ) . getCoveredPositiveExamples ( ) ) ; TextRulerToolkit . log ( ""+P2Covering  : "" + newRule . getParent2 ( ) . getCoveringStatistics ( ) . getCoveredPositiveExamples ( ) ) ; } } ruleList . add ( newRule ) ; } int n = 0 ; double bestValue = Double . MAX_VALUE ; int noImprovementCounter = 0 ; while ( true ) { n ++ ; TextRulerToolkit . log ( "" --- NEW SPECIALIZATOIN ROUND; n = "" + n + ""  noImprovementCounter = "" + noImprovementCounter ) ; List < RapierRule > newRuleList = new ArrayList < RapierRule > ( ) ; for ( RapierRule curRule : ruleList ) { List < RapierRule > specTestRules = new ArrayList < RapierRule > ( specializePreFiller ( curRule , n ) ) ; for ( RapierRule r : specTestRules ) r . combineSenselessPatternListItems ( ) ; testRulesIfNotCached ( specTestRules ) ; if ( shouldAbort ( ) ) return null ; for ( RapierRule r : specTestRules ) newRuleList . add ( r ) ; } ruleList . addAll ( newRuleList ) ; newRuleList . clear ( ) ; for ( RapierRule curRule : ruleList ) { List < RapierRule > specTestRules = new ArrayList < RapierRule > ( specializePostFiller ( curRule , n ) ) ; for ( RapierRule r : specTestRules ) r . combineSenselessPatternListItems ( ) ; testRulesIfNotCached ( specTestRules ) ; if ( shouldAbort ( ) ) return null ; for ( RapierRule r : specTestRules ) newRuleList . add ( r ) ; } ruleList . addAll ( newRuleList ) ; RapierRule bestRule = ruleList . peek ( ) ; if ( TextRulerToolkit . DEBUG ) { TextRulerToolkit . log ( ""------------------------------------"" ) ; TextRulerToolkit . log ( ""BEST RULE FOR THIS SESSION: "" + bestRule . getCoveringStatistics ( ) ) ; TextRulerToolkit . log ( bestRule . getRuleString ( ) ) ; TextRulerToolkit . log ( ""------------------------------------"" ) ; } if ( bestRule . producesOnlyValidFillers ( ) ) break ; if ( bestRule . getPriority ( ) < bestValue ) { noImprovementCounter = 0 ; bestValue = bestRule . getPriority ( ) ; } else { noImprovementCounter ++ ; if ( noImprovementCounter > limNoImprovements ) break ; } } RapierRule bestRule = ruleList . peek ( ) ; return bestRule ; } private List < RapierRule > getFillerGeneralizationsForRulePair ( RapierRule rule1 , RapierRule rule2 ) { TextRulerToolkit . log ( ""------------------------------------------------------------------------------------------"" ) ; TextRulerToolkit . log ( ""getFillerGeneralizationsForRulePair:"" ) ; TextRulerToolkit . log ( ""Rule1: "" + rule1 . getRuleString ( ) ) ; TextRulerToolkit . log ( ""Rule2: "" + rule2 . getRuleString ( ) ) ; List < RapierRule > result = new ArrayList < RapierRule > ( ) ; List < TextRulerRulePattern > genList = RapierGeneralizationHelper . getGeneralizationsForRuleItemPatterns ( rule1 . getFillerPattern ( ) , rule2 . getFillerPattern ( ) ) ; for ( TextRulerRulePattern pattern : genList ) { RapierRule newRule = new RapierRule ( this , rule1 . getTarget ( ) ) ; for ( TextRulerRuleItem patternItem : pattern ) newRule . addFillerItem ( patternItem . copy ( ) ) ; newRule . setParent1 ( rule1 . copy ( ) ) ; newRule . setParent1PreFiller_n ( 0 ) ; newRule . setParent1PostFiller_n ( 0 ) ; newRule . setParent2 ( rule2 . copy ( ) ) ; newRule . setParent2PreFiller_n ( 0 ) ; newRule . setParent2PostFiller_n ( 0 ) ; result . add ( newRule ) ; newRule . setNeedsCompile ( true ) ; } TextRulerToolkit . log ( ""   getGeneralizationsForRulePair result list size = "" + result . size ( ) ) ; return result ; } public List < RapierRule > specializePreFiller ( RapierRule curRule , int n ) { RapierRule baseRule1 = curRule . getParent1 ( ) ; RapierRule baseRule2 = curRule . getParent2 ( ) ; int n1 = curRule . getParent1PreFiller_n ( ) ; int n2 = curRule . getParent2PreFiller_n ( ) ; TextRulerRulePattern preFiller1 = baseRule1 . getPreFillerPattern ( ) ; TextRulerRulePattern preFiller2 = baseRule2 . getPreFillerPattern ( ) ; int preFiller1MaxIndex = preFiller1 . size ( ) - n1 - 1 ; int preFiller2MaxIndex = preFiller2 . size ( ) - n2 - 1 ; TextRulerRulePattern consideredPreFiller1 = new TextRulerRulePattern ( ) ; TextRulerRulePattern consideredPreFiller2 = new TextRulerRulePattern ( ) ; for ( int i = preFiller1 . size ( ) - n ; i >= 0 && i <= preFiller1MaxIndex ; i ++ ) consideredPreFiller1 . add ( preFiller1 . get ( i ) ) ; for ( int i = preFiller2 . size ( ) - n + 1 ; i >= 0 && i <= preFiller2MaxIndex ; i ++ ) consideredPreFiller2 . add ( preFiller2 . get ( i ) ) ; List < TextRulerRulePattern > genList1 = null ; if ( consideredPreFiller1 . size ( ) + consideredPreFiller2 . size ( ) > 0 ) genList1 = RapierGeneralizationHelper . getGeneralizationsForRuleItemPatterns ( consideredPreFiller1 , consideredPreFiller2 ) ; List < TextRulerRulePattern > genList2 = null ; List < TextRulerRulePattern > genList3 = null ; if ( useAllGenSetsAtSpecialization ) { consideredPreFiller1 . clear ( ) ; consideredPreFiller2 . clear ( ) ; for ( int i = preFiller1 . size ( ) - n + 1 ; i >= 0 && i <= preFiller1MaxIndex ; i ++ ) consideredPreFiller1 . add ( preFiller1 . get ( i ) ) ; for ( int i = preFiller2 . size ( ) - n ; i >= 0 && i <= preFiller2MaxIndex ; i ++ ) consideredPreFiller2 . add ( preFiller2 . get ( i ) ) ; if ( consideredPreFiller1 . size ( ) + consideredPreFiller2 . size ( ) > 0 ) genList2 = RapierGeneralizationHelper . getGeneralizationsForRuleItemPatterns ( consideredPreFiller1 , consideredPreFiller2 ) ; consideredPreFiller1 . clear ( ) ; consideredPreFiller2 . clear ( ) ; for ( int i = preFiller1 . size ( ) - n ; i >= 0 && i <= preFiller1MaxIndex ; i ++ ) consideredPreFiller1 . add ( preFiller1 . get ( i ) ) ; for ( int i = preFiller2 . size ( ) - n ; i >= 0 && i <= preFiller2MaxIndex ; i ++ ) consideredPreFiller2 . add ( preFiller2 . get ( i ) ) ; if ( consideredPreFiller1 . size ( ) + consideredPreFiller2 . size ( ) > 0 ) genList3 = RapierGeneralizationHelper . getGeneralizationsForRuleItemPatterns ( consideredPreFiller1 , consideredPreFiller2 ) ; } Set < TextRulerRulePattern > genSet = new HashSet < TextRulerRulePattern > ( ) ; if ( genList1 != null ) genSet . addAll ( genList1 ) ; if ( genList2 != null ) genSet . addAll ( genList2 ) ; if ( genList3 != null ) genSet . addAll ( genList3 ) ; List < RapierRule > resultRules = new ArrayList < RapierRule > ( ) ; for ( TextRulerRulePattern l : genSet ) { RapierRule newRule = curRule . copy ( ) ; for ( int i = l . size ( ) - 1 ; i >= 0 ; i -- ) newRule . addPreFillerItem ( l . get ( i ) ) ; newRule . setParent1PreFiller_n ( n ) ; newRule . setParent2PreFiller_n ( n ) ; resultRules . add ( newRule ) ; } return resultRules ; } public List < RapierRule > specializePostFiller ( RapierRule curRule , int n ) { if ( n == 0 ) { TextRulerToolkit . log ( ""ERROR ! N SHOULD NOT BE 0!"" ) ; } RapierRule baseRule1 = curRule . getParent1 ( ) ; RapierRule baseRule2 = curRule . getParent2 ( ) ; int n1 = curRule . getParent1PostFiller_n ( ) ; int n2 = curRule . getParent2PostFiller_n ( ) ; TextRulerRulePattern postFiller1 = baseRule1 . getPostFillerPattern ( ) ; TextRulerRulePattern postFiller2 = baseRule2 . getPostFillerPattern ( ) ; int postFiller1MinIndex = n1 ; int postFiller2MinIndex = n2 ; TextRulerRulePattern consideredPostFiller1 = new TextRulerRulePattern ( ) ; TextRulerRulePattern consideredPostFiller2 = new TextRulerRulePattern ( ) ; for ( int i = postFiller1MinIndex ; i < postFiller1 . size ( ) && i < n ; i ++ ) consideredPostFiller1 . add ( postFiller1 . get ( i ) ) ; for ( int i = postFiller2MinIndex ; i < postFiller2 . size ( ) && i < n - 1 ; i ++ ) consideredPostFiller2 . add ( postFiller2 . get ( i ) ) ; List < TextRulerRulePattern > genList1 = null ; if ( consideredPostFiller1 . size ( ) + consideredPostFiller2 . size ( ) > 0 ) genList1 = RapierGeneralizationHelper . getGeneralizationsForRuleItemPatterns ( consideredPostFiller1 , consideredPostFiller2 ) ; consideredPostFiller1 . clear ( ) ; consideredPostFiller2 . clear ( ) ; for ( int i = postFiller1MinIndex ; i < postFiller1 . size ( ) && i < n - 1 ; i ++ ) consideredPostFiller1 . add ( postFiller1 . get ( i ) ) ; for ( int i = postFiller2MinIndex ; i < postFiller2 . size ( ) && i < n ; i ++ ) consideredPostFiller2 . add ( postFiller2 . get ( i ) ) ; List < TextRulerRulePattern > genList2 = null ; if ( consideredPostFiller1 . size ( ) + consideredPostFiller2 . size ( ) > 0 ) genList2 = RapierGeneralizationHelper . getGeneralizationsForRuleItemPatterns ( consideredPostFiller1 , consideredPostFiller2 ) ; consideredPostFiller1 . clear ( ) ; consideredPostFiller2 . clear ( ) ; for ( int i = postFiller1MinIndex ; i < postFiller1 . size ( ) && i < n ; i ++ ) consideredPostFiller1 . add ( postFiller1 . get ( i ) ) ; for ( int i = postFiller2MinIndex ; i < postFiller2 . size ( ) && i < n ; i ++ ) consideredPostFiller2 . add ( postFiller2 . get ( i ) ) ; List < TextRulerRulePattern > genList3 = null ; if ( consideredPostFiller1 . size ( ) + consideredPostFiller2 . size ( ) > 0 ) genList3 = RapierGeneralizationHelper . getGeneralizationsForRuleItemPatterns ( consideredPostFiller1 , consideredPostFiller2 ) ; Set < TextRulerRulePattern > genSet = new HashSet < TextRulerRulePattern > ( ) ; if ( genList1 != null ) genSet . addAll ( genList1 ) ; if ( genList2 != null ) genSet . addAll ( genList2 ) ; if ( genList3 != null ) genSet . addAll ( genList3 ) ; List < RapierRule > resultRules = new ArrayList < RapierRule > ( ) ; for ( TextRulerRulePattern l : genSet ) { RapierRule newRule = curRule . copy ( ) ; for ( TextRulerRuleItem t : l ) newRule . addPostFillerItem ( t ) ; newRule . setParent1PostFiller_n ( n ) ; newRule . setParent2PostFiller_n ( n ) ; resultRules . add ( newRule ) ; } return resultRules ; } @ Override public boolean collectNegativeCoveredInstancesWhenTesting ( ) { return false ; } public String getResultString ( ) { if ( slotRules != null ) return slotRules . getTMFileString ( getFileHeaderString ( true ) , 1000 ) ; else return ""No results available yet!"" ; } public void setParameters ( Map < String , Object > params ) { if ( TextRulerToolkit . DEBUG ) saveParametersToTempFolder ( params ) ; if ( params . containsKey ( COMPRESSION_FAIL_MAX_COUNT_KEY ) ) compressionFailMaxCount = ( Integer ) params . get ( COMPRESSION_FAIL_MAX_COUNT_KEY ) ; if ( params . containsKey ( RULELIST_SIZE_KEY ) ) ruleListSize = ( Integer ) params . get ( RULELIST_SIZE_KEY ) ; if ( params . containsKey ( PAIR_COUNT_KEY ) ) pairCount = ( Integer ) params . get ( PAIR_COUNT_KEY ) ; if ( params . containsKey ( LIM_NO_IMPROVEMENTS_KEY ) ) limNoImprovements = ( Integer ) params . get ( LIM_NO_IMPROVEMENTS_KEY ) ; if ( params . containsKey ( NOISE_THESHOLD_KEY ) ) noiseThreshold = ( Float ) params . get ( NOISE_THESHOLD_KEY ) ; if ( params . containsKey ( POSTAG_ROOTTYPE_KEY ) ) posTagRootTypeName = ( String ) params . get ( POSTAG_ROOTTYPE_KEY ) ; if ( params . containsKey ( MIN_COVERED_POSITIVES_KEY ) ) minCoveredPositives = ( Integer ) params . get ( MIN_COVERED_POSITIVES_KEY ) ; if ( params . containsKey ( USE_ALL_GENSETS_AT_SPECIALIZATION_KEY ) ) useAllGenSetsAtSpecialization = ( Boolean ) params . get ( USE_ALL_GENSETS_AT_SPECIALIZATION_KEY ) ; } protected void testRulesIfNotCached ( List < RapierRule > rules ) { List < TextRulerRule > rulesToTest = new ArrayList < TextRulerRule > ( ) ; for ( RapierRule r : rules ) { String key = r . getRuleString ( ) ; if ( cachedTestedRuleStatistics . containsKey ( key ) ) { r . setCoveringStatistics ( cachedTestedRuleStatistics . get ( key ) . copy ( ) ) ; TextRulerToolkit . log ( ""CACHE HIT; size="" + cachedTestedRuleStatistics . size ( ) ) ; } else rulesToTest . add ( r ) ; } if ( rulesToTest . size ( ) > 0 ) { testRulesOnDocumentSet ( rulesToTest , exampleDocuments ) ; if ( shouldAbort ( ) ) return ; while ( cachedTestedRuleStatistics . size ( ) + rulesToTest . size ( ) > 10000 ) { Iterator < String > it = cachedTestedRuleStatistics . keySet ( ) . iterator ( ) ; if ( ! it . hasNext ( ) ) break ; String removeKey = cachedTestedRuleStatistics . keySet ( ) . iterator ( ) . next ( ) ; cachedTestedRuleStatistics . remove ( removeKey ) ; } for ( TextRulerRule r : rulesToTest ) { String key = r . getRuleString ( ) ; cachedTestedRuleStatistics . put ( key , r . getCoveringStatistics ( ) . copy ( ) ) ; } } } }",Smelly
"public class DefaultResultMapBuilderTest extends TestCase { public void testBuild ( ) throws Exception { ServletContext context = mockServletContext ( ""/WEB-INF/location"" ) ; PackageConfig packageConfig = createPackageConfigBuilder ( ""/namespace"" ) ; DefaultResultMapBuilder builder = new DefaultResultMapBuilder ( context , new ConventionsServiceImpl ( ""/WEB-INF/location"" ) , ""dispatcher,velocity,freemarker"" ) ; Map < String , ResultConfig > results = builder . build ( NoAnnotationAction . class , null , ""action"" , packageConfig ) ; verify ( context , ""/WEB-INF/location"" , results , false ) ; context = mockServletContext ( ""/WEB-INF/location"" ) ; packageConfig = createPackageConfigBuilder ( ""namespace"" ) ; builder = new DefaultResultMapBuilder ( context , new ConventionsServiceImpl ( ""/WEB-INF/location"" ) , ""dispatcher,velocity,freemarker"" ) ; results = builder . build ( NoAnnotationAction . class , null , ""action"" , packageConfig ) ; verify ( context , ""/WEB-INF/location"" , results , false ) ; } public void testNull ( ) throws Exception { ServletContext context = EasyMock . createStrictMock ( ServletContext . class ) ; EasyMock . expect ( context . getResourcePaths ( ""/WEB-INF/location/namespace/"" ) ) . andReturn ( null ) ; EasyMock . replay ( context ) ; PackageConfig packageConfig = createPackageConfigBuilder ( ""/namespace"" ) ; DefaultResultMapBuilder builder = new DefaultResultMapBuilder ( context , new ConventionsServiceImpl ( ""/WEB-INF/location"" ) , ""dispatcher,velocity,freemarker"" ) ; Map < String , ResultConfig > results = builder . build ( NoAnnotationAction . class , null , ""action"" , packageConfig ) ; assertEquals ( 0 , results . size ( ) ) ; EasyMock . verify ( context ) ; } public void testResultPath ( ) throws Exception { ServletContext context = mockServletContext ( ""/class-level"" ) ; PackageConfig packageConfig = createPackageConfigBuilder ( ""/namespace"" ) ; DefaultResultMapBuilder builder = new DefaultResultMapBuilder ( context , new ConventionsServiceImpl ( ""/not-used"" ) , ""dispatcher,velocity,freemarker"" ) ; Map < String , ResultConfig > results = builder . build ( ClassLevelResultPathAction . class , null , ""action"" , packageConfig ) ; verify ( context , ""/class-level"" , results , false ) ; } public void testFromServletContext ( ) throws Exception { ServletContext context = EasyMock . createStrictMock ( ServletContext . class ) ; Set < String > resources = new HashSet < String > ( ) ; resources . add ( ""/WEB-INF/location/namespace/no-annotation.ftl"" ) ; resources . add ( ""/WEB-INF/location/namespace/no-annotation-success.jsp"" ) ; resources . add ( ""/WEB-INF/location/namespace/no-annotation-failure.jsp"" ) ; EasyMock . expect ( context . getResourcePaths ( ""/WEB-INF/location/namespace/"" ) ) . andReturn ( resources ) ; EasyMock . replay ( context ) ; PackageConfig packageConfig = createPackageConfigBuilder ( ""/namespace"" ) ; DefaultResultMapBuilder builder = new DefaultResultMapBuilder ( context , new ConventionsServiceImpl ( ""/WEB-INF/location"" ) , ""dispatcher,velocity,freemarker"" ) ; Map < String , ResultConfig > results = builder . build ( NoAnnotationAction . class , null , ""no-annotation"" , packageConfig ) ; assertEquals ( 4 , results . size ( ) ) ; assertEquals ( ""success"" , results . get ( ""success"" ) . getName ( ) ) ; assertEquals ( 3 , results . get ( ""success"" ) . getParams ( ) . size ( ) ) ; assertEquals ( ""org.apache.struts2.dispatcher.ServletDispatcherResult"" , results . get ( ""success"" ) . getClassName ( ) ) ; assertEquals ( ""/WEB-INF/location/namespace/no-annotation-success.jsp"" , results . get ( ""success"" ) . getParams ( ) . get ( ""location"" ) ) ; assertEquals ( 1 , results . get ( ""input"" ) . getParams ( ) . size ( ) ) ; assertEquals ( ""org.apache.struts2.views.freemarker.FreemarkerResult"" , results . get ( ""input"" ) . getClassName ( ) ) ; assertEquals ( ""/WEB-INF/location/namespace/no-annotation.ftl"" , results . get ( ""input"" ) . getParams ( ) . get ( ""location"" ) ) ; assertEquals ( 1 , results . get ( ""error"" ) . getParams ( ) . size ( ) ) ; assertEquals ( ""org.apache.struts2.views.freemarker.FreemarkerResult"" , results . get ( ""error"" ) . getClassName ( ) ) ; assertEquals ( ""/WEB-INF/location/namespace/no-annotation.ftl"" , results . get ( ""error"" ) . getParams ( ) . get ( ""location"" ) ) ; assertEquals ( 3 , results . get ( ""failure"" ) . getParams ( ) . size ( ) ) ; assertEquals ( ""org.apache.struts2.dispatcher.ServletDispatcherResult"" , results . get ( ""success"" ) . getClassName ( ) ) ; assertEquals ( ""/WEB-INF/location/namespace/no-annotation-failure.jsp"" , results . get ( ""failure"" ) . getParams ( ) . get ( ""location"" ) ) ; EasyMock . verify ( context ) ; } public void testClassLevelSingleResultAnnotation ( ) throws Exception { ServletContext context = EasyMock . createStrictMock ( ServletContext . class ) ; Set < String > resources = new HashSet < String > ( ) ; EasyMock . expect ( context . getResourcePaths ( ""/WEB-INF/location/namespace/"" ) ) . andReturn ( resources ) ; EasyMock . replay ( context ) ; PackageConfig packageConfig = createPackageConfigBuilder ( ""/namespace"" ) ; DefaultResultMapBuilder builder = new DefaultResultMapBuilder ( context , new ConventionsServiceImpl ( ""/WEB-INF/location"" ) , ""dispatcher,velocity,freemarker"" ) ; Map < String , ResultConfig > results = builder . build ( ClassLevelResultAction . class , null , ""class-level-result"" , packageConfig ) ; assertEquals ( 1 , results . size ( ) ) ; assertEquals ( ""error"" , results . get ( ""error"" ) . getName ( ) ) ; assertEquals ( 3 , results . get ( ""error"" ) . getParams ( ) . size ( ) ) ; assertEquals ( ""org.apache.struts2.dispatcher.ServletDispatcherResult"" , results . get ( ""error"" ) . getClassName ( ) ) ; assertEquals ( ""/WEB-INF/location/namespace/error.jsp"" , results . get ( ""error"" ) . getParams ( ) . get ( ""location"" ) ) ; assertEquals ( ""value"" , results . get ( ""error"" ) . getParams ( ) . get ( ""key"" ) ) ; assertEquals ( ""value1"" , results . get ( ""error"" ) . getParams ( ) . get ( ""key1"" ) ) ; EasyMock . verify ( context ) ; } public void testClassLevelMultipleResultAnnotation ( ) throws Exception { ServletContext context = EasyMock . createStrictMock ( ServletContext . class ) ; Set < String > resources = new HashSet < String > ( ) ; EasyMock . expect ( context . getResourcePaths ( ""/WEB-INF/location/namespace/"" ) ) . andReturn ( resources ) ; EasyMock . replay ( context ) ; PackageConfig packageConfig = createPackageConfigBuilder ( ""/namespace"" ) ; DefaultResultMapBuilder builder = new DefaultResultMapBuilder ( context , new ConventionsServiceImpl ( ""/WEB-INF/location"" ) , ""dispatcher,velocity,freemarker"" ) ; Map < String , ResultConfig > results = builder . build ( ClassLevelResultsAction . class , null , ""class-level-results"" , packageConfig ) ; assertEquals ( 4 , results . size ( ) ) ; assertEquals ( ""error"" , results . get ( ""error"" ) . getName ( ) ) ; assertEquals ( ""input"" , results . get ( ""input"" ) . getName ( ) ) ; assertEquals ( ""success"" , results . get ( ""success"" ) . getName ( ) ) ; assertEquals ( ""failure"" , results . get ( ""failure"" ) . getName ( ) ) ; assertEquals ( 3 , results . get ( ""error"" ) . getParams ( ) . size ( ) ) ; assertEquals ( ""org.apache.struts2.dispatcher.ServletDispatcherResult"" , results . get ( ""error"" ) . getClassName ( ) ) ; assertEquals ( ""/WEB-INF/location/namespace/error.jsp"" , results . get ( ""error"" ) . getParams ( ) . get ( ""location"" ) ) ; assertEquals ( ""ann-value"" , results . get ( ""error"" ) . getParams ( ) . get ( ""key"" ) ) ; assertEquals ( ""ann-value1"" , results . get ( ""error"" ) . getParams ( ) . get ( ""key1"" ) ) ; assertEquals ( 1 , results . get ( ""input"" ) . getParams ( ) . size ( ) ) ; assertEquals ( ""foo.action"" , results . get ( ""input"" ) . getParams ( ) . get ( ""actionName"" ) ) ; assertEquals ( ""org.apache.struts2.dispatcher.ServletActionRedirectResult"" , results . get ( ""input"" ) . getClassName ( ) ) ; assertEquals ( 3 , results . get ( ""failure"" ) . getParams ( ) . size ( ) ) ; assertEquals ( ""/WEB-INF/location/namespace/action-failure.jsp"" , results . get ( ""failure"" ) . getParams ( ) . get ( ""location"" ) ) ; assertEquals ( ""org.apache.struts2.dispatcher.ServletDispatcherResult"" , results . get ( ""failure"" ) . getClassName ( ) ) ; assertEquals ( ""value"" , results . get ( ""failure"" ) . getParams ( ) . get ( ""key"" ) ) ; assertEquals ( ""value1"" , results . get ( ""failure"" ) . getParams ( ) . get ( ""key1"" ) ) ; assertEquals ( 3 , results . get ( ""success"" ) . getParams ( ) . size ( ) ) ; assertEquals ( ""/WEB-INF/location/namespace/action-success.jsp"" , results . get ( ""success"" ) . getParams ( ) . get ( ""location"" ) ) ; assertEquals ( ""org.apache.struts2.dispatcher.ServletDispatcherResult"" , results . get ( ""success"" ) . getClassName ( ) ) ; assertEquals ( ""value"" , results . get ( ""success"" ) . getParams ( ) . get ( ""key"" ) ) ; assertEquals ( ""value1"" , results . get ( ""success"" ) . getParams ( ) . get ( ""key1"" ) ) ; EasyMock . verify ( context ) ; } public void testActionLevelSingleResultAnnotation ( ) throws Exception { ServletContext context = EasyMock . createStrictMock ( ServletContext . class ) ; Set < String > resources = new HashSet < String > ( ) ; EasyMock . expect ( context . getResourcePaths ( ""/WEB-INF/location/namespace/"" ) ) . andReturn ( resources ) ; EasyMock . replay ( context ) ; PackageConfig packageConfig = createPackageConfigBuilder ( ""/namespace"" ) ; DefaultResultMapBuilder builder = new DefaultResultMapBuilder ( context , new ConventionsServiceImpl ( ""/WEB-INF/location"" ) , ""dispatcher,velocity,freemarker"" ) ; Map < String , ResultConfig > results = builder . build ( ActionLevelResultAction . class , getAnnotation ( ActionLevelResultAction . class , ""execute"" , Action . class ) , ""action-level-result"" , packageConfig ) ; assertEquals ( 1 , results . size ( ) ) ; assertEquals ( ""success"" , results . get ( ""success"" ) . getName ( ) ) ; assertEquals ( 3 , results . get ( ""success"" ) . getParams ( ) . size ( ) ) ; assertEquals ( ""org.apache.struts2.dispatcher.ServletDispatcherResult"" , results . get ( ""success"" ) . getClassName ( ) ) ; assertEquals ( ""/WEB-INF/location/namespace/action-success.jsp"" , results . get ( ""success"" ) . getParams ( ) . get ( ""location"" ) ) ; assertEquals ( ""value"" , results . get ( ""success"" ) . getParams ( ) . get ( ""key"" ) ) ; assertEquals ( ""value1"" , results . get ( ""success"" ) . getParams ( ) . get ( ""key1"" ) ) ; EasyMock . verify ( context ) ; } public void testActionLevelMultipleResultAnnotation ( ) throws Exception { ServletContext context = EasyMock . createStrictMock ( ServletContext . class ) ; Set < String > resources = new HashSet < String > ( ) ; EasyMock . expect ( context . getResourcePaths ( ""/WEB-INF/location/namespace/"" ) ) . andReturn ( resources ) ; EasyMock . replay ( context ) ; PackageConfig packageConfig = createPackageConfigBuilder ( ""/namespace"" ) ; DefaultResultMapBuilder builder = new DefaultResultMapBuilder ( context , new ConventionsServiceImpl ( ""/WEB-INF/location"" ) , ""dispatcher,velocity,freemarker"" ) ; Map < String , ResultConfig > results = builder . build ( ActionLevelResultsAction . class , getAnnotation ( ActionLevelResultsAction . class , ""execute"" , Action . class ) , ""action-level-results"" , packageConfig ) ; assertEquals ( 4 , results . size ( ) ) ; assertEquals ( ""error"" , results . get ( ""error"" ) . getName ( ) ) ; assertEquals ( ""input"" , results . get ( ""input"" ) . getName ( ) ) ; assertEquals ( ""success"" , results . get ( ""success"" ) . getName ( ) ) ; assertEquals ( ""failure"" , results . get ( ""failure"" ) . getName ( ) ) ; assertEquals ( 3 , results . get ( ""error"" ) . getParams ( ) . size ( ) ) ; assertEquals ( ""org.apache.struts2.dispatcher.ServletDispatcherResult"" , results . get ( ""error"" ) . getClassName ( ) ) ; assertEquals ( ""/WEB-INF/location/namespace/error.jsp"" , results . get ( ""error"" ) . getParams ( ) . get ( ""location"" ) ) ; assertEquals ( ""value"" , results . get ( ""success"" ) . getParams ( ) . get ( ""key"" ) ) ; assertEquals ( ""value1"" , results . get ( ""success"" ) . getParams ( ) . get ( ""key1"" ) ) ; assertEquals ( 1 , results . get ( ""input"" ) . getParams ( ) . size ( ) ) ; assertEquals ( ""foo.action"" , results . get ( ""input"" ) . getParams ( ) . get ( ""actionName"" ) ) ; assertEquals ( ""org.apache.struts2.dispatcher.ServletActionRedirectResult"" , results . get ( ""input"" ) . getClassName ( ) ) ; assertEquals ( 3 , results . get ( ""failure"" ) . getParams ( ) . size ( ) ) ; assertEquals ( ""/WEB-INF/location/namespace/action-failure.jsp"" , results . get ( ""failure"" ) . getParams ( ) . get ( ""location"" ) ) ; assertEquals ( ""org.apache.struts2.dispatcher.ServletDispatcherResult"" , results . get ( ""failure"" ) . getClassName ( ) ) ; assertEquals ( 3 , results . get ( ""success"" ) . getParams ( ) . size ( ) ) ; assertEquals ( ""/WEB-INF/location/namespace/action-success.jsp"" , results . get ( ""success"" ) . getParams ( ) . get ( ""location"" ) ) ; assertEquals ( ""org.apache.struts2.dispatcher.ServletDispatcherResult"" , results . get ( ""success"" ) . getClassName ( ) ) ; EasyMock . verify ( context ) ; } public void testClassPath ( ) throws Exception { ServletContext context = EasyMock . createNiceMock ( ServletContext . class ) ; ResultTypeConfig resultType = new ResultTypeConfig . Builder ( ""freemarker"" , ""org.apache.struts2.dispatcher.ServletDispatcherResult"" ) . defaultResultParam ( ""location"" ) . build ( ) ; PackageConfig packageConfig = new PackageConfig . Builder ( ""package"" ) . defaultResultType ( ""dispatcher"" ) . addResultTypeConfig ( resultType ) . build ( ) ; DefaultResultMapBuilder builder = new DefaultResultMapBuilder ( context , new ConventionsServiceImpl ( ""/WEB-INF/component"" ) , ""dispatcher,velocity,freemarker"" ) ; Map < String , ResultConfig > results = builder . build ( NoAnnotationAction . class , null , ""no-annotation"" , packageConfig ) ; assertEquals ( 4 , results . size ( ) ) ; assertEquals ( ""input"" , results . get ( ""input"" ) . getName ( ) ) ; assertEquals ( ""error"" , results . get ( ""error"" ) . getName ( ) ) ; assertEquals ( ""success"" , results . get ( ""success"" ) . getName ( ) ) ; assertEquals ( ""foo"" , results . get ( ""foo"" ) . getName ( ) ) ; assertEquals ( 1 , results . get ( ""success"" ) . getParams ( ) . size ( ) ) ; assertEquals ( ""/WEB-INF/component/no-annotation.ftl"" , results . get ( ""success"" ) . getParams ( ) . get ( ""location"" ) ) ; assertEquals ( 1 , results . get ( ""input"" ) . getParams ( ) . size ( ) ) ; assertEquals ( ""/WEB-INF/component/no-annotation.ftl"" , results . get ( ""input"" ) . getParams ( ) . get ( ""location"" ) ) ; assertEquals ( 1 , results . get ( ""error"" ) . getParams ( ) . size ( ) ) ; assertEquals ( ""/WEB-INF/component/no-annotation.ftl"" , results . get ( ""error"" ) . getParams ( ) . get ( ""location"" ) ) ; assertEquals ( 1 , results . get ( ""foo"" ) . getParams ( ) . size ( ) ) ; assertEquals ( ""/WEB-INF/component/no-annotation-foo.ftl"" , results . get ( ""foo"" ) . getParams ( ) . get ( ""location"" ) ) ; } private PackageConfig createPackageConfigBuilder ( String namespace ) { ResultTypeConfig resultType = new ResultTypeConfig . Builder ( ""dispatcher"" , ""org.apache.struts2.dispatcher.ServletDispatcherResult"" ) . addParam ( ""key"" , ""value"" ) . addParam ( ""key1"" , ""value1"" ) . defaultResultParam ( ""location"" ) . build ( ) ; ResultTypeConfig redirect = new ResultTypeConfig . Builder ( ""redirectAction"" , ""org.apache.struts2.dispatcher.ServletActionRedirectResult"" ) . defaultResultParam ( ""actionName"" ) . build ( ) ; ResultTypeConfig ftlResultType = new ResultTypeConfig . Builder ( ""freemarker"" , ""org.apache.struts2.views.freemarker.FreemarkerResult"" ) . defaultResultParam ( ""location"" ) . build ( ) ; return new PackageConfig . Builder ( ""package"" ) . namespace ( namespace ) . defaultResultType ( ""dispatcher"" ) . addResultTypeConfig ( resultType ) . addResultTypeConfig ( redirect ) . addResultTypeConfig ( ftlResultType ) . build ( ) ; } private ServletContext mockServletContext ( String resultPath ) { ServletContext context = EasyMock . createStrictMock ( ServletContext . class ) ; Set < String > resources = new HashSet < String > ( ) ; resources . add ( resultPath + ""/namespace/action.jsp"" ) ; resources . add ( resultPath + ""/namespace/action-success.jsp"" ) ; resources . add ( resultPath + ""/namespace/action-failure.jsp"" ) ; EasyMock . expect ( context . getResourcePaths ( resultPath + ""/namespace/"" ) ) . andReturn ( resources ) ; EasyMock . replay ( context ) ; return context ; } private void verify ( ServletContext context , String resultPath , Map < String , ResultConfig > results , boolean redirect ) { assertEquals ( 4 , results . size ( ) ) ; assertEquals ( ""success"" , results . get ( ""success"" ) . getName ( ) ) ; assertEquals ( ""input"" , results . get ( ""input"" ) . getName ( ) ) ; assertEquals ( ""error"" , results . get ( ""error"" ) . getName ( ) ) ; assertEquals ( ""failure"" , results . get ( ""failure"" ) . getName ( ) ) ; assertEquals ( 3 , results . get ( ""success"" ) . getParams ( ) . size ( ) ) ; assertEquals ( resultPath + ""/namespace/action-success.jsp"" , results . get ( ""success"" ) . getParams ( ) . get ( ""location"" ) ) ; assertEquals ( ""value"" , results . get ( ""success"" ) . getParams ( ) . get ( ""key"" ) ) ; assertEquals ( ""value1"" , results . get ( ""success"" ) . getParams ( ) . get ( ""key1"" ) ) ; assertEquals ( 3 , results . get ( ""failure"" ) . getParams ( ) . size ( ) ) ; assertEquals ( resultPath + ""/namespace/action-failure.jsp"" , results . get ( ""failure"" ) . getParams ( ) . get ( ""location"" ) ) ; assertEquals ( ""value"" , results . get ( ""failure"" ) . getParams ( ) . get ( ""key"" ) ) ; assertEquals ( ""value1"" , results . get ( ""failure"" ) . getParams ( ) . get ( ""key1"" ) ) ; if ( redirect ) { assertEquals ( 1 , results . get ( ""input"" ) . getParams ( ) . size ( ) ) ; assertEquals ( ""foo.action"" , results . get ( ""input"" ) . getParams ( ) . get ( ""actionName"" ) ) ; } else { assertEquals ( 3 , results . get ( ""input"" ) . getParams ( ) . size ( ) ) ; assertEquals ( resultPath + ""/namespace/action.jsp"" , results . get ( ""input"" ) . getParams ( ) . get ( ""location"" ) ) ; assertEquals ( ""value"" , results . get ( ""input"" ) . getParams ( ) . get ( ""key"" ) ) ; assertEquals ( ""value1"" , results . get ( ""input"" ) . getParams ( ) . get ( ""key1"" ) ) ; } assertEquals ( 3 , results . get ( ""error"" ) . getParams ( ) . size ( ) ) ; assertEquals ( resultPath + ""/namespace/action.jsp"" , results . get ( ""error"" ) . getParams ( ) . get ( ""location"" ) ) ; assertEquals ( ""value"" , results . get ( ""error"" ) . getParams ( ) . get ( ""key"" ) ) ; assertEquals ( ""value1"" , results . get ( ""error"" ) . getParams ( ) . get ( ""key1"" ) ) ; EasyMock . verify ( context ) ; } }",Smelly
"@ RunWith ( Suite . class ) @ Suite . SuiteClasses ( { TestNodeLib . class , TestStringAbbrev . class , TestColumnMap . class } ) public class TS_LibTDB { }",No
"public class MultiKahaDBPersistenceAdapter extends DestinationMap implements PersistenceAdapter , BrokerServiceAware { static final Logger LOG = LoggerFactory . getLogger ( MultiKahaDBPersistenceAdapter . class ) ; final static ActiveMQDestination matchAll = new AnyDestination ( new ActiveMQDestination [ ] { new ActiveMQQueue ( "">"" ) , new ActiveMQTopic ( "">"" ) } ) ; final int LOCAL_FORMAT_ID_MAGIC = Integer . valueOf ( System . getProperty ( ""org.apache.activemq.store.kahadb.MultiKahaDBTransactionStore.localXaFormatId"" , ""61616"" ) ) ; BrokerService brokerService ; List < KahaDBPersistenceAdapter > adapters = new LinkedList < KahaDBPersistenceAdapter > ( ) ; private File directory = new File ( IOHelper . getDefaultDataDirectory ( ) + File . separator + ""mKahaDB"" ) ; MultiKahaDBTransactionStore transactionStore = new MultiKahaDBTransactionStore ( this ) ; TransactionIdTransformer transactionIdTransformer = new TransactionIdTransformer ( ) { @ Override public KahaTransactionInfo transform ( TransactionId txid ) { if ( txid == null ) { return null ; } KahaTransactionInfo rc = new KahaTransactionInfo ( ) ; KahaXATransactionId kahaTxId = new KahaXATransactionId ( ) ; if ( txid . isLocalTransaction ( ) ) { LocalTransactionId t = ( LocalTransactionId ) txid ; kahaTxId . setBranchQualifier ( new Buffer ( Long . toString ( t . getValue ( ) ) . getBytes ( Charset . forName ( ""utf-8"" ) ) ) ) ; kahaTxId . setGlobalTransactionId ( new Buffer ( t . getConnectionId ( ) . getValue ( ) . getBytes ( Charset . forName ( ""utf-8"" ) ) ) ) ; kahaTxId . setFormatId ( LOCAL_FORMAT_ID_MAGIC ) ; } else { XATransactionId t = ( XATransactionId ) txid ; kahaTxId . setBranchQualifier ( new Buffer ( t . getBranchQualifier ( ) ) ) ; kahaTxId . setGlobalTransactionId ( new Buffer ( t . getGlobalTransactionId ( ) ) ) ; kahaTxId . setFormatId ( t . getFormatId ( ) ) ; } rc . setXaTransactionId ( kahaTxId ) ; return rc ; } } ; @ SuppressWarnings ( { ""rawtypes"" , ""unchecked"" } ) public void setFilteredPersistenceAdapters ( List entries ) { for ( Object entry : entries ) { FilteredKahaDBPersistenceAdapter filteredAdapter = ( FilteredKahaDBPersistenceAdapter ) entry ; KahaDBPersistenceAdapter adapter = filteredAdapter . getPersistenceAdapter ( ) ; if ( filteredAdapter . getDestination ( ) == null ) { filteredAdapter . setDestination ( matchAll ) ; } if ( filteredAdapter . isPerDestination ( ) ) { configureDirectory ( adapter , null ) ; continue ; } else { configureDirectory ( adapter , nameFromDestinationFilter ( filteredAdapter . getDestination ( ) ) ) ; } configureAdapter ( adapter ) ; adapters . add ( adapter ) ; } super . setEntries ( entries ) ; } private String nameFromDestinationFilter ( ActiveMQDestination destination ) { if ( destination . getQualifiedName ( ) . length ( ) > IOHelper . getMaxFileNameLength ( ) ) { LOG . warn ( ""Destination name is longer than 'MaximumFileNameLength' system property, "" + ""potential problem with recovery can result from name truncation."" ) ; } return IOHelper . toFileSystemSafeName ( destination . getQualifiedName ( ) ) ; } public boolean isLocalXid ( TransactionId xid ) { return xid instanceof XATransactionId && ( ( XATransactionId ) xid ) . getFormatId ( ) == LOCAL_FORMAT_ID_MAGIC ; } @ Override public void beginTransaction ( ConnectionContext context ) throws IOException { throw new IllegalStateException ( ) ; } @ Override public void checkpoint ( final boolean sync ) throws IOException { for ( PersistenceAdapter persistenceAdapter : adapters ) { persistenceAdapter . checkpoint ( sync ) ; } } @ Override public void commitTransaction ( ConnectionContext context ) throws IOException { throw new IllegalStateException ( ) ; } @ Override public MessageStore createQueueMessageStore ( ActiveMQQueue destination ) throws IOException { PersistenceAdapter persistenceAdapter = getMatchingPersistenceAdapter ( destination ) ; return transactionStore . proxy ( persistenceAdapter . createTransactionStore ( ) , persistenceAdapter . createQueueMessageStore ( destination ) ) ; } private PersistenceAdapter getMatchingPersistenceAdapter ( ActiveMQDestination destination ) { Object result = this . chooseValue ( destination ) ; if ( result == null ) { throw new RuntimeException ( ""No matching persistence adapter configured for destination: "" + destination + "", options:"" + adapters ) ; } FilteredKahaDBPersistenceAdapter filteredAdapter = ( FilteredKahaDBPersistenceAdapter ) result ; if ( filteredAdapter . getDestination ( ) == matchAll && filteredAdapter . isPerDestination ( ) ) { result = addAdapter ( filteredAdapter , destination ) ; startAdapter ( ( ( FilteredKahaDBPersistenceAdapter ) result ) . getPersistenceAdapter ( ) , destination . getQualifiedName ( ) ) ; if ( LOG . isTraceEnabled ( ) ) { LOG . info ( ""created per destination adapter for: "" + destination + "", "" + result ) ; } } return ( ( FilteredKahaDBPersistenceAdapter ) result ) . getPersistenceAdapter ( ) ; } private void startAdapter ( KahaDBPersistenceAdapter kahaDBPersistenceAdapter , String destination ) { try { kahaDBPersistenceAdapter . start ( ) ; } catch ( Exception e ) { RuntimeException detail = new RuntimeException ( ""Failed to start per destination persistence adapter for destination: "" + destination + "", options:"" + adapters , e ) ; LOG . error ( detail . toString ( ) , e ) ; throw detail ; } } private void stopAdapter ( KahaDBPersistenceAdapter kahaDBPersistenceAdapter , String destination ) { try { kahaDBPersistenceAdapter . stop ( ) ; } catch ( Exception e ) { RuntimeException detail = new RuntimeException ( ""Failed to stop per destination persistence adapter for destination: "" + destination + "", options:"" + adapters , e ) ; LOG . error ( detail . toString ( ) , e ) ; throw detail ; } } @ Override public TopicMessageStore createTopicMessageStore ( ActiveMQTopic destination ) throws IOException { PersistenceAdapter persistenceAdapter = getMatchingPersistenceAdapter ( destination ) ; return transactionStore . proxy ( persistenceAdapter . createTransactionStore ( ) , persistenceAdapter . createTopicMessageStore ( destination ) ) ; } @ Override public TransactionStore createTransactionStore ( ) throws IOException { return transactionStore ; } @ Override public void deleteAllMessages ( ) throws IOException { for ( PersistenceAdapter persistenceAdapter : adapters ) { persistenceAdapter . deleteAllMessages ( ) ; } transactionStore . deleteAllMessages ( ) ; IOHelper . deleteChildren ( getDirectory ( ) ) ; } @ Override public Set < ActiveMQDestination > getDestinations ( ) { Set < ActiveMQDestination > results = new HashSet < ActiveMQDestination > ( ) ; for ( PersistenceAdapter persistenceAdapter : adapters ) { results . addAll ( persistenceAdapter . getDestinations ( ) ) ; } return results ; } @ Override public long getLastMessageBrokerSequenceId ( ) throws IOException { long maxId = - 1 ; for ( PersistenceAdapter persistenceAdapter : adapters ) { maxId = Math . max ( maxId , persistenceAdapter . getLastMessageBrokerSequenceId ( ) ) ; } return maxId ; } @ Override public long getLastProducerSequenceId ( ProducerId id ) throws IOException { long maxId = - 1 ; for ( PersistenceAdapter persistenceAdapter : adapters ) { maxId = Math . max ( maxId , persistenceAdapter . getLastProducerSequenceId ( id ) ) ; } return maxId ; } @ Override public void removeQueueMessageStore ( ActiveMQQueue destination ) { PersistenceAdapter adapter = getMatchingPersistenceAdapter ( destination ) ; if ( adapter instanceof KahaDBPersistenceAdapter ) { adapter . removeQueueMessageStore ( destination ) ; removeMessageStore ( ( KahaDBPersistenceAdapter ) adapter , destination ) ; removeAll ( destination ) ; } } @ Override public void removeTopicMessageStore ( ActiveMQTopic destination ) { PersistenceAdapter adapter = getMatchingPersistenceAdapter ( destination ) ; if ( adapter instanceof KahaDBPersistenceAdapter ) { adapter . removeTopicMessageStore ( destination ) ; removeMessageStore ( ( KahaDBPersistenceAdapter ) adapter , destination ) ; removeAll ( destination ) ; } } private void removeMessageStore ( KahaDBPersistenceAdapter adapter , ActiveMQDestination destination ) { if ( adapter . getDestinations ( ) . isEmpty ( ) ) { stopAdapter ( adapter , destination . toString ( ) ) ; File adapterDir = adapter . getDirectory ( ) ; if ( adapterDir != null ) { if ( IOHelper . deleteFile ( adapterDir ) ) { if ( LOG . isTraceEnabled ( ) ) { LOG . info ( ""deleted per destination adapter directory for: "" + destination ) ; } } else { if ( LOG . isTraceEnabled ( ) ) { LOG . info ( ""failed to deleted per destination adapter directory for: "" + destination ) ; } } } } } @ Override public void rollbackTransaction ( ConnectionContext context ) throws IOException { throw new IllegalStateException ( ) ; } @ Override public void setBrokerName ( String brokerName ) { for ( PersistenceAdapter persistenceAdapter : adapters ) { persistenceAdapter . setBrokerName ( brokerName ) ; } } @ Override public void setUsageManager ( SystemUsage usageManager ) { for ( PersistenceAdapter persistenceAdapter : adapters ) { persistenceAdapter . setUsageManager ( usageManager ) ; } } @ Override public long size ( ) { long size = 0 ; for ( PersistenceAdapter persistenceAdapter : adapters ) { size += persistenceAdapter . size ( ) ; } return size ; } @ Override public void start ( ) throws Exception { Object result = this . chooseValue ( matchAll ) ; if ( result != null ) { FilteredKahaDBPersistenceAdapter filteredAdapter = ( FilteredKahaDBPersistenceAdapter ) result ; if ( filteredAdapter . getDestination ( ) == matchAll && filteredAdapter . isPerDestination ( ) ) { findAndRegisterExistingAdapters ( filteredAdapter ) ; } } for ( PersistenceAdapter persistenceAdapter : adapters ) { persistenceAdapter . start ( ) ; } } private void findAndRegisterExistingAdapters ( FilteredKahaDBPersistenceAdapter template ) { FileFilter destinationNames = new FileFilter ( ) { @ Override public boolean accept ( File file ) { return file . getName ( ) . startsWith ( ""queue#"" ) || file . getName ( ) . startsWith ( ""topic#"" ) ; } } ; File [ ] candidates = template . getPersistenceAdapter ( ) . getDirectory ( ) . listFiles ( destinationNames ) ; if ( candidates != null ) { for ( File candidate : candidates ) { registerExistingAdapter ( template , candidate ) ; } } } private void registerExistingAdapter ( FilteredKahaDBPersistenceAdapter filteredAdapter , File candidate ) { KahaDBPersistenceAdapter adapter = adapterFromTemplate ( filteredAdapter . getPersistenceAdapter ( ) , candidate . getName ( ) ) ; startAdapter ( adapter , candidate . getName ( ) ) ; Set < ActiveMQDestination > destinations = adapter . getDestinations ( ) ; if ( destinations . size ( ) != 0 ) { registerAdapter ( adapter , destinations . toArray ( new ActiveMQDestination [ ] { } ) [ 0 ] ) ; } else { stopAdapter ( adapter , candidate . getName ( ) ) ; } } private FilteredKahaDBPersistenceAdapter addAdapter ( FilteredKahaDBPersistenceAdapter filteredAdapter , ActiveMQDestination destination ) { KahaDBPersistenceAdapter adapter = adapterFromTemplate ( filteredAdapter . getPersistenceAdapter ( ) , nameFromDestinationFilter ( destination ) ) ; return registerAdapter ( adapter , destination ) ; } private KahaDBPersistenceAdapter adapterFromTemplate ( KahaDBPersistenceAdapter template , String destinationName ) { KahaDBPersistenceAdapter adapter = kahaDBFromTemplate ( template ) ; configureAdapter ( adapter ) ; configureDirectory ( adapter , destinationName ) ; return adapter ; } private void configureDirectory ( KahaDBPersistenceAdapter adapter , String fileName ) { File directory = null ; if ( MessageDatabase . DEFAULT_DIRECTORY . equals ( adapter . getDirectory ( ) ) ) { directory = getDirectory ( ) ; } else { directory = adapter . getDirectory ( ) ; } if ( fileName != null ) { directory = new File ( directory , fileName ) ; } adapter . setDirectory ( directory ) ; } private FilteredKahaDBPersistenceAdapter registerAdapter ( KahaDBPersistenceAdapter adapter , ActiveMQDestination destination ) { adapters . add ( adapter ) ; FilteredKahaDBPersistenceAdapter result = new FilteredKahaDBPersistenceAdapter ( destination , adapter ) ; put ( destination , result ) ; return result ; } private void configureAdapter ( KahaDBPersistenceAdapter adapter ) { adapter . getStore ( ) . setTransactionIdTransformer ( transactionIdTransformer ) ; adapter . setBrokerService ( getBrokerService ( ) ) ; } private KahaDBPersistenceAdapter kahaDBFromTemplate ( KahaDBPersistenceAdapter template ) { Map < String , Object > configuration = new HashMap < String , Object > ( ) ; IntrospectionSupport . getProperties ( template , configuration , null ) ; KahaDBPersistenceAdapter adapter = new KahaDBPersistenceAdapter ( ) ; IntrospectionSupport . setProperties ( adapter , configuration ) ; return adapter ; } @ Override public void stop ( ) throws Exception { for ( PersistenceAdapter persistenceAdapter : adapters ) { persistenceAdapter . stop ( ) ; } } @ Override public File getDirectory ( ) { return this . directory ; } @ Override public void setDirectory ( File directory ) { this . directory = directory ; } @ Override public void setBrokerService ( BrokerService brokerService ) { for ( KahaDBPersistenceAdapter persistenceAdapter : adapters ) { persistenceAdapter . setBrokerService ( brokerService ) ; } this . brokerService = brokerService ; } public BrokerService getBrokerService ( ) { return brokerService ; } public void setTransactionStore ( MultiKahaDBTransactionStore transactionStore ) { this . transactionStore = transactionStore ; } public void setJournalMaxFileLength ( int maxFileLength ) { transactionStore . setJournalMaxFileLength ( maxFileLength ) ; } public int getJournalMaxFileLength ( ) { return transactionStore . getJournalMaxFileLength ( ) ; } public void setJournalWriteBatchSize ( int journalWriteBatchSize ) { transactionStore . setJournalMaxWriteBatchSize ( journalWriteBatchSize ) ; } public int getJournalWriteBatchSize ( ) { return transactionStore . getJournalMaxWriteBatchSize ( ) ; } @ Override public String toString ( ) { String path = getDirectory ( ) != null ? getDirectory ( ) . getAbsolutePath ( ) : ""DIRECTORY_NOT_SET"" ; return ""MultiKahaDBPersistenceAdapter["" + path + ""]"" + adapters ; } }",Smelly
"public class WebBeansContext { private final Map < Class < ? > , Object > managerMap = new HashMap < Class < ? > , Object > ( ) ; private final Map < Class < ? > , Object > serviceMap = new HashMap < Class < ? > , Object > ( ) ; private final WebBeansUtil webBeansUtil = new WebBeansUtil ( this ) ; private final ContextFactory contextFactory = new ContextFactory ( this ) ; private final AlternativesManager alternativesManager = new AlternativesManager ( this ) ; private final AnnotatedElementFactory annotatedElementFactory = new AnnotatedElementFactory ( this ) ; private final BeanManagerImpl beanManagerImpl = new BeanManagerImpl ( this ) ; private final ConversationManager conversationManager = new ConversationManager ( this ) ; private final CreationalContextFactory creationalContextFactory = new CreationalContextFactory ( this ) ; private final DecoratorsManager decoratorsManager = new DecoratorsManager ( this ) ; private final EJBInterceptorConfig ejbInterceptorConfig = new EJBInterceptorConfig ( this ) ; private final ExtensionLoader extensionLoader = new ExtensionLoader ( this ) ; private final InterceptorsManager interceptorsManager = new InterceptorsManager ( this ) ; private final WebBeansInterceptorConfig webBeansInterceptorConfig = new WebBeansInterceptorConfig ( this ) ; private final ProxyFactory proxyFactory ; private final OpenWebBeansConfiguration openWebBeansConfiguration ; private final PluginLoader pluginLoader = new PluginLoader ( ) ; private final SerializableBeanVault serializableBeanVault = new SerializableBeanVault ( ) ; private final StereoTypeManager stereoTypeManager = new StereoTypeManager ( ) ; private final AnnotationManager annotationManager = new AnnotationManager ( this ) ; private final ResolutionUtil resolutionUtil = new ResolutionUtil ( this ) ; private final InjectionPointFactory injectionPointFactory = new InjectionPointFactory ( this ) ; private final InterceptorUtil interceptorUtil = new InterceptorUtil ( this ) ; private final DefinitionUtil definitionUtil = new DefinitionUtil ( this ) ; private final WebBeansAnnotatedTypeUtil annotatedTypeUtil = new WebBeansAnnotatedTypeUtil ( this ) ; private final ManagedBeanConfigurator managedBeanConfigurator = new ManagedBeanConfigurator ( this ) ; private final SecurityService securityService ; private final LoaderService loaderService ; private ScannerService scannerService ; public WebBeansContext ( ) { this ( null , new OpenWebBeansConfiguration ( ) ) ; } public WebBeansContext ( Map < Class < ? > , Object > initialServices , Properties properties ) { this ( initialServices , new OpenWebBeansConfiguration ( properties ) ) ; } private WebBeansContext ( Map < Class < ? > , Object > initialServices , OpenWebBeansConfiguration openWebBeansConfiguration ) { this . openWebBeansConfiguration = openWebBeansConfiguration ; if ( initialServices == null || ! initialServices . containsKey ( LoaderService . class ) ) { String implementationLoaderServiceName = openWebBeansConfiguration . getProperty ( LoaderService . class . getName ( ) ) ; if ( implementationLoaderServiceName == null ) { serviceMap . put ( LoaderService . class , new DefaultLoaderService ( ) ) ; } else { serviceMap . put ( LoaderService . class , LoaderService . class . cast ( get ( implementationLoaderServiceName ) ) ) ; } } if ( initialServices != null ) { for ( Map . Entry < Class < ? > , Object > entry : initialServices . entrySet ( ) ) { if ( ! entry . getKey ( ) . isAssignableFrom ( entry . getValue ( ) . getClass ( ) ) ) { throw new IllegalArgumentException ( ""Initial service claiming to be of type "" + entry . getKey ( ) + "" is a "" + entry . getValue ( ) . getClass ( ) ) ; } serviceMap . put ( entry . getKey ( ) , entry . getValue ( ) ) ; } } loaderService = getService ( LoaderService . class ) ; securityService = getService ( SecurityService . class ) ; proxyFactory = serviceMap . containsKey ( ProxyFactory . class ) ? ( ProxyFactory ) serviceMap . get ( ProxyFactory . class ) : new ProxyFactory ( ) ; OpenWebBeansClassLoaderProvider . initProxyFactoryClassLoaderProvider ( ) ; managerMap . put ( getClass ( ) , this ) ; managerMap . put ( AlternativesManager . class , alternativesManager ) ; managerMap . put ( AnnotatedElementFactory . class , annotatedElementFactory ) ; managerMap . put ( BeanManagerImpl . class , beanManagerImpl ) ; managerMap . put ( ConversationManager . class , conversationManager ) ; managerMap . put ( CreationalContextFactory . class , creationalContextFactory ) ; managerMap . put ( DecoratorsManager . class , decoratorsManager ) ; managerMap . put ( ExtensionLoader . class , extensionLoader ) ; managerMap . put ( InterceptorsManager . class , interceptorsManager ) ; managerMap . put ( ProxyFactory . class , proxyFactory ) ; managerMap . put ( OpenWebBeansConfiguration . class , openWebBeansConfiguration ) ; managerMap . put ( PluginLoader . class , pluginLoader ) ; managerMap . put ( SerializableBeanVault . class , serializableBeanVault ) ; managerMap . put ( StereoTypeManager . class , stereoTypeManager ) ; } @ Deprecated public static WebBeansContext getInstance ( ) { WebBeansContext webBeansContext = WebBeansFinder . getSingletonInstance ( ) ; return webBeansContext ; } public static WebBeansContext currentInstance ( ) { return getInstance ( ) ; } public < T > T getService ( Class < T > clazz ) { T t = clazz . cast ( serviceMap . get ( clazz ) ) ; if ( t == null ) { t = doServiceLoader ( clazz ) ; registerService ( clazz , t ) ; } return t ; } public < T > void registerService ( Class < T > clazz , T t ) { serviceMap . put ( clazz , t ) ; } private < T > T doServiceLoader ( Class < T > serviceInterface ) { String implName = getOpenWebBeansConfiguration ( ) . getProperty ( serviceInterface . getName ( ) ) ; if ( implName == null ) { List < OpenWebBeansPlugin > plugins = getPluginLoader ( ) . getPlugins ( ) ; if ( plugins != null && plugins . size ( ) > 0 ) { for ( OpenWebBeansPlugin plugin : plugins ) { if ( plugin . supportService ( serviceInterface ) ) { return plugin . getSupportedService ( serviceInterface ) ; } } } return null ; } return serviceInterface . cast ( get ( implName ) ) ; } public ManagedBeanConfigurator getManagedBeanConfigurator ( ) { return managedBeanConfigurator ; } public InterceptorUtil getInterceptorUtil ( ) { return interceptorUtil ; } public DefinitionUtil getDefinitionUtil ( ) { return definitionUtil ; } public WebBeansAnnotatedTypeUtil getAnnotatedTypeUtil ( ) { return annotatedTypeUtil ; } public InjectionPointFactory getInjectionPointFactory ( ) { return injectionPointFactory ; } public ResolutionUtil getResolutionUtil ( ) { return resolutionUtil ; } public WebBeansUtil getWebBeansUtil ( ) { return webBeansUtil ; } @ Deprecated public ContextFactory getContextFactory ( ) { return contextFactory ; } public AnnotationManager getAnnotationManager ( ) { return annotationManager ; } public ConversationManager getConversationManager ( ) { return conversationManager ; } public OpenWebBeansConfiguration getOpenWebBeansConfiguration ( ) { return openWebBeansConfiguration ; } public AnnotatedElementFactory getAnnotatedElementFactory ( ) { return annotatedElementFactory ; } public BeanManagerImpl getBeanManagerImpl ( ) { return beanManagerImpl ; } public SerializableBeanVault getSerializableBeanVault ( ) { return serializableBeanVault ; } public CreationalContextFactory getCreationalContextFactory ( ) { return creationalContextFactory ; } public DecoratorsManager getDecoratorsManager ( ) { return decoratorsManager ; } public WebBeansInterceptorConfig getWebBeansInterceptorConfig ( ) { return webBeansInterceptorConfig ; } public EJBInterceptorConfig getEJBInterceptorConfig ( ) { return ejbInterceptorConfig ; } public StereoTypeManager getStereoTypeManager ( ) { return stereoTypeManager ; } public AlternativesManager getAlternativesManager ( ) { return alternativesManager ; } public InterceptorsManager getInterceptorsManager ( ) { return interceptorsManager ; } public PluginLoader getPluginLoader ( ) { return pluginLoader ; } public ExtensionLoader getExtensionLoader ( ) { return extensionLoader ; } public ProxyFactory getProxyFactory ( ) { return proxyFactory ; } public ScannerService getScannerService ( ) { if ( scannerService == null ) { scannerService = getService ( ScannerService . class ) ; } return scannerService ; } public ContextsService getContextsService ( ) { return getService ( ContextsService . class ) ; } public SecurityService getSecurityService ( ) { return securityService ; } private Object get ( String singletonName ) { Class < ? > clazz = ClassUtil . getClassFromName ( singletonName ) ; if ( clazz == null ) { throw new WebBeansException ( ""Class not found exception in creating instance with class : "" + singletonName , new ClassNotFoundException ( ""Class with name: "" + singletonName + "" is not found in the system"" ) ) ; } return get ( clazz ) ; } public < T > T get ( Class < T > clazz ) { T object = clazz . cast ( managerMap . get ( clazz ) ) ; if ( object == null ) { object = createInstance ( clazz ) ; managerMap . put ( clazz , object ) ; } return object ; } private < T > T createInstance ( Class < T > clazz ) { try { try { Constructor < T > constructor = clazz . getConstructor ( WebBeansContext . class ) ; return constructor . newInstance ( this ) ; } catch ( NoSuchMethodException e ) { } try { Constructor < T > constructor = clazz . getConstructor ( ) ; return constructor . newInstance ( ) ; } catch ( NoSuchMethodException e ) { throw new WebBeansException ( ""No suitable constructor : "" + clazz . getName ( ) , e . getCause ( ) ) ; } } catch ( InstantiationException e ) { throw new WebBeansException ( ""Unable to instantiate class : "" + clazz . getName ( ) , e . getCause ( ) ) ; } catch ( InvocationTargetException e ) { throw new WebBeansException ( ""Unable to instantiate class : "" + clazz . getName ( ) , e . getCause ( ) ) ; } catch ( IllegalAccessException e ) { throw new WebBeansException ( ""Illegal access exception in creating instance with class : "" + clazz . getName ( ) , e ) ; } } public void clear ( ) { managerMap . clear ( ) ; } public LoaderService getLoaderService ( ) { return loaderService ; } }",Smelly
"public class ClassTypeDifference extends AbstractPropertyDifference { public ClassTypeDifference ( Object source , Object destination ) { super ( source , destination , DifferenceType . MODIFIED ) ; } }",No
"public class PolygonsSetTest { @ Test public void testSimplyConnected ( ) { Vector2D [ ] [ ] vertices = new Vector2D [ ] [ ] { new Vector2D [ ] { new Vector2D ( 36.0 , 22.0 ) , new Vector2D ( 39.0 , 32.0 ) , new Vector2D ( 19.0 , 32.0 ) , new Vector2D ( 6.0 , 16.0 ) , new Vector2D ( 31.0 , 10.0 ) , new Vector2D ( 42.0 , 16.0 ) , new Vector2D ( 34.0 , 20.0 ) , new Vector2D ( 29.0 , 19.0 ) , new Vector2D ( 23.0 , 22.0 ) , new Vector2D ( 33.0 , 25.0 ) } } ; PolygonsSet set = buildSet ( vertices ) ; Assert . assertEquals ( Region . Location . OUTSIDE , set . checkPoint ( new Vector2D ( 50.0 , 30.0 ) ) ) ; checkPoints ( Region . Location . INSIDE , set , new Vector2D [ ] { new Vector2D ( 30.0 , 15.0 ) , new Vector2D ( 15.0 , 20.0 ) , new Vector2D ( 24.0 , 25.0 ) , new Vector2D ( 35.0 , 30.0 ) , new Vector2D ( 19.0 , 17.0 ) } ) ; checkPoints ( Region . Location . OUTSIDE , set , new Vector2D [ ] { new Vector2D ( 50.0 , 30.0 ) , new Vector2D ( 30.0 , 35.0 ) , new Vector2D ( 10.0 , 25.0 ) , new Vector2D ( 10.0 , 10.0 ) , new Vector2D ( 40.0 , 10.0 ) , new Vector2D ( 50.0 , 15.0 ) , new Vector2D ( 30.0 , 22.0 ) } ) ; checkPoints ( Region . Location . BOUNDARY , set , new Vector2D [ ] { new Vector2D ( 30.0 , 32.0 ) , new Vector2D ( 34.0 , 20.0 ) } ) ; checkVertices ( set . getVertices ( ) , vertices ) ; } @ Test public void testBox ( ) { PolygonsSet box = new PolygonsSet ( 0 , 2 , - 1 , 1 , 1.0e-10 ) ; Assert . assertEquals ( 4.0 , box . getSize ( ) , 1.0e-10 ) ; Assert . assertEquals ( 8.0 , box . getBoundarySize ( ) , 1.0e-10 ) ; } @ Test public void testInfinite ( ) { PolygonsSet box = new PolygonsSet ( new BSPTree < Euclidean2D > ( Boolean . TRUE ) , 1.0e-10 ) ; Assert . assertTrue ( Double . isInfinite ( box . getSize ( ) ) ) ; } @ Test public void testStair ( ) { Vector2D [ ] [ ] vertices = new Vector2D [ ] [ ] { new Vector2D [ ] { new Vector2D ( 0.0 , 0.0 ) , new Vector2D ( 0.0 , 2.0 ) , new Vector2D ( - 0.1 , 2.0 ) , new Vector2D ( - 0.1 , 1.0 ) , new Vector2D ( - 0.3 , 1.0 ) , new Vector2D ( - 0.3 , 1.5 ) , new Vector2D ( - 1.3 , 1.5 ) , new Vector2D ( - 1.3 , 2.0 ) , new Vector2D ( - 1.8 , 2.0 ) , new Vector2D ( - 1.8 - 1.0 / FastMath . sqrt ( 2.0 ) , 2.0 - 1.0 / FastMath . sqrt ( 2.0 ) ) } } ; PolygonsSet set = buildSet ( vertices ) ; checkVertices ( set . getVertices ( ) , vertices ) ; Assert . assertEquals ( 1.1 + 0.95 * FastMath . sqrt ( 2.0 ) , set . getSize ( ) , 1.0e-10 ) ; } @ Test public void testEmpty ( ) { PolygonsSet empty = ( PolygonsSet ) new RegionFactory < Euclidean2D > ( ) . getComplement ( new PolygonsSet ( 1.0e-10 ) ) ; Assert . assertTrue ( empty . isEmpty ( ) ) ; Assert . assertEquals ( 0 , empty . getVertices ( ) . length ) ; Assert . assertEquals ( 0.0 , empty . getBoundarySize ( ) , 1.0e-10 ) ; Assert . assertEquals ( 0.0 , empty . getSize ( ) , 1.0e-10 ) ; for ( double y = - 1 ; y < 1 ; y += 0.1 ) { for ( double x = - 1 ; x < 1 ; x += 0.1 ) { Assert . assertEquals ( Double . POSITIVE_INFINITY , empty . projectToBoundary ( new Vector2D ( x , y ) ) . getOffset ( ) , 1.0e-10 ) ; } } } @ Test public void testFull ( ) { PolygonsSet empty = new PolygonsSet ( 1.0e-10 ) ; Assert . assertFalse ( empty . isEmpty ( ) ) ; Assert . assertEquals ( 0 , empty . getVertices ( ) . length ) ; Assert . assertEquals ( 0.0 , empty . getBoundarySize ( ) , 1.0e-10 ) ; Assert . assertEquals ( Double . POSITIVE_INFINITY , empty . getSize ( ) , 1.0e-10 ) ; for ( double y = - 1 ; y < 1 ; y += 0.1 ) { for ( double x = - 1 ; x < 1 ; x += 0.1 ) { Assert . assertEquals ( Double . NEGATIVE_INFINITY , empty . projectToBoundary ( new Vector2D ( x , y ) ) . getOffset ( ) , 1.0e-10 ) ; } } } @ Test public void testHole ( ) { Vector2D [ ] [ ] vertices = new Vector2D [ ] [ ] { new Vector2D [ ] { new Vector2D ( 0.0 , 0.0 ) , new Vector2D ( 3.0 , 0.0 ) , new Vector2D ( 3.0 , 3.0 ) , new Vector2D ( 0.0 , 3.0 ) } , new Vector2D [ ] { new Vector2D ( 1.0 , 2.0 ) , new Vector2D ( 2.0 , 2.0 ) , new Vector2D ( 2.0 , 1.0 ) , new Vector2D ( 1.0 , 1.0 ) } } ; PolygonsSet set = buildSet ( vertices ) ; checkPoints ( Region . Location . INSIDE , set , new Vector2D [ ] { new Vector2D ( 0.5 , 0.5 ) , new Vector2D ( 1.5 , 0.5 ) , new Vector2D ( 2.5 , 0.5 ) , new Vector2D ( 0.5 , 1.5 ) , new Vector2D ( 2.5 , 1.5 ) , new Vector2D ( 0.5 , 2.5 ) , new Vector2D ( 1.5 , 2.5 ) , new Vector2D ( 2.5 , 2.5 ) , new Vector2D ( 0.5 , 1.0 ) } ) ; checkPoints ( Region . Location . OUTSIDE , set , new Vector2D [ ] { new Vector2D ( 1.5 , 1.5 ) , new Vector2D ( 3.5 , 1.0 ) , new Vector2D ( 4.0 , 1.5 ) , new Vector2D ( 6.0 , 6.0 ) } ) ; checkPoints ( Region . Location . BOUNDARY , set , new Vector2D [ ] { new Vector2D ( 1.0 , 1.0 ) , new Vector2D ( 1.5 , 0.0 ) , new Vector2D ( 1.5 , 1.0 ) , new Vector2D ( 1.5 , 2.0 ) , new Vector2D ( 1.5 , 3.0 ) , new Vector2D ( 3.0 , 3.0 ) } ) ; checkVertices ( set . getVertices ( ) , vertices ) ; for ( double x = - 0.999 ; x < 3.999 ; x += 0.11 ) { Vector2D v = new Vector2D ( x , x + 0.5 ) ; BoundaryProjection < Euclidean2D > projection = set . projectToBoundary ( v ) ; Assert . assertTrue ( projection . getOriginal ( ) == v ) ; Vector2D p = ( Vector2D ) projection . getProjected ( ) ; if ( x < - 0.5 ) { Assert . assertEquals ( 0.0 , p . getX ( ) , 1.0e-10 ) ; Assert . assertEquals ( 0.0 , p . getY ( ) , 1.0e-10 ) ; Assert . assertEquals ( + v . distance ( Vector2D . ZERO ) , projection . getOffset ( ) , 1.0e-10 ) ; } else if ( x < 0.5 ) { Assert . assertEquals ( 0.0 , p . getX ( ) , 1.0e-10 ) ; Assert . assertEquals ( v . getY ( ) , p . getY ( ) , 1.0e-10 ) ; Assert . assertEquals ( - v . getX ( ) , projection . getOffset ( ) , 1.0e-10 ) ; } else if ( x < 1.25 ) { Assert . assertEquals ( 1.0 , p . getX ( ) , 1.0e-10 ) ; Assert . assertEquals ( v . getY ( ) , p . getY ( ) , 1.0e-10 ) ; Assert . assertEquals ( v . getX ( ) - 1.0 , projection . getOffset ( ) , 1.0e-10 ) ; } else if ( x < 2.0 ) { Assert . assertEquals ( v . getX ( ) , p . getX ( ) , 1.0e-10 ) ; Assert . assertEquals ( 2.0 , p . getY ( ) , 1.0e-10 ) ; Assert . assertEquals ( 2.0 - v . getY ( ) , projection . getOffset ( ) , 1.0e-10 ) ; } else if ( x < 3.0 ) { Assert . assertEquals ( v . getX ( ) , p . getX ( ) , 1.0e-10 ) ; Assert . assertEquals ( 3.0 , p . getY ( ) , 1.0e-10 ) ; Assert . assertEquals ( v . getY ( ) - 3.0 , projection . getOffset ( ) , 1.0e-10 ) ; } else { Assert . assertEquals ( 3.0 , p . getX ( ) , 1.0e-10 ) ; Assert . assertEquals ( 3.0 , p . getY ( ) , 1.0e-10 ) ; Assert . assertEquals ( + v . distance ( new Vector2D ( 3 , 3 ) ) , projection . getOffset ( ) , 1.0e-10 ) ; } } } @ Test public void testDisjointPolygons ( ) { Vector2D [ ] [ ] vertices = new Vector2D [ ] [ ] { new Vector2D [ ] { new Vector2D ( 0.0 , 1.0 ) , new Vector2D ( 2.0 , 1.0 ) , new Vector2D ( 1.0 , 2.0 ) } , new Vector2D [ ] { new Vector2D ( 4.0 , 0.0 ) , new Vector2D ( 5.0 , 1.0 ) , new Vector2D ( 3.0 , 1.0 ) } } ; PolygonsSet set = buildSet ( vertices ) ; Assert . assertEquals ( Region . Location . INSIDE , set . checkPoint ( new Vector2D ( 1.0 , 1.5 ) ) ) ; checkPoints ( Region . Location . INSIDE , set , new Vector2D [ ] { new Vector2D ( 1.0 , 1.5 ) , new Vector2D ( 4.5 , 0.8 ) } ) ; checkPoints ( Region . Location . OUTSIDE , set , new Vector2D [ ] { new Vector2D ( 1.0 , 0.0 ) , new Vector2D ( 3.5 , 1.2 ) , new Vector2D ( 2.5 , 1.0 ) , new Vector2D ( 3.0 , 4.0 ) } ) ; checkPoints ( Region . Location . BOUNDARY , set , new Vector2D [ ] { new Vector2D ( 1.0 , 1.0 ) , new Vector2D ( 3.5 , 0.5 ) , new Vector2D ( 0.0 , 1.0 ) } ) ; checkVertices ( set . getVertices ( ) , vertices ) ; } @ Test public void testOppositeHyperplanes ( ) { Vector2D [ ] [ ] vertices = new Vector2D [ ] [ ] { new Vector2D [ ] { new Vector2D ( 1.0 , 0.0 ) , new Vector2D ( 2.0 , 1.0 ) , new Vector2D ( 3.0 , 1.0 ) , new Vector2D ( 2.0 , 2.0 ) , new Vector2D ( 1.0 , 1.0 ) , new Vector2D ( 0.0 , 1.0 ) } } ; PolygonsSet set = buildSet ( vertices ) ; checkVertices ( set . getVertices ( ) , vertices ) ; } @ Test public void testSingularPoint ( ) { Vector2D [ ] [ ] vertices = new Vector2D [ ] [ ] { new Vector2D [ ] { new Vector2D ( 0.0 , 0.0 ) , new Vector2D ( 1.0 , 0.0 ) , new Vector2D ( 1.0 , 1.0 ) , new Vector2D ( 0.0 , 1.0 ) , new Vector2D ( 0.0 , 0.0 ) , new Vector2D ( - 1.0 , 0.0 ) , new Vector2D ( - 1.0 , - 1.0 ) , new Vector2D ( 0.0 , - 1.0 ) } } ; PolygonsSet set = buildSet ( vertices ) ; checkVertices ( set . getVertices ( ) , vertices ) ; } @ Test public void testLineIntersection ( ) { Vector2D [ ] [ ] vertices = new Vector2D [ ] [ ] { new Vector2D [ ] { new Vector2D ( 0.0 , 0.0 ) , new Vector2D ( 2.0 , 0.0 ) , new Vector2D ( 2.0 , 1.0 ) , new Vector2D ( 3.0 , 1.0 ) , new Vector2D ( 3.0 , 3.0 ) , new Vector2D ( 1.0 , 3.0 ) , new Vector2D ( 1.0 , 2.0 ) , new Vector2D ( 0.0 , 2.0 ) } } ; PolygonsSet set = buildSet ( vertices ) ; Line l1 = new Line ( new Vector2D ( - 1.5 , 0.0 ) , FastMath . PI / 4 , 1.0e-10 ) ; SubLine s1 = ( SubLine ) set . intersection ( l1 . wholeHyperplane ( ) ) ; List < Interval > i1 = ( ( IntervalsSet ) s1 . getRemainingRegion ( ) ) . asList ( ) ; Assert . assertEquals ( 2 , i1 . size ( ) ) ; Interval v10 = i1 . get ( 0 ) ; Vector2D p10Lower = l1 . toSpace ( new Vector1D ( v10 . getInf ( ) ) ) ; Assert . assertEquals ( 0.0 , p10Lower . getX ( ) , 1.0e-10 ) ; Assert . assertEquals ( 1.5 , p10Lower . getY ( ) , 1.0e-10 ) ; Vector2D p10Upper = l1 . toSpace ( new Vector1D ( v10 . getSup ( ) ) ) ; Assert . assertEquals ( 0.5 , p10Upper . getX ( ) , 1.0e-10 ) ; Assert . assertEquals ( 2.0 , p10Upper . getY ( ) , 1.0e-10 ) ; Interval v11 = i1 . get ( 1 ) ; Vector2D p11Lower = l1 . toSpace ( new Vector1D ( v11 . getInf ( ) ) ) ; Assert . assertEquals ( 1.0 , p11Lower . getX ( ) , 1.0e-10 ) ; Assert . assertEquals ( 2.5 , p11Lower . getY ( ) , 1.0e-10 ) ; Vector2D p11Upper = l1 . toSpace ( new Vector1D ( v11 . getSup ( ) ) ) ; Assert . assertEquals ( 1.5 , p11Upper . getX ( ) , 1.0e-10 ) ; Assert . assertEquals ( 3.0 , p11Upper . getY ( ) , 1.0e-10 ) ; Line l2 = new Line ( new Vector2D ( - 1.0 , 2.0 ) , 0 , 1.0e-10 ) ; SubLine s2 = ( SubLine ) set . intersection ( l2 . wholeHyperplane ( ) ) ; List < Interval > i2 = ( ( IntervalsSet ) s2 . getRemainingRegion ( ) ) . asList ( ) ; Assert . assertEquals ( 1 , i2 . size ( ) ) ; Interval v20 = i2 . get ( 0 ) ; Vector2D p20Lower = l2 . toSpace ( new Vector1D ( v20 . getInf ( ) ) ) ; Assert . assertEquals ( 1.0 , p20Lower . getX ( ) , 1.0e-10 ) ; Assert . assertEquals ( 2.0 , p20Lower . getY ( ) , 1.0e-10 ) ; Vector2D p20Upper = l2 . toSpace ( new Vector1D ( v20 . getSup ( ) ) ) ; Assert . assertEquals ( 3.0 , p20Upper . getX ( ) , 1.0e-10 ) ; Assert . assertEquals ( 2.0 , p20Upper . getY ( ) , 1.0e-10 ) ; } @ Test public void testUnlimitedSubHyperplane ( ) { Vector2D [ ] [ ] vertices1 = new Vector2D [ ] [ ] { new Vector2D [ ] { new Vector2D ( 0.0 , 0.0 ) , new Vector2D ( 4.0 , 0.0 ) , new Vector2D ( 1.4 , 1.5 ) , new Vector2D ( 0.0 , 3.5 ) } } ; PolygonsSet set1 = buildSet ( vertices1 ) ; Vector2D [ ] [ ] vertices2 = new Vector2D [ ] [ ] { new Vector2D [ ] { new Vector2D ( 1.4 , 0.2 ) , new Vector2D ( 2.8 , - 1.2 ) , new Vector2D ( 2.5 , 0.6 ) } } ; PolygonsSet set2 = buildSet ( vertices2 ) ; PolygonsSet set = ( PolygonsSet ) new RegionFactory < Euclidean2D > ( ) . union ( set1 . copySelf ( ) , set2 . copySelf ( ) ) ; checkVertices ( set1 . getVertices ( ) , vertices1 ) ; checkVertices ( set2 . getVertices ( ) , vertices2 ) ; checkVertices ( set . getVertices ( ) , new Vector2D [ ] [ ] { new Vector2D [ ] { new Vector2D ( 0.0 , 0.0 ) , new Vector2D ( 1.6 , 0.0 ) , new Vector2D ( 2.8 , - 1.2 ) , new Vector2D ( 2.6 , 0.0 ) , new Vector2D ( 4.0 , 0.0 ) , new Vector2D ( 1.4 , 1.5 ) , new Vector2D ( 0.0 , 3.5 ) } } ) ; } @ Test public void testUnion ( ) { Vector2D [ ] [ ] vertices1 = new Vector2D [ ] [ ] { new Vector2D [ ] { new Vector2D ( 0.0 , 0.0 ) , new Vector2D ( 2.0 , 0.0 ) , new Vector2D ( 2.0 , 2.0 ) , new Vector2D ( 0.0 , 2.0 ) } } ; PolygonsSet set1 = buildSet ( vertices1 ) ; Vector2D [ ] [ ] vertices2 = new Vector2D [ ] [ ] { new Vector2D [ ] { new Vector2D ( 1.0 , 1.0 ) , new Vector2D ( 3.0 , 1.0 ) , new Vector2D ( 3.0 , 3.0 ) , new Vector2D ( 1.0 , 3.0 ) } } ; PolygonsSet set2 = buildSet ( vertices2 ) ; PolygonsSet set = ( PolygonsSet ) new RegionFactory < Euclidean2D > ( ) . union ( set1 . copySelf ( ) , set2 . copySelf ( ) ) ; checkVertices ( set1 . getVertices ( ) , vertices1 ) ; checkVertices ( set2 . getVertices ( ) , vertices2 ) ; checkVertices ( set . getVertices ( ) , new Vector2D [ ] [ ] { new Vector2D [ ] { new Vector2D ( 0.0 , 0.0 ) , new Vector2D ( 2.0 , 0.0 ) , new Vector2D ( 2.0 , 1.0 ) , new Vector2D ( 3.0 , 1.0 ) , new Vector2D ( 3.0 , 3.0 ) , new Vector2D ( 1.0 , 3.0 ) , new Vector2D ( 1.0 , 2.0 ) , new Vector2D ( 0.0 , 2.0 ) } } ) ; checkPoints ( Region . Location . INSIDE , set , new Vector2D [ ] { new Vector2D ( 1.0 , 1.0 ) , new Vector2D ( 0.5 , 0.5 ) , new Vector2D ( 2.0 , 2.0 ) , new Vector2D ( 2.5 , 2.5 ) , new Vector2D ( 0.5 , 1.5 ) , new Vector2D ( 1.5 , 1.5 ) , new Vector2D ( 1.5 , 0.5 ) , new Vector2D ( 1.5 , 2.5 ) , new Vector2D ( 2.5 , 1.5 ) , new Vector2D ( 2.5 , 2.5 ) } ) ; checkPoints ( Region . Location . OUTSIDE , set , new Vector2D [ ] { new Vector2D ( - 0.5 , 0.5 ) , new Vector2D ( 0.5 , 2.5 ) , new Vector2D ( 2.5 , 0.5 ) , new Vector2D ( 3.5 , 2.5 ) } ) ; checkPoints ( Region . Location . BOUNDARY , set , new Vector2D [ ] { new Vector2D ( 0.0 , 0.0 ) , new Vector2D ( 0.5 , 2.0 ) , new Vector2D ( 2.0 , 0.5 ) , new Vector2D ( 2.5 , 1.0 ) , new Vector2D ( 3.0 , 2.5 ) } ) ; } @ Test public void testIntersection ( ) { Vector2D [ ] [ ] vertices1 = new Vector2D [ ] [ ] { new Vector2D [ ] { new Vector2D ( 0.0 , 0.0 ) , new Vector2D ( 2.0 , 0.0 ) , new Vector2D ( 2.0 , 2.0 ) , new Vector2D ( 0.0 , 2.0 ) } } ; PolygonsSet set1 = buildSet ( vertices1 ) ; Vector2D [ ] [ ] vertices2 = new Vector2D [ ] [ ] { new Vector2D [ ] { new Vector2D ( 1.0 , 1.0 ) , new Vector2D ( 3.0 , 1.0 ) , new Vector2D ( 3.0 , 3.0 ) , new Vector2D ( 1.0 , 3.0 ) } } ; PolygonsSet set2 = buildSet ( vertices2 ) ; PolygonsSet set = ( PolygonsSet ) new RegionFactory < Euclidean2D > ( ) . intersection ( set1 . copySelf ( ) , set2 . copySelf ( ) ) ; checkVertices ( set1 . getVertices ( ) , vertices1 ) ; checkVertices ( set2 . getVertices ( ) , vertices2 ) ; checkVertices ( set . getVertices ( ) , new Vector2D [ ] [ ] { new Vector2D [ ] { new Vector2D ( 1.0 , 1.0 ) , new Vector2D ( 2.0 , 1.0 ) , new Vector2D ( 2.0 , 2.0 ) , new Vector2D ( 1.0 , 2.0 ) } } ) ; checkPoints ( Region . Location . INSIDE , set , new Vector2D [ ] { new Vector2D ( 1.5 , 1.5 ) } ) ; checkPoints ( Region . Location . OUTSIDE , set , new Vector2D [ ] { new Vector2D ( 0.5 , 1.5 ) , new Vector2D ( 2.5 , 1.5 ) , new Vector2D ( 1.5 , 0.5 ) , new Vector2D ( 0.5 , 0.5 ) } ) ; checkPoints ( Region . Location . BOUNDARY , set , new Vector2D [ ] { new Vector2D ( 1.0 , 1.0 ) , new Vector2D ( 2.0 , 2.0 ) , new Vector2D ( 1.0 , 1.5 ) , new Vector2D ( 1.5 , 2.0 ) } ) ; } @ Test public void testXor ( ) { Vector2D [ ] [ ] vertices1 = new Vector2D [ ] [ ] { new Vector2D [ ] { new Vector2D ( 0.0 , 0.0 ) , new Vector2D ( 2.0 , 0.0 ) , new Vector2D ( 2.0 , 2.0 ) , new Vector2D ( 0.0 , 2.0 ) } } ; PolygonsSet set1 = buildSet ( vertices1 ) ; Vector2D [ ] [ ] vertices2 = new Vector2D [ ] [ ] { new Vector2D [ ] { new Vector2D ( 1.0 , 1.0 ) , new Vector2D ( 3.0 , 1.0 ) , new Vector2D ( 3.0 , 3.0 ) , new Vector2D ( 1.0 , 3.0 ) } } ; PolygonsSet set2 = buildSet ( vertices2 ) ; PolygonsSet set = ( PolygonsSet ) new RegionFactory < Euclidean2D > ( ) . xor ( set1 . copySelf ( ) , set2 . copySelf ( ) ) ; checkVertices ( set1 . getVertices ( ) , vertices1 ) ; checkVertices ( set2 . getVertices ( ) , vertices2 ) ; checkVertices ( set . getVertices ( ) , new Vector2D [ ] [ ] { new Vector2D [ ] { new Vector2D ( 0.0 , 0.0 ) , new Vector2D ( 2.0 , 0.0 ) , new Vector2D ( 2.0 , 1.0 ) , new Vector2D ( 3.0 , 1.0 ) , new Vector2D ( 3.0 , 3.0 ) , new Vector2D ( 1.0 , 3.0 ) , new Vector2D ( 1.0 , 2.0 ) , new Vector2D ( 0.0 , 2.0 ) } , new Vector2D [ ] { new Vector2D ( 1.0 , 1.0 ) , new Vector2D ( 1.0 , 2.0 ) , new Vector2D ( 2.0 , 2.0 ) , new Vector2D ( 2.0 , 1.0 ) } } ) ; checkPoints ( Region . Location . INSIDE , set , new Vector2D [ ] { new Vector2D ( 0.5 , 0.5 ) , new Vector2D ( 2.5 , 2.5 ) , new Vector2D ( 0.5 , 1.5 ) , new Vector2D ( 1.5 , 0.5 ) , new Vector2D ( 1.5 , 2.5 ) , new Vector2D ( 2.5 , 1.5 ) , new Vector2D ( 2.5 , 2.5 ) } ) ; checkPoints ( Region . Location . OUTSIDE , set , new Vector2D [ ] { new Vector2D ( - 0.5 , 0.5 ) , new Vector2D ( 0.5 , 2.5 ) , new Vector2D ( 2.5 , 0.5 ) , new Vector2D ( 1.5 , 1.5 ) , new Vector2D ( 3.5 , 2.5 ) } ) ; checkPoints ( Region . Location . BOUNDARY , set , new Vector2D [ ] { new Vector2D ( 1.0 , 1.0 ) , new Vector2D ( 2.0 , 2.0 ) , new Vector2D ( 1.5 , 1.0 ) , new Vector2D ( 2.0 , 1.5 ) , new Vector2D ( 0.0 , 0.0 ) , new Vector2D ( 0.5 , 2.0 ) , new Vector2D ( 2.0 , 0.5 ) , new Vector2D ( 2.5 , 1.0 ) , new Vector2D ( 3.0 , 2.5 ) } ) ; } @ Test public void testDifference ( ) { Vector2D [ ] [ ] vertices1 = new Vector2D [ ] [ ] { new Vector2D [ ] { new Vector2D ( 0.0 , 0.0 ) , new Vector2D ( 2.0 , 0.0 ) , new Vector2D ( 2.0 , 2.0 ) , new Vector2D ( 0.0 , 2.0 ) } } ; PolygonsSet set1 = buildSet ( vertices1 ) ; Vector2D [ ] [ ] vertices2 = new Vector2D [ ] [ ] { new Vector2D [ ] { new Vector2D ( 1.0 , 1.0 ) , new Vector2D ( 3.0 , 1.0 ) , new Vector2D ( 3.0 , 3.0 ) , new Vector2D ( 1.0 , 3.0 ) } } ; PolygonsSet set2 = buildSet ( vertices2 ) ; PolygonsSet set = ( PolygonsSet ) new RegionFactory < Euclidean2D > ( ) . difference ( set1 . copySelf ( ) , set2 . copySelf ( ) ) ; checkVertices ( set1 . getVertices ( ) , vertices1 ) ; checkVertices ( set2 . getVertices ( ) , vertices2 ) ; checkVertices ( set . getVertices ( ) , new Vector2D [ ] [ ] { new Vector2D [ ] { new Vector2D ( 0.0 , 0.0 ) , new Vector2D ( 2.0 , 0.0 ) , new Vector2D ( 2.0 , 1.0 ) , new Vector2D ( 1.0 , 1.0 ) , new Vector2D ( 1.0 , 2.0 ) , new Vector2D ( 0.0 , 2.0 ) } } ) ; checkPoints ( Region . Location . INSIDE , set , new Vector2D [ ] { new Vector2D ( 0.5 , 0.5 ) , new Vector2D ( 0.5 , 1.5 ) , new Vector2D ( 1.5 , 0.5 ) } ) ; checkPoints ( Region . Location . OUTSIDE , set , new Vector2D [ ] { new Vector2D ( 2.5 , 2.5 ) , new Vector2D ( - 0.5 , 0.5 ) , new Vector2D ( 0.5 , 2.5 ) , new Vector2D ( 2.5 , 0.5 ) , new Vector2D ( 1.5 , 1.5 ) , new Vector2D ( 3.5 , 2.5 ) , new Vector2D ( 1.5 , 2.5 ) , new Vector2D ( 2.5 , 1.5 ) , new Vector2D ( 2.0 , 1.5 ) , new Vector2D ( 2.0 , 2.0 ) , new Vector2D ( 2.5 , 1.0 ) , new Vector2D ( 2.5 , 2.5 ) , new Vector2D ( 3.0 , 2.5 ) } ) ; checkPoints ( Region . Location . BOUNDARY , set , new Vector2D [ ] { new Vector2D ( 1.0 , 1.0 ) , new Vector2D ( 1.5 , 1.0 ) , new Vector2D ( 0.0 , 0.0 ) , new Vector2D ( 0.5 , 2.0 ) , new Vector2D ( 2.0 , 0.5 ) } ) ; } @ Test public void testEmptyDifference ( ) { Vector2D [ ] [ ] vertices1 = new Vector2D [ ] [ ] { new Vector2D [ ] { new Vector2D ( 0.5 , 3.5 ) , new Vector2D ( 0.5 , 4.5 ) , new Vector2D ( - 0.5 , 4.5 ) , new Vector2D ( - 0.5 , 3.5 ) } } ; PolygonsSet set1 = buildSet ( vertices1 ) ; Vector2D [ ] [ ] vertices2 = new Vector2D [ ] [ ] { new Vector2D [ ] { new Vector2D ( 1.0 , 2.0 ) , new Vector2D ( 1.0 , 8.0 ) , new Vector2D ( - 1.0 , 8.0 ) , new Vector2D ( - 1.0 , 2.0 ) } } ; PolygonsSet set2 = buildSet ( vertices2 ) ; Assert . assertTrue ( new RegionFactory < Euclidean2D > ( ) . difference ( set1 . copySelf ( ) , set2 . copySelf ( ) ) . isEmpty ( ) ) ; } @ Test public void testChoppedHexagon ( ) { double pi6 = FastMath . PI / 6.0 ; double sqrt3 = FastMath . sqrt ( 3.0 ) ; SubLine [ ] hyp = { new Line ( new Vector2D ( 0.0 , 1.0 ) , 5 * pi6 , 1.0e-10 ) . wholeHyperplane ( ) , new Line ( new Vector2D ( - sqrt3 , 1.0 ) , 7 * pi6 , 1.0e-10 ) . wholeHyperplane ( ) , new Line ( new Vector2D ( - sqrt3 , 1.0 ) , 9 * pi6 , 1.0e-10 ) . wholeHyperplane ( ) , new Line ( new Vector2D ( - sqrt3 , 0.0 ) , 11 * pi6 , 1.0e-10 ) . wholeHyperplane ( ) , new Line ( new Vector2D ( 0.0 , 0.0 ) , 13 * pi6 , 1.0e-10 ) . wholeHyperplane ( ) , new Line ( new Vector2D ( 0.0 , 1.0 ) , 3 * pi6 , 1.0e-10 ) . wholeHyperplane ( ) , new Line ( new Vector2D ( - 5.0 * sqrt3 / 6.0 , 0.0 ) , 9 * pi6 , 1.0e-10 ) . wholeHyperplane ( ) } ; hyp [ 1 ] = ( SubLine ) hyp [ 1 ] . split ( hyp [ 0 ] . getHyperplane ( ) ) . getMinus ( ) ; hyp [ 2 ] = ( SubLine ) hyp [ 2 ] . split ( hyp [ 1 ] . getHyperplane ( ) ) . getMinus ( ) ; hyp [ 3 ] = ( SubLine ) hyp [ 3 ] . split ( hyp [ 2 ] . getHyperplane ( ) ) . getMinus ( ) ; hyp [ 4 ] = ( SubLine ) hyp [ 4 ] . split ( hyp [ 3 ] . getHyperplane ( ) ) . getMinus ( ) . split ( hyp [ 0 ] . getHyperplane ( ) ) . getMinus ( ) ; hyp [ 5 ] = ( SubLine ) hyp [ 5 ] . split ( hyp [ 4 ] . getHyperplane ( ) ) . getMinus ( ) . split ( hyp [ 0 ] . getHyperplane ( ) ) . getMinus ( ) ; hyp [ 6 ] = ( SubLine ) hyp [ 6 ] . split ( hyp [ 3 ] . getHyperplane ( ) ) . getMinus ( ) . split ( hyp [ 1 ] . getHyperplane ( ) ) . getMinus ( ) ; BSPTree < Euclidean2D > tree = new BSPTree < Euclidean2D > ( Boolean . TRUE ) ; for ( int i = hyp . length - 1 ; i >= 0 ; -- i ) { tree = new BSPTree < Euclidean2D > ( hyp [ i ] , new BSPTree < Euclidean2D > ( Boolean . FALSE ) , tree , null ) ; } PolygonsSet set = new PolygonsSet ( tree , 1.0e-10 ) ; SubLine splitter = new Line ( new Vector2D ( - 2.0 * sqrt3 / 3.0 , 0.0 ) , 9 * pi6 , 1.0e-10 ) . wholeHyperplane ( ) ; PolygonsSet slice = new PolygonsSet ( new BSPTree < Euclidean2D > ( splitter , set . getTree ( false ) . split ( splitter ) . getPlus ( ) , new BSPTree < Euclidean2D > ( Boolean . FALSE ) , null ) , 1.0e-10 ) ; Assert . assertEquals ( Region . Location . OUTSIDE , slice . checkPoint ( new Vector2D ( 0.1 , 0.5 ) ) ) ; Assert . assertEquals ( 11.0 / 3.0 , slice . getBoundarySize ( ) , 1.0e-10 ) ; } @ Test public void testConcentric ( ) { double h = FastMath . sqrt ( 3.0 ) / 2.0 ; Vector2D [ ] [ ] vertices1 = new Vector2D [ ] [ ] { new Vector2D [ ] { new Vector2D ( 0.00 , 0.1 * h ) , new Vector2D ( 0.05 , 0.1 * h ) , new Vector2D ( 0.10 , 0.2 * h ) , new Vector2D ( 0.05 , 0.3 * h ) , new Vector2D ( - 0.05 , 0.3 * h ) , new Vector2D ( - 0.10 , 0.2 * h ) , new Vector2D ( - 0.05 , 0.1 * h ) } } ; PolygonsSet set1 = buildSet ( vertices1 ) ; Vector2D [ ] [ ] vertices2 = new Vector2D [ ] [ ] { new Vector2D [ ] { new Vector2D ( 0.00 , 0.0 * h ) , new Vector2D ( 0.10 , 0.0 * h ) , new Vector2D ( 0.20 , 0.2 * h ) , new Vector2D ( 0.10 , 0.4 * h ) , new Vector2D ( - 0.10 , 0.4 * h ) , new Vector2D ( - 0.20 , 0.2 * h ) , new Vector2D ( - 0.10 , 0.0 * h ) } } ; PolygonsSet set2 = buildSet ( vertices2 ) ; Assert . assertTrue ( set2 . contains ( set1 ) ) ; } @ Test public void testBug20040520 ( ) { BSPTree < Euclidean2D > a0 = new BSPTree < Euclidean2D > ( buildSegment ( new Vector2D ( 0.85 , - 0.05 ) , new Vector2D ( 0.90 , - 0.10 ) ) , new BSPTree < Euclidean2D > ( Boolean . FALSE ) , new BSPTree < Euclidean2D > ( Boolean . TRUE ) , null ) ; BSPTree < Euclidean2D > a1 = new BSPTree < Euclidean2D > ( buildSegment ( new Vector2D ( 0.85 , - 0.10 ) , new Vector2D ( 0.90 , - 0.10 ) ) , new BSPTree < Euclidean2D > ( Boolean . FALSE ) , a0 , null ) ; BSPTree < Euclidean2D > a2 = new BSPTree < Euclidean2D > ( buildSegment ( new Vector2D ( 0.90 , - 0.05 ) , new Vector2D ( 0.85 , - 0.05 ) ) , new BSPTree < Euclidean2D > ( Boolean . FALSE ) , a1 , null ) ; BSPTree < Euclidean2D > a3 = new BSPTree < Euclidean2D > ( buildSegment ( new Vector2D ( 0.82 , - 0.05 ) , new Vector2D ( 0.82 , - 0.08 ) ) , new BSPTree < Euclidean2D > ( Boolean . FALSE ) , new BSPTree < Euclidean2D > ( Boolean . TRUE ) , null ) ; BSPTree < Euclidean2D > a4 = new BSPTree < Euclidean2D > ( buildHalfLine ( new Vector2D ( 0.85 , - 0.05 ) , new Vector2D ( 0.80 , - 0.05 ) , false ) , new BSPTree < Euclidean2D > ( Boolean . FALSE ) , a3 , null ) ; BSPTree < Euclidean2D > a5 = new BSPTree < Euclidean2D > ( buildSegment ( new Vector2D ( 0.82 , - 0.08 ) , new Vector2D ( 0.82 , - 0.18 ) ) , new BSPTree < Euclidean2D > ( Boolean . FALSE ) , new BSPTree < Euclidean2D > ( Boolean . TRUE ) , null ) ; BSPTree < Euclidean2D > a6 = new BSPTree < Euclidean2D > ( buildHalfLine ( new Vector2D ( 0.82 , - 0.18 ) , new Vector2D ( 0.85 , - 0.15 ) , true ) , new BSPTree < Euclidean2D > ( Boolean . FALSE ) , a5 , null ) ; BSPTree < Euclidean2D > a7 = new BSPTree < Euclidean2D > ( buildHalfLine ( new Vector2D ( 0.85 , - 0.05 ) , new Vector2D ( 0.82 , - 0.08 ) , false ) , a4 , a6 , null ) ; BSPTree < Euclidean2D > a8 = new BSPTree < Euclidean2D > ( buildLine ( new Vector2D ( 0.85 , - 0.25 ) , new Vector2D ( 0.85 , 0.05 ) ) , a2 , a7 , null ) ; BSPTree < Euclidean2D > a9 = new BSPTree < Euclidean2D > ( buildLine ( new Vector2D ( 0.90 , 0.05 ) , new Vector2D ( 0.90 , - 0.50 ) ) , a8 , new BSPTree < Euclidean2D > ( Boolean . FALSE ) , null ) ; BSPTree < Euclidean2D > b0 = new BSPTree < Euclidean2D > ( buildSegment ( new Vector2D ( 0.92 , - 0.12 ) , new Vector2D ( 0.92 , - 0.08 ) ) , new BSPTree < Euclidean2D > ( Boolean . FALSE ) , new BSPTree < Euclidean2D > ( Boolean . TRUE ) , null ) ; BSPTree < Euclidean2D > b1 = new BSPTree < Euclidean2D > ( buildHalfLine ( new Vector2D ( 0.92 , - 0.08 ) , new Vector2D ( 0.90 , - 0.10 ) , true ) , new BSPTree < Euclidean2D > ( Boolean . FALSE ) , b0 , null ) ; BSPTree < Euclidean2D > b2 = new BSPTree < Euclidean2D > ( buildSegment ( new Vector2D ( 0.92 , - 0.18 ) , new Vector2D ( 0.92 , - 0.12 ) ) , new BSPTree < Euclidean2D > ( Boolean . FALSE ) , new BSPTree < Euclidean2D > ( Boolean . TRUE ) , null ) ; BSPTree < Euclidean2D > b3 = new BSPTree < Euclidean2D > ( buildSegment ( new Vector2D ( 0.85 , - 0.15 ) , new Vector2D ( 0.90 , - 0.20 ) ) , new BSPTree < Euclidean2D > ( Boolean . FALSE ) , b2 , null ) ; BSPTree < Euclidean2D > b4 = new BSPTree < Euclidean2D > ( buildSegment ( new Vector2D ( 0.95 , - 0.15 ) , new Vector2D ( 0.85 , - 0.05 ) ) , b1 , b3 , null ) ; BSPTree < Euclidean2D > b5 = new BSPTree < Euclidean2D > ( buildHalfLine ( new Vector2D ( 0.85 , - 0.05 ) , new Vector2D ( 0.85 , - 0.25 ) , true ) , new BSPTree < Euclidean2D > ( Boolean . FALSE ) , b4 , null ) ; BSPTree < Euclidean2D > b6 = new BSPTree < Euclidean2D > ( buildLine ( new Vector2D ( 0.0 , - 1.10 ) , new Vector2D ( 1.0 , - 0.10 ) ) , new BSPTree < Euclidean2D > ( Boolean . FALSE ) , b5 , null ) ; PolygonsSet c = ( PolygonsSet ) new RegionFactory < Euclidean2D > ( ) . union ( new PolygonsSet ( a9 , 1.0e-10 ) , new PolygonsSet ( b6 , 1.0e-10 ) ) ; checkPoints ( Region . Location . INSIDE , c , new Vector2D [ ] { new Vector2D ( 0.83 , - 0.06 ) , new Vector2D ( 0.83 , - 0.15 ) , new Vector2D ( 0.88 , - 0.15 ) , new Vector2D ( 0.88 , - 0.09 ) , new Vector2D ( 0.88 , - 0.07 ) , new Vector2D ( 0.91 , - 0.18 ) , new Vector2D ( 0.91 , - 0.10 ) } ) ; checkPoints ( Region . Location . OUTSIDE , c , new Vector2D [ ] { new Vector2D ( 0.80 , - 0.10 ) , new Vector2D ( 0.83 , - 0.50 ) , new Vector2D ( 0.83 , - 0.20 ) , new Vector2D ( 0.83 , - 0.02 ) , new Vector2D ( 0.87 , - 0.50 ) , new Vector2D ( 0.87 , - 0.20 ) , new Vector2D ( 0.87 , - 0.02 ) , new Vector2D ( 0.91 , - 0.20 ) , new Vector2D ( 0.91 , - 0.08 ) , new Vector2D ( 0.93 , - 0.15 ) } ) ; checkVertices ( c . getVertices ( ) , new Vector2D [ ] [ ] { new Vector2D [ ] { new Vector2D ( 0.85 , - 0.15 ) , new Vector2D ( 0.90 , - 0.20 ) , new Vector2D ( 0.92 , - 0.18 ) , new Vector2D ( 0.92 , - 0.08 ) , new Vector2D ( 0.90 , - 0.10 ) , new Vector2D ( 0.90 , - 0.05 ) , new Vector2D ( 0.82 , - 0.05 ) , new Vector2D ( 0.82 , - 0.18 ) , } } ) ; } @ Test public void testBug20041003 ( ) { Line [ ] l = { new Line ( new Vector2D ( 0.0 , 0.625000007541172 ) , new Vector2D ( 1.0 , 0.625000007541172 ) , 1.0e-10 ) , new Line ( new Vector2D ( - 0.19204433621902645 , 0.0 ) , new Vector2D ( - 0.19204433621902645 , 1.0 ) , 1.0e-10 ) , new Line ( new Vector2D ( - 0.40303524786887 , 0.4248364535319128 ) , new Vector2D ( - 1.12851149797877 , - 0.2634107480798909 ) , 1.0e-10 ) , new Line ( new Vector2D ( 0.0 , 2.0 ) , new Vector2D ( 1.0 , 2.0 ) , 1.0e-10 ) } ; BSPTree < Euclidean2D > node1 = new BSPTree < Euclidean2D > ( new SubLine ( l [ 0 ] , new IntervalsSet ( intersectionAbscissa ( l [ 0 ] , l [ 1 ] ) , intersectionAbscissa ( l [ 0 ] , l [ 2 ] ) , 1.0e-10 ) ) , new BSPTree < Euclidean2D > ( Boolean . TRUE ) , new BSPTree < Euclidean2D > ( Boolean . FALSE ) , null ) ; BSPTree < Euclidean2D > node2 = new BSPTree < Euclidean2D > ( new SubLine ( l [ 1 ] , new IntervalsSet ( intersectionAbscissa ( l [ 1 ] , l [ 2 ] ) , intersectionAbscissa ( l [ 1 ] , l [ 3 ] ) , 1.0e-10 ) ) , node1 , new BSPTree < Euclidean2D > ( Boolean . FALSE ) , null ) ; BSPTree < Euclidean2D > node3 = new BSPTree < Euclidean2D > ( new SubLine ( l [ 2 ] , new IntervalsSet ( intersectionAbscissa ( l [ 2 ] , l [ 3 ] ) , Double . POSITIVE_INFINITY , 1.0e-10 ) ) , node2 , new BSPTree < Euclidean2D > ( Boolean . FALSE ) , null ) ; BSPTree < Euclidean2D > node4 = new BSPTree < Euclidean2D > ( l [ 3 ] . wholeHyperplane ( ) , node3 , new BSPTree < Euclidean2D > ( Boolean . FALSE ) , null ) ; PolygonsSet set = new PolygonsSet ( node4 , 1.0e-10 ) ; Assert . assertEquals ( 0 , set . getVertices ( ) . length ) ; } @ Test public void testSqueezedHexa ( ) { PolygonsSet set = new PolygonsSet ( 1.0e-10 , new Vector2D ( - 6 , - 4 ) , new Vector2D ( - 8 , - 8 ) , new Vector2D ( 8 , - 8 ) , new Vector2D ( 6 , - 4 ) , new Vector2D ( 10 , 4 ) , new Vector2D ( - 10 , 4 ) ) ; Assert . assertEquals ( Location . OUTSIDE , set . checkPoint ( new Vector2D ( 0 , 6 ) ) ) ; } @ Test public void testIssue880Simplified ( ) { Vector2D [ ] vertices1 = new Vector2D [ ] { new Vector2D ( 90.13595870833188 , 38.33604606376991 ) , new Vector2D ( 90.14047850603913 , 38.34600084496253 ) , new Vector2D ( 90.11045289492762 , 38.36801537312368 ) , new Vector2D ( 90.10871471476526 , 38.36878044144294 ) , new Vector2D ( 90.10424901707671 , 38.374300101757 ) , new Vector2D ( 90.0979455456843 , 38.373578376172475 ) , new Vector2D ( 90.09081227075944 , 38.37526295920463 ) , new Vector2D ( 90.09081378927135 , 38.375193883266434 ) } ; PolygonsSet set1 = new PolygonsSet ( 1.0e-10 , vertices1 ) ; Assert . assertEquals ( Location . OUTSIDE , set1 . checkPoint ( new Vector2D ( 90.12 , 38.32 ) ) ) ; Assert . assertEquals ( Location . OUTSIDE , set1 . checkPoint ( new Vector2D ( 90.135 , 38.355 ) ) ) ; } @ Test public void testIssue880Complete ( ) { Vector2D [ ] vertices1 = new Vector2D [ ] { new Vector2D ( 90.08714908223715 , 38.370299337260235 ) , new Vector2D ( 90.08709517675004 , 38.3702895991413 ) , new Vector2D ( 90.08401538704919 , 38.368849330127944 ) , new Vector2D ( 90.08258210430711 , 38.367634558585564 ) , new Vector2D ( 90.08251455106665 , 38.36763409247078 ) , new Vector2D ( 90.08106599752608 , 38.36761621664249 ) , new Vector2D ( 90.08249585300035 , 38.36753627557965 ) , new Vector2D ( 90.09075743352184 , 38.35914647644972 ) , new Vector2D ( 90.09099945896571 , 38.35896264724079 ) , new Vector2D ( 90.09269383800086 , 38.34595756121246 ) , new Vector2D ( 90.09638631543191 , 38.3457988093121 ) , new Vector2D ( 90.09666417351019 , 38.34523360999418 ) , new Vector2D ( 90.1297082145872 , 38.337670454923625 ) , new Vector2D ( 90.12971687748956 , 38.337669827794684 ) , new Vector2D ( 90.1240820219179 , 38.34328502001131 ) , new Vector2D ( 90.13084259656404 , 38.34017811765017 ) , new Vector2D ( 90.13378567942857 , 38.33860579180606 ) , new Vector2D ( 90.13519557833206 , 38.33621054663689 ) , new Vector2D ( 90.13545616732307 , 38.33614965452864 ) , new Vector2D ( 90.13553111202748 , 38.33613962818305 ) , new Vector2D ( 90.1356903436448 , 38.33610227127048 ) , new Vector2D ( 90.13576283227428 , 38.33609255422783 ) , new Vector2D ( 90.13595870833188 , 38.33604606376991 ) , new Vector2D ( 90.1361556630693 , 38.3360024198866 ) , new Vector2D ( 90.13622408795709 , 38.335987048115726 ) , new Vector2D ( 90.13696189099994 , 38.33581914328681 ) , new Vector2D ( 90.13746655304897 , 38.33616706665265 ) , new Vector2D ( 90.13845973716064 , 38.33650776167099 ) , new Vector2D ( 90.13950901827667 , 38.3368469456463 ) , new Vector2D ( 90.14393814424852 , 38.337591835857495 ) , new Vector2D ( 90.14483839716831 , 38.337076122362475 ) , new Vector2D ( 90.14565474433601 , 38.33769000964429 ) , new Vector2D ( 90.14569421179482 , 38.3377117256905 ) , new Vector2D ( 90.14577067124333 , 38.33770883625908 ) , new Vector2D ( 90.14600350631684 , 38.337714326520995 ) , new Vector2D ( 90.14600355139731 , 38.33771435193319 ) , new Vector2D ( 90.14600369112401 , 38.33771443882085 ) , new Vector2D ( 90.14600382486884 , 38.33771453466096 ) , new Vector2D ( 90.14600395205912 , 38.33771463904344 ) , new Vector2D ( 90.14600407214999 , 38.337714751520764 ) , new Vector2D ( 90.14600418462749 , 38.337714871611695 ) , new Vector2D ( 90.14600422249327 , 38.337714915811034 ) , new Vector2D ( 90.14867838361471 , 38.34113888210675 ) , new Vector2D ( 90.14923750157374 , 38.341582537502575 ) , new Vector2D ( 90.14877083250991 , 38.34160685841391 ) , new Vector2D ( 90.14816667319519 , 38.34244232585684 ) , new Vector2D ( 90.14797696744586 , 38.34248455284745 ) , new Vector2D ( 90.14484318014337 , 38.34385573215269 ) , new Vector2D ( 90.14477919958296 , 38.3453797747614 ) , new Vector2D ( 90.14202393306448 , 38.34464324839456 ) , new Vector2D ( 90.14198920640195 , 38.344651155237216 ) , new Vector2D ( 90.14155207025175 , 38.34486424263724 ) , new Vector2D ( 90.1415196143314 , 38.344871730519 ) , new Vector2D ( 90.14128611910814 , 38.34500196593859 ) , new Vector2D ( 90.14047850603913 , 38.34600084496253 ) , new Vector2D ( 90.14045907000337 , 38.34601860032171 ) , new Vector2D ( 90.14039496493928 , 38.346223030432384 ) , new Vector2D ( 90.14037626063737 , 38.346240203360026 ) , new Vector2D ( 90.14030005823724 , 38.34646920000705 ) , new Vector2D ( 90.13799164754806 , 38.34903093011013 ) , new Vector2D ( 90.11045289492762 , 38.36801537312368 ) , new Vector2D ( 90.10871471476526 , 38.36878044144294 ) , new Vector2D ( 90.10424901707671 , 38.374300101757 ) , new Vector2D ( 90.10263482039932 , 38.37310041316073 ) , new Vector2D ( 90.09834601753448 , 38.373615053823414 ) , new Vector2D ( 90.0979455456843 , 38.373578376172475 ) , new Vector2D ( 90.09086514328669 , 38.37527884194668 ) , new Vector2D ( 90.09084931407364 , 38.37590801712463 ) , new Vector2D ( 90.09081227075944 , 38.37526295920463 ) , new Vector2D ( 90.09081378927135 , 38.375193883266434 ) } ; PolygonsSet set1 = new PolygonsSet ( 1.0e-8 , vertices1 ) ; Assert . assertEquals ( Location . OUTSIDE , set1 . checkPoint ( new Vector2D ( 90.0905 , 38.3755 ) ) ) ; Assert . assertEquals ( Location . INSIDE , set1 . checkPoint ( new Vector2D ( 90.09084 , 38.3755 ) ) ) ; Assert . assertEquals ( Location . OUTSIDE , set1 . checkPoint ( new Vector2D ( 90.0913 , 38.3755 ) ) ) ; Assert . assertEquals ( Location . INSIDE , set1 . checkPoint ( new Vector2D ( 90.1042 , 38.3739 ) ) ) ; Assert . assertEquals ( Location . INSIDE , set1 . checkPoint ( new Vector2D ( 90.1111 , 38.3673 ) ) ) ; Assert . assertEquals ( Location . OUTSIDE , set1 . checkPoint ( new Vector2D ( 90.0959 , 38.3457 ) ) ) ; Vector2D [ ] vertices2 = new Vector2D [ ] { new Vector2D ( 90.13067558880044 , 38.36977255037573 ) , new Vector2D ( 90.12907570488 , 38.36817308242706 ) , new Vector2D ( 90.1342774136516 , 38.356886880294724 ) , new Vector2D ( 90.13090330629757 , 38.34664392676211 ) , new Vector2D ( 90.13078571364593 , 38.344904617518466 ) , new Vector2D ( 90.1315602208914 , 38.3447185040846 ) , new Vector2D ( 90.1316336226821 , 38.34470643148342 ) , new Vector2D ( 90.134020944832 , 38.340936644972885 ) , new Vector2D ( 90.13912536387306 , 38.335497255122334 ) , new Vector2D ( 90.1396178806582 , 38.334878075552126 ) , new Vector2D ( 90.14083049696671 , 38.33316530644106 ) , new Vector2D ( 90.14145252901329 , 38.33152722916191 ) , new Vector2D ( 90.1404779335565 , 38.32863516047786 ) , new Vector2D ( 90.14282712131586 , 38.327504432532066 ) , new Vector2D ( 90.14616669875488 , 38.3237354115015 ) , new Vector2D ( 90.14860976050608 , 38.315714862457924 ) , new Vector2D ( 90.14999277782437 , 38.3164932507504 ) , new Vector2D ( 90.15005207194997 , 38.316534677663356 ) , new Vector2D ( 90.15508513859612 , 38.31878731691609 ) , new Vector2D ( 90.15919938519221 , 38.31852743183782 ) , new Vector2D ( 90.16093758658837 , 38.31880662005153 ) , new Vector2D ( 90.16099420184912 , 38.318825953291594 ) , new Vector2D ( 90.1665411125756 , 38.31859497874757 ) , new Vector2D ( 90.16999653861313 , 38.32505772048029 ) , new Vector2D ( 90.17475243391698 , 38.32594398441148 ) , new Vector2D ( 90.17940844844992 , 38.327427213761325 ) , new Vector2D ( 90.20951909541378 , 38.330616833491774 ) , new Vector2D ( 90.2155400467941 , 38.331746223670336 ) , new Vector2D ( 90.21559881391778 , 38.33175551425302 ) , new Vector2D ( 90.21916646426041 , 38.332584299620805 ) , new Vector2D ( 90.23863749852285 , 38.34778978875795 ) , new Vector2D ( 90.25459855175802 , 38.357790570608984 ) , new Vector2D ( 90.25964298227257 , 38.356918010203174 ) , new Vector2D ( 90.26024593994703 , 38.361692743151366 ) , new Vector2D ( 90.26146187570015 , 38.36311080550837 ) , new Vector2D ( 90.26614159359622 , 38.36510808579902 ) , new Vector2D ( 90.26621342936448 , 38.36507942500333 ) , new Vector2D ( 90.26652190211962 , 38.36494042196722 ) , new Vector2D ( 90.26621240678867 , 38.365113172030874 ) , new Vector2D ( 90.26614057102057 , 38.365141832826794 ) , new Vector2D ( 90.26380080055299 , 38.3660381760273 ) , new Vector2D ( 90.26315345241 , 38.36670658276421 ) , new Vector2D ( 90.26251574942881 , 38.367490323488084 ) , new Vector2D ( 90.26247873448426 , 38.36755266444749 ) , new Vector2D ( 90.26234628016698 , 38.36787989125406 ) , new Vector2D ( 90.26214559424784 , 38.36945909356126 ) , new Vector2D ( 90.25861728442555 , 38.37200753430875 ) , new Vector2D ( 90.23905557537864 , 38.375405314295904 ) , new Vector2D ( 90.22517251874075 , 38.38984691662256 ) , new Vector2D ( 90.22549955153215 , 38.3911564273979 ) , new Vector2D ( 90.22434386063355 , 38.391476432092134 ) , new Vector2D ( 90.22147729457276 , 38.39134652252034 ) , new Vector2D ( 90.22142070120117 , 38.391349167741964 ) , new Vector2D ( 90.20665060751588 , 38.39475580900313 ) , new Vector2D ( 90.20042268367109 , 38.39842558622888 ) , new Vector2D ( 90.17423771242085 , 38.402727751805344 ) , new Vector2D ( 90.16756796257476 , 38.40913898597597 ) , new Vector2D ( 90.16728283954308 , 38.411255399912875 ) , new Vector2D ( 90.16703538220418 , 38.41136059866693 ) , new Vector2D ( 90.16725865657685 , 38.41013618805954 ) , new Vector2D ( 90.16746107640665 , 38.40902614307544 ) , new Vector2D ( 90.16122795307462 , 38.39773101873203 ) } ; PolygonsSet set2 = new PolygonsSet ( 1.0e-8 , vertices2 ) ; PolygonsSet set = ( PolygonsSet ) new RegionFactory < Euclidean2D > ( ) . difference ( set1 . copySelf ( ) , set2 . copySelf ( ) ) ; Vector2D [ ] [ ] verticies = set . getVertices ( ) ; Assert . assertTrue ( verticies [ 0 ] [ 0 ] != null ) ; Assert . assertEquals ( 1 , verticies . length ) ; } @ Test public void testTooThinBox ( ) { Assert . assertEquals ( 0.0 , new PolygonsSet ( 0.0 , 0.0 , 0.0 , 10.3206397147574 , 1.0e-10 ) . getSize ( ) , 1.0e-10 ) ; } @ Test public void testWrongUsage ( ) { PolygonsSet ps = new PolygonsSet ( new BSPTree < Euclidean2D > ( ) , 1.0e-10 ) ; Assert . assertNotNull ( ps ) ; try { ps . getSize ( ) ; Assert . fail ( ""an exception should have been thrown"" ) ; } catch ( NullPointerException npe ) { } } private PolygonsSet buildSet ( Vector2D [ ] [ ] vertices ) { ArrayList < SubHyperplane < Euclidean2D > > edges = new ArrayList < SubHyperplane < Euclidean2D > > ( ) ; for ( int i = 0 ; i < vertices . length ; ++ i ) { int l = vertices [ i ] . length ; for ( int j = 0 ; j < l ; ++ j ) { edges . add ( buildSegment ( vertices [ i ] [ j ] , vertices [ i ] [ ( j + 1 ) % l ] ) ) ; } } return new PolygonsSet ( edges , 1.0e-10 ) ; } private SubHyperplane < Euclidean2D > buildLine ( Vector2D start , Vector2D end ) { return new Line ( start , end , 1.0e-10 ) . wholeHyperplane ( ) ; } private double intersectionAbscissa ( Line l0 , Line l1 ) { Vector2D p = l0 . intersection ( l1 ) ; return ( l0 . toSubSpace ( p ) ) . getX ( ) ; } private SubHyperplane < Euclidean2D > buildHalfLine ( Vector2D start , Vector2D end , boolean startIsVirtual ) { Line line = new Line ( start , end , 1.0e-10 ) ; double lower = startIsVirtual ? Double . NEGATIVE_INFINITY : ( line . toSubSpace ( start ) ) . getX ( ) ; double upper = startIsVirtual ? ( line . toSubSpace ( end ) ) . getX ( ) : Double . POSITIVE_INFINITY ; return new SubLine ( line , new IntervalsSet ( lower , upper , 1.0e-10 ) ) ; } private SubHyperplane < Euclidean2D > buildSegment ( Vector2D start , Vector2D end ) { Line line = new Line ( start , end , 1.0e-10 ) ; double lower = ( line . toSubSpace ( start ) ) . getX ( ) ; double upper = ( line . toSubSpace ( end ) ) . getX ( ) ; return new SubLine ( line , new IntervalsSet ( lower , upper , 1.0e-10 ) ) ; } private void checkPoints ( Region . Location expected , PolygonsSet set , Vector2D [ ] points ) { for ( int i = 0 ; i < points . length ; ++ i ) { Assert . assertEquals ( expected , set . checkPoint ( points [ i ] ) ) ; } } private boolean checkInSegment ( Vector2D p , Vector2D p1 , Vector2D p2 , double tolerance ) { Line line = new Line ( p1 , p2 , 1.0e-10 ) ; if ( line . getOffset ( p ) < tolerance ) { double x = ( line . toSubSpace ( p ) ) . getX ( ) ; double x1 = ( line . toSubSpace ( p1 ) ) . getX ( ) ; double x2 = ( line . toSubSpace ( p2 ) ) . getX ( ) ; return ( ( ( x - x1 ) * ( x - x2 ) <= 0.0 ) || ( p1 . distance ( p ) < tolerance ) || ( p2 . distance ( p ) < tolerance ) ) ; } else { return false ; } } private void checkVertices ( Vector2D [ ] [ ] rebuiltVertices , Vector2D [ ] [ ] vertices ) { for ( int i = 0 ; i < rebuiltVertices . length ; ++ i ) { for ( int j = 0 ; j < rebuiltVertices [ i ] . length ; ++ j ) { boolean inSegment = false ; Vector2D p = rebuiltVertices [ i ] [ j ] ; for ( int k = 0 ; k < vertices . length ; ++ k ) { Vector2D [ ] loop = vertices [ k ] ; int length = loop . length ; for ( int l = 0 ; ( ! inSegment ) && ( l < length ) ; ++ l ) { inSegment = checkInSegment ( p , loop [ l ] , loop [ ( l + 1 ) % length ] , 1.0e-10 ) ; } } Assert . assertTrue ( inSegment ) ; } } for ( int k = 0 ; k < vertices . length ; ++ k ) { for ( int l = 0 ; l < vertices [ k ] . length ; ++ l ) { double min = Double . POSITIVE_INFINITY ; for ( int i = 0 ; i < rebuiltVertices . length ; ++ i ) { for ( int j = 0 ; j < rebuiltVertices [ i ] . length ; ++ j ) { min = FastMath . min ( vertices [ k ] [ l ] . distance ( rebuiltVertices [ i ] [ j ] ) , min ) ; } } Assert . assertEquals ( 0.0 , min , 1.0e-10 ) ; } } } }",Smelly
"public class BratDocumentStream implements ObjectStream < BratDocument > { private AnnotationConfiguration config ; private List < String > documentIds = new LinkedList < > ( ) ; private Iterator < String > documentIdIterator ; public BratDocumentStream ( AnnotationConfiguration config , File bratCorpusDirectory , boolean searchRecursive , FileFilter fileFilter ) throws IOException { if ( ! bratCorpusDirectory . isDirectory ( ) ) { throw new IOException ( ""Input corpus directory must be a directory "" + ""according to File.isDirectory()!"" ) ; } this . config = config ; Stack < File > directoryStack = new Stack < > ( ) ; directoryStack . add ( bratCorpusDirectory ) ; while ( ! directoryStack . isEmpty ( ) ) { for ( File file : directoryStack . pop ( ) . listFiles ( fileFilter ) ) { if ( file . isFile ( ) ) { String annFilePath = file . getAbsolutePath ( ) ; if ( annFilePath . endsWith ( "".ann"" ) ) { String documentId = annFilePath . substring ( 0 , annFilePath . length ( ) - 4 ) ; File txtFile = new File ( documentId + "".txt"" ) ; if ( txtFile . exists ( ) && txtFile . isFile ( ) ) { documentIds . add ( documentId ) ; } } } else if ( searchRecursive && file . isDirectory ( ) ) { directoryStack . push ( file ) ; } } } reset ( ) ; } public BratDocument read ( ) throws IOException { BratDocument doc = null ; if ( documentIdIterator . hasNext ( ) ) { String id = documentIdIterator . next ( ) ; try ( InputStream txtIn = new BufferedInputStream ( new FileInputStream ( id + "".txt"" ) ) ; InputStream annIn = new BufferedInputStream ( new FileInputStream ( id + "".ann"" ) ) ) { doc = BratDocument . parseDocument ( config , id , txtIn , annIn ) ; } } return doc ; } public void reset ( ) { documentIdIterator = documentIds . iterator ( ) ; } public void close ( ) { documentIds = null ; documentIdIterator = null ; } }",No
"public class QueryableRecorder < T > implements QueryableFactory < T > { private static final QueryableRecorder INSTANCE = new QueryableRecorder ( ) ; @ SuppressWarnings ( ""unchecked"" ) public static < T > QueryableRecorder < T > instance ( ) { return INSTANCE ; } public T aggregate ( final Queryable < T > source , final FunctionExpression < Function2 < T , T , T > > func ) { return new QueryableDefaults . NonLeafReplayableQueryable < T > ( source ) { public void replay ( QueryableFactory < T > factory ) { factory . aggregate ( source , func ) ; } } . single ( ) ; } public < TAccumulate > TAccumulate aggregate ( final Queryable < T > source , final TAccumulate seed , final FunctionExpression < Function2 < TAccumulate , T , TAccumulate > > func ) { return new NonLeafReplayableQueryable < T > ( source ) { public void replay ( QueryableFactory < T > factory ) { factory . aggregate ( source , seed , func ) ; } } . castSingle ( ) ; } public < TAccumulate , TResult > TResult aggregate ( final Queryable < T > source , final TAccumulate seed , final FunctionExpression < Function2 < TAccumulate , T , TAccumulate > > func , final FunctionExpression < Function1 < TAccumulate , TResult > > selector ) { return new NonLeafReplayableQueryable < T > ( source ) { public void replay ( QueryableFactory < T > factory ) { factory . aggregate ( source , seed , func , selector ) ; } } . castSingle ( ) ; } public boolean all ( final Queryable < T > source , final FunctionExpression < Predicate1 < T > > predicate ) { return new NonLeafReplayableQueryable < T > ( source ) { public void replay ( QueryableFactory < T > factory ) { factory . all ( source , predicate ) ; } } . < Boolean > castSingle ( ) ; } public boolean any ( final Queryable < T > source ) { return new NonLeafReplayableQueryable < T > ( source ) { public void replay ( QueryableFactory < T > factory ) { factory . any ( source ) ; } } . < Boolean > castSingle ( ) ; } public boolean any ( final Queryable < T > source , final FunctionExpression < Predicate1 < T > > predicate ) { return new NonLeafReplayableQueryable < T > ( source ) { public void replay ( QueryableFactory < T > factory ) { factory . any ( source , predicate ) ; } } . < Boolean > castSingle ( ) ; } public BigDecimal averageBigDecimal ( final Queryable < T > source , final FunctionExpression < BigDecimalFunction1 < T > > selector ) { return new NonLeafReplayableQueryable < T > ( source ) { public void replay ( QueryableFactory < T > factory ) { factory . averageBigDecimal ( source , selector ) ; } } . castSingle ( ) ; } public BigDecimal averageNullableBigDecimal ( final Queryable < T > source , final FunctionExpression < NullableBigDecimalFunction1 < T > > selector ) { return new NonLeafReplayableQueryable < T > ( source ) { public void replay ( QueryableFactory < T > factory ) { factory . averageNullableBigDecimal ( source , selector ) ; } } . castSingle ( ) ; } public double averageDouble ( final Queryable < T > source , final FunctionExpression < DoubleFunction1 < T > > selector ) { return new NonLeafReplayableQueryable < T > ( source ) { public void replay ( QueryableFactory < T > factory ) { factory . averageDouble ( source , selector ) ; } } . < Double > castSingle ( ) ; } public Double averageNullableDouble ( final Queryable < T > source , final FunctionExpression < NullableDoubleFunction1 < T > > selector ) { return new NonLeafReplayableQueryable < T > ( source ) { public void replay ( QueryableFactory < T > factory ) { factory . averageNullableDouble ( source , selector ) ; } } . < Double > castSingle ( ) ; } public int averageInteger ( final Queryable < T > source , final FunctionExpression < IntegerFunction1 < T > > selector ) { return new NonLeafReplayableQueryable < T > ( source ) { public void replay ( QueryableFactory < T > factory ) { factory . averageInteger ( source , selector ) ; } } . < Integer > castSingle ( ) ; } public Integer averageNullableInteger ( final Queryable < T > source , final FunctionExpression < NullableIntegerFunction1 < T > > selector ) { return new NonLeafReplayableQueryable < T > ( source ) { public void replay ( QueryableFactory < T > factory ) { factory . averageNullableInteger ( source , selector ) ; } } . < Integer > castSingle ( ) ; } public float averageFloat ( final Queryable < T > source , final FunctionExpression < FloatFunction1 < T > > selector ) { return new NonLeafReplayableQueryable < T > ( source ) { public void replay ( QueryableFactory < T > factory ) { factory . averageFloat ( source , selector ) ; } } . < Float > castSingle ( ) ; } public Float averageNullableFloat ( final Queryable < T > source , final FunctionExpression < NullableFloatFunction1 < T > > selector ) { return new NonLeafReplayableQueryable < T > ( source ) { public void replay ( QueryableFactory < T > factory ) { factory . averageNullableFloat ( source , selector ) ; } } . < Float > castSingle ( ) ; } public long averageLong ( final Queryable < T > source , final FunctionExpression < LongFunction1 < T > > selector ) { return new NonLeafReplayableQueryable < T > ( source ) { public void replay ( QueryableFactory < T > factory ) { factory . averageLong ( source , selector ) ; } } . < Long > castSingle ( ) ; } public Long averageNullableLong ( final Queryable < T > source , final FunctionExpression < NullableLongFunction1 < T > > selector ) { return new NonLeafReplayableQueryable < T > ( source ) { public void replay ( QueryableFactory < T > factory ) { factory . averageNullableLong ( source , selector ) ; } } . < Long > castSingle ( ) ; } public < T2 > Queryable < T2 > cast ( final Queryable < T > source , final Class < T2 > clazz ) { return new NonLeafReplayableQueryable < T > ( source ) { public void replay ( QueryableFactory < T > factory ) { factory . cast ( source , clazz ) ; } } . castQueryable ( ) ; } public Queryable < T > concat ( final Queryable < T > source , final Enumerable < T > source2 ) { return new NonLeafReplayableQueryable < T > ( source ) { public void replay ( QueryableFactory < T > factory ) { factory . concat ( source , source2 ) ; } } ; } public boolean contains ( final Queryable < T > source , final T element ) { return new NonLeafReplayableQueryable < T > ( source ) { public void replay ( QueryableFactory < T > factory ) { factory . contains ( source , element ) ; } } . < Boolean > castSingle ( ) ; } public boolean contains ( final Queryable < T > source , final T element , final EqualityComparer < T > comparer ) { return new NonLeafReplayableQueryable < T > ( source ) { public void replay ( QueryableFactory < T > factory ) { factory . contains ( source , element , comparer ) ; } } . < Boolean > castSingle ( ) ; } public int count ( final Queryable < T > source ) { return new NonLeafReplayableQueryable < T > ( source ) { public void replay ( QueryableFactory < T > factory ) { factory . count ( source ) ; } } . < Integer > castSingle ( ) ; } public int count ( final Queryable < T > source , final FunctionExpression < Predicate1 < T > > func ) { return new NonLeafReplayableQueryable < T > ( source ) { public void replay ( QueryableFactory < T > factory ) { factory . count ( source , func ) ; } } . < Integer > castSingle ( ) ; } public Queryable < T > defaultIfEmpty ( final Queryable < T > source ) { return new NonLeafReplayableQueryable < T > ( source ) { public void replay ( QueryableFactory < T > factory ) { factory . defaultIfEmpty ( source ) ; } } ; } public Queryable < T > defaultIfEmpty ( final Queryable < T > source , final T value ) { return new NonLeafReplayableQueryable < T > ( source ) { public void replay ( QueryableFactory < T > factory ) { factory . defaultIfEmpty ( source , value ) ; } } ; } public Queryable < T > distinct ( final Queryable < T > source ) { return new NonLeafReplayableQueryable < T > ( source ) { public void replay ( QueryableFactory < T > factory ) { factory . distinct ( source ) ; } } ; } public Queryable < T > distinct ( final Queryable < T > source , final EqualityComparer < T > comparer ) { return new NonLeafReplayableQueryable < T > ( source ) { public void replay ( QueryableFactory < T > factory ) { factory . distinct ( source , comparer ) ; } } ; } public T elementAt ( final Queryable < T > source , final int index ) { return new NonLeafReplayableQueryable < T > ( source ) { public void replay ( QueryableFactory < T > factory ) { factory . elementAt ( source , index ) ; } } . castSingle ( ) ; } public T elementAtOrDefault ( final Queryable < T > source , final int index ) { return new NonLeafReplayableQueryable < T > ( source ) { public void replay ( QueryableFactory < T > factory ) { factory . elementAtOrDefault ( source , index ) ; } } . castSingle ( ) ; } public Queryable < T > except ( final Queryable < T > source , final Enumerable < T > enumerable ) { return new NonLeafReplayableQueryable < T > ( source ) { public void replay ( QueryableFactory < T > factory ) { factory . except ( source , enumerable ) ; } } ; } public Queryable < T > except ( final Queryable < T > source , final Enumerable < T > enumerable , final EqualityComparer < T > comparer ) { return new NonLeafReplayableQueryable < T > ( source ) { public void replay ( QueryableFactory < T > factory ) { factory . except ( source , enumerable , comparer ) ; } } ; } public T first ( final Queryable < T > source ) { return new NonLeafReplayableQueryable < T > ( source ) { public void replay ( QueryableFactory < T > factory ) { factory . first ( source ) ; } } . single ( ) ; } public T first ( final Queryable < T > source , final FunctionExpression < Predicate1 < T > > predicate ) { return new NonLeafReplayableQueryable < T > ( source ) { public void replay ( QueryableFactory < T > factory ) { factory . first ( source , predicate ) ; } } . single ( ) ; } public T firstOrDefault ( final Queryable < T > source ) { return new NonLeafReplayableQueryable < T > ( source ) { public void replay ( QueryableFactory < T > factory ) { factory . firstOrDefault ( source ) ; } } . single ( ) ; } public T firstOrDefault ( final Queryable < T > source , final FunctionExpression < Predicate1 < T > > predicate ) { return new NonLeafReplayableQueryable < T > ( source ) { public void replay ( QueryableFactory < T > factory ) { factory . firstOrDefault ( source , predicate ) ; } } . single ( ) ; } public < TKey > Queryable < Grouping < TKey , T > > groupBy ( final Queryable < T > source , final FunctionExpression < Function1 < T , TKey > > keySelector ) { return new NonLeafReplayableQueryable < T > ( source ) { public void replay ( QueryableFactory < T > factory ) { factory . groupBy ( source , keySelector ) ; } } . castQueryable ( ) ; } public < TKey > Queryable < Grouping < TKey , T > > groupBy ( final Queryable < T > source , final FunctionExpression < Function1 < T , TKey > > keySelector , final EqualityComparer < TKey > comparer ) { return new NonLeafReplayableQueryable < T > ( source ) { public void replay ( QueryableFactory < T > factory ) { factory . groupBy ( source , keySelector , comparer ) ; } } . castQueryable ( ) ; } public < TKey , TElement > Queryable < Grouping < TKey , TElement > > groupBy ( final Queryable < T > source , final FunctionExpression < Function1 < T , TKey > > keySelector , final FunctionExpression < Function1 < T , TElement > > elementSelector ) { return new NonLeafReplayableQueryable < T > ( source ) { public void replay ( QueryableFactory < T > factory ) { factory . groupBy ( source , keySelector , elementSelector ) ; } } . castQueryable ( ) ; } public < TKey , TElement > Queryable < Grouping < TKey , TElement > > groupBy ( final Queryable < T > source , final FunctionExpression < Function1 < T , TKey > > keySelector , final FunctionExpression < Function1 < T , TElement > > elementSelector , final EqualityComparer < TKey > comparer ) { return new NonLeafReplayableQueryable < T > ( source ) { public void replay ( QueryableFactory < T > factory ) { factory . groupBy ( source , keySelector , elementSelector , comparer ) ; } } . castQueryable ( ) ; } public < TKey , TResult > Queryable < TResult > groupByK ( final Queryable < T > source , final FunctionExpression < Function1 < T , TKey > > keySelector , final FunctionExpression < Function2 < TKey , Enumerable < T > , TResult > > resultSelector ) { return new NonLeafReplayableQueryable < T > ( source ) { public void replay ( QueryableFactory < T > factory ) { factory . groupByK ( source , keySelector , resultSelector ) ; } } . castQueryable ( ) ; } public < TKey , TResult > Queryable < TResult > groupByK ( final Queryable < T > source , final FunctionExpression < Function1 < T , TKey > > keySelector , final FunctionExpression < Function2 < TKey , Enumerable < T > , TResult > > resultSelector , final EqualityComparer < TKey > comparer ) { return new NonLeafReplayableQueryable < T > ( source ) { public void replay ( QueryableFactory < T > factory ) { factory . groupByK ( source , keySelector , resultSelector , comparer ) ; } } . castQueryable ( ) ; } public < TKey , TElement , TResult > Queryable < TResult > groupBy ( final Queryable < T > source , final FunctionExpression < Function1 < T , TKey > > keySelector , final FunctionExpression < Function1 < T , TElement > > elementSelector , final FunctionExpression < Function2 < TKey , Enumerable < TElement > , TResult > > resultSelector ) { return new NonLeafReplayableQueryable < T > ( source ) { public void replay ( QueryableFactory < T > factory ) { factory . groupBy ( source , keySelector , elementSelector , resultSelector ) ; } } . castQueryable ( ) ; } public < TKey , TElement , TResult > Queryable < TResult > groupBy ( final Queryable < T > source , final FunctionExpression < Function1 < T , TKey > > keySelector , final FunctionExpression < Function1 < T , TElement > > elementSelector , final FunctionExpression < Function2 < TKey , Enumerable < TElement > , TResult > > resultSelector , final EqualityComparer < TKey > comparer ) { return new NonLeafReplayableQueryable < T > ( source ) { public void replay ( QueryableFactory < T > factory ) { factory . groupBy ( source , keySelector , elementSelector , resultSelector , comparer ) ; } } . castQueryable ( ) ; } public < TInner , TKey , TResult > Queryable < TResult > groupJoin ( final Queryable < T > source , final Enumerable < TInner > inner , final FunctionExpression < Function1 < T , TKey > > outerKeySelector , final FunctionExpression < Function1 < TInner , TKey > > innerKeySelector , final FunctionExpression < Function2 < T , Enumerable < TInner > , TResult > > resultSelector ) { return new NonLeafReplayableQueryable < T > ( source ) { public void replay ( QueryableFactory < T > factory ) { factory . groupJoin ( source , inner , outerKeySelector , innerKeySelector , resultSelector ) ; } } . castQueryable ( ) ; } public < TInner , TKey , TResult > Queryable < TResult > groupJoin ( final Queryable < T > source , final Enumerable < TInner > inner , final FunctionExpression < Function1 < T , TKey > > outerKeySelector , final FunctionExpression < Function1 < TInner , TKey > > innerKeySelector , final FunctionExpression < Function2 < T , Enumerable < TInner > , TResult > > resultSelector , final EqualityComparer < TKey > comparer ) { return new NonLeafReplayableQueryable < T > ( source ) { public void replay ( QueryableFactory < T > factory ) { factory . groupJoin ( source , inner , outerKeySelector , innerKeySelector , resultSelector , comparer ) ; } } . castQueryable ( ) ; } public Queryable < T > intersect ( final Queryable < T > source , final Enumerable < T > enumerable ) { return new NonLeafReplayableQueryable < T > ( source ) { public void replay ( QueryableFactory < T > factory ) { factory . intersect ( source , enumerable ) ; } } ; } public Queryable < T > intersect ( final Queryable < T > source , final Enumerable < T > enumerable , final EqualityComparer < T > comparer ) { return new NonLeafReplayableQueryable < T > ( source ) { public void replay ( QueryableFactory < T > factory ) { factory . intersect ( source , enumerable , comparer ) ; } } ; } public < TInner , TKey , TResult > Queryable < TResult > join ( final Queryable < T > source , final Enumerable < TInner > inner , final FunctionExpression < Function1 < T , TKey > > outerKeySelector , final FunctionExpression < Function1 < TInner , TKey > > innerKeySelector , final FunctionExpression < Function2 < T , TInner , TResult > > resultSelector ) { return new NonLeafReplayableQueryable < T > ( source ) { public void replay ( QueryableFactory < T > factory ) { factory . join ( source , inner , outerKeySelector , innerKeySelector , resultSelector ) ; } } . castQueryable ( ) ; } public < TInner , TKey , TResult > Queryable < TResult > join ( final Queryable < T > source , final Enumerable < TInner > inner , final FunctionExpression < Function1 < T , TKey > > outerKeySelector , final FunctionExpression < Function1 < TInner , TKey > > innerKeySelector , final FunctionExpression < Function2 < T , TInner , TResult > > resultSelector , final EqualityComparer < TKey > comparer ) { return new NonLeafReplayableQueryable < T > ( source ) { public void replay ( QueryableFactory < T > factory ) { factory . join ( source , inner , outerKeySelector , innerKeySelector , resultSelector , comparer ) ; } } . castQueryable ( ) ; } public T last ( final Queryable < T > source ) { return new NonLeafReplayableQueryable < T > ( source ) { public void replay ( QueryableFactory < T > factory ) { factory . last ( source ) ; } } . single ( ) ; } public T last ( final Queryable < T > source , final FunctionExpression < Predicate1 < T > > predicate ) { return new NonLeafReplayableQueryable < T > ( source ) { public void replay ( QueryableFactory < T > factory ) { factory . last ( source , predicate ) ; } } . single ( ) ; } public T lastOrDefault ( final Queryable < T > source ) { return new NonLeafReplayableQueryable < T > ( source ) { public void replay ( QueryableFactory < T > factory ) { factory . lastOrDefault ( source ) ; } } . single ( ) ; } public T lastOrDefault ( final Queryable < T > source , final FunctionExpression < Predicate1 < T > > predicate ) { return new NonLeafReplayableQueryable < T > ( source ) { public void replay ( QueryableFactory < T > factory ) { factory . lastOrDefault ( source , predicate ) ; } } . single ( ) ; } public long longCount ( final Queryable < T > source ) { return new NonLeafReplayableQueryable < T > ( source ) { public void replay ( QueryableFactory < T > factory ) { factory . longCount ( source ) ; } } . < Long > castSingle ( ) ; } public long longCount ( final Queryable < T > source , final FunctionExpression < Predicate1 < T > > predicate ) { return new NonLeafReplayableQueryable < T > ( source ) { public void replay ( QueryableFactory < T > factory ) { factory . longCount ( source , predicate ) ; } } . longCount ( ) ; } public T max ( final Queryable < T > source ) { return new NonLeafReplayableQueryable < T > ( source ) { public void replay ( QueryableFactory < T > factory ) { factory . max ( source ) ; } } . castSingle ( ) ; } public < TResult extends Comparable < TResult > > TResult max ( final Queryable < T > source , final FunctionExpression < Function1 < T , TResult > > selector ) { return new NonLeafReplayableQueryable < T > ( source ) { public void replay ( QueryableFactory < T > factory ) { factory . max ( source , selector ) ; } } . castSingle ( ) ; } public T min ( final Queryable < T > source ) { return new NonLeafReplayableQueryable < T > ( source ) { public void replay ( QueryableFactory < T > factory ) { factory . min ( source ) ; } } . castSingle ( ) ; } public < TResult extends Comparable < TResult > > TResult min ( final Queryable < T > source , final FunctionExpression < Function1 < T , TResult > > selector ) { return new NonLeafReplayableQueryable < T > ( source ) { public void replay ( QueryableFactory < T > factory ) { factory . min ( source , selector ) ; } } . castSingle ( ) ; } public < TResult > Queryable < TResult > ofType ( final Queryable < T > source , final Class < TResult > clazz ) { return new NonLeafReplayableQueryable < T > ( source ) { public void replay ( QueryableFactory < T > factory ) { factory . ofType ( source , clazz ) ; } } . castQueryable ( ) ; } public < TKey extends Comparable > OrderedQueryable < T > orderBy ( final Queryable < T > source , final FunctionExpression < Function1 < T , TKey > > keySelector ) { return new NonLeafReplayableQueryable < T > ( source ) { public void replay ( QueryableFactory < T > factory ) { factory . orderBy ( source , keySelector ) ; } } ; } public < TKey > OrderedQueryable < T > orderBy ( final Queryable < T > source , final FunctionExpression < Function1 < T , TKey > > keySelector , final Comparator < TKey > comparator ) { return new NonLeafReplayableQueryable < T > ( source ) { public void replay ( QueryableFactory < T > factory ) { factory . orderBy ( source , keySelector , comparator ) ; } } ; } public < TKey extends Comparable > OrderedQueryable < T > orderByDescending ( final Queryable < T > source , final FunctionExpression < Function1 < T , TKey > > keySelector ) { return new NonLeafReplayableQueryable < T > ( source ) { public void replay ( QueryableFactory < T > factory ) { factory . orderByDescending ( source , keySelector ) ; } } ; } public < TKey > OrderedQueryable < T > orderByDescending ( final Queryable < T > source , final FunctionExpression < Function1 < T , TKey > > keySelector , final Comparator < TKey > comparator ) { return new NonLeafReplayableQueryable < T > ( source ) { public void replay ( QueryableFactory < T > factory ) { factory . orderByDescending ( source , keySelector , comparator ) ; } } ; } public Queryable < T > reverse ( final Queryable < T > source ) { return new NonLeafReplayableQueryable < T > ( source ) { public void replay ( QueryableFactory < T > factory ) { factory . reverse ( source ) ; } } ; } public < TResult > Queryable < TResult > select ( final Queryable < T > source , final FunctionExpression < Function1 < T , TResult > > selector ) { return new NonLeafReplayableQueryable < T > ( source ) { public void replay ( QueryableFactory < T > factory ) { factory . select ( source , selector ) ; } @ Override public Type getElementType ( ) { return selector . body . type ; } } . castQueryable ( ) ; } public < TResult > Queryable < TResult > selectN ( final Queryable < T > source , final FunctionExpression < Function2 < T , Integer , TResult > > selector ) { return new NonLeafReplayableQueryable < T > ( source ) { public void replay ( QueryableFactory < T > factory ) { factory . selectN ( source , selector ) ; } } . castQueryable ( ) ; } public < TResult > Queryable < TResult > selectMany ( final Queryable < T > source , final FunctionExpression < Function1 < T , Enumerable < TResult > > > selector ) { return new NonLeafReplayableQueryable < T > ( source ) { public void replay ( QueryableFactory < T > factory ) { factory . selectMany ( source , selector ) ; } } . castQueryable ( ) ; } public < TResult > Queryable < TResult > selectManyN ( final Queryable < T > source , final FunctionExpression < Function2 < T , Integer , Enumerable < TResult > > > selector ) { return new NonLeafReplayableQueryable < T > ( source ) { public void replay ( QueryableFactory < T > factory ) { factory . selectManyN ( source , selector ) ; } } . castQueryable ( ) ; } public < TCollection , TResult > Queryable < TResult > selectMany ( final Queryable < T > source , final FunctionExpression < Function2 < T , Integer , Enumerable < TCollection > > > collectionSelector , final FunctionExpression < Function2 < T , TCollection , TResult > > resultSelector ) { return new NonLeafReplayableQueryable < T > ( source ) { public void replay ( QueryableFactory < T > factory ) { factory . selectMany ( source , collectionSelector , resultSelector ) ; } } . castQueryable ( ) ; } public < TCollection , TResult > Queryable < TResult > selectManyN ( final Queryable < T > source , final FunctionExpression < Function1 < T , Enumerable < TCollection > > > collectionSelector , final FunctionExpression < Function2 < T , TCollection , TResult > > resultSelector ) { return new NonLeafReplayableQueryable < T > ( source ) { public void replay ( QueryableFactory < T > factory ) { factory . selectManyN ( source , collectionSelector , resultSelector ) ; } } . castQueryable ( ) ; } public boolean sequenceEqual ( final Queryable < T > source , final Enumerable < T > enumerable ) { return new NonLeafReplayableQueryable < T > ( source ) { public void replay ( QueryableFactory < T > factory ) { factory . sequenceEqual ( source , enumerable ) ; } } . < Boolean > castSingle ( ) ; } public boolean sequenceEqual ( final Queryable < T > source , final Enumerable < T > enumerable , final EqualityComparer < T > comparer ) { return new NonLeafReplayableQueryable < T > ( source ) { public void replay ( QueryableFactory < T > factory ) { factory . sequenceEqual ( source , enumerable , comparer ) ; } } . < Boolean > castSingle ( ) ; } public T single ( final Queryable < T > source ) { return new NonLeafReplayableQueryable < T > ( source ) { public void replay ( QueryableFactory < T > factory ) { factory . single ( source ) ; } } . single ( ) ; } public T single ( final Queryable < T > source , final FunctionExpression < Predicate1 < T > > predicate ) { return new NonLeafReplayableQueryable < T > ( source ) { public void replay ( QueryableFactory < T > factory ) { factory . single ( source , predicate ) ; } } . single ( ) ; } public T singleOrDefault ( final Queryable < T > source ) { return new NonLeafReplayableQueryable < T > ( source ) { public void replay ( QueryableFactory < T > factory ) { factory . singleOrDefault ( source ) ; } } . single ( ) ; } public T singleOrDefault ( final Queryable < T > source , final FunctionExpression < Predicate1 < T > > predicate ) { return new NonLeafReplayableQueryable < T > ( source ) { public void replay ( QueryableFactory < T > factory ) { factory . singleOrDefault ( source , predicate ) ; } } . single ( ) ; } public Queryable < T > skip ( final Queryable < T > source , final int count ) { return new NonLeafReplayableQueryable < T > ( source ) { public void replay ( QueryableFactory < T > factory ) { factory . skip ( source , count ) ; } } ; } public Queryable < T > skipWhile ( final Queryable < T > source , final FunctionExpression < Predicate1 < T > > predicate ) { return new NonLeafReplayableQueryable < T > ( source ) { public void replay ( QueryableFactory < T > factory ) { factory . skipWhile ( source , predicate ) ; } } ; } public Queryable < T > skipWhileN ( final Queryable < T > source , final FunctionExpression < Predicate2 < T , Integer > > predicate ) { return new NonLeafReplayableQueryable < T > ( source ) { public void replay ( QueryableFactory < T > factory ) { factory . skipWhileN ( source , predicate ) ; } } ; } public BigDecimal sumBigDecimal ( final Queryable < T > source , final FunctionExpression < BigDecimalFunction1 < T > > selector ) { return new NonLeafReplayableQueryable < T > ( source ) { public void replay ( QueryableFactory < T > factory ) { factory . sumBigDecimal ( source , selector ) ; } } . castSingle ( ) ; } public BigDecimal sumNullableBigDecimal ( final Queryable < T > source , final FunctionExpression < NullableBigDecimalFunction1 < T > > selector ) { return new NonLeafReplayableQueryable < T > ( source ) { public void replay ( QueryableFactory < T > factory ) { factory . sumNullableBigDecimal ( source , selector ) ; } } . castSingle ( ) ; } public double sumDouble ( final Queryable < T > source , final FunctionExpression < DoubleFunction1 < T > > selector ) { return new NonLeafReplayableQueryable < T > ( source ) { public void replay ( QueryableFactory < T > factory ) { factory . sumDouble ( source , selector ) ; } } . < Double > castSingle ( ) ; } public Double sumNullableDouble ( final Queryable < T > source , final FunctionExpression < NullableDoubleFunction1 < T > > selector ) { return new NonLeafReplayableQueryable < T > ( source ) { public void replay ( QueryableFactory < T > factory ) { factory . sumNullableDouble ( source , selector ) ; } } . < Double > castSingle ( ) ; } public int sumInteger ( final Queryable < T > source , final FunctionExpression < IntegerFunction1 < T > > selector ) { return new NonLeafReplayableQueryable < T > ( source ) { public void replay ( QueryableFactory < T > factory ) { factory . sumInteger ( source , selector ) ; } } . < Integer > castSingle ( ) ; } public Integer sumNullableInteger ( final Queryable < T > source , final FunctionExpression < NullableIntegerFunction1 < T > > selector ) { return new NonLeafReplayableQueryable < T > ( source ) { public void replay ( QueryableFactory < T > factory ) { factory . sumNullableInteger ( source , selector ) ; } } . < Integer > castSingle ( ) ; } public long sumLong ( final Queryable < T > source , final FunctionExpression < LongFunction1 < T > > selector ) { return new NonLeafReplayableQueryable < T > ( source ) { public void replay ( QueryableFactory < T > factory ) { factory . sumLong ( source , selector ) ; } } . < Long > castSingle ( ) ; } public Long sumNullableLong ( final Queryable < T > source , final FunctionExpression < NullableLongFunction1 < T > > selector ) { return new NonLeafReplayableQueryable < T > ( source ) { public void replay ( QueryableFactory < T > factory ) { factory . sumNullableLong ( source , selector ) ; } } . < Long > castSingle ( ) ; } public float sumFloat ( final Queryable < T > source , final FunctionExpression < FloatFunction1 < T > > selector ) { return new NonLeafReplayableQueryable < T > ( source ) { public void replay ( QueryableFactory < T > factory ) { factory . sumFloat ( source , selector ) ; } } . < Float > castSingle ( ) ; } public Float sumNullableFloat ( final Queryable < T > source , final FunctionExpression < NullableFloatFunction1 < T > > selector ) { return new NonLeafReplayableQueryable < T > ( source ) { public void replay ( QueryableFactory < T > factory ) { factory . sumNullableFloat ( source , selector ) ; } } . < Float > castSingle ( ) ; } public Queryable < T > take ( final Queryable < T > source , final int count ) { return new NonLeafReplayableQueryable < T > ( source ) { public void replay ( QueryableFactory < T > factory ) { factory . take ( source , count ) ; } } ; } public Queryable < T > takeWhile ( final Queryable < T > source , final FunctionExpression < Predicate1 < T > > predicate ) { return new NonLeafReplayableQueryable < T > ( source ) { public void replay ( QueryableFactory < T > factory ) { factory . takeWhile ( source , predicate ) ; } } ; } public Queryable < T > takeWhileN ( final Queryable < T > source , final FunctionExpression < Predicate2 < T , Integer > > predicate ) { return new NonLeafReplayableQueryable < T > ( source ) { public void replay ( QueryableFactory < T > factory ) { factory . takeWhileN ( source , predicate ) ; } } ; } public < TKey extends Comparable < TKey > > OrderedQueryable < T > thenBy ( final OrderedQueryable < T > source , final FunctionExpression < Function1 < T , TKey > > keySelector ) { return new NonLeafReplayableQueryable < T > ( source ) { public void replay ( QueryableFactory < T > factory ) { factory . thenBy ( source , keySelector ) ; } } ; } public < TKey > OrderedQueryable < T > thenBy ( final OrderedQueryable < T > source , final FunctionExpression < Function1 < T , TKey > > keySelector , final Comparator < TKey > comparator ) { return new NonLeafReplayableQueryable < T > ( source ) { public void replay ( QueryableFactory < T > factory ) { factory . thenBy ( source , keySelector , comparator ) ; } } ; } public < TKey extends Comparable < TKey > > OrderedQueryable < T > thenByDescending ( final OrderedQueryable < T > source , final FunctionExpression < Function1 < T , TKey > > keySelector ) { return new NonLeafReplayableQueryable < T > ( source ) { public void replay ( QueryableFactory < T > factory ) { factory . thenByDescending ( source , keySelector ) ; } } ; } public < TKey > OrderedQueryable < T > thenByDescending ( final OrderedQueryable < T > source , final FunctionExpression < Function1 < T , TKey > > keySelector , final Comparator < TKey > comparator ) { return new NonLeafReplayableQueryable < T > ( source ) { public void replay ( QueryableFactory < T > factory ) { factory . thenByDescending ( source , keySelector , comparator ) ; } } ; } public Queryable < T > union ( final Queryable < T > source , final Enumerable < T > source1 ) { return new NonLeafReplayableQueryable < T > ( source ) { public void replay ( QueryableFactory < T > factory ) { factory . union ( source , source1 ) ; } } ; } public Queryable < T > union ( final Queryable < T > source , final Enumerable < T > source1 , final EqualityComparer < T > comparer ) { return new NonLeafReplayableQueryable < T > ( source ) { public void replay ( QueryableFactory < T > factory ) { factory . union ( source , source1 , comparer ) ; } } ; } public Queryable < T > where ( final Queryable < T > source , final FunctionExpression < ? extends Predicate1 < T > > predicate ) { return new NonLeafReplayableQueryable < T > ( source ) { public void replay ( QueryableFactory < T > factory ) { factory . where ( source , predicate ) ; } } ; } public Queryable < T > whereN ( final Queryable < T > source , final FunctionExpression < ? extends Predicate2 < T , Integer > > predicate ) { return new NonLeafReplayableQueryable < T > ( source ) { public void replay ( QueryableFactory < T > factory ) { factory . whereN ( source , predicate ) ; } } ; } public < T1 , TResult > Queryable < TResult > zip ( final Queryable < T > source , final Enumerable < T1 > source1 , final FunctionExpression < Function2 < T , T1 , TResult > > resultSelector ) { return new NonLeafReplayableQueryable < T > ( source ) { public void replay ( QueryableFactory < T > factory ) { factory . zip ( source , source1 , resultSelector ) ; } } . castQueryable ( ) ; } }",Smelly
"class Add extends MathVal { public Add ( Val val1 , Val val2 ) { super ( val1 , val2 ) ; } protected Object operate ( Object o1 , Class c1 , Object o2 , Class c2 ) { return Filters . add ( o1 , c1 , o2 , c2 ) ; } }",No
"public class SafeFixLengthColumnPage extends ColumnPage { private byte [ ] byteData ; private short [ ] shortData ; private int [ ] intData ; private long [ ] longData ; private float [ ] floatData ; private double [ ] doubleData ; private byte [ ] shortIntData ; private byte [ ] [ ] fixedLengthdata ; private int totalLength ; private int arrayElementCount = 0 ; SafeFixLengthColumnPage ( ColumnPageEncoderMeta columnPageEncoderMeta , int pageSize ) { super ( columnPageEncoderMeta , pageSize ) ; } @ Override public void putByte ( int rowId , byte value ) { ensureArraySize ( rowId , DataTypes . BYTE ) ; byteData [ rowId ] = value ; arrayElementCount ++ ; totalLength += DataTypes . BYTE . getSizeInBytes ( ) ; } @ Override public void putShort ( int rowId , short value ) { ensureArraySize ( rowId , DataTypes . SHORT ) ; shortData [ rowId ] = value ; arrayElementCount ++ ; totalLength += DataTypes . SHORT . getSizeInBytes ( ) ; } @ Override public void putInt ( int rowId , int value ) { ensureArraySize ( rowId , DataTypes . INT ) ; intData [ rowId ] = value ; arrayElementCount ++ ; totalLength += DataTypes . INT . getSizeInBytes ( ) ; } @ Override public void putLong ( int rowId , long value ) { ensureArraySize ( rowId , DataTypes . LONG ) ; longData [ rowId ] = value ; arrayElementCount ++ ; totalLength += DataTypes . LONG . getSizeInBytes ( ) ; } @ Override public void putDouble ( int rowId , double value ) { ensureArraySize ( rowId , DataTypes . DOUBLE ) ; doubleData [ rowId ] = value ; arrayElementCount ++ ; totalLength += DataTypes . DOUBLE . getSizeInBytes ( ) ; } @ Override public void putFloat ( int rowId , float value ) { ensureArraySize ( rowId , DataTypes . FLOAT ) ; floatData [ rowId ] = value ; arrayElementCount ++ ; totalLength += DataTypes . FLOAT . getSizeInBytes ( ) ; } @ Override public void putBytes ( int rowId , byte [ ] bytes ) { ensureArraySize ( rowId , DataTypes . BYTE_ARRAY ) ; this . fixedLengthdata [ rowId ] = bytes ; arrayElementCount ++ ; totalLength += bytes . length ; } @ Override public void putShortInt ( int rowId , int value ) { ensureArraySize ( rowId , DataTypes . SHORT_INT ) ; byte [ ] converted = ByteUtil . to3Bytes ( value ) ; System . arraycopy ( converted , 0 , shortIntData , rowId * 3 , 3 ) ; arrayElementCount ++ ; totalLength += DataTypes . SHORT_INT . getSizeInBytes ( ) ; } @ Override public void putBytes ( int rowId , byte [ ] bytes , int offset , int length ) { throw new UnsupportedOperationException ( ""invalid data type: "" + columnPageEncoderMeta . getStoreDataType ( ) ) ; } @ Override public void putDecimal ( int rowId , BigDecimal decimal ) { throw new UnsupportedOperationException ( ""invalid data type: "" + columnPageEncoderMeta . getStoreDataType ( ) ) ; } @ Override public byte [ ] getDecimalPage ( ) { throw new UnsupportedOperationException ( ""invalid data type: "" + columnPageEncoderMeta . getStoreDataType ( ) ) ; } @ Override public byte getByte ( int rowId ) { return byteData [ rowId ] ; } @ Override public short getShort ( int rowId ) { return shortData [ rowId ] ; } @ Override public int getShortInt ( int rowId ) { return ByteUtil . valueOf3Bytes ( shortIntData , rowId * 3 ) ; } @ Override public int getInt ( int rowId ) { return intData [ rowId ] ; } @ Override public long getLong ( int rowId ) { return longData [ rowId ] ; } @ Override public float getFloat ( int rowId ) { return floatData [ rowId ] ; } @ Override public double getDouble ( int rowId ) { return doubleData [ rowId ] ; } @ Override public BigDecimal getDecimal ( int rowId ) { throw new UnsupportedOperationException ( ""invalid data type: "" + columnPageEncoderMeta . getStoreDataType ( ) ) ; } @ Override public byte [ ] getBytes ( int rowId ) { return this . fixedLengthdata [ rowId ] ; } @ Override public byte [ ] getBytePage ( ) { return byteData ; } @ Override public short [ ] getShortPage ( ) { return shortData ; } @ Override public byte [ ] getShortIntPage ( ) { return shortIntData ; } @ Override public int [ ] getIntPage ( ) { return intData ; } @ Override public long [ ] getLongPage ( ) { return longData ; } @ Override public float [ ] getFloatPage ( ) { return floatData ; } @ Override public double [ ] getDoublePage ( ) { return doubleData ; } @ Override public byte [ ] [ ] getByteArrayPage ( ) { byte [ ] [ ] data = new byte [ arrayElementCount ] [ ] ; for ( int i = 0 ; i < arrayElementCount ; i ++ ) { data [ i ] = fixedLengthdata [ i ] ; } return data ; } @ Override public byte [ ] getLVFlattenedBytePage ( ) { throw new UnsupportedOperationException ( ""invalid data type: "" + columnPageEncoderMeta . getStoreDataType ( ) ) ; } @ Override public byte [ ] getComplexChildrenLVFlattenedBytePage ( DataType dataType ) throws IOException { ByteArrayOutputStream stream = new ByteArrayOutputStream ( ) ; DataOutputStream out = new DataOutputStream ( stream ) ; for ( int i = 0 ; i < arrayElementCount ; i ++ ) { out . write ( fixedLengthdata [ i ] ) ; } return stream . toByteArray ( ) ; } @ Override public byte [ ] getComplexParentFlattenedBytePage ( ) { throw new UnsupportedOperationException ( ""internal error"" ) ; } @ Override public void setBytePage ( byte [ ] byteData ) { this . byteData = byteData ; } @ Override public void setShortPage ( short [ ] shortData ) { this . shortData = shortData ; } @ Override public void setShortIntPage ( byte [ ] shortIntData ) { this . shortIntData = shortIntData ; } @ Override public void setIntPage ( int [ ] intData ) { this . intData = intData ; } @ Override public void setLongPage ( long [ ] longData ) { this . longData = longData ; } @ Override public void setFloatPage ( float [ ] floatData ) { this . floatData = floatData ; } @ Override public void setDoublePage ( double [ ] doubleData ) { this . doubleData = doubleData ; } @ Override public void setByteArrayPage ( byte [ ] [ ] byteArray ) { throw new UnsupportedOperationException ( ""invalid data type: "" + columnPageEncoderMeta . getStoreDataType ( ) ) ; } @ Override public void freeMemory ( ) { byteData = null ; shortData = null ; intData = null ; longData = null ; floatData = null ; doubleData = null ; shortIntData = null ; fixedLengthdata = null ; } @ Override public void convertValue ( ColumnPageValueConverter codec ) { if ( columnPageEncoderMeta . getStoreDataType ( ) == DataTypes . BYTE ) { for ( int i = 0 ; i < arrayElementCount ; i ++ ) { codec . encode ( i , byteData [ i ] ) ; } } else if ( columnPageEncoderMeta . getStoreDataType ( ) == DataTypes . SHORT ) { for ( int i = 0 ; i < arrayElementCount ; i ++ ) { codec . encode ( i , shortData [ i ] ) ; } } else if ( columnPageEncoderMeta . getStoreDataType ( ) == DataTypes . INT ) { for ( int i = 0 ; i < arrayElementCount ; i ++ ) { codec . encode ( i , intData [ i ] ) ; } } else if ( columnPageEncoderMeta . getStoreDataType ( ) == DataTypes . LONG ) { for ( int i = 0 ; i < arrayElementCount ; i ++ ) { codec . encode ( i , longData [ i ] ) ; } } else if ( columnPageEncoderMeta . getStoreDataType ( ) == DataTypes . FLOAT ) { for ( int i = 0 ; i < arrayElementCount ; i ++ ) { codec . encode ( i , floatData [ i ] ) ; } } else if ( columnPageEncoderMeta . getStoreDataType ( ) == DataTypes . DOUBLE ) { for ( int i = 0 ; i < arrayElementCount ; i ++ ) { codec . encode ( i , doubleData [ i ] ) ; } } else { throw new UnsupportedOperationException ( ""not support value conversion on "" + columnPageEncoderMeta . getStoreDataType ( ) + "" page"" ) ; } } private void ensureArraySize ( int requestSize , DataType dataType ) { if ( dataType == DataTypes . BYTE ) { if ( requestSize >= byteData . length ) { byte [ ] newArray = new byte [ arrayElementCount * 2 ] ; System . arraycopy ( byteData , 0 , newArray , 0 , arrayElementCount ) ; byteData = newArray ; } } else if ( dataType == DataTypes . SHORT ) { if ( requestSize >= shortData . length ) { short [ ] newArray = new short [ arrayElementCount * 2 ] ; System . arraycopy ( shortData , 0 , newArray , 0 , arrayElementCount ) ; shortData = newArray ; } } else if ( dataType == DataTypes . SHORT_INT ) { if ( requestSize >= shortIntData . length / 3 ) { byte [ ] newArray = new byte [ arrayElementCount * 6 ] ; System . arraycopy ( shortIntData , 0 , newArray , 0 , arrayElementCount * 3 ) ; shortIntData = newArray ; } } else if ( dataType == DataTypes . INT ) { if ( requestSize >= intData . length ) { int [ ] newArray = new int [ arrayElementCount * 2 ] ; System . arraycopy ( intData , 0 , newArray , 0 , arrayElementCount ) ; intData = newArray ; } } else if ( dataType == DataTypes . LONG ) { if ( requestSize >= longData . length ) { long [ ] newArray = new long [ arrayElementCount * 2 ] ; System . arraycopy ( longData , 0 , newArray , 0 , arrayElementCount ) ; longData = newArray ; } } else if ( dataType == DataTypes . FLOAT ) { if ( requestSize >= floatData . length ) { float [ ] newArray = new float [ arrayElementCount * 2 ] ; System . arraycopy ( floatData , 0 , newArray , 0 , arrayElementCount ) ; floatData = newArray ; } } else if ( dataType == DataTypes . DOUBLE ) { if ( requestSize >= doubleData . length ) { double [ ] newArray = new double [ arrayElementCount * 2 ] ; System . arraycopy ( doubleData , 0 , newArray , 0 , arrayElementCount ) ; doubleData = newArray ; } } else if ( dataType == DataTypes . BYTE_ARRAY ) { if ( fixedLengthdata == null ) { fixedLengthdata = new byte [ pageSize ] [ ] ; } if ( requestSize >= fixedLengthdata . length ) { byte [ ] [ ] newArray = new byte [ arrayElementCount * 2 ] [ ] ; int index = 0 ; for ( byte [ ] data : fixedLengthdata ) { newArray [ index ++ ] = data ; } fixedLengthdata = newArray ; } } else { throw new UnsupportedOperationException ( ""not support value conversion on "" + dataType + "" page"" ) ; } } public int getActualRowCount ( ) { return arrayElementCount ; } @ Override public long getPageLengthInBytes ( ) { return totalLength ; } }",Smelly
"public final class SpringClient { private SpringClient ( ) { } public static void main ( String args [ ] ) throws Exception { ClassPathXmlApplicationContext context = new ClassPathXmlApplicationContext ( new String [ ] { ""/demo/hw/client/client-beans.xml"" } ) ; Greeter port = ( Greeter ) context . getBean ( ""client"" ) ; String resp ; System . out . println ( ""Invoking sayHi..."" ) ; resp = port . sayHi ( ) ; System . out . println ( ""Server responded with: "" + resp ) ; System . out . println ( ) ; System . out . println ( ""Invoking greetMe..."" ) ; resp = port . greetMe ( System . getProperty ( ""user.name"" ) ) ; System . out . println ( ""Server responded with: "" + resp ) ; System . out . println ( ) ; System . out . println ( ""Invoking greetMe with invalid length string, expecting exception..."" ) ; try { resp = port . greetMe ( ""Invoking greetMe with invalid length string, expecting exception..."" ) ; } catch ( WebServiceException ex ) { System . out . println ( ""Caught expected WebServiceException:"" ) ; System . out . println ( ""    "" + ex . getMessage ( ) ) ; } System . out . println ( ) ; System . out . println ( ""Invoking greetMeOneWay..."" ) ; port . greetMeOneWay ( System . getProperty ( ""user.name"" ) ) ; System . out . println ( ""No response from server as method is OneWay"" ) ; System . out . println ( ) ; try { System . out . println ( ""Invoking pingMe, expecting exception..."" ) ; port . pingMe ( ) ; } catch ( PingMeFault ex ) { System . out . println ( ""Expected exception: PingMeFault has occurred: "" + ex . getMessage ( ) ) ; FaultDetailDocument detailDocument = ex . getFaultInfo ( ) ; FaultDetail detail = detailDocument . getFaultDetail ( ) ; System . out . println ( ""FaultDetail major:"" + detail . getMajor ( ) ) ; System . out . println ( ""FaultDetail minor:"" + detail . getMinor ( ) ) ; } System . exit ( 0 ) ; } }",No
"public final class CarbonDataMergerUtil { private static final Logger LOGGER = LogServiceFactory . getLogService ( CarbonDataMergerUtil . class . getName ( ) ) ; private CarbonDataMergerUtil ( ) { } private static long getSizeOfFactFileInLoad ( CarbonFile carbonFile ) { long factSize = 0 ; CarbonFile [ ] factFile = carbonFile . listFiles ( new CarbonFileFilter ( ) { @ Override public boolean accept ( CarbonFile file ) { return CarbonTablePath . isCarbonDataFile ( file . getName ( ) ) ; } } ) ; for ( CarbonFile fact : factFile ) { factSize += fact . getSize ( ) ; } return factSize ; } public static boolean checkIfAutoLoadMergingRequired ( CarbonTable carbonTable ) { Map < String , String > tblProps = carbonTable . getTableInfo ( ) . getFactTable ( ) . getTableProperties ( ) ; String isLoadMergeEnabled = CarbonProperties . getInstance ( ) . getProperty ( CarbonCommonConstants . ENABLE_AUTO_LOAD_MERGE , CarbonCommonConstants . DEFAULT_ENABLE_AUTO_LOAD_MERGE ) ; if ( tblProps . containsKey ( CarbonCommonConstants . TABLE_AUTO_LOAD_MERGE ) ) { isLoadMergeEnabled = tblProps . get ( CarbonCommonConstants . TABLE_AUTO_LOAD_MERGE ) ; } if ( isLoadMergeEnabled . equalsIgnoreCase ( ""false"" ) ) { return false ; } return true ; } public static String getMergedLoadName ( List < LoadMetadataDetails > segmentsToBeMergedList ) { String firstSegmentName = segmentsToBeMergedList . get ( 0 ) . getLoadName ( ) ; if ( firstSegmentName . contains ( ""."" ) ) { String beforeDecimal = firstSegmentName . substring ( 0 , firstSegmentName . indexOf ( ""."" ) ) ; String afterDecimal = firstSegmentName . substring ( firstSegmentName . indexOf ( ""."" ) + 1 ) ; int fraction = Integer . parseInt ( afterDecimal ) + 1 ; String mergedSegmentName = beforeDecimal + ""."" + fraction ; return CarbonCommonConstants . LOAD_FOLDER + mergedSegmentName ; } else { String mergeName = firstSegmentName + ""."" + 1 ; return CarbonCommonConstants . LOAD_FOLDER + mergeName ; } } public static boolean updateLoadMetadataIUDUpdateDeltaMergeStatus ( List < LoadMetadataDetails > loadsToMerge , String metaDataFilepath , CarbonLoadModel carbonLoadModel , List < Segment > segmentFilesToBeUpdated ) { boolean status = false ; boolean updateLockStatus = false ; boolean tableLockStatus = false ; String timestamp = """" + carbonLoadModel . getFactTimeStamp ( ) ; List < String > updatedDeltaFilesList = null ; AbsoluteTableIdentifier identifier = carbonLoadModel . getCarbonDataLoadSchema ( ) . getCarbonTable ( ) . getAbsoluteTableIdentifier ( ) ; SegmentUpdateStatusManager segmentUpdateStatusManager = new SegmentUpdateStatusManager ( carbonLoadModel . getCarbonDataLoadSchema ( ) . getCarbonTable ( ) ) ; SegmentStatusManager segmentStatusManager = new SegmentStatusManager ( identifier ) ; ICarbonLock updateLock = segmentUpdateStatusManager . getTableUpdateStatusLock ( ) ; ICarbonLock statusLock = segmentStatusManager . getTableStatusLock ( ) ; try { updatedDeltaFilesList = segmentUpdateStatusManager . getUpdateDeltaFiles ( loadsToMerge . get ( 0 ) . getLoadName ( ) ) ; } catch ( Exception e ) { LOGGER . error ( ""Error while getting the Update Delta Blocks."" ) ; status = false ; return status ; } if ( updatedDeltaFilesList . size ( ) > 0 ) { try { updateLockStatus = updateLock . lockWithRetries ( ) ; tableLockStatus = statusLock . lockWithRetries ( ) ; List < String > blockNames = new ArrayList < > ( updatedDeltaFilesList . size ( ) ) ; for ( String compactedBlocks : updatedDeltaFilesList ) { int endIndex = compactedBlocks . lastIndexOf ( File . separator ) ; String blkNoExt = compactedBlocks . substring ( endIndex + 1 , compactedBlocks . lastIndexOf ( ""-"" ) ) ; blockNames . add ( blkNoExt ) ; } if ( updateLockStatus && tableLockStatus ) { SegmentUpdateDetails [ ] updateLists = segmentUpdateStatusManager . readLoadMetadata ( ) ; for ( String compactedBlocks : blockNames ) { for ( int i = 0 ; i < updateLists . length ; i ++ ) { if ( updateLists [ i ] . getBlockName ( ) . equalsIgnoreCase ( compactedBlocks ) && updateLists [ i ] . getSegmentStatus ( ) != SegmentStatus . COMPACTED && updateLists [ i ] . getSegmentStatus ( ) != SegmentStatus . MARKED_FOR_DELETE ) { updateLists [ i ] . setSegmentStatus ( SegmentStatus . COMPACTED ) ; } } } LoadMetadataDetails [ ] loadDetails = SegmentStatusManager . readLoadMetadata ( metaDataFilepath ) ; for ( LoadMetadataDetails loadDetail : loadDetails ) { if ( loadsToMerge . contains ( loadDetail ) ) { loadDetail . setUpdateDeltaStartTimestamp ( timestamp ) ; loadDetail . setUpdateDeltaEndTimestamp ( timestamp ) ; if ( loadDetail . getLoadName ( ) . equalsIgnoreCase ( ""0"" ) ) { loadDetail . setUpdateStatusFileName ( CarbonUpdateUtil . getUpdateStatusFileName ( timestamp ) ) ; } int segmentFileIndex = segmentFilesToBeUpdated . indexOf ( Segment . toSegment ( loadDetail . getLoadName ( ) , null ) ) ; if ( segmentFileIndex > - 1 ) { loadDetail . setSegmentFile ( segmentFilesToBeUpdated . get ( segmentFileIndex ) . getSegmentFileName ( ) ) ; } } } segmentUpdateStatusManager . writeLoadDetailsIntoFile ( Arrays . asList ( updateLists ) , timestamp ) ; SegmentStatusManager . writeLoadDetailsIntoFile ( CarbonTablePath . getTableStatusFilePath ( identifier . getTablePath ( ) ) , loadDetails ) ; status = true ; } else { LOGGER . error ( ""Not able to acquire the lock."" ) ; status = false ; } } catch ( IOException e ) { LOGGER . error ( ""Error while updating metadata. The metadata file path is "" + CarbonTablePath . getMetadataPath ( identifier . getTablePath ( ) ) ) ; status = false ; } finally { if ( updateLockStatus ) { if ( updateLock . unlock ( ) ) { LOGGER . info ( ""Unlock the segment update lock successfully."" ) ; } else { LOGGER . error ( ""Not able to unlock the segment update lock."" ) ; } } if ( tableLockStatus ) { if ( statusLock . unlock ( ) ) { LOGGER . info ( ""Unlock the table status lock successfully."" ) ; } else { LOGGER . error ( ""Not able to unlock the table status lock."" ) ; } } } } return status ; } public static boolean updateLoadMetadataWithMergeStatus ( List < LoadMetadataDetails > loadsToMerge , String metaDataFilepath , String mergedLoadNumber , CarbonLoadModel carbonLoadModel , CompactionType compactionType , String segmentFile , MVManager viewManager ) throws IOException , NoSuchMVException { boolean tableStatusUpdationStatus = false ; AbsoluteTableIdentifier identifier = carbonLoadModel . getCarbonDataLoadSchema ( ) . getCarbonTable ( ) . getAbsoluteTableIdentifier ( ) ; SegmentStatusManager segmentStatusManager = new SegmentStatusManager ( identifier ) ; ICarbonLock carbonLock = segmentStatusManager . getTableStatusLock ( ) ; try { if ( carbonLock . lockWithRetries ( ) ) { LOGGER . info ( ""Acquired lock for the table "" + carbonLoadModel . getDatabaseName ( ) + ""."" + carbonLoadModel . getTableName ( ) + "" for table status updation "" ) ; String statusFilePath = CarbonTablePath . getTableStatusFilePath ( identifier . getTablePath ( ) ) ; LoadMetadataDetails [ ] loadDetails = SegmentStatusManager . readLoadMetadata ( metaDataFilepath ) ; long modificationOrDeletionTimeStamp = CarbonUpdateUtil . readCurrentTime ( ) ; for ( LoadMetadataDetails loadDetail : loadDetails ) { if ( loadsToMerge . contains ( loadDetail ) ) { if ( loadDetail . getSegmentStatus ( ) == SegmentStatus . MARKED_FOR_DELETE ) { LOGGER . error ( ""Compaction is aborted as the segment "" + loadDetail . getLoadName ( ) + "" is deleted after the compaction is started."" ) ; return false ; } loadDetail . setSegmentStatus ( SegmentStatus . COMPACTED ) ; loadDetail . setModificationOrdeletionTimesStamp ( modificationOrDeletionTimeStamp ) ; loadDetail . setMergedLoadName ( mergedLoadNumber ) ; } } LoadMetadataDetails loadMetadataDetails = new LoadMetadataDetails ( ) ; loadMetadataDetails . setSegmentStatus ( SegmentStatus . SUCCESS ) ; long loadEnddate = CarbonUpdateUtil . readCurrentTime ( ) ; loadMetadataDetails . setLoadEndTime ( loadEnddate ) ; CarbonTable carbonTable = carbonLoadModel . getCarbonDataLoadSchema ( ) . getCarbonTable ( ) ; loadMetadataDetails . setLoadName ( mergedLoadNumber ) ; loadMetadataDetails . setSegmentFile ( segmentFile ) ; CarbonLoaderUtil . addDataIndexSizeIntoMetaEntry ( loadMetadataDetails , mergedLoadNumber , carbonTable ) ; loadMetadataDetails . setLoadStartTime ( carbonLoadModel . getFactTimeStamp ( ) ) ; if ( CompactionType . MAJOR == compactionType ) { loadMetadataDetails . setMajorCompacted ( ""true"" ) ; } if ( carbonTable . isMV ( ) ) { MVSchema viewSchema = viewManager . getSchema ( carbonTable . getDatabaseName ( ) , carbonTable . getTableName ( ) ) ; if ( null != viewSchema ) { String segmentMap = MVManager . getUpdatedSegmentMap ( mergedLoadNumber , viewSchema , loadDetails ) ; loadMetadataDetails . setExtraInfo ( segmentMap ) ; } else { throw new NoSuchMVException ( carbonTable . getDatabaseName ( ) , carbonTable . getTableName ( ) ) ; } } List < LoadMetadataDetails > updatedDetailsList = new ArrayList < > ( Arrays . asList ( loadDetails ) ) ; updatedDetailsList . add ( loadMetadataDetails ) ; try { SegmentStatusManager . writeLoadDetailsIntoFile ( statusFilePath , updatedDetailsList . toArray ( new LoadMetadataDetails [ updatedDetailsList . size ( ) ] ) ) ; tableStatusUpdationStatus = true ; } catch ( IOException e ) { LOGGER . error ( ""Error while writing metadata"" ) ; tableStatusUpdationStatus = false ; } } else { LOGGER . error ( ""Could not able to obtain lock for table"" + carbonLoadModel . getDatabaseName ( ) + ""."" + carbonLoadModel . getTableName ( ) + ""for table status updation"" ) ; } } finally { if ( carbonLock . unlock ( ) ) { LOGGER . info ( ""Table unlocked successfully after table status updation"" + carbonLoadModel . getDatabaseName ( ) + ""."" + carbonLoadModel . getTableName ( ) ) ; } else { LOGGER . error ( ""Unable to unlock Table lock for table"" + carbonLoadModel . getDatabaseName ( ) + ""."" + carbonLoadModel . getTableName ( ) + "" during table status updation"" ) ; } } return tableStatusUpdationStatus ; } public static String getLoadNumberFromLoadName ( String loadName ) { return loadName . substring ( loadName . lastIndexOf ( CarbonCommonConstants . LOAD_FOLDER ) + CarbonCommonConstants . LOAD_FOLDER . length ( ) , loadName . length ( ) ) ; } public static List < LoadMetadataDetails > identifySegmentsToBeMerged ( CarbonLoadModel carbonLoadModel , long compactionSize , List < LoadMetadataDetails > segments , CompactionType compactionType , List < String > customSegmentIds ) throws IOException , MalformedCarbonCommandException { Map < String , String > tableLevelProperties = carbonLoadModel . getCarbonDataLoadSchema ( ) . getCarbonTable ( ) . getTableInfo ( ) . getFactTable ( ) . getTableProperties ( ) ; List < LoadMetadataDetails > sortedSegments = new ArrayList < LoadMetadataDetails > ( segments ) ; sortSegments ( sortedSegments ) ; if ( CompactionType . CUSTOM == compactionType ) { return identitySegmentsToBeMergedBasedOnSpecifiedSegments ( sortedSegments , new LinkedHashSet < > ( customSegmentIds ) ) ; } if ( CompactionType . IUD_UPDDEL_DELTA == compactionType ) { return identifySegmentsToBeMergedBasedOnIUD ( sortedSegments , carbonLoadModel ) ; } List < LoadMetadataDetails > listOfSegmentsAfterPreserve = checkPreserveSegmentsPropertyReturnRemaining ( sortedSegments , tableLevelProperties ) ; List < LoadMetadataDetails > listOfSegmentsLoadedInSameDateInterval = identifySegmentsToBeMergedBasedOnLoadedDate ( listOfSegmentsAfterPreserve , tableLevelProperties ) ; List < LoadMetadataDetails > listOfSegmentsToBeMerged ; if ( CompactionType . MAJOR == compactionType ) { listOfSegmentsToBeMerged = identifySegmentsToBeMergedBasedOnSize ( compactionSize , listOfSegmentsLoadedInSameDateInterval , carbonLoadModel ) ; } else { listOfSegmentsToBeMerged = identifySegmentsToBeMergedBasedOnSegCount ( listOfSegmentsLoadedInSameDateInterval , tableLevelProperties ) ; } return listOfSegmentsToBeMerged ; } public static void sortSegments ( List segments ) { Collections . sort ( segments , new Comparator < LoadMetadataDetails > ( ) { @ Override public int compare ( LoadMetadataDetails seg1 , LoadMetadataDetails seg2 ) { double seg1Id = Double . parseDouble ( seg1 . getLoadName ( ) ) ; double seg2Id = Double . parseDouble ( seg2 . getLoadName ( ) ) ; return Double . compare ( seg1Id , seg2Id ) ; } } ) ; } private static List < LoadMetadataDetails > identitySegmentsToBeMergedBasedOnSpecifiedSegments ( List < LoadMetadataDetails > listOfSegments , Set < String > segmentIds ) throws MalformedCarbonCommandException { Map < String , LoadMetadataDetails > specifiedSegments = new LinkedHashMap < > ( CarbonCommonConstants . DEFAULT_COLLECTION_SIZE ) ; for ( LoadMetadataDetails detail : listOfSegments ) { if ( segmentIds . contains ( detail . getLoadName ( ) ) ) { specifiedSegments . put ( detail . getLoadName ( ) , detail ) ; } } for ( String segmentId : segmentIds ) { if ( ! specifiedSegments . containsKey ( segmentId ) || ! isSegmentValid ( specifiedSegments . get ( segmentId ) ) ) { String errMsg = String . format ( ""Segment %s does not exist or is not valid"" , segmentId ) ; LOGGER . error ( errMsg ) ; throw new MalformedCarbonCommandException ( errMsg ) ; } } return new ArrayList < > ( specifiedSegments . values ( ) ) ; } private static List < LoadMetadataDetails > identifySegmentsToBeMergedBasedOnLoadedDate ( List < LoadMetadataDetails > listOfSegmentsBelowThresholdSize , Map < String , String > tblProps ) { List < LoadMetadataDetails > loadsOfSameDate = new ArrayList < > ( CarbonCommonConstants . DEFAULT_COLLECTION_SIZE ) ; long numberOfDaysAllowedToMerge = 0 ; try { numberOfDaysAllowedToMerge = Long . parseLong ( CarbonProperties . getInstance ( ) . getProperty ( CarbonCommonConstants . DAYS_ALLOWED_TO_COMPACT , CarbonCommonConstants . DEFAULT_DAYS_ALLOWED_TO_COMPACT ) ) ; if ( tblProps . containsKey ( CarbonCommonConstants . TABLE_ALLOWED_COMPACTION_DAYS ) ) { numberOfDaysAllowedToMerge = Long . parseLong ( tblProps . get ( CarbonCommonConstants . TABLE_ALLOWED_COMPACTION_DAYS ) ) ; } if ( numberOfDaysAllowedToMerge < 0 || numberOfDaysAllowedToMerge > 100 ) { LOGGER . error ( ""The specified value for property "" + CarbonCommonConstants . DAYS_ALLOWED_TO_COMPACT + "" is incorrect."" + "" Correct value should be in range of 0 -100. Taking the default value."" ) ; numberOfDaysAllowedToMerge = Long . parseLong ( CarbonCommonConstants . DEFAULT_DAYS_ALLOWED_TO_COMPACT ) ; } } catch ( NumberFormatException e ) { numberOfDaysAllowedToMerge = Long . parseLong ( CarbonCommonConstants . DEFAULT_DAYS_ALLOWED_TO_COMPACT ) ; } if ( numberOfDaysAllowedToMerge > 0 ) { boolean first = true ; Date segDate1 = null ; SimpleDateFormat sdf = new SimpleDateFormat ( CarbonCommonConstants . CARBON_TIMESTAMP ) ; for ( LoadMetadataDetails segment : listOfSegmentsBelowThresholdSize ) { if ( segment . getSegmentStatus ( ) == SegmentStatus . STREAMING || segment . getSegmentStatus ( ) == SegmentStatus . STREAMING_FINISH ) { continue ; } if ( first ) { segDate1 = initializeFirstSegment ( loadsOfSameDate , segment , sdf ) ; first = false ; continue ; } long segmentDate = segment . getLoadStartTime ( ) ; Date segDate2 = null ; try { segDate2 = sdf . parse ( sdf . format ( segmentDate ) ) ; } catch ( ParseException e ) { LOGGER . error ( ""Error while parsing segment start time"" + e . getMessage ( ) , e ) ; } if ( isTwoDatesPresentInRequiredRange ( segDate1 , segDate2 , numberOfDaysAllowedToMerge ) ) { loadsOfSameDate . add ( segment ) ; } else if ( loadsOfSameDate . size ( ) < 2 ) { loadsOfSameDate . clear ( ) ; segDate1 = initializeFirstSegment ( loadsOfSameDate , segment , sdf ) ; } else { break ; } } } else { for ( LoadMetadataDetails segment : listOfSegmentsBelowThresholdSize ) { if ( segment . getSegmentStatus ( ) == SegmentStatus . STREAMING || segment . getSegmentStatus ( ) == SegmentStatus . STREAMING_FINISH ) { continue ; } loadsOfSameDate . add ( segment ) ; } } return loadsOfSameDate ; } private static Date initializeFirstSegment ( List < LoadMetadataDetails > loadsOfSameDate , LoadMetadataDetails segment , SimpleDateFormat sdf ) { long baselineLoadStartTime = segment . getLoadStartTime ( ) ; Date segDate1 = null ; try { segDate1 = sdf . parse ( sdf . format ( baselineLoadStartTime ) ) ; } catch ( ParseException e ) { LOGGER . error ( ""Error while parsing segment start time"" + e . getMessage ( ) , e ) ; } loadsOfSameDate . add ( segment ) ; return segDate1 ; } private static boolean isTwoDatesPresentInRequiredRange ( Date segDate1 , Date segDate2 , long numberOfDaysAllowedToMerge ) { if ( segDate1 == null || segDate2 == null ) { return false ; } Calendar cal1 = Calendar . getInstance ( ) ; cal1 . set ( segDate1 . getYear ( ) , segDate1 . getMonth ( ) , segDate1 . getDate ( ) ) ; Calendar cal2 = Calendar . getInstance ( ) ; cal2 . set ( segDate2 . getYear ( ) , segDate2 . getMonth ( ) , segDate2 . getDate ( ) ) ; long diff = cal2 . getTimeInMillis ( ) - cal1 . getTimeInMillis ( ) ; if ( ( diff / ( 24 * 60 * 60 * 1000 ) ) < numberOfDaysAllowedToMerge ) { return true ; } return false ; } private static List < LoadMetadataDetails > identifySegmentsToBeMergedBasedOnSize ( long compactionSize , List < LoadMetadataDetails > listOfSegmentsAfterPreserve , CarbonLoadModel carbonLoadModel ) throws IOException { List < LoadMetadataDetails > segmentsToBeMerged = new ArrayList < > ( CarbonCommonConstants . DEFAULT_COLLECTION_SIZE ) ; CarbonTable carbonTable = carbonLoadModel . getCarbonDataLoadSchema ( ) . getCarbonTable ( ) ; long totalLength = 0 ; for ( LoadMetadataDetails segment : listOfSegmentsAfterPreserve ) { if ( segment . getSegmentStatus ( ) == SegmentStatus . STREAMING || segment . getSegmentStatus ( ) == SegmentStatus . STREAMING_FINISH ) { continue ; } String segId = segment . getLoadName ( ) ; long sizeOfOneSegmentAcrossPartition ; if ( segment . getSegmentFile ( ) != null ) { if ( ! StringUtils . isEmpty ( segment . getDataSize ( ) ) ) { sizeOfOneSegmentAcrossPartition = Long . parseLong ( segment . getDataSize ( ) ) ; } else { sizeOfOneSegmentAcrossPartition = CarbonUtil . getSizeOfSegment ( carbonTable . getTablePath ( ) , new Segment ( segId , segment . getSegmentFile ( ) ) ) ; } } else { sizeOfOneSegmentAcrossPartition = getSizeOfSegment ( carbonTable . getTablePath ( ) , segId ) ; } if ( sizeOfOneSegmentAcrossPartition > ( compactionSize * 1024 * 1024 ) ) { if ( segmentsToBeMerged . size ( ) > 1 ) { break ; } else { segmentsToBeMerged = new ArrayList < > ( CarbonCommonConstants . DEFAULT_COLLECTION_SIZE ) ; totalLength = 0 ; continue ; } } totalLength += sizeOfOneSegmentAcrossPartition ; if ( totalLength < ( compactionSize * 1024 * 1024 ) ) { segmentsToBeMerged . add ( segment ) ; } else { if ( segmentsToBeMerged . size ( ) > 1 ) { break ; } else { segmentsToBeMerged = new ArrayList < > ( CarbonCommonConstants . DEFAULT_COLLECTION_SIZE ) ; segmentsToBeMerged . add ( segment ) ; totalLength = sizeOfOneSegmentAcrossPartition ; } } } return segmentsToBeMerged ; } private static long getSizeOfSegment ( String tablePath , String segId ) { String loadPath = CarbonTablePath . getSegmentPath ( tablePath , segId ) ; CarbonFile segmentFolder = FileFactory . getCarbonFile ( loadPath ) ; return getSizeOfFactFileInLoad ( segmentFolder ) ; } private static List < LoadMetadataDetails > identifySegmentsToBeMergedBasedOnSegCount ( List < LoadMetadataDetails > listOfSegmentsAfterPreserve , Map < String , String > tblProps ) { List < LoadMetadataDetails > mergedSegments = new ArrayList < > ( CarbonCommonConstants . DEFAULT_COLLECTION_SIZE ) ; List < LoadMetadataDetails > unMergedSegments = new ArrayList < > ( CarbonCommonConstants . DEFAULT_COLLECTION_SIZE ) ; int [ ] noOfSegmentLevelsCount = CarbonProperties . getInstance ( ) . getCompactionSegmentLevelCount ( ) ; if ( tblProps . containsKey ( CarbonCommonConstants . TABLE_COMPACTION_LEVEL_THRESHOLD ) ) { noOfSegmentLevelsCount = CarbonProperties . getInstance ( ) . getIntArray ( tblProps . get ( CarbonCommonConstants . TABLE_COMPACTION_LEVEL_THRESHOLD ) ) ; if ( 0 == noOfSegmentLevelsCount . length ) { noOfSegmentLevelsCount = CarbonProperties . getInstance ( ) . getCompactionSegmentLevelCount ( ) ; } } int level1Size = 0 ; int level2Size = 0 ; int size = noOfSegmentLevelsCount . length ; if ( size >= 2 ) { level1Size = noOfSegmentLevelsCount [ 0 ] ; level2Size = noOfSegmentLevelsCount [ 1 ] ; level2Size = level2Size == 1 ? 0 : level2Size ; } else if ( size == 1 ) { level1Size = noOfSegmentLevelsCount [ 0 ] ; } int unMergeCounter = 0 ; int mergeCounter = 0 ; for ( LoadMetadataDetails segment : listOfSegmentsAfterPreserve ) { if ( segment . getSegmentStatus ( ) == SegmentStatus . STREAMING || segment . getSegmentStatus ( ) == SegmentStatus . STREAMING_FINISH ) { continue ; } String segName = segment . getLoadName ( ) ; if ( segName . endsWith ( CarbonCommonConstants . LEVEL2_COMPACTION_INDEX ) || ( segment . isMajorCompacted ( ) != null && segment . isMajorCompacted ( ) . equalsIgnoreCase ( ""true"" ) ) ) { continue ; } if ( ! isMergedSegment ( segName ) ) { unMergeCounter ++ ; unMergedSegments . add ( segment ) ; if ( unMergeCounter == ( level1Size ) ) { return unMergedSegments ; } } else { mergeCounter ++ ; mergedSegments . add ( segment ) ; if ( mergeCounter == ( level2Size ) ) { return mergedSegments ; } } } return new ArrayList < > ( 0 ) ; } private static boolean isMergedSegment ( String segName ) { if ( segName . contains ( ""."" ) ) { return true ; } return false ; } private static List < LoadMetadataDetails > checkPreserveSegmentsPropertyReturnRemaining ( List < LoadMetadataDetails > segments , Map < String , String > tblProps ) { int numberOfSegmentsToBePreserved = CarbonProperties . getInstance ( ) . getNumberOfSegmentsToBePreserved ( ) ; if ( tblProps . containsKey ( CarbonCommonConstants . TABLE_COMPACTION_PRESERVE_SEGMENTS ) ) { numberOfSegmentsToBePreserved = Integer . parseInt ( tblProps . get ( CarbonCommonConstants . TABLE_COMPACTION_PRESERVE_SEGMENTS ) ) ; } return CarbonDataMergerUtil . getValidLoadDetailsWithRetaining ( segments , numberOfSegmentsToBePreserved ) ; } private static List < LoadMetadataDetails > getValidLoadDetailsWithRetaining ( List < LoadMetadataDetails > loadMetadataDetails , int numberOfSegToBeRetained ) { List < LoadMetadataDetails > validList = new ArrayList < > ( CarbonCommonConstants . DEFAULT_COLLECTION_SIZE ) ; for ( LoadMetadataDetails segment : loadMetadataDetails ) { if ( isSegmentValid ( segment ) ) { validList . add ( segment ) ; } } int removingIndex = validList . size ( ) - 1 ; for ( int i = validList . size ( ) ; i > 0 ; i -- ) { if ( numberOfSegToBeRetained == 0 ) { break ; } validList . remove ( removingIndex -- ) ; numberOfSegToBeRetained -- ; } return validList ; } public static long getCompactionSize ( CompactionType compactionType , CarbonLoadModel carbonLoadModel ) { long compactionSize = 0 ; switch ( compactionType ) { case MAJOR : compactionSize = CarbonProperties . getInstance ( ) . getMajorCompactionSize ( ) ; Map < String , String > tblProps = carbonLoadModel . getCarbonDataLoadSchema ( ) . getCarbonTable ( ) . getTableInfo ( ) . getFactTable ( ) . getTableProperties ( ) ; if ( tblProps . containsKey ( CarbonCommonConstants . TABLE_MAJOR_COMPACTION_SIZE ) ) { compactionSize = Long . parseLong ( tblProps . get ( CarbonCommonConstants . TABLE_MAJOR_COMPACTION_SIZE ) ) ; } break ; default : } return compactionSize ; } public static List < Segment > getValidSegments ( List < LoadMetadataDetails > loadMetadataDetails ) { List < Segment > segments = new ArrayList < > ( ) ; for ( LoadMetadataDetails segment : loadMetadataDetails ) { if ( null != segment . getMergedLoadName ( ) ) { segments . add ( Segment . toSegment ( segment . getMergedLoadName ( ) , null ) ) ; } else { segments . add ( Segment . toSegment ( segment . getLoadName ( ) , null ) ) ; } } return segments ; } public static List < Segment > getValidSegmentList ( CarbonTable carbonTable ) throws IOException { SegmentStatusManager . ValidAndInvalidSegmentsInfo validAndInvalidSegments = null ; try { validAndInvalidSegments = new SegmentStatusManager ( carbonTable . getAbsoluteTableIdentifier ( ) ) . getValidAndInvalidSegments ( carbonTable . isMV ( ) ) ; } catch ( IOException e ) { LOGGER . error ( ""Error while getting valid segment list for a table identifier"" ) ; throw new IOException ( ) ; } return validAndInvalidSegments . getValidSegments ( ) ; } public static List < LoadMetadataDetails > filterOutNewlyAddedSegments ( List < LoadMetadataDetails > segments , LoadMetadataDetails lastSeg ) { List < LoadMetadataDetails > list = new ArrayList < > ( segments ) ; CarbonDataMergerUtil . sortSegments ( list ) ; return list . subList ( 0 , list . indexOf ( lastSeg ) + 1 ) ; } private static List < LoadMetadataDetails > identifySegmentsToBeMergedBasedOnIUD ( List < LoadMetadataDetails > segments , CarbonLoadModel carbonLoadModel ) { List < LoadMetadataDetails > validSegments = new ArrayList < > ( segments . size ( ) ) ; AbsoluteTableIdentifier absoluteTableIdentifier = carbonLoadModel . getCarbonDataLoadSchema ( ) . getCarbonTable ( ) . getAbsoluteTableIdentifier ( ) ; int numberUpdateDeltaFilesThreshold = CarbonProperties . getInstance ( ) . getNoUpdateDeltaFilesThresholdForIUDCompaction ( ) ; for ( LoadMetadataDetails seg : segments ) { if ( ( isSegmentValid ( seg ) ) && checkUpdateDeltaFilesInSeg ( new Segment ( seg . getLoadName ( ) , seg . getSegmentFile ( ) ) , absoluteTableIdentifier , carbonLoadModel . getSegmentUpdateStatusManager ( ) , numberUpdateDeltaFilesThreshold ) ) { validSegments . add ( seg ) ; } } return validSegments ; } private static boolean isSegmentValid ( LoadMetadataDetails seg ) { return seg . getSegmentStatus ( ) == SegmentStatus . SUCCESS || seg . getSegmentStatus ( ) == SegmentStatus . LOAD_PARTIAL_SUCCESS || seg . getSegmentStatus ( ) == SegmentStatus . MARKED_FOR_UPDATE ; } public static List < String > getSegListIUDCompactionQualified ( List < Segment > segments , AbsoluteTableIdentifier absoluteTableIdentifier , SegmentUpdateStatusManager segmentUpdateStatusManager , CompactionType compactionTypeIUD ) { List < String > validSegments = new ArrayList < > ( ) ; if ( CompactionType . IUD_DELETE_DELTA == compactionTypeIUD ) { int numberDeleteDeltaFilesThreshold = CarbonProperties . getInstance ( ) . getNoDeleteDeltaFilesThresholdForIUDCompaction ( ) ; List < Segment > deleteSegments = new ArrayList < > ( ) ; for ( Segment seg : segments ) { if ( checkDeleteDeltaFilesInSeg ( seg , segmentUpdateStatusManager , numberDeleteDeltaFilesThreshold ) ) { deleteSegments . add ( seg ) ; } } if ( deleteSegments . size ( ) > 0 ) { for ( Segment segName : deleteSegments ) { List < String > tempSegments = getDeleteDeltaFilesInSeg ( segName , segmentUpdateStatusManager , numberDeleteDeltaFilesThreshold ) ; validSegments . addAll ( tempSegments ) ; } } } else if ( CompactionType . IUD_UPDDEL_DELTA == compactionTypeIUD ) { int numberUpdateDeltaFilesThreshold = CarbonProperties . getInstance ( ) . getNoUpdateDeltaFilesThresholdForIUDCompaction ( ) ; for ( Segment seg : segments ) { if ( checkUpdateDeltaFilesInSeg ( seg , absoluteTableIdentifier , segmentUpdateStatusManager , numberUpdateDeltaFilesThreshold ) ) { validSegments . add ( seg . getSegmentNo ( ) ) ; } } } return validSegments ; } public static Boolean checkUpdateDeltaMatchBlock ( final String seg , final String blkName , SegmentUpdateStatusManager segmentUpdateStatusManager ) { List < String > list = segmentUpdateStatusManager . getUpdateDeltaFiles ( seg ) ; String [ ] FileParts = blkName . split ( CarbonCommonConstants . FILE_SEPARATOR ) ; String blockName = FileParts [ FileParts . length - 1 ] ; for ( String str : list ) { if ( str . contains ( blockName ) ) { return true ; } } return false ; } private static Boolean checkUpdateDeltaFilesInSeg ( Segment seg , AbsoluteTableIdentifier identifier , SegmentUpdateStatusManager segmentUpdateStatusManager , int numberDeltaFilesThreshold ) { CarbonFile [ ] updateDeltaFiles = null ; Set < String > uniqueBlocks = new HashSet < String > ( ) ; String segmentPath = CarbonTablePath . getSegmentPath ( identifier . getTablePath ( ) , seg . getSegmentNo ( ) ) ; CarbonFile segDir = FileFactory . getCarbonFile ( segmentPath ) ; CarbonFile [ ] allSegmentFiles = segDir . listFiles ( ) ; updateDeltaFiles = segmentUpdateStatusManager . getUpdateDeltaFilesForSegment ( seg . getSegmentNo ( ) , true , CarbonCommonConstants . UPDATE_DELTA_FILE_EXT , false , allSegmentFiles ) ; if ( updateDeltaFiles == null ) { return false ; } for ( CarbonFile blocks : updateDeltaFiles ) { String task = CarbonTablePath . DataFileUtil . getTaskNo ( blocks . getName ( ) ) ; String timestamp = CarbonTablePath . DataFileUtil . getTimeStampFromDeleteDeltaFile ( blocks . getName ( ) ) ; String taskAndTimeStamp = task + ""-"" + timestamp ; uniqueBlocks . add ( taskAndTimeStamp ) ; } if ( uniqueBlocks . size ( ) > numberDeltaFilesThreshold ) { return true ; } else { return false ; } } private static boolean checkDeleteDeltaFilesInSeg ( Segment seg , SegmentUpdateStatusManager segmentUpdateStatusManager , int numberDeltaFilesThreshold ) { Set < String > uniqueBlocks = new HashSet < String > ( ) ; List < String > blockNameList = segmentUpdateStatusManager . getBlockNameFromSegment ( seg . getSegmentNo ( ) ) ; for ( final String blockName : blockNameList ) { CarbonFile [ ] deleteDeltaFiles = segmentUpdateStatusManager . getDeleteDeltaFilesList ( seg , blockName ) ; if ( null != deleteDeltaFiles ) { for ( CarbonFile blocks : deleteDeltaFiles ) { String task = CarbonTablePath . DataFileUtil . getTaskNo ( blocks . getName ( ) ) ; String timestamp = CarbonTablePath . DataFileUtil . getTimeStampFromDeleteDeltaFile ( blocks . getName ( ) ) ; String taskAndTimeStamp = task + ""-"" + timestamp ; uniqueBlocks . add ( taskAndTimeStamp ) ; } if ( uniqueBlocks . size ( ) > numberDeltaFilesThreshold ) { return true ; } } } return false ; } private static List < String > getDeleteDeltaFilesInSeg ( Segment seg , SegmentUpdateStatusManager segmentUpdateStatusManager , int numberDeltaFilesThreshold ) { List < String > blockLists = new ArrayList < > ( ) ; List < String > blockNameList = segmentUpdateStatusManager . getBlockNameFromSegment ( seg . getSegmentNo ( ) ) ; for ( final String blockName : blockNameList ) { CarbonFile [ ] deleteDeltaFiles = segmentUpdateStatusManager . getDeleteDeltaFilesList ( seg , blockName ) ; if ( null != deleteDeltaFiles && ( deleteDeltaFiles . length > numberDeltaFilesThreshold ) ) { blockLists . add ( seg . getSegmentNo ( ) + ""/"" + blockName ) ; } } return blockLists ; } public static boolean isHorizontalCompactionEnabled ( ) { if ( ( CarbonProperties . getInstance ( ) . getProperty ( CarbonCommonConstants . CARBON_HORIZONTAL_COMPACTION_ENABLE , CarbonCommonConstants . CARBON_HORIZONTAL_COMPACTION_ENABLE_DEFAULT ) ) . equalsIgnoreCase ( ""true"" ) ) { return true ; } else { return false ; } } public static List < CarbonDataMergerUtilResult > compactBlockDeleteDeltaFiles ( String seg , String blockName , CarbonTable table , SegmentUpdateDetails [ ] segmentUpdateDetails , Long timestamp ) throws IOException { SegmentUpdateStatusManager segmentUpdateStatusManager = new SegmentUpdateStatusManager ( table ) ; List < CarbonDataMergerUtilResult > resultList = new ArrayList < CarbonDataMergerUtilResult > ( 1 ) ; segmentUpdateStatusManager . setUpdateStatusDetails ( segmentUpdateDetails ) ; CarbonFile [ ] deleteDeltaFiles = segmentUpdateStatusManager . getDeleteDeltaFilesList ( new Segment ( seg ) , blockName ) ; String destFileName = blockName + ""-"" + timestamp . toString ( ) + CarbonCommonConstants . DELETE_DELTA_FILE_EXT ; List < String > deleteFilePathList = new ArrayList < > ( ) ; if ( null != deleteDeltaFiles && deleteDeltaFiles . length > 0 && null != deleteDeltaFiles [ 0 ] . getParentFile ( ) ) { String fullBlockFilePath = deleteDeltaFiles [ 0 ] . getParentFile ( ) . getCanonicalPath ( ) + CarbonCommonConstants . FILE_SEPARATOR + destFileName ; for ( CarbonFile cFile : deleteDeltaFiles ) { deleteFilePathList . add ( cFile . getCanonicalPath ( ) ) ; } CarbonDataMergerUtilResult blockDetails = new CarbonDataMergerUtilResult ( ) ; blockDetails . setBlockName ( blockName ) ; blockDetails . setSegmentName ( seg ) ; blockDetails . setDeleteDeltaStartTimestamp ( timestamp . toString ( ) ) ; blockDetails . setDeleteDeltaEndTimestamp ( timestamp . toString ( ) ) ; try { startCompactionDeleteDeltaFiles ( deleteFilePathList , blockName , fullBlockFilePath ) ; blockDetails . setCompactionStatus ( true ) ; resultList . add ( blockDetails ) ; } catch ( IOException e ) { LOGGER . error ( ""Compaction of Delete Delta Files failed. The complete file path is "" + fullBlockFilePath ) ; throw new IOException ( ) ; } } return resultList ; } public static void startCompactionDeleteDeltaFiles ( List < String > deleteDeltaFiles , String blockName , String fullBlockFilePath ) throws IOException { DeleteDeltaBlockDetails deleteDeltaBlockDetails = null ; int numberOfcores = CarbonProperties . getInstance ( ) . getNumberOfCompactingCores ( ) ; CarbonDeleteFilesDataReader dataReader = new CarbonDeleteFilesDataReader ( numberOfcores ) ; try { deleteDeltaBlockDetails = dataReader . getCompactedDeleteDeltaFileFromBlock ( deleteDeltaFiles , blockName ) ; } catch ( Exception e ) { String blockFilePath = fullBlockFilePath . substring ( 0 , fullBlockFilePath . lastIndexOf ( CarbonCommonConstants . FILE_SEPARATOR ) ) ; LOGGER . error ( ""Error while getting the delete delta blocks in path "" + blockFilePath ) ; throw new IOException ( ) ; } CarbonDeleteDeltaWriterImpl carbonDeleteWriter = new CarbonDeleteDeltaWriterImpl ( fullBlockFilePath ) ; try { carbonDeleteWriter . write ( deleteDeltaBlockDetails ) ; } catch ( IOException e ) { LOGGER . error ( ""Error while writing compacted delete delta file "" + fullBlockFilePath ) ; throw new IOException ( ) ; } } public static Boolean updateStatusFile ( List < CarbonDataMergerUtilResult > updateDataMergerDetailsList , CarbonTable table , String timestamp , SegmentUpdateStatusManager segmentUpdateStatusManager ) { List < SegmentUpdateDetails > segmentUpdateDetails = new ArrayList < SegmentUpdateDetails > ( updateDataMergerDetailsList . size ( ) ) ; for ( CarbonDataMergerUtilResult carbonDataMergerUtilResult : updateDataMergerDetailsList ) { if ( carbonDataMergerUtilResult . getCompactionStatus ( ) ) { SegmentUpdateDetails tempSegmentUpdateDetails = new SegmentUpdateDetails ( ) ; tempSegmentUpdateDetails . setSegmentName ( carbonDataMergerUtilResult . getSegmentName ( ) ) ; tempSegmentUpdateDetails . setBlockName ( carbonDataMergerUtilResult . getBlockName ( ) ) ; for ( SegmentUpdateDetails origDetails : segmentUpdateStatusManager . getUpdateStatusDetails ( ) ) { if ( origDetails . getBlockName ( ) . equalsIgnoreCase ( carbonDataMergerUtilResult . getBlockName ( ) ) && origDetails . getSegmentName ( ) . equalsIgnoreCase ( carbonDataMergerUtilResult . getSegmentName ( ) ) ) { tempSegmentUpdateDetails . setDeletedRowsInBlock ( origDetails . getDeletedRowsInBlock ( ) ) ; tempSegmentUpdateDetails . setSegmentStatus ( origDetails . getSegmentStatus ( ) ) ; break ; } } tempSegmentUpdateDetails . setDeleteDeltaStartTimestamp ( carbonDataMergerUtilResult . getDeleteDeltaStartTimestamp ( ) ) ; tempSegmentUpdateDetails . setDeleteDeltaEndTimestamp ( carbonDataMergerUtilResult . getDeleteDeltaEndTimestamp ( ) ) ; segmentUpdateDetails . add ( tempSegmentUpdateDetails ) ; } else return false ; } CarbonUpdateUtil . updateSegmentStatus ( segmentUpdateDetails , table , timestamp , true ) ; String metaDataFilepath = table . getMetadataPath ( ) ; AbsoluteTableIdentifier identifier = table . getAbsoluteTableIdentifier ( ) ; String tableStatusPath = CarbonTablePath . getTableStatusFilePath ( identifier . getTablePath ( ) ) ; SegmentStatusManager segmentStatusManager = new SegmentStatusManager ( identifier ) ; ICarbonLock carbonLock = segmentStatusManager . getTableStatusLock ( ) ; boolean lockStatus = false ; try { lockStatus = carbonLock . lockWithRetries ( ) ; if ( lockStatus ) { LOGGER . info ( ""Acquired lock for table"" + table . getDatabaseName ( ) + ""."" + table . getTableName ( ) + "" for table status updation"" ) ; LoadMetadataDetails [ ] listOfLoadFolderDetailsArray = SegmentStatusManager . readLoadMetadata ( metaDataFilepath ) ; for ( LoadMetadataDetails loadMetadata : listOfLoadFolderDetailsArray ) { if ( loadMetadata . getLoadName ( ) . equalsIgnoreCase ( ""0"" ) ) { loadMetadata . setUpdateStatusFileName ( CarbonUpdateUtil . getUpdateStatusFileName ( timestamp ) ) ; } } try { SegmentStatusManager . writeLoadDetailsIntoFile ( tableStatusPath , listOfLoadFolderDetailsArray ) ; } catch ( IOException e ) { return false ; } } else { LOGGER . error ( ""Not able to acquire the lock for Table status updation for table "" + table . getDatabaseName ( ) + ""."" + table . getTableName ( ) ) ; } } finally { if ( lockStatus ) { if ( carbonLock . unlock ( ) ) { LOGGER . info ( ""Table unlocked successfully after table status updation"" + table . getDatabaseName ( ) + ""."" + table . getTableName ( ) ) ; } else { LOGGER . error ( ""Unable to unlock Table lock for table"" + table . getDatabaseName ( ) + ""."" + table . getTableName ( ) + "" during table status updation"" ) ; } } } return true ; } }",Smelly
"@ Category ( IntegrationTest . class ) public class TestInsertQuery extends QueryTestCaseBase { @ Test public final void testInsertOverwrite ( ) throws Exception { ResultSet res = executeFile ( ""table1_ddl.sql"" ) ; res . close ( ) ; CatalogService catalog = testingCluster . getMaster ( ) . getCatalog ( ) ; assertTrue ( catalog . existsTable ( getCurrentDatabase ( ) , ""table1"" ) ) ; res = executeFile ( ""testInsertOverwrite.sql"" ) ; res . close ( ) ; TableDesc desc = catalog . getTableDesc ( getCurrentDatabase ( ) , ""table1"" ) ; if ( ! testingCluster . isHiveCatalogStoreRunning ( ) ) { assertEquals ( 5 , desc . getStats ( ) . getNumRows ( ) . intValue ( ) ) ; } executeString ( ""DROP TABLE table1 PURGE"" ) ; } @ Test public final void testInsertInto ( ) throws Exception { ResultSet res = executeFile ( ""table1_ddl.sql"" ) ; res . close ( ) ; CatalogService catalog = testingCluster . getMaster ( ) . getCatalog ( ) ; assertTrue ( catalog . existsTable ( getCurrentDatabase ( ) , ""table1"" ) ) ; res = executeFile ( ""testInsertOverwrite.sql"" ) ; res . close ( ) ; TableDesc desc = catalog . getTableDesc ( getCurrentDatabase ( ) , ""table1"" ) ; if ( ! testingCluster . isHiveCatalogStoreRunning ( ) ) { assertEquals ( 5 , desc . getStats ( ) . getNumRows ( ) . intValue ( ) ) ; } res = executeFile ( ""testInsertInto.sql"" ) ; res . close ( ) ; List < Path > dataFiles = listTableFiles ( ""table1"" ) ; assertEquals ( 2 , dataFiles . size ( ) ) ; for ( int i = 0 ; i < dataFiles . size ( ) ; i ++ ) { String name = dataFiles . get ( i ) . getName ( ) ; assertTrue ( name . matches ( ""part-[0-9]*-[0-9]*-[0-9]*"" ) ) ; String [ ] tokens = name . split ( ""-"" ) ; assertEquals ( 4 , tokens . length ) ; assertEquals ( i , Integer . parseInt ( tokens [ 3 ] ) ) ; } String tableDatas = getTableFileContents ( ""table1"" ) ; String expected = ""1|1|17.0\n"" + ""1|1|36.0\n"" + ""2|2|38.0\n"" + ""3|2|45.0\n"" + ""3|3|49.0\n"" + ""1|1|17.0\n"" + ""1|1|36.0\n"" + ""2|2|38.0\n"" + ""3|2|45.0\n"" + ""3|3|49.0\n"" ; assertNotNull ( tableDatas ) ; assertEquals ( expected , tableDatas ) ; executeString ( ""DROP TABLE table1 PURGE"" ) ; } @ Test public final void testInsertIntoLocation ( ) throws Exception { Path dfsPath = new Path ( ""/tajo-data/testInsertIntoLocation"" ) ; assertTestInsertIntoLocation ( dfsPath ) ; } @ Test public final void testInsertIntoLocationDifferentFSs ( ) throws Exception { Path localPath = CommonTestingUtil . getTestDir ( ) ; assertTestInsertIntoLocation ( localPath ) ; } public final void assertTestInsertIntoLocation ( Path path ) throws Exception { FileSystem fs = null ; try { executeString ( ""insert into location '"" + path + ""' select l_orderkey, l_partkey, l_linenumber from default.lineitem"" ) . close ( ) ; String resultFileData = getTableFileContents ( path ) ; String expected = ""1|1|1\n"" + ""1|1|2\n"" + ""2|2|1\n"" + ""3|2|1\n"" + ""3|3|2\n"" ; assertEquals ( expected , resultFileData ) ; fs = path . getFileSystem ( testingCluster . getConfiguration ( ) ) ; FileStatus [ ] files = fs . listStatus ( path ) ; assertNotNull ( files ) ; assertEquals ( 1 , files . length ) ; for ( FileStatus eachFileStatus : files ) { String name = eachFileStatus . getPath ( ) . getName ( ) ; assertTrue ( name . matches ( ""part-[0-9]*-[0-9]*-[0-9]*"" ) ) ; } executeString ( ""insert into location '"" + path + ""' select l_orderkey, l_partkey, l_linenumber from default.lineitem"" ) . close ( ) ; resultFileData = getTableFileContents ( path ) ; expected = ""1|1|1\n"" + ""1|1|2\n"" + ""2|2|1\n"" + ""3|2|1\n"" + ""3|3|2\n"" ; assertEquals ( expected + expected , resultFileData ) ; files = fs . listStatus ( path ) ; assertNotNull ( files ) ; assertEquals ( 2 , files . length ) ; for ( FileStatus eachFileStatus : files ) { String name = eachFileStatus . getPath ( ) . getName ( ) ; assertTrue ( name . matches ( ""part-[0-9]*-[0-9]*-[0-9]*"" ) ) ; } } finally { if ( fs != null ) { fs . delete ( path , true ) ; } } } @ Test public final void testInsertIntoPartitionedTable ( ) throws Exception { String tableName = CatalogUtil . normalizeIdentifier ( ""testInsertIntoPartitionedTable"" ) ; executeString ( ""create table "" + tableName + "" (n_name TEXT, n_regionkey INT4)"" + ""USING csv PARTITION by column(n_nationkey INT4)"" ) . close ( ) ; try { executeString ( ""insert into "" + tableName + "" select n_name, n_regionkey, n_nationkey from default.nation"" ) . close ( ) ; ResultSet res = executeString ( ""select * from "" + tableName ) ; String expected = ""n_name,n_regionkey,n_nationkey\n"" + ""-------------------------------\n"" + ""ALGERIA,0,0\n"" + ""ARGENTINA,1,1\n"" + ""IRAN,4,10\n"" + ""IRAQ,4,11\n"" + ""JAPAN,2,12\n"" + ""JORDAN,4,13\n"" + ""KENYA,0,14\n"" + ""MOROCCO,0,15\n"" + ""MOZAMBIQUE,0,16\n"" + ""PERU,1,17\n"" + ""CHINA,2,18\n"" + ""ROMANIA,3,19\n"" + ""BRAZIL,1,2\n"" + ""SAUDI ARABIA,4,20\n"" + ""VIETNAM,2,21\n"" + ""RUSSIA,3,22\n"" + ""UNITED KINGDOM,3,23\n"" + ""UNITED STATES,1,24\n"" + ""CANADA,1,3\n"" + ""EGYPT,4,4\n"" + ""ETHIOPIA,0,5\n"" + ""FRANCE,3,6\n"" + ""GERMANY,3,7\n"" + ""INDIA,2,8\n"" + ""INDONESIA,2,9\n"" ; assertEquals ( expected , resultSetToString ( res ) ) ; res . close ( ) ; executeString ( ""insert into "" + tableName + "" select n_name, n_regionkey, n_nationkey from default.nation"" ) . close ( ) ; res = executeString ( ""select * from "" + tableName ) ; expected = ""n_name,n_regionkey,n_nationkey\n"" + ""-------------------------------\n"" + ""ALGERIA,0,0\n"" + ""ALGERIA,0,0\n"" + ""ARGENTINA,1,1\n"" + ""ARGENTINA,1,1\n"" + ""IRAN,4,10\n"" + ""IRAN,4,10\n"" + ""IRAQ,4,11\n"" + ""IRAQ,4,11\n"" + ""JAPAN,2,12\n"" + ""JAPAN,2,12\n"" + ""JORDAN,4,13\n"" + ""JORDAN,4,13\n"" + ""KENYA,0,14\n"" + ""KENYA,0,14\n"" + ""MOROCCO,0,15\n"" + ""MOROCCO,0,15\n"" + ""MOZAMBIQUE,0,16\n"" + ""MOZAMBIQUE,0,16\n"" + ""PERU,1,17\n"" + ""PERU,1,17\n"" + ""CHINA,2,18\n"" + ""CHINA,2,18\n"" + ""ROMANIA,3,19\n"" + ""ROMANIA,3,19\n"" + ""BRAZIL,1,2\n"" + ""BRAZIL,1,2\n"" + ""SAUDI ARABIA,4,20\n"" + ""SAUDI ARABIA,4,20\n"" + ""VIETNAM,2,21\n"" + ""VIETNAM,2,21\n"" + ""RUSSIA,3,22\n"" + ""RUSSIA,3,22\n"" + ""UNITED KINGDOM,3,23\n"" + ""UNITED KINGDOM,3,23\n"" + ""UNITED STATES,1,24\n"" + ""UNITED STATES,1,24\n"" + ""CANADA,1,3\n"" + ""CANADA,1,3\n"" + ""EGYPT,4,4\n"" + ""EGYPT,4,4\n"" + ""ETHIOPIA,0,5\n"" + ""ETHIOPIA,0,5\n"" + ""FRANCE,3,6\n"" + ""FRANCE,3,6\n"" + ""GERMANY,3,7\n"" + ""GERMANY,3,7\n"" + ""INDIA,2,8\n"" + ""INDIA,2,8\n"" + ""INDONESIA,2,9\n"" + ""INDONESIA,2,9\n"" ; assertEquals ( expected , resultSetToString ( res ) ) ; TableDesc tableDesc = testingCluster . getMaster ( ) . getCatalog ( ) . getTableDesc ( getCurrentDatabase ( ) , tableName ) ; assertNotNull ( tableDesc ) ; Path path = new Path ( tableDesc . getUri ( ) ) ; FileSystem fs = path . getFileSystem ( testingCluster . getConfiguration ( ) ) ; FileStatus [ ] files = fs . listStatus ( path ) ; assertNotNull ( files ) ; assertEquals ( 25 , files . length ) ; for ( FileStatus eachFileStatus : files ) { assertTrue ( eachFileStatus . getPath ( ) . getName ( ) . indexOf ( ""n_nationkey="" ) == 0 ) ; FileStatus [ ] dataFiles = fs . listStatus ( eachFileStatus . getPath ( ) ) ; assertEquals ( 2 , dataFiles . length ) ; for ( FileStatus eachDataFileStatus : dataFiles ) { String name = eachDataFileStatus . getPath ( ) . getName ( ) ; assertTrue ( name . matches ( ""part-[0-9]*-[0-9]*-[0-9]*"" ) ) ; } } } finally { executeString ( ""DROP TABLE "" + tableName + "" PURGE"" ) ; } } @ Test public final void testInsertOverwriteSmallerColumns ( ) throws Exception { ResultSet res = executeFile ( ""table1_ddl.sql"" ) ; res . close ( ) ; CatalogService catalog = testingCluster . getMaster ( ) . getCatalog ( ) ; assertTrue ( catalog . existsTable ( getCurrentDatabase ( ) , ""table1"" ) ) ; TableDesc originalDesc = catalog . getTableDesc ( getCurrentDatabase ( ) , ""table1"" ) ; res = executeFile ( ""testInsertOverwriteSmallerColumns.sql"" ) ; res . close ( ) ; TableDesc desc = catalog . getTableDesc ( getCurrentDatabase ( ) , ""table1"" ) ; if ( ! testingCluster . isHiveCatalogStoreRunning ( ) ) { assertEquals ( 5 , desc . getStats ( ) . getNumRows ( ) . intValue ( ) ) ; } assertEquals ( originalDesc . getSchema ( ) , desc . getSchema ( ) ) ; executeString ( ""DROP TABLE table1 PURGE"" ) ; } @ Test public final void testInsertOverwriteWithTargetColumns ( ) throws Exception { ResultSet res = executeFile ( ""table1_ddl.sql"" ) ; res . close ( ) ; CatalogService catalog = testingCluster . getMaster ( ) . getCatalog ( ) ; assertTrue ( catalog . existsTable ( getCurrentDatabase ( ) , ""table1"" ) ) ; TableDesc originalDesc = catalog . getTableDesc ( getCurrentDatabase ( ) , ""table1"" ) ; res = executeFile ( ""testInsertOverwriteWithTargetColumns.sql"" ) ; res . close ( ) ; TableDesc desc = catalog . getTableDesc ( getCurrentDatabase ( ) , ""table1"" ) ; if ( ! testingCluster . isHiveCatalogStoreRunning ( ) ) { assertEquals ( 5 , desc . getStats ( ) . getNumRows ( ) . intValue ( ) ) ; } res = executeString ( ""select * from "" + CatalogUtil . denormalizeIdentifier ( getCurrentDatabase ( ) ) + "".table1"" ) ; assertTrue ( res . next ( ) ) ; assertEquals ( 1 , res . getLong ( 1 ) ) ; assertTrue ( 0f == res . getFloat ( 2 ) ) ; assertTrue ( res . wasNull ( ) ) ; assertTrue ( 17.0 == res . getFloat ( 3 ) ) ; assertTrue ( res . next ( ) ) ; assertEquals ( 1 , res . getLong ( 1 ) ) ; assertTrue ( 0f == res . getFloat ( 2 ) ) ; assertTrue ( res . wasNull ( ) ) ; assertTrue ( 36.0 == res . getFloat ( 3 ) ) ; assertTrue ( res . next ( ) ) ; assertEquals ( 2 , res . getLong ( 1 ) ) ; assertTrue ( 0f == res . getFloat ( 2 ) ) ; assertTrue ( res . wasNull ( ) ) ; assertTrue ( 38.0 == res . getFloat ( 3 ) ) ; assertTrue ( res . next ( ) ) ; assertTrue ( 0f == res . getFloat ( 2 ) ) ; assertTrue ( res . wasNull ( ) ) ; assertTrue ( 45.0 == res . getFloat ( 3 ) ) ; assertTrue ( res . next ( ) ) ; assertEquals ( 3 , res . getLong ( 1 ) ) ; assertTrue ( 0f == res . getFloat ( 2 ) ) ; assertTrue ( res . wasNull ( ) ) ; assertTrue ( 49.0 == res . getFloat ( 3 ) ) ; assertFalse ( res . next ( ) ) ; res . close ( ) ; assertEquals ( originalDesc . getSchema ( ) , desc . getSchema ( ) ) ; executeString ( ""DROP TABLE table1 PURGE"" ) ; } @ Test public final void testInsertOverwriteWithAsterisk ( ) throws Exception { ResultSet res = executeFile ( ""full_table_csv_ddl.sql"" ) ; res . close ( ) ; CatalogService catalog = testingCluster . getMaster ( ) . getCatalog ( ) ; assertTrue ( catalog . existsTable ( getCurrentDatabase ( ) , ""full_table_csv"" ) ) ; res = executeString ( ""insert overwrite into full_table_csv select * from default.lineitem where l_orderkey = 3"" ) ; res . close ( ) ; TableDesc desc = catalog . getTableDesc ( getCurrentDatabase ( ) , ""full_table_csv"" ) ; if ( ! testingCluster . isHiveCatalogStoreRunning ( ) ) { assertEquals ( 2 , desc . getStats ( ) . getNumRows ( ) . intValue ( ) ) ; } executeString ( ""DROP TABLE full_table_csv PURGE"" ) ; } @ Test public final void testInsertOverwriteWithAsteriskAndMore ( ) throws Exception { ResultSet res = executeFile ( ""lineitem_year_month_ddl.sql"" ) ; res . close ( ) ; CatalogService catalog = testingCluster . getMaster ( ) . getCatalog ( ) ; assertTrue ( catalog . existsTable ( getCurrentDatabase ( ) , ""lineitem_year_month"" ) ) ; res = executeFile ( ""load_to_lineitem_year_month.sql"" ) ; res . close ( ) ; TableDesc desc = catalog . getTableDesc ( getCurrentDatabase ( ) , ""lineitem_year_month"" ) ; if ( ! testingCluster . isHiveCatalogStoreRunning ( ) ) { assertEquals ( 5 , desc . getStats ( ) . getNumRows ( ) . intValue ( ) ) ; } res = executeQuery ( ) ; assertResultSet ( res ) ; res . close ( ) ; executeString ( ""DROP TABLE lineitem_year_month PURGE"" ) ; } @ Test public final void testInsertOverwriteIntoSelect ( ) throws Exception { String tableName = CatalogUtil . normalizeIdentifier ( ""insertoverwriteintoselect"" ) ; ResultSet res = executeString ( ""create table "" + tableName + "" as select l_orderkey from default.lineitem"" ) ; assertFalse ( res . next ( ) ) ; res . close ( ) ; CatalogService catalog = testingCluster . getMaster ( ) . getCatalog ( ) ; assertTrue ( catalog . existsTable ( getCurrentDatabase ( ) , tableName ) ) ; TableDesc orderKeys = catalog . getTableDesc ( getCurrentDatabase ( ) , tableName ) ; if ( ! testingCluster . isHiveCatalogStoreRunning ( ) ) { assertEquals ( 5 , orderKeys . getStats ( ) . getNumRows ( ) . intValue ( ) ) ; } res = executeString ( ""insert overwrite into "" + tableName + "" select l_orderkey from default.lineitem where l_orderkey = 3"" ) ; assertFalse ( res . next ( ) ) ; res . close ( ) ; assertTrue ( catalog . existsTable ( getCurrentDatabase ( ) , tableName ) ) ; orderKeys = catalog . getTableDesc ( getCurrentDatabase ( ) , tableName ) ; if ( ! testingCluster . isHiveCatalogStoreRunning ( ) ) { assertEquals ( 2 , orderKeys . getStats ( ) . getNumRows ( ) . intValue ( ) ) ; } executeString ( ""DROP TABLE "" + tableName + "" PURGE"" ) ; } @ Test public final void testInsertOverwriteCapitalTableName ( ) throws Exception { String tableName = CatalogUtil . normalizeIdentifier ( ""testInsertOverwriteCapitalTableName"" ) ; ResultSet res = executeString ( ""create table "" + tableName + "" as select * from default.lineitem"" ) ; res . close ( ) ; CatalogService catalog = testingCluster . getMaster ( ) . getCatalog ( ) ; assertTrue ( catalog . existsTable ( getCurrentDatabase ( ) , tableName ) ) ; res = executeString ( ""insert overwrite into "" + tableName + "" select * from default.lineitem where l_orderkey = 3"" ) ; res . close ( ) ; TableDesc desc = catalog . getTableDesc ( getCurrentDatabase ( ) , tableName ) ; if ( ! testingCluster . isHiveCatalogStoreRunning ( ) ) { assertEquals ( 2 , desc . getStats ( ) . getNumRows ( ) . intValue ( ) ) ; } executeString ( ""DROP TABLE "" + tableName + "" PURGE"" ) ; } @ Test public final void testInsertOverwriteLocation ( ) throws Exception { ResultSet res = executeQuery ( ) ; res . close ( ) ; FileSystem fs = FileSystem . get ( testingCluster . getConfiguration ( ) ) ; assertTrue ( fs . exists ( new Path ( ""/tajo-data/testInsertOverwriteCapitalTableName"" ) ) ) ; assertEquals ( 1 , fs . listStatus ( new Path ( ""/tajo-data/testInsertOverwriteCapitalTableName"" ) ) . length ) ; } @ Test public final void testInsertOverwriteWithCompression ( ) throws Exception { String tableName = CatalogUtil . normalizeIdentifier ( ""testInsertOverwriteWithCompression"" ) ; ResultSet res = executeFile ( ""testInsertOverwriteWithCompression_ddl.sql"" ) ; res . close ( ) ; CatalogService catalog = testingCluster . getMaster ( ) . getCatalog ( ) ; assertTrue ( catalog . existsTable ( getCurrentDatabase ( ) , tableName ) ) ; res = executeQuery ( ) ; res . close ( ) ; TableDesc desc = catalog . getTableDesc ( getCurrentDatabase ( ) , tableName ) ; if ( ! testingCluster . isHiveCatalogStoreRunning ( ) ) { assertEquals ( 2 , desc . getStats ( ) . getNumRows ( ) . intValue ( ) ) ; } FileSystem fs = FileSystem . get ( testingCluster . getConfiguration ( ) ) ; assertTrue ( fs . exists ( new Path ( desc . getUri ( ) ) ) ) ; CompressionCodecFactory factory = new CompressionCodecFactory ( testingCluster . getConfiguration ( ) ) ; for ( FileStatus file : fs . listStatus ( new Path ( desc . getUri ( ) ) ) ) { CompressionCodec codec = factory . getCodec ( file . getPath ( ) ) ; assertTrue ( codec instanceof DeflateCodec ) ; } executeString ( ""DROP TABLE "" + tableName + "" PURGE"" ) ; } @ Test public final void testInsertOverwriteLocationWithCompression ( ) throws Exception { if ( ! testingCluster . isHiveCatalogStoreRunning ( ) ) { ResultSet res = executeQuery ( ) ; res . close ( ) ; FileSystem fs = FileSystem . get ( testingCluster . getConfiguration ( ) ) ; Path path = new Path ( ""/tajo-data/testInsertOverwriteLocationWithCompression"" ) ; assertTrue ( fs . exists ( path ) ) ; assertEquals ( 1 , fs . listStatus ( path ) . length ) ; CompressionCodecFactory factory = new CompressionCodecFactory ( testingCluster . getConfiguration ( ) ) ; for ( FileStatus file : fs . listStatus ( path ) ) { CompressionCodec codec = factory . getCodec ( file . getPath ( ) ) ; assertTrue ( codec instanceof DeflateCodec ) ; } } } @ Test public final void testInsertOverwriteWithAsteriskUsingParquet ( ) throws Exception { if ( ! testingCluster . isHiveCatalogStoreRunning ( ) ) { ResultSet res = executeFile ( ""full_table_parquet_ddl.sql"" ) ; res . close ( ) ; CatalogService catalog = testingCluster . getMaster ( ) . getCatalog ( ) ; assertTrue ( catalog . existsTable ( getCurrentDatabase ( ) , ""full_table_parquet"" ) ) ; res = executeString ( ""insert overwrite into full_table_parquet select * from default.lineitem where l_orderkey = 3"" ) ; res . close ( ) ; TableDesc desc = catalog . getTableDesc ( getCurrentDatabase ( ) , ""full_table_parquet"" ) ; if ( ! testingCluster . isHiveCatalogStoreRunning ( ) ) { assertEquals ( 2 , desc . getStats ( ) . getNumRows ( ) . intValue ( ) ) ; } res = executeString ( ""select * from full_table_parquet;"" ) ; assertResultSet ( res ) ; res = executeString ( ""select l_orderkey, l_partkey from full_table_parquet;"" ) ; assertResultSet ( res , ""testInsertOverwriteWithAsteriskUsingParquet2.result"" ) ; executeString ( ""DROP TABLE full_table_parquet PURGE"" ) ; } } @ Test public final void testInsertOverwriteIntoParquet ( ) throws Exception { if ( ! testingCluster . isHiveCatalogStoreRunning ( ) ) { executeString ( ""create table parquet_table "" + ""(l_orderkey int4, l_shipdate text, l_shipdate_function text) using parquet"" ) . close ( ) ; CatalogService catalog = testingCluster . getMaster ( ) . getCatalog ( ) ; assertTrue ( catalog . existsTable ( getCurrentDatabase ( ) , ""parquet_table"" ) ) ; executeString ( ""insert overwrite into parquet_table  "" + ""select l_orderkey, l_shipdate, substr(l_shipdate, 1, 10) from default.lineitem"" ) . close ( ) ; TableDesc desc = catalog . getTableDesc ( getCurrentDatabase ( ) , ""parquet_table"" ) ; if ( ! testingCluster . isHiveCatalogStoreRunning ( ) ) { assertEquals ( 5 , desc . getStats ( ) . getNumRows ( ) . intValue ( ) ) ; } ResultSet res = executeString ( ""select l_orderkey, l_shipdate, l_shipdate_function "" + ""from parquet_table "" ) ; String expected = ""l_orderkey,l_shipdate,l_shipdate_function\n"" + ""-------------------------------\n"" + ""1,1996-03-13,1996-03-13\n"" + ""1,1996-04-12,1996-04-12\n"" + ""2,1997-01-28,1997-01-28\n"" + ""3,1994-02-02,1994-02-02\n"" + ""3,1993-11-09,1993-11-09\n"" ; assertEquals ( expected , resultSetToString ( res ) ) ; executeString ( ""DROP TABLE parquet_table PURGE"" ) ; } } @ Test public final void testInsertOverwriteIntoPartitionedParquet ( ) throws Exception { if ( ! testingCluster . isHiveCatalogStoreRunning ( ) ) { executeString ( ""create table parquet_table "" + ""(l_orderkey int4, l_shipdate_function text) using parquet partition by column (l_shipdate text)"" ) . close ( ) ; CatalogService catalog = testingCluster . getMaster ( ) . getCatalog ( ) ; assertTrue ( catalog . existsTable ( getCurrentDatabase ( ) , ""parquet_table"" ) ) ; executeString ( ""insert overwrite into parquet_table  "" + ""select l_orderkey, substr(l_shipdate, 1, 10), l_shipdate from default.lineitem"" ) . close ( ) ; TableDesc desc = catalog . getTableDesc ( getCurrentDatabase ( ) , ""parquet_table"" ) ; if ( ! testingCluster . isHiveCatalogStoreRunning ( ) ) { assertEquals ( 5 , desc . getStats ( ) . getNumRows ( ) . intValue ( ) ) ; } ResultSet res = executeString ( ""select l_orderkey, l_shipdate, l_shipdate_function "" + ""from parquet_table "" ) ; String expected = ""l_orderkey,l_shipdate,l_shipdate_function\n"" + ""-------------------------------\n"" + ""3,1993-11-09,1993-11-09\n"" + ""3,1994-02-02,1994-02-02\n"" + ""1,1996-03-13,1996-03-13\n"" + ""1,1996-04-12,1996-04-12\n"" + ""2,1997-01-28,1997-01-28\n"" ; assertEquals ( expected , resultSetToString ( res ) ) ; executeString ( ""DROP TABLE parquet_table PURGE"" ) ; } } @ Test public final void testInsertOverwriteWithDatabase ( ) throws Exception { ResultSet res = executeFile ( ""table1_ddl.sql"" ) ; res . close ( ) ; CatalogService catalog = testingCluster . getMaster ( ) . getCatalog ( ) ; assertTrue ( catalog . existsTable ( getCurrentDatabase ( ) , ""table1"" ) ) ; res = executeQuery ( ) ; res . close ( ) ; TableDesc desc = catalog . getTableDesc ( getCurrentDatabase ( ) , ""table1"" ) ; if ( ! testingCluster . isHiveCatalogStoreRunning ( ) ) { assertEquals ( 5 , desc . getStats ( ) . getNumRows ( ) . intValue ( ) ) ; } executeString ( ""DROP TABLE table1 PURGE"" ) ; } @ Test public final void testInsertOverwriteTableWithNonFromQuery ( ) throws Exception { String tableName = CatalogUtil . normalizeIdentifier ( ""InsertOverwriteWithEvalQuery"" ) ; ResultSet res = executeString ( ""create table "" + tableName + "" (col1 int4, col2 float4, col3 text)"" ) ; res . close ( ) ; CatalogService catalog = testingCluster . getMaster ( ) . getCatalog ( ) ; assertTrue ( catalog . existsTable ( getCurrentDatabase ( ) , tableName ) ) ; res = executeString ( ""insert overwrite into "" + tableName + "" select 1::INT4, 2.1::FLOAT4, 'test'; "" ) ; res . close ( ) ; TableDesc desc = catalog . getTableDesc ( getCurrentDatabase ( ) , tableName ) ; if ( ! testingCluster . isHiveCatalogStoreRunning ( ) ) { assertEquals ( 1 , desc . getStats ( ) . getNumRows ( ) . intValue ( ) ) ; } res = executeString ( ""select * from "" + tableName + "";"" ) ; assertTrue ( res . next ( ) ) ; assertEquals ( 3 , res . getMetaData ( ) . getColumnCount ( ) ) ; assertEquals ( 1 , res . getInt ( 1 ) ) ; assertEquals ( 2.1f , res . getFloat ( 2 ) , 10 ) ; assertEquals ( ""test"" , res . getString ( 3 ) ) ; res . close ( ) ; executeString ( ""DROP TABLE "" + tableName + "" PURGE"" ) ; } @ Test public final void testInsertOverwriteTableWithNonFromQuery2 ( ) throws Exception { String tableName = CatalogUtil . normalizeIdentifier ( ""InsertOverwriteWithEvalQuery2"" ) ; ResultSet res = executeString ( ""create table "" + tableName + "" (col1 int4, col2 float4, col3 text)"" ) ; res . close ( ) ; CatalogService catalog = testingCluster . getMaster ( ) . getCatalog ( ) ; assertTrue ( catalog . existsTable ( getCurrentDatabase ( ) , tableName ) ) ; res = executeString ( ""insert overwrite into "" + tableName + "" (col1, col3) select 1::INT4, 'test';"" ) ; res . close ( ) ; TableDesc desc = catalog . getTableDesc ( getCurrentDatabase ( ) , tableName ) ; if ( ! testingCluster . isHiveCatalogStoreRunning ( ) ) { assertEquals ( 1 , desc . getStats ( ) . getNumRows ( ) . intValue ( ) ) ; } res = executeString ( ""select * from "" + tableName + "";"" ) ; assertTrue ( res . next ( ) ) ; assertEquals ( 3 , res . getMetaData ( ) . getColumnCount ( ) ) ; assertEquals ( 1 , res . getInt ( 1 ) ) ; assertNull ( res . getString ( 2 ) ) ; assertEquals ( 0.0 , res . getDouble ( 2 ) , 10 ) ; assertEquals ( ""test"" , res . getString ( 3 ) ) ; res . close ( ) ; executeString ( ""DROP TABLE "" + tableName + "" PURGE"" ) ; } @ Test public final void testInsertOverwritePathWithNonFromQuery ( ) throws Exception { ResultSet res = executeString ( ""insert overwrite into location "" + ""'/tajo-data/testInsertOverwritePathWithNonFromQuery' "" + ""USING csv WITH ('text.delimiter'='|','compression.codec'='org.apache.hadoop.io.compress.DeflateCodec') "" + ""select 1::INT4, 2.1::FLOAT4, 'test'"" ) ; res . close ( ) ; FileSystem fs = FileSystem . get ( testingCluster . getConfiguration ( ) ) ; Path path = new Path ( ""/tajo-data/testInsertOverwritePathWithNonFromQuery"" ) ; assertTrue ( fs . exists ( path ) ) ; assertEquals ( 1 , fs . listStatus ( path ) . length ) ; CompressionCodecFactory factory = new CompressionCodecFactory ( testingCluster . getConfiguration ( ) ) ; FileStatus file = fs . listStatus ( path ) [ 0 ] ; CompressionCodec codec = factory . getCodec ( file . getPath ( ) ) ; assertTrue ( codec instanceof DeflateCodec ) ; BufferedReader reader = new BufferedReader ( new InputStreamReader ( codec . createInputStream ( fs . open ( file . getPath ( ) ) ) ) ) ; try { String line = reader . readLine ( ) ; assertNotNull ( line ) ; String [ ] tokens = line . split ( ""\\|"" ) ; assertEquals ( 3 , tokens . length ) ; assertEquals ( ""1"" , tokens [ 0 ] ) ; assertEquals ( ""2.1"" , tokens [ 1 ] ) ; assertEquals ( ""test"" , tokens [ 2 ] ) ; } finally { reader . close ( ) ; } } @ Test public final void testInsertOverwriteWithUnion ( ) throws Exception { ResultSet res = executeFile ( ""table1_ddl.sql"" ) ; res . close ( ) ; CatalogService catalog = testingCluster . getMaster ( ) . getCatalog ( ) ; assertTrue ( catalog . existsTable ( getCurrentDatabase ( ) , ""table1"" ) ) ; res = executeFile ( ""testInsertOverwriteWithUnion.sql"" ) ; res . close ( ) ; String tableDatas = getTableFileContents ( ""table1"" ) ; String expected = ""1|1|17.0\n"" + ""1|1|36.0\n"" + ""2|2|38.0\n"" + ""3|2|45.0\n"" + ""3|3|49.0\n"" + ""1|3|173665.47\n"" + ""2|4|46929.18\n"" + ""3|2|193846.25\n"" ; assertNotNull ( tableDatas ) ; assertEquals ( expected , tableDatas ) ; executeString ( ""DROP TABLE table1 PURGE"" ) ; } @ Test public final void testInsertOverwriteWithUnionDifferentAlias ( ) throws Exception { ResultSet res = executeFile ( ""table1_ddl.sql"" ) ; res . close ( ) ; CatalogService catalog = testingCluster . getMaster ( ) . getCatalog ( ) ; assertTrue ( catalog . existsTable ( getCurrentDatabase ( ) , ""table1"" ) ) ; res = executeFile ( ""testInsertOverwriteWithUnionDifferentAlias.sql"" ) ; res . close ( ) ; String tableDatas = getTableFileContents ( ""table1"" ) ; String expected = ""1|1|17.0\n"" + ""1|1|36.0\n"" + ""2|2|38.0\n"" + ""3|2|45.0\n"" + ""3|3|49.0\n"" + ""1|3|173665.47\n"" + ""2|4|46929.18\n"" + ""3|2|193846.25\n"" ; assertNotNull ( tableDatas ) ; assertEquals ( expected , tableDatas ) ; executeString ( ""DROP TABLE table1 PURGE"" ) ; } @ Test public final void testInsertOverwriteLocationWithUnion ( ) throws Exception { ResultSet res = executeFile ( ""testInsertOverwriteLocationWithUnion.sql"" ) ; res . close ( ) ; String resultDatas = getTableFileContents ( new Path ( ""/tajo-data/testInsertOverwriteLocationWithUnion"" ) ) ; String expected = ""1|1|17.0\n"" + ""1|1|36.0\n"" + ""2|2|38.0\n"" + ""3|2|45.0\n"" + ""3|3|49.0\n"" + ""1|3|173665.47\n"" + ""2|4|46929.18\n"" + ""3|2|193846.25\n"" ; assertNotNull ( resultDatas ) ; assertEquals ( expected , resultDatas ) ; } @ Test public final void testInsertOverwriteLocationWithUnionDifferenceAlias ( ) throws Exception { ResultSet res = executeFile ( ""testInsertOverwriteLocationWithUnionDifferenceAlias.sql"" ) ; res . close ( ) ; String resultDatas = getTableFileContents ( new Path ( ""/tajo-data/testInsertOverwriteLocationWithUnionDifferenceAlias"" ) ) ; String expected = ""1|1|17.0\n"" + ""1|1|36.0\n"" + ""2|2|38.0\n"" + ""3|2|45.0\n"" + ""3|3|49.0\n"" + ""1|3|173665.47\n"" + ""2|4|46929.18\n"" + ""3|2|193846.25\n"" ; assertNotNull ( resultDatas ) ; assertEquals ( expected , resultDatas ) ; } @ Test public final void testInsertWithDifferentColumnOrder ( ) throws Exception { ResultSet res = executeFile ( ""nation_diff_col_order.ddl"" ) ; res . close ( ) ; CatalogService catalog = testingCluster . getMaster ( ) . getCatalog ( ) ; assertTrue ( catalog . existsTable ( getCurrentDatabase ( ) , ""nation_diff"" ) ) ; try { res = executeFile ( ""testInsertWithDifferentColumnOrder.sql"" ) ; res . close ( ) ; res = executeString ( ""select * from nation_diff"" ) ; assertResultSet ( res ) ; } finally { executeString ( ""drop table nation_diff purge;"" ) ; } } @ Test public final void testFixedCharSelectWithNoLength ( ) throws Exception { ResultSet res = executeFile ( ""test1_nolength_ddl.sql"" ) ; res . close ( ) ; CatalogService catalog = testingCluster . getMaster ( ) . getCatalog ( ) ; assertTrue ( catalog . existsTable ( getCurrentDatabase ( ) , ""test1"" ) ) ; res = executeFile ( ""testInsertIntoSelectWithFixedSizeCharWithNoLength.sql"" ) ; res . close ( ) ; String resultDatas = getTableFileContents ( ""test1"" ) . replaceAll ( ""\0"" , """" ) ; String expected = ""a\n"" ; assertNotNull ( resultDatas ) ; assertEquals ( expected . length ( ) , resultDatas . length ( ) ) ; assertEquals ( expected , resultDatas ) ; executeString ( ""DROP TABLE test1 PURGE"" ) ; } @ Test public final void testFixedCharSelect ( ) throws Exception { ResultSet res = executeFile ( ""test1_ddl.sql"" ) ; res . close ( ) ; CatalogService catalog = testingCluster . getMaster ( ) . getCatalog ( ) ; assertTrue ( catalog . existsTable ( getCurrentDatabase ( ) , ""test1"" ) ) ; res = executeFile ( ""testInsertIntoSelectWithFixedSizeChar.sql"" ) ; res . close ( ) ; String resultDatas = getTableFileContents ( ""test1"" ) . replaceAll ( ""\0"" , """" ) ; String expected = ""a\n"" + ""abc\n"" + ""abcde\n"" ; assertNotNull ( resultDatas ) ; assertEquals ( expected . length ( ) , resultDatas . length ( ) ) ; assertEquals ( expected , resultDatas ) ; executeString ( ""DROP TABLE test1 PURGE"" ) ; } }",Smelly
"public class BetaTest { private static final Method LOG_GAMMA_SUM_METHOD ; private static final Method LOG_GAMMA_MINUS_LOG_GAMMA_SUM_METHOD ; private static final Method SUM_DELTA_MINUS_DELTA_SUM_METHOD ; static { final Class < Beta > b ; final Class < Double > d = Double . TYPE ; b = Beta . class ; Method m = null ; try { m = b . getDeclaredMethod ( ""logGammaSum"" , d , d ) ; } catch ( NoSuchMethodException e ) { Assert . fail ( e . getMessage ( ) ) ; } LOG_GAMMA_SUM_METHOD = m ; LOG_GAMMA_SUM_METHOD . setAccessible ( true ) ; m = null ; try { m = b . getDeclaredMethod ( ""logGammaMinusLogGammaSum"" , d , d ) ; } catch ( NoSuchMethodException e ) { Assert . fail ( e . getMessage ( ) ) ; } LOG_GAMMA_MINUS_LOG_GAMMA_SUM_METHOD = m ; LOG_GAMMA_MINUS_LOG_GAMMA_SUM_METHOD . setAccessible ( true ) ; m = null ; try { m = b . getDeclaredMethod ( ""sumDeltaMinusDeltaSum"" , d , d ) ; } catch ( NoSuchMethodException e ) { Assert . fail ( e . getMessage ( ) ) ; } SUM_DELTA_MINUS_DELTA_SUM_METHOD = m ; SUM_DELTA_MINUS_DELTA_SUM_METHOD . setAccessible ( true ) ; } private void testRegularizedBeta ( double expected , double x , double a , double b ) { double actual = Beta . regularizedBeta ( x , a , b ) ; TestUtils . assertEquals ( expected , actual , 10e-15 ) ; } private void testLogBeta ( double expected , double a , double b ) { double actual = Beta . logBeta ( a , b ) ; TestUtils . assertEquals ( expected , actual , 10e-15 ) ; } @ Test public void testRegularizedBetaNanPositivePositive ( ) { testRegularizedBeta ( Double . NaN , Double . NaN , 1.0 , 1.0 ) ; } @ Test public void testRegularizedBetaPositiveNanPositive ( ) { testRegularizedBeta ( Double . NaN , 0.5 , Double . NaN , 1.0 ) ; } @ Test public void testRegularizedBetaPositivePositiveNan ( ) { testRegularizedBeta ( Double . NaN , 0.5 , 1.0 , Double . NaN ) ; } @ Test public void testRegularizedBetaNegativePositivePositive ( ) { testRegularizedBeta ( Double . NaN , - 0.5 , 1.0 , 2.0 ) ; } @ Test public void testRegularizedBetaPositiveNegativePositive ( ) { testRegularizedBeta ( Double . NaN , 0.5 , - 1.0 , 2.0 ) ; } @ Test public void testRegularizedBetaPositivePositiveNegative ( ) { testRegularizedBeta ( Double . NaN , 0.5 , 1.0 , - 2.0 ) ; } @ Test public void testRegularizedBetaZeroPositivePositive ( ) { testRegularizedBeta ( 0.0 , 0.0 , 1.0 , 2.0 ) ; } @ Test public void testRegularizedBetaPositiveZeroPositive ( ) { testRegularizedBeta ( Double . NaN , 0.5 , 0.0 , 2.0 ) ; } @ Test public void testRegularizedBetaPositivePositiveZero ( ) { testRegularizedBeta ( Double . NaN , 0.5 , 1.0 , 0.0 ) ; } @ Test public void testRegularizedBetaPositivePositivePositive ( ) { testRegularizedBeta ( 0.75 , 0.5 , 1.0 , 2.0 ) ; } @ Test public void testRegularizedBetaTinyArgument ( ) { double actual = Beta . regularizedBeta ( 1e-17 , 1.0 , 1e12 ) ; TestUtils . assertEquals ( 9.999950000166648e-6 , actual , 1e-16 ) ; } @ Test public void testMath1067 ( ) { final double x = 0.22580645161290325 ; final double a = 64.33333333333334 ; final double b = 223 ; try { final double r = Beta . regularizedBeta ( x , a , b , 1e-14 , 10000 ) ; } catch ( StackOverflowError error ) { Assert . fail ( ""Infinite recursion"" ) ; } } @ Test public void testLogBetaNanPositive ( ) { testLogBeta ( Double . NaN , Double . NaN , 2.0 ) ; } @ Test public void testLogBetaPositiveNan ( ) { testLogBeta ( Double . NaN , 1.0 , Double . NaN ) ; } @ Test public void testLogBetaNegativePositive ( ) { testLogBeta ( Double . NaN , - 1.0 , 2.0 ) ; } @ Test public void testLogBetaPositiveNegative ( ) { testLogBeta ( Double . NaN , 1.0 , - 2.0 ) ; } @ Test public void testLogBetaZeroPositive ( ) { testLogBeta ( Double . NaN , 0.0 , 2.0 ) ; } @ Test public void testLogBetaPositiveZero ( ) { testLogBeta ( Double . NaN , 1.0 , 0.0 ) ; } @ Test public void testLogBetaPositivePositive ( ) { testLogBeta ( - 0.693147180559945 , 1.0 , 2.0 ) ; } private static final double [ ] [ ] LOG_GAMMA_SUM_REF = { { 1.0 , 1.0 , 0.0 } , { 1.0 , 1.125 , .05775985153034387 } , { 1.0 , 1.25 , .1248717148923966 } , { 1.0 , 1.375 , .2006984603774558 } , { 1.0 , 1.5 , .2846828704729192 } , { 1.0 , 1.625 , .3763336820249054 } , { 1.0 , 1.75 , .4752146669149371 } , { 1.0 , 1.875 , .5809359740231859 } , { 1.0 , 2.0 , .6931471805599453 } , { 1.125 , 1.0 , .05775985153034387 } , { 1.125 , 1.125 , .1248717148923966 } , { 1.125 , 1.25 , .2006984603774558 } , { 1.125 , 1.375 , .2846828704729192 } , { 1.125 , 1.5 , .3763336820249054 } , { 1.125 , 1.625 , .4752146669149371 } , { 1.125 , 1.75 , .5809359740231859 } , { 1.125 , 1.875 , .6931471805599453 } , { 1.125 , 2.0 , 0.811531653906724 } , { 1.25 , 1.0 , .1248717148923966 } , { 1.25 , 1.125 , .2006984603774558 } , { 1.25 , 1.25 , .2846828704729192 } , { 1.25 , 1.375 , .3763336820249054 } , { 1.25 , 1.5 , .4752146669149371 } , { 1.25 , 1.625 , .5809359740231859 } , { 1.25 , 1.75 , .6931471805599453 } , { 1.25 , 1.875 , 0.811531653906724 } , { 1.25 , 2.0 , .9358019311087253 } , { 1.375 , 1.0 , .2006984603774558 } , { 1.375 , 1.125 , .2846828704729192 } , { 1.375 , 1.25 , .3763336820249054 } , { 1.375 , 1.375 , .4752146669149371 } , { 1.375 , 1.5 , .5809359740231859 } , { 1.375 , 1.625 , .6931471805599453 } , { 1.375 , 1.75 , 0.811531653906724 } , { 1.375 , 1.875 , .9358019311087253 } , { 1.375 , 2.0 , 1.06569589786406 } , { 1.5 , 1.0 , .2846828704729192 } , { 1.5 , 1.125 , .3763336820249054 } , { 1.5 , 1.25 , .4752146669149371 } , { 1.5 , 1.375 , .5809359740231859 } , { 1.5 , 1.5 , .6931471805599453 } , { 1.5 , 1.625 , 0.811531653906724 } , { 1.5 , 1.75 , .9358019311087253 } , { 1.5 , 1.875 , 1.06569589786406 } , { 1.5 , 2.0 , 1.200973602347074 } , { 1.625 , 1.0 , .3763336820249054 } , { 1.625 , 1.125 , .4752146669149371 } , { 1.625 , 1.25 , .5809359740231859 } , { 1.625 , 1.375 , .6931471805599453 } , { 1.625 , 1.5 , 0.811531653906724 } , { 1.625 , 1.625 , .9358019311087253 } , { 1.625 , 1.75 , 1.06569589786406 } , { 1.625 , 1.875 , 1.200973602347074 } , { 1.625 , 2.0 , 1.341414578068493 } , { 1.75 , 1.0 , .4752146669149371 } , { 1.75 , 1.125 , .5809359740231859 } , { 1.75 , 1.25 , .6931471805599453 } , { 1.75 , 1.375 , 0.811531653906724 } , { 1.75 , 1.5 , .9358019311087253 } , { 1.75 , 1.625 , 1.06569589786406 } , { 1.75 , 1.75 , 1.200973602347074 } , { 1.75 , 1.875 , 1.341414578068493 } , { 1.75 , 2.0 , 1.486815578593417 } , { 1.875 , 1.0 , .5809359740231859 } , { 1.875 , 1.125 , .6931471805599453 } , { 1.875 , 1.25 , 0.811531653906724 } , { 1.875 , 1.375 , .9358019311087253 } , { 1.875 , 1.5 , 1.06569589786406 } , { 1.875 , 1.625 , 1.200973602347074 } , { 1.875 , 1.75 , 1.341414578068493 } , { 1.875 , 1.875 , 1.486815578593417 } , { 1.875 , 2.0 , 1.6369886482725 } , { 2.0 , 1.0 , .6931471805599453 } , { 2.0 , 1.125 , 0.811531653906724 } , { 2.0 , 1.25 , .9358019311087253 } , { 2.0 , 1.375 , 1.06569589786406 } , { 2.0 , 1.5 , 1.200973602347074 } , { 2.0 , 1.625 , 1.341414578068493 } , { 2.0 , 1.75 , 1.486815578593417 } , { 2.0 , 1.875 , 1.6369886482725 } , { 2.0 , 2.0 , 1.791759469228055 } , } ; private static double logGammaSum ( final double a , final double b ) { try { return ( ( Double ) LOG_GAMMA_SUM_METHOD . invoke ( null , a , b ) ) . doubleValue ( ) ; } catch ( final IllegalAccessException e ) { Assert . fail ( e . getMessage ( ) ) ; } catch ( final IllegalArgumentException e ) { Assert . fail ( e . getMessage ( ) ) ; } catch ( final InvocationTargetException e ) { final Throwable te = e . getTargetException ( ) ; if ( te instanceof MathIllegalArgumentException ) { throw ( MathIllegalArgumentException ) te ; } Assert . fail ( e . getMessage ( ) ) ; } return Double . NaN ; } @ Test public void testLogGammaSum ( ) { final int ulps = 2 ; for ( int i = 0 ; i < LOG_GAMMA_SUM_REF . length ; i ++ ) { final double [ ] ref = LOG_GAMMA_SUM_REF [ i ] ; final double a = ref [ 0 ] ; final double b = ref [ 1 ] ; final double expected = ref [ 2 ] ; final double actual = logGammaSum ( a , b ) ; final double tol = ulps * FastMath . ulp ( expected ) ; final StringBuilder builder = new StringBuilder ( ) ; builder . append ( a ) . append ( "", "" ) . append ( b ) ; Assert . assertEquals ( builder . toString ( ) , expected , actual , tol ) ; } } @ Test ( expected = OutOfRangeException . class ) public void testLogGammaSumPrecondition1 ( ) { logGammaSum ( 0.0 , 1.0 ) ; } @ Test ( expected = OutOfRangeException . class ) public void testLogGammaSumPrecondition2 ( ) { logGammaSum ( 3.0 , 1.0 ) ; } @ Test ( expected = OutOfRangeException . class ) public void testLogGammaSumPrecondition3 ( ) { logGammaSum ( 1.0 , 0.0 ) ; } @ Test ( expected = OutOfRangeException . class ) public void testLogGammaSumPrecondition4 ( ) { logGammaSum ( 1.0 , 3.0 ) ; } private static final double [ ] [ ] LOG_GAMMA_MINUS_LOG_GAMMA_SUM_REF = { { 0.0 , 10.0 , 0.0 } , { 0.0 , 11.0 , 0.0 } , { 0.0 , 12.0 , 0.0 } , { 0.0 , 13.0 , 0.0 } , { 0.0 , 14.0 , 0.0 } , { 0.0 , 15.0 , 0.0 } , { 0.0 , 16.0 , 0.0 } , { 0.0 , 17.0 , 0.0 } , { 0.0 , 18.0 , 0.0 } , { 1.0 , 10.0 , - 2.302585092994046 } , { 1.0 , 11.0 , - 2.397895272798371 } , { 1.0 , 12.0 , - 2.484906649788 } , { 1.0 , 13.0 , - 2.564949357461537 } , { 1.0 , 14.0 , - 2.639057329615258 } , { 1.0 , 15.0 , - 2.70805020110221 } , { 1.0 , 16.0 , - 2.772588722239781 } , { 1.0 , 17.0 , - 2.833213344056216 } , { 1.0 , 18.0 , - 2.890371757896165 } , { 2.0 , 10.0 , - 4.700480365792417 } , { 2.0 , 11.0 , - 4.882801922586371 } , { 2.0 , 12.0 , - 5.049856007249537 } , { 2.0 , 13.0 , - 5.204006687076795 } , { 2.0 , 14.0 , - 5.347107530717468 } , { 2.0 , 15.0 , - 5.480638923341991 } , { 2.0 , 16.0 , - 5.605802066295998 } , { 2.0 , 17.0 , - 5.723585101952381 } , { 2.0 , 18.0 , - 5.834810737062605 } , { 3.0 , 10.0 , - 7.185387015580416 } , { 3.0 , 11.0 , - 7.447751280047908 } , { 3.0 , 12.0 , - 7.688913336864796 } , { 3.0 , 13.0 , - 7.912056888179006 } , { 3.0 , 14.0 , - 8.11969625295725 } , { 3.0 , 15.0 , - 8.313852267398207 } , { 3.0 , 16.0 , - 8.496173824192162 } , { 3.0 , 17.0 , - 8.668024081118821 } , { 3.0 , 18.0 , - 8.830543010616596 } , { 4.0 , 10.0 , - 9.750336373041954 } , { 4.0 , 11.0 , - 10.08680860966317 } , { 4.0 , 12.0 , - 10.39696353796701 } , { 4.0 , 13.0 , - 10.68464561041879 } , { 4.0 , 14.0 , - 10.95290959701347 } , { 4.0 , 15.0 , - 11.20422402529437 } , { 4.0 , 16.0 , - 11.4406128033586 } , { 4.0 , 17.0 , - 11.66375635467281 } , { 4.0 , 18.0 , - 11.87506544834002 } , { 5.0 , 10.0 , - 12.38939370265721 } , { 5.0 , 11.0 , - 12.79485881076538 } , { 5.0 , 12.0 , - 13.16955226020679 } , { 5.0 , 13.0 , - 13.517858954475 } , { 5.0 , 14.0 , - 13.84328135490963 } , { 5.0 , 15.0 , - 14.14866300446081 } , { 5.0 , 16.0 , - 14.43634507691259 } , { 5.0 , 17.0 , - 14.70827879239624 } , { 5.0 , 18.0 , - 14.96610790169833 } , { 6.0 , 10.0 , - 15.09744390375942 } , { 6.0 , 11.0 , - 15.56744753300516 } , { 6.0 , 12.0 , - 16.002765604263 } , { 6.0 , 13.0 , - 16.40823071237117 } , { 6.0 , 14.0 , - 16.78772033407607 } , { 6.0 , 15.0 , - 17.14439527801481 } , { 6.0 , 16.0 , - 17.48086751463602 } , { 6.0 , 17.0 , - 17.79932124575455 } , { 6.0 , 18.0 , - 18.10160211762749 } , { 7.0 , 10.0 , - 17.8700326259992 } , { 7.0 , 11.0 , - 18.40066087706137 } , { 7.0 , 12.0 , - 18.89313736215917 } , { 7.0 , 13.0 , - 19.35266969153761 } , { 7.0 , 14.0 , - 19.78345260763006 } , { 7.0 , 15.0 , - 20.18891771573823 } , { 7.0 , 16.0 , - 20.57190996799433 } , { 7.0 , 17.0 , - 20.9348154616837 } , { 7.0 , 18.0 , - 21.27965594797543 } , { 8.0 , 10.0 , - 20.70324597005542 } , { 8.0 , 11.0 , - 21.29103263495754 } , { 8.0 , 12.0 , - 21.83757634132561 } , { 8.0 , 13.0 , - 22.3484019650916 } , { 8.0 , 14.0 , - 22.82797504535349 } , { 8.0 , 15.0 , - 23.27996016909654 } , { 8.0 , 16.0 , - 23.70740418392348 } , { 8.0 , 17.0 , - 24.11286929203165 } , { 8.0 , 18.0 , - 24.49853177284363 } , { 9.0 , 10.0 , - 23.59361772795159 } , { 9.0 , 11.0 , - 24.23547161412398 } , { 9.0 , 12.0 , - 24.8333086148796 } , { 9.0 , 13.0 , - 25.39292440281502 } , { 9.0 , 14.0 , - 25.9190174987118 } , { 9.0 , 15.0 , - 26.41545438502569 } , { 9.0 , 16.0 , - 26.88545801427143 } , { 9.0 , 17.0 , - 27.33174511689985 } , { 9.0 , 18.0 , - 27.75662831086511 } , { 10.0 , 10.0 , - 26.53805670711802 } , { 10.0 , 11.0 , - 27.23120388767797 } , { 10.0 , 12.0 , - 27.87783105260302 } , { 10.0 , 13.0 , - 28.48396685617334 } , { 10.0 , 14.0 , - 29.05451171464095 } , { 10.0 , 15.0 , - 29.59350821537364 } , { 10.0 , 16.0 , - 30.10433383913963 } , { 10.0 , 17.0 , - 30.58984165492133 } , { 10.0 , 18.0 , - 31.05246517686944 } , } ; private static double logGammaMinusLogGammaSum ( final double a , final double b ) { try { final Method m = LOG_GAMMA_MINUS_LOG_GAMMA_SUM_METHOD ; return ( ( Double ) m . invoke ( null , a , b ) ) . doubleValue ( ) ; } catch ( final IllegalAccessException e ) { Assert . fail ( e . getMessage ( ) ) ; } catch ( final IllegalArgumentException e ) { Assert . fail ( e . getMessage ( ) ) ; } catch ( final InvocationTargetException e ) { final Throwable te = e . getTargetException ( ) ; if ( te instanceof MathIllegalArgumentException ) { throw ( MathIllegalArgumentException ) te ; } Assert . fail ( e . getMessage ( ) ) ; } return Double . NaN ; } @ Test public void testLogGammaMinusLogGammaSum ( ) { final int ulps = 4 ; for ( int i = 0 ; i < LOG_GAMMA_MINUS_LOG_GAMMA_SUM_REF . length ; i ++ ) { final double [ ] ref = LOG_GAMMA_MINUS_LOG_GAMMA_SUM_REF [ i ] ; final double a = ref [ 0 ] ; final double b = ref [ 1 ] ; final double expected = ref [ 2 ] ; final double actual = logGammaMinusLogGammaSum ( a , b ) ; final double tol = ulps * FastMath . ulp ( expected ) ; final StringBuilder builder = new StringBuilder ( ) ; builder . append ( a ) . append ( "", "" ) . append ( b ) ; Assert . assertEquals ( builder . toString ( ) , expected , actual , tol ) ; } } @ Test ( expected = NumberIsTooSmallException . class ) public void testLogGammaMinusLogGammaSumPrecondition1 ( ) { logGammaMinusLogGammaSum ( - 1.0 , 8.0 ) ; } @ Test ( expected = NumberIsTooSmallException . class ) public void testLogGammaMinusLogGammaSumPrecondition2 ( ) { logGammaMinusLogGammaSum ( 1.0 , 7.0 ) ; } private static final double [ ] [ ] SUM_DELTA_MINUS_DELTA_SUM_REF = { { 10.0 , 10.0 , .01249480717472882 } , { 10.0 , 11.0 , .01193628470267385 } , { 10.0 , 12.0 , .01148578547212797 } , { 10.0 , 13.0 , .01111659739668398 } , { 10.0 , 14.0 , .01080991216314295 } , { 10.0 , 15.0 , .01055214134859758 } , { 10.0 , 16.0 , .01033324912491747 } , { 10.0 , 17.0 , .01014568069918883 } , { 10.0 , 18.0 , .009983653199146491 } , { 10.0 , 19.0 , .009842674320242729 } , { 10.0 , 20.0 , 0.0097192081956071 } , { 11.0 , 10.0 , .01193628470267385 } , { 11.0 , 11.0 , .01135973290745925 } , { 11.0 , 12.0 , .01089355537047828 } , { 11.0 , 13.0 , .01051064829297728 } , { 11.0 , 14.0 , 0.0101918899639826 } , { 11.0 , 15.0 , .009923438811859604 } , { 11.0 , 16.0 , .009695052724952705 } , { 11.0 , 17.0 , 0.00949900745283617 } , { 11.0 , 18.0 , .009329379874933402 } , { 11.0 , 19.0 , 0.00918156080743147 } , { 11.0 , 20.0 , 0.00905191635141762 } , { 12.0 , 10.0 , .01148578547212797 } , { 12.0 , 11.0 , .01089355537047828 } , { 12.0 , 12.0 , .01041365883144029 } , { 12.0 , 13.0 , .01001867865848564 } , { 12.0 , 14.0 , 0.00968923999191334 } , { 12.0 , 15.0 , .009411294976563555 } , { 12.0 , 16.0 , .009174432043268762 } , { 12.0 , 17.0 , .008970786693291802 } , { 12.0 , 18.0 , .008794318926790865 } , { 12.0 , 19.0 , .008640321527910711 } , { 12.0 , 20.0 , .008505077879954796 } , { 13.0 , 10.0 , .01111659739668398 } , { 13.0 , 11.0 , .01051064829297728 } , { 13.0 , 12.0 , .01001867865848564 } , { 13.0 , 13.0 , .009613018147953376 } , { 13.0 , 14.0 , .009274085618154277 } , { 13.0 , 15.0 , 0.0089876637564166 } , { 13.0 , 16.0 , .008743200745261382 } , { 13.0 , 17.0 , .008532715206686251 } , { 13.0 , 18.0 , .008350069108807093 } , { 13.0 , 19.0 , .008190472517984874 } , { 13.0 , 20.0 , .008050138630244345 } , { 14.0 , 10.0 , .01080991216314295 } , { 14.0 , 11.0 , 0.0101918899639826 } , { 14.0 , 12.0 , 0.00968923999191334 } , { 14.0 , 13.0 , .009274085618154277 } , { 14.0 , 14.0 , .008926676241967286 } , { 14.0 , 15.0 , .008632654302369184 } , { 14.0 , 16.0 , .008381351102615795 } , { 14.0 , 17.0 , .008164687232662443 } , { 14.0 , 18.0 , .007976441942841219 } , { 14.0 , 19.0 , .007811755112234388 } , { 14.0 , 20.0 , .007666780069317652 } , { 15.0 , 10.0 , .01055214134859758 } , { 15.0 , 11.0 , .009923438811859604 } , { 15.0 , 12.0 , .009411294976563555 } , { 15.0 , 13.0 , 0.0089876637564166 } , { 15.0 , 14.0 , .008632654302369184 } , { 15.0 , 15.0 , 0.00833179217417291 } , { 15.0 , 16.0 , .008074310643041299 } , { 15.0 , 17.0 , .007852047581145882 } , { 15.0 , 18.0 , .007658712051540045 } , { 15.0 , 19.0 , .007489384065757007 } , { 15.0 , 20.0 , .007340165635725612 } , { 16.0 , 10.0 , .01033324912491747 } , { 16.0 , 11.0 , .009695052724952705 } , { 16.0 , 12.0 , .009174432043268762 } , { 16.0 , 13.0 , .008743200745261382 } , { 16.0 , 14.0 , .008381351102615795 } , { 16.0 , 15.0 , .008074310643041299 } , { 16.0 , 16.0 , .007811229919967624 } , { 16.0 , 17.0 , .007583876618287594 } , { 16.0 , 18.0 , .007385899933505551 } , { 16.0 , 19.0 , .007212328560607852 } , { 16.0 , 20.0 , .007059220321091879 } , { 17.0 , 10.0 , .01014568069918883 } , { 17.0 , 11.0 , 0.00949900745283617 } , { 17.0 , 12.0 , .008970786693291802 } , { 17.0 , 13.0 , .008532715206686251 } , { 17.0 , 14.0 , .008164687232662443 } , { 17.0 , 15.0 , .007852047581145882 } , { 17.0 , 16.0 , .007583876618287594 } , { 17.0 , 17.0 , .007351882161431358 } , { 17.0 , 18.0 , .007149662089534654 } , { 17.0 , 19.0 , .006972200907152378 } , { 17.0 , 20.0 , .006815518216094137 } , { 18.0 , 10.0 , .009983653199146491 } , { 18.0 , 11.0 , .009329379874933402 } , { 18.0 , 12.0 , .008794318926790865 } , { 18.0 , 13.0 , .008350069108807093 } , { 18.0 , 14.0 , .007976441942841219 } , { 18.0 , 15.0 , .007658712051540045 } , { 18.0 , 16.0 , .007385899933505551 } , { 18.0 , 17.0 , .007149662089534654 } , { 18.0 , 18.0 , .006943552208153373 } , { 18.0 , 19.0 , .006762516574228829 } , { 18.0 , 20.0 , .006602541598043117 } , { 19.0 , 10.0 , .009842674320242729 } , { 19.0 , 11.0 , 0.00918156080743147 } , { 19.0 , 12.0 , .008640321527910711 } , { 19.0 , 13.0 , .008190472517984874 } , { 19.0 , 14.0 , .007811755112234388 } , { 19.0 , 15.0 , .007489384065757007 } , { 19.0 , 16.0 , .007212328560607852 } , { 19.0 , 17.0 , .006972200907152378 } , { 19.0 , 18.0 , .006762516574228829 } , { 19.0 , 19.0 , .006578188655176814 } , { 19.0 , 20.0 , .006415174623476747 } , { 20.0 , 10.0 , 0.0097192081956071 } , { 20.0 , 11.0 , 0.00905191635141762 } , { 20.0 , 12.0 , .008505077879954796 } , { 20.0 , 13.0 , .008050138630244345 } , { 20.0 , 14.0 , .007666780069317652 } , { 20.0 , 15.0 , .007340165635725612 } , { 20.0 , 16.0 , .007059220321091879 } , { 20.0 , 17.0 , .006815518216094137 } , { 20.0 , 18.0 , .006602541598043117 } , { 20.0 , 19.0 , .006415174623476747 } , { 20.0 , 20.0 , .006249349445691423 } , } ; private static double sumDeltaMinusDeltaSum ( final double a , final double b ) { try { final Method m = SUM_DELTA_MINUS_DELTA_SUM_METHOD ; return ( ( Double ) m . invoke ( null , a , b ) ) . doubleValue ( ) ; } catch ( final IllegalAccessException e ) { Assert . fail ( e . getMessage ( ) ) ; } catch ( final IllegalArgumentException e ) { Assert . fail ( e . getMessage ( ) ) ; } catch ( final InvocationTargetException e ) { final Throwable te = e . getTargetException ( ) ; if ( te instanceof MathIllegalArgumentException ) { throw ( MathIllegalArgumentException ) te ; } Assert . fail ( e . getMessage ( ) ) ; } return Double . NaN ; } @ Test public void testSumDeltaMinusDeltaSum ( ) { final int ulps = 3 ; for ( int i = 0 ; i < SUM_DELTA_MINUS_DELTA_SUM_REF . length ; i ++ ) { final double [ ] ref = SUM_DELTA_MINUS_DELTA_SUM_REF [ i ] ; final double a = ref [ 0 ] ; final double b = ref [ 1 ] ; final double expected = ref [ 2 ] ; final double actual = sumDeltaMinusDeltaSum ( a , b ) ; final double tol = ulps * FastMath . ulp ( expected ) ; final StringBuilder builder = new StringBuilder ( ) ; builder . append ( a ) . append ( "", "" ) . append ( b ) ; Assert . assertEquals ( builder . toString ( ) , expected , actual , tol ) ; } } @ Test ( expected = NumberIsTooSmallException . class ) public void testSumDeltaMinusDeltaSumPrecondition1 ( ) { sumDeltaMinusDeltaSum ( 9.0 , 10.0 ) ; } @ Test ( expected = NumberIsTooSmallException . class ) public void testSumDeltaMinusDeltaSumPrecondition2 ( ) { sumDeltaMinusDeltaSum ( 10.0 , 9.0 ) ; } private static final double [ ] [ ] LOG_BETA_REF = { { 0.125 , 0.125 , 2.750814190409515 } , { 0.125 , 0.25 , 2.444366899981226 } , { 0.125 , 0.5 , 2.230953804989556 } , { 0.125 , 1.0 , 2.079441541679836 } , { 0.125 , 2.0 , 1.961658506023452 } , { 0.125 , 3.0 , 1.901033884207018 } , { 0.125 , 4.0 , 1.860211889686763 } , { 0.125 , 5.0 , 1.829440231020009 } , { 0.125 , 6.0 , 1.804747618429637 } , { 0.125 , 7.0 , 1.784128331226902 } , { 0.125 , 8.0 , 1.766428754127501 } , { 0.125 , 9.0 , 1.750924567591535 } , { 0.125 , 10.0 , 1.7371312454592 } , { 0.125 , 1000.0 , 1.156003642015969 } , { 0.125 , 1001.0 , 1.155878649827818 } , { 0.125 , 10000.0 , .8681312798751318 } , { 0.25 , 0.125 , 2.444366899981226 } , { 0.25 , 0.25 , 2.003680106471455 } , { 0.25 , 0.5 , 1.657106516191482 } , { 0.25 , 1.0 , 1.386294361119891 } , { 0.25 , 2.0 , 1.163150809805681 } , { 0.25 , 3.0 , 1.045367774149297 } , { 0.25 , 4.0 , 0.965325066475761 } , { 0.25 , 5.0 , .9047004446593261 } , { 0.25 , 6.0 , .8559102804898941 } , { 0.25 , 7.0 , 0.815088285969639 } , { 0.25 , 8.0 , .7799969661583689 } , { 0.25 , 9.0 , .7492253074916152 } , { 0.25 , 10.0 , .7218263333035008 } , { 0.25 , 1000.0 , - .4388225372378877 } , { 0.25 , 1001.0 , - .4390725059930951 } , { 0.25 , 10000.0 , - 1.014553193217846 } , { 0.5 , 0.125 , 2.230953804989556 } , { 0.5 , 0.25 , 1.657106516191482 } , { 0.5 , 0.5 , 1.1447298858494 } , { 0.5 , 1.0 , .6931471805599453 } , { 0.5 , 2.0 , .2876820724517809 } , { 0.5 , 3.0 , .06453852113757118 } , { 0.5 , 5.0 , - .2073951943460706 } , { 0.5 , 6.0 , - .3027053741503954 } , { 0.5 , 7.0 , - .3827480818239319 } , { 0.5 , 8.0 , - .4517409533108833 } , { 0.5 , 9.0 , - .5123655751273182 } , { 0.5 , 10.0 , - .5664327963975939 } , { 0.5 , 1000.0 , - 2.881387696571577 } , { 0.5 , 1001.0 , - 2.881887571613228 } , { 0.5 , 10000.0 , - 4.032792743063396 } , { 1.0 , 0.125 , 2.079441541679836 } , { 1.0 , 0.25 , 1.386294361119891 } , { 1.0 , 0.5 , .6931471805599453 } , { 1.0 , 1.0 , 0.0 } , { 1.0 , 2.0 , - .6931471805599453 } , { 1.0 , 3.0 , - 1.09861228866811 } , { 1.0 , 4.0 , - 1.386294361119891 } , { 1.0 , 5.0 , - 1.6094379124341 } , { 1.0 , 6.0 , - 1.791759469228055 } , { 1.0 , 7.0 , - 1.945910149055313 } , { 1.0 , 8.0 , - 2.079441541679836 } , { 1.0 , 9.0 , - 2.19722457733622 } , { 1.0 , 10.0 , - 2.302585092994046 } , { 1.0 , 1000.0 , - 6.907755278982137 } , { 1.0 , 1001.0 , - 6.90875477931522 } , { 1.0 , 10000.0 , - 9.210340371976184 } , { 2.0 , 0.125 , 1.961658506023452 } , { 2.0 , 0.25 , 1.163150809805681 } , { 2.0 , 0.5 , .2876820724517809 } , { 2.0 , 1.0 , - .6931471805599453 } , { 2.0 , 2.0 , - 1.791759469228055 } , { 2.0 , 3.0 , - 2.484906649788 } , { 2.0 , 4.0 , - 2.995732273553991 } , { 2.0 , 5.0 , - 3.401197381662155 } , { 2.0 , 6.0 , - 3.737669618283368 } , { 2.0 , 7.0 , - 4.02535169073515 } , { 2.0 , 8.0 , - 4.276666119016055 } , { 2.0 , 9.0 , - 4.499809670330265 } , { 2.0 , 10.0 , - 4.700480365792417 } , { 2.0 , 1000.0 , - 13.81651005829736 } , { 2.0 , 1001.0 , - 13.81850806096003 } , { 2.0 , 10000.0 , - 18.4207807389527 } , { 3.0 , 0.125 , 1.901033884207018 } , { 3.0 , 0.25 , 1.045367774149297 } , { 3.0 , 0.5 , .06453852113757118 } , { 3.0 , 1.0 , - 1.09861228866811 } , { 3.0 , 2.0 , - 2.484906649788 } , { 3.0 , 3.0 , - 3.401197381662155 } , { 3.0 , 4.0 , - 4.0943445622221 } , { 3.0 , 5.0 , - 4.653960350157523 } , { 3.0 , 6.0 , - 5.123963979403259 } , { 3.0 , 7.0 , - 5.529429087511423 } , { 3.0 , 8.0 , - 5.886104031450156 } , { 3.0 , 9.0 , - 6.20455776256869 } , { 3.0 , 10.0 , - 6.492239835020471 } , { 3.0 , 1000.0 , - 20.03311615938222 } , { 3.0 , 1001.0 , - 20.03611166836202 } , { 3.0 , 10000.0 , - 26.9381739103716 } , { 4.0 , 0.125 , 1.860211889686763 } , { 4.0 , 0.25 , 0.965325066475761 } , { 4.0 , 1.0 , - 1.386294361119891 } , { 4.0 , 2.0 , - 2.995732273553991 } , { 4.0 , 3.0 , - 4.0943445622221 } , { 4.0 , 4.0 , - 4.941642422609304 } , { 4.0 , 5.0 , - 5.634789603169249 } , { 4.0 , 6.0 , - 6.222576268071369 } , { 4.0 , 7.0 , - 6.733401891837359 } , { 4.0 , 8.0 , - 7.185387015580416 } , { 4.0 , 9.0 , - 7.590852123688581 } , { 4.0 , 10.0 , - 7.958576903813898 } , { 4.0 , 1000.0 , - 25.84525465867605 } , { 4.0 , 1001.0 , - 25.84924667994559 } , { 4.0 , 10000.0 , - 35.05020194868867 } , { 5.0 , 0.125 , 1.829440231020009 } , { 5.0 , 0.25 , .9047004446593261 } , { 5.0 , 0.5 , - .2073951943460706 } , { 5.0 , 1.0 , - 1.6094379124341 } , { 5.0 , 2.0 , - 3.401197381662155 } , { 5.0 , 3.0 , - 4.653960350157523 } , { 5.0 , 4.0 , - 5.634789603169249 } , { 5.0 , 5.0 , - 6.445719819385578 } , { 5.0 , 6.0 , - 7.138866999945524 } , { 5.0 , 7.0 , - 7.745002803515839 } , { 5.0 , 8.0 , - 8.283999304248526 } , { 5.0 , 9.0 , - 8.769507120030227 } , { 5.0 , 10.0 , - 9.211339872309265 } , { 5.0 , 1000.0 , - 31.37070759780783 } , { 5.0 , 1001.0 , - 31.37569513931887 } , { 5.0 , 10000.0 , - 42.87464787956629 } , { 6.0 , 0.125 , 1.804747618429637 } , { 6.0 , 0.25 , .8559102804898941 } , { 6.0 , 0.5 , - .3027053741503954 } , { 6.0 , 1.0 , - 1.791759469228055 } , { 6.0 , 2.0 , - 3.737669618283368 } , { 6.0 , 3.0 , - 5.123963979403259 } , { 6.0 , 4.0 , - 6.222576268071369 } , { 6.0 , 5.0 , - 7.138866999945524 } , { 6.0 , 6.0 , - 7.927324360309794 } , { 6.0 , 7.0 , - 8.620471540869739 } , { 6.0 , 8.0 , - 9.239510749275963 } , { 6.0 , 9.0 , - 9.799126537211386 } , { 6.0 , 10.0 , - 10.30995216097738 } , { 6.0 , 1000.0 , - 36.67401250586691 } , { 6.0 , 1001.0 , - 36.67999457754446 } , { 6.0 , 10000.0 , - 50.47605021415003 } , { 7.0 , 0.125 , 1.784128331226902 } , { 7.0 , 0.25 , 0.815088285969639 } , { 7.0 , 0.5 , - .3827480818239319 } , { 7.0 , 1.0 , - 1.945910149055313 } , { 7.0 , 2.0 , - 4.02535169073515 } , { 7.0 , 3.0 , - 5.529429087511423 } , { 7.0 , 4.0 , - 6.733401891837359 } , { 7.0 , 5.0 , - 7.745002803515839 } , { 7.0 , 6.0 , - 8.620471540869739 } , { 7.0 , 7.0 , - 9.39366142910322 } , { 7.0 , 8.0 , - 10.08680860966317 } , { 7.0 , 9.0 , - 10.71541726908554 } , { 7.0 , 10.0 , - 11.2907814139891 } , { 7.0 , 1000.0 , - 41.79599038729854 } , { 7.0 , 1001.0 , - 41.80296600103496 } , { 7.0 , 10000.0 , - 57.89523093697012 } , { 8.0 , 0.125 , 1.766428754127501 } , { 8.0 , 0.25 , .7799969661583689 } , { 8.0 , 0.5 , - .4517409533108833 } , { 8.0 , 1.0 , - 2.079441541679836 } , { 8.0 , 2.0 , - 4.276666119016055 } , { 8.0 , 3.0 , - 5.886104031450156 } , { 8.0 , 4.0 , - 7.185387015580416 } , { 8.0 , 5.0 , - 8.283999304248526 } , { 8.0 , 6.0 , - 9.239510749275963 } , { 8.0 , 7.0 , - 10.08680860966317 } , { 8.0 , 8.0 , - 10.84894866171006 } , { 8.0 , 9.0 , - 11.54209584227001 } , { 8.0 , 10.0 , - 12.17808460899001 } , { 8.0 , 1000.0 , - 46.76481113096179 } , { 8.0 , 1001.0 , - 46.77277930061096 } , { 8.0 , 10000.0 , - 65.16036091500527 } , { 9.0 , 0.125 , 1.750924567591535 } , { 9.0 , 0.25 , .7492253074916152 } , { 9.0 , 0.5 , - .5123655751273182 } , { 9.0 , 1.0 , - 2.19722457733622 } , { 9.0 , 2.0 , - 4.499809670330265 } , { 9.0 , 3.0 , - 6.20455776256869 } , { 9.0 , 4.0 , - 7.590852123688581 } , { 9.0 , 5.0 , - 8.769507120030227 } , { 9.0 , 6.0 , - 9.799126537211386 } , { 9.0 , 7.0 , - 10.71541726908554 } , { 9.0 , 8.0 , - 11.54209584227001 } , { 9.0 , 9.0 , - 12.29586764464639 } , { 9.0 , 10.0 , - 12.98901482520633 } , { 9.0 , 1000.0 , - 51.60109303791327 } , { 9.0 , 1001.0 , - 51.61005277928474 } , { 9.0 , 10000.0 , - 72.29205942547217 } , { 10.0 , 0.125 , 1.7371312454592 } , { 10.0 , 0.25 , .7218263333035008 } , { 10.0 , 0.5 , - .5664327963975939 } , { 10.0 , 1.0 , - 2.302585092994046 } , { 10.0 , 2.0 , - 4.700480365792417 } , { 10.0 , 3.0 , - 6.492239835020471 } , { 10.0 , 4.0 , - 7.958576903813898 } , { 10.0 , 5.0 , - 9.211339872309265 } , { 10.0 , 6.0 , - 10.30995216097738 } , { 10.0 , 7.0 , - 11.2907814139891 } , { 10.0 , 8.0 , - 12.17808460899001 } , { 10.0 , 9.0 , - 12.98901482520633 } , { 10.0 , 10.0 , - 13.73622922703655 } , { 10.0 , 1000.0 , - 56.32058348093065 } , { 10.0 , 1001.0 , - 56.33053381178382 } , { 10.0 , 10000.0 , - 79.30607481535498 } , { 1000.0 , 0.125 , 1.156003642015969 } , { 1000.0 , 0.25 , - .4388225372378877 } , { 1000.0 , 0.5 , - 2.881387696571577 } , { 1000.0 , 1.0 , - 6.907755278982137 } , { 1000.0 , 2.0 , - 13.81651005829736 } , { 1000.0 , 3.0 , - 20.03311615938222 } , { 1000.0 , 4.0 , - 25.84525465867605 } , { 1000.0 , 5.0 , - 31.37070759780783 } , { 1000.0 , 6.0 , - 36.67401250586691 } , { 1000.0 , 7.0 , - 41.79599038729854 } , { 1000.0 , 8.0 , - 46.76481113096179 } , { 1000.0 , 9.0 , - 51.60109303791327 } , { 1000.0 , 10.0 , - 56.32058348093065 } , { 1000.0 , 1000.0 , - 1388.482601635902 } , { 1000.0 , 1001.0 , - 1389.175748816462 } , { 1000.0 , 10000.0 , - 3353.484270767097 } , { 1001.0 , 0.125 , 1.155878649827818 } , { 1001.0 , 0.25 , - .4390725059930951 } , { 1001.0 , 0.5 , - 2.881887571613228 } , { 1001.0 , 1.0 , - 6.90875477931522 } , { 1001.0 , 2.0 , - 13.81850806096003 } , { 1001.0 , 3.0 , - 20.03611166836202 } , { 1001.0 , 4.0 , - 25.84924667994559 } , { 1001.0 , 5.0 , - 31.37569513931887 } , { 1001.0 , 6.0 , - 36.67999457754446 } , { 1001.0 , 7.0 , - 41.80296600103496 } , { 1001.0 , 8.0 , - 46.77277930061096 } , { 1001.0 , 9.0 , - 51.61005277928474 } , { 1001.0 , 10.0 , - 56.33053381178382 } , { 1001.0 , 1000.0 , - 1389.175748816462 } , { 1001.0 , 1001.0 , - 1389.869395872064 } , { 1001.0 , 10000.0 , - 3355.882166039895 } , { 10000.0 , 0.125 , .8681312798751318 } , { 10000.0 , 0.25 , - 1.014553193217846 } , { 10000.0 , 0.5 , - 4.032792743063396 } , { 10000.0 , 1.0 , - 9.210340371976184 } , { 10000.0 , 2.0 , - 18.4207807389527 } , { 10000.0 , 3.0 , - 26.9381739103716 } , { 10000.0 , 4.0 , - 35.05020194868867 } , { 10000.0 , 5.0 , - 42.87464787956629 } , { 10000.0 , 6.0 , - 50.47605021415003 } , { 10000.0 , 7.0 , - 57.89523093697012 } , { 10000.0 , 8.0 , - 65.16036091500527 } , { 10000.0 , 9.0 , - 72.29205942547217 } , { 10000.0 , 10.0 , - 79.30607481535498 } , { 10000.0 , 1000.0 , - 3353.484270767097 } , { 10000.0 , 1001.0 , - 3355.882166039895 } , { 10000.0 , 10000.0 , - 13866.28325676141 } , } ; @ Test public void testLogBeta ( ) { final int ulps = 3 ; for ( int i = 0 ; i < LOG_BETA_REF . length ; i ++ ) { final double [ ] ref = LOG_BETA_REF [ i ] ; final double a = ref [ 0 ] ; final double b = ref [ 1 ] ; final double expected = ref [ 2 ] ; final double actual = Beta . logBeta ( a , b ) ; final double tol = ulps * FastMath . ulp ( expected ) ; final StringBuilder builder = new StringBuilder ( ) ; builder . append ( a ) . append ( "", "" ) . append ( b ) ; Assert . assertEquals ( builder . toString ( ) , expected , actual , tol ) ; } } }",Smelly
"public class DrillJoinRule extends RelOptRule { public static final RelOptRule INSTANCE = new DrillJoinRule ( ) ; protected static final Logger tracer = CalciteTrace . getPlannerTracer ( ) ; private DrillJoinRule ( ) { super ( RelOptHelper . any ( LogicalJoin . class , Convention . NONE ) , ""DrillJoinRule"" ) ; } @ Override public void onMatch ( RelOptRuleCall call ) { final LogicalJoin join = ( LogicalJoin ) call . rel ( 0 ) ; final RelNode left = join . getLeft ( ) ; final RelNode right = join . getRight ( ) ; final RelTraitSet traits = join . getTraitSet ( ) . plus ( DrillRel . DRILL_LOGICAL ) ; final RelNode convertedLeft = convert ( left , left . getTraitSet ( ) . plus ( DrillRel . DRILL_LOGICAL ) ) ; final RelNode convertedRight = convert ( right , right . getTraitSet ( ) . plus ( DrillRel . DRILL_LOGICAL ) ) ; List < Integer > leftKeys = Lists . newArrayList ( ) ; List < Integer > rightKeys = Lists . newArrayList ( ) ; List < Boolean > filterNulls = Lists . newArrayList ( ) ; int numLeftFields = convertedLeft . getRowType ( ) . getFieldCount ( ) ; boolean addFilter = false ; RexNode origJoinCondition = join . getCondition ( ) ; RexNode newJoinCondition = origJoinCondition ; RexNode remaining = RelOptUtil . splitJoinCondition ( convertedLeft , convertedRight , origJoinCondition , leftKeys , rightKeys , filterNulls ) ; boolean hasEquijoins = leftKeys . size ( ) == rightKeys . size ( ) && leftKeys . size ( ) > 0 ; if ( ! remaining . isAlwaysTrue ( ) ) { if ( hasEquijoins && join . getJoinType ( ) == JoinRelType . INNER ) { addFilter = true ; newJoinCondition = buildJoinCondition ( convertedLeft , convertedRight , leftKeys , rightKeys , filterNulls , join . getCluster ( ) . getRexBuilder ( ) ) ; } } else { newJoinCondition = buildJoinCondition ( convertedLeft , convertedRight , leftKeys , rightKeys , filterNulls , join . getCluster ( ) . getRexBuilder ( ) ) ; } try { if ( ! addFilter ) { RelNode joinRel = new DrillJoinRel ( join . getCluster ( ) , traits , convertedLeft , convertedRight , newJoinCondition , join . getJoinType ( ) , leftKeys , rightKeys ) ; call . transformTo ( joinRel ) ; } else { RelNode joinRel = new DrillJoinRel ( join . getCluster ( ) , traits , convertedLeft , convertedRight , newJoinCondition , join . getJoinType ( ) , leftKeys , rightKeys ) ; call . transformTo ( new DrillFilterRel ( join . getCluster ( ) , traits , joinRel , remaining ) ) ; } } catch ( InvalidRelException e ) { tracer . warning ( e . toString ( ) ) ; } } private RexNode buildJoinCondition ( RelNode convertedLeft , RelNode convertedRight , List < Integer > leftKeys , List < Integer > rightKeys , List < Boolean > filterNulls , RexBuilder builder ) { List < RexNode > equijoinList = Lists . newArrayList ( ) ; final int numLeftFields = convertedLeft . getRowType ( ) . getFieldCount ( ) ; List < RelDataTypeField > leftTypes = convertedLeft . getRowType ( ) . getFieldList ( ) ; List < RelDataTypeField > rightTypes = convertedRight . getRowType ( ) . getFieldList ( ) ; for ( int i = 0 ; i < leftKeys . size ( ) ; i ++ ) { int leftKeyOrdinal = leftKeys . get ( i ) . intValue ( ) ; int rightKeyOrdinal = rightKeys . get ( i ) . intValue ( ) ; equijoinList . add ( builder . makeCall ( filterNulls . get ( i ) ? SqlStdOperatorTable . EQUALS : SqlStdOperatorTable . IS_NOT_DISTINCT_FROM , builder . makeInputRef ( leftTypes . get ( leftKeyOrdinal ) . getType ( ) , leftKeyOrdinal ) , builder . makeInputRef ( rightTypes . get ( rightKeyOrdinal ) . getType ( ) , rightKeyOrdinal + numLeftFields ) ) ) ; } return RexUtil . composeConjunction ( builder , equijoinList , false ) ; } }",No
"public class FlowTest extends TestCase { public FlowTest ( String s ) { super ( s ) ; } static { JXPathIntrospector . registerDynamicClass ( VarMap . class , VarMapHandler . class ) ; } private static ClassLoader loader = new ContinuationClassLoader ( FlowTest . class . getClassLoader ( ) ) ; private ContinuationContext context ; private MockRequest request ; private MockRedirector redirector ; private HashMap objectmodel ; public void setUp ( ) { context = new ContinuationContext ( ) ; DefaultContext avalonContext = new DefaultContext ( ) ; request = new MockRequest ( ) ; avalonContext . put ( ContextHelper . CONTEXT_REQUEST_OBJECT , request ) ; objectmodel = new HashMap ( ) ; objectmodel . put ( ObjectModelHelper . REQUEST_OBJECT , request ) ; avalonContext . put ( ContextHelper . CONTEXT_OBJECT_MODEL , objectmodel ) ; redirector = new MockRedirector ( ) ; context . setAvalonContext ( avalonContext ) ; context . setRedirector ( redirector ) ; } public void testSimple ( ) throws Exception { Class clazz = loader . loadClass ( ""org.apache.cocoon.components.flow.java.test.SimpleFlow"" ) ; Continuable flow = ( Continuable ) clazz . newInstance ( ) ; Method method = clazz . getMethod ( ""run"" , new Class [ 0 ] ) ; Continuation c = new Continuation ( context ) ; assertTrue ( ! c . isRestoring ( ) ) ; assertTrue ( ! c . isCapturing ( ) ) ; System . out . println ( ""*** start flow"" ) ; c . registerThread ( ) ; method . invoke ( flow , new Object [ 0 ] ) ; if ( c . isCapturing ( ) ) c . getStack ( ) . popReference ( ) ; c . deregisterThread ( ) ; System . out . println ( ""*** return from flow"" ) ; assertTrue ( ! c . isRestoring ( ) ) ; assertTrue ( c . isCapturing ( ) ) ; request . addParameter ( ""a"" , ""2.3"" ) ; redirector . reset ( ) ; c = new Continuation ( c , context ) ; assertTrue ( c . isRestoring ( ) ) ; assertTrue ( ! c . isCapturing ( ) ) ; System . out . println ( ""*** resume flow"" ) ; c . registerThread ( ) ; method . invoke ( flow , new Object [ 0 ] ) ; if ( c . isCapturing ( ) ) c . getStack ( ) . popReference ( ) ; c . deregisterThread ( ) ; System . out . println ( ""*** return from flow"" ) ; assertTrue ( ! c . isRestoring ( ) ) ; assertTrue ( ! c . isCapturing ( ) ) ; VarMap map = ( VarMap ) FlowHelper . getContextObject ( objectmodel ) ; assertEquals ( ( ( Float ) map . getMap ( ) . get ( ""result"" ) ) . floatValue ( ) , 3.3f , 0.1f ) ; JXPathContext jxcontext = JXPathContext . newContext ( FlowHelper . getContextObject ( objectmodel ) ) ; Float result = ( Float ) jxcontext . getValue ( ""result"" ) ; assertEquals ( result . floatValue ( ) , 3.3f , 0.1f ) ; } public void testCatch ( ) throws Exception { Class clazz = loader . loadClass ( ""org.apache.cocoon.components.flow.java.test.SimpleFlow"" ) ; Continuable flow = ( Continuable ) clazz . newInstance ( ) ; Method method = clazz . getMethod ( ""testCatch"" , new Class [ 0 ] ) ; Continuation c = new Continuation ( context ) ; assertTrue ( ! c . isRestoring ( ) ) ; assertTrue ( ! c . isCapturing ( ) ) ; System . out . println ( ""*** start flow"" ) ; c . registerThread ( ) ; method . invoke ( flow , new Object [ 0 ] ) ; if ( c . isCapturing ( ) ) c . getStack ( ) . popReference ( ) ; c . deregisterThread ( ) ; System . out . println ( ""*** return from flow"" ) ; assertTrue ( ! c . isRestoring ( ) ) ; assertTrue ( c . isCapturing ( ) ) ; assertEquals ( redirector . getRedirect ( ) , ""cocoon:/getNumberA"" ) ; request . addParameter ( ""a"" , ""bla"" ) ; redirector . reset ( ) ; c = new Continuation ( c , context ) ; assertTrue ( c . isRestoring ( ) ) ; assertTrue ( ! c . isCapturing ( ) ) ; System . out . println ( ""*** resume flow"" ) ; c . registerThread ( ) ; method . invoke ( flow , new Object [ 0 ] ) ; if ( c . isCapturing ( ) ) c . getStack ( ) . popReference ( ) ; c . deregisterThread ( ) ; System . out . println ( ""*** return from flow"" ) ; assertTrue ( ! c . isRestoring ( ) ) ; assertTrue ( c . isCapturing ( ) ) ; assertEquals ( redirector . getRedirect ( ) , ""cocoon:/error"" ) ; redirector . reset ( ) ; c = new Continuation ( c , context ) ; assertTrue ( c . isRestoring ( ) ) ; assertTrue ( ! c . isCapturing ( ) ) ; System . out . println ( ""*** resume flow"" ) ; c . registerThread ( ) ; method . invoke ( flow , new Object [ 0 ] ) ; if ( c . isCapturing ( ) ) c . getStack ( ) . popReference ( ) ; c . deregisterThread ( ) ; System . out . println ( ""*** return from flow"" ) ; assertTrue ( ! c . isRestoring ( ) ) ; assertTrue ( ! c . isCapturing ( ) ) ; assertEquals ( redirector . getRedirect ( ) , ""cocoon:/result"" ) ; } public void testFormFlow ( ) throws Exception { Class clazz = loader . loadClass ( ""org.apache.cocoon.samples.flow.java.FormFlow"" ) ; Continuable flow = ( Continuable ) clazz . newInstance ( ) ; assertNotNull ( flow ) ; } public void testAbstract ( ) throws Exception { Class clazz = loader . loadClass ( ""org.apache.cocoon.components.flow.java.test.SimpleFlow"" ) ; Continuable flow = ( Continuable ) clazz . newInstance ( ) ; Method method = clazz . getMethod ( ""testAbstract"" , new Class [ 0 ] ) ; Continuation c = new Continuation ( context ) ; assertTrue ( ! c . isRestoring ( ) ) ; assertTrue ( ! c . isCapturing ( ) ) ; System . out . println ( ""*** start flow"" ) ; c . registerThread ( ) ; method . invoke ( flow , new Object [ 0 ] ) ; if ( c . isCapturing ( ) ) c . getStack ( ) . popReference ( ) ; c . deregisterThread ( ) ; System . out . println ( ""*** return from flow"" ) ; assertTrue ( ! c . isRestoring ( ) ) ; assertTrue ( c . isCapturing ( ) ) ; assertEquals ( redirector . getRedirect ( ) , ""cocoon:/parent"" ) ; } public void testDelegate ( ) throws Exception { ClassLoader loader = new ContinuationClassLoader ( getClass ( ) . getClassLoader ( ) ) ; Class clazz = loader . loadClass ( ""org.apache.cocoon.components.flow.java.test.SimpleFlow"" ) ; Continuable flow = ( Continuable ) clazz . newInstance ( ) ; Method method = clazz . getMethod ( ""testDelegate"" , new Class [ 0 ] ) ; Continuation c = new Continuation ( context ) ; assertTrue ( ! c . isRestoring ( ) ) ; assertTrue ( ! c . isCapturing ( ) ) ; System . out . println ( ""*** start flow"" ) ; c . registerThread ( ) ; method . invoke ( flow , new Object [ 0 ] ) ; if ( c . isCapturing ( ) ) c . getStack ( ) . popReference ( ) ; c . deregisterThread ( ) ; System . out . println ( ""*** return from flow"" ) ; System . out . println ( ) ; assertTrue ( ! c . isRestoring ( ) ) ; assertTrue ( c . isCapturing ( ) ) ; assertEquals ( redirector . getRedirect ( ) , ""cocoon:/page/getNumberA"" ) ; request . addParameter ( ""a"" , ""2"" ) ; redirector . reset ( ) ; c = new Continuation ( c , context ) ; assertTrue ( c . isRestoring ( ) ) ; assertTrue ( ! c . isCapturing ( ) ) ; System . out . println ( ) ; System . out . println ( ""*** resume flow"" ) ; c . registerThread ( ) ; method . invoke ( flow , new Object [ 0 ] ) ; if ( c . isCapturing ( ) ) c . getStack ( ) . popReference ( ) ; c . deregisterThread ( ) ; System . out . println ( ""*** return from flow"" ) ; System . out . println ( ) ; assertTrue ( ! c . isRestoring ( ) ) ; assertTrue ( c . isCapturing ( ) ) ; assertEquals ( redirector . getRedirect ( ) , ""cocoon:/page/getNumberB"" ) ; request . addParameter ( ""b"" , ""2"" ) ; redirector . reset ( ) ; c = new Continuation ( c , context ) ; assertTrue ( c . isRestoring ( ) ) ; assertTrue ( ! c . isCapturing ( ) ) ; System . out . println ( ) ; System . out . println ( ""*** resume flow"" ) ; c . registerThread ( ) ; method . invoke ( flow , new Object [ 0 ] ) ; if ( c . isCapturing ( ) ) c . getStack ( ) . popReference ( ) ; c . deregisterThread ( ) ; System . out . println ( ""*** return from flow"" ) ; System . out . println ( ) ; assertTrue ( ! c . isRestoring ( ) ) ; assertTrue ( c . isCapturing ( ) ) ; assertEquals ( redirector . getRedirect ( ) , ""cocoon:/page/getOperator"" ) ; request . addParameter ( ""operator"" , ""plus"" ) ; redirector . reset ( ) ; c = new Continuation ( c , context ) ; assertTrue ( c . isRestoring ( ) ) ; assertTrue ( ! c . isCapturing ( ) ) ; System . out . println ( ) ; System . out . println ( ""*** resume flow"" ) ; c . registerThread ( ) ; method . invoke ( flow , new Object [ 0 ] ) ; if ( c . isCapturing ( ) ) c . getStack ( ) . popReference ( ) ; c . deregisterThread ( ) ; System . out . println ( ""*** return from flow"" ) ; System . out . println ( ) ; assertTrue ( ! c . isRestoring ( ) ) ; assertTrue ( ! c . isCapturing ( ) ) ; assertEquals ( redirector . getRedirect ( ) , ""cocoon:/page/displayResult"" ) ; } public static void main ( String [ ] args ) throws Exception { new FlowTest ( ""test"" ) . testDelegate ( ) ; } }",Smelly
"public abstract class IvyPostResolveTask extends IvyTask { private String conf ; private boolean haltOnFailure = true ; private boolean transitive = true ; private boolean inline = false ; private String organisation ; private String module ; private String revision = ""latest.integration"" ; private String resolveId ; private String type ; private File file ; private Filter artifactFilter = null ; private boolean useOrigin = false ; private Boolean keep = null ; private String log = ResolveOptions . LOG_DEFAULT ; public boolean isUseOrigin ( ) { return useOrigin ; } public void setUseOrigin ( boolean useOrigin ) { this . useOrigin = useOrigin ; } public String getLog ( ) { return log ; } public void setLog ( String log ) { this . log = log ; } protected void prepareAndCheck ( ) { Ivy ivy = getIvyInstance ( ) ; IvySettings settings = ivy . getSettings ( ) ; boolean orgAndModSetManually = ( organisation != null ) && ( module != null ) ; organisation = getProperty ( organisation , settings , ""ivy.organisation"" ) ; module = getProperty ( module , settings , ""ivy.module"" ) ; if ( file == null ) { String fileName = getProperty ( settings , ""ivy.resolved.file"" , resolveId ) ; if ( fileName != null ) { file = getProject ( ) . resolveFile ( fileName ) ; } } if ( isInline ( ) ) { conf = conf == null ? ""*"" : conf ; if ( organisation == null ) { throw new BuildException ( ""no organisation provided for ivy cache task in inline mode: "" + ""It can either be set explicitely via the attribute 'organisation' "" + ""or via 'ivy.organisation' property"" ) ; } if ( module == null ) { throw new BuildException ( ""no module name provided for ivy cache task in inline mode: "" + ""It can either be set explicitely via the attribute 'module' "" + ""or via 'ivy.module' property"" ) ; } String [ ] toResolve = getConfsToResolve ( getOrganisation ( ) , getModule ( ) + ""-caller"" , conf , true ) ; for ( int i = 0 ; i < toResolve . length ; i ++ ) { if ( ""*"" . equals ( toResolve [ i ] ) ) { toResolve [ i ] = ""*(public)"" ; } } if ( toResolve . length > 0 ) { Message . verbose ( ""using inline mode to resolve "" + getOrganisation ( ) + "" "" + getModule ( ) + "" "" + getRevision ( ) + "" ("" + StringUtils . join ( toResolve , "", "" ) + "")"" ) ; IvyResolve resolve = createResolve ( isHaltonfailure ( ) , isUseOrigin ( ) ) ; resolve . setOrganisation ( getOrganisation ( ) ) ; resolve . setModule ( getModule ( ) ) ; resolve . setRevision ( getRevision ( ) ) ; resolve . setInline ( true ) ; resolve . setConf ( conf ) ; resolve . setResolveId ( resolveId ) ; resolve . setTransitive ( isTransitive ( ) ) ; resolve . execute ( ) ; } else { Message . verbose ( ""inline resolve already done for "" + getOrganisation ( ) + "" "" + getModule ( ) + "" "" + getRevision ( ) + "" ("" + conf + "")"" ) ; } if ( ""*"" . equals ( conf ) ) { conf = StringUtils . join ( getResolvedConfigurations ( getOrganisation ( ) , getModule ( ) + ""-caller"" , true ) , "", "" ) ; } } else { Message . debug ( ""using standard ensure resolved"" ) ; if ( ! orgAndModSetManually ) { ensureResolved ( settings ) ; } conf = getProperty ( conf , settings , ""ivy.resolved.configurations"" ) ; if ( ""*"" . equals ( conf ) ) { conf = getProperty ( settings , ""ivy.resolved.configurations"" ) ; if ( conf == null ) { throw new BuildException ( ""bad conf provided for ivy cache task: "" + ""'*' can only be used with a prior call to <resolve/>"" ) ; } } } organisation = getProperty ( organisation , settings , ""ivy.organisation"" ) ; module = getProperty ( module , settings , ""ivy.module"" ) ; if ( organisation == null ) { throw new BuildException ( ""no organisation provided for ivy cache task: "" + ""It can either be set explicitely via the attribute 'organisation' "" + ""or via 'ivy.organisation' property or a prior call to <resolve/>"" ) ; } if ( module == null ) { throw new BuildException ( ""no module name provided for ivy cache task: "" + ""It can either be set explicitely via the attribute 'module' "" + ""or via 'ivy.module' property or a prior call to <resolve/>"" ) ; } if ( conf == null ) { throw new BuildException ( ""no conf provided for ivy cache task: "" + ""It can either be set explicitely via the attribute 'conf' or "" + ""via 'ivy.resolved.configurations' property or a prior call to <resolve/>"" ) ; } artifactFilter = FilterHelper . getArtifactTypeFilter ( type ) ; } protected void ensureResolved ( IvySettings settings ) { String requestedConfigs = getProperty ( getConf ( ) , settings , ""ivy.resolved.configurations"" ) ; String [ ] confs = null ; if ( getResolveId ( ) != null ) { confs = getConfsToResolve ( getResolveId ( ) , requestedConfigs ) ; } else { confs = getConfsToResolve ( getOrganisation ( ) , getModule ( ) , requestedConfigs , false ) ; } if ( confs . length > 0 ) { IvyResolve resolve = createResolve ( isHaltonfailure ( ) , isUseOrigin ( ) ) ; resolve . setFile ( getFile ( ) ) ; resolve . setTransitive ( isTransitive ( ) ) ; resolve . setConf ( StringUtils . join ( confs , "", "" ) ) ; resolve . setResolveId ( getResolveId ( ) ) ; resolve . execute ( ) ; } } protected String [ ] getConfsToResolve ( String org , String module , String conf , boolean strict ) { ModuleDescriptor reference = ( ModuleDescriptor ) getResolvedDescriptor ( org , module , strict ) ; String [ ] rconfs = getResolvedConfigurations ( org , module , strict ) ; return getConfsToResolve ( reference , conf , rconfs ) ; } protected String [ ] getConfsToResolve ( String resolveId , String conf ) { ModuleDescriptor reference = ( ModuleDescriptor ) getResolvedDescriptor ( resolveId , false ) ; if ( reference == null ) { if ( conf == null ) { return new String [ ] { ""*"" } ; } else { return splitConfs ( conf ) ; } } String [ ] rconfs = ( String [ ] ) getProject ( ) . getReference ( ""ivy.resolved.configurations.ref."" + resolveId ) ; return getConfsToResolve ( reference , conf , rconfs ) ; } private String [ ] getConfsToResolve ( ModuleDescriptor reference , String conf , String [ ] rconfs ) { Message . debug ( ""calculating configurations to resolve"" ) ; if ( reference == null ) { Message . debug ( ""module not yet resolved, all confs still need to be resolved"" ) ; if ( conf == null ) { return new String [ ] { ""*"" } ; } else { return splitConfs ( conf ) ; } } else if ( conf != null ) { String [ ] confs ; if ( ""*"" . equals ( conf ) ) { confs = reference . getConfigurationsNames ( ) ; } else { confs = splitConfs ( conf ) ; } HashSet rconfsSet = new HashSet ( Arrays . asList ( rconfs ) ) ; ResolutionCacheManager cache = getSettings ( ) . getResolutionCacheManager ( ) ; for ( Iterator it = rconfsSet . iterator ( ) ; it . hasNext ( ) ; ) { String resolvedConf = ( String ) it . next ( ) ; String resolveId = getResolveId ( ) ; if ( resolveId == null ) { resolveId = ResolveOptions . getDefaultResolveId ( reference ) ; } File report = cache . getConfigurationResolveReportInCache ( resolveId , resolvedConf ) ; if ( ! report . exists ( ) ) { it . remove ( ) ; } } HashSet confsSet = new HashSet ( Arrays . asList ( confs ) ) ; Message . debug ( ""resolved configurations:   "" + rconfsSet ) ; Message . debug ( ""asked configurations:      "" + confsSet ) ; confsSet . removeAll ( rconfsSet ) ; Message . debug ( ""to resolve configurations: "" + confsSet ) ; return ( String [ ] ) confsSet . toArray ( new String [ confsSet . size ( ) ] ) ; } else { Message . debug ( ""module already resolved, no configuration to resolve"" ) ; return new String [ 0 ] ; } } protected IvyResolve createResolve ( boolean haltOnFailure , boolean useOrigin ) { Message . verbose ( ""no resolved descriptor found: launching default resolve"" ) ; IvyResolve resolve = new IvyResolve ( ) ; resolve . setTaskName ( getTaskName ( ) ) ; resolve . setProject ( getProject ( ) ) ; resolve . setHaltonfailure ( haltOnFailure ) ; resolve . setUseOrigin ( useOrigin ) ; resolve . setValidate ( isValidate ( ) ) ; resolve . setKeep ( isKeep ( ) ) ; resolve . setLog ( getLog ( ) ) ; resolve . setSettingsRef ( getSettingsRef ( ) ) ; return resolve ; } protected ModuleRevisionId getResolvedMrid ( ) { return new ModuleRevisionId ( getResolvedModuleId ( ) , getRevision ( ) == null ? Ivy . getWorkingRevision ( ) : getRevision ( ) ) ; } protected ModuleId getResolvedModuleId ( ) { return isInline ( ) ? new ModuleId ( getOrganisation ( ) , getModule ( ) + ""-caller"" ) : new ModuleId ( getOrganisation ( ) , getModule ( ) ) ; } protected ResolveReport getResolvedReport ( ) { return getResolvedReport ( getOrganisation ( ) , isInline ( ) ? getModule ( ) + ""-caller"" : getModule ( ) , resolveId ) ; } public String getType ( ) { return type ; } public void setType ( String type ) { this . type = type ; } public String getConf ( ) { return conf ; } public void setConf ( String conf ) { this . conf = conf ; } public String getModule ( ) { return module ; } public void setModule ( String module ) { this . module = module ; } public String getOrganisation ( ) { return organisation ; } public void setOrganisation ( String organisation ) { this . organisation = organisation ; } public boolean isHaltonfailure ( ) { return haltOnFailure ; } public void setHaltonfailure ( boolean haltOnFailure ) { this . haltOnFailure = haltOnFailure ; } public void setCache ( File cache ) { cacheAttributeNotSupported ( ) ; } public String getRevision ( ) { return revision ; } public void setRevision ( String rev ) { revision = rev ; } public Filter getArtifactFilter ( ) { return artifactFilter ; } public boolean isTransitive ( ) { return transitive ; } public void setTransitive ( boolean transitive ) { this . transitive = transitive ; } public boolean isInline ( ) { return inline ; } public void setInline ( boolean inline ) { this . inline = inline ; } public void setResolveId ( String resolveId ) { this . resolveId = resolveId ; } public String getResolveId ( ) { return resolveId ; } public void setFile ( File file ) { this . file = file ; } public File getFile ( ) { return file ; } public void setKeep ( boolean keep ) { this . keep = Boolean . valueOf ( keep ) ; } public boolean isKeep ( ) { return this . keep == null ? ! isInline ( ) : this . keep . booleanValue ( ) ; } }",Smelly
"@ Entity @ DiscriminatorValue ( ""StrF"" ) public class PIdJTSDMSCLeafC extends PIdJTSDMSCMappedSuperclass implements LeafC { private String leafCData ; public String getLeafCData ( ) { return leafCData ; } public void setLeafCData ( String leafCData ) { this . leafCData = leafCData ; } }",No
"public class XmlGraphGenerator extends GraphGeneratorSupport { private boolean addUrl = true ; public XmlGraphGenerator ( String dir ) { super ( dir , "".xml"" ) ; } protected void generateFile ( PrintWriter writer , Map < String , List < RouteType > > map ) { writer . println ( ""<?xml version='1.0' encoding='UTF-8'?>"" ) ; writer . println ( ""<Graph>"" ) ; writer . println ( ) ; if ( map . size ( ) > 0 ) { writer . println ( ""<Node id='root' name='Camel Routes' description='Collection of Camel Routes' nodeType='root'/>"" ) ; } printRoutes ( writer , map ) ; writer . println ( ) ; writer . println ( ""</Graph>"" ) ; } protected void printRoutes ( PrintWriter writer , Map < String , List < RouteType > > map ) { Set < Map . Entry < String , List < RouteType > > > entries = map . entrySet ( ) ; for ( Map . Entry < String , List < RouteType > > entry : entries ) { String group = entry . getKey ( ) ; printRoutes ( writer , group , entry . getValue ( ) ) ; } } protected void printRoutes ( PrintWriter writer , String group , List < RouteType > routes ) { group = encode ( group ) ; if ( group != null ) { int idx = group . lastIndexOf ( '.' ) ; String name = group ; if ( idx > 0 && idx < group . length ( ) - 1 ) { name = group . substring ( idx + 1 ) ; } writer . println ( ""<Node id='"" + group + ""' name='"" + name + ""' description='"" + group + ""' nodeType='group'/>"" ) ; writer . println ( ""<Edge fromID='root' toID='"" + group + ""'/>"" ) ; } for ( RouteType route : routes ) { List < FromType > inputs = route . getInputs ( ) ; boolean first = true ; for ( FromType input : inputs ) { NodeData nodeData = getNodeData ( input ) ; if ( first ) { first = false ; if ( group != null ) { writer . println ( ""<Edge fromID='"" + group + ""' toID='"" + encode ( nodeData . id ) + ""'/>"" ) ; } } printRoute ( writer , route , nodeData ) ; } writer . println ( ) ; } } protected void printRoute ( PrintWriter writer , final RouteType route , NodeData nodeData ) { printNode ( writer , nodeData ) ; NodeData from = nodeData ; for ( ProcessorType output : route . getOutputs ( ) ) { NodeData newData = printNode ( writer , from , output ) ; from = newData ; } } protected NodeData printNode ( PrintWriter writer , NodeData fromData , ProcessorType node ) { if ( node instanceof MulticastType ) { List < ProcessorType > outputs = node . getOutputs ( ) ; for ( ProcessorType output : outputs ) { printNode ( writer , fromData , output ) ; } return fromData ; } NodeData toData = getNodeData ( node ) ; printNode ( writer , toData ) ; if ( fromData != null ) { writer . print ( ""<Edge fromID=\"""" ) ; writer . print ( encode ( fromData . id ) ) ; writer . print ( ""\"" toID=\"""" ) ; writer . print ( encode ( toData . id ) ) ; String association = toData . edgeLabel ; if ( isNullOrBlank ( association ) ) { writer . print ( ""\"" association=\"""" ) ; writer . print ( encode ( association ) ) ; } writer . println ( ""\""/>"" ) ; } List < ProcessorType > outputs = toData . outputs ; if ( outputs != null ) { for ( ProcessorType output : outputs ) { NodeData newData = printNode ( writer , toData , output ) ; if ( ! isMulticastNode ( node ) ) { toData = newData ; } } } return toData ; } protected void printNode ( PrintWriter writer , NodeData data ) { if ( ! data . nodeWritten ) { data . nodeWritten = true ; writer . println ( ) ; writer . print ( ""<Node id=\"""" ) ; writer . print ( encode ( data . id ) ) ; writer . print ( ""\"" name=\"""" ) ; String name = data . label ; if ( isNullOrBlank ( name ) ) { name = data . tooltop ; } writer . print ( encode ( name ) ) ; writer . print ( ""\"" nodeType=\"""" ) ; String nodeType = data . image ; if ( isNullOrBlank ( nodeType ) ) { nodeType = data . shape ; if ( isNullOrBlank ( nodeType ) ) { nodeType = ""node"" ; } } writer . print ( encode ( nodeType ) ) ; writer . print ( ""\"" description=\"""" ) ; writer . print ( encode ( data . tooltop ) ) ; if ( addUrl ) { writer . print ( ""\"" url=\"""" ) ; writer . print ( encode ( data . url ) ) ; } writer . println ( ""\""/>"" ) ; } } protected String encode ( String text ) { if ( text == null ) { return """" ; } return text . replaceAll ( ""\"""" , ""&quot;"" ) . replaceAll ( ""<"" , ""&lt;"" ) . replaceAll ( "">"" , ""&gt;"" ) . replaceAll ( ""&"" , ""&amp;"" ) ; } }",Smelly
"public class PersistentDispatcherMultipleConsumers extends AbstractDispatcherMultipleConsumers implements Dispatcher , ReadEntriesCallback { protected final PersistentTopic topic ; protected final ManagedCursor cursor ; private CompletableFuture < Void > closeFuture = null ; LongPairSet messagesToRedeliver = new ConcurrentSortedLongPairSet ( 128 , 2 ) ; protected final RedeliveryTracker redeliveryTracker ; private Optional < DelayedDeliveryTracker > delayedDeliveryTracker = Optional . empty ( ) ; private final boolean isDelayedDeliveryEnabled ; private boolean havePendingRead = false ; private boolean havePendingReplayRead = false ; private boolean shouldRewindBeforeReadingOrReplaying = false ; protected final String name ; protected int totalAvailablePermits = 0 ; private int readBatchSize ; private final Backoff readFailureBackoff = new Backoff ( 15 , TimeUnit . SECONDS , 1 , TimeUnit . MINUTES , 0 , TimeUnit . MILLISECONDS ) ; private static final AtomicIntegerFieldUpdater < PersistentDispatcherMultipleConsumers > TOTAL_UNACKED_MESSAGES_UPDATER = AtomicIntegerFieldUpdater . newUpdater ( PersistentDispatcherMultipleConsumers . class , ""totalUnackedMessages"" ) ; private volatile int totalUnackedMessages = 0 ; private final int maxUnackedMessages ; private volatile int blockedDispatcherOnUnackedMsgs = FALSE ; private static final AtomicIntegerFieldUpdater < PersistentDispatcherMultipleConsumers > BLOCKED_DISPATCHER_ON_UNACKMSG_UPDATER = AtomicIntegerFieldUpdater . newUpdater ( PersistentDispatcherMultipleConsumers . class , ""blockedDispatcherOnUnackedMsgs"" ) ; protected final ServiceConfiguration serviceConfig ; protected Optional < DispatchRateLimiter > dispatchRateLimiter = Optional . empty ( ) ; enum ReadType { Normal , Replay } public PersistentDispatcherMultipleConsumers ( PersistentTopic topic , ManagedCursor cursor , Subscription subscription ) { super ( subscription ) ; this . serviceConfig = topic . getBrokerService ( ) . pulsar ( ) . getConfiguration ( ) ; this . cursor = cursor ; this . name = topic . getName ( ) + "" / "" + Codec . decode ( cursor . getName ( ) ) ; this . topic = topic ; this . redeliveryTracker = this . serviceConfig . isSubscriptionRedeliveryTrackerEnabled ( ) ? new InMemoryRedeliveryTracker ( ) : RedeliveryTrackerDisabled . REDELIVERY_TRACKER_DISABLED ; this . readBatchSize = serviceConfig . getDispatcherMaxReadBatchSize ( ) ; this . maxUnackedMessages = topic . getBrokerService ( ) . pulsar ( ) . getConfiguration ( ) . getMaxUnackedMessagesPerSubscription ( ) ; this . isDelayedDeliveryEnabled = topic . getBrokerService ( ) . pulsar ( ) . getConfiguration ( ) . isDelayedDeliveryEnabled ( ) ; this . initializeDispatchRateLimiterIfNeeded ( Optional . empty ( ) ) ; } @ Override public synchronized void addConsumer ( Consumer consumer ) throws BrokerServiceException { if ( IS_CLOSED_UPDATER . get ( this ) == TRUE ) { log . warn ( ""[{}] Dispatcher is already closed. Closing consumer "" , name , consumer ) ; consumer . disconnect ( ) ; return ; } if ( consumerList . isEmpty ( ) ) { if ( havePendingRead || havePendingReplayRead ) { shouldRewindBeforeReadingOrReplaying = true ; } else { cursor . rewind ( ) ; shouldRewindBeforeReadingOrReplaying = false ; } messagesToRedeliver . clear ( ) ; } if ( isConsumersExceededOnTopic ( ) ) { log . warn ( ""[{}] Attempting to add consumer to topic which reached max consumers limit"" , name ) ; throw new ConsumerBusyException ( ""Topic reached max consumers limit"" ) ; } if ( isConsumersExceededOnSubscription ( ) ) { log . warn ( ""[{}] Attempting to add consumer to subscription which reached max consumers limit"" , name ) ; throw new ConsumerBusyException ( ""Subscription reached max consumers limit"" ) ; } consumerList . add ( consumer ) ; consumerList . sort ( ( c1 , c2 ) -> c1 . getPriorityLevel ( ) - c2 . getPriorityLevel ( ) ) ; consumerSet . add ( consumer ) ; } private boolean isConsumersExceededOnTopic ( ) { Policies policies ; try { policies = topic . getBrokerService ( ) . pulsar ( ) . getConfigurationCache ( ) . policiesCache ( ) . get ( AdminResource . path ( POLICIES , TopicName . get ( topic . getName ( ) ) . getNamespace ( ) ) ) . orElseGet ( ( ) -> new Policies ( ) ) ; } catch ( Exception e ) { policies = new Policies ( ) ; } final int maxConsumersPerTopic = policies . max_consumers_per_topic > 0 ? policies . max_consumers_per_topic : serviceConfig . getMaxConsumersPerTopic ( ) ; if ( maxConsumersPerTopic > 0 && maxConsumersPerTopic <= topic . getNumberOfConsumers ( ) ) { return true ; } return false ; } private boolean isConsumersExceededOnSubscription ( ) { Policies policies ; try { policies = topic . getBrokerService ( ) . pulsar ( ) . getConfigurationCache ( ) . policiesCache ( ) . get ( AdminResource . path ( POLICIES , TopicName . get ( topic . getName ( ) ) . getNamespace ( ) ) ) . orElseGet ( ( ) -> new Policies ( ) ) ; } catch ( Exception e ) { policies = new Policies ( ) ; } final int maxConsumersPerSubscription = policies . max_consumers_per_subscription > 0 ? policies . max_consumers_per_subscription : serviceConfig . getMaxConsumersPerSubscription ( ) ; if ( maxConsumersPerSubscription > 0 && maxConsumersPerSubscription <= consumerList . size ( ) ) { return true ; } return false ; } @ Override public synchronized void removeConsumer ( Consumer consumer ) throws BrokerServiceException { addUnAckedMessages ( - consumer . getUnackedMessages ( ) ) ; if ( consumerSet . removeAll ( consumer ) == 1 ) { consumerList . remove ( consumer ) ; log . info ( ""Removed consumer {} with pending {} acks"" , consumer , consumer . getPendingAcks ( ) . size ( ) ) ; if ( consumerList . isEmpty ( ) ) { if ( havePendingRead && cursor . cancelPendingReadRequest ( ) ) { havePendingRead = false ; } messagesToRedeliver . clear ( ) ; if ( closeFuture != null ) { log . info ( ""[{}] All consumers removed. Subscription is disconnected"" , name ) ; closeFuture . complete ( null ) ; } totalAvailablePermits = 0 ; } else { if ( log . isDebugEnabled ( ) ) { log . debug ( ""[{}] Consumer are left, reading more entries"" , name ) ; } consumer . getPendingAcks ( ) . forEach ( ( ledgerId , entryId , batchSize , none ) -> { messagesToRedeliver . add ( ledgerId , entryId ) ; } ) ; totalAvailablePermits -= consumer . getAvailablePermits ( ) ; readMoreEntries ( ) ; } } else { if ( log . isDebugEnabled ( ) ) { log . debug ( ""[{}] Trying to remove a non-connected consumer: {}"" , name , consumer ) ; } } } @ Override public synchronized void consumerFlow ( Consumer consumer , int additionalNumberOfMessages ) { if ( ! consumerSet . contains ( consumer ) ) { if ( log . isDebugEnabled ( ) ) { log . debug ( ""[{}] Ignoring flow control from disconnected consumer {}"" , name , consumer ) ; } return ; } totalAvailablePermits += additionalNumberOfMessages ; if ( log . isDebugEnabled ( ) ) { log . debug ( ""[{}-{}] Trigger new read after receiving flow control message with permits {}"" , name , consumer , totalAvailablePermits ) ; } readMoreEntries ( ) ; } public void readMoreEntries ( ) { if ( totalAvailablePermits > 0 && isAtleastOneConsumerAvailable ( ) ) { int messagesToRead = Math . min ( totalAvailablePermits , readBatchSize ) ; if ( serviceConfig . isDispatchThrottlingOnNonBacklogConsumerEnabled ( ) || ! cursor . isActive ( ) ) { if ( topic . getDispatchRateLimiter ( ) . isPresent ( ) && topic . getDispatchRateLimiter ( ) . get ( ) . isDispatchRateLimitingEnabled ( ) ) { DispatchRateLimiter topicRateLimiter = topic . getDispatchRateLimiter ( ) . get ( ) ; if ( ! topicRateLimiter . hasMessageDispatchPermit ( ) ) { if ( log . isDebugEnabled ( ) ) { log . debug ( ""[{}] message-read exceeded topic message-rate {}/{}, schedule after a {}"" , name , topicRateLimiter . getDispatchRateOnMsg ( ) , topicRateLimiter . getDispatchRateOnByte ( ) , MESSAGE_RATE_BACKOFF_MS ) ; } topic . getBrokerService ( ) . executor ( ) . schedule ( ( ) -> readMoreEntries ( ) , MESSAGE_RATE_BACKOFF_MS , TimeUnit . MILLISECONDS ) ; return ; } else { long availablePermitsOnMsg = topicRateLimiter . getAvailableDispatchRateLimitOnMsg ( ) ; if ( availablePermitsOnMsg > 0 ) { messagesToRead = Math . min ( messagesToRead , ( int ) availablePermitsOnMsg ) ; } } } if ( dispatchRateLimiter . isPresent ( ) && dispatchRateLimiter . get ( ) . isDispatchRateLimitingEnabled ( ) ) { if ( ! dispatchRateLimiter . get ( ) . hasMessageDispatchPermit ( ) ) { if ( log . isDebugEnabled ( ) ) { log . debug ( ""[{}] message-read exceeded subscription message-rate {}/{}, schedule after a {}"" , name , dispatchRateLimiter . get ( ) . getDispatchRateOnMsg ( ) , dispatchRateLimiter . get ( ) . getDispatchRateOnByte ( ) , MESSAGE_RATE_BACKOFF_MS ) ; } topic . getBrokerService ( ) . executor ( ) . schedule ( ( ) -> readMoreEntries ( ) , MESSAGE_RATE_BACKOFF_MS , TimeUnit . MILLISECONDS ) ; return ; } else { long availablePermitsOnMsg = dispatchRateLimiter . get ( ) . getAvailableDispatchRateLimitOnMsg ( ) ; if ( availablePermitsOnMsg > 0 ) { messagesToRead = Math . min ( messagesToRead , ( int ) availablePermitsOnMsg ) ; } } } } if ( hasMessagesToReplay ( ) ) { if ( havePendingReplayRead ) { log . debug ( ""[{}] Skipping replay while awaiting previous read to complete"" , name ) ; return ; } Set < PositionImpl > messagesToReplayNow = getMessagesToReplayNow ( messagesToRead ) ; if ( log . isDebugEnabled ( ) ) { log . debug ( ""[{}] Schedule replay of {} messages for {} consumers"" , name , messagesToReplayNow . size ( ) , consumerList . size ( ) ) ; } havePendingReplayRead = true ; Set < ? extends Position > deletedMessages = asyncReplayEntries ( messagesToReplayNow ) ; deletedMessages . forEach ( position -> messagesToRedeliver . remove ( ( ( PositionImpl ) position ) . getLedgerId ( ) , ( ( PositionImpl ) position ) . getEntryId ( ) ) ) ; if ( ( messagesToReplayNow . size ( ) - deletedMessages . size ( ) ) == 0 ) { havePendingReplayRead = false ; readMoreEntries ( ) ; } } else if ( BLOCKED_DISPATCHER_ON_UNACKMSG_UPDATER . get ( this ) == TRUE ) { log . warn ( ""[{}] Dispatcher read is blocked due to unackMessages {} reached to max {}"" , name , totalUnackedMessages , maxUnackedMessages ) ; } else if ( ! havePendingRead ) { if ( log . isDebugEnabled ( ) ) { log . debug ( ""[{}] Schedule read of {} messages for {} consumers"" , name , messagesToRead , consumerList . size ( ) ) ; } havePendingRead = true ; cursor . asyncReadEntriesOrWait ( messagesToRead , this , ReadType . Normal ) ; } else { log . debug ( ""[{}] Cannot schedule next read until previous one is done"" , name ) ; } } else { if ( log . isDebugEnabled ( ) ) { log . debug ( ""[{}] Consumer buffer is full, pause reading"" , name ) ; } } } protected Set < ? extends Position > asyncReplayEntries ( Set < ? extends Position > positions ) { return cursor . asyncReplayEntries ( positions , this , ReadType . Replay ) ; } @ Override public boolean isConsumerConnected ( ) { return ! consumerList . isEmpty ( ) ; } @ Override public CopyOnWriteArrayList < Consumer > getConsumers ( ) { return consumerList ; } @ Override public synchronized boolean canUnsubscribe ( Consumer consumer ) { return consumerList . size ( ) == 1 && consumerSet . contains ( consumer ) ; } @ Override public CompletableFuture < Void > close ( ) { IS_CLOSED_UPDATER . set ( this , TRUE ) ; Optional < DelayedDeliveryTracker > delayedDeliveryTracker ; synchronized ( this ) { delayedDeliveryTracker = this . delayedDeliveryTracker ; this . delayedDeliveryTracker = Optional . empty ( ) ; } if ( delayedDeliveryTracker . isPresent ( ) ) { delayedDeliveryTracker . get ( ) . close ( ) ; } return disconnectAllConsumers ( ) ; } @ Override public synchronized CompletableFuture < Void > disconnectAllConsumers ( ) { closeFuture = new CompletableFuture < > ( ) ; if ( consumerList . isEmpty ( ) ) { closeFuture . complete ( null ) ; } else { consumerList . forEach ( Consumer :: disconnect ) ; if ( havePendingRead && cursor . cancelPendingReadRequest ( ) ) { havePendingRead = false ; } } return closeFuture ; } @ Override public void reset ( ) { IS_CLOSED_UPDATER . set ( this , FALSE ) ; } @ Override public SubType getType ( ) { return SubType . Shared ; } @ Override public synchronized void readEntriesComplete ( List < Entry > entries , Object ctx ) { ReadType readType = ( ReadType ) ctx ; if ( readType == ReadType . Normal ) { havePendingRead = false ; } else { havePendingReplayRead = false ; } if ( readBatchSize < serviceConfig . getDispatcherMaxReadBatchSize ( ) ) { int newReadBatchSize = Math . min ( readBatchSize * 2 , serviceConfig . getDispatcherMaxReadBatchSize ( ) ) ; if ( log . isDebugEnabled ( ) ) { log . debug ( ""[{}] Increasing read batch size from {} to {}"" , name , readBatchSize , newReadBatchSize ) ; } readBatchSize = newReadBatchSize ; } readFailureBackoff . reduceToHalf ( ) ; if ( shouldRewindBeforeReadingOrReplaying && readType == ReadType . Normal ) { entries . forEach ( Entry :: release ) ; cursor . rewind ( ) ; shouldRewindBeforeReadingOrReplaying = false ; readMoreEntries ( ) ; return ; } if ( log . isDebugEnabled ( ) ) { log . debug ( ""[{}] Distributing {} messages to {} consumers"" , name , entries . size ( ) , consumerList . size ( ) ) ; } sendMessagesToConsumers ( readType , entries ) ; } protected void sendMessagesToConsumers ( ReadType readType , List < Entry > entries ) { int start = 0 ; int entriesToDispatch = entries . size ( ) ; long totalMessagesSent = 0 ; long totalBytesSent = 0 ; while ( entriesToDispatch > 0 && totalAvailablePermits > 0 && isAtleastOneConsumerAvailable ( ) ) { Consumer c = getNextConsumer ( ) ; if ( c == null ) { log . info ( ""[{}] rewind because no available consumer found from total {}"" , name , consumerList . size ( ) ) ; entries . subList ( start , entries . size ( ) ) . forEach ( Entry :: release ) ; cursor . rewind ( ) ; return ; } int messagesForC = Math . min ( Math . min ( entriesToDispatch , c . getAvailablePermits ( ) ) , serviceConfig . getDispatcherMaxRoundRobinBatchSize ( ) ) ; if ( messagesForC > 0 ) { if ( readType == ReadType . Replay ) { entries . subList ( start , start + messagesForC ) . forEach ( entry -> { messagesToRedeliver . remove ( entry . getLedgerId ( ) , entry . getEntryId ( ) ) ; } ) ; } SendMessageInfo sendMessageInfo = SendMessageInfo . getThreadLocal ( ) ; List < Entry > entriesForThisConsumer = entries . subList ( start , start + messagesForC ) ; EntryBatchSizes batchSizes = EntryBatchSizes . get ( entriesForThisConsumer . size ( ) ) ; filterEntriesForConsumer ( entriesForThisConsumer , batchSizes , sendMessageInfo ) ; c . sendMessages ( entriesForThisConsumer , batchSizes , sendMessageInfo . getTotalMessages ( ) , sendMessageInfo . getTotalBytes ( ) , redeliveryTracker ) ; long msgSent = sendMessageInfo . getTotalMessages ( ) ; start += messagesForC ; entriesToDispatch -= messagesForC ; totalAvailablePermits -= msgSent ; totalMessagesSent += sendMessageInfo . getTotalMessages ( ) ; totalBytesSent += sendMessageInfo . getTotalBytes ( ) ; } } if ( serviceConfig . isDispatchThrottlingOnNonBacklogConsumerEnabled ( ) || ! cursor . isActive ( ) ) { if ( topic . getDispatchRateLimiter ( ) . isPresent ( ) ) { topic . getDispatchRateLimiter ( ) . get ( ) . tryDispatchPermit ( totalMessagesSent , totalBytesSent ) ; } if ( dispatchRateLimiter . isPresent ( ) ) { dispatchRateLimiter . get ( ) . tryDispatchPermit ( totalMessagesSent , totalBytesSent ) ; } } if ( entriesToDispatch > 0 ) { if ( log . isDebugEnabled ( ) ) { log . debug ( ""[{}] No consumers found with available permits, storing {} positions for later replay"" , name , entries . size ( ) - start ) ; } entries . subList ( start , entries . size ( ) ) . forEach ( entry -> { messagesToRedeliver . add ( entry . getLedgerId ( ) , entry . getEntryId ( ) ) ; entry . release ( ) ; } ) ; } readMoreEntries ( ) ; } @ Override public synchronized void readEntriesFailed ( ManagedLedgerException exception , Object ctx ) { ReadType readType = ( ReadType ) ctx ; long waitTimeMillis = readFailureBackoff . next ( ) ; if ( exception instanceof NoMoreEntriesToReadException ) { if ( cursor . getNumberOfEntriesInBacklog ( ) == 0 ) { consumerList . forEach ( Consumer :: reachedEndOfTopic ) ; } } else if ( ! ( exception instanceof TooManyRequestsException ) ) { log . error ( ""[{}] Error reading entries at {} : {}, Read Type {} - Retrying to read in {} seconds"" , name , cursor . getReadPosition ( ) , exception . getMessage ( ) , readType , waitTimeMillis / 1000.0 ) ; } else { if ( log . isDebugEnabled ( ) ) { log . debug ( ""[{}] Error reading entries at {} : {}, Read Type {} - Retrying to read in {} seconds"" , name , cursor . getReadPosition ( ) , exception . getMessage ( ) , readType , waitTimeMillis / 1000.0 ) ; } } if ( shouldRewindBeforeReadingOrReplaying ) { shouldRewindBeforeReadingOrReplaying = false ; cursor . rewind ( ) ; } if ( readType == ReadType . Normal ) { havePendingRead = false ; } else { havePendingReplayRead = false ; if ( exception instanceof ManagedLedgerException . InvalidReplayPositionException ) { PositionImpl markDeletePosition = ( PositionImpl ) cursor . getMarkDeletedPosition ( ) ; messagesToRedeliver . removeIf ( ( ledgerId , entryId ) -> { return ComparisonChain . start ( ) . compare ( ledgerId , markDeletePosition . getLedgerId ( ) ) . compare ( entryId , markDeletePosition . getEntryId ( ) ) . result ( ) <= 0 ; } ) ; } } readBatchSize = serviceConfig . getDispatcherMinReadBatchSize ( ) ; topic . getBrokerService ( ) . executor ( ) . schedule ( ( ) -> { synchronized ( PersistentDispatcherMultipleConsumers . this ) { if ( ! havePendingRead ) { log . info ( ""[{}] Retrying read operation"" , name ) ; readMoreEntries ( ) ; } else { log . info ( ""[{}] Skipping read retry: havePendingRead {}"" , name , havePendingRead , exception ) ; } } } , waitTimeMillis , TimeUnit . MILLISECONDS ) ; } protected boolean isAtleastOneConsumerAvailable ( ) { if ( consumerList . isEmpty ( ) || IS_CLOSED_UPDATER . get ( this ) == TRUE ) { return false ; } for ( Consumer consumer : consumerList ) { if ( isConsumerAvailable ( consumer ) ) { return true ; } } return false ; } @ Override public boolean isConsumerAvailable ( Consumer consumer ) { return consumer != null && ! consumer . isBlocked ( ) && consumer . getAvailablePermits ( ) > 0 ; } @ Override public synchronized void redeliverUnacknowledgedMessages ( Consumer consumer ) { consumer . getPendingAcks ( ) . forEach ( ( ledgerId , entryId , batchSize , none ) -> { messagesToRedeliver . add ( ledgerId , entryId ) ; } ) ; if ( log . isDebugEnabled ( ) ) { log . debug ( ""[{}-{}] Redelivering unacknowledged messages for consumer {}"" , name , consumer , messagesToRedeliver ) ; } readMoreEntries ( ) ; } @ Override public synchronized void redeliverUnacknowledgedMessages ( Consumer consumer , List < PositionImpl > positions ) { positions . forEach ( position -> { messagesToRedeliver . add ( position . getLedgerId ( ) , position . getEntryId ( ) ) ; redeliveryTracker . incrementAndGetRedeliveryCount ( position ) ; } ) ; if ( log . isDebugEnabled ( ) ) { log . debug ( ""[{}-{}] Redelivering unacknowledged messages for consumer {}"" , name , consumer , positions ) ; } readMoreEntries ( ) ; } @ Override public void addUnAckedMessages ( int numberOfMessages ) { if ( maxUnackedMessages <= 0 ) { return ; } int unAckedMessages = TOTAL_UNACKED_MESSAGES_UPDATER . addAndGet ( this , numberOfMessages ) ; if ( unAckedMessages >= maxUnackedMessages && BLOCKED_DISPATCHER_ON_UNACKMSG_UPDATER . compareAndSet ( this , FALSE , TRUE ) ) { log . info ( ""[{}] Dispatcher is blocked due to unackMessages {} reached to max {}"" , name , TOTAL_UNACKED_MESSAGES_UPDATER . get ( this ) , maxUnackedMessages ) ; } else if ( topic . getBrokerService ( ) . isBrokerDispatchingBlocked ( ) && blockedDispatcherOnUnackedMsgs == TRUE ) { if ( totalUnackedMessages < ( topic . getBrokerService ( ) . maxUnackedMsgsPerDispatcher / 2 ) ) { if ( BLOCKED_DISPATCHER_ON_UNACKMSG_UPDATER . compareAndSet ( this , TRUE , FALSE ) ) { topic . getBrokerService ( ) . unblockDispatchersOnUnAckMessages ( Lists . newArrayList ( this ) ) ; } } } else if ( blockedDispatcherOnUnackedMsgs == TRUE && unAckedMessages < maxUnackedMessages / 2 ) { if ( BLOCKED_DISPATCHER_ON_UNACKMSG_UPDATER . compareAndSet ( this , TRUE , FALSE ) ) { log . info ( ""[{}] Dispatcher is unblocked"" , name ) ; topic . getBrokerService ( ) . executor ( ) . execute ( ( ) -> readMoreEntries ( ) ) ; } } topic . getBrokerService ( ) . addUnAckedMessages ( this , numberOfMessages ) ; } public boolean isBlockedDispatcherOnUnackedMsgs ( ) { return blockedDispatcherOnUnackedMsgs == TRUE ; } public void blockDispatcherOnUnackedMsgs ( ) { blockedDispatcherOnUnackedMsgs = TRUE ; } public void unBlockDispatcherOnUnackedMsgs ( ) { blockedDispatcherOnUnackedMsgs = FALSE ; } public int getTotalUnackedMessages ( ) { return totalUnackedMessages ; } public String getName ( ) { return name ; } @ Override public RedeliveryTracker getRedeliveryTracker ( ) { return redeliveryTracker ; } @ Override public Optional < DispatchRateLimiter > getRateLimiter ( ) { return dispatchRateLimiter ; } @ Override public void initializeDispatchRateLimiterIfNeeded ( Optional < Policies > policies ) { if ( ! dispatchRateLimiter . isPresent ( ) && DispatchRateLimiter . isDispatchRateNeeded ( topic . getBrokerService ( ) , policies , topic . getName ( ) , Type . SUBSCRIPTION ) ) { this . dispatchRateLimiter = Optional . of ( new DispatchRateLimiter ( topic , Type . SUBSCRIPTION ) ) ; } } @ Override public synchronized boolean trackDelayedDelivery ( long ledgerId , long entryId , MessageMetadata msgMetadata ) { if ( ! isDelayedDeliveryEnabled ) { return false ; } if ( ! delayedDeliveryTracker . isPresent ( ) ) { delayedDeliveryTracker = Optional . of ( topic . getBrokerService ( ) . getDelayedDeliveryTrackerFactory ( ) . newTracker ( this ) ) ; } return delayedDeliveryTracker . get ( ) . addMessage ( ledgerId , entryId , msgMetadata . getDeliverAtTime ( ) ) ; } private boolean hasMessagesToReplay ( ) { if ( ! messagesToRedeliver . isEmpty ( ) ) { return true ; } if ( delayedDeliveryTracker . isPresent ( ) && delayedDeliveryTracker . get ( ) . hasMessageAvailable ( ) ) { return true ; } return false ; } private synchronized Set < PositionImpl > getMessagesToReplayNow ( int maxMessagesToRead ) { if ( ! messagesToRedeliver . isEmpty ( ) ) { return messagesToRedeliver . items ( maxMessagesToRead , ( ledgerId , entryId ) -> new PositionImpl ( ledgerId , entryId ) ) ; } else { return delayedDeliveryTracker . get ( ) . getScheduledMessages ( maxMessagesToRead ) ; } } public synchronized long getNumberOfDelayedMessages ( ) { if ( delayedDeliveryTracker . isPresent ( ) ) { return delayedDeliveryTracker . get ( ) . getNumberOfDelayedMessages ( ) ; } else { return 0 ; } } public PersistentTopic getTopic ( ) { return topic ; } private static final Logger log = LoggerFactory . getLogger ( PersistentDispatcherMultipleConsumers . class ) ; }",No
" public class WindowParser extends Parser { static { RuntimeMetaData . checkVersion ( ""4.5"" , RuntimeMetaData . VERSION ) ; } protected static final DFA [ ] _decisionToDFA ; protected static final PredictionContextCache _sharedContextCache = new PredictionContextCache ( ) ; public static final int COMMA = 1 , COLON = 2 , WINDOW = 3 , INCLUDE = 4 , EXCLUDE = 5 , FROM = 6 , EVERY = 7 , TO = 8 , AGO = 9 , NUMBER = 10 , IDENTIFIER = 11 , DAY_SPECIFIER = 12 , TIME_UNIT = 13 , WS = 14 ; public static final int RULE_window = 0 , RULE_window_expression = 1 , RULE_excluding_specifier = 2 , RULE_including_specifier = 3 , RULE_specifier = 4 , RULE_specifier_arg_list = 5 , RULE_day_specifier = 6 , RULE_identifier = 7 , RULE_specifier_list = 8 , RULE_duration = 9 , RULE_skip_distance = 10 , RULE_window_width = 11 , RULE_time_interval = 12 , RULE_time_amount = 13 , RULE_time_unit = 14 ; public static final String [ ] ruleNames = { ""window"" , ""window_expression"" , ""excluding_specifier"" , ""including_specifier"" , ""specifier"" , ""specifier_arg_list"" , ""day_specifier"" , ""identifier"" , ""specifier_list"" , ""duration"" , ""skip_distance"" , ""window_width"" , ""time_interval"" , ""time_amount"" , ""time_unit"" } ; private static final String [ ] _LITERAL_NAMES = { null , ""','"" , ""':'"" } ; private static final String [ ] _SYMBOLIC_NAMES = { null , ""COMMA"" , ""COLON"" , ""WINDOW"" , ""INCLUDE"" , ""EXCLUDE"" , ""FROM"" , ""EVERY"" , ""TO"" , ""AGO"" , ""NUMBER"" , ""IDENTIFIER"" , ""DAY_SPECIFIER"" , ""TIME_UNIT"" , ""WS"" } ; public static final Vocabulary VOCABULARY = new VocabularyImpl ( _LITERAL_NAMES , _SYMBOLIC_NAMES ) ; @ Deprecated public static final String [ ] tokenNames ; static { tokenNames = new String [ _SYMBOLIC_NAMES . length ] ; for ( int i = 0 ; i < tokenNames . length ; i ++ ) { tokenNames [ i ] = VOCABULARY . getLiteralName ( i ) ; if ( tokenNames [ i ] == null ) { tokenNames [ i ] = VOCABULARY . getSymbolicName ( i ) ; } if ( tokenNames [ i ] == null ) { tokenNames [ i ] = ""<INVALID>"" ; } } } @ Override @ Deprecated public String [ ] getTokenNames ( ) { return tokenNames ; } @ Override public Vocabulary getVocabulary ( ) { return VOCABULARY ; } @ Override public String getGrammarFileName ( ) { return ""Window.g4"" ; } @ Override public String [ ] getRuleNames ( ) { return ruleNames ; } @ Override public String getSerializedATN ( ) { return _serializedATN ; } @ Override public ATN getATN ( ) { return _ATN ; } public WindowParser ( TokenStream input ) { super ( input ) ; _interp = new ParserATNSimulator ( this , _ATN , _decisionToDFA , _sharedContextCache ) ; } public static class WindowContext extends ParserRuleContext { public Window_expressionContext window_expression ( ) { return getRuleContext ( Window_expressionContext . class , 0 ) ; } public TerminalNode EOF ( ) { return getToken ( WindowParser . EOF , 0 ) ; } public WindowContext ( ParserRuleContext parent , int invokingState ) { super ( parent , invokingState ) ; } @ Override public int getRuleIndex ( ) { return RULE_window ; } @ Override public void enterRule ( ParseTreeListener listener ) { if ( listener instanceof WindowListener ) ( ( WindowListener ) listener ) . enterWindow ( this ) ; } @ Override public void exitRule ( ParseTreeListener listener ) { if ( listener instanceof WindowListener ) ( ( WindowListener ) listener ) . exitWindow ( this ) ; } } public final WindowContext window ( ) throws RecognitionException { WindowContext _localctx = new WindowContext ( _ctx , getState ( ) ) ; enterRule ( _localctx , 0 , RULE_window ) ; try { enterOuterAlt ( _localctx , 1 ) ; { setState ( 30 ) ; window_expression ( ) ; setState ( 31 ) ; match ( EOF ) ; } } catch ( RecognitionException re ) { _localctx . exception = re ; _errHandler . reportError ( this , re ) ; _errHandler . recover ( this , re ) ; } finally { exitRule ( ) ; } return _localctx ; } public static class Window_expressionContext extends ParserRuleContext { public Window_expressionContext ( ParserRuleContext parent , int invokingState ) { super ( parent , invokingState ) ; } @ Override public int getRuleIndex ( ) { return RULE_window_expression ; } public Window_expressionContext ( ) { } public void copyFrom ( Window_expressionContext ctx ) { super . copyFrom ( ctx ) ; } } public static class RepeatingWindowContext extends Window_expressionContext { public Window_widthContext window_width ( ) { return getRuleContext ( Window_widthContext . class , 0 ) ; } public Skip_distanceContext skip_distance ( ) { return getRuleContext ( Skip_distanceContext . class , 0 ) ; } public DurationContext duration ( ) { return getRuleContext ( DurationContext . class , 0 ) ; } public Including_specifierContext including_specifier ( ) { return getRuleContext ( Including_specifierContext . class , 0 ) ; } public Excluding_specifierContext excluding_specifier ( ) { return getRuleContext ( Excluding_specifierContext . class , 0 ) ; } public RepeatingWindowContext ( Window_expressionContext ctx ) { copyFrom ( ctx ) ; } @ Override public void enterRule ( ParseTreeListener listener ) { if ( listener instanceof WindowListener ) ( ( WindowListener ) listener ) . enterRepeatingWindow ( this ) ; } @ Override public void exitRule ( ParseTreeListener listener ) { if ( listener instanceof WindowListener ) ( ( WindowListener ) listener ) . exitRepeatingWindow ( this ) ; } } public static class DenseWindowContext extends Window_expressionContext { public DurationContext duration ( ) { return getRuleContext ( DurationContext . class , 0 ) ; } public DenseWindowContext ( Window_expressionContext ctx ) { copyFrom ( ctx ) ; } @ Override public void enterRule ( ParseTreeListener listener ) { if ( listener instanceof WindowListener ) ( ( WindowListener ) listener ) . enterDenseWindow ( this ) ; } @ Override public void exitRule ( ParseTreeListener listener ) { if ( listener instanceof WindowListener ) ( ( WindowListener ) listener ) . exitDenseWindow ( this ) ; } } public static class NonRepeatingWindowContext extends Window_expressionContext { public Window_widthContext window_width ( ) { return getRuleContext ( Window_widthContext . class , 0 ) ; } public Including_specifierContext including_specifier ( ) { return getRuleContext ( Including_specifierContext . class , 0 ) ; } public Excluding_specifierContext excluding_specifier ( ) { return getRuleContext ( Excluding_specifierContext . class , 0 ) ; } public NonRepeatingWindowContext ( Window_expressionContext ctx ) { copyFrom ( ctx ) ; } @ Override public void enterRule ( ParseTreeListener listener ) { if ( listener instanceof WindowListener ) ( ( WindowListener ) listener ) . enterNonRepeatingWindow ( this ) ; } @ Override public void exitRule ( ParseTreeListener listener ) { if ( listener instanceof WindowListener ) ( ( WindowListener ) listener ) . exitNonRepeatingWindow ( this ) ; } } public final Window_expressionContext window_expression ( ) throws RecognitionException { Window_expressionContext _localctx = new Window_expressionContext ( _ctx , getState ( ) ) ; enterRule ( _localctx , 2 , RULE_window_expression ) ; int _la ; try { setState ( 50 ) ; switch ( getInterpreter ( ) . adaptivePredict ( _input , 4 , _ctx ) ) { case 1 : _localctx = new NonRepeatingWindowContext ( _localctx ) ; enterOuterAlt ( _localctx , 1 ) ; { setState ( 33 ) ; window_width ( ) ; setState ( 35 ) ; _la = _input . LA ( 1 ) ; if ( _la == INCLUDE ) { { setState ( 34 ) ; including_specifier ( ) ; } } setState ( 38 ) ; _la = _input . LA ( 1 ) ; if ( _la == EXCLUDE ) { { setState ( 37 ) ; excluding_specifier ( ) ; } } } break ; case 2 : _localctx = new RepeatingWindowContext ( _localctx ) ; enterOuterAlt ( _localctx , 2 ) ; { setState ( 40 ) ; window_width ( ) ; setState ( 41 ) ; skip_distance ( ) ; setState ( 42 ) ; duration ( ) ; setState ( 44 ) ; _la = _input . LA ( 1 ) ; if ( _la == INCLUDE ) { { setState ( 43 ) ; including_specifier ( ) ; } } setState ( 47 ) ; _la = _input . LA ( 1 ) ; if ( _la == EXCLUDE ) { { setState ( 46 ) ; excluding_specifier ( ) ; } } } break ; case 3 : _localctx = new DenseWindowContext ( _localctx ) ; enterOuterAlt ( _localctx , 3 ) ; { setState ( 49 ) ; duration ( ) ; } break ; } } catch ( RecognitionException re ) { _localctx . exception = re ; _errHandler . reportError ( this , re ) ; _errHandler . recover ( this , re ) ; } finally { exitRule ( ) ; } return _localctx ; } public static class Excluding_specifierContext extends ParserRuleContext { public TerminalNode EXCLUDE ( ) { return getToken ( WindowParser . EXCLUDE , 0 ) ; } public Specifier_listContext specifier_list ( ) { return getRuleContext ( Specifier_listContext . class , 0 ) ; } public Excluding_specifierContext ( ParserRuleContext parent , int invokingState ) { super ( parent , invokingState ) ; } @ Override public int getRuleIndex ( ) { return RULE_excluding_specifier ; } @ Override public void enterRule ( ParseTreeListener listener ) { if ( listener instanceof WindowListener ) ( ( WindowListener ) listener ) . enterExcluding_specifier ( this ) ; } @ Override public void exitRule ( ParseTreeListener listener ) { if ( listener instanceof WindowListener ) ( ( WindowListener ) listener ) . exitExcluding_specifier ( this ) ; } } public final Excluding_specifierContext excluding_specifier ( ) throws RecognitionException { Excluding_specifierContext _localctx = new Excluding_specifierContext ( _ctx , getState ( ) ) ; enterRule ( _localctx , 4 , RULE_excluding_specifier ) ; try { enterOuterAlt ( _localctx , 1 ) ; { setState ( 52 ) ; match ( EXCLUDE ) ; setState ( 53 ) ; specifier_list ( 0 ) ; } } catch ( RecognitionException re ) { _localctx . exception = re ; _errHandler . reportError ( this , re ) ; _errHandler . recover ( this , re ) ; } finally { exitRule ( ) ; } return _localctx ; } public static class Including_specifierContext extends ParserRuleContext { public TerminalNode INCLUDE ( ) { return getToken ( WindowParser . INCLUDE , 0 ) ; } public Specifier_listContext specifier_list ( ) { return getRuleContext ( Specifier_listContext . class , 0 ) ; } public Including_specifierContext ( ParserRuleContext parent , int invokingState ) { super ( parent , invokingState ) ; } @ Override public int getRuleIndex ( ) { return RULE_including_specifier ; } @ Override public void enterRule ( ParseTreeListener listener ) { if ( listener instanceof WindowListener ) ( ( WindowListener ) listener ) . enterIncluding_specifier ( this ) ; } @ Override public void exitRule ( ParseTreeListener listener ) { if ( listener instanceof WindowListener ) ( ( WindowListener ) listener ) . exitIncluding_specifier ( this ) ; } } public final Including_specifierContext including_specifier ( ) throws RecognitionException { Including_specifierContext _localctx = new Including_specifierContext ( _ctx , getState ( ) ) ; enterRule ( _localctx , 6 , RULE_including_specifier ) ; try { enterOuterAlt ( _localctx , 1 ) ; { setState ( 55 ) ; match ( INCLUDE ) ; setState ( 56 ) ; specifier_list ( 0 ) ; } } catch ( RecognitionException re ) { _localctx . exception = re ; _errHandler . reportError ( this , re ) ; _errHandler . recover ( this , re ) ; } finally { exitRule ( ) ; } return _localctx ; } public static class SpecifierContext extends ParserRuleContext { public Day_specifierContext day_specifier ( ) { return getRuleContext ( Day_specifierContext . class , 0 ) ; } public Specifier_arg_listContext specifier_arg_list ( ) { return getRuleContext ( Specifier_arg_listContext . class , 0 ) ; } public SpecifierContext ( ParserRuleContext parent , int invokingState ) { super ( parent , invokingState ) ; } @ Override public int getRuleIndex ( ) { return RULE_specifier ; } @ Override public void enterRule ( ParseTreeListener listener ) { if ( listener instanceof WindowListener ) ( ( WindowListener ) listener ) . enterSpecifier ( this ) ; } @ Override public void exitRule ( ParseTreeListener listener ) { if ( listener instanceof WindowListener ) ( ( WindowListener ) listener ) . exitSpecifier ( this ) ; } } public final SpecifierContext specifier ( ) throws RecognitionException { SpecifierContext _localctx = new SpecifierContext ( _ctx , getState ( ) ) ; enterRule ( _localctx , 8 , RULE_specifier ) ; try { setState ( 62 ) ; switch ( getInterpreter ( ) . adaptivePredict ( _input , 5 , _ctx ) ) { case 1 : enterOuterAlt ( _localctx , 1 ) ; { setState ( 58 ) ; day_specifier ( ) ; } break ; case 2 : enterOuterAlt ( _localctx , 2 ) ; { setState ( 59 ) ; day_specifier ( ) ; setState ( 60 ) ; specifier_arg_list ( ) ; } break ; } } catch ( RecognitionException re ) { _localctx . exception = re ; _errHandler . reportError ( this , re ) ; _errHandler . recover ( this , re ) ; } finally { exitRule ( ) ; } return _localctx ; } public static class Specifier_arg_listContext extends ParserRuleContext { public IdentifierContext identifier ( ) { return getRuleContext ( IdentifierContext . class , 0 ) ; } public Specifier_arg_listContext specifier_arg_list ( ) { return getRuleContext ( Specifier_arg_listContext . class , 0 ) ; } public Specifier_arg_listContext ( ParserRuleContext parent , int invokingState ) { super ( parent , invokingState ) ; } @ Override public int getRuleIndex ( ) { return RULE_specifier_arg_list ; } @ Override public void enterRule ( ParseTreeListener listener ) { if ( listener instanceof WindowListener ) ( ( WindowListener ) listener ) . enterSpecifier_arg_list ( this ) ; } @ Override public void exitRule ( ParseTreeListener listener ) { if ( listener instanceof WindowListener ) ( ( WindowListener ) listener ) . exitSpecifier_arg_list ( this ) ; } } public final Specifier_arg_listContext specifier_arg_list ( ) throws RecognitionException { Specifier_arg_listContext _localctx = new Specifier_arg_listContext ( _ctx , getState ( ) ) ; enterRule ( _localctx , 10 , RULE_specifier_arg_list ) ; try { setState ( 68 ) ; switch ( getInterpreter ( ) . adaptivePredict ( _input , 6 , _ctx ) ) { case 1 : enterOuterAlt ( _localctx , 1 ) ; { setState ( 64 ) ; identifier ( ) ; } break ; case 2 : enterOuterAlt ( _localctx , 2 ) ; { setState ( 65 ) ; identifier ( ) ; setState ( 66 ) ; specifier_arg_list ( ) ; } break ; } } catch ( RecognitionException re ) { _localctx . exception = re ; _errHandler . reportError ( this , re ) ; _errHandler . recover ( this , re ) ; } finally { exitRule ( ) ; } return _localctx ; } public static class Day_specifierContext extends ParserRuleContext { public TerminalNode DAY_SPECIFIER ( ) { return getToken ( WindowParser . DAY_SPECIFIER , 0 ) ; } public Day_specifierContext ( ParserRuleContext parent , int invokingState ) { super ( parent , invokingState ) ; } @ Override public int getRuleIndex ( ) { return RULE_day_specifier ; } @ Override public void enterRule ( ParseTreeListener listener ) { if ( listener instanceof WindowListener ) ( ( WindowListener ) listener ) . enterDay_specifier ( this ) ; } @ Override public void exitRule ( ParseTreeListener listener ) { if ( listener instanceof WindowListener ) ( ( WindowListener ) listener ) . exitDay_specifier ( this ) ; } } public final Day_specifierContext day_specifier ( ) throws RecognitionException { Day_specifierContext _localctx = new Day_specifierContext ( _ctx , getState ( ) ) ; enterRule ( _localctx , 12 , RULE_day_specifier ) ; try { enterOuterAlt ( _localctx , 1 ) ; { setState ( 70 ) ; match ( DAY_SPECIFIER ) ; } } catch ( RecognitionException re ) { _localctx . exception = re ; _errHandler . reportError ( this , re ) ; _errHandler . recover ( this , re ) ; } finally { exitRule ( ) ; } return _localctx ; } public static class IdentifierContext extends ParserRuleContext { public TerminalNode NUMBER ( ) { return getToken ( WindowParser . NUMBER , 0 ) ; } public TerminalNode IDENTIFIER ( ) { return getToken ( WindowParser . IDENTIFIER , 0 ) ; } public IdentifierContext ( ParserRuleContext parent , int invokingState ) { super ( parent , invokingState ) ; } @ Override public int getRuleIndex ( ) { return RULE_identifier ; } @ Override public void enterRule ( ParseTreeListener listener ) { if ( listener instanceof WindowListener ) ( ( WindowListener ) listener ) . enterIdentifier ( this ) ; } @ Override public void exitRule ( ParseTreeListener listener ) { if ( listener instanceof WindowListener ) ( ( WindowListener ) listener ) . exitIdentifier ( this ) ; } } public final IdentifierContext identifier ( ) throws RecognitionException { IdentifierContext _localctx = new IdentifierContext ( _ctx , getState ( ) ) ; enterRule ( _localctx , 14 , RULE_identifier ) ; int _la ; try { enterOuterAlt ( _localctx , 1 ) ; { setState ( 72 ) ; _la = _input . LA ( 1 ) ; if ( ! ( _la == NUMBER || _la == IDENTIFIER ) ) { _errHandler . recoverInline ( this ) ; } else { consume ( ) ; } } } catch ( RecognitionException re ) { _localctx . exception = re ; _errHandler . reportError ( this , re ) ; _errHandler . recover ( this , re ) ; } finally { exitRule ( ) ; } return _localctx ; } public static class Specifier_listContext extends ParserRuleContext { public SpecifierContext specifier ( ) { return getRuleContext ( SpecifierContext . class , 0 ) ; } public Specifier_listContext specifier_list ( ) { return getRuleContext ( Specifier_listContext . class , 0 ) ; } public TerminalNode COMMA ( ) { return getToken ( WindowParser . COMMA , 0 ) ; } public Specifier_listContext ( ParserRuleContext parent , int invokingState ) { super ( parent , invokingState ) ; } @ Override public int getRuleIndex ( ) { return RULE_specifier_list ; } @ Override public void enterRule ( ParseTreeListener listener ) { if ( listener instanceof WindowListener ) ( ( WindowListener ) listener ) . enterSpecifier_list ( this ) ; } @ Override public void exitRule ( ParseTreeListener listener ) { if ( listener instanceof WindowListener ) ( ( WindowListener ) listener ) . exitSpecifier_list ( this ) ; } } public final Specifier_listContext specifier_list ( ) throws RecognitionException { return specifier_list ( 0 ) ; } private Specifier_listContext specifier_list ( int _p ) throws RecognitionException { ParserRuleContext _parentctx = _ctx ; int _parentState = getState ( ) ; Specifier_listContext _localctx = new Specifier_listContext ( _ctx , _parentState ) ; Specifier_listContext _prevctx = _localctx ; int _startState = 16 ; enterRecursionRule ( _localctx , 16 , RULE_specifier_list , _p ) ; try { int _alt ; enterOuterAlt ( _localctx , 1 ) ; { { setState ( 75 ) ; specifier ( ) ; } _ctx . stop = _input . LT ( - 1 ) ; setState ( 82 ) ; _errHandler . sync ( this ) ; _alt = getInterpreter ( ) . adaptivePredict ( _input , 7 , _ctx ) ; while ( _alt != 2 && _alt != org . antlr . v4 . runtime . atn . ATN . INVALID_ALT_NUMBER ) { if ( _alt == 1 ) { if ( _parseListeners != null ) triggerExitRuleEvent ( ) ; _prevctx = _localctx ; { { _localctx = new Specifier_listContext ( _parentctx , _parentState ) ; pushNewRecursionContext ( _localctx , _startState , RULE_specifier_list ) ; setState ( 77 ) ; if ( ! ( precpred ( _ctx , 1 ) ) ) throw new FailedPredicateException ( this , ""precpred(_ctx, 1)"" ) ; setState ( 78 ) ; match ( COMMA ) ; setState ( 79 ) ; specifier ( ) ; } } } setState ( 84 ) ; _errHandler . sync ( this ) ; _alt = getInterpreter ( ) . adaptivePredict ( _input , 7 , _ctx ) ; } } } catch ( RecognitionException re ) { _localctx . exception = re ; _errHandler . reportError ( this , re ) ; _errHandler . recover ( this , re ) ; } finally { unrollRecursionContexts ( _parentctx ) ; } return _localctx ; } public static class DurationContext extends ParserRuleContext { public DurationContext ( ParserRuleContext parent , int invokingState ) { super ( parent , invokingState ) ; } @ Override public int getRuleIndex ( ) { return RULE_duration ; } public DurationContext ( ) { } public void copyFrom ( DurationContext ctx ) { super . copyFrom ( ctx ) ; } } public static class FromToDurationContext extends DurationContext { public TerminalNode FROM ( ) { return getToken ( WindowParser . FROM , 0 ) ; } public List < Time_intervalContext > time_interval ( ) { return getRuleContexts ( Time_intervalContext . class ) ; } public Time_intervalContext time_interval ( int i ) { return getRuleContext ( Time_intervalContext . class , i ) ; } public TerminalNode TO ( ) { return getToken ( WindowParser . TO , 0 ) ; } public List < TerminalNode > AGO ( ) { return getTokens ( WindowParser . AGO ) ; } public TerminalNode AGO ( int i ) { return getToken ( WindowParser . AGO , i ) ; } public FromToDurationContext ( DurationContext ctx ) { copyFrom ( ctx ) ; } @ Override public void enterRule ( ParseTreeListener listener ) { if ( listener instanceof WindowListener ) ( ( WindowListener ) listener ) . enterFromToDuration ( this ) ; } @ Override public void exitRule ( ParseTreeListener listener ) { if ( listener instanceof WindowListener ) ( ( WindowListener ) listener ) . exitFromToDuration ( this ) ; } } public static class FromDurationContext extends DurationContext { public TerminalNode FROM ( ) { return getToken ( WindowParser . FROM , 0 ) ; } public Time_intervalContext time_interval ( ) { return getRuleContext ( Time_intervalContext . class , 0 ) ; } public TerminalNode AGO ( ) { return getToken ( WindowParser . AGO , 0 ) ; } public FromDurationContext ( DurationContext ctx ) { copyFrom ( ctx ) ; } @ Override public void enterRule ( ParseTreeListener listener ) { if ( listener instanceof WindowListener ) ( ( WindowListener ) listener ) . enterFromDuration ( this ) ; } @ Override public void exitRule ( ParseTreeListener listener ) { if ( listener instanceof WindowListener ) ( ( WindowListener ) listener ) . exitFromDuration ( this ) ; } } public final DurationContext duration ( ) throws RecognitionException { DurationContext _localctx = new DurationContext ( _ctx , getState ( ) ) ; enterRule ( _localctx , 18 , RULE_duration ) ; int _la ; try { setState ( 100 ) ; switch ( getInterpreter ( ) . adaptivePredict ( _input , 11 , _ctx ) ) { case 1 : _localctx = new FromToDurationContext ( _localctx ) ; enterOuterAlt ( _localctx , 1 ) ; { setState ( 85 ) ; match ( FROM ) ; setState ( 86 ) ; time_interval ( ) ; setState ( 88 ) ; _la = _input . LA ( 1 ) ; if ( _la == AGO ) { { setState ( 87 ) ; match ( AGO ) ; } } setState ( 90 ) ; match ( TO ) ; setState ( 91 ) ; time_interval ( ) ; setState ( 93 ) ; _la = _input . LA ( 1 ) ; if ( _la == AGO ) { { setState ( 92 ) ; match ( AGO ) ; } } } break ; case 2 : _localctx = new FromDurationContext ( _localctx ) ; enterOuterAlt ( _localctx , 2 ) ; { setState ( 95 ) ; match ( FROM ) ; setState ( 96 ) ; time_interval ( ) ; setState ( 98 ) ; _la = _input . LA ( 1 ) ; if ( _la == AGO ) { { setState ( 97 ) ; match ( AGO ) ; } } } break ; } } catch ( RecognitionException re ) { _localctx . exception = re ; _errHandler . reportError ( this , re ) ; _errHandler . recover ( this , re ) ; } finally { exitRule ( ) ; } return _localctx ; } public static class Skip_distanceContext extends ParserRuleContext { public Skip_distanceContext ( ParserRuleContext parent , int invokingState ) { super ( parent , invokingState ) ; } @ Override public int getRuleIndex ( ) { return RULE_skip_distance ; } public Skip_distanceContext ( ) { } public void copyFrom ( Skip_distanceContext ctx ) { super . copyFrom ( ctx ) ; } } public static class SkipDistanceContext extends Skip_distanceContext { public TerminalNode EVERY ( ) { return getToken ( WindowParser . EVERY , 0 ) ; } public Time_intervalContext time_interval ( ) { return getRuleContext ( Time_intervalContext . class , 0 ) ; } public SkipDistanceContext ( Skip_distanceContext ctx ) { copyFrom ( ctx ) ; } @ Override public void enterRule ( ParseTreeListener listener ) { if ( listener instanceof WindowListener ) ( ( WindowListener ) listener ) . enterSkipDistance ( this ) ; } @ Override public void exitRule ( ParseTreeListener listener ) { if ( listener instanceof WindowListener ) ( ( WindowListener ) listener ) . exitSkipDistance ( this ) ; } } public final Skip_distanceContext skip_distance ( ) throws RecognitionException { Skip_distanceContext _localctx = new Skip_distanceContext ( _ctx , getState ( ) ) ; enterRule ( _localctx , 20 , RULE_skip_distance ) ; try { _localctx = new SkipDistanceContext ( _localctx ) ; enterOuterAlt ( _localctx , 1 ) ; { setState ( 102 ) ; match ( EVERY ) ; setState ( 103 ) ; time_interval ( ) ; } } catch ( RecognitionException re ) { _localctx . exception = re ; _errHandler . reportError ( this , re ) ; _errHandler . recover ( this , re ) ; } finally { exitRule ( ) ; } return _localctx ; } public static class Window_widthContext extends ParserRuleContext { public Window_widthContext ( ParserRuleContext parent , int invokingState ) { super ( parent , invokingState ) ; } @ Override public int getRuleIndex ( ) { return RULE_window_width ; } public Window_widthContext ( ) { } public void copyFrom ( Window_widthContext ctx ) { super . copyFrom ( ctx ) ; } } public static class WindowWidthContext extends Window_widthContext { public Time_intervalContext time_interval ( ) { return getRuleContext ( Time_intervalContext . class , 0 ) ; } public TerminalNode WINDOW ( ) { return getToken ( WindowParser . WINDOW , 0 ) ; } public WindowWidthContext ( Window_widthContext ctx ) { copyFrom ( ctx ) ; } @ Override public void enterRule ( ParseTreeListener listener ) { if ( listener instanceof WindowListener ) ( ( WindowListener ) listener ) . enterWindowWidth ( this ) ; } @ Override public void exitRule ( ParseTreeListener listener ) { if ( listener instanceof WindowListener ) ( ( WindowListener ) listener ) . exitWindowWidth ( this ) ; } } public final Window_widthContext window_width ( ) throws RecognitionException { Window_widthContext _localctx = new Window_widthContext ( _ctx , getState ( ) ) ; enterRule ( _localctx , 22 , RULE_window_width ) ; int _la ; try { _localctx = new WindowWidthContext ( _localctx ) ; enterOuterAlt ( _localctx , 1 ) ; { setState ( 105 ) ; time_interval ( ) ; setState ( 107 ) ; _la = _input . LA ( 1 ) ; if ( _la == WINDOW ) { { setState ( 106 ) ; match ( WINDOW ) ; } } } } catch ( RecognitionException re ) { _localctx . exception = re ; _errHandler . reportError ( this , re ) ; _errHandler . recover ( this , re ) ; } finally { exitRule ( ) ; } return _localctx ; } public static class Time_intervalContext extends ParserRuleContext { public Time_intervalContext ( ParserRuleContext parent , int invokingState ) { super ( parent , invokingState ) ; } @ Override public int getRuleIndex ( ) { return RULE_time_interval ; } public Time_intervalContext ( ) { } public void copyFrom ( Time_intervalContext ctx ) { super . copyFrom ( ctx ) ; } } public static class TimeIntervalContext extends Time_intervalContext { public Time_amountContext time_amount ( ) { return getRuleContext ( Time_amountContext . class , 0 ) ; } public Time_unitContext time_unit ( ) { return getRuleContext ( Time_unitContext . class , 0 ) ; } public TimeIntervalContext ( Time_intervalContext ctx ) { copyFrom ( ctx ) ; } @ Override public void enterRule ( ParseTreeListener listener ) { if ( listener instanceof WindowListener ) ( ( WindowListener ) listener ) . enterTimeInterval ( this ) ; } @ Override public void exitRule ( ParseTreeListener listener ) { if ( listener instanceof WindowListener ) ( ( WindowListener ) listener ) . exitTimeInterval ( this ) ; } } public final Time_intervalContext time_interval ( ) throws RecognitionException { Time_intervalContext _localctx = new Time_intervalContext ( _ctx , getState ( ) ) ; enterRule ( _localctx , 24 , RULE_time_interval ) ; try { _localctx = new TimeIntervalContext ( _localctx ) ; enterOuterAlt ( _localctx , 1 ) ; { setState ( 109 ) ; time_amount ( ) ; setState ( 110 ) ; time_unit ( ) ; } } catch ( RecognitionException re ) { _localctx . exception = re ; _errHandler . reportError ( this , re ) ; _errHandler . recover ( this , re ) ; } finally { exitRule ( ) ; } return _localctx ; } public static class Time_amountContext extends ParserRuleContext { public Time_amountContext ( ParserRuleContext parent , int invokingState ) { super ( parent , invokingState ) ; } @ Override public int getRuleIndex ( ) { return RULE_time_amount ; } public Time_amountContext ( ) { } public void copyFrom ( Time_amountContext ctx ) { super . copyFrom ( ctx ) ; } } public static class TimeAmountContext extends Time_amountContext { public TerminalNode NUMBER ( ) { return getToken ( WindowParser . NUMBER , 0 ) ; } public TimeAmountContext ( Time_amountContext ctx ) { copyFrom ( ctx ) ; } @ Override public void enterRule ( ParseTreeListener listener ) { if ( listener instanceof WindowListener ) ( ( WindowListener ) listener ) . enterTimeAmount ( this ) ; } @ Override public void exitRule ( ParseTreeListener listener ) { if ( listener instanceof WindowListener ) ( ( WindowListener ) listener ) . exitTimeAmount ( this ) ; } } public final Time_amountContext time_amount ( ) throws RecognitionException { Time_amountContext _localctx = new Time_amountContext ( _ctx , getState ( ) ) ; enterRule ( _localctx , 26 , RULE_time_amount ) ; try { _localctx = new TimeAmountContext ( _localctx ) ; enterOuterAlt ( _localctx , 1 ) ; { setState ( 112 ) ; match ( NUMBER ) ; } } catch ( RecognitionException re ) { _localctx . exception = re ; _errHandler . reportError ( this , re ) ; _errHandler . recover ( this , re ) ; } finally { exitRule ( ) ; } return _localctx ; } public static class Time_unitContext extends ParserRuleContext { public Time_unitContext ( ParserRuleContext parent , int invokingState ) { super ( parent , invokingState ) ; } @ Override public int getRuleIndex ( ) { return RULE_time_unit ; } public Time_unitContext ( ) { } public void copyFrom ( Time_unitContext ctx ) { super . copyFrom ( ctx ) ; } } public static class TimeUnitContext extends Time_unitContext { public TerminalNode TIME_UNIT ( ) { return getToken ( WindowParser . TIME_UNIT , 0 ) ; } public TimeUnitContext ( Time_unitContext ctx ) { copyFrom ( ctx ) ; } @ Override public void enterRule ( ParseTreeListener listener ) { if ( listener instanceof WindowListener ) ( ( WindowListener ) listener ) . enterTimeUnit ( this ) ; } @ Override public void exitRule ( ParseTreeListener listener ) { if ( listener instanceof WindowListener ) ( ( WindowListener ) listener ) . exitTimeUnit ( this ) ; } } public final Time_unitContext time_unit ( ) throws RecognitionException { Time_unitContext _localctx = new Time_unitContext ( _ctx , getState ( ) ) ; enterRule ( _localctx , 28 , RULE_time_unit ) ; try { _localctx = new TimeUnitContext ( _localctx ) ; enterOuterAlt ( _localctx , 1 ) ; { setState ( 114 ) ; match ( TIME_UNIT ) ; } } catch ( RecognitionException re ) { _localctx . exception = re ; _errHandler . reportError ( this , re ) ; _errHandler . recover ( this , re ) ; } finally { exitRule ( ) ; } return _localctx ; } public boolean sempred ( RuleContext _localctx , int ruleIndex , int predIndex ) { switch ( ruleIndex ) { case 8 : return specifier_list_sempred ( ( Specifier_listContext ) _localctx , predIndex ) ; } return true ; } private boolean specifier_list_sempred ( Specifier_listContext _localctx , int predIndex ) { switch ( predIndex ) { case 0 : return precpred ( _ctx , 1 ) ; } return true ; } public static final String _serializedATN = ""\3\u0430\ud6d1\u8206\uad2d\u4417\uaef1\u8d80\uaadd\3\20w\4\2\t\2\4\3\t"" + ""\3\4\4\t\4\4\5\t\5\4\6\t\6\4\7\t\7\4\b\t\b\4\t\t\t\4\n\t\n\4\13\t\13\4"" + ""\f\t\f\4\r\t\r\4\16\t\16\4\17\t\17\4\20\t\20\3\2\3\2\3\2\3\3\3\3\5\3&"" + ""\n\3\3\3\5\3)\n\3\3\3\3\3\3\3\3\3\5\3/\n\3\3\3\5\3\62\n\3\3\3\5\3\65\n"" + ""\3\3\4\3\4\3\4\3\5\3\5\3\5\3\6\3\6\3\6\3\6\5\6A\n\6\3\7\3\7\3\7\3\7\5"" + ""\7G\n\7\3\b\3\b\3\t\3\t\3\n\3\n\3\n\3\n\3\n\3\n\7\nS\n\n\f\n\16\nV\13"" + ""\n\3\13\3\13\3\13\5\13[\n\13\3\13\3\13\3\13\5\13`\n\13\3\13\3\13\3\13"" + ""\5\13e\n\13\5\13g\n\13\3\f\3\f\3\f\3\r\3\r\5\rn\n\r\3\16\3\16\3\16\3\17"" + ""\3\17\3\20\3\20\3\20\2\3\22\21\2\4\6\b\n\f\16\20\22\24\26\30\32\34\36"" + ""\2\3\3\2\f\ru\2 \3\2\2\2\4\64\3\2\2\2\6\66\3\2\2\2\b9\3\2\2\2\n@\3\2\2"" + ""\2\fF\3\2\2\2\16H\3\2\2\2\20J\3\2\2\2\22L\3\2\2\2\24f\3\2\2\2\26h\3\2"" + ""\2\2\30k\3\2\2\2\32o\3\2\2\2\34r\3\2\2\2\36t\3\2\2\2 !\5\4\3\2!\""\7\2"" + ""\2\3\""\3\3\2\2\2#%\5\30\r\2$&\5\b\5\2%$\3\2\2\2%&\3\2\2\2&(\3\2\2\2\'"" + "")\5\6\4\2(\'\3\2\2\2()\3\2\2\2)\65\3\2\2\2*+\5\30\r\2+,\5\26\f\2,.\5\24"" + ""\13\2-/\5\b\5\2.-\3\2\2\2./\3\2\2\2/\61\3\2\2\2\60\62\5\6\4\2\61\60\3"" + ""\2\2\2\61\62\3\2\2\2\62\65\3\2\2\2\63\65\5\24\13\2\64#\3\2\2\2\64*\3\2"" + ""\2\2\64\63\3\2\2\2\65\5\3\2\2\2\66\67\7\7\2\2\678\5\22\n\28\7\3\2\2\2"" + ""9:\7\6\2\2:;\5\22\n\2;\t\3\2\2\2<A\5\16\b\2=>\5\16\b\2>?\5\f\7\2?A\3\2"" + ""\2\2@<\3\2\2\2@=\3\2\2\2A\13\3\2\2\2BG\5\20\t\2CD\5\20\t\2DE\5\f\7\2E"" + ""G\3\2\2\2FB\3\2\2\2FC\3\2\2\2G\r\3\2\2\2HI\7\16\2\2I\17\3\2\2\2JK\t\2"" + ""\2\2K\21\3\2\2\2LM\b\n\1\2MN\5\n\6\2NT\3\2\2\2OP\f\3\2\2PQ\7\3\2\2QS\5"" + ""\n\6\2RO\3\2\2\2SV\3\2\2\2TR\3\2\2\2TU\3\2\2\2U\23\3\2\2\2VT\3\2\2\2W"" + ""X\7\b\2\2XZ\5\32\16\2Y[\7\13\2\2ZY\3\2\2\2Z[\3\2\2\2[\\\3\2\2\2\\]\7\n"" + ""\2\2]_\5\32\16\2^`\7\13\2\2_^\3\2\2\2_`\3\2\2\2`g\3\2\2\2ab\7\b\2\2bd"" + ""\5\32\16\2ce\7\13\2\2dc\3\2\2\2de\3\2\2\2eg\3\2\2\2fW\3\2\2\2fa\3\2\2"" + ""\2g\25\3\2\2\2hi\7\t\2\2ij\5\32\16\2j\27\3\2\2\2km\5\32\16\2ln\7\5\2\2"" + ""ml\3\2\2\2mn\3\2\2\2n\31\3\2\2\2op\5\34\17\2pq\5\36\20\2q\33\3\2\2\2r"" + ""s\7\f\2\2s\35\3\2\2\2tu\7\17\2\2u\37\3\2\2\2\17%(.\61\64@FTZ_dfm"" ; public static final ATN _ATN = new ATNDeserializer ( ) . deserialize ( _serializedATN . toCharArray ( ) ) ; static { _decisionToDFA = new DFA [ _ATN . getNumberOfDecisions ( ) ] ; for ( int i = 0 ; i < _ATN . getNumberOfDecisions ( ) ; i ++ ) { _decisionToDFA [ i ] = new DFA ( _ATN . getDecisionState ( i ) , i ) ; } } ",Smelly
"public class XMLTokener extends JSONTokener { public static final java . util . HashMap entity ; static { entity = new java . util . HashMap ( 8 ) ; entity . put ( ""amp"" , XML . AMP ) ; entity . put ( ""apos"" , XML . APOS ) ; entity . put ( ""gt"" , XML . GT ) ; entity . put ( ""lt"" , XML . LT ) ; entity . put ( ""quot"" , XML . QUOT ) ; } public XMLTokener ( String s ) { super ( s ) ; } public String nextCDATA ( ) throws JSONException { char c ; int i ; StringBuffer sb = new StringBuffer ( ) ; for ( ; ; ) { c = next ( ) ; if ( end ( ) ) { throw syntaxError ( ""Unclosed CDATA"" ) ; } sb . append ( c ) ; i = sb . length ( ) - 3 ; if ( i >= 0 && sb . charAt ( i ) == ']' && sb . charAt ( i + 1 ) == ']' && sb . charAt ( i + 2 ) == '>' ) { sb . setLength ( i ) ; return sb . toString ( ) ; } } } public Object nextContent ( ) throws JSONException { char c ; StringBuffer sb ; do { c = next ( ) ; } while ( Character . isWhitespace ( c ) ) ; if ( c == 0 ) { return null ; } if ( c == '<' ) { return XML . LT ; } sb = new StringBuffer ( ) ; for ( ; ; ) { if ( c == '<' || c == 0 ) { back ( ) ; return sb . toString ( ) . trim ( ) ; } if ( c == '&' ) { sb . append ( nextEntity ( c ) ) ; } else { sb . append ( c ) ; } c = next ( ) ; } } public Object nextEntity ( char ampersand ) throws JSONException { StringBuffer sb = new StringBuffer ( ) ; for ( ; ; ) { char c = next ( ) ; if ( Character . isLetterOrDigit ( c ) || c == '#' ) { sb . append ( Character . toLowerCase ( c ) ) ; } else if ( c == ';' ) { break ; } else { throw syntaxError ( ""Missing ';' in XML entity: &"" + sb ) ; } } String string = sb . toString ( ) ; Object object = entity . get ( string ) ; return object != null ? object : ampersand + string + "";"" ; } public Object nextMeta ( ) throws JSONException { char c ; char q ; do { c = next ( ) ; } while ( Character . isWhitespace ( c ) ) ; switch ( c ) { case 0 : throw syntaxError ( ""Misshaped meta tag"" ) ; case '<' : return XML . LT ; case '>' : return XML . GT ; case '/' : return XML . SLASH ; case '=' : return XML . EQ ; case '!' : return XML . BANG ; case '?' : return XML . QUEST ; case '""' : case '\'' : q = c ; for ( ; ; ) { c = next ( ) ; if ( c == 0 ) { throw syntaxError ( ""Unterminated string"" ) ; } if ( c == q ) { return Boolean . TRUE ; } } default : for ( ; ; ) { c = next ( ) ; if ( Character . isWhitespace ( c ) ) { return Boolean . TRUE ; } switch ( c ) { case 0 : case '<' : case '>' : case '/' : case '=' : case '!' : case '?' : case '""' : case '\'' : back ( ) ; return Boolean . TRUE ; } } } } public Object nextToken ( ) throws JSONException { char c ; char q ; StringBuffer sb ; do { c = next ( ) ; } while ( Character . isWhitespace ( c ) ) ; switch ( c ) { case 0 : throw syntaxError ( ""Misshaped element"" ) ; case '<' : throw syntaxError ( ""Misplaced '<'"" ) ; case '>' : return XML . GT ; case '/' : return XML . SLASH ; case '=' : return XML . EQ ; case '!' : return XML . BANG ; case '?' : return XML . QUEST ; case '""' : case '\'' : q = c ; sb = new StringBuffer ( ) ; for ( ; ; ) { c = next ( ) ; if ( c == 0 ) { throw syntaxError ( ""Unterminated string"" ) ; } if ( c == q ) { return sb . toString ( ) ; } if ( c == '&' ) { sb . append ( nextEntity ( c ) ) ; } else { sb . append ( c ) ; } } default : sb = new StringBuffer ( ) ; for ( ; ; ) { sb . append ( c ) ; c = next ( ) ; if ( Character . isWhitespace ( c ) ) { return sb . toString ( ) ; } switch ( c ) { case 0 : return sb . toString ( ) ; case '>' : case '/' : case '=' : case '!' : case '?' : case '[' : case ']' : back ( ) ; return sb . toString ( ) ; case '<' : case '""' : case '\'' : throw syntaxError ( ""Bad character in a name"" ) ; } } } } public boolean skipPast ( String to ) throws JSONException { boolean b ; char c ; int i ; int j ; int offset = 0 ; int length = to . length ( ) ; char [ ] circle = new char [ length ] ; for ( i = 0 ; i < length ; i += 1 ) { c = next ( ) ; if ( c == 0 ) { return false ; } circle [ i ] = c ; } for ( ; ; ) { j = offset ; b = true ; for ( i = 0 ; i < length ; i += 1 ) { if ( circle [ j ] != to . charAt ( i ) ) { b = false ; break ; } j += 1 ; if ( j >= length ) { j -= length ; } } if ( b ) { return true ; } c = next ( ) ; if ( c == 0 ) { return false ; } circle [ offset ] = c ; offset += 1 ; if ( offset >= length ) { offset -= length ; } } } }",Smelly
"class AuthorizablePropertiesImpl implements AuthorizableProperties { private static final Logger log = LoggerFactory . getLogger ( AuthorizablePropertiesImpl . class ) ; private final AuthorizableImpl authorizable ; AuthorizablePropertiesImpl ( AuthorizableImpl authorizable ) { this . authorizable = authorizable ; } @ Override public Iterator < String > getNames ( String relPath ) throws RepositoryException { checkRelativePath ( relPath ) ; Tree tree = getTree ( ) ; TreeLocation location = getLocation ( tree , relPath ) ; Tree parent = location . getTree ( ) ; if ( parent != null && Text . isDescendantOrEqual ( tree . getPath ( ) , parent . getPath ( ) ) ) { List < String > l = new ArrayList < String > ( ) ; for ( PropertyState property : parent . getProperties ( ) ) { String propName = property . getName ( ) ; if ( isAuthorizableProperty ( tree , location . getChild ( propName ) , false ) ) { l . add ( propName ) ; } } return l . iterator ( ) ; } else { throw new RepositoryException ( ""Relative path "" + relPath + "" refers to items outside of scope of authorizable."" ) ; } } @ Override public boolean hasProperty ( String relPath ) throws RepositoryException { checkRelativePath ( relPath ) ; return isAuthorizableProperty ( getTree ( ) , getLocation ( getTree ( ) , relPath ) , true ) ; } @ Override public Value [ ] getProperty ( String relPath ) throws RepositoryException { checkRelativePath ( relPath ) ; Tree tree = getTree ( ) ; Value [ ] values = null ; PropertyState property = getAuthorizableProperty ( tree , getLocation ( tree , relPath ) , true ) ; if ( property != null ) { NamePathMapper npMapper = authorizable . getUserManager ( ) . getNamePathMapper ( ) ; if ( property . isArray ( ) ) { List < Value > vs = ValueFactoryImpl . createValues ( property , npMapper ) ; values = vs . toArray ( new Value [ vs . size ( ) ] ) ; } else { values = new Value [ ] { ValueFactoryImpl . createValue ( property , npMapper ) } ; } } return values ; } @ Override public void setProperty ( String relPath , Value value ) throws RepositoryException { if ( value == null ) { removeProperty ( relPath ) ; } else { checkRelativePath ( relPath ) ; String name = Text . getName ( relPath ) ; PropertyState propertyState = PropertyStates . createProperty ( name , value ) ; String intermediate = ( relPath . equals ( name ) ) ? null : Text . getRelativeParent ( relPath , 1 ) ; Tree parent = getOrCreateTargetTree ( intermediate ) ; checkProtectedProperty ( parent , propertyState ) ; parent . setProperty ( propertyState ) ; } } @ Override public void setProperty ( String relPath , Value [ ] values ) throws RepositoryException { if ( values == null ) { removeProperty ( relPath ) ; } else { checkRelativePath ( relPath ) ; String name = Text . getName ( relPath ) ; PropertyState propertyState = PropertyStates . createProperty ( name , Arrays . asList ( values ) ) ; String intermediate = ( relPath . equals ( name ) ) ? null : Text . getRelativeParent ( relPath , 1 ) ; Tree parent = getOrCreateTargetTree ( intermediate ) ; checkProtectedProperty ( parent , propertyState ) ; parent . setProperty ( propertyState ) ; } } @ Override public boolean removeProperty ( String relPath ) throws RepositoryException { checkRelativePath ( relPath ) ; Tree node = getTree ( ) ; TreeLocation propertyLocation = getLocation ( node , relPath ) ; if ( propertyLocation . getProperty ( ) != null ) { if ( isAuthorizableProperty ( node , propertyLocation , true ) ) { return propertyLocation . remove ( ) ; } else { throw new ConstraintViolationException ( ""Property "" + relPath + "" isn't a modifiable authorizable property"" ) ; } } return false ; } @ Nonnull private Tree getTree ( ) { return authorizable . getTree ( ) ; } private boolean isAuthorizableProperty ( Tree authorizableTree , TreeLocation propertyLocation , boolean verifyAncestor ) throws RepositoryException { return getAuthorizableProperty ( authorizableTree , propertyLocation , verifyAncestor ) != null ; } @ CheckForNull private PropertyState getAuthorizableProperty ( Tree authorizableTree , TreeLocation propertyLocation , boolean verifyAncestor ) throws RepositoryException { if ( propertyLocation == null ) { return null ; } PropertyState property = propertyLocation . getProperty ( ) ; if ( property == null ) { return null ; } String authorizablePath = authorizableTree . getPath ( ) ; if ( verifyAncestor && ! Text . isDescendant ( authorizablePath , propertyLocation . getPath ( ) ) ) { log . debug ( ""Attempt to access property outside of authorizable scope."" ) ; return null ; } Tree parent = propertyLocation . getParent ( ) . getTree ( ) ; if ( parent == null ) { log . debug ( ""Unable to determine definition of authorizable property at "" + propertyLocation . getPath ( ) ) ; return null ; } ReadOnlyNodeTypeManager nodeTypeManager = authorizable . getUserManager ( ) . getNodeTypeManager ( ) ; PropertyDefinition def = nodeTypeManager . getDefinition ( parent , property , true ) ; if ( def . isProtected ( ) || ( authorizablePath . equals ( parent . getPath ( ) ) && ! def . getDeclaringNodeType ( ) . isNodeType ( UserConstants . NT_REP_AUTHORIZABLE ) ) ) { return null ; } return property ; } private void checkProtectedProperty ( Tree parent , PropertyState property ) throws RepositoryException { ReadOnlyNodeTypeManager nodeTypeManager = authorizable . getUserManager ( ) . getNodeTypeManager ( ) ; PropertyDefinition def = nodeTypeManager . getDefinition ( parent , property , false ) ; if ( def . isProtected ( ) ) { throw new ConstraintViolationException ( ""Attempt to set an protected property "" + property . getName ( ) ) ; } } @ Nonnull private Tree getOrCreateTargetTree ( String relPath ) throws RepositoryException { Tree targetTree ; Tree userTree = getTree ( ) ; if ( relPath != null ) { String userPath = userTree . getPath ( ) ; targetTree = getLocation ( userTree , relPath ) . getTree ( ) ; if ( targetTree != null ) { if ( ! Text . isDescendantOrEqual ( userPath , targetTree . getPath ( ) ) ) { throw new RepositoryException ( ""Relative path "" + relPath + "" outside of scope of "" + this ) ; } } else { targetTree = new NodeUtil ( userTree ) . getOrAddTree ( relPath , JcrConstants . NT_UNSTRUCTURED ) . getTree ( ) ; if ( ! Text . isDescendantOrEqual ( userPath , targetTree . getPath ( ) ) ) { throw new RepositoryException ( ""Relative path "" + relPath + "" outside of scope of "" + this ) ; } } } else { targetTree = userTree ; } return targetTree ; } @ Nonnull private static TreeLocation getLocation ( Tree tree , String relativePath ) { TreeLocation loc = TreeLocation . create ( tree ) ; for ( String element : Text . explode ( relativePath , '/' , false ) ) { if ( PathUtils . denotesParent ( element ) ) { loc = loc . getParent ( ) ; } else if ( ! PathUtils . denotesCurrent ( element ) ) { loc = loc . getChild ( element ) ; } } return loc ; } private static void checkRelativePath ( String relativePath ) throws RepositoryException { if ( relativePath == null || relativePath . isEmpty ( ) || relativePath . charAt ( 0 ) == '/' ) { throw new RepositoryException ( ""Relative path expected. Found "" + relativePath ) ; } } }",No
"@ javax . jws . WebService ( targetNamespace = ""http://WSSec/wssec10"" , serviceName = ""PingService"" , portName = ""UserNameOverTransportLocal_IPingService"" , endpointInterface = ""wssec.wssec10.IPingService"" , wsdlLocation = ""target/test-classes/wsdl_systest_wssec/wssec10/WsSecurity10_restricted.wsdl"" ) public class UserNameOverTransportRestricted extends PingServiceBase { }",No
"@ SuppressWarnings ( ""serial"" ) public class SemaphoreWaitException extends GenericServiceException { public SemaphoreWaitException ( ) { super ( ) ; } public SemaphoreWaitException ( String str ) { super ( str ) ; } public SemaphoreWaitException ( String str , Throwable nested ) { super ( str , nested ) ; } public SemaphoreWaitException ( Throwable nested ) { super ( nested ) ; } }",No
"public class DeltaBinaryPackingValuesWriterTest { DeltaBinaryPackingValuesReader reader ; private int blockSize ; private int miniBlockNum ; private ValuesWriter writer ; private Random random ; @ Before public void setUp ( ) { blockSize = 128 ; miniBlockNum = 4 ; writer = new DeltaBinaryPackingValuesWriter ( blockSize , miniBlockNum , 100 , 200 ) ; random = new Random ( ) ; } @ Test ( expected = IllegalArgumentException . class ) public void miniBlockSizeShouldBeMultipleOf8 ( ) { new DeltaBinaryPackingValuesWriter ( 1281 , 4 , 100 , 100 ) ; } @ Test public void shouldWriteWhenDataIsAlignedWithBlock ( ) throws IOException { int [ ] data = new int [ 5 * blockSize ] ; for ( int i = 0 ; i < blockSize * 5 ; i ++ ) { data [ i ] = random . nextInt ( ) ; } shouldWriteAndRead ( data ) ; } @ Test public void shouldWriteAndReadWhenBlockIsNotFullyWritten ( ) throws IOException { int [ ] data = new int [ blockSize - 3 ] ; for ( int i = 0 ; i < data . length ; i ++ ) { data [ i ] = random . nextInt ( ) ; } shouldWriteAndRead ( data ) ; } @ Test public void shouldWriteAndReadWhenAMiniBlockIsNotFullyWritten ( ) throws IOException { int miniBlockSize = blockSize / miniBlockNum ; int [ ] data = new int [ miniBlockSize - 3 ] ; for ( int i = 0 ; i < data . length ; i ++ ) { data [ i ] = random . nextInt ( ) ; } shouldWriteAndRead ( data ) ; } @ Test public void shouldWriteNegativeDeltas ( ) throws IOException { int [ ] data = new int [ blockSize ] ; for ( int i = 0 ; i < data . length ; i ++ ) { data [ i ] = 10 - ( i * 32 - random . nextInt ( 6 ) ) ; } shouldWriteAndRead ( data ) ; } @ Test public void shouldWriteAndReadWhenDeltasAreSame ( ) throws IOException { int [ ] data = new int [ 2 * blockSize ] ; for ( int i = 0 ; i < blockSize ; i ++ ) { data [ i ] = i * 32 ; } shouldWriteAndRead ( data ) ; } @ Test public void shouldWriteAndReadWhenValuesAreSame ( ) throws IOException { int [ ] data = new int [ 2 * blockSize ] ; for ( int i = 0 ; i < blockSize ; i ++ ) { data [ i ] = 3 ; } shouldWriteAndRead ( data ) ; } @ Test public void shouldWriteWhenDeltaIs0ForEachBlock ( ) throws IOException { int [ ] data = new int [ 5 * blockSize + 1 ] ; for ( int i = 0 ; i < data . length ; i ++ ) { data [ i ] = ( i - 1 ) / blockSize ; } shouldWriteAndRead ( data ) ; } @ Test public void shouldReadWriteWhenDataIsNotAlignedWithBlock ( ) throws IOException { int [ ] data = new int [ 5 * blockSize + 3 ] ; for ( int i = 0 ; i < data . length ; i ++ ) { data [ i ] = random . nextInt ( 20 ) - 10 ; } shouldWriteAndRead ( data ) ; } @ Test public void shouldReadMaxMinValue ( ) throws IOException { int [ ] data = new int [ 10 ] ; for ( int i = 0 ; i < data . length ; i ++ ) { if ( i % 2 == 0 ) { data [ i ] = Integer . MIN_VALUE ; } else { data [ i ] = Integer . MAX_VALUE ; } } shouldWriteAndRead ( data ) ; } @ Test public void shouldReturnCorrectOffsetAfterInitialization ( ) throws IOException { int [ ] data = new int [ 2 * blockSize + 3 ] ; for ( int i = 0 ; i < data . length ; i ++ ) { data [ i ] = i * 32 ; } writeData ( data ) ; reader = new DeltaBinaryPackingValuesReader ( ) ; BytesInput bytes = writer . getBytes ( ) ; byte [ ] valueContent = bytes . toByteArray ( ) ; byte [ ] pageContent = new byte [ valueContent . length * 10 ] ; int contentOffsetInPage = 33 ; System . arraycopy ( valueContent , 0 , pageContent , contentOffsetInPage , valueContent . length ) ; reader . initFromPage ( 100 , pageContent , contentOffsetInPage ) ; int offset = reader . getNextOffset ( ) ; assertEquals ( valueContent . length + contentOffsetInPage , offset ) ; for ( int i : data ) { assertEquals ( i , reader . readInteger ( ) ) ; } } @ Test public void shouldThrowExceptionWhenReadMoreThanWritten ( ) throws IOException { int [ ] data = new int [ 5 * blockSize + 1 ] ; for ( int i = 0 ; i < data . length ; i ++ ) { data [ i ] = i * 32 ; } shouldWriteAndRead ( data ) ; try { reader . readInteger ( ) ; } catch ( ParquetDecodingException e ) { assertEquals ( ""no more value to read, total value count is "" + data . length , e . getMessage ( ) ) ; } } @ Test public void shouldSkip ( ) throws IOException { int [ ] data = new int [ 5 * blockSize + 1 ] ; for ( int i = 0 ; i < data . length ; i ++ ) { data [ i ] = i * 32 ; } writeData ( data ) ; reader = new DeltaBinaryPackingValuesReader ( ) ; reader . initFromPage ( 100 , writer . getBytes ( ) . toByteArray ( ) , 0 ) ; for ( int i = 0 ; i < data . length ; i ++ ) { if ( i % 3 == 0 ) { reader . skip ( ) ; } else { assertEquals ( i * 32 , reader . readInteger ( ) ) ; } } } @ Test public void shouldReset ( ) throws IOException { shouldReadWriteWhenDataIsNotAlignedWithBlock ( ) ; int [ ] data = new int [ 5 * blockSize ] ; for ( int i = 0 ; i < blockSize * 5 ; i ++ ) { data [ i ] = i * 2 ; } writer . reset ( ) ; shouldWriteAndRead ( data ) ; } @ Test public void randomDataTest ( ) throws IOException { int maxSize = 1000 ; int [ ] data = new int [ maxSize ] ; for ( int round = 0 ; round < 100000 ; round ++ ) { int size = random . nextInt ( maxSize ) ; for ( int i = 0 ; i < size ; i ++ ) { data [ i ] = random . nextInt ( ) ; } shouldReadAndWrite ( data , size ) ; writer . reset ( ) ; } } private void shouldWriteAndRead ( int [ ] data ) throws IOException { shouldReadAndWrite ( data , data . length ) ; } private void shouldReadAndWrite ( int [ ] data , int length ) throws IOException { writeData ( data , length ) ; reader = new DeltaBinaryPackingValuesReader ( ) ; byte [ ] page = writer . getBytes ( ) . toByteArray ( ) ; int miniBlockSize = blockSize / miniBlockNum ; double miniBlockFlushed = Math . ceil ( ( ( double ) length - 1 ) / miniBlockSize ) ; double blockFlushed = Math . ceil ( ( ( double ) length - 1 ) / blockSize ) ; double estimatedSize = 4 * 5 + 4 * miniBlockFlushed * miniBlockSize + blockFlushed * miniBlockNum + ( 5.0 * blockFlushed ) ; assertTrue ( estimatedSize >= page . length ) ; reader . initFromPage ( 100 , page , 0 ) ; for ( int i = 0 ; i < length ; i ++ ) { assertEquals ( data [ i ] , reader . readInteger ( ) ) ; } } private void writeData ( int [ ] data ) { writeData ( data , data . length ) ; } private void writeData ( int [ ] data , int length ) { for ( int i = 0 ; i < length ; i ++ ) { writer . writeInteger ( data [ i ] ) ; } } }",Smelly
"public class ClientNode extends ClientItem implements Node { private RemoteNode remote ; public ClientNode ( Session session , RemoteNode remote , LocalAdapterFactory factory ) { super ( session , remote , factory ) ; this . remote = remote ; } public boolean isNode ( ) { return true ; } public void accept ( ItemVisitor visitor ) throws RepositoryException { visitor . visit ( this ) ; } public Node addNode ( String path ) throws RepositoryException { try { return getNode ( getSession ( ) , remote . addNode ( path ) ) ; } catch ( RemoteException ex ) { throw new RemoteRepositoryException ( ex ) ; } } public Node addNode ( String path , String type ) throws RepositoryException { try { RemoteNode node = remote . addNode ( path , type ) ; return getNode ( getSession ( ) , node ) ; } catch ( RemoteException ex ) { throw new RemoteRepositoryException ( ex ) ; } } public void orderBefore ( String src , String dst ) throws RepositoryException { try { remote . orderBefore ( src , dst ) ; } catch ( RemoteException ex ) { throw new RemoteRepositoryException ( ex ) ; } } public Property setProperty ( String name , Value value ) throws RepositoryException { try { if ( value == null ) { remote . setProperty ( name , value ) ; return null ; } else { RemoteProperty property = remote . setProperty ( name , SerialValueFactory . makeSerialValue ( value ) ) ; return getFactory ( ) . getProperty ( getSession ( ) , property ) ; } } catch ( RemoteException ex ) { throw new RemoteRepositoryException ( ex ) ; } } public Property setProperty ( String name , Value [ ] values ) throws RepositoryException { try { if ( values == null ) { remote . setProperty ( name , values ) ; return null ; } else { Value [ ] serials = SerialValueFactory . makeSerialValueArray ( values ) ; RemoteProperty property = remote . setProperty ( name , serials ) ; return getFactory ( ) . getProperty ( getSession ( ) , property ) ; } } catch ( RemoteException ex ) { throw new RemoteRepositoryException ( ex ) ; } } public Property setProperty ( String name , String [ ] strings ) throws RepositoryException { try { if ( strings == null ) { remote . setProperty ( name , ( Value [ ] ) null ) ; return null ; } else { Value [ ] serials = SerialValueFactory . makeSerialValueArray ( strings ) ; RemoteProperty property = remote . setProperty ( name , serials ) ; return getFactory ( ) . getProperty ( getSession ( ) , property ) ; } } catch ( RemoteException ex ) { throw new RemoteRepositoryException ( ex ) ; } } public Property setProperty ( String name , String value ) throws RepositoryException { if ( value == null ) { return setProperty ( name , ( Value ) null ) ; } else { return setProperty ( name , getSession ( ) . getValueFactory ( ) . createValue ( value ) ) ; } } public Property setProperty ( String name , InputStream value ) throws RepositoryException { if ( value == null ) { return setProperty ( name , ( Value ) null ) ; } else { return setProperty ( name , getSession ( ) . getValueFactory ( ) . createValue ( value ) ) ; } } public Property setProperty ( String name , boolean value ) throws RepositoryException { return setProperty ( name , getSession ( ) . getValueFactory ( ) . createValue ( value ) ) ; } public Property setProperty ( String name , double value ) throws RepositoryException { return setProperty ( name , getSession ( ) . getValueFactory ( ) . createValue ( value ) ) ; } public Property setProperty ( String name , long value ) throws RepositoryException { return setProperty ( name , getSession ( ) . getValueFactory ( ) . createValue ( value ) ) ; } public Property setProperty ( String name , Calendar value ) throws RepositoryException { if ( value == null ) { return setProperty ( name , ( Value ) null ) ; } else { return setProperty ( name , getSession ( ) . getValueFactory ( ) . createValue ( value ) ) ; } } public Property setProperty ( String name , Node value ) throws RepositoryException { if ( value == null ) { return setProperty ( name , ( Value ) null ) ; } else { return setProperty ( name , getSession ( ) . getValueFactory ( ) . createValue ( value ) ) ; } } public Property setProperty ( String name , Binary value ) throws RepositoryException { if ( value == null ) { return setProperty ( name , ( Value ) null ) ; } else { return setProperty ( name , getSession ( ) . getValueFactory ( ) . createValue ( value ) ) ; } } public Property setProperty ( String name , BigDecimal value ) throws RepositoryException { if ( value == null ) { return setProperty ( name , ( Value ) null ) ; } else { return setProperty ( name , getSession ( ) . getValueFactory ( ) . createValue ( value ) ) ; } } public Node getNode ( String path ) throws RepositoryException { try { return getNode ( getSession ( ) , remote . getNode ( path ) ) ; } catch ( RemoteException ex ) { throw new RemoteRepositoryException ( ex ) ; } } public NodeIterator getNodes ( ) throws RepositoryException { try { return getFactory ( ) . getNodeIterator ( getSession ( ) , remote . getNodes ( ) ) ; } catch ( RemoteException ex ) { throw new RemoteRepositoryException ( ex ) ; } } public NodeIterator getNodes ( String pattern ) throws RepositoryException { try { return getFactory ( ) . getNodeIterator ( getSession ( ) , remote . getNodes ( pattern ) ) ; } catch ( RemoteException ex ) { throw new RemoteRepositoryException ( ex ) ; } } public NodeIterator getNodes ( String [ ] globs ) throws RepositoryException { try { return getFactory ( ) . getNodeIterator ( getSession ( ) , remote . getNodes ( globs ) ) ; } catch ( RemoteException ex ) { throw new RemoteRepositoryException ( ex ) ; } } public Property getProperty ( String path ) throws RepositoryException { try { RemoteProperty property = remote . getProperty ( path ) ; return getFactory ( ) . getProperty ( getSession ( ) , property ) ; } catch ( RemoteException ex ) { throw new RemoteRepositoryException ( ex ) ; } } public PropertyIterator getProperties ( ) throws RepositoryException { try { return getFactory ( ) . getPropertyIterator ( getSession ( ) , remote . getProperties ( ) ) ; } catch ( RemoteException ex ) { throw new RemoteRepositoryException ( ex ) ; } } public PropertyIterator getProperties ( String pattern ) throws RepositoryException { try { return getFactory ( ) . getPropertyIterator ( getSession ( ) , remote . getProperties ( pattern ) ) ; } catch ( RemoteException ex ) { throw new RemoteRepositoryException ( ex ) ; } } public PropertyIterator getProperties ( String [ ] globs ) throws RepositoryException { try { return getFactory ( ) . getPropertyIterator ( getSession ( ) , remote . getProperties ( globs ) ) ; } catch ( RemoteException ex ) { throw new RemoteRepositoryException ( ex ) ; } } public Item getPrimaryItem ( ) throws RepositoryException { try { return getItem ( getSession ( ) , remote . getPrimaryItem ( ) ) ; } catch ( RemoteException ex ) { throw new RemoteRepositoryException ( ex ) ; } } public String getIdentifier ( ) throws RepositoryException { try { return remote . getIdentifier ( ) ; } catch ( RemoteException ex ) { throw new RemoteRepositoryException ( ex ) ; } } public String getUUID ( ) throws RepositoryException { try { return remote . getUUID ( ) ; } catch ( RemoteException ex ) { throw new RemoteRepositoryException ( ex ) ; } } public PropertyIterator getReferences ( ) throws RepositoryException { try { return getFactory ( ) . getPropertyIterator ( getSession ( ) , remote . getReferences ( ) ) ; } catch ( RemoteException ex ) { throw new RemoteRepositoryException ( ex ) ; } } public PropertyIterator getReferences ( String name ) throws RepositoryException { try { return getFactory ( ) . getPropertyIterator ( getSession ( ) , remote . getReferences ( name ) ) ; } catch ( RemoteException ex ) { throw new RemoteRepositoryException ( ex ) ; } } public boolean hasNode ( String path ) throws RepositoryException { try { return remote . hasNode ( path ) ; } catch ( RemoteException ex ) { throw new RemoteRepositoryException ( ex ) ; } } public boolean hasProperty ( String path ) throws RepositoryException { try { return remote . hasProperty ( path ) ; } catch ( RemoteException ex ) { throw new RemoteRepositoryException ( ex ) ; } } public boolean hasNodes ( ) throws RepositoryException { try { return remote . hasNodes ( ) ; } catch ( RemoteException ex ) { throw new RemoteRepositoryException ( ex ) ; } } public boolean hasProperties ( ) throws RepositoryException { try { return remote . hasProperties ( ) ; } catch ( RemoteException ex ) { throw new RemoteRepositoryException ( ex ) ; } } public NodeType getPrimaryNodeType ( ) throws RepositoryException { try { return getFactory ( ) . getNodeType ( remote . getPrimaryNodeType ( ) ) ; } catch ( RemoteException ex ) { throw new RemoteRepositoryException ( ex ) ; } } public NodeType [ ] getMixinNodeTypes ( ) throws RepositoryException { try { return getNodeTypeArray ( remote . getMixinNodeTypes ( ) ) ; } catch ( RemoteException ex ) { throw new RemoteRepositoryException ( ex ) ; } } public boolean isNodeType ( String type ) throws RepositoryException { try { return remote . isNodeType ( type ) ; } catch ( RemoteException ex ) { throw new RemoteRepositoryException ( ex ) ; } } public void addMixin ( String name ) throws RepositoryException { try { remote . addMixin ( name ) ; } catch ( RemoteException ex ) { throw new RemoteRepositoryException ( ex ) ; } } public void removeMixin ( String name ) throws RepositoryException { try { remote . removeMixin ( name ) ; } catch ( RemoteException ex ) { throw new RemoteRepositoryException ( ex ) ; } } public boolean canAddMixin ( String name ) throws RepositoryException { try { return remote . canAddMixin ( name ) ; } catch ( RemoteException ex ) { throw new RemoteRepositoryException ( ex ) ; } } public NodeDefinition getDefinition ( ) throws RepositoryException { try { return getFactory ( ) . getNodeDef ( remote . getDefinition ( ) ) ; } catch ( RemoteException ex ) { throw new RemoteRepositoryException ( ex ) ; } } public Version checkin ( ) throws RepositoryException { try { return getFactory ( ) . getVersion ( getSession ( ) , remote . checkin ( ) ) ; } catch ( RemoteException ex ) { throw new RemoteRepositoryException ( ex ) ; } } public void checkout ( ) throws RepositoryException { try { remote . checkout ( ) ; } catch ( RemoteException ex ) { throw new RemoteRepositoryException ( ex ) ; } } public void update ( String workspace ) throws RepositoryException { try { remote . update ( workspace ) ; } catch ( RemoteException ex ) { throw new RemoteRepositoryException ( ex ) ; } } public NodeIterator merge ( String workspace , boolean bestEffort ) throws RepositoryException { try { return getFactory ( ) . getNodeIterator ( getSession ( ) , remote . merge ( workspace , bestEffort ) ) ; } catch ( RemoteException ex ) { throw new RemoteRepositoryException ( ex ) ; } } public void cancelMerge ( Version version ) throws RepositoryException { try { remote . cancelMerge ( version . getUUID ( ) ) ; } catch ( RemoteException ex ) { throw new RemoteRepositoryException ( ex ) ; } } public void doneMerge ( Version version ) throws RepositoryException { try { remote . doneMerge ( version . getUUID ( ) ) ; } catch ( RemoteException ex ) { throw new RemoteRepositoryException ( ex ) ; } } public String getCorrespondingNodePath ( String workspace ) throws RepositoryException { try { return remote . getCorrespondingNodePath ( workspace ) ; } catch ( RemoteException ex ) { throw new RemoteRepositoryException ( ex ) ; } } public int getIndex ( ) throws RepositoryException { try { return remote . getIndex ( ) ; } catch ( RemoteException ex ) { throw new RemoteRepositoryException ( ex ) ; } } public void restore ( String version , boolean removeExisting ) throws RepositoryException { try { remote . restore ( version , removeExisting ) ; } catch ( RemoteException ex ) { throw new RemoteRepositoryException ( ex ) ; } } public void restore ( Version version , boolean removeExisting ) throws RepositoryException { try { remote . restoreByUUID ( version . getUUID ( ) , removeExisting ) ; } catch ( RemoteException ex ) { throw new RemoteRepositoryException ( ex ) ; } } public void restore ( Version version , String path , boolean removeExisting ) throws RepositoryException { try { remote . restore ( version . getUUID ( ) , path , removeExisting ) ; } catch ( RemoteException ex ) { throw new RemoteRepositoryException ( ex ) ; } } public void restoreByLabel ( String label , boolean removeExisting ) throws RepositoryException { try { remote . restoreByLabel ( label , removeExisting ) ; } catch ( RemoteException ex ) { throw new RemoteRepositoryException ( ex ) ; } } public Property setProperty ( String name , String [ ] strings , int type ) throws RepositoryException { try { if ( strings == null ) { remote . setProperty ( name , ( Value [ ] ) null ) ; return null ; } else { Value [ ] serials = SerialValueFactory . makeSerialValueArray ( strings ) ; RemoteProperty property = remote . setProperty ( name , serials , type ) ; return getFactory ( ) . getProperty ( getSession ( ) , property ) ; } } catch ( RemoteException ex ) { throw new RemoteRepositoryException ( ex ) ; } } public Property setProperty ( String name , Value [ ] values , int type ) throws RepositoryException { try { if ( values != null ) { values = SerialValueFactory . makeSerialValueArray ( values ) ; } RemoteProperty property = remote . setProperty ( name , values , type ) ; if ( property != null ) { return getFactory ( ) . getProperty ( getSession ( ) , property ) ; } else { return null ; } } catch ( RemoteException ex ) { throw new RemoteRepositoryException ( ex ) ; } } public Property setProperty ( String name , Value value , int type ) throws RepositoryException { try { if ( value != null ) { value = SerialValueFactory . makeSerialValue ( value ) ; } RemoteProperty property = remote . setProperty ( name , value , type ) ; if ( property != null ) { return getFactory ( ) . getProperty ( getSession ( ) , property ) ; } else { return null ; } } catch ( RemoteException ex ) { throw new RemoteRepositoryException ( ex ) ; } } public Property setProperty ( String name , String string , int type ) throws RepositoryException { Value value = null ; if ( string != null ) { value = getSession ( ) . getValueFactory ( ) . createValue ( string ) ; } return setProperty ( name , value , type ) ; } public boolean isCheckedOut ( ) throws RepositoryException { try { return remote . isCheckedOut ( ) ; } catch ( RemoteException ex ) { throw new RemoteRepositoryException ( ex ) ; } } public VersionHistory getVersionHistory ( ) throws RepositoryException { try { return getFactory ( ) . getVersionHistory ( getSession ( ) , remote . getVersionHistory ( ) ) ; } catch ( RemoteException ex ) { throw new RemoteRepositoryException ( ex ) ; } } public Version getBaseVersion ( ) throws RepositoryException { try { return getFactory ( ) . getVersion ( getSession ( ) , remote . getBaseVersion ( ) ) ; } catch ( RemoteException ex ) { throw new RemoteRepositoryException ( ex ) ; } } public Lock lock ( boolean isDeep , boolean isSessionScoped ) throws RepositoryException { try { RemoteLock lock = remote . lock ( isDeep , isSessionScoped ) ; return getFactory ( ) . getLock ( getSession ( ) , this , lock ) ; } catch ( RemoteException ex ) { throw new RemoteRepositoryException ( ex ) ; } } public Lock getLock ( ) throws RepositoryException { try { return getFactory ( ) . getLock ( getSession ( ) , this , remote . getLock ( ) ) ; } catch ( RemoteException ex ) { throw new RemoteRepositoryException ( ex ) ; } } public void unlock ( ) throws RepositoryException { try { remote . unlock ( ) ; } catch ( RemoteException ex ) { throw new RemoteRepositoryException ( ex ) ; } } public boolean holdsLock ( ) throws RepositoryException { try { return remote . holdsLock ( ) ; } catch ( RemoteException ex ) { throw new RemoteRepositoryException ( ex ) ; } } public boolean isLocked ( ) throws RepositoryException { try { return remote . isLocked ( ) ; } catch ( RemoteException ex ) { throw new RemoteRepositoryException ( ex ) ; } } public void followLifecycleTransition ( String transition ) throws RepositoryException { throw new UnsupportedRepositoryOperationException ( ""TODO: JCRRMI-26"" ) ; } public String [ ] getAllowedLifecycleTransistions ( ) throws RepositoryException { throw new UnsupportedRepositoryOperationException ( ""TODO: JCRRMI-26"" ) ; } public NodeIterator getSharedSet ( ) throws RepositoryException { throw new UnsupportedRepositoryOperationException ( ""TODO: JCRRMI-26"" ) ; } public PropertyIterator getWeakReferences ( ) throws RepositoryException { throw new UnsupportedRepositoryOperationException ( ""TODO: JCRRMI-26"" ) ; } public PropertyIterator getWeakReferences ( String name ) throws RepositoryException { throw new UnsupportedRepositoryOperationException ( ""TODO: JCRRMI-26"" ) ; } public void removeShare ( ) throws RepositoryException { throw new UnsupportedRepositoryOperationException ( ""TODO: JCRRMI-26"" ) ; } public void removeSharedSet ( ) throws RepositoryException { throw new UnsupportedRepositoryOperationException ( ""TODO: JCRRMI-26"" ) ; } public void setPrimaryType ( String nodeTypeName ) throws RepositoryException { throw new UnsupportedRepositoryOperationException ( ""TODO: JCRRMI-26"" ) ; } }",Smelly
"@ Service ( ""archivaAdministrationService#default"" ) public class DefaultArchivaAdministrationService extends AbstractRestService implements ArchivaAdministrationService { @ Inject private ArchivaAdministration archivaAdministration ; @ Inject @ Named ( value = ""managedRepositoryContent#legacy"" ) private ManagedRepositoryContent repositoryContent ; @ Inject private RepositoryContentConsumers repoConsumerUtil ; public List < LegacyArtifactPath > getLegacyArtifactPaths ( ) throws ArchivaRestServiceException { try { return archivaAdministration . getLegacyArtifactPaths ( ) ; } catch ( RepositoryAdminException e ) { throw new ArchivaRestServiceException ( e . getMessage ( ) , e ) ; } } public void addLegacyArtifactPath ( LegacyArtifactPath legacyArtifactPath ) throws ArchivaRestServiceException { ArtifactReference artifact = new ArtifactReference ( ) ; artifact . setGroupId ( legacyArtifactPath . getGroupId ( ) ) ; artifact . setArtifactId ( legacyArtifactPath . getArtifactId ( ) ) ; artifact . setClassifier ( legacyArtifactPath . getClassifier ( ) ) ; artifact . setVersion ( legacyArtifactPath . getVersion ( ) ) ; artifact . setType ( legacyArtifactPath . getType ( ) ) ; String path = repositoryContent . toPath ( artifact ) ; if ( ! StringUtils . equals ( path , legacyArtifactPath . getPath ( ) ) ) { throw new ArchivaRestServiceException ( ""artifact path reference '"" + legacyArtifactPath . getPath ( ) + ""' does not match the initial path: '"" + path + ""'"" , Response . Status . BAD_REQUEST . getStatusCode ( ) , null ) ; } try { archivaAdministration . addLegacyArtifactPath ( legacyArtifactPath , getAuditInformation ( ) ) ; } catch ( RepositoryAdminException e ) { throw new ArchivaRestServiceException ( e . getMessage ( ) , e ) ; } } public Boolean deleteLegacyArtifactPath ( String path ) throws ArchivaRestServiceException { try { archivaAdministration . deleteLegacyArtifactPath ( path , getAuditInformation ( ) ) ; return Boolean . TRUE ; } catch ( RepositoryAdminException e ) { throw new ArchivaRestServiceException ( e . getMessage ( ) , e ) ; } } public Boolean addFileTypePattern ( String fileTypeId , String pattern ) throws ArchivaRestServiceException { try { archivaAdministration . addFileTypePattern ( fileTypeId , pattern , getAuditInformation ( ) ) ; return Boolean . TRUE ; } catch ( RepositoryAdminException e ) { throw new ArchivaRestServiceException ( e . getMessage ( ) , e ) ; } } public Boolean removeFileTypePattern ( String fileTypeId , String pattern ) throws ArchivaRestServiceException { try { archivaAdministration . removeFileTypePattern ( fileTypeId , pattern , getAuditInformation ( ) ) ; return Boolean . TRUE ; } catch ( RepositoryAdminException e ) { throw new ArchivaRestServiceException ( e . getMessage ( ) , e ) ; } } public FileType getFileType ( String fileTypeId ) throws ArchivaRestServiceException { try { return archivaAdministration . getFileType ( fileTypeId ) ; } catch ( RepositoryAdminException e ) { throw new ArchivaRestServiceException ( e . getMessage ( ) , e ) ; } } public void addFileType ( FileType fileType ) throws ArchivaRestServiceException { try { archivaAdministration . addFileType ( fileType , getAuditInformation ( ) ) ; } catch ( RepositoryAdminException e ) { throw new ArchivaRestServiceException ( e . getMessage ( ) , e ) ; } } public Boolean removeFileType ( String fileTypeId ) throws ArchivaRestServiceException { try { archivaAdministration . removeFileType ( fileTypeId , getAuditInformation ( ) ) ; return Boolean . TRUE ; } catch ( RepositoryAdminException e ) { throw new ArchivaRestServiceException ( e . getMessage ( ) , e ) ; } } public Boolean enabledKnownContentConsumer ( String knownContentConsumer ) throws ArchivaRestServiceException { try { archivaAdministration . addKnownContentConsumer ( knownContentConsumer , getAuditInformation ( ) ) ; return Boolean . TRUE ; } catch ( RepositoryAdminException e ) { throw new ArchivaRestServiceException ( e . getMessage ( ) , e ) ; } } public void enabledKnownContentConsumers ( List < String > knownContentConsumers ) throws ArchivaRestServiceException { try { archivaAdministration . setKnownContentConsumers ( knownContentConsumers , getAuditInformation ( ) ) ; } catch ( RepositoryAdminException e ) { throw new ArchivaRestServiceException ( e . getMessage ( ) , e ) ; } } public Boolean disabledKnownContentConsumer ( String knownContentConsumer ) throws ArchivaRestServiceException { try { archivaAdministration . removeKnownContentConsumer ( knownContentConsumer , getAuditInformation ( ) ) ; return Boolean . TRUE ; } catch ( RepositoryAdminException e ) { throw new ArchivaRestServiceException ( e . getMessage ( ) , e ) ; } } public Boolean enabledInvalidContentConsumer ( String invalidContentConsumer ) throws ArchivaRestServiceException { try { archivaAdministration . addInvalidContentConsumer ( invalidContentConsumer , getAuditInformation ( ) ) ; return Boolean . TRUE ; } catch ( RepositoryAdminException e ) { throw new ArchivaRestServiceException ( e . getMessage ( ) , e ) ; } } public void enabledInvalidContentConsumers ( List < String > invalidContentConsumers ) throws ArchivaRestServiceException { try { archivaAdministration . setInvalidContentConsumers ( invalidContentConsumers , getAuditInformation ( ) ) ; } catch ( RepositoryAdminException e ) { throw new ArchivaRestServiceException ( e . getMessage ( ) , e ) ; } } public Boolean disabledInvalidContentConsumer ( String invalidContentConsumer ) throws ArchivaRestServiceException { try { archivaAdministration . removeInvalidContentConsumer ( invalidContentConsumer , getAuditInformation ( ) ) ; return Boolean . TRUE ; } catch ( RepositoryAdminException e ) { throw new ArchivaRestServiceException ( e . getMessage ( ) , e ) ; } } public List < FileType > getFileTypes ( ) throws ArchivaRestServiceException { try { List < FileType > modelfileTypes = archivaAdministration . getFileTypes ( ) ; if ( modelfileTypes == null || modelfileTypes . isEmpty ( ) ) { return Collections . emptyList ( ) ; } return modelfileTypes ; } catch ( RepositoryAdminException e ) { throw new ArchivaRestServiceException ( e . getMessage ( ) , e ) ; } } public List < String > getKnownContentConsumers ( ) throws ArchivaRestServiceException { try { return new ArrayList < String > ( archivaAdministration . getKnownContentConsumers ( ) ) ; } catch ( RepositoryAdminException e ) { throw new ArchivaRestServiceException ( e . getMessage ( ) , e ) ; } } public List < String > getInvalidContentConsumers ( ) throws ArchivaRestServiceException { try { return new ArrayList < String > ( archivaAdministration . getInvalidContentConsumers ( ) ) ; } catch ( RepositoryAdminException e ) { throw new ArchivaRestServiceException ( e . getMessage ( ) , e ) ; } } public OrganisationInformation getOrganisationInformation ( ) throws ArchivaRestServiceException { try { return archivaAdministration . getOrganisationInformation ( ) ; } catch ( RepositoryAdminException e ) { throw new ArchivaRestServiceException ( e . getMessage ( ) , e ) ; } } public void setOrganisationInformation ( OrganisationInformation organisationInformation ) throws ArchivaRestServiceException { try { archivaAdministration . setOrganisationInformation ( organisationInformation ) ; } catch ( RepositoryAdminException e ) { throw new ArchivaRestServiceException ( e . getMessage ( ) , e ) ; } } public Boolean registrationDisabled ( ) throws ArchivaRestServiceException { return getUiConfiguration ( ) . isDisableRegistration ( ) ; } public UiConfiguration getUiConfiguration ( ) throws ArchivaRestServiceException { try { return archivaAdministration . getUiConfiguration ( ) ; } catch ( RepositoryAdminException e ) { throw new ArchivaRestServiceException ( e . getMessage ( ) , e ) ; } } public void setUiConfiguration ( UiConfiguration uiConfiguration ) throws ArchivaRestServiceException { try { archivaAdministration . updateUiConfiguration ( uiConfiguration ) ; } catch ( RepositoryAdminException e ) { throw new ArchivaRestServiceException ( e . getMessage ( ) , e ) ; } } public String getApplicationUrl ( ) throws ArchivaRestServiceException { try { return archivaAdministration . getUiConfiguration ( ) . getApplicationUrl ( ) ; } catch ( RepositoryAdminException e ) { throw new ArchivaRestServiceException ( e . getMessage ( ) , e ) ; } } public NetworkConfiguration getNetworkConfiguration ( ) throws ArchivaRestServiceException { try { return archivaAdministration . getNetworkConfiguration ( ) ; } catch ( RepositoryAdminException e ) { throw new ArchivaRestServiceException ( e . getMessage ( ) , e ) ; } } public void setNetworkConfiguration ( NetworkConfiguration networkConfiguration ) throws ArchivaRestServiceException { try { archivaAdministration . setNetworkConfiguration ( networkConfiguration ) ; } catch ( RepositoryAdminException e ) { throw new ArchivaRestServiceException ( e . getMessage ( ) , e ) ; } } public List < AdminRepositoryConsumer > getKnownContentAdminRepositoryConsumers ( ) throws ArchivaRestServiceException { try { AddAdminRepoConsumerClosure addAdminRepoConsumer = new AddAdminRepoConsumerClosure ( archivaAdministration . getKnownContentConsumers ( ) ) ; CollectionUtils . forAllDo ( repoConsumerUtil . getAvailableKnownConsumers ( ) , addAdminRepoConsumer ) ; List < AdminRepositoryConsumer > knownContentConsumers = addAdminRepoConsumer . getList ( ) ; Collections . sort ( knownContentConsumers , AdminRepositoryConsumerComparator . getInstance ( ) ) ; return knownContentConsumers ; } catch ( RepositoryAdminException e ) { throw new ArchivaRestServiceException ( e . getMessage ( ) , e ) ; } } public List < AdminRepositoryConsumer > getInvalidContentAdminRepositoryConsumers ( ) throws ArchivaRestServiceException { try { AddAdminRepoConsumerClosure addAdminRepoConsumer = new AddAdminRepoConsumerClosure ( archivaAdministration . getInvalidContentConsumers ( ) ) ; CollectionUtils . forAllDo ( repoConsumerUtil . getAvailableInvalidConsumers ( ) , addAdminRepoConsumer ) ; List < AdminRepositoryConsumer > invalidContentConsumers = addAdminRepoConsumer . getList ( ) ; Collections . sort ( invalidContentConsumers , AdminRepositoryConsumerComparator . getInstance ( ) ) ; return invalidContentConsumers ; } catch ( RepositoryAdminException e ) { throw new ArchivaRestServiceException ( e . getMessage ( ) , e ) ; } } }",Smelly
"public class AbstractReleaseAction extends ContinuumActionSupport { protected Map < String , String > getEnvironments ( Profile profile , String defaultBuildagent ) { if ( profile == null ) { return Collections . EMPTY_MAP ; } Map < String , String > envVars = new HashMap < String , String > ( ) ; if ( defaultBuildagent != null && defaultBuildagent . length ( ) > 0 ) { BuildAgentGroupConfiguration group = getContinuum ( ) . getConfiguration ( ) . getBuildAgentGroup ( profile . getBuildAgentGroup ( ) ) ; if ( group != null ) { List < BuildAgentConfiguration > agents = group . getBuildAgents ( ) ; if ( agents != null ) { if ( isDefaultBuildAgentEnabledInGroup ( defaultBuildagent , agents ) ) { envVars . put ( DistributedReleaseUtil . KEY_BUILD_AGENT_URL , defaultBuildagent ) ; } else { for ( BuildAgentConfiguration agent : agents ) { if ( agent . isEnabled ( ) == true ) { envVars . put ( DistributedReleaseUtil . KEY_BUILD_AGENT_URL , agent . getUrl ( ) ) ; break ; } } } } } } String javaHome = getJavaHomeValue ( profile ) ; if ( ! StringUtils . isEmpty ( javaHome ) ) { envVars . put ( getContinuum ( ) . getInstallationService ( ) . getEnvVar ( InstallationService . JDK_TYPE ) , javaHome ) ; } Installation builder = profile . getBuilder ( ) ; if ( builder != null ) { envVars . put ( getContinuum ( ) . getInstallationService ( ) . getEnvVar ( InstallationService . MAVEN2_TYPE ) , builder . getVarValue ( ) ) ; } List < Installation > installations = profile . getEnvironmentVariables ( ) ; for ( Installation installation : installations ) { envVars . put ( installation . getVarName ( ) , installation . getVarValue ( ) ) ; } return envVars ; } private boolean isDefaultBuildAgentEnabledInGroup ( String defaultBuildagent , List < BuildAgentConfiguration > agents ) { boolean isInGroup = false ; for ( BuildAgentConfiguration agent : agents ) { if ( agent . isEnabled ( ) == true ) { if ( defaultBuildagent . equals ( agent . getUrl ( ) ) ) { isInGroup = true ; break ; } } } return isInGroup ; } private String getJavaHomeValue ( Profile profile ) { Installation jdk = profile . getJdk ( ) ; if ( jdk == null ) { return null ; } return jdk . getVarValue ( ) ; } }",No
"public class ProcessorEndpoint extends DefaultPollingEndpoint < Exchange > { private Processor processor ; protected ProcessorEndpoint ( ) { } protected ProcessorEndpoint ( String endpointUri ) { super ( endpointUri ) ; } public ProcessorEndpoint ( String endpointUri , CamelContext context , Processor processor ) { super ( endpointUri , context ) ; this . processor = processor ; } public ProcessorEndpoint ( String endpointUri , Component component , Processor processor ) { super ( endpointUri , component ) ; this . processor = processor ; } public ProcessorEndpoint ( String endpointUri , Processor processor ) { super ( endpointUri ) ; this . processor = processor ; } protected ProcessorEndpoint ( String endpointUri , Component component ) { super ( endpointUri , component ) ; } public Producer < Exchange > createProducer ( ) throws Exception { return new DefaultProducer < Exchange > ( this ) { public void process ( Exchange exchange ) throws Exception { onExchange ( exchange ) ; } } ; } @ Override public PollingConsumer < Exchange > createPollingConsumer ( ) throws Exception { return new ProcessorPollingConsumer ( this , getProcessor ( ) ) ; } public Processor getProcessor ( ) throws Exception { if ( processor == null ) { processor = createProcessor ( ) ; } return processor ; } protected Processor createProcessor ( ) throws Exception { return new Processor ( ) { public void process ( Exchange exchange ) throws Exception { onExchange ( exchange ) ; } } ; } protected void onExchange ( Exchange exchange ) throws Exception { getProcessor ( ) . process ( exchange ) ; } public boolean isSingleton ( ) { return true ; } }",No
"public class TestChildReaper extends BaseClassForTests { @ Test public void testMaxChildren ( ) throws Exception { server . close ( ) ; final int LARGE_QTY = 10000 ; System . setProperty ( ""jute.maxbuffer"" , """" + LARGE_QTY ) ; server = new TestingServer ( ) ; try { Timing timing = new Timing ( ) ; ChildReaper reaper = null ; CuratorFramework client = CuratorFrameworkFactory . newClient ( server . getConnectString ( ) , timing . session ( ) , timing . connection ( ) , new ExponentialBackoffRetry ( 100 , 3 ) ) ; try { client . start ( ) ; for ( int i = 0 ; i < LARGE_QTY ; ++ i ) { if ( ( i % 1000 ) == 0 ) { System . out . println ( i ) ; } client . create ( ) . creatingParentsIfNeeded ( ) . forPath ( ""/big/node-"" + i ) ; } try { client . getChildren ( ) . forPath ( ""/big"" ) ; Assert . fail ( ""Should have been a connection loss"" ) ; } catch ( KeeperException . ConnectionLossException e ) { } final CountDownLatch latch = new CountDownLatch ( 1 ) ; reaper = new ChildReaper ( client , ""/big"" , Reaper . Mode . REAP_UNTIL_DELETE , 1 ) { @ Override protected void warnMaxChildren ( String path , Stat stat ) { latch . countDown ( ) ; super . warnMaxChildren ( path , stat ) ; } } ; reaper . setMaxChildren ( 100 ) ; reaper . start ( ) ; Assert . assertTrue ( timing . awaitLatch ( latch ) ) ; } finally { CloseableUtils . closeQuietly ( reaper ) ; CloseableUtils . closeQuietly ( client ) ; } } finally { System . clearProperty ( ""jute.maxbuffer"" ) ; } } @ Test public void testLargeNodes ( ) throws Exception { server . close ( ) ; final int LARGE_QTY = 10000 ; final int SMALL_QTY = 100 ; System . setProperty ( ""jute.maxbuffer"" , """" + LARGE_QTY ) ; server = new TestingServer ( ) ; try { Timing timing = new Timing ( ) ; ChildReaper reaper = null ; CuratorFramework client = CuratorFrameworkFactory . newClient ( server . getConnectString ( ) , timing . session ( ) , timing . connection ( ) , new ExponentialBackoffRetry ( 100 , 3 ) ) ; try { client . start ( ) ; for ( int i = 0 ; i < LARGE_QTY ; ++ i ) { if ( ( i % 1000 ) == 0 ) { System . out . println ( i ) ; } client . create ( ) . creatingParentsIfNeeded ( ) . forPath ( ""/big/node-"" + i ) ; if ( i < SMALL_QTY ) { client . create ( ) . creatingParentsIfNeeded ( ) . forPath ( ""/small/node-"" + i ) ; } } reaper = new ChildReaper ( client , ""/foo"" , Reaper . Mode . REAP_UNTIL_DELETE , 1 ) ; reaper . start ( ) ; reaper . addPath ( ""/big"" ) ; reaper . addPath ( ""/small"" ) ; int count = - 1 ; for ( int i = 0 ; ( i < 10 ) && ( count != 0 ) ; ++ i ) { timing . sleepABit ( ) ; count = client . checkExists ( ) . forPath ( ""/small"" ) . getNumChildren ( ) ; } Assert . assertEquals ( count , 0 ) ; } finally { CloseableUtils . closeQuietly ( reaper ) ; CloseableUtils . closeQuietly ( client ) ; } } finally { System . clearProperty ( ""jute.maxbuffer"" ) ; } } @ Test public void testSomeNodes ( ) throws Exception { Timing timing = new Timing ( ) ; ChildReaper reaper = null ; CuratorFramework client = CuratorFrameworkFactory . newClient ( server . getConnectString ( ) , timing . session ( ) , timing . connection ( ) , new RetryOneTime ( 1 ) ) ; try { client . start ( ) ; Random r = new Random ( ) ; int nonEmptyNodes = 0 ; for ( int i = 0 ; i < 10 ; ++ i ) { client . create ( ) . creatingParentsIfNeeded ( ) . forPath ( ""/test/"" + Integer . toString ( i ) ) ; if ( r . nextBoolean ( ) ) { client . create ( ) . forPath ( ""/test/"" + Integer . toString ( i ) + ""/foo"" ) ; ++ nonEmptyNodes ; } } reaper = new ChildReaper ( client , ""/test"" , Reaper . Mode . REAP_UNTIL_DELETE , 1 ) ; reaper . start ( ) ; timing . forWaiting ( ) . sleepABit ( ) ; Stat stat = client . checkExists ( ) . forPath ( ""/test"" ) ; Assert . assertEquals ( stat . getNumChildren ( ) , nonEmptyNodes ) ; } finally { CloseableUtils . closeQuietly ( reaper ) ; CloseableUtils . closeQuietly ( client ) ; } } @ Test public void testSimple ( ) throws Exception { Timing timing = new Timing ( ) ; ChildReaper reaper = null ; CuratorFramework client = CuratorFrameworkFactory . newClient ( server . getConnectString ( ) , timing . session ( ) , timing . connection ( ) , new RetryOneTime ( 1 ) ) ; try { client . start ( ) ; for ( int i = 0 ; i < 10 ; ++ i ) { client . create ( ) . creatingParentsIfNeeded ( ) . forPath ( ""/test/"" + Integer . toString ( i ) ) ; } reaper = new ChildReaper ( client , ""/test"" , Reaper . Mode . REAP_UNTIL_DELETE , 1 ) ; reaper . start ( ) ; timing . forWaiting ( ) . sleepABit ( ) ; Stat stat = client . checkExists ( ) . forPath ( ""/test"" ) ; Assert . assertEquals ( stat . getNumChildren ( ) , 0 ) ; } finally { CloseableUtils . closeQuietly ( reaper ) ; CloseableUtils . closeQuietly ( client ) ; } } @ Test public void testLeaderElection ( ) throws Exception { Timing timing = new Timing ( ) ; ChildReaper reaper = null ; CuratorFramework client = CuratorFrameworkFactory . newClient ( server . getConnectString ( ) , timing . session ( ) , timing . connection ( ) , new RetryOneTime ( 1 ) ) ; LeaderLatch otherLeader = null ; try { client . start ( ) ; for ( int i = 0 ; i < 10 ; ++ i ) { client . create ( ) . creatingParentsIfNeeded ( ) . forPath ( ""/test/"" + Integer . toString ( i ) ) ; } otherLeader = new LeaderLatch ( client , ""/test-leader"" ) ; otherLeader . start ( ) ; otherLeader . await ( ) ; reaper = new ChildReaper ( client , ""/test"" , Reaper . Mode . REAP_UNTIL_DELETE , ChildReaper . newExecutorService ( ) , 1 , ""/test-leader"" ) ; reaper . start ( ) ; timing . forWaiting ( ) . sleepABit ( ) ; Stat stat = client . checkExists ( ) . forPath ( ""/test"" ) ; Assert . assertEquals ( stat . getNumChildren ( ) , 10 ) ; CloseableUtils . closeQuietly ( otherLeader ) ; timing . forWaiting ( ) . sleepABit ( ) ; stat = client . checkExists ( ) . forPath ( ""/test"" ) ; Assert . assertEquals ( stat . getNumChildren ( ) , 0 ) ; } finally { CloseableUtils . closeQuietly ( reaper ) ; if ( otherLeader != null && otherLeader . getState ( ) == LeaderLatch . State . STARTED ) { CloseableUtils . closeQuietly ( otherLeader ) ; } CloseableUtils . closeQuietly ( client ) ; } } @ Test public void testMultiPath ( ) throws Exception { Timing timing = new Timing ( ) ; ChildReaper reaper = null ; CuratorFramework client = CuratorFrameworkFactory . newClient ( server . getConnectString ( ) , timing . session ( ) , timing . connection ( ) , new RetryOneTime ( 1 ) ) ; try { client . start ( ) ; for ( int i = 0 ; i < 10 ; ++ i ) { client . create ( ) . creatingParentsIfNeeded ( ) . forPath ( ""/test1/"" + Integer . toString ( i ) ) ; client . create ( ) . creatingParentsIfNeeded ( ) . forPath ( ""/test2/"" + Integer . toString ( i ) ) ; client . create ( ) . creatingParentsIfNeeded ( ) . forPath ( ""/test3/"" + Integer . toString ( i ) ) ; } reaper = new ChildReaper ( client , ""/test2"" , Reaper . Mode . REAP_UNTIL_DELETE , 1 ) ; reaper . start ( ) ; reaper . addPath ( ""/test1"" ) ; timing . forWaiting ( ) . sleepABit ( ) ; Stat stat = client . checkExists ( ) . forPath ( ""/test1"" ) ; Assert . assertEquals ( stat . getNumChildren ( ) , 0 ) ; stat = client . checkExists ( ) . forPath ( ""/test2"" ) ; Assert . assertEquals ( stat . getNumChildren ( ) , 0 ) ; stat = client . checkExists ( ) . forPath ( ""/test3"" ) ; Assert . assertEquals ( stat . getNumChildren ( ) , 10 ) ; } finally { CloseableUtils . closeQuietly ( reaper ) ; CloseableUtils . closeQuietly ( client ) ; } } @ Test public void testNamespace ( ) throws Exception { Timing timing = new Timing ( ) ; ChildReaper reaper = null ; CuratorFramework client = CuratorFrameworkFactory . builder ( ) . connectString ( server . getConnectString ( ) ) . sessionTimeoutMs ( timing . session ( ) ) . connectionTimeoutMs ( timing . connection ( ) ) . retryPolicy ( new RetryOneTime ( 1 ) ) . namespace ( ""foo"" ) . build ( ) ; try { client . start ( ) ; for ( int i = 0 ; i < 10 ; ++ i ) { client . create ( ) . creatingParentsIfNeeded ( ) . forPath ( ""/test/"" + Integer . toString ( i ) ) ; } reaper = new ChildReaper ( client , ""/test"" , Reaper . Mode . REAP_UNTIL_DELETE , 1 ) ; reaper . start ( ) ; timing . forWaiting ( ) . sleepABit ( ) ; Stat stat = client . checkExists ( ) . forPath ( ""/test"" ) ; Assert . assertEquals ( stat . getNumChildren ( ) , 0 ) ; stat = client . usingNamespace ( null ) . checkExists ( ) . forPath ( ""/foo/test"" ) ; Assert . assertNotNull ( stat ) ; Assert . assertEquals ( stat . getNumChildren ( ) , 0 ) ; } finally { CloseableUtils . closeQuietly ( reaper ) ; CloseableUtils . closeQuietly ( client ) ; } } }",Smelly
"public class PlainSchemaITCase extends AbstractITCase { private PlainSchemaTO buildPlainSchemaTO ( final String name , final AttrSchemaType type ) { PlainSchemaTO schemaTO = new PlainSchemaTO ( ) ; schemaTO . setKey ( name + getUUIDString ( ) ) ; schemaTO . setType ( type ) ; return schemaTO ; } @ Test public void create ( ) { PlainSchemaTO schemaTO = buildPlainSchemaTO ( ""testAttribute"" , AttrSchemaType . String ) ; schemaTO . setMandatoryCondition ( ""false"" ) ; PlainSchemaTO newPlainSchemaTO = createSchema ( SchemaType . PLAIN , schemaTO ) ; assertEquals ( schemaTO , newPlainSchemaTO ) ; try { createSchema ( SchemaType . PLAIN , schemaTO ) ; fail ( ) ; } catch ( SyncopeClientException e ) { assertEquals ( ClientExceptionType . EntityExists , e . getType ( ) ) ; } } @ Test public void createWithNotPermittedName ( ) { PlainSchemaTO schemaTO = new PlainSchemaTO ( ) ; schemaTO . setKey ( ""failedLogins"" ) ; schemaTO . setType ( AttrSchemaType . String ) ; try { createSchema ( SchemaType . PLAIN , schemaTO ) ; fail ( ""This should not be reacheable"" ) ; } catch ( SyncopeClientException e ) { assertEquals ( ClientExceptionType . InvalidPlainSchema , e . getType ( ) ) ; boolean entityViolationTypeCheck = false ; for ( String element : e . getElements ( ) ) { if ( ! entityViolationTypeCheck ) { entityViolationTypeCheck = element . contains ( EntityViolationType . InvalidKey . name ( ) ) ; } } assertTrue ( entityViolationTypeCheck ) ; } } @ Test public void createREnumWithoutEnumeration ( ) { PlainSchemaTO schemaTO = new PlainSchemaTO ( ) ; schemaTO . setKey ( ""enumcheck"" ) ; schemaTO . setType ( AttrSchemaType . Enum ) ; try { createSchema ( SchemaType . PLAIN , schemaTO ) ; fail ( ""This should not be reacheable"" ) ; } catch ( SyncopeClientException e ) { assertEquals ( ClientExceptionType . InvalidPlainSchema , e . getType ( ) ) ; assertTrue ( e . getElements ( ) . iterator ( ) . next ( ) . contains ( EntityViolationType . InvalidSchemaEnum . name ( ) ) ) ; } } @ Test public void createUEnumWithoutEnumeration ( ) { PlainSchemaTO schemaTO = new PlainSchemaTO ( ) ; schemaTO . setKey ( ""enumcheck"" ) ; schemaTO . setType ( AttrSchemaType . Enum ) ; try { createSchema ( SchemaType . PLAIN , schemaTO ) ; fail ( ""This should not be reacheable"" ) ; } catch ( SyncopeClientException e ) { assertEquals ( ClientExceptionType . InvalidPlainSchema , e . getType ( ) ) ; assertTrue ( e . getElements ( ) . iterator ( ) . next ( ) . contains ( EntityViolationType . InvalidSchemaEnum . name ( ) ) ) ; } } @ Test public void createEncrypted ( ) { PlainSchemaTO schemaTO = new PlainSchemaTO ( ) ; schemaTO . setKey ( ""encrypted"" ) ; schemaTO . setType ( AttrSchemaType . Encrypted ) ; schemaTO . setCipherAlgorithm ( CipherAlgorithm . AES ) ; schemaTO . setSecretKey ( ""huhadfhsjfsfsdkj!####"" ) ; createSchema ( SchemaType . PLAIN , schemaTO ) ; } @ Test public void createBinary ( ) { PlainSchemaTO schemaTO = new PlainSchemaTO ( ) ; schemaTO . setKey ( ""x509certificate"" ) ; schemaTO . setType ( AttrSchemaType . Binary ) ; schemaTO . setMimeType ( ""application/x-x509-ca-cert"" ) ; createSchema ( SchemaType . PLAIN , schemaTO ) ; } @ Test public void delete ( ) { PlainSchemaTO schemaTO = buildPlainSchemaTO ( ""todelete"" , AttrSchemaType . String ) ; schemaTO . setMandatoryCondition ( ""false"" ) ; createSchema ( SchemaType . PLAIN , schemaTO ) ; schemaService . delete ( SchemaType . PLAIN , schemaTO . getKey ( ) ) ; PlainSchemaTO firstname = null ; try { firstname = schemaService . read ( SchemaType . PLAIN , schemaTO . getKey ( ) ) ; } catch ( SyncopeClientException e ) { assertEquals ( Response . Status . NOT_FOUND , e . getType ( ) . getResponseStatus ( ) ) ; } assertNull ( firstname ) ; } @ Test public void list ( ) { List < PlainSchemaTO > schemas = schemaService . list ( new SchemaQuery . Builder ( ) . type ( SchemaType . PLAIN ) . build ( ) ) ; assertFalse ( schemas . isEmpty ( ) ) ; for ( PlainSchemaTO schemaTO : schemas ) { assertNotNull ( schemaTO ) ; } } @ Test public void listByAnyTypeClass ( ) { List < PlainSchemaTO > userSchemas = schemaService . list ( new SchemaQuery . Builder ( ) . type ( SchemaType . PLAIN ) . anyTypeClass ( ""minimal user"" ) . build ( ) ) ; assertTrue ( IterableUtils . matchesAny ( userSchemas , new Predicate < PlainSchemaTO > ( ) { @ Override public boolean evaluate ( final PlainSchemaTO object ) { return ""fullname"" . equals ( object . getKey ( ) ) ; } } ) ) ; assertFalse ( IterableUtils . matchesAny ( userSchemas , new Predicate < PlainSchemaTO > ( ) { @ Override public boolean evaluate ( final PlainSchemaTO object ) { return ""password.cipher.algorithm"" . equals ( object . getKey ( ) ) || ""rderived_dx"" . equals ( object . getKey ( ) ) || ""icon"" . equals ( object . getKey ( ) ) || ""mderived_sx"" . equals ( object . getKey ( ) ) || ""self.membership.layout"" . equals ( object . getKey ( ) ) ; } } ) ) ; } @ Test public void update ( ) { PlainSchemaTO schemaTO = schemaService . read ( SchemaType . PLAIN , ""icon"" ) ; assertNotNull ( schemaTO ) ; schemaService . update ( SchemaType . PLAIN , schemaTO ) ; PlainSchemaTO updatedTO = schemaService . read ( SchemaType . PLAIN , ""icon"" ) ; assertEquals ( schemaTO , updatedTO ) ; updatedTO . setType ( AttrSchemaType . Date ) ; try { schemaService . update ( SchemaType . PLAIN , updatedTO ) ; fail ( ""This should not be reacheable"" ) ; } catch ( SyncopeClientException e ) { assertEquals ( ClientExceptionType . InvalidPlainSchema , e . getType ( ) ) ; } } @ Test public void issue258 ( ) { PlainSchemaTO schemaTO = new PlainSchemaTO ( ) ; schemaTO . setKey ( ""schema_issue258"" ) ; schemaTO . setType ( AttrSchemaType . Double ) ; schemaTO = createSchema ( SchemaType . PLAIN , schemaTO ) ; assertNotNull ( schemaTO ) ; AnyTypeClassTO typeClass = new AnyTypeClassTO ( ) ; typeClass . setKey ( ""issue258"" ) ; typeClass . getPlainSchemas ( ) . add ( schemaTO . getKey ( ) ) ; anyTypeClassService . create ( typeClass ) ; UserTO userTO = UserITCase . getUniqueSampleTO ( ""issue258@syncope.apache.org"" ) ; userTO . getAuxClasses ( ) . add ( typeClass . getKey ( ) ) ; userTO . getPlainAttrs ( ) . add ( attrTO ( schemaTO . getKey ( ) , ""1.2"" ) ) ; userTO = createUser ( userTO ) . getEntity ( ) ; assertNotNull ( userTO ) ; schemaTO . setType ( AttrSchemaType . Long ) ; try { schemaService . update ( SchemaType . PLAIN , schemaTO ) ; fail ( ""This should not be reacheable"" ) ; } catch ( SyncopeClientException e ) { assertEquals ( ClientExceptionType . InvalidPlainSchema , e . getType ( ) ) ; } } @ Test public void issue259 ( ) { PlainSchemaTO schemaTO = buildPlainSchemaTO ( ""schema_issue259"" , AttrSchemaType . Double ) ; schemaTO . setUniqueConstraint ( true ) ; schemaTO = createSchema ( SchemaType . PLAIN , schemaTO ) ; assertNotNull ( schemaTO ) ; AnyTypeClassTO typeClass = new AnyTypeClassTO ( ) ; typeClass . setKey ( ""issue259"" ) ; typeClass . getPlainSchemas ( ) . add ( schemaTO . getKey ( ) ) ; anyTypeClassService . create ( typeClass ) ; UserTO userTO = UserITCase . getUniqueSampleTO ( ""issue259@syncope.apache.org"" ) ; userTO . getAuxClasses ( ) . add ( typeClass . getKey ( ) ) ; userTO . getPlainAttrs ( ) . add ( attrTO ( schemaTO . getKey ( ) , ""1"" ) ) ; userTO = createUser ( userTO ) . getEntity ( ) ; assertNotNull ( userTO ) ; UserTO newUserTO = SerializationUtils . clone ( userTO ) ; newUserTO . getMemberships ( ) . add ( new MembershipTO . Builder ( ) . group ( ""b1f7c12d-ec83-441f-a50e-1691daaedf3b"" ) . build ( ) ) ; userTO = userService . update ( newUserTO ) . readEntity ( new GenericType < ProvisioningResult < UserTO > > ( ) { } ) . getEntity ( ) ; assertNotNull ( userTO ) ; } @ Test public void issue260 ( ) { PlainSchemaTO schemaTO = buildPlainSchemaTO ( ""schema_issue260"" , AttrSchemaType . Double ) ; schemaTO . setUniqueConstraint ( true ) ; schemaTO = createSchema ( SchemaType . PLAIN , schemaTO ) ; assertNotNull ( schemaTO ) ; AnyTypeClassTO typeClass = new AnyTypeClassTO ( ) ; typeClass . setKey ( ""issue260"" ) ; typeClass . getPlainSchemas ( ) . add ( schemaTO . getKey ( ) ) ; anyTypeClassService . create ( typeClass ) ; UserTO userTO = UserITCase . getUniqueSampleTO ( ""issue260@syncope.apache.org"" ) ; userTO . getAuxClasses ( ) . add ( typeClass . getKey ( ) ) ; userTO . getPlainAttrs ( ) . add ( attrTO ( schemaTO . getKey ( ) , ""1.2"" ) ) ; userTO = createUser ( userTO ) . getEntity ( ) ; assertNotNull ( userTO ) ; schemaTO . setUniqueConstraint ( false ) ; try { schemaService . update ( SchemaType . PLAIN , schemaTO ) ; fail ( ""This should not be reacheable"" ) ; } catch ( SyncopeClientException e ) { assertEquals ( ClientExceptionType . InvalidPlainSchema , e . getType ( ) ) ; } } @ Test public void issueSYNCOPE323 ( ) { PlainSchemaTO actual = schemaService . read ( SchemaType . PLAIN , ""icon"" ) ; assertNotNull ( actual ) ; try { createSchema ( SchemaType . PLAIN , actual ) ; fail ( ) ; } catch ( SyncopeClientException e ) { assertEquals ( Response . Status . CONFLICT , e . getType ( ) . getResponseStatus ( ) ) ; assertEquals ( ClientExceptionType . EntityExists , e . getType ( ) ) ; } actual . setKey ( null ) ; try { createSchema ( SchemaType . PLAIN , actual ) ; fail ( ) ; } catch ( SyncopeClientException e ) { assertEquals ( Response . Status . BAD_REQUEST , e . getType ( ) . getResponseStatus ( ) ) ; assertEquals ( ClientExceptionType . RequiredValuesMissing , e . getType ( ) ) ; } } @ Test public void issueSYNCOPE418 ( ) { PlainSchemaTO schema = buildPlainSchemaTO ( ""http://schemas.examples.org/security/authorization/organizationUnit"" , AttrSchemaType . Double ) ; try { createSchema ( SchemaType . PLAIN , schema ) ; fail ( ) ; } catch ( SyncopeClientException e ) { assertEquals ( ClientExceptionType . InvalidPlainSchema , e . getType ( ) ) ; assertTrue ( e . getElements ( ) . iterator ( ) . next ( ) . contains ( EntityViolationType . InvalidKey . name ( ) ) ) ; } } }",Smelly
"public abstract class StudioRunnableWithProgressAdapter implements StudioRunnableWithProgress { private static final Object [ ] EMPTY_OBJECT_ARRAY = new Object [ 0 ] ; public Object [ ] getLockedObjects ( ) { return EMPTY_OBJECT_ARRAY ; } public String getErrorMessage ( ) { return """" ; } }",No
"@ XmlRootElement ( name = ""redeliveryPolicy"" ) @ XmlAccessorType ( XmlAccessType . FIELD ) public class RedeliveryPolicyType { @ XmlAttribute ( ) private String ref ; @ XmlAttribute private Integer maximumRedeliveries ; @ XmlAttribute private Long initialRedeliveryDelay ; @ XmlAttribute private Double backOffMultiplier ; @ XmlAttribute private Boolean useExponentialBackOff ; @ XmlAttribute private Double collisionAvoidanceFactor ; @ XmlAttribute private Boolean useCollisionAvoidance ; @ XmlAttribute private Long maximumRedeliveryDelay ; @ XmlAttribute private LoggingLevel retriesExhaustedLogLevel ; @ XmlAttribute private LoggingLevel retryAttemptedLogLevel ; public RedeliveryPolicy createRedeliveryPolicy ( CamelContext context , RedeliveryPolicy parentPolicy ) { if ( ref != null ) { return CamelContextHelper . mandatoryLookup ( context , ref , RedeliveryPolicy . class ) ; } RedeliveryPolicy answer = parentPolicy . copy ( ) ; if ( maximumRedeliveries != null ) { answer . setMaximumRedeliveries ( maximumRedeliveries ) ; } if ( initialRedeliveryDelay != null ) { answer . setDelay ( initialRedeliveryDelay ) ; } if ( retriesExhaustedLogLevel != null ) { answer . setRetriesExhaustedLogLevel ( retriesExhaustedLogLevel ) ; } if ( retryAttemptedLogLevel != null ) { answer . setRetryAttemptedLogLevel ( retryAttemptedLogLevel ) ; } if ( backOffMultiplier != null ) { answer . setBackOffMultiplier ( backOffMultiplier ) ; } if ( useExponentialBackOff != null ) { answer . setUseExponentialBackOff ( useExponentialBackOff ) ; } if ( collisionAvoidanceFactor != null ) { answer . setCollisionAvoidanceFactor ( collisionAvoidanceFactor ) ; } if ( useCollisionAvoidance != null ) { answer . setUseCollisionAvoidance ( useCollisionAvoidance ) ; } if ( maximumRedeliveryDelay != null ) { answer . setMaximumRedeliveryDelay ( maximumRedeliveryDelay ) ; } return answer ; } public String toString ( ) { return ""RedeliveryPolicy[maximumRedeliveries: "" + maximumRedeliveries + ""]"" ; } public RedeliveryPolicyType backOffMultiplier ( double backOffMultiplier ) { setBackOffMultiplier ( backOffMultiplier ) ; return this ; } public RedeliveryPolicyType collisionAvoidancePercent ( double collisionAvoidancePercent ) { setCollisionAvoidanceFactor ( collisionAvoidancePercent * 0.01d ) ; return this ; } public RedeliveryPolicyType collisionAvoidanceFactor ( double collisionAvoidanceFactor ) { setCollisionAvoidanceFactor ( collisionAvoidanceFactor ) ; return this ; } public RedeliveryPolicyType initialRedeliveryDelay ( long initialRedeliveryDelay ) { setInitialRedeliveryDelay ( initialRedeliveryDelay ) ; return this ; } public RedeliveryPolicyType retriesExhaustedLogLevel ( LoggingLevel retriesExhaustedLogLevel ) { setRetriesExhaustedLogLevel ( retriesExhaustedLogLevel ) ; return this ; } public RedeliveryPolicyType retryAttemptedLogLevel ( LoggingLevel retryAttemptedLogLevel ) { setRetryAttemptedLogLevel ( retryAttemptedLogLevel ) ; return this ; } public RedeliveryPolicyType maximumRedeliveries ( int maximumRedeliveries ) { setMaximumRedeliveries ( maximumRedeliveries ) ; return this ; } public RedeliveryPolicyType useCollisionAvoidance ( ) { setUseCollisionAvoidance ( Boolean . TRUE ) ; return this ; } public RedeliveryPolicyType useExponentialBackOff ( ) { setUseExponentialBackOff ( Boolean . TRUE ) ; return this ; } public RedeliveryPolicyType maximumRedeliveryDelay ( long maximumRedeliveryDelay ) { setMaximumRedeliveryDelay ( maximumRedeliveryDelay ) ; return this ; } public RedeliveryPolicyType ref ( String ref ) { setRef ( ref ) ; return this ; } public Double getBackOffMultiplier ( ) { return backOffMultiplier ; } public void setBackOffMultiplier ( Double backOffMultiplier ) { this . backOffMultiplier = backOffMultiplier ; } public Double getCollisionAvoidanceFactor ( ) { return collisionAvoidanceFactor ; } public void setCollisionAvoidanceFactor ( Double collisionAvoidanceFactor ) { this . collisionAvoidanceFactor = collisionAvoidanceFactor ; } public Long getInitialRedeliveryDelay ( ) { return initialRedeliveryDelay ; } public void setInitialRedeliveryDelay ( Long initialRedeliveryDelay ) { this . initialRedeliveryDelay = initialRedeliveryDelay ; } public Integer getMaximumRedeliveries ( ) { return maximumRedeliveries ; } public void setMaximumRedeliveries ( Integer maximumRedeliveries ) { this . maximumRedeliveries = maximumRedeliveries ; } public Boolean getUseCollisionAvoidance ( ) { return useCollisionAvoidance ; } public void setUseCollisionAvoidance ( Boolean useCollisionAvoidance ) { this . useCollisionAvoidance = useCollisionAvoidance ; } public Boolean getUseExponentialBackOff ( ) { return useExponentialBackOff ; } public void setUseExponentialBackOff ( Boolean useExponentialBackOff ) { this . useExponentialBackOff = useExponentialBackOff ; } public Long getMaximumRedeliveryDelay ( ) { return maximumRedeliveryDelay ; } public void setMaximumRedeliveryDelay ( Long maximumRedeliveryDelay ) { this . maximumRedeliveryDelay = maximumRedeliveryDelay ; } public void setRetriesExhaustedLogLevel ( LoggingLevel retriesExhaustedLogLevel ) { this . retriesExhaustedLogLevel = retriesExhaustedLogLevel ; } public LoggingLevel getRetriesExhaustedLogLevel ( ) { return retriesExhaustedLogLevel ; } public void setRetryAttemptedLogLevel ( LoggingLevel retryAttemptedLogLevel ) { this . retryAttemptedLogLevel = retryAttemptedLogLevel ; } public LoggingLevel getRetryAttemptedLogLevel ( ) { return retryAttemptedLogLevel ; } public String getRef ( ) { return ref ; } public void setRef ( String ref ) { this . ref = ref ; } }",Smelly
" public static class ExampleJobConfigurableTIF extends ExampleTIF implements JobConfigurable { @ Override public void configure ( JobConf job ) { try { initialize ( job ) ; } catch ( IOException exception ) { throw new RuntimeException ( ""Failed to initialize."" , exception ) ; } } @ Override protected void initialize ( JobConf job ) throws IOException { initialize ( job , ""exampleJobConfigurableTable"" ) ; } ",No
"@ SuppressWarnings ( ""serial"" ) public class EntityFieldTag extends TagSupport { public static final String module = EntityFieldTag . class . getName ( ) ; protected String field = null ; protected String type = null ; protected String attribute = null ; protected Object defaultObj = """" ; protected String prefix = null ; protected String suffix = null ; public String getAttribute ( ) { return attribute ; } public void setAttribute ( String attribute ) { this . attribute = attribute ; } public String getField ( ) { return field ; } public void setField ( String field ) { this . field = field ; } public String getType ( ) { return type ; } public void setType ( String type ) { this . type = type ; } public String getPrefix ( ) { return prefix ; } public void setPrefix ( String prefix ) { this . prefix = prefix ; } public String getSuffix ( ) { return suffix ; } public void setSuffix ( String suffix ) { this . suffix = suffix ; } public Object getDefault ( ) { return defaultObj ; } public void setDefault ( Object defaultObj ) { this . defaultObj = defaultObj ; } @ Override public int doStartTag ( ) throws JspException { try { EntityField . run ( attribute , field , prefix , suffix , defaultObj . toString ( ) , type , pageContext ) ; } catch ( IOException e ) { if ( UtilJ2eeCompat . useNestedJspException ( pageContext . getServletContext ( ) ) ) { throw new JspException ( e . getMessage ( ) , e ) ; } else { Debug . logError ( e , ""Server does not support nested exceptions, here is the exception"" , module ) ; throw new JspException ( e . toString ( ) ) ; } } catch ( GenericEntityException e ) { if ( UtilJ2eeCompat . useNestedJspException ( pageContext . getServletContext ( ) ) ) { throw new JspException ( ""Entity Engine error: "" + e . getMessage ( ) , e ) ; } else { Debug . logError ( e , ""Server does not support nested exceptions, here is the exception"" , module ) ; throw new JspException ( ""Entity Engine error: "" + e . toString ( ) ) ; } } return ( SKIP_BODY ) ; } }",No
"@ DomainService ( nature = NatureOfService . DOMAIN , menuOrder = """" + Integer . MAX_VALUE ) public class CommandDtoServiceInternalDefault implements CommandDtoServiceInternal { private final MementoServiceDefault mementoService ; public CommandDtoServiceInternalDefault ( ) { this ( new MementoServiceDefault ( ) ) ; } CommandDtoServiceInternalDefault ( MementoServiceDefault mementoService ) { this . mementoService = mementoService . withNoEncoding ( ) ; } @ Programmatic @ PostConstruct public void init ( Map < String , String > props ) { } private ObjectSpecificationDefault getJavaSpecificationOfOwningClass ( final Method method ) { return getJavaSpecification ( method . getDeclaringClass ( ) ) ; } private ObjectSpecificationDefault getJavaSpecification ( final Class < ? > cls ) { final ObjectSpecification objectSpec = getSpecification ( cls ) ; if ( ! ( objectSpec instanceof ObjectSpecificationDefault ) ) { throw new UnsupportedOperationException ( ""Only Java is supported "" + ""(specification is '"" + objectSpec . getClass ( ) . getCanonicalName ( ) + ""')"" ) ; } return ( ObjectSpecificationDefault ) objectSpec ; } private ObjectSpecification getSpecification ( final Class < ? > type ) { return specificationLoader . loadSpecification ( type ) ; } @ Deprecated @ Programmatic @ Override public ActionInvocationMemento asActionInvocationMemento ( final Method method , final Object domainObject , final Object [ ] args ) { final ObjectSpecificationDefault targetObjSpec = getJavaSpecificationOfOwningClass ( method ) ; final ObjectMember member = targetObjSpec . getMember ( method ) ; if ( member == null ) { return null ; } if ( ! ( member instanceof ObjectAction ) ) { throw new UnsupportedOperationException ( String . format ( ""Method %s does not correspond to an action."" , method . getName ( ) ) ) ; } final ObjectAction action = ( ObjectAction ) member ; final String actionIdentifier = CommandUtil . memberIdentifierFor ( action ) ; final Bookmark domainObjectBookmark = bookmarkService . bookmarkFor ( domainObject ) ; final List < Class < ? > > argTypes = Lists . newArrayList ( ) ; final List < Object > argObjs = Lists . newArrayList ( ) ; CommandUtil . buildMementoArgLists ( mementoService , bookmarkService , method , args , argTypes , argObjs ) ; final ActionInvocationMemento aim = new ActionInvocationMemento ( mementoService , actionIdentifier , domainObjectBookmark , argTypes , argObjs ) ; return aim ; } @ Override public CommandDto asCommandDto ( final List < ObjectAdapter > targetAdapters , final ObjectAction objectAction , final ObjectAdapter [ ] argAdapters ) { final CommandDto dto = asCommandDto ( targetAdapters ) ; final ActionDto actionDto = new ActionDto ( ) ; actionDto . setInteractionType ( InteractionType . ACTION_INVOCATION ) ; dto . setMember ( actionDto ) ; addActionArgs ( objectAction , actionDto , argAdapters ) ; return dto ; } @ Override public CommandDto asCommandDto ( final List < ObjectAdapter > targetAdapters , final OneToOneAssociation property , final ObjectAdapter valueAdapterOrNull ) { final CommandDto dto = asCommandDto ( targetAdapters ) ; final PropertyDto propertyDto = new PropertyDto ( ) ; propertyDto . setInteractionType ( InteractionType . PROPERTY_EDIT ) ; dto . setMember ( propertyDto ) ; addPropertyValue ( property , propertyDto , valueAdapterOrNull ) ; return dto ; } private CommandDto asCommandDto ( final List < ObjectAdapter > targetAdapters ) { final CommandDto dto = new CommandDto ( ) ; dto . setMajorVersion ( ""1"" ) ; dto . setMinorVersion ( ""0"" ) ; String transactionId = determineTransactionId ( ) . toString ( ) ; dto . setTransactionId ( transactionId ) ; for ( ObjectAdapter targetAdapter : targetAdapters ) { final RootOid rootOid = ( RootOid ) targetAdapter . getOid ( ) ; final Bookmark bookmark = rootOid . asBookmark ( ) ; final OidsDto targets = CommandDtoUtils . targetsFor ( dto ) ; targets . getOid ( ) . add ( bookmark . toOidDto ( ) ) ; } return dto ; } protected UUID determineTransactionId ( ) { Command command = commandContext . getCommand ( ) ; if ( command != null && command . getTransactionId ( ) != null ) { return command . getTransactionId ( ) ; } else { return UUID . randomUUID ( ) ; } } @ Override public void addActionArgs ( final ObjectAction objectAction , final ActionDto actionDto , final ObjectAdapter [ ] argAdapters ) { final String actionId = CommandUtil . memberIdentifierFor ( objectAction ) ; final ObjectSpecification onType = objectAction . getOnType ( ) ; final String objectType = onType . getSpecId ( ) . asString ( ) ; final String localId = objectAction . getIdentifier ( ) . toNameIdentityString ( ) ; actionDto . setLogicalMemberIdentifier ( objectType + ""#"" + localId ) ; actionDto . setMemberIdentifier ( actionId ) ; List < ObjectActionParameter > actionParameters = objectAction . getParameters ( ) ; for ( int paramNum = 0 ; paramNum < actionParameters . size ( ) ; paramNum ++ ) { final ObjectActionParameter actionParameter = actionParameters . get ( paramNum ) ; final String parameterName = actionParameter . getName ( ) ; final Class < ? > paramType = actionParameter . getSpecification ( ) . getCorrespondingClass ( ) ; final ObjectAdapter argAdapter = argAdapters [ paramNum ] ; final Object arg = argAdapter != null ? argAdapter . getObject ( ) : null ; final ParamsDto parameters = CommandDtoUtils . parametersFor ( actionDto ) ; final List < ParamDto > parameterList = parameters . getParameter ( ) ; ParamDto paramDto = CommonDtoUtils . newParamDto ( parameterName , paramType , arg , bookmarkService ) ; parameterList . add ( paramDto ) ; } } @ Override public void addPropertyValue ( final OneToOneAssociation property , final PropertyDto propertyDto , final ObjectAdapter valueAdapter ) { final String actionIdentifier = CommandUtil . memberIdentifierFor ( property ) ; final ObjectSpecification onType = property . getOnType ( ) ; final String objectType = onType . getSpecId ( ) . asString ( ) ; final String localId = property . getIdentifier ( ) . toNameIdentityString ( ) ; propertyDto . setLogicalMemberIdentifier ( objectType + ""#"" + localId ) ; propertyDto . setMemberIdentifier ( actionIdentifier ) ; final ObjectSpecification valueSpec = property . getSpecification ( ) ; final Class < ? > valueType = valueSpec . getCorrespondingClass ( ) ; final ValueWithTypeDto newValue = CommonDtoUtils . newValueWithTypeDto ( valueType , ObjectAdapter . Util . unwrap ( valueAdapter ) , bookmarkService ) ; propertyDto . setNewValue ( newValue ) ; } @ javax . inject . Inject CommandContext commandContext ; @ javax . inject . Inject private BookmarkService bookmarkService ; @ javax . inject . Inject SpecificationLoader specificationLoader ; @ javax . inject . Inject IsisSessionFactory isisSessionFactory ; protected AdapterManager getAdapterManager ( ) { return isisSessionFactory . getCurrentSession ( ) . getPersistenceSession ( ) ; } }",Smelly
"@ InterfaceAudience . User @ InterfaceStability . Evolving public class CarbonReaderBuilder { private String tablePath ; private String [ ] projectionColumns ; private Expression filterExpression ; private String tableName ; private Configuration hadoopConf ; private boolean useVectorReader = true ; private InputSplit inputSplit ; private boolean useArrowReader ; private List fileLists ; private Class < ? extends CarbonReadSupport > readSupportClass ; CarbonReaderBuilder ( String tablePath , String tableName ) { this . tablePath = tablePath ; this . tableName = tableName ; ThreadLocalSessionInfo . setCarbonSessionInfo ( new CarbonSessionInfo ( ) ) ; } CarbonReaderBuilder ( InputSplit inputSplit ) { this . inputSplit = inputSplit ; ThreadLocalSessionInfo . setCarbonSessionInfo ( new CarbonSessionInfo ( ) ) ; } CarbonReaderBuilder ( String tableName ) { this . tableName = tableName ; ThreadLocalSessionInfo . setCarbonSessionInfo ( new CarbonSessionInfo ( ) ) ; } public CarbonReaderBuilder withFolder ( String tablePath ) { this . tablePath = tablePath ; return this ; } public CarbonReaderBuilder withFileLists ( List fileLists ) { if ( null == this . fileLists ) { this . fileLists = fileLists ; } else { this . fileLists . addAll ( fileLists ) ; } return this ; } public CarbonReaderBuilder withFile ( String file ) { List fileLists = new ArrayList ( ) ; fileLists . add ( file ) ; return withFileLists ( fileLists ) ; } public CarbonReaderBuilder withReadSupport ( Class < ? extends CarbonReadSupport > readSupportClass ) { this . readSupportClass = readSupportClass ; return this ; } public CarbonReaderBuilder projection ( String [ ] projectionColumnNames ) { Objects . requireNonNull ( projectionColumnNames ) ; this . projectionColumns = projectionColumnNames ; return this ; } public CarbonReaderBuilder projection ( List < String > projectionColumnNames ) { Objects . requireNonNull ( projectionColumnNames ) ; String [ ] strings = new String [ projectionColumnNames . size ( ) ] ; for ( int i = 0 ; i < projectionColumnNames . size ( ) ; i ++ ) { strings [ i ] = projectionColumnNames . get ( i ) ; } return projection ( strings ) ; } public CarbonReaderBuilder filter ( Expression filterExpression ) { Objects . requireNonNull ( filterExpression ) ; this . filterExpression = filterExpression ; return this ; } public CarbonReaderBuilder withHadoopConf ( Configuration conf ) { if ( conf != null ) { this . hadoopConf = conf ; } return this ; } public CarbonReaderBuilder withBatch ( int batch ) { CarbonProperties . getInstance ( ) . addProperty ( CarbonCommonConstants . DETAIL_QUERY_BATCH_SIZE , String . valueOf ( batch ) ) ; return this ; } public CarbonReaderBuilder withHadoopConf ( String key , String value ) { if ( this . hadoopConf == null ) { this . hadoopConf = new Configuration ( ) ; } this . hadoopConf . set ( key , value ) ; return this ; } public CarbonReaderBuilder withRowRecordReader ( ) { this . useVectorReader = false ; return this ; } public < T > ArrowCarbonReader < T > buildArrowReader ( ) throws IOException , InterruptedException { useArrowReader = true ; return ( ArrowCarbonReader < T > ) this . build ( ) ; } private CarbonFileInputFormat prepareFileInputFormat ( Job job , boolean enableBlockletDistribution , boolean disableLoadBlockIndex ) throws IOException { if ( inputSplit != null && inputSplit instanceof CarbonInputSplit ) { tablePath = ( ( CarbonInputSplit ) inputSplit ) . getSegment ( ) . getReadCommittedScope ( ) . getFilePath ( ) ; tableName = ""UnknownTable"" + UUID . randomUUID ( ) ; } if ( null == this . fileLists && null == tablePath ) { throw new IllegalArgumentException ( ""Please set table path first."" ) ; } CarbonTable table ; if ( null != this . fileLists ) { if ( fileLists . size ( ) < 1 ) { throw new IllegalArgumentException ( ""fileLists must have one file in list as least!"" ) ; } String commonString = String . valueOf ( fileLists . get ( 0 ) ) ; for ( int i = 1 ; i < fileLists . size ( ) ; i ++ ) { commonString = commonString . substring ( 0 , StringUtils . indexOfDifference ( commonString , String . valueOf ( fileLists . get ( i ) ) ) ) ; } int index = commonString . lastIndexOf ( ""/"" ) ; commonString = commonString . substring ( 0 , index ) ; table = CarbonTable . buildTable ( commonString , tableName , hadoopConf ) ; } else { table = CarbonTable . buildTable ( tablePath , tableName , hadoopConf ) ; } if ( enableBlockletDistribution ) { Map < String , String > tableProperties = table . getTableInfo ( ) . getFactTable ( ) . getTableProperties ( ) ; tableProperties . put ( CarbonCommonConstants . CACHE_LEVEL , ""BLOCKLET"" ) ; table . getTableInfo ( ) . getFactTable ( ) . setTableProperties ( tableProperties ) ; } final CarbonFileInputFormat format = new CarbonFileInputFormat ( ) ; format . setTableInfo ( job . getConfiguration ( ) , table . getTableInfo ( ) ) ; format . setTablePath ( job . getConfiguration ( ) , table . getTablePath ( ) ) ; format . setTableName ( job . getConfiguration ( ) , table . getTableName ( ) ) ; format . setDatabaseName ( job . getConfiguration ( ) , table . getDatabaseName ( ) ) ; if ( filterExpression != null ) { format . setFilterPredicates ( job . getConfiguration ( ) , new IndexFilter ( table , filterExpression , true ) ) ; } if ( null != this . fileLists ) { format . setFileLists ( this . fileLists ) ; } if ( projectionColumns != null ) { int len = projectionColumns . length ; for ( int i = 0 ; i < len ; i ++ ) { if ( projectionColumns [ i ] . contains ( ""."" ) ) { throw new UnsupportedOperationException ( ""Complex child columns projection NOT supported through CarbonReader"" ) ; } } format . setColumnProjection ( job . getConfiguration ( ) , projectionColumns ) ; } if ( ( disableLoadBlockIndex ) && ( filterExpression == null ) ) { job . getConfiguration ( ) . set ( ""filter_blocks"" , ""false"" ) ; } return format ; } private < T > RecordReader getRecordReader ( Job job , CarbonFileInputFormat format , List < RecordReader < Void , T > > readers , InputSplit split ) throws IOException , InterruptedException { TaskAttemptContextImpl attempt = new TaskAttemptContextImpl ( job . getConfiguration ( ) , new TaskAttemptID ( ) ) ; RecordReader reader ; QueryModel queryModel = format . createQueryModel ( split , attempt ) ; boolean hasComplex = false ; for ( ProjectionDimension projectionDimension : queryModel . getProjectionDimensions ( ) ) { if ( projectionDimension . getDimension ( ) . isComplex ( ) ) { hasComplex = true ; break ; } } if ( useVectorReader && ! hasComplex ) { queryModel . setDirectVectorFill ( filterExpression == null ) ; reader = new CarbonVectorizedRecordReader ( queryModel ) ; } else { reader = format . createRecordReader ( split , attempt ) ; } try { reader . initialize ( split , attempt ) ; } catch ( Exception e ) { CarbonUtil . closeStreams ( readers . toArray ( new RecordReader [ 0 ] ) ) ; throw e ; } return reader ; } public < T > CarbonReader < T > build ( ) throws IOException , InterruptedException { if ( inputSplit != null ) { return buildWithSplits ( inputSplit ) ; } if ( hadoopConf == null ) { hadoopConf = FileFactory . getConfiguration ( ) ; } CarbonTableInputFormat . setCarbonReadSupport ( hadoopConf , readSupportClass ) ; final Job job = new Job ( new JobConf ( hadoopConf ) ) ; CarbonFileInputFormat format = prepareFileInputFormat ( job , false , true ) ; try { List < InputSplit > splits = format . getSplits ( new JobContextImpl ( job . getConfiguration ( ) , new JobID ( ) ) ) ; List < RecordReader < Void , T > > readers = new ArrayList < > ( splits . size ( ) ) ; for ( InputSplit split : splits ) { RecordReader reader = getRecordReader ( job , format , readers , split ) ; readers . add ( reader ) ; } if ( useArrowReader ) { return new ArrowCarbonReader < > ( readers ) ; } else { return new CarbonReader < > ( readers ) ; } } catch ( Exception ex ) { IndexStoreManager . getInstance ( ) . clearIndexCache ( format . getOrCreateCarbonTable ( ( job . getConfiguration ( ) ) ) . getAbsoluteTableIdentifier ( ) , false ) ; throw ex ; } } private < T > CarbonReader < T > buildWithSplits ( InputSplit inputSplit ) throws IOException , InterruptedException { if ( hadoopConf == null ) { hadoopConf = FileFactory . getConfiguration ( ) ; } CarbonTableInputFormat . setCarbonReadSupport ( hadoopConf , readSupportClass ) ; final Job job = new Job ( new JobConf ( hadoopConf ) ) ; CarbonFileInputFormat format = prepareFileInputFormat ( job , false , true ) ; format . setAllColumnProjectionIfNotConfigured ( job , format . getOrCreateCarbonTable ( job . getConfiguration ( ) ) ) ; try { List < RecordReader < Void , T > > readers = new ArrayList < > ( 1 ) ; RecordReader reader = getRecordReader ( job , format , readers , inputSplit ) ; readers . add ( reader ) ; if ( useArrowReader ) { return new ArrowCarbonReader < > ( readers ) ; } else { return new CarbonReader < > ( readers ) ; } } catch ( Exception ex ) { throw ex ; } } public InputSplit [ ] getSplits ( boolean enableBlockletDistribution ) throws IOException { if ( hadoopConf == null ) { hadoopConf = FileFactory . getConfiguration ( ) ; } Job job = null ; List < InputSplit > splits ; CarbonFileInputFormat format = null ; try { job = new Job ( new JobConf ( hadoopConf ) ) ; format = prepareFileInputFormat ( job , enableBlockletDistribution , false ) ; splits = format . getSplits ( new JobContextImpl ( job . getConfiguration ( ) , new JobID ( ) ) ) ; for ( InputSplit split : splits ) { ( ( CarbonInputSplit ) split ) . getDetailInfo ( ) ; } } finally { if ( format != null ) { IndexStoreManager . getInstance ( ) . clearIndexCache ( format . getOrCreateCarbonTable ( ( job . getConfiguration ( ) ) ) . getAbsoluteTableIdentifier ( ) , false ) ; } } return splits . toArray ( new InputSplit [ splits . size ( ) ] ) ; } }",No
"public class DoWhileNodeGUI extends ConfigurableNodeGUI { private static final String CONFIG_AREA_STRING = ""Config"" ; private DoWhileNode node ; private DoWhileConfigrationDialog configurationWindow ; private Polygon polygon ; private GeneralPath generalPath ; public DoWhileNodeGUI ( DoWhileNode node ) { super ( node ) ; this . node = node ; setConfigurationText ( CONFIG_AREA_STRING ) ; this . polygon = new Polygon ( ) ; generalPath = new GeneralPath ( ) ; } @ Override protected void showConfigurationDialog ( XBayaGUI xbayaGUI ) { if ( this . configurationWindow == null ) { this . configurationWindow = new DoWhileConfigrationDialog ( this . node , xbayaGUI ) ; } this . configurationWindow . show ( ) ; } @ Override protected void calculatePositions ( Graphics g ) { super . calculatePositions ( g ) ; calculatePositions ( ) ; setPortPositions ( ) ; } @ Override protected Rectangle getBounds ( ) { return this . polygon . getBounds ( ) ; } @ Override protected boolean isIn ( Point point ) { return this . polygon . contains ( point ) ; } protected GeneralPath getComponentHeaderShape ( ) { return DrawUtils . getRoundedShape ( createHeader ( getPosition ( ) ) ) ; } protected String getComponentHeaderText ( ) { return node . getName ( ) ; } protected Color getComponentHeaderColor ( ) { return headColor ; } protected GeneralPath getComponentShape ( ) { return generalPath ; } protected Node getNode ( ) { return this . node ; } private Polygon createHeader ( Point position ) { Polygon head = new Polygon ( ) ; head . addPoint ( position . x , position . y + this . headHeight / 2 ) ; head . addPoint ( position . x , position . y + this . headHeight ) ; head . addPoint ( position . x + this . dimension . width , position . y + this . headHeight ) ; head . addPoint ( position . x + this . dimension . width , position . y + this . headHeight / 2 ) ; head . addPoint ( position . x + this . dimension . width / 2 , position . y ) ; return head ; } @ Override protected void setPortPositions ( ) { List < ? extends Port > inputPorts = this . node . getInputPorts ( ) ; for ( int i = 0 ; i < inputPorts . size ( ) ; i ++ ) { Port port = inputPorts . get ( i ) ; Point offset = new Point ( PortGUI . DATA_PORT_SIZE / 2 , this . headHeight + PORT_INITIAL_GAP + PORT_GAP * i ) ; NodeController . getGUI ( port ) . setOffset ( offset ) ; } List < ? extends Port > outputPorts = this . node . getOutputPorts ( ) ; for ( int i = 0 ; i < outputPorts . size ( ) ; i ++ ) { Port port = outputPorts . get ( i ) ; Point offset = new Point ( this . getBounds ( ) . width - PortGUI . DATA_PORT_SIZE / 2 , this . headHeight + PORT_INITIAL_GAP + PORT_GAP * i ) ; NodeController . getGUI ( port ) . setOffset ( offset ) ; } PortImpl controlInPort = this . node . getControlInPort ( ) ; if ( controlInPort != null ) { Point offset = new Point ( 0 , this . headHeight / 2 ) ; NodeController . getGUI ( controlInPort ) . setOffset ( offset ) ; } List < ? extends Port > controlOutPorts = this . node . getControlOutPorts ( ) ; Port controlOutPort1 = controlOutPorts . get ( 0 ) ; Point offset = new Point ( getBounds ( ) . width , + this . headHeight / 2 ) ; NodeController . getGUI ( controlOutPort1 ) . setOffset ( offset ) ; Port controlOutPort2 = controlOutPorts . get ( 1 ) ; offset = new Point ( this . getBounds ( ) . width , getBounds ( ) . height - this . headHeight / 2 ) ; NodeController . getGUI ( controlOutPort2 ) . setOffset ( offset ) ; } private void calculatePositions ( ) { this . polygon . reset ( ) ; Point position = getPosition ( ) ; this . polygon . addPoint ( position . x , position . y + this . headHeight / 2 ) ; this . polygon . addPoint ( position . x , position . y + this . dimension . height ) ; this . polygon . addPoint ( position . x + this . dimension . width / 2 , position . y + this . dimension . height + this . headHeight / 2 ) ; this . polygon . addPoint ( position . x + this . dimension . width , position . y + this . dimension . height ) ; this . polygon . addPoint ( position . x + this . dimension . width , position . y + this . headHeight / 2 ) ; this . polygon . addPoint ( position . x + this . dimension . width / 2 , position . y ) ; DrawUtils . setupRoundedGeneralPath ( polygon , getComponentShape ( ) ) ; } }",No
"@ Category ( IntegrationTest . class ) public class TestUnionQuery extends QueryTestCaseBase { public TestUnionQuery ( ) { super ( TajoConstants . DEFAULT_DATABASE_NAME ) ; conf . setBoolVar ( TajoConf . ConfVars . $DEBUG_ENABLED , true ) ; } @ AfterClass public static void tearDown ( ) throws Exception { conf . setBoolVar ( TajoConf . ConfVars . $DEBUG_ENABLED , false ) ; } @ Test @ SimpleTest public final void testUnionAll1 ( ) throws Exception { Optional < TajoResultSetBase [ ] > existing = runSimpleTests ( ) ; verifyResultStats ( existing , 8L ) ; } @ Test @ SimpleTest public final void testUnionAll2 ( ) throws Exception { Optional < TajoResultSetBase [ ] > existing = runSimpleTests ( ) ; verifyResultStats ( existing , 10L ) ; } @ Test @ SimpleTest public final void testUnionAll3 ( ) throws Exception { Optional < TajoResultSetBase [ ] > existing = runSimpleTests ( ) ; verifyResultStats ( existing , 2L ) ; } @ Test @ SimpleTest public final void testUnionAll4 ( ) throws Exception { Optional < TajoResultSetBase [ ] > existing = runSimpleTests ( ) ; verifyResultStats ( existing , 1L ) ; } @ Test @ SimpleTest public final void testUnionAll5 ( ) throws Exception { Optional < TajoResultSetBase [ ] > existing = runSimpleTests ( ) ; verifyResultStats ( existing , 1L ) ; } @ Test @ SimpleTest public final void testUnionAll6 ( ) throws Exception { Optional < TajoResultSetBase [ ] > existing = runSimpleTests ( ) ; verifyResultStats ( existing , 1L ) ; } @ Test @ SimpleTest public final void testUnionAll7 ( ) throws Exception { Optional < TajoResultSetBase [ ] > existing = runSimpleTests ( ) ; verifyResultStats ( existing , 10L ) ; } @ Test @ SimpleTest public final void testUnionAll8 ( ) throws Exception { Optional < TajoResultSetBase [ ] > existing = runSimpleTests ( ) ; verifyResultStats ( existing , 1L ) ; } @ Test @ SimpleTest public final void testUnionAll9 ( ) throws Exception { Optional < TajoResultSetBase [ ] > existing = runSimpleTests ( ) ; verifyResultStats ( existing , 5L ) ; } @ Test @ SimpleTest public final void testUnionAll10 ( ) throws Exception { Optional < TajoResultSetBase [ ] > existing = runSimpleTests ( ) ; verifyResultStats ( existing , 20L ) ; } @ Test @ SimpleTest public final void testUnionAll11 ( ) throws Exception { Optional < TajoResultSetBase [ ] > existing = runSimpleTests ( ) ; verifyResultStats ( existing , 1L ) ; } @ Test @ SimpleTest public final void testUnionAll12 ( ) throws Exception { Optional < TajoResultSetBase [ ] > existing = runSimpleTests ( ) ; verifyResultStats ( existing , 5L ) ; } @ Test @ SimpleTest public final void testUnionAll13 ( ) throws Exception { Optional < TajoResultSetBase [ ] > existing = runSimpleTests ( ) ; verifyResultStats ( existing , 5L ) ; } @ Test @ SimpleTest public final void testUnionAll14 ( ) throws Exception { Optional < TajoResultSetBase [ ] > existing = runSimpleTests ( ) ; verifyResultStats ( existing , 7L ) ; } @ Test @ SimpleTest public final void testUnionAll15 ( ) throws Exception { Optional < TajoResultSetBase [ ] > existing = runSimpleTests ( ) ; verifyResultStats ( existing , 3L ) ; } @ Test @ SimpleTest public final void testUnionAll16 ( ) throws Exception { Optional < TajoResultSetBase [ ] > existing = runSimpleTests ( ) ; verifyResultStats ( existing , 3L ) ; } @ Test @ SimpleTest public final void testUnion1 ( ) throws Exception { Optional < TajoResultSetBase [ ] > existing = runSimpleTests ( ) ; verifyResultStats ( existing , 5L ) ; } @ Test @ SimpleTest public final void testUnion2 ( ) throws Exception { Optional < TajoResultSetBase [ ] > existing = runSimpleTests ( ) ; verifyResultStats ( existing , 3L ) ; } @ Test @ SimpleTest public final void testUnion3 ( ) throws Exception { Optional < TajoResultSetBase [ ] > existing = runSimpleTests ( ) ; verifyResultStats ( existing , 2L ) ; } @ Test @ SimpleTest public final void testUnion4 ( ) throws Exception { Optional < TajoResultSetBase [ ] > existing = runSimpleTests ( ) ; verifyResultStats ( existing , 1L ) ; } @ Test @ SimpleTest public final void testUnion5 ( ) throws Exception { Optional < TajoResultSetBase [ ] > existing = runSimpleTests ( ) ; verifyResultStats ( existing , 1L ) ; } @ Test @ SimpleTest public final void testUnion6 ( ) throws Exception { Optional < TajoResultSetBase [ ] > existing = runSimpleTests ( ) ; verifyResultStats ( existing , 1L ) ; } @ Test @ SimpleTest public final void testUnion7 ( ) throws Exception { Optional < TajoResultSetBase [ ] > existing = runSimpleTests ( ) ; verifyResultStats ( existing , 3L ) ; } @ Test @ SimpleTest public final void testUnion8 ( ) throws Exception { Optional < TajoResultSetBase [ ] > existing = runSimpleTests ( ) ; verifyResultStats ( existing , 1L ) ; } @ Test @ SimpleTest public final void testUnion9 ( ) throws Exception { Optional < TajoResultSetBase [ ] > existing = runSimpleTests ( ) ; verifyResultStats ( existing , 5L ) ; } @ Test @ SimpleTest public final void testUnion10 ( ) throws Exception { Optional < TajoResultSetBase [ ] > existing = runSimpleTests ( ) ; verifyResultStats ( existing , 5L ) ; } @ Test @ SimpleTest public final void testUnion11 ( ) throws Exception { Optional < TajoResultSetBase [ ] > existing = runSimpleTests ( ) ; verifyResultStats ( existing , 1L ) ; } @ Test @ SimpleTest public final void testUnion12 ( ) throws Exception { Optional < TajoResultSetBase [ ] > existing = runSimpleTests ( ) ; verifyResultStats ( existing , 5L ) ; } @ Test @ SimpleTest public final void testUnion13 ( ) throws Exception { Optional < TajoResultSetBase [ ] > existing = runSimpleTests ( ) ; verifyResultStats ( existing , 5L ) ; } @ Test @ SimpleTest public final void testUnion14 ( ) throws Exception { Optional < TajoResultSetBase [ ] > existing = runSimpleTests ( ) ; verifyResultStats ( existing , 7L ) ; } @ Test @ SimpleTest public final void testUnion15 ( ) throws Exception { Optional < TajoResultSetBase [ ] > existing = runSimpleTests ( ) ; verifyResultStats ( existing , 3L ) ; } @ Test @ SimpleTest public final void testUnion16 ( ) throws Exception { Optional < TajoResultSetBase [ ] > existing = runSimpleTests ( ) ; verifyResultStats ( existing , 3L ) ; } @ Test @ SimpleTest public final void testUnionAllWithSameAliasNames ( ) throws Exception { Optional < TajoResultSetBase [ ] > existing = runSimpleTests ( ) ; verifyResultStats ( existing , 10L ) ; } @ Test @ SimpleTest public final void testUnionAllWithDifferentAlias ( ) throws Exception { Optional < TajoResultSetBase [ ] > existing = runSimpleTests ( ) ; verifyResultStats ( existing , 2L ) ; } @ Test @ SimpleTest public final void testUnionAllWithDifferentAliasAndFunction ( ) throws Exception { Optional < TajoResultSetBase [ ] > existing = runSimpleTests ( ) ; verifyResultStats ( existing , 5L ) ; } @ Test @ SimpleTest public final void testUnionWithSameAliasNames ( ) throws Exception { Optional < TajoResultSetBase [ ] > existing = runSimpleTests ( ) ; verifyResultStats ( existing , 3L ) ; } @ Test @ SimpleTest public final void testUnionWithDifferentAlias ( ) throws Exception { Optional < TajoResultSetBase [ ] > existing = runSimpleTests ( ) ; verifyResultStats ( existing , 2L ) ; } @ Test @ SimpleTest public final void testUnionWithDifferentAliasAndFunction ( ) throws Exception { Optional < TajoResultSetBase [ ] > existing = runSimpleTests ( ) ; verifyResultStats ( existing , 5L ) ; } @ Test @ SimpleTest public final void testLeftUnionWithJoin ( ) throws Exception { Optional < TajoResultSetBase [ ] > existing = runSimpleTests ( ) ; verifyResultStats ( existing , 8L ) ; } @ Test @ SimpleTest public final void testRightUnionWithJoin ( ) throws Exception { Optional < TajoResultSetBase [ ] > existing = runSimpleTests ( ) ; verifyResultStats ( existing , 8L ) ; } @ Test @ SimpleTest public final void testAllUnionWithJoin ( ) throws Exception { Optional < TajoResultSetBase [ ] > existing = runSimpleTests ( ) ; verifyResultStats ( existing , 16L ) ; } @ Test @ SimpleTest public final void testUnionWithCrossJoin ( ) throws Exception { Optional < TajoResultSetBase [ ] > existing = runSimpleTests ( ) ; verifyResultStats ( existing , 40L ) ; } @ Test @ SimpleTest public final void testThreeJoinInUnion ( ) throws Exception { Optional < TajoResultSetBase [ ] > existing = runSimpleTests ( ) ; verifyResultStats ( existing , 30L ) ; } @ Test @ SimpleTest public void testUnionCaseOfFirstEmptyAndJoin ( ) throws Exception { Optional < TajoResultSetBase [ ] > existing = runSimpleTests ( ) ; verifyResultStats ( existing , 5L ) ; } @ Test @ SimpleTest public void testTajo1368Case1 ( ) throws Exception { Optional < TajoResultSetBase [ ] > existing = runSimpleTests ( ) ; verifyResultStats ( existing , 10L ) ; } @ Test @ SimpleTest public void testTajo1368Case2 ( ) throws Exception { Optional < TajoResultSetBase [ ] > existing = runSimpleTests ( ) ; verifyResultStats ( existing , 10L ) ; } @ Test @ Option ( withExplain = true , withExplainGlobal = true ) @ SimpleTest public void testComplexUnion1 ( ) throws Exception { Optional < TajoResultSetBase [ ] > existing = runSimpleTests ( ) ; verifyResultStats ( existing , 4L ) ; } @ Test @ Option ( withExplain = true , withExplainGlobal = true , sort = true ) @ SimpleTest public void testComplexUnion2 ( ) throws Exception { Optional < TajoResultSetBase [ ] > existing = runSimpleTests ( ) ; verifyResultStats ( existing , 5L ) ; } @ Test @ Option ( withExplain = true , sort = true ) @ SimpleTest public void testUnionAndFilter ( ) throws Exception { Optional < TajoResultSetBase [ ] > existing = runSimpleTests ( ) ; verifyResultStats ( existing , 5L ) ; } private void verifyResultStats ( Optional < TajoResultSetBase [ ] > existing , long numRows ) throws Exception { assertTrue ( existing . isPresent ( ) ) ; TajoResultSetBase [ ] resultSet = existing . get ( ) ; QueryId qid = resultSet [ 0 ] . getQueryId ( ) ; QueryInfo queryInfo = testingCluster . getMaster ( ) . getContext ( ) . getQueryJobManager ( ) . getFinishedQuery ( qid ) ; TableDesc desc = queryInfo . getResultDesc ( ) ; TableStats stats = desc . getStats ( ) ; assertEquals ( numRows , stats . getNumRows ( ) . longValue ( ) ) ; FileSystem fs = FileSystem . get ( conf ) ; Path path = new Path ( desc . getUri ( ) ) ; assertTrue ( fs . exists ( path ) ) ; ContentSummary summary = fs . getContentSummary ( path ) ; assertEquals ( summary . getLength ( ) , stats . getNumBytes ( ) . longValue ( ) ) ; closeResultSets ( resultSet ) ; } }",Smelly
"public class BaseAlgebraVisitor < CONTEXT , RESULT > implements AlgebraVisitor < CONTEXT , RESULT > { public void preHook ( CONTEXT ctx , Stack < Expr > stack , Expr expr ) throws TajoException { } public RESULT postHook ( CONTEXT ctx , Stack < Expr > stack , Expr expr , RESULT current ) throws TajoException { return current ; } public RESULT visit ( CONTEXT ctx , Stack < Expr > stack , Expr expr ) throws TajoException { preHook ( ctx , stack , expr ) ; RESULT current ; switch ( expr . getType ( ) ) { case SetSession : current = visitSetSession ( ctx , stack , ( SetSession ) expr ) ; break ; case Projection : current = visitProjection ( ctx , stack , ( Projection ) expr ) ; break ; case Limit : current = visitLimit ( ctx , stack , ( Limit ) expr ) ; break ; case Sort : current = visitSort ( ctx , stack , ( Sort ) expr ) ; break ; case Having : current = visitHaving ( ctx , stack , ( Having ) expr ) ; break ; case Aggregation : current = visitGroupBy ( ctx , stack , ( Aggregation ) expr ) ; break ; case Join : current = visitJoin ( ctx , stack , ( Join ) expr ) ; break ; case Filter : current = visitFilter ( ctx , stack , ( Selection ) expr ) ; break ; case Union : current = visitUnion ( ctx , stack , ( SetOperation ) expr ) ; break ; case Except : current = visitExcept ( ctx , stack , ( SetOperation ) expr ) ; break ; case Intersect : current = visitIntersect ( ctx , stack , ( SetOperation ) expr ) ; break ; case SimpleTableSubquery : current = visitSimpleTableSubquery ( ctx , stack , ( SimpleTableSubquery ) expr ) ; break ; case TablePrimaryTableSubQuery : current = visitTableSubQuery ( ctx , stack , ( TablePrimarySubQuery ) expr ) ; break ; case RelationList : current = visitRelationList ( ctx , stack , ( RelationList ) expr ) ; break ; case Relation : current = visitRelation ( ctx , stack , ( Relation ) expr ) ; break ; case ScalarSubQuery : current = visitScalarSubQuery ( ctx , stack , ( ScalarSubQuery ) expr ) ; break ; case Explain : current = visitExplain ( ctx , stack , ( Explain ) expr ) ; break ; case CreateDatabase : current = visitCreateDatabase ( ctx , stack , ( CreateDatabase ) expr ) ; break ; case DropDatabase : current = visitDropDatabase ( ctx , stack , ( DropDatabase ) expr ) ; break ; case CreateTable : current = visitCreateTable ( ctx , stack , ( CreateTable ) expr ) ; break ; case DropTable : current = visitDropTable ( ctx , stack , ( DropTable ) expr ) ; break ; case AlterTablespace : current = visitAlterTablespace ( ctx , stack , ( AlterTablespace ) expr ) ; break ; case AlterTable : current = visitAlterTable ( ctx , stack , ( AlterTable ) expr ) ; break ; case CreateIndex : current = visitCreateIndex ( ctx , stack , ( CreateIndex ) expr ) ; break ; case TruncateTable : current = visitTruncateTable ( ctx , stack , ( TruncateTable ) expr ) ; break ; case DropIndex : current = visitDropIndex ( ctx , stack , ( DropIndex ) expr ) ; break ; case Insert : current = visitInsert ( ctx , stack , ( Insert ) expr ) ; break ; case And : current = visitAnd ( ctx , stack , ( BinaryOperator ) expr ) ; break ; case Or : current = visitOr ( ctx , stack , ( BinaryOperator ) expr ) ; break ; case Not : current = visitNot ( ctx , stack , ( NotExpr ) expr ) ; break ; case Equals : current = visitEquals ( ctx , stack , ( BinaryOperator ) expr ) ; break ; case NotEquals : current = visitNotEquals ( ctx , stack , ( BinaryOperator ) expr ) ; break ; case LessThan : current = visitLessThan ( ctx , stack , ( BinaryOperator ) expr ) ; break ; case LessThanOrEquals : current = visitLessThanOrEquals ( ctx , stack , ( BinaryOperator ) expr ) ; break ; case GreaterThan : current = visitGreaterThan ( ctx , stack , ( BinaryOperator ) expr ) ; break ; case GreaterThanOrEquals : current = visitGreaterThanOrEquals ( ctx , stack , ( BinaryOperator ) expr ) ; break ; case Between : current = visitBetween ( ctx , stack , ( BetweenPredicate ) expr ) ; break ; case CaseWhen : current = visitCaseWhen ( ctx , stack , ( CaseWhenPredicate ) expr ) ; break ; case IsNullPredicate : current = visitIsNullPredicate ( ctx , stack , ( IsNullPredicate ) expr ) ; break ; case InPredicate : current = visitInPredicate ( ctx , stack , ( InPredicate ) expr ) ; break ; case ValueList : current = visitValueListExpr ( ctx , stack , ( ValueListExpr ) expr ) ; break ; case ExistsPredicate : current = visitExistsPredicate ( ctx , stack , ( ExistsPredicate ) expr ) ; break ; case LikePredicate : current = visitLikePredicate ( ctx , stack , ( PatternMatchPredicate ) expr ) ; break ; case SimilarToPredicate : current = visitSimilarToPredicate ( ctx , stack , ( PatternMatchPredicate ) expr ) ; break ; case Regexp : current = visitRegexpPredicate ( ctx , stack , ( PatternMatchPredicate ) expr ) ; break ; case Concatenate : current = visitConcatenate ( ctx , stack , ( BinaryOperator ) expr ) ; break ; case Plus : current = visitPlus ( ctx , stack , ( BinaryOperator ) expr ) ; break ; case Minus : current = visitMinus ( ctx , stack , ( BinaryOperator ) expr ) ; break ; case Multiply : current = visitMultiply ( ctx , stack , ( BinaryOperator ) expr ) ; break ; case Divide : current = visitDivide ( ctx , stack , ( BinaryOperator ) expr ) ; break ; case Modular : current = visitModular ( ctx , stack , ( BinaryOperator ) expr ) ; break ; case Sign : current = visitSign ( ctx , stack , ( SignedExpr ) expr ) ; break ; case Column : current = visitColumnReference ( ctx , stack , ( ColumnReferenceExpr ) expr ) ; break ; case Target : current = visitTargetExpr ( ctx , stack , ( NamedExpr ) expr ) ; break ; case Function : current = visitFunction ( ctx , stack , ( FunctionExpr ) expr ) ; break ; case Asterisk : current = visitQualifiedAsterisk ( ctx , stack , ( QualifiedAsteriskExpr ) expr ) ; break ; case CountRowsFunction : current = visitCountRowsFunction ( ctx , stack , ( CountRowsFunctionExpr ) expr ) ; break ; case GeneralSetFunction : current = visitGeneralSetFunction ( ctx , stack , ( GeneralSetFunctionExpr ) expr ) ; break ; case WindowFunction : current = visitWindowFunction ( ctx , stack , ( WindowFunctionExpr ) expr ) ; break ; case DataType : current = visitDataType ( ctx , stack , ( DataTypeExpr ) expr ) ; break ; case Cast : current = visitCastExpr ( ctx , stack , ( CastExpr ) expr ) ; break ; case Literal : current = visitLiteral ( ctx , stack , ( LiteralValue ) expr ) ; break ; case NullLiteral : current = visitNullLiteral ( ctx , stack , ( NullLiteral ) expr ) ; break ; case DateLiteral : current = visitDateLiteral ( ctx , stack , ( DateLiteral ) expr ) ; break ; case TimeLiteral : current = visitTimeLiteral ( ctx , stack , ( TimeLiteral ) expr ) ; break ; case TimestampLiteral : current = visitTimestampLiteral ( ctx , stack , ( TimestampLiteral ) expr ) ; break ; case IntervalLiteral : current = visitIntervalLiteral ( ctx , stack , ( IntervalLiteral ) expr ) ; break ; default : throw new TajoInternalError ( ""Cannot support this type algebra \"""" + expr . getType ( ) + ""\"""" ) ; } if ( expr . getType ( ) == OpType . RelationList ) { RelationList relationList = ( RelationList ) expr ; if ( relationList . size ( ) == 1 && relationList . getRelations ( ) [ 0 ] . getType ( ) == OpType . Relation ) { return current ; } } postHook ( ctx , stack , expr , current ) ; return current ; } private RESULT visitDefaultUnaryExpr ( CONTEXT ctx , Stack < Expr > stack , UnaryOperator expr ) throws TajoException { stack . push ( expr ) ; RESULT child = visit ( ctx , stack , expr . getChild ( ) ) ; stack . pop ( ) ; return child ; } private RESULT visitDefaultBinaryExpr ( CONTEXT ctx , Stack < Expr > stack , BinaryOperator expr ) throws TajoException { stack . push ( expr ) ; RESULT child = visit ( ctx , stack , expr . getLeft ( ) ) ; visit ( ctx , stack , expr . getRight ( ) ) ; stack . pop ( ) ; return child ; } @ Override public RESULT visitSetSession ( CONTEXT ctx , Stack < Expr > stack , SetSession expr ) throws TajoException { return null ; } @ Override public RESULT visitProjection ( CONTEXT ctx , Stack < Expr > stack , Projection expr ) throws TajoException { stack . push ( expr ) ; try { for ( NamedExpr target : expr . getNamedExprs ( ) ) { visit ( ctx , stack , target ) ; } if ( expr . hasChild ( ) ) { return visit ( ctx , stack , expr . getChild ( ) ) ; } } finally { stack . pop ( ) ; } return null ; } @ Override public RESULT visitLimit ( CONTEXT ctx , Stack < Expr > stack , Limit expr ) throws TajoException { stack . push ( expr ) ; visit ( ctx , stack , expr . getFetchFirstNum ( ) ) ; RESULT result = visit ( ctx , stack , expr . getChild ( ) ) ; stack . pop ( ) ; return result ; } @ Override public RESULT visitSort ( CONTEXT ctx , Stack < Expr > stack , Sort expr ) throws TajoException { stack . push ( expr ) ; for ( Sort . SortSpec sortSpec : expr . getSortSpecs ( ) ) { visit ( ctx , stack , sortSpec . getKey ( ) ) ; } RESULT result = visit ( ctx , stack , expr . getChild ( ) ) ; return result ; } @ Override public RESULT visitHaving ( CONTEXT ctx , Stack < Expr > stack , Having expr ) throws TajoException { stack . push ( expr ) ; visit ( ctx , stack , expr . getQual ( ) ) ; RESULT result = visit ( ctx , stack , expr . getChild ( ) ) ; stack . pop ( ) ; return result ; } @ Override public RESULT visitGroupBy ( CONTEXT ctx , Stack < Expr > stack , Aggregation expr ) throws TajoException { stack . push ( expr ) ; for ( org . apache . tajo . algebra . Aggregation . GroupElement groupElement : expr . getGroupSet ( ) ) { for ( Expr groupingSet : groupElement . getGroupingSets ( ) ) { visit ( ctx , stack , groupingSet ) ; } } RESULT result = visit ( ctx , stack , expr . getChild ( ) ) ; stack . pop ( ) ; return result ; } @ Override public RESULT visitJoin ( CONTEXT ctx , Stack < Expr > stack , Join expr ) throws TajoException { stack . push ( expr ) ; if ( expr . getQual ( ) != null ) { visit ( ctx , stack , expr . getQual ( ) ) ; } visit ( ctx , stack , expr . getLeft ( ) ) ; RESULT result = visit ( ctx , stack , expr . getRight ( ) ) ; stack . pop ( ) ; return result ; } @ Override public RESULT visitFilter ( CONTEXT ctx , Stack < Expr > stack , Selection expr ) throws TajoException { stack . push ( expr ) ; visit ( ctx , stack , expr . getQual ( ) ) ; RESULT result = visit ( ctx , stack , expr . getChild ( ) ) ; stack . pop ( ) ; return result ; } @ Override public RESULT visitUnion ( CONTEXT ctx , Stack < Expr > stack , SetOperation expr ) throws TajoException { return visitDefaultBinaryExpr ( ctx , stack , expr ) ; } @ Override public RESULT visitExcept ( CONTEXT ctx , Stack < Expr > stack , SetOperation expr ) throws TajoException { return visitDefaultBinaryExpr ( ctx , stack , expr ) ; } @ Override public RESULT visitIntersect ( CONTEXT ctx , Stack < Expr > stack , SetOperation expr ) throws TajoException { return visitDefaultBinaryExpr ( ctx , stack , expr ) ; } @ Override public RESULT visitSimpleTableSubquery ( CONTEXT ctx , Stack < Expr > stack , SimpleTableSubquery expr ) throws TajoException { stack . push ( expr ) ; RESULT child = visit ( ctx , stack , expr . getSubQuery ( ) ) ; stack . pop ( ) ; return child ; } @ Override public RESULT visitTableSubQuery ( CONTEXT ctx , Stack < Expr > stack , TablePrimarySubQuery expr ) throws TajoException { stack . push ( expr ) ; RESULT child = visit ( ctx , stack , expr . getSubQuery ( ) ) ; stack . pop ( ) ; return child ; } @ Override public RESULT visitRelationList ( CONTEXT ctx , Stack < Expr > stack , RelationList expr ) throws TajoException { stack . push ( expr ) ; RESULT child = null ; for ( Expr e : expr . getRelations ( ) ) { child = visit ( ctx , stack , e ) ; } stack . pop ( ) ; return child ; } @ Override public RESULT visitRelation ( CONTEXT ctx , Stack < Expr > stack , Relation expr ) throws TajoException { return null ; } @ Override public RESULT visitScalarSubQuery ( CONTEXT ctx , Stack < Expr > stack , ScalarSubQuery expr ) throws TajoException { return visitDefaultUnaryExpr ( ctx , stack , expr ) ; } @ Override public RESULT visitExplain ( CONTEXT ctx , Stack < Expr > stack , Explain expr ) throws TajoException { stack . push ( expr ) ; RESULT child = visit ( ctx , stack , expr . getChild ( ) ) ; stack . pop ( ) ; return child ; } @ Override public RESULT visitCreateDatabase ( CONTEXT ctx , Stack < Expr > stack , CreateDatabase expr ) throws TajoException { return null ; } @ Override public RESULT visitDropDatabase ( CONTEXT ctx , Stack < Expr > stack , DropDatabase expr ) throws TajoException { return null ; } @ Override public RESULT visitCreateTable ( CONTEXT ctx , Stack < Expr > stack , CreateTable expr ) throws TajoException { stack . push ( expr ) ; RESULT child = null ; if ( expr . hasSubQuery ( ) ) { child = visit ( ctx , stack , expr . getSubQuery ( ) ) ; } stack . pop ( ) ; return child ; } @ Override public RESULT visitDropTable ( CONTEXT ctx , Stack < Expr > stack , DropTable expr ) throws TajoException { return null ; } @ Override public RESULT visitAlterTablespace ( CONTEXT ctx , Stack < Expr > stack , AlterTablespace expr ) throws TajoException { return null ; } @ Override public RESULT visitAlterTable ( CONTEXT ctx , Stack < Expr > stack , AlterTable expr ) throws TajoException { return null ; } @ Override public RESULT visitCreateIndex ( CONTEXT ctx , Stack < Expr > stack , CreateIndex expr ) throws TajoException { return null ; } @ Override public RESULT visitDropIndex ( CONTEXT ctx , Stack < Expr > stack , DropIndex expr ) { return null ; } @ Override public RESULT visitTruncateTable ( CONTEXT ctx , Stack < Expr > stack , TruncateTable expr ) throws TajoException { return null ; } @ Override public RESULT visitInsert ( CONTEXT ctx , Stack < Expr > stack , Insert expr ) throws TajoException { stack . push ( expr ) ; RESULT child = visit ( ctx , stack , expr . getSubQuery ( ) ) ; stack . pop ( ) ; return child ; } @ Override public RESULT visitAnd ( CONTEXT ctx , Stack < Expr > stack , BinaryOperator expr ) throws TajoException { return visitDefaultBinaryExpr ( ctx , stack , expr ) ; } @ Override public RESULT visitOr ( CONTEXT ctx , Stack < Expr > stack , BinaryOperator expr ) throws TajoException { return visitDefaultBinaryExpr ( ctx , stack , expr ) ; } @ Override public RESULT visitNot ( CONTEXT ctx , Stack < Expr > stack , NotExpr expr ) throws TajoException { return visitDefaultUnaryExpr ( ctx , stack , expr ) ; } @ Override public RESULT visitEquals ( CONTEXT ctx , Stack < Expr > stack , BinaryOperator expr ) throws TajoException { return visitDefaultBinaryExpr ( ctx , stack , expr ) ; } @ Override public RESULT visitNotEquals ( CONTEXT ctx , Stack < Expr > stack , BinaryOperator expr ) throws TajoException { return visitDefaultBinaryExpr ( ctx , stack , expr ) ; } @ Override public RESULT visitLessThan ( CONTEXT ctx , Stack < Expr > stack , BinaryOperator expr ) throws TajoException { return visitDefaultBinaryExpr ( ctx , stack , expr ) ; } @ Override public RESULT visitLessThanOrEquals ( CONTEXT ctx , Stack < Expr > stack , BinaryOperator expr ) throws TajoException { return visitDefaultBinaryExpr ( ctx , stack , expr ) ; } @ Override public RESULT visitGreaterThan ( CONTEXT ctx , Stack < Expr > stack , BinaryOperator expr ) throws TajoException { return visitDefaultBinaryExpr ( ctx , stack , expr ) ; } @ Override public RESULT visitGreaterThanOrEquals ( CONTEXT ctx , Stack < Expr > stack , BinaryOperator expr ) throws TajoException { return visitDefaultBinaryExpr ( ctx , stack , expr ) ; } @ Override public RESULT visitBetween ( CONTEXT ctx , Stack < Expr > stack , BetweenPredicate expr ) throws TajoException { stack . push ( expr ) ; RESULT result = visit ( ctx , stack , expr . predicand ( ) ) ; visit ( ctx , stack , expr . begin ( ) ) ; visit ( ctx , stack , expr . end ( ) ) ; stack . pop ( ) ; return result ; } @ Override public RESULT visitCaseWhen ( CONTEXT ctx , Stack < Expr > stack , CaseWhenPredicate expr ) throws TajoException { stack . push ( expr ) ; RESULT result = null ; for ( CaseWhenPredicate . WhenExpr when : expr . getWhens ( ) ) { result = visit ( ctx , stack , when . getCondition ( ) ) ; visit ( ctx , stack , when . getResult ( ) ) ; } if ( expr . hasElseResult ( ) ) { visit ( ctx , stack , expr . getElseResult ( ) ) ; } stack . pop ( ) ; return result ; } @ Override public RESULT visitIsNullPredicate ( CONTEXT ctx , Stack < Expr > stack , IsNullPredicate expr ) throws TajoException { return visitDefaultUnaryExpr ( ctx , stack , expr ) ; } @ Override public RESULT visitInPredicate ( CONTEXT ctx , Stack < Expr > stack , InPredicate expr ) throws TajoException { return visitDefaultBinaryExpr ( ctx , stack , expr ) ; } @ Override public RESULT visitValueListExpr ( CONTEXT ctx , Stack < Expr > stack , ValueListExpr expr ) throws TajoException { stack . push ( expr ) ; RESULT result = null ; for ( Expr value : expr . getValues ( ) ) { result = visit ( ctx , stack , value ) ; } stack . pop ( ) ; return result ; } @ Override public RESULT visitExistsPredicate ( CONTEXT ctx , Stack < Expr > stack , ExistsPredicate expr ) throws TajoException { return visitDefaultUnaryExpr ( ctx , stack , expr ) ; } @ Override public RESULT visitLikePredicate ( CONTEXT ctx , Stack < Expr > stack , PatternMatchPredicate expr ) throws TajoException { return visitDefaultBinaryExpr ( ctx , stack , expr ) ; } @ Override public RESULT visitSimilarToPredicate ( CONTEXT ctx , Stack < Expr > stack , PatternMatchPredicate expr ) throws TajoException { return visitDefaultBinaryExpr ( ctx , stack , expr ) ; } @ Override public RESULT visitRegexpPredicate ( CONTEXT ctx , Stack < Expr > stack , PatternMatchPredicate expr ) throws TajoException { return visitDefaultBinaryExpr ( ctx , stack , expr ) ; } @ Override public RESULT visitConcatenate ( CONTEXT ctx , Stack < Expr > stack , BinaryOperator expr ) throws TajoException { return visitDefaultBinaryExpr ( ctx , stack , expr ) ; } @ Override public RESULT visitPlus ( CONTEXT ctx , Stack < Expr > stack , BinaryOperator expr ) throws TajoException { return visitDefaultBinaryExpr ( ctx , stack , expr ) ; } @ Override public RESULT visitMinus ( CONTEXT ctx , Stack < Expr > stack , BinaryOperator expr ) throws TajoException { return visitDefaultBinaryExpr ( ctx , stack , expr ) ; } @ Override public RESULT visitMultiply ( CONTEXT ctx , Stack < Expr > stack , BinaryOperator expr ) throws TajoException { return visitDefaultBinaryExpr ( ctx , stack , expr ) ; } @ Override public RESULT visitDivide ( CONTEXT ctx , Stack < Expr > stack , BinaryOperator expr ) throws TajoException { return visitDefaultBinaryExpr ( ctx , stack , expr ) ; } @ Override public RESULT visitModular ( CONTEXT ctx , Stack < Expr > stack , BinaryOperator expr ) throws TajoException { return visitDefaultBinaryExpr ( ctx , stack , expr ) ; } @ Override public RESULT visitSign ( CONTEXT ctx , Stack < Expr > stack , SignedExpr expr ) throws TajoException { return visitDefaultUnaryExpr ( ctx , stack , expr ) ; } @ Override public RESULT visitColumnReference ( CONTEXT ctx , Stack < Expr > stack , ColumnReferenceExpr expr ) throws TajoException { return null ; } @ Override public RESULT visitTargetExpr ( CONTEXT ctx , Stack < Expr > stack , NamedExpr expr ) throws TajoException { return visitDefaultUnaryExpr ( ctx , stack , expr ) ; } @ Override public RESULT visitFunction ( CONTEXT ctx , Stack < Expr > stack , FunctionExpr expr ) throws TajoException { stack . push ( expr ) ; RESULT result = null ; if ( expr . hasParams ( ) ) { for ( Expr param : expr . getParams ( ) ) { result = visit ( ctx , stack , param ) ; } } stack . pop ( ) ; return result ; } @ Override public RESULT visitQualifiedAsterisk ( CONTEXT ctx , Stack < Expr > stack , QualifiedAsteriskExpr expr ) throws TajoException { return null ; } @ Override public RESULT visitCountRowsFunction ( CONTEXT ctx , Stack < Expr > stack , CountRowsFunctionExpr expr ) throws TajoException { return null ; } @ Override public RESULT visitGeneralSetFunction ( CONTEXT ctx , Stack < Expr > stack , GeneralSetFunctionExpr expr ) throws TajoException { stack . push ( expr ) ; RESULT result = null ; for ( Expr param : expr . getParams ( ) ) { result = visit ( ctx , stack , param ) ; } stack . pop ( ) ; return result ; } @ Override public RESULT visitWindowFunction ( CONTEXT ctx , Stack < Expr > stack , WindowFunctionExpr expr ) throws TajoException { stack . push ( expr ) ; RESULT result = null ; for ( Expr param : expr . getParams ( ) ) { result = visit ( ctx , stack , param ) ; } WindowSpec windowSpec = expr . getWindowSpec ( ) ; if ( windowSpec . hasPartitionBy ( ) ) { for ( Expr partitionKey : windowSpec . getPartitionKeys ( ) ) { visit ( ctx , stack , partitionKey ) ; } } if ( windowSpec . hasOrderBy ( ) ) { for ( Sort . SortSpec sortKey : windowSpec . getSortSpecs ( ) ) { visit ( ctx , stack , sortKey . getKey ( ) ) ; } } if ( windowSpec . hasWindowFrame ( ) ) { if ( windowSpec . getWindowFrame ( ) . getStartBound ( ) . hasNumber ( ) ) { visit ( ctx , stack , windowSpec . getWindowFrame ( ) . getStartBound ( ) . getNumber ( ) ) ; } if ( windowSpec . getWindowFrame ( ) . getEndBound ( ) . hasNumber ( ) ) { visit ( ctx , stack , windowSpec . getWindowFrame ( ) . getEndBound ( ) . getNumber ( ) ) ; } } stack . pop ( ) ; return result ; } @ Override public RESULT visitDataType ( CONTEXT ctx , Stack < Expr > stack , DataTypeExpr expr ) throws TajoException { return null ; } @ Override public RESULT visitCastExpr ( CONTEXT ctx , Stack < Expr > stack , CastExpr expr ) throws TajoException { stack . push ( expr ) ; RESULT result = visit ( ctx , stack , expr . getOperand ( ) ) ; stack . pop ( ) ; return result ; } @ Override public RESULT visitLiteral ( CONTEXT ctx , Stack < Expr > stack , LiteralValue expr ) throws TajoException { return null ; } @ Override public RESULT visitNullLiteral ( CONTEXT ctx , Stack < Expr > stack , NullLiteral expr ) throws TajoException { return null ; } @ Override public RESULT visitTimestampLiteral ( CONTEXT ctx , Stack < Expr > stack , TimestampLiteral expr ) throws TajoException { return null ; } @ Override public RESULT visitIntervalLiteral ( CONTEXT ctx , Stack < Expr > stack , IntervalLiteral expr ) throws TajoException { return null ; } @ Override public RESULT visitTimeLiteral ( CONTEXT ctx , Stack < Expr > stack , TimeLiteral expr ) throws TajoException { return null ; } @ Override public RESULT visitDateLiteral ( CONTEXT ctx , Stack < Expr > stack , DateLiteral expr ) throws TajoException { return null ; } }",Smelly
"public class MailBinding { private HeaderFilterStrategy headerFilterStrategy ; public MailBinding ( ) { headerFilterStrategy = new DefaultHeaderFilterStrategy ( ) ; } public MailBinding ( HeaderFilterStrategy headerFilterStrategy ) { this . headerFilterStrategy = headerFilterStrategy ; } public void populateMailMessage ( MailEndpoint endpoint , MimeMessage mimeMessage , Exchange exchange ) throws MessagingException , IOException { if ( hasRecipientHeaders ( exchange . getIn ( ) ) ) { setRecipientFromCamelMessage ( mimeMessage , exchange , exchange . getIn ( ) ) ; } else { setRecipientFromEndpointConfiguration ( mimeMessage , endpoint ) ; } if ( mimeMessage . getAllRecipients ( ) == null ) { throw new IllegalArgumentException ( ""The mail message does not have any recipients set."" ) ; } appendHeadersFromCamelMessage ( mimeMessage , exchange , exchange . getIn ( ) ) ; if ( empty ( mimeMessage . getFrom ( ) ) ) { String from = endpoint . getConfiguration ( ) . getFrom ( ) ; mimeMessage . setFrom ( new InternetAddress ( from ) ) ; } if ( exchange . getIn ( ) . hasAttachments ( ) ) { appendAttachmentsFromCamel ( mimeMessage , exchange . getIn ( ) , endpoint . getConfiguration ( ) ) ; } else { if ( ""text/html"" . equals ( endpoint . getConfiguration ( ) . getContentType ( ) ) ) { DataSource ds = new ByteArrayDataSource ( exchange . getIn ( ) . getBody ( String . class ) , ""text/html"" ) ; mimeMessage . setDataHandler ( new DataHandler ( ds ) ) ; } else { mimeMessage . setText ( exchange . getIn ( ) . getBody ( String . class ) ) ; } } } public Object extractBodyFromMail ( MailExchange exchange , Message message ) { try { return message . getContent ( ) ; } catch ( Exception e ) { throw new RuntimeCamelException ( ""Failed to extract body due to: "" + e . getMessage ( ) + "". Exchange: "" + exchange + "". Message: "" + message , e ) ; } } protected void appendHeadersFromCamelMessage ( MimeMessage mimeMessage , Exchange exchange , org . apache . camel . Message camelMessage ) throws MessagingException { for ( Map . Entry < String , Object > entry : camelMessage . getHeaders ( ) . entrySet ( ) ) { String headerName = entry . getKey ( ) ; Object headerValue = entry . getValue ( ) ; if ( headerValue != null ) { if ( headerFilterStrategy != null && ! headerFilterStrategy . applyFilterToCamelHeaders ( headerName , headerValue ) ) { if ( isRecipientHeader ( headerName ) ) { continue ; } if ( ObjectConverter . isCollection ( headerValue ) ) { Iterator iter = ObjectConverter . iterator ( headerValue ) ; while ( iter . hasNext ( ) ) { Object value = iter . next ( ) ; mimeMessage . addHeader ( headerName , asString ( exchange , value ) ) ; } } else { mimeMessage . setHeader ( headerName , asString ( exchange , headerValue ) ) ; } } } } } private void setRecipientFromCamelMessage ( MimeMessage mimeMessage , Exchange exchange , org . apache . camel . Message camelMessage ) throws MessagingException { for ( Map . Entry < String , Object > entry : camelMessage . getHeaders ( ) . entrySet ( ) ) { String headerName = entry . getKey ( ) ; Object headerValue = entry . getValue ( ) ; if ( headerValue != null && isRecipientHeader ( headerName ) ) { if ( ObjectConverter . isCollection ( headerValue ) ) { Iterator iter = ObjectConverter . iterator ( headerValue ) ; while ( iter . hasNext ( ) ) { Object recipient = iter . next ( ) ; appendRecipientToMimeMessage ( mimeMessage , headerName , asString ( exchange , recipient ) ) ; } } else { appendRecipientToMimeMessage ( mimeMessage , headerName , asString ( exchange , headerValue ) ) ; } } } } protected void setRecipientFromEndpointConfiguration ( MimeMessage mimeMessage , MailEndpoint endpoint ) throws MessagingException { Map < Message . RecipientType , String > recipients = endpoint . getConfiguration ( ) . getRecipients ( ) ; if ( recipients . containsKey ( Message . RecipientType . TO ) ) { appendRecipientToMimeMessage ( mimeMessage , Message . RecipientType . TO . toString ( ) , recipients . get ( Message . RecipientType . TO ) ) ; } if ( recipients . containsKey ( Message . RecipientType . CC ) ) { appendRecipientToMimeMessage ( mimeMessage , Message . RecipientType . CC . toString ( ) , recipients . get ( Message . RecipientType . CC ) ) ; } if ( recipients . containsKey ( Message . RecipientType . BCC ) ) { appendRecipientToMimeMessage ( mimeMessage , Message . RecipientType . BCC . toString ( ) , recipients . get ( Message . RecipientType . BCC ) ) ; } String destination = endpoint . getConfiguration ( ) . getDestination ( ) ; if ( destination != null && mimeMessage . getRecipients ( Message . RecipientType . TO ) == null ) { appendRecipientToMimeMessage ( mimeMessage , Message . RecipientType . TO . toString ( ) , destination ) ; } } protected void appendAttachmentsFromCamel ( MimeMessage mimeMessage , org . apache . camel . Message camelMessage , MailConfiguration configuration ) throws MessagingException { MimeMultipart multipart = new MimeMultipart ( ) ; multipart . setSubType ( ""mixed"" ) ; MimeBodyPart textBodyPart = new MimeBodyPart ( ) ; textBodyPart . setContent ( camelMessage . getBody ( String . class ) , configuration . getContentType ( ) ) ; multipart . addBodyPart ( textBodyPart ) ; for ( Map . Entry < String , DataHandler > entry : camelMessage . getAttachments ( ) . entrySet ( ) ) { String attachmentFilename = entry . getKey ( ) ; DataHandler handler = entry . getValue ( ) ; if ( handler != null ) { if ( shouldOutputAttachment ( camelMessage , attachmentFilename , handler ) ) { BodyPart messageBodyPart = new MimeBodyPart ( ) ; messageBodyPart . setDataHandler ( handler ) ; messageBodyPart . setFileName ( attachmentFilename ) ; messageBodyPart . setDisposition ( Part . ATTACHMENT ) ; multipart . addBodyPart ( messageBodyPart ) ; } } } mimeMessage . setContent ( multipart ) ; } protected boolean shouldOutputAttachment ( org . apache . camel . Message camelMessage , String attachmentFilename , DataHandler handler ) { return true ; } protected Map < String , Object > extractHeadersFromMail ( Message mailMessage ) throws MessagingException { Map < String , Object > answer = new HashMap < String , Object > ( ) ; Enumeration names = mailMessage . getAllHeaders ( ) ; while ( names . hasMoreElements ( ) ) { Header header = ( Header ) names . nextElement ( ) ; String [ ] value = mailMessage . getHeader ( header . getName ( ) ) ; if ( headerFilterStrategy != null && ! headerFilterStrategy . applyFilterToExternalHeaders ( header . getName ( ) , value ) ) { if ( value . length == 1 ) { CollectionHelper . appendValue ( answer , header . getName ( ) . toLowerCase ( ) , value [ 0 ] ) ; } else { CollectionHelper . appendValue ( answer , header . getName ( ) . toLowerCase ( ) , value ) ; } } } return answer ; } private static void appendRecipientToMimeMessage ( MimeMessage mimeMessage , String type , String recipient ) throws MessagingException { String [ ] lines = recipient . split ( ""[,|;]"" ) ; for ( String line : lines ) { line = line . trim ( ) ; mimeMessage . addRecipients ( asRecipientType ( type ) , line ) ; } } private static boolean hasRecipientHeaders ( org . apache . camel . Message camelMessage ) { for ( String key : camelMessage . getHeaders ( ) . keySet ( ) ) { if ( isRecipientHeader ( key ) ) { return true ; } } return false ; } private static boolean isRecipientHeader ( String key ) { if ( Message . RecipientType . TO . toString ( ) . equalsIgnoreCase ( key ) ) { return true ; } else if ( Message . RecipientType . CC . toString ( ) . equalsIgnoreCase ( key ) ) { return true ; } else if ( Message . RecipientType . BCC . toString ( ) . equalsIgnoreCase ( key ) ) { return true ; } return false ; } private static Message . RecipientType asRecipientType ( String type ) { if ( Message . RecipientType . TO . toString ( ) . equalsIgnoreCase ( type ) ) { return Message . RecipientType . TO ; } else if ( Message . RecipientType . CC . toString ( ) . equalsIgnoreCase ( type ) ) { return Message . RecipientType . CC ; } else if ( Message . RecipientType . BCC . toString ( ) . equalsIgnoreCase ( type ) ) { return Message . RecipientType . BCC ; } throw new IllegalArgumentException ( ""Unknown recipient type: "" + type ) ; } private static boolean empty ( Address [ ] addresses ) { return addresses == null || addresses . length == 0 ; } private static String asString ( Exchange exchange , Object value ) { return exchange . getContext ( ) . getTypeConverter ( ) . convertTo ( String . class , exchange , value ) ; } }",Smelly
"@ Transactional ( ""Master"" ) public class GroupTest extends AbstractTest { @ Autowired private AnyTypeDAO anyTypeDAO ; @ Autowired private AnyObjectDAO anyObjectDAO ; @ Autowired private UserDAO userDAO ; @ Autowired private GroupDAO groupDAO ; @ Autowired private RealmDAO realmDAO ; @ Autowired private PlainSchemaDAO plainSchemaDAO ; @ Autowired private PlainAttrDAO plainAttrDAO ; @ Autowired private PlainAttrValueDAO plainAttrValueDAO ; @ Autowired private AnyTypeClassDAO anyTypeClassDAO ; @ Test ( expected = InvalidEntityException . class ) public void saveWithTwoOwners ( ) { Group root = groupDAO . findByName ( ""root"" ) ; assertNotNull ( ""did not find expected group"" , root ) ; User user = userDAO . findByUsername ( ""rossini"" ) ; assertNotNull ( ""did not find expected user"" , user ) ; Group group = entityFactory . newEntity ( Group . class ) ; group . setRealm ( realmDAO . getRoot ( ) ) ; group . setName ( ""error"" ) ; group . setUserOwner ( user ) ; group . setGroupOwner ( root ) ; groupDAO . save ( group ) ; } @ Test public void findByOwner ( ) { Group group = groupDAO . find ( ""ebf97068-aa4b-4a85-9f01-680e8c4cf227"" ) ; assertNotNull ( ""did not find expected group"" , group ) ; User user = userDAO . find ( ""823074dc-d280-436d-a7dd-07399fae48ec"" ) ; assertNotNull ( ""did not find expected user"" , user ) ; assertEquals ( user , group . getUserOwner ( ) ) ; List < Group > ownedGroups = groupDAO . findOwnedByUser ( user . getKey ( ) ) ; assertFalse ( ownedGroups . isEmpty ( ) ) ; assertEquals ( 1 , ownedGroups . size ( ) ) ; assertTrue ( ownedGroups . contains ( group ) ) ; } @ Test public void create ( ) { Group group = entityFactory . newEntity ( Group . class ) ; group . setRealm ( realmDAO . getRoot ( ) ) ; group . setName ( ""new"" ) ; TypeExtension typeExt = entityFactory . newEntity ( TypeExtension . class ) ; typeExt . setAnyType ( anyTypeDAO . findUser ( ) ) ; typeExt . add ( anyTypeClassDAO . find ( ""csv"" ) ) ; typeExt . add ( anyTypeClassDAO . find ( ""other"" ) ) ; group . add ( typeExt ) ; typeExt . setGroup ( group ) ; groupDAO . save ( group ) ; groupDAO . flush ( ) ; group = groupDAO . findByName ( ""new"" ) ; assertNotNull ( group ) ; assertEquals ( 1 , group . getTypeExtensions ( ) . size ( ) ) ; assertEquals ( 2 , group . getTypeExtension ( anyTypeDAO . findUser ( ) ) . getAuxClasses ( ) . size ( ) ) ; } @ Test public void createWithInternationalCharacters ( ) { Group group = entityFactory . newEntity ( Group . class ) ; group . setName ( ""räksmörgås"" ) ; group . setRealm ( realmDAO . findByFullPath ( SyncopeConstants . ROOT_REALM ) ) ; groupDAO . save ( group ) ; groupDAO . flush ( ) ; } @ Test public void delete ( ) { groupDAO . delete ( ""b1f7c12d-ec83-441f-a50e-1691daaedf3b"" ) ; groupDAO . flush ( ) ; assertNull ( groupDAO . find ( ""b1f7c12d-ec83-441f-a50e-1691daaedf3b"" ) ) ; assertEquals ( userDAO . findAllGroups ( userDAO . findByUsername ( ""verdi"" ) ) . size ( ) , 2 ) ; assertNull ( plainAttrDAO . find ( ""f82fc61f-8e74-4a4b-9f9e-b8a41f38aad9"" , GPlainAttr . class ) ) ; assertNull ( plainAttrValueDAO . find ( ""49f35879-2510-4f11-a901-24152f753538"" , GPlainAttrValue . class ) ) ; assertNotNull ( plainSchemaDAO . find ( ""icon"" ) ) ; } private List < Group > findDynGroups ( final User user ) { Query query = entityManager ( ) . createNativeQuery ( ""SELECT group_id FROM "" + JPAGroupDAO . UDYNMEMB_TABLE + "" WHERE any_id=?"" ) ; query . setParameter ( 1 , user . getKey ( ) ) ; List < Group > result = new ArrayList < > ( ) ; for ( Object key : query . getResultList ( ) ) { String actualKey = key instanceof Object [ ] ? ( String ) ( ( Object [ ] ) key ) [ 0 ] : ( ( String ) key ) ; Group group = groupDAO . find ( actualKey ) ; if ( group != null && ! result . contains ( group ) ) { result . add ( group ) ; } } return result ; } @ Test public void udynMembership ( ) { User user = entityFactory . newEntity ( User . class ) ; user . setUsername ( ""username"" ) ; user . setRealm ( realmDAO . findByFullPath ( ""/even/two"" ) ) ; user . add ( anyTypeClassDAO . find ( ""other"" ) ) ; UPlainAttr attr = entityFactory . newEntity ( UPlainAttr . class ) ; attr . setOwner ( user ) ; attr . setSchema ( plainSchemaDAO . find ( ""cool"" ) ) ; attr . add ( ""true"" , anyUtilsFactory . getInstance ( AnyTypeKind . USER ) ) ; user . add ( attr ) ; user = userDAO . save ( user ) ; String newUserKey = user . getKey ( ) ; assertNotNull ( newUserKey ) ; Group group = entityFactory . newEntity ( Group . class ) ; group . setRealm ( realmDAO . getRoot ( ) ) ; group . setName ( ""new"" ) ; UDynGroupMembership dynMembership = entityFactory . newEntity ( UDynGroupMembership . class ) ; dynMembership . setFIQLCond ( ""cool==true"" ) ; dynMembership . setGroup ( group ) ; group . setUDynMembership ( dynMembership ) ; Group actual = groupDAO . save ( group ) ; assertNotNull ( actual ) ; groupDAO . flush ( ) ; actual = groupDAO . find ( actual . getKey ( ) ) ; assertNotNull ( actual ) ; assertNotNull ( actual . getUDynMembership ( ) ) ; assertNotNull ( actual . getUDynMembership ( ) . getKey ( ) ) ; assertEquals ( actual , actual . getUDynMembership ( ) . getGroup ( ) ) ; List < String > members = groupDAO . findUDynMembers ( actual ) ; assertEquals ( 2 , members . size ( ) ) ; assertEquals ( new HashSet < > ( Arrays . asList ( ""c9b2dec2-00a7-4855-97c0-d854842b4b24"" , newUserKey ) ) , new HashSet < > ( members ) ) ; user = userDAO . findByUsername ( ""bellini"" ) ; assertNotNull ( user ) ; Collection < Group > dynGroupMemberships = findDynGroups ( user ) ; assertEquals ( 1 , dynGroupMemberships . size ( ) ) ; assertTrue ( dynGroupMemberships . contains ( actual . getUDynMembership ( ) . getGroup ( ) ) ) ; userDAO . delete ( newUserKey ) ; userDAO . flush ( ) ; actual = groupDAO . find ( actual . getKey ( ) ) ; members = groupDAO . findUDynMembers ( actual ) ; assertEquals ( 1 , members . size ( ) ) ; assertEquals ( ""c9b2dec2-00a7-4855-97c0-d854842b4b24"" , members . get ( 0 ) ) ; String dynMembershipKey = actual . getUDynMembership ( ) . getKey ( ) ; groupDAO . delete ( actual ) ; groupDAO . flush ( ) ; assertNull ( entityManager ( ) . find ( JPAUDynGroupMembership . class , dynMembershipKey ) ) ; dynGroupMemberships = findDynGroups ( user ) ; assertTrue ( dynGroupMemberships . isEmpty ( ) ) ; } private List < Group > findDynGroups ( final AnyObject anyObject ) { Query query = entityManager ( ) . createNativeQuery ( ""SELECT group_id FROM "" + JPAGroupDAO . ADYNMEMB_TABLE + "" WHERE any_id=?"" ) ; query . setParameter ( 1 , anyObject . getKey ( ) ) ; List < Group > result = new ArrayList < > ( ) ; for ( Object key : query . getResultList ( ) ) { String actualKey = key instanceof Object [ ] ? ( String ) ( ( Object [ ] ) key ) [ 0 ] : ( ( String ) key ) ; Group group = groupDAO . find ( actualKey ) ; if ( group != null && ! result . contains ( group ) ) { result . add ( group ) ; } } return result ; } @ Test public void adynMembership ( ) { AnyObject anyObject = entityFactory . newEntity ( AnyObject . class ) ; anyObject . setName ( ""name"" ) ; anyObject . setType ( anyTypeDAO . find ( ""PRINTER"" ) ) ; anyObject . setRealm ( realmDAO . findByFullPath ( ""/even/two"" ) ) ; APlainAttr attr = entityFactory . newEntity ( APlainAttr . class ) ; attr . setOwner ( anyObject ) ; attr . setSchema ( plainSchemaDAO . find ( ""model"" ) ) ; attr . add ( ""Canon MFC8030"" , anyUtilsFactory . getInstance ( AnyTypeKind . ANY_OBJECT ) ) ; anyObject . add ( attr ) ; anyObject = anyObjectDAO . save ( anyObject ) ; String newAnyObjectKey = anyObject . getKey ( ) ; assertNotNull ( newAnyObjectKey ) ; Group group = entityFactory . newEntity ( Group . class ) ; group . setRealm ( realmDAO . getRoot ( ) ) ; group . setName ( ""new"" ) ; ADynGroupMembership dynMembership = entityFactory . newEntity ( ADynGroupMembership . class ) ; dynMembership . setAnyType ( anyTypeDAO . find ( ""PRINTER"" ) ) ; dynMembership . setFIQLCond ( ""model==Canon MFC8030"" ) ; dynMembership . setGroup ( group ) ; group . add ( dynMembership ) ; Group actual = groupDAO . save ( group ) ; assertNotNull ( actual ) ; groupDAO . flush ( ) ; actual = groupDAO . find ( actual . getKey ( ) ) ; assertNotNull ( actual ) ; assertNotNull ( actual . getADynMembership ( anyTypeDAO . find ( ""PRINTER"" ) ) ) ; assertNotNull ( actual . getADynMembership ( anyTypeDAO . find ( ""PRINTER"" ) ) . getKey ( ) ) ; assertEquals ( actual , actual . getADynMembership ( anyTypeDAO . find ( ""PRINTER"" ) ) . getGroup ( ) ) ; List < String > members = CollectionUtils . select ( groupDAO . findADynMembers ( actual ) , new Predicate < String > ( ) { @ Override public boolean evaluate ( final String object ) { return ""PRINTER"" . equals ( anyObjectDAO . find ( object ) . getType ( ) . getKey ( ) ) ; } } , new ArrayList < String > ( ) ) ; assertEquals ( 2 , members . size ( ) ) ; assertEquals ( new HashSet < > ( Arrays . asList ( ""fc6dbc3a-6c07-4965-8781-921e7401a4a5"" , newAnyObjectKey ) ) , new HashSet < > ( members ) ) ; anyObject = anyObjectDAO . find ( ""fc6dbc3a-6c07-4965-8781-921e7401a4a5"" ) ; assertNotNull ( anyObject ) ; Collection < Group > dynGroupMemberships = findDynGroups ( anyObject ) ; assertEquals ( 1 , dynGroupMemberships . size ( ) ) ; assertTrue ( dynGroupMemberships . contains ( actual . getADynMembership ( anyTypeDAO . find ( ""PRINTER"" ) ) . getGroup ( ) ) ) ; anyObjectDAO . delete ( newAnyObjectKey ) ; anyObjectDAO . flush ( ) ; actual = groupDAO . find ( actual . getKey ( ) ) ; members = CollectionUtils . select ( groupDAO . findADynMembers ( actual ) , new Predicate < String > ( ) { @ Override public boolean evaluate ( final String object ) { return ""PRINTER"" . equals ( anyObjectDAO . find ( object ) . getType ( ) . getKey ( ) ) ; } } , new ArrayList < String > ( ) ) ; assertEquals ( 1 , members . size ( ) ) ; assertEquals ( ""fc6dbc3a-6c07-4965-8781-921e7401a4a5"" , members . get ( 0 ) ) ; String dynMembershipKey = actual . getADynMembership ( anyTypeDAO . find ( ""PRINTER"" ) ) . getKey ( ) ; groupDAO . delete ( actual ) ; groupDAO . flush ( ) ; assertNull ( entityManager ( ) . find ( JPAADynGroupMembership . class , dynMembershipKey ) ) ; dynGroupMemberships = findDynGroups ( anyObject ) ; assertTrue ( dynGroupMemberships . isEmpty ( ) ) ; } }",Smelly
public class ApacheLicenceHeaderTest extends ApacheLicenseHeaderTestCase { public ApacheLicenceHeaderTest ( ) { } },No
"public class MailConfiguration implements Cloneable { public static final String DEFAULT_FOLDER_NAME = ""INBOX"" ; public static final String DEFAULT_FROM = ""camel@localhost"" ; public static final long DEFAULT_CONNECTION_TIMEOUT = 30000L ; private Properties javaMailProperties ; private String protocol ; private String host ; private int port = - 1 ; private String username ; private String password ; private Session session ; private String defaultEncoding ; private String from = DEFAULT_FROM ; private String folderName = DEFAULT_FOLDER_NAME ; private boolean deleteProcessedMessages ; private boolean ignoreUriScheme ; private boolean processOnlyUnseenMessages = true ; private Map < Message . RecipientType , String > recipients = new HashMap < Message . RecipientType , String > ( ) ; private String destination ; private int fetchSize = - 1 ; private boolean debugMode ; private long connectionTimeout = DEFAULT_CONNECTION_TIMEOUT ; private boolean dummyTrustManager ; private String contentType = ""text/plain"" ; public MailConfiguration ( ) { } public MailConfiguration copy ( ) { try { return ( MailConfiguration ) clone ( ) ; } catch ( CloneNotSupportedException e ) { throw new RuntimeCamelException ( e ) ; } } public void configure ( URI uri ) { String value = uri . getHost ( ) ; if ( value != null ) { setHost ( value ) ; } if ( ! isIgnoreUriScheme ( ) ) { String scheme = uri . getScheme ( ) ; if ( scheme != null ) { setProtocol ( scheme ) ; } } String userInfo = uri . getUserInfo ( ) ; if ( userInfo != null ) { setUsername ( userInfo ) ; } int port = uri . getPort ( ) ; if ( port > 0 ) { setPort ( port ) ; } else if ( port <= 0 && this . port <= 0 ) { setPort ( MailUtils . getDefaultPortForProtocol ( uri . getScheme ( ) ) ) ; } } protected JavaMailSenderImpl createJavaMailSender ( ) { JavaMailSenderImpl answer = new JavaMailSenderImpl ( ) ; answer . getSession ( ) . setDebug ( debugMode ) ; if ( javaMailProperties != null ) { answer . setJavaMailProperties ( javaMailProperties ) ; } else { answer . setJavaMailProperties ( createJavaMailProperties ( ) ) ; } if ( defaultEncoding != null ) { answer . setDefaultEncoding ( defaultEncoding ) ; } if ( host != null ) { answer . setHost ( host ) ; } if ( port >= 0 ) { answer . setPort ( port ) ; } if ( password != null ) { answer . setPassword ( password ) ; } if ( protocol != null ) { answer . setProtocol ( protocol ) ; } if ( session != null ) { answer . setSession ( session ) ; } else { Session session = Session . getDefaultInstance ( answer . getJavaMailProperties ( ) , getAuthenticator ( ) ) ; answer . setSession ( session ) ; } if ( username != null ) { answer . setUsername ( username ) ; } return answer ; } private Properties createJavaMailProperties ( ) { Properties properties = ( Properties ) System . getProperties ( ) . clone ( ) ; properties . put ( ""mail."" + protocol + "".connectiontimeout"" , connectionTimeout ) ; properties . put ( ""mail."" + protocol + "".timeout"" , connectionTimeout ) ; properties . put ( ""mail."" + protocol + "".host"" , host ) ; properties . put ( ""mail."" + protocol + "".port"" , """" + port ) ; if ( username != null ) { properties . put ( ""mail."" + protocol + "".user"" , username ) ; properties . put ( ""mail.user"" , username ) ; properties . put ( ""mail."" + protocol + "".auth"" , ""true"" ) ; } else { properties . put ( ""mail."" + protocol + "".auth"" , ""false"" ) ; } properties . put ( ""mail."" + protocol + "".rsetbeforequit"" , ""true"" ) ; properties . put ( ""mail.transport.protocol"" , protocol ) ; properties . put ( ""mail.store.protocol"" , protocol ) ; properties . put ( ""mail.host"" , host ) ; if ( debugMode ) { properties . put ( ""javax.net.debug"" , ""all"" ) ; } if ( dummyTrustManager && isSecureProtocol ( ) ) { properties . put ( ""mail."" + protocol + "".socketFactory.class"" , ""org.apache.camel.component.mail.security.DummySSLSocketFactory"" ) ; properties . put ( ""mail."" + protocol + "".socketFactory.fallback"" , ""false"" ) ; properties . put ( ""mail."" + protocol + "".socketFactory.port"" , """" + port ) ; } return properties ; } public boolean isSecureProtocol ( ) { return this . protocol . equalsIgnoreCase ( ""smtps"" ) || this . protocol . equalsIgnoreCase ( ""pop3s"" ) || this . protocol . equalsIgnoreCase ( ""imaps"" ) ; } public Authenticator getAuthenticator ( ) { return new Authenticator ( ) { protected PasswordAuthentication getPasswordAuthentication ( ) { return new PasswordAuthentication ( getUsername ( ) , getPassword ( ) ) ; } } ; } public String getMailStoreLogInformation ( ) { String ssl = """" ; if ( isSecureProtocol ( ) ) { ssl = ""(SSL enabled"" + ( dummyTrustManager ? "" using DummyTrustManager)"" : "")"" ) ; } return protocol + ""//"" + host + "":"" + port + ssl + "", folder="" + folderName ; } public String getDefaultEncoding ( ) { return defaultEncoding ; } public void setDefaultEncoding ( String defaultEncoding ) { this . defaultEncoding = defaultEncoding ; } public String getHost ( ) { return host ; } public void setHost ( String host ) { this . host = host ; } public Properties getJavaMailProperties ( ) { return javaMailProperties ; } public void setJavaMailProperties ( Properties javaMailProperties ) { this . javaMailProperties = javaMailProperties ; } public String getPassword ( ) { return password ; } public void setPassword ( String password ) { this . password = password ; } public int getPort ( ) { return port ; } public void setPort ( int port ) { this . port = port ; } public String getProtocol ( ) { return protocol ; } public void setProtocol ( String protocol ) { this . protocol = protocol ; } public Session getSession ( ) { return session ; } public void setSession ( Session session ) { this . session = session ; } public String getUsername ( ) { return username ; } public void setUsername ( String username ) { this . username = username ; if ( destination == null ) { String address = username ; if ( address . indexOf ( ""@"" ) == - 1 ) { address += ""@"" + host ; } destination = address ; } } public String getDestination ( ) { return destination ; } public void setDestination ( String destination ) { this . destination = destination ; } public String getFrom ( ) { return from ; } public void setFrom ( String from ) { this . from = from ; } public boolean isDeleteProcessedMessages ( ) { return deleteProcessedMessages ; } public void setDeleteProcessedMessages ( boolean deleteProcessedMessages ) { this . deleteProcessedMessages = deleteProcessedMessages ; } public String getFolderName ( ) { return folderName ; } public void setFolderName ( String folderName ) { this . folderName = folderName ; } public boolean isIgnoreUriScheme ( ) { return ignoreUriScheme ; } public void setIgnoreUriScheme ( boolean ignoreUriScheme ) { this . ignoreUriScheme = ignoreUriScheme ; } public boolean isProcessOnlyUnseenMessages ( ) { return processOnlyUnseenMessages ; } public void setProcessOnlyUnseenMessages ( boolean processOnlyUnseenMessages ) { this . processOnlyUnseenMessages = processOnlyUnseenMessages ; } public void setTo ( String address ) { recipients . put ( Message . RecipientType . TO , address ) ; } public void setCC ( String address ) { recipients . put ( Message . RecipientType . CC , address ) ; } public void setBCC ( String address ) { recipients . put ( Message . RecipientType . BCC , address ) ; } public Map < Message . RecipientType , String > getRecipients ( ) { return recipients ; } public int getFetchSize ( ) { return fetchSize ; } public void setFetchSize ( int fetchSize ) { this . fetchSize = fetchSize ; } public boolean isDebugMode ( ) { return debugMode ; } public void setDebugMode ( boolean debugMode ) { this . debugMode = debugMode ; } public long getConnectionTimeout ( ) { return connectionTimeout ; } public void setConnectionTimeout ( long connectionTimeout ) { this . connectionTimeout = connectionTimeout ; } public boolean isDummyTrustManager ( ) { return dummyTrustManager ; } public void setDummyTrustManager ( boolean dummyTrustManager ) { this . dummyTrustManager = dummyTrustManager ; } public String getContentType ( ) { return contentType ; } public void setContentType ( String contentType ) { this . contentType = contentType ; } }",Smelly
"public abstract class AbstractNotifierTest extends AbstractContinuumTest { public void assertGroupNotifierPage ( String projectGroupName ) { assertTextPresent ( ""Project Group Notifiers of group "" + projectGroupName ) ; } public void assertProjectNotifierPage ( ) { assertTextPresent ( ""Add Notifier"" ) ; } public void assertAddNotifierPage ( ) { assertPage ( ""Continuum - Add Notifier"" ) ; assertTextPresent ( ""Add Notifier"" ) ; assertTextPresent ( ""Type"" ) ; assertElementPresent ( ""notifierType"" ) ; assertElementPresent ( ""Cancel"" ) ; } public void assertAddEditMailNotifierPage ( ) { assertPage ( ""Continuum - Add/Edit Mail Notifier"" ) ; assertTextPresent ( ""Add/Edit Mail Notifier"" ) ; assertTextPresent ( ""Mail Recipient Address"" ) ; assertTextPresent ( ""Send a mail to latest committers"" ) ; assertTextPresent ( ""Send on Success"" ) ; assertTextPresent ( ""Send on Failure"" ) ; assertTextPresent ( ""Send on Error"" ) ; assertTextPresent ( ""Send on Warning"" ) ; assertTextPresent ( ""Send on SCM Failure"" ) ; assertElementPresent ( ""address"" ) ; assertElementPresent ( ""Cancel"" ) ; } public void assertAddEditIrcNotifierPage ( ) { assertPage ( ""Continuum - Add/Edit IRC Notifier"" ) ; assertTextPresent ( ""IRC Host"" ) ; assertElementPresent ( ""host"" ) ; assertTextPresent ( ""IRC port"" ) ; assertElementPresent ( ""port"" ) ; assertTextPresent ( ""IRC channel"" ) ; assertElementPresent ( ""channel"" ) ; assertTextPresent ( ""Nick Name"" ) ; assertElementPresent ( ""nick"" ) ; assertTextPresent ( ""Alternate Nick Name"" ) ; assertElementPresent ( ""alternateNick"" ) ; assertTextPresent ( ""User Name"" ) ; assertElementPresent ( ""username"" ) ; assertTextPresent ( ""Full Name"" ) ; assertElementPresent ( ""fullName"" ) ; assertTextPresent ( ""Password"" ) ; assertElementPresent ( ""password"" ) ; assertTextPresent ( ""SSL"" ) ; assertTextPresent ( ""Send on Success"" ) ; assertTextPresent ( ""Send on Failure"" ) ; assertTextPresent ( ""Send on Error"" ) ; assertTextPresent ( ""Send on Warning"" ) ; assertTextPresent ( ""Send on SCM Failure"" ) ; } public void assertAddEditJabberPage ( ) { assertPage ( ""Continuum - Add/Edit Jabber Notifier"" ) ; assertTextPresent ( ""Jabber Host"" ) ; assertElementPresent ( ""host"" ) ; assertTextPresent ( ""Jabber port"" ) ; assertElementPresent ( ""port"" ) ; assertTextPresent ( ""Jabber login"" ) ; assertElementPresent ( ""login"" ) ; assertTextPresent ( ""Jabber Password"" ) ; assertElementPresent ( ""password"" ) ; assertTextPresent ( ""Jabber Domain Name"" ) ; assertElementPresent ( ""domainName"" ) ; assertTextPresent ( ""Jabber Recipient Address"" ) ; assertElementPresent ( ""address"" ) ; assertTextPresent ( ""Is it a SSL connection?"" ) ; assertTextPresent ( ""Is it a Jabber group?"" ) ; assertTextPresent ( ""Send on Success"" ) ; assertTextPresent ( ""Send on Failure"" ) ; assertTextPresent ( ""Send on Error"" ) ; assertTextPresent ( ""Send on Warning"" ) ; assertTextPresent ( ""Send on SCM Failure"" ) ; } public void assertAddEditMsnPage ( ) { assertPage ( ""Continuum - Add/Edit MSN Notifier"" ) ; assertTextPresent ( ""MSN login"" ) ; assertElementPresent ( ""login"" ) ; assertTextPresent ( ""MSN Password"" ) ; assertElementPresent ( ""password"" ) ; assertTextPresent ( ""MSN Recipient Address"" ) ; assertElementPresent ( ""address"" ) ; assertTextPresent ( ""Send on Success"" ) ; assertTextPresent ( ""Send on Failure"" ) ; assertTextPresent ( ""Send on Error"" ) ; assertTextPresent ( ""Send on Warning"" ) ; assertTextPresent ( ""Send on SCM Failure"" ) ; } public void assertAddEditWagonPage ( ) { assertPage ( ""Continuum - Add/Edit Wagon Notifier"" ) ; assertTextPresent ( ""Project Site URL"" ) ; assertTextPresent ( ""Server Id (defined in your settings.xml for authentication)"" ) ; assertElementPresent ( ""url"" ) ; assertElementPresent ( ""id"" ) ; assertTextPresent ( ""Send on Success"" ) ; assertTextPresent ( ""Send on Failure"" ) ; assertTextPresent ( ""Send on Error"" ) ; assertTextPresent ( ""Send on Warning"" ) ; } public void goToGroupNotifier ( String projectGroupName , String projectGroupId , String projectGroupDescription ) throws Exception { showProjectGroup ( projectGroupName , projectGroupId , projectGroupDescription ) ; clickLinkWithText ( ""Notifiers"" ) ; assertGroupNotifierPage ( projectGroupName ) ; clickButtonWithValue ( ""Add"" ) ; assertAddNotifierPage ( ) ; } public void goToProjectNotifier ( String projectGroupName , String projectName ) throws Exception { goToProjectInformationPage ( projectGroupName , projectName ) ; clickLinkWithXPath ( ""//input[contains(@id,'addProjectNotifier') and @type='submit']"" ) ; assertAddNotifierPage ( ) ; } public void addMailNotifier ( String projectGroupName , String projectName , String email , boolean isValid ) throws Exception { selectValue ( ""//select"" , ""Mail"" ) ; clickButtonWithValue ( ""Submit"" ) ; assertAddEditMailNotifierPage ( ) ; setFieldValue ( ""address"" , email ) ; clickButtonWithValue ( ""Save"" ) ; if ( ! isValid ) { assertTextPresent ( ""Address is invalid"" ) ; } else if ( projectName != null ) { assertProjectInformationPage ( ) ; } else { assertGroupNotifierPage ( projectGroupName ) ; } } public void editMailNotifier ( String projectGroupName , String projectName , String oldMail , String newMail , boolean isValid ) throws Exception { if ( projectName == null ) { clickLinkWithXPath ( ""(//a[contains(@href,'editProjectGroupNotifier') and contains(@href,'mail')])//img"" ) ; } else { clickLinkWithXPath ( ""(//a[contains(@href,'editProjectNotifier') and contains(@href,'mail')])//img"" ) ; } assertAddEditMailNotifierPage ( ) ; assertFieldValue ( oldMail , ""address"" ) ; setFieldValue ( ""address"" , newMail ) ; clickButtonWithValue ( ""Save"" ) ; if ( ! isValid ) { assertTextPresent ( ""Address is invalid"" ) ; } else if ( projectName != null ) { assertProjectInformationPage ( ) ; } else { assertGroupNotifierPage ( projectGroupName ) ; } } public void addIrcNotifier ( String projectGroupName , String projectName , String host , String channel , boolean isValid ) throws Exception { selectValue ( ""//select"" , ""IRC"" ) ; clickButtonWithValue ( ""Submit"" ) ; assertAddEditIrcNotifierPage ( ) ; setFieldValue ( ""host"" , host ) ; setFieldValue ( ""channel"" , channel ) ; clickButtonWithValue ( ""Save"" ) ; if ( ! isValid ) { assertTextPresent ( ""Host is required"" ) ; assertTextPresent ( ""Channel is required"" ) ; } else if ( projectName != null ) { assertProjectInformationPage ( ) ; } else { assertGroupNotifierPage ( projectGroupName ) ; } } public void editIrcNotifier ( String projectGroupName , String projectName , String oldHost , String oldChannel , String newHost , String newChannel , boolean isValid ) throws Exception { if ( projectName == null ) { clickLinkWithXPath ( ""(//a[contains(@href,'editProjectGroupNotifier') and contains(@href,'irc')])//img"" ) ; } else { clickLinkWithXPath ( ""(//a[contains(@href,'editProjectNotifier') and contains(@href,'irc')])//img"" ) ; } assertAddEditIrcNotifierPage ( ) ; assertFieldValue ( oldHost , ""host"" ) ; assertFieldValue ( oldChannel , ""channel"" ) ; setFieldValue ( ""host"" , newHost ) ; setFieldValue ( ""channel"" , newChannel ) ; clickButtonWithValue ( ""Save"" ) ; if ( ! isValid ) { assertTextPresent ( ""Host is required"" ) ; assertTextPresent ( ""Channel is required"" ) ; } else if ( projectName != null ) { assertProjectInformationPage ( ) ; } else { assertGroupNotifierPage ( projectGroupName ) ; } } public void addJabberNotifier ( String projectGroupName , String projectName , String host , String login , String password , String address , boolean isValid ) throws Exception { selectValue ( ""//select"" , ""Jabber"" ) ; clickButtonWithValue ( ""Submit"" ) ; assertAddEditJabberPage ( ) ; setFieldValue ( ""host"" , host ) ; setFieldValue ( ""login"" , login ) ; setFieldValue ( ""password"" , password ) ; setFieldValue ( ""address"" , address ) ; clickButtonWithValue ( ""Save"" ) ; if ( ! isValid ) { assertTextPresent ( ""Host is required"" ) ; assertTextPresent ( ""Login is required"" ) ; assertTextPresent ( ""Password is required"" ) ; assertTextPresent ( ""Address is required"" ) ; } else if ( projectName != null ) { assertProjectInformationPage ( ) ; } else { assertGroupNotifierPage ( projectGroupName ) ; } } public void editJabberNotifier ( String projectGroupName , String projectName , String oldHost , String oldLogin , String oldAddress , String newHost , String newLogin , String newPassword , String newAddress , boolean isValid ) throws Exception { if ( projectName == null ) { clickLinkWithXPath ( ""(//a[contains(@href,'editProjectGroupNotifier') and contains(@href,'jabber')])//img"" ) ; } else { clickLinkWithXPath ( ""(//a[contains(@href,'editProjectNotifier') and contains(@href,'jabber')])//img"" ) ; } assertAddEditJabberPage ( ) ; assertFieldValue ( oldHost , ""host"" ) ; assertFieldValue ( oldLogin , ""login"" ) ; assertFieldValue ( oldAddress , ""address"" ) ; setFieldValue ( ""host"" , newHost ) ; setFieldValue ( ""login"" , newLogin ) ; setFieldValue ( ""password"" , newPassword ) ; setFieldValue ( ""address"" , newAddress ) ; clickButtonWithValue ( ""Save"" ) ; if ( ! isValid ) { assertTextPresent ( ""Host is required"" ) ; assertTextPresent ( ""Login is required"" ) ; assertTextPresent ( ""Password is required"" ) ; assertTextPresent ( ""Address is required"" ) ; } else if ( projectName != null ) { assertProjectInformationPage ( ) ; } else { assertGroupNotifierPage ( projectGroupName ) ; } } public void addMsnNotifier ( String projectGroupName , String projectName , String login , String password , String recipientAddress , boolean isValid ) throws Exception { selectValue ( ""//select"" , ""MSN"" ) ; clickButtonWithValue ( ""Submit"" ) ; assertAddEditMsnPage ( ) ; setFieldValue ( ""login"" , login ) ; setFieldValue ( ""password"" , password ) ; setFieldValue ( ""address"" , recipientAddress ) ; clickButtonWithValue ( ""Save"" ) ; if ( ! isValid ) { assertTextPresent ( ""Login is required"" ) ; assertTextPresent ( ""Password is required"" ) ; assertTextPresent ( ""Address is required"" ) ; } else if ( projectName != null ) { assertProjectInformationPage ( ) ; } else { assertGroupNotifierPage ( projectGroupName ) ; } } public void editMsnNotifier ( String projectGroupName , String projectName , String oldLogin , String oldAddress , String newLogin , String newPassword , String newAddress , boolean isValid ) throws Exception { if ( projectName == null ) { clickLinkWithXPath ( ""(//a[contains(@href,'editProjectGroupNotifier') and contains(@href,'msn')])//img"" ) ; } else { clickLinkWithXPath ( ""(//a[contains(@href,'editProjectNotifier') and contains(@href,'msn')])//img"" ) ; } assertAddEditMsnPage ( ) ; assertFieldValue ( oldLogin , ""login"" ) ; assertFieldValue ( oldAddress , ""address"" ) ; setFieldValue ( ""login"" , newLogin ) ; setFieldValue ( ""password"" , newPassword ) ; setFieldValue ( ""address"" , newAddress ) ; clickButtonWithValue ( ""Save"" ) ; if ( ! isValid ) { assertTextPresent ( ""Login is required"" ) ; assertTextPresent ( ""Password is required"" ) ; assertTextPresent ( ""Address is required"" ) ; } else if ( projectName != null ) { assertProjectInformationPage ( ) ; } else { assertGroupNotifierPage ( projectGroupName ) ; } } public void addWagonNotifierPage ( String projectGroupName , String projectName , String siteUrl , String serverId , boolean isValid ) throws Exception { selectValue ( ""//select"" , ""Wagon"" ) ; clickButtonWithValue ( ""Submit"" ) ; assertAddEditWagonPage ( ) ; setFieldValue ( ""url"" , siteUrl ) ; setFieldValue ( ""id"" , serverId ) ; clickButtonWithValue ( ""Save"" ) ; if ( ! isValid ) { assertTextPresent ( ""Destination URL is required"" ) ; assertTextPresent ( ""Server Id is required"" ) ; } else if ( projectName != null ) { assertProjectInformationPage ( ) ; } else { assertGroupNotifierPage ( projectGroupName ) ; } } public void editWagonNotifier ( String projectGroupName , String projectName , String oldUrl , String oldId , String newUrl , String newId , boolean isValid ) throws Exception { if ( projectName == null ) { clickLinkWithXPath ( ""(//a[contains(@href,'editProjectGroupNotifier') and contains(@href,'wagon')])//img"" ) ; } else { clickLinkWithXPath ( ""(//a[contains(@href,'editProjectNotifier') and contains(@href,'wagon')])//img"" ) ; } assertAddEditWagonPage ( ) ; assertFieldValue ( oldUrl , ""url"" ) ; assertFieldValue ( oldId , ""id"" ) ; setFieldValue ( ""url"" , newUrl ) ; setFieldValue ( ""id"" , newId ) ; clickButtonWithValue ( ""Save"" ) ; if ( ! isValid ) { assertTextPresent ( ""Destination URL is required"" ) ; assertTextPresent ( ""Server Id is required"" ) ; } else if ( projectName != null ) { assertProjectInformationPage ( ) ; } else { assertGroupNotifierPage ( projectGroupName ) ; } } }",Smelly
"public class GiraphConfigurationValidator < I extends WritableComparable , V extends Writable , E extends Writable , M1 extends Writable , M2 extends Writable > { private static Logger LOG = Logger . getLogger ( GiraphConfigurationValidator . class ) ; private static final int ID_PARAM_INDEX = 0 ; private static final int VALUE_PARAM_INDEX = 1 ; private static final int EDGE_PARAM_INDEX = 2 ; private static final int MSG_COMBINER_PARAM_INDEX = 1 ; private static final int EDGE_PARAM_EDGE_INPUT_FORMAT_INDEX = 1 ; private static final int EDGE_PARAM_OUT_EDGES_INDEX = 1 ; private static final int VALUE_PARAM_VERTEX_VALUE_FACTORY_INDEX = 0 ; private static final int VALUE_PARAM_VERTEX_VALUE_COMBINER_INDEX = 0 ; private ImmutableClassesGiraphConfiguration conf ; public GiraphConfigurationValidator ( Configuration conf ) { this . conf = new ImmutableClassesGiraphConfiguration ( conf ) ; } private Class < ? extends WritableComparable > vertexIndexType ( ) { return conf . getGiraphTypes ( ) . getVertexIdClass ( ) ; } private Class < ? extends Writable > vertexValueType ( ) { return conf . getGiraphTypes ( ) . getVertexValueClass ( ) ; } private Class < ? extends Writable > edgeValueType ( ) { return conf . getGiraphTypes ( ) . getEdgeValueClass ( ) ; } private Class < ? extends Writable > outgoingMessageValueType ( ) { return conf . getGiraphTypes ( ) . getOutgoingMessageValueClass ( ) ; } public void validateConfiguration ( ) { checkConfiguration ( ) ; verifyOutEdgesGenericTypes ( ) ; verifyVertexInputFormatGenericTypes ( ) ; verifyEdgeInputFormatGenericTypes ( ) ; verifyVertexOutputFormatGenericTypes ( ) ; verifyEdgeOutputFormatGenericTypes ( ) ; verifyVertexResolverGenericTypes ( ) ; verifyVertexValueCombinerGenericTypes ( ) ; verifyMessageCombinerGenericTypes ( ) ; verifyVertexValueFactoryGenericTypes ( ) ; } private void checkConfiguration ( ) { if ( conf . getMaxWorkers ( ) < 0 ) { throw new RuntimeException ( ""checkConfiguration: No valid "" + GiraphConstants . MAX_WORKERS ) ; } if ( conf . getMinPercentResponded ( ) <= 0.0f || conf . getMinPercentResponded ( ) > 100.0f ) { throw new IllegalArgumentException ( ""checkConfiguration: Invalid "" + conf . getMinPercentResponded ( ) + "" for "" + GiraphConstants . MIN_PERCENT_RESPONDED . getKey ( ) ) ; } if ( conf . getMinWorkers ( ) < 0 ) { throw new IllegalArgumentException ( ""checkConfiguration: No valid "" + GiraphConstants . MIN_WORKERS ) ; } conf . createComputationFactory ( ) . checkConfiguration ( conf ) ; if ( conf . getVertexInputFormatClass ( ) == null && conf . getEdgeInputFormatClass ( ) == null ) { throw new IllegalArgumentException ( ""checkConfiguration: One of "" + GiraphConstants . VERTEX_INPUT_FORMAT_CLASS . getKey ( ) + "" and "" + GiraphConstants . EDGE_INPUT_FORMAT_CLASS . getKey ( ) + "" must be non-null"" ) ; } if ( conf . getVertexResolverClass ( ) == null ) { if ( LOG . isInfoEnabled ( ) ) { LOG . info ( ""checkConfiguration: No class found for "" + VERTEX_RESOLVER_CLASS . getKey ( ) + "", defaulting to "" + VERTEX_RESOLVER_CLASS . getDefaultClass ( ) . getCanonicalName ( ) ) ; } } if ( conf . getOutEdgesClass ( ) == null ) { if ( LOG . isInfoEnabled ( ) ) { LOG . info ( ""checkConfiguration: No class found for "" + VERTEX_EDGES_CLASS . getKey ( ) + "", defaulting to "" + VERTEX_EDGES_CLASS . getDefaultClass ( ) . getCanonicalName ( ) ) ; } } } private void verifyOutEdgesGenericTypesClass ( Class < ? extends OutEdges < I , E > > outEdgesClass ) { Class < ? > [ ] classList = getTypeArguments ( OutEdges . class , outEdgesClass ) ; checkAssignable ( classList , ID_PARAM_INDEX , vertexIndexType ( ) , OutEdges . class , ""vertex index"" ) ; checkAssignable ( classList , EDGE_PARAM_OUT_EDGES_INDEX , edgeValueType ( ) , OutEdges . class , ""edge value"" ) ; } private void verifyOutEdgesGenericTypes ( ) { Class < ? extends OutEdges < I , E > > outEdgesClass = conf . getOutEdgesClass ( ) ; Class < ? extends OutEdges < I , E > > inputOutEdgesClass = conf . getInputOutEdgesClass ( ) ; verifyOutEdgesGenericTypesClass ( outEdgesClass ) ; verifyOutEdgesGenericTypesClass ( inputOutEdgesClass ) ; } private void verifyVertexInputFormatGenericTypes ( ) { Class < ? extends VertexInputFormat < I , V , E > > vertexInputFormatClass = conf . getVertexInputFormatClass ( ) ; if ( vertexInputFormatClass != null ) { Class < ? > [ ] classList = getTypeArguments ( VertexInputFormat . class , vertexInputFormatClass ) ; checkAssignable ( classList , ID_PARAM_INDEX , vertexIndexType ( ) , VertexInputFormat . class , ""vertex index"" ) ; checkAssignable ( classList , VALUE_PARAM_INDEX , vertexValueType ( ) , VertexInputFormat . class , ""vertex value"" ) ; checkAssignable ( classList , EDGE_PARAM_INDEX , edgeValueType ( ) , VertexInputFormat . class , ""edge value"" ) ; } } private void verifyEdgeInputFormatGenericTypes ( ) { Class < ? extends EdgeInputFormat < I , E > > edgeInputFormatClass = conf . getEdgeInputFormatClass ( ) ; if ( edgeInputFormatClass != null ) { Class < ? > [ ] classList = getTypeArguments ( EdgeInputFormat . class , edgeInputFormatClass ) ; checkAssignable ( classList , ID_PARAM_INDEX , vertexIndexType ( ) , EdgeInputFormat . class , ""vertex index"" ) ; checkAssignable ( classList , EDGE_PARAM_EDGE_INPUT_FORMAT_INDEX , edgeValueType ( ) , EdgeInputFormat . class , ""edge value"" ) ; } } private void verifyVertexValueCombinerGenericTypes ( ) { Class < ? extends VertexValueCombiner < V > > vertexValueCombiner = conf . getVertexValueCombinerClass ( ) ; if ( vertexValueCombiner != null ) { Class < ? > [ ] classList = getTypeArguments ( VertexValueCombiner . class , vertexValueCombiner ) ; checkAssignable ( classList , VALUE_PARAM_VERTEX_VALUE_COMBINER_INDEX , vertexValueType ( ) , VertexValueCombiner . class , ""vertex value"" ) ; } } private void verifyMessageCombinerGenericTypes ( ) { Class < ? extends MessageCombiner < I , M2 > > messageCombinerClass = conf . getMessageCombinerClass ( ) ; if ( messageCombinerClass != null ) { Class < ? > [ ] classList = getTypeArguments ( MessageCombiner . class , messageCombinerClass ) ; checkEquals ( classList , ID_PARAM_INDEX , vertexIndexType ( ) , MessageCombiner . class , ""vertex index"" ) ; checkEquals ( classList , MSG_COMBINER_PARAM_INDEX , outgoingMessageValueType ( ) , MessageCombiner . class , ""message value"" ) ; } } private void verifyVertexOutputFormatGenericTypes ( ) { Class < ? extends EdgeOutputFormat < I , V , E > > edgeOutputFormatClass = conf . getEdgeOutputFormatClass ( ) ; if ( conf . hasEdgeOutputFormat ( ) ) { Class < ? > [ ] classList = getTypeArguments ( EdgeOutputFormat . class , edgeOutputFormatClass ) ; checkAssignable ( classList , ID_PARAM_INDEX , vertexIndexType ( ) , VertexOutputFormat . class , ""vertex index"" ) ; checkAssignable ( classList , VALUE_PARAM_INDEX , vertexValueType ( ) , VertexOutputFormat . class , ""vertex value"" ) ; checkAssignable ( classList , EDGE_PARAM_INDEX , edgeValueType ( ) , VertexOutputFormat . class , ""edge value"" ) ; } } private void verifyEdgeOutputFormatGenericTypes ( ) { Class < ? extends VertexOutputFormat < I , V , E > > vertexOutputFormatClass = conf . getVertexOutputFormatClass ( ) ; if ( conf . hasVertexOutputFormat ( ) ) { Class < ? > [ ] classList = getTypeArguments ( VertexOutputFormat . class , vertexOutputFormatClass ) ; checkAssignable ( classList , ID_PARAM_INDEX , vertexIndexType ( ) , VertexOutputFormat . class , ""vertex index"" ) ; checkAssignable ( classList , VALUE_PARAM_INDEX , vertexValueType ( ) , VertexOutputFormat . class , ""vertex value"" ) ; checkAssignable ( classList , EDGE_PARAM_INDEX , edgeValueType ( ) , VertexOutputFormat . class , ""edge value"" ) ; } } private void verifyVertexValueFactoryGenericTypes ( ) { Class < ? extends VertexValueFactory < V > > vvfClass = conf . getVertexValueFactoryClass ( ) ; if ( DefaultVertexValueFactory . class . equals ( vvfClass ) ) { return ; } Class < ? > [ ] classList = getTypeArguments ( VertexValueFactory . class , vvfClass ) ; checkEquals ( classList , VALUE_PARAM_VERTEX_VALUE_FACTORY_INDEX , vertexValueType ( ) , VertexValueFactory . class , ""vertex value"" ) ; } private void verifyVertexResolverGenericTypes ( ) { Class < ? extends VertexResolver < I , V , E > > vrClass = conf . getVertexResolverClass ( ) ; if ( DefaultVertexResolver . class . equals ( vrClass ) ) { return ; } Class < ? > [ ] classList = getTypeArguments ( VertexResolver . class , vrClass ) ; checkEquals ( classList , ID_PARAM_INDEX , vertexIndexType ( ) , VertexResolver . class , ""vertex index"" ) ; checkEquals ( classList , VALUE_PARAM_INDEX , vertexValueType ( ) , VertexResolver . class , ""vertex value"" ) ; checkEquals ( classList , EDGE_PARAM_INDEX , edgeValueType ( ) , VertexResolver . class , ""edge value"" ) ; } private static void checkEquals ( Class < ? > [ ] classList , int index , Class < ? > classFromComputation , Class klass , String typeName ) { if ( classList [ index ] == null ) { LOG . warn ( klass . getSimpleName ( ) + "" "" + typeName + "" type is not known"" ) ; } else if ( ! classList [ index ] . equals ( classFromComputation ) ) { throw new IllegalArgumentException ( ""checkClassTypes: "" + typeName + "" types not equal, "" + ""computation - "" + classFromComputation + "", "" + klass . getSimpleName ( ) + "" - "" + classList [ index ] ) ; } } private static void checkAssignable ( Class < ? > [ ] classList , int index , Class < ? > classFromComputation , Class klass , String typeName ) { if ( classList [ index ] == null ) { LOG . warn ( klass . getSimpleName ( ) + "" "" + typeName + "" type is not known"" ) ; } else if ( ! classList [ index ] . isAssignableFrom ( classFromComputation ) ) { throw new IllegalArgumentException ( ""checkClassTypes: "" + typeName + "" types not assignable, "" + ""computation - "" + classFromComputation + "", "" + klass . getSimpleName ( ) + "" - "" + classList [ EDGE_PARAM_EDGE_INPUT_FORMAT_INDEX ] ) ; } } }",Smelly
"class SnowballProgram { protected SnowballProgram ( ) { current = new StringBuffer ( ) ; setCurrent ( """" ) ; } public void setCurrent ( String value ) { current . replace ( 0 , current . length ( ) , value ) ; cursor = 0 ; limit = current . length ( ) ; limit_backward = 0 ; bra = cursor ; ket = limit ; } public String getCurrent ( ) { String result = current . toString ( ) ; current = new StringBuffer ( ) ; return result ; } protected StringBuffer current ; protected int cursor ; protected int limit ; protected int limit_backward ; protected int bra ; protected int ket ; protected void copy_from ( SnowballProgram other ) { current = other . current ; cursor = other . cursor ; limit = other . limit ; limit_backward = other . limit_backward ; bra = other . bra ; ket = other . ket ; } protected boolean in_grouping ( char [ ] s , int min , int max ) { if ( cursor >= limit ) return false ; char ch = current . charAt ( cursor ) ; if ( ch > max || ch < min ) return false ; ch -= min ; if ( ( s [ ch > > 3 ] & ( 0X1 < < ( ch & 0X7 ) ) ) == 0 ) return false ; cursor ++ ; return true ; } protected boolean in_grouping_b ( char [ ] s , int min , int max ) { if ( cursor <= limit_backward ) return false ; char ch = current . charAt ( cursor - 1 ) ; if ( ch > max || ch < min ) return false ; ch -= min ; if ( ( s [ ch > > 3 ] & ( 0X1 < < ( ch & 0X7 ) ) ) == 0 ) return false ; cursor -- ; return true ; } protected boolean out_grouping ( char [ ] s , int min , int max ) { if ( cursor >= limit ) return false ; char ch = current . charAt ( cursor ) ; if ( ch > max || ch < min ) { cursor ++ ; return true ; } ch -= min ; if ( ( s [ ch > > 3 ] & ( 0X1 < < ( ch & 0X7 ) ) ) == 0 ) { cursor ++ ; return true ; } return false ; } protected boolean out_grouping_b ( char [ ] s , int min , int max ) { if ( cursor <= limit_backward ) return false ; char ch = current . charAt ( cursor - 1 ) ; if ( ch > max || ch < min ) { cursor -- ; return true ; } ch -= min ; if ( ( s [ ch > > 3 ] & ( 0X1 < < ( ch & 0X7 ) ) ) == 0 ) { cursor -- ; return true ; } return false ; } protected boolean in_range ( int min , int max ) { if ( cursor >= limit ) return false ; char ch = current . charAt ( cursor ) ; if ( ch > max || ch < min ) return false ; cursor ++ ; return true ; } protected boolean in_range_b ( int min , int max ) { if ( cursor <= limit_backward ) return false ; char ch = current . charAt ( cursor - 1 ) ; if ( ch > max || ch < min ) return false ; cursor -- ; return true ; } protected boolean out_range ( int min , int max ) { if ( cursor >= limit ) return false ; char ch = current . charAt ( cursor ) ; if ( ! ( ch > max || ch < min ) ) return false ; cursor ++ ; return true ; } protected boolean out_range_b ( int min , int max ) { if ( cursor <= limit_backward ) return false ; char ch = current . charAt ( cursor - 1 ) ; if ( ! ( ch > max || ch < min ) ) return false ; cursor -- ; return true ; } protected boolean eq_s ( int s_size , String s ) { if ( limit - cursor < s_size ) return false ; int i ; for ( i = 0 ; i != s_size ; i ++ ) { if ( current . charAt ( cursor + i ) != s . charAt ( i ) ) return false ; } cursor += s_size ; return true ; } protected boolean eq_s_b ( int s_size , String s ) { if ( cursor - limit_backward < s_size ) return false ; int i ; for ( i = 0 ; i != s_size ; i ++ ) { if ( current . charAt ( cursor - s_size + i ) != s . charAt ( i ) ) return false ; } cursor -= s_size ; return true ; } protected boolean eq_v ( CharSequence s ) { return eq_s ( s . length ( ) , s . toString ( ) ) ; } protected boolean eq_v_b ( CharSequence s ) { return eq_s_b ( s . length ( ) , s . toString ( ) ) ; } protected int find_among ( Among v [ ] , int v_size ) { int i = 0 ; int j = v_size ; int c = cursor ; int l = limit ; int common_i = 0 ; int common_j = 0 ; boolean first_key_inspected = false ; while ( true ) { int k = i + ( ( j - i ) > > 1 ) ; int diff = 0 ; int common = common_i < common_j ? common_i : common_j ; Among w = v [ k ] ; int i2 ; for ( i2 = common ; i2 < w . s_size ; i2 ++ ) { if ( c + common == l ) { diff = - 1 ; break ; } diff = current . charAt ( c + common ) - w . s [ i2 ] ; if ( diff != 0 ) break ; common ++ ; } if ( diff < 0 ) { j = k ; common_j = common ; } else { i = k ; common_i = common ; } if ( j - i <= 1 ) { if ( i > 0 ) break ; if ( j == i ) break ; if ( first_key_inspected ) break ; first_key_inspected = true ; } } while ( true ) { Among w = v [ i ] ; if ( common_i >= w . s_size ) { cursor = c + w . s_size ; if ( w . method == null ) return w . result ; boolean res ; try { Object resobj = w . method . invoke ( w . methodobject , new Object [ 0 ] ) ; res = resobj . toString ( ) . equals ( ""true"" ) ; } catch ( InvocationTargetException e ) { res = false ; } catch ( IllegalAccessException e ) { res = false ; } cursor = c + w . s_size ; if ( res ) return w . result ; } i = w . substring_i ; if ( i < 0 ) return 0 ; } } protected int find_among_b ( Among v [ ] , int v_size ) { int i = 0 ; int j = v_size ; int c = cursor ; int lb = limit_backward ; int common_i = 0 ; int common_j = 0 ; boolean first_key_inspected = false ; while ( true ) { int k = i + ( ( j - i ) > > 1 ) ; int diff = 0 ; int common = common_i < common_j ? common_i : common_j ; Among w = v [ k ] ; int i2 ; for ( i2 = w . s_size - 1 - common ; i2 >= 0 ; i2 -- ) { if ( c - common == lb ) { diff = - 1 ; break ; } diff = current . charAt ( c - 1 - common ) - w . s [ i2 ] ; if ( diff != 0 ) break ; common ++ ; } if ( diff < 0 ) { j = k ; common_j = common ; } else { i = k ; common_i = common ; } if ( j - i <= 1 ) { if ( i > 0 ) break ; if ( j == i ) break ; if ( first_key_inspected ) break ; first_key_inspected = true ; } } while ( true ) { Among w = v [ i ] ; if ( common_i >= w . s_size ) { cursor = c - w . s_size ; if ( w . method == null ) return w . result ; boolean res ; try { Object resobj = w . method . invoke ( w . methodobject , new Object [ 0 ] ) ; res = resobj . toString ( ) . equals ( ""true"" ) ; } catch ( InvocationTargetException e ) { res = false ; } catch ( IllegalAccessException e ) { res = false ; } cursor = c - w . s_size ; if ( res ) return w . result ; } i = w . substring_i ; if ( i < 0 ) return 0 ; } } protected int replace_s ( int c_bra , int c_ket , String s ) { int adjustment = s . length ( ) - ( c_ket - c_bra ) ; current . replace ( c_bra , c_ket , s ) ; limit += adjustment ; if ( cursor >= c_ket ) cursor += adjustment ; else if ( cursor > c_bra ) cursor = c_bra ; return adjustment ; } protected void slice_check ( ) { if ( bra < 0 || bra > ket || ket > limit || limit > current . length ( ) ) { System . err . println ( ""faulty slice operation"" ) ; } } protected void slice_from ( String s ) { slice_check ( ) ; replace_s ( bra , ket , s ) ; } protected void slice_from ( CharSequence s ) { slice_from ( s . toString ( ) ) ; } protected void slice_del ( ) { slice_from ( """" ) ; } protected void insert ( int c_bra , int c_ket , String s ) { int adjustment = replace_s ( c_bra , c_ket , s ) ; if ( c_bra <= bra ) bra += adjustment ; if ( c_bra <= ket ) ket += adjustment ; } protected void insert ( int c_bra , int c_ket , CharSequence s ) { insert ( c_bra , c_ket , s . toString ( ) ) ; } protected StringBuffer slice_to ( StringBuffer s ) { slice_check ( ) ; int len = ket - bra ; s . replace ( 0 , s . length ( ) , current . substring ( bra , ket ) ) ; return s ; } protected StringBuilder slice_to ( StringBuilder s ) { slice_check ( ) ; int len = ket - bra ; s . replace ( 0 , s . length ( ) , current . substring ( bra , ket ) ) ; return s ; } protected StringBuffer assign_to ( StringBuffer s ) { s . replace ( 0 , s . length ( ) , current . substring ( 0 , limit ) ) ; return s ; } protected StringBuilder assign_to ( StringBuilder s ) { s . replace ( 0 , s . length ( ) , current . substring ( 0 , limit ) ) ; return s ; } }",Smelly
"public class JavaMarshallingGenerator extends MultiSourceGenerator { protected List < JClass > concreteClasses = new ArrayList < JClass > ( ) ; protected File factoryFile ; protected String factoryFileName = ""MarshallerFactory"" ; protected String indent = ""    "" ; protected String targetDir = ""src/main/java"" ; public Object run ( ) { if ( destDir == null ) { destDir = new File ( targetDir + ""/org/apache/activemq/openwire/v"" + getOpenwireVersion ( ) ) ; } Object answer = super . run ( ) ; processFactory ( ) ; return answer ; } protected void generateFile ( PrintWriter out ) throws Exception { generateLicence ( out ) ; out . println ( """" ) ; out . println ( ""package org.apache.activemq.openwire.v"" + getOpenwireVersion ( ) + "";"" ) ; out . println ( """" ) ; out . println ( ""import java.io.DataInput;"" ) ; out . println ( ""import java.io.DataOutput;"" ) ; out . println ( ""import java.io.IOException;"" ) ; out . println ( """" ) ; out . println ( ""import org.apache.activemq.openwire.*;"" ) ; out . println ( ""import org.apache.activemq.command.*;"" ) ; out . println ( """" ) ; out . println ( """" ) ; for ( int i = 0 ; i < getJclass ( ) . getImportedPackages ( ) . length ; i ++ ) { JPackage pkg = getJclass ( ) . getImportedPackages ( ) [ i ] ; for ( int j = 0 ; j < pkg . getClasses ( ) . length ; j ++ ) { JClass clazz = pkg . getClasses ( ) [ j ] ; out . println ( ""import "" + clazz . getQualifiedName ( ) + "";"" ) ; } } out . println ( """" ) ; out . println ( ""/**"" ) ; out . println ( "" * Marshalling code for Open Wire Format for "" + getClassName ( ) + """" ) ; out . println ( "" *"" ) ; out . println ( "" *"" ) ; out . println ( "" * NOTE!: This file is auto generated - do not modify!"" ) ; out . println ( "" *        if you need to make a change, please see the modify the groovy scripts in the"" ) ; out . println ( "" *        under src/gram/script and then use maven openwire:generate to regenerate "" ) ; out . println ( "" *        this file."" ) ; out . println ( "" *"" ) ; out . println ( "" * "" ) ; out . println ( "" */"" ) ; out . println ( ""public "" + getAbstractClassText ( ) + ""class "" + getClassName ( ) + "" extends "" + getBaseClass ( ) + "" {"" ) ; out . println ( """" ) ; if ( ! isAbstractClass ( ) ) { out . println ( ""    /**"" ) ; out . println ( ""     * Return the type of Data Structure we marshal"" ) ; out . println ( ""     * @return short representation of the type data structure"" ) ; out . println ( ""     */"" ) ; out . println ( ""    public byte getDataStructureType() {"" ) ; out . println ( ""        return "" + getJclass ( ) . getSimpleName ( ) + "".DATA_STRUCTURE_TYPE;"" ) ; out . println ( ""    }"" ) ; out . println ( ""    "" ) ; out . println ( ""    /**"" ) ; out . println ( ""     * @return a new object instance"" ) ; out . println ( ""     */"" ) ; out . println ( ""    public DataStructure createObject() {"" ) ; out . println ( ""        return new "" + getJclass ( ) . getSimpleName ( ) + ""();"" ) ; out . println ( ""    }"" ) ; out . println ( """" ) ; } out . println ( ""    /**"" ) ; out . println ( ""     * Un-marshal an object instance from the data input stream"" ) ; out . println ( ""     *"" ) ; out . println ( ""     * @param o the object to un-marshal"" ) ; out . println ( ""     * @param dataIn the data input stream to build the object from"" ) ; out . println ( ""     * @throws IOException"" ) ; out . println ( ""     */"" ) ; out . println ( ""    public void tightUnmarshal(OpenWireFormat wireFormat, Object o, DataInput dataIn, BooleanStream bs) throws IOException {"" ) ; out . println ( ""        super.tightUnmarshal(wireFormat, o, dataIn, bs);"" ) ; if ( ! getProperties ( ) . isEmpty ( ) ) { out . println ( """" ) ; out . println ( ""        "" + getJclass ( ) . getSimpleName ( ) + "" info = ("" + getJclass ( ) . getSimpleName ( ) + "")o;"" ) ; } if ( isMarshallerAware ( ) ) { out . println ( """" ) ; out . println ( ""        info.beforeUnmarshall(wireFormat);"" ) ; out . println ( ""        "" ) ; } generateTightUnmarshalBody ( out ) ; if ( isMarshallerAware ( ) ) { out . println ( """" ) ; out . println ( ""        info.afterUnmarshall(wireFormat);"" ) ; } out . println ( """" ) ; out . println ( ""    }"" ) ; out . println ( """" ) ; out . println ( """" ) ; out . println ( ""    /**"" ) ; out . println ( ""     * Write the booleans that this object uses to a BooleanStream"" ) ; out . println ( ""     */"" ) ; out . println ( ""    public int tightMarshal1(OpenWireFormat wireFormat, Object o, BooleanStream bs) throws IOException {"" ) ; if ( ! getProperties ( ) . isEmpty ( ) ) { out . println ( """" ) ; out . println ( ""        "" + getJclass ( ) . getSimpleName ( ) + "" info = ("" + getJclass ( ) . getSimpleName ( ) + "")o;"" ) ; } if ( isMarshallerAware ( ) ) { out . println ( """" ) ; out . println ( ""        info.beforeMarshall(wireFormat);"" ) ; } out . println ( """" ) ; out . println ( ""        int rc = super.tightMarshal1(wireFormat, o, bs);"" ) ; int baseSize = generateTightMarshal1Body ( out ) ; out . println ( """" ) ; out . println ( ""        return rc + "" + baseSize + "";"" ) ; out . println ( ""    }"" ) ; out . println ( """" ) ; out . println ( ""    /**"" ) ; out . println ( ""     * Write a object instance to data output stream"" ) ; out . println ( ""     *"" ) ; out . println ( ""     * @param o the instance to be marshaled"" ) ; out . println ( ""     * @param dataOut the output stream"" ) ; out . println ( ""     * @throws IOException thrown if an error occurs"" ) ; out . println ( ""     */"" ) ; out . println ( ""    public void tightMarshal2(OpenWireFormat wireFormat, Object o, DataOutput dataOut, BooleanStream bs) throws IOException {"" ) ; out . println ( ""        super.tightMarshal2(wireFormat, o, dataOut, bs);"" ) ; if ( ! getProperties ( ) . isEmpty ( ) ) { out . println ( """" ) ; out . println ( ""        "" + getJclass ( ) . getSimpleName ( ) + "" info = ("" + getJclass ( ) . getSimpleName ( ) + "")o;"" ) ; } generateTightMarshal2Body ( out ) ; if ( isMarshallerAware ( ) ) { out . println ( """" ) ; out . println ( ""        info.afterMarshall(wireFormat);"" ) ; } out . println ( """" ) ; out . println ( ""    }"" ) ; out . println ( """" ) ; out . println ( ""    /**"" ) ; out . println ( ""     * Un-marshal an object instance from the data input stream"" ) ; out . println ( ""     *"" ) ; out . println ( ""     * @param o the object to un-marshal"" ) ; out . println ( ""     * @param dataIn the data input stream to build the object from"" ) ; out . println ( ""     * @throws IOException"" ) ; out . println ( ""     */"" ) ; out . println ( ""    public void looseUnmarshal(OpenWireFormat wireFormat, Object o, DataInput dataIn) throws IOException {"" ) ; out . println ( ""        super.looseUnmarshal(wireFormat, o, dataIn);"" ) ; if ( ! getProperties ( ) . isEmpty ( ) ) { out . println ( """" ) ; out . println ( ""        "" + getJclass ( ) . getSimpleName ( ) + "" info = ("" + getJclass ( ) . getSimpleName ( ) + "")o;"" ) ; } if ( isMarshallerAware ( ) ) { out . println ( """" ) ; out . println ( ""        info.beforeUnmarshall(wireFormat);"" ) ; out . println ( ""        "" ) ; } generateLooseUnmarshalBody ( out ) ; if ( isMarshallerAware ( ) ) { out . println ( """" ) ; out . println ( ""        info.afterUnmarshall(wireFormat);"" ) ; } out . println ( """" ) ; out . println ( ""    }"" ) ; out . println ( """" ) ; out . println ( """" ) ; out . println ( ""    /**"" ) ; out . println ( ""     * Write the booleans that this object uses to a BooleanStream"" ) ; out . println ( ""     */"" ) ; out . println ( ""    public void looseMarshal(OpenWireFormat wireFormat, Object o, DataOutput dataOut) throws IOException {"" ) ; if ( ! getProperties ( ) . isEmpty ( ) ) { out . println ( """" ) ; out . println ( ""        "" + getJclass ( ) . getSimpleName ( ) + "" info = ("" + getJclass ( ) . getSimpleName ( ) + "")o;"" ) ; } if ( isMarshallerAware ( ) ) { out . println ( """" ) ; out . println ( ""        info.beforeMarshall(wireFormat);"" ) ; } out . println ( """" ) ; out . println ( ""        super.looseMarshal(wireFormat, o, dataOut);"" ) ; generateLooseMarshalBody ( out ) ; out . println ( """" ) ; out . println ( ""    }"" ) ; out . println ( ""}"" ) ; } private void generateLicence ( PrintWriter out ) { out . println ( ""/**"" ) ; out . println ( "" *"" ) ; out . println ( "" * Licensed to the Apache Software Foundation (ASF) under one or more"" ) ; out . println ( "" * contributor license agreements.  See the NOTICE file distributed with"" ) ; out . println ( "" * this work for additional information regarding copyright ownership."" ) ; out . println ( "" * The ASF licenses this file to You under the Apache License, Version 2.0"" ) ; out . println ( "" * (the \""License\""); you may not use this file except in compliance with"" ) ; out . println ( "" * the License.  You may obtain a copy of the License at"" ) ; out . println ( "" *"" ) ; out . println ( "" * http://www.apache.org/licenses/LICENSE-2.0"" ) ; out . println ( "" *"" ) ; out . println ( "" * Unless required by applicable law or agreed to in writing, software"" ) ; out . println ( "" * distributed under the License is distributed on an \""AS IS\"" BASIS,"" ) ; out . println ( "" * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied."" ) ; out . println ( "" * See the License for the specific language governing permissions and"" ) ; out . println ( "" * limitations under the License."" ) ; out . println ( "" */"" ) ; } protected void processFactory ( ) { if ( factoryFile == null ) { factoryFile = new File ( destDir , factoryFileName + filePostFix ) ; } PrintWriter out = null ; try { out = new PrintWriter ( new FileWriter ( factoryFile ) ) ; generateFactory ( out ) ; } catch ( Exception e ) { throw new RuntimeException ( e ) ; } finally { if ( out != null ) { out . close ( ) ; } } } protected void generateFactory ( PrintWriter out ) { generateLicence ( out ) ; out . println ( """" ) ; out . println ( ""package org.apache.activemq.openwire.v"" + getOpenwireVersion ( ) + "";"" ) ; out . println ( """" ) ; out . println ( ""import org.apache.activemq.openwire.DataStreamMarshaller;"" ) ; out . println ( ""import org.apache.activemq.openwire.OpenWireFormat;"" ) ; out . println ( """" ) ; out . println ( ""/**"" ) ; out . println ( "" * MarshallerFactory for Open Wire Format."" ) ; out . println ( "" *"" ) ; out . println ( "" *"" ) ; out . println ( "" * NOTE!: This file is auto generated - do not modify!"" ) ; out . println ( "" *        if you need to make a change, please see the modify the groovy scripts in the"" ) ; out . println ( "" *        under src/gram/script and then use maven openwire:generate to regenerate "" ) ; out . println ( "" *        this file."" ) ; out . println ( "" *"" ) ; out . println ( "" * "" ) ; out . println ( "" */"" ) ; out . println ( ""public class MarshallerFactory {"" ) ; out . println ( """" ) ; out . println ( ""    /**"" ) ; out . println ( ""     * Creates a Map of command type -> Marshallers"" ) ; out . println ( ""     */"" ) ; out . println ( ""    static final private DataStreamMarshaller marshaller[] = new DataStreamMarshaller[256];"" ) ; out . println ( ""    static {"" ) ; out . println ( """" ) ; List < JClass > list = new ArrayList < JClass > ( getConcreteClasses ( ) ) ; Collections . sort ( list , new Comparator ( ) { public int compare ( Object o1 , Object o2 ) { JClass c1 = ( JClass ) o1 ; JClass c2 = ( JClass ) o2 ; return c1 . getSimpleName ( ) . compareTo ( c2 . getSimpleName ( ) ) ; } } ) ; for ( Iterator < JClass > iter = list . iterator ( ) ; iter . hasNext ( ) ; ) { JClass jclass = iter . next ( ) ; out . println ( ""        add(new "" + jclass . getSimpleName ( ) + ""Marshaller());"" ) ; } out . println ( """" ) ; out . println ( ""    }"" ) ; out . println ( """" ) ; out . println ( ""    static private void add(DataStreamMarshaller dsm) {"" ) ; out . println ( ""        marshaller[dsm.getDataStructureType()] = dsm;"" ) ; out . println ( ""    }"" ) ; out . println ( ""    "" ) ; out . println ( ""    static public DataStreamMarshaller[] createMarshallerMap(OpenWireFormat wireFormat) {"" ) ; out . println ( ""        return marshaller;"" ) ; out . println ( ""    }"" ) ; out . println ( ""}"" ) ; } protected void processClass ( JClass jclass ) { super . processClass ( jclass ) ; if ( ! jclass . isAbstract ( ) ) { concreteClasses . add ( jclass ) ; } } protected String getClassName ( JClass jclass ) { return super . getClassName ( jclass ) + ""Marshaller"" ; } protected String getBaseClassName ( JClass jclass ) { String answer = ""BaseDataStreamMarshaller"" ; JClass superclass = jclass . getSuperclass ( ) ; if ( superclass != null ) { String superName = superclass . getSimpleName ( ) ; if ( ! superName . equals ( ""Object"" ) && ! superName . equals ( ""JNDIBaseStorable"" ) && ! superName . equals ( ""DataStructureSupport"" ) ) { answer = superName + ""Marshaller"" ; } } return answer ; } protected void initialiseManuallyMaintainedClasses ( ) { } protected void generateTightUnmarshalBody ( PrintWriter out ) { List properties = getProperties ( ) ; for ( Iterator iter = properties . iterator ( ) ; iter . hasNext ( ) ; ) { JProperty property = ( JProperty ) iter . next ( ) ; JAnnotation annotation = property . getAnnotation ( ""openwire:property"" ) ; JAnnotationValue size = annotation . getValue ( ""size"" ) ; JClass propertyType = property . getType ( ) ; String propertyTypeName = propertyType . getSimpleName ( ) ; if ( propertyType . isArrayType ( ) && ! propertyTypeName . equals ( ""byte[]"" ) ) { generateTightUnmarshalBodyForArrayProperty ( out , property , size ) ; } else { generateTightUnmarshalBodyForProperty ( out , property , size ) ; } } } protected void generateTightUnmarshalBodyForProperty ( PrintWriter out , JProperty property , JAnnotationValue size ) { String setter = property . getSetter ( ) . getSimpleName ( ) ; String type = property . getType ( ) . getSimpleName ( ) ; if ( type . equals ( ""boolean"" ) ) { out . println ( ""        info."" + setter + ""(bs.readBoolean());"" ) ; } else if ( type . equals ( ""byte"" ) ) { out . println ( ""        info."" + setter + ""(dataIn.readByte());"" ) ; } else if ( type . equals ( ""char"" ) ) { out . println ( ""        info."" + setter + ""(dataIn.readChar());"" ) ; } else if ( type . equals ( ""short"" ) ) { out . println ( ""        info."" + setter + ""(dataIn.readShort());"" ) ; } else if ( type . equals ( ""int"" ) ) { out . println ( ""        info."" + setter + ""(dataIn.readInt());"" ) ; } else if ( type . equals ( ""long"" ) ) { out . println ( ""        info."" + setter + ""(tightUnmarshalLong(wireFormat, dataIn, bs));"" ) ; } else if ( type . equals ( ""String"" ) ) { out . println ( ""        info."" + setter + ""(tightUnmarshalString(dataIn, bs));"" ) ; } else if ( type . equals ( ""byte[]"" ) ) { if ( size != null ) { out . println ( ""        info."" + setter + ""(tightUnmarshalConstByteArray(dataIn, bs, "" + size . asInt ( ) + ""));"" ) ; } else { out . println ( ""        info."" + setter + ""(tightUnmarshalByteArray(dataIn, bs));"" ) ; } } else if ( type . equals ( ""ByteSequence"" ) ) { out . println ( ""        info."" + setter + ""(tightUnmarshalByteSequence(dataIn, bs));"" ) ; } else if ( isThrowable ( property . getType ( ) ) ) { out . println ( ""        info."" + setter + ""(("" + property . getType ( ) . getQualifiedName ( ) + "") tightUnmarsalThrowable(wireFormat, dataIn, bs));"" ) ; } else if ( isCachedProperty ( property ) ) { out . println ( ""        info."" + setter + ""(("" + property . getType ( ) . getQualifiedName ( ) + "") tightUnmarsalCachedObject(wireFormat, dataIn, bs));"" ) ; } else { out . println ( ""        info."" + setter + ""(("" + property . getType ( ) . getQualifiedName ( ) + "") tightUnmarsalNestedObject(wireFormat, dataIn, bs));"" ) ; } } protected void generateTightUnmarshalBodyForArrayProperty ( PrintWriter out , JProperty property , JAnnotationValue size ) { JClass propertyType = property . getType ( ) ; String arrayType = propertyType . getArrayComponentType ( ) . getQualifiedName ( ) ; String setter = property . getSetter ( ) . getSimpleName ( ) ; out . println ( ) ; if ( size != null ) { out . println ( ""        {"" ) ; out . println ( ""            "" + arrayType + "" value[] = new "" + arrayType + ""["" + size . asInt ( ) + ""];"" ) ; out . println ( ""            "" + ""for( int i=0; i < "" + size . asInt ( ) + ""; i++ ) {"" ) ; out . println ( ""                value[i] = ("" + arrayType + "") tightUnmarsalNestedObject(wireFormat,dataIn, bs);"" ) ; out . println ( ""            }"" ) ; out . println ( ""            info."" + setter + ""(value);"" ) ; out . println ( ""        }"" ) ; } else { out . println ( ""        if (bs.readBoolean()) {"" ) ; out . println ( ""            short size = dataIn.readShort();"" ) ; out . println ( ""            "" + arrayType + "" value[] = new "" + arrayType + ""[size];"" ) ; out . println ( ""            for( int i=0; i < size; i++ ) {"" ) ; out . println ( ""                value[i] = ("" + arrayType + "") tightUnmarsalNestedObject(wireFormat,dataIn, bs);"" ) ; out . println ( ""            }"" ) ; out . println ( ""            info."" + setter + ""(value);"" ) ; out . println ( ""        }"" ) ; out . println ( ""        else {"" ) ; out . println ( ""            info."" + setter + ""(null);"" ) ; out . println ( ""        }"" ) ; } } protected int generateTightMarshal1Body ( PrintWriter out ) { List properties = getProperties ( ) ; int baseSize = 0 ; for ( Iterator iter = properties . iterator ( ) ; iter . hasNext ( ) ; ) { JProperty property = ( JProperty ) iter . next ( ) ; JAnnotation annotation = property . getAnnotation ( ""openwire:property"" ) ; JAnnotationValue size = annotation . getValue ( ""size"" ) ; JClass propertyType = property . getType ( ) ; String type = propertyType . getSimpleName ( ) ; String getter = ""info."" + property . getGetter ( ) . getSimpleName ( ) + ""()"" ; if ( type . equals ( ""boolean"" ) ) { out . println ( ""        bs.writeBoolean("" + getter + "");"" ) ; } else if ( type . equals ( ""byte"" ) ) { baseSize += 1 ; } else if ( type . equals ( ""char"" ) ) { baseSize += 2 ; } else if ( type . equals ( ""short"" ) ) { baseSize += 2 ; } else if ( type . equals ( ""int"" ) ) { baseSize += 4 ; } else if ( type . equals ( ""long"" ) ) { out . println ( ""        rc+=tightMarshalLong1(wireFormat, "" + getter + "", bs);"" ) ; } else if ( type . equals ( ""String"" ) ) { out . println ( ""        rc += tightMarshalString1("" + getter + "", bs);"" ) ; } else if ( type . equals ( ""byte[]"" ) ) { if ( size == null ) { out . println ( ""        rc += tightMarshalByteArray1("" + getter + "", bs);"" ) ; } else { out . println ( ""        rc += tightMarshalConstByteArray1("" + getter + "", bs, "" + size . asInt ( ) + "");"" ) ; } } else if ( type . equals ( ""ByteSequence"" ) ) { out . println ( ""        rc += tightMarshalByteSequence1("" + getter + "", bs);"" ) ; } else if ( propertyType . isArrayType ( ) ) { if ( size != null ) { out . println ( ""        rc += tightMarshalObjectArrayConstSize1(wireFormat, "" + getter + "", bs, "" + size . asInt ( ) + "");"" ) ; } else { out . println ( ""        rc += tightMarshalObjectArray1(wireFormat, "" + getter + "", bs);"" ) ; } } else if ( isThrowable ( propertyType ) ) { out . println ( ""        rc += tightMarshalThrowable1(wireFormat, "" + getter + "", bs);"" ) ; } else { if ( isCachedProperty ( property ) ) { out . println ( ""        rc += tightMarshalCachedObject1(wireFormat, (DataStructure)"" + getter + "", bs);"" ) ; } else { out . println ( ""        rc += tightMarshalNestedObject1(wireFormat, (DataStructure)"" + getter + "", bs);"" ) ; } } } return baseSize ; } protected void generateTightMarshal2Body ( PrintWriter out ) { List properties = getProperties ( ) ; for ( Iterator iter = properties . iterator ( ) ; iter . hasNext ( ) ; ) { JProperty property = ( JProperty ) iter . next ( ) ; JAnnotation annotation = property . getAnnotation ( ""openwire:property"" ) ; JAnnotationValue size = annotation . getValue ( ""size"" ) ; JClass propertyType = property . getType ( ) ; String type = propertyType . getSimpleName ( ) ; String getter = ""info."" + property . getGetter ( ) . getSimpleName ( ) + ""()"" ; if ( type . equals ( ""boolean"" ) ) { out . println ( ""        bs.readBoolean();"" ) ; } else if ( type . equals ( ""byte"" ) ) { out . println ( ""        dataOut.writeByte("" + getter + "");"" ) ; } else if ( type . equals ( ""char"" ) ) { out . println ( ""        dataOut.writeChar("" + getter + "");"" ) ; } else if ( type . equals ( ""short"" ) ) { out . println ( ""        dataOut.writeShort("" + getter + "");"" ) ; } else if ( type . equals ( ""int"" ) ) { out . println ( ""        dataOut.writeInt("" + getter + "");"" ) ; } else if ( type . equals ( ""long"" ) ) { out . println ( ""        tightMarshalLong2(wireFormat, "" + getter + "", dataOut, bs);"" ) ; } else if ( type . equals ( ""String"" ) ) { out . println ( ""        tightMarshalString2("" + getter + "", dataOut, bs);"" ) ; } else if ( type . equals ( ""byte[]"" ) ) { if ( size != null ) { out . println ( ""        tightMarshalConstByteArray2("" + getter + "", dataOut, bs, "" + size . asInt ( ) + "");"" ) ; } else { out . println ( ""        tightMarshalByteArray2("" + getter + "", dataOut, bs);"" ) ; } } else if ( type . equals ( ""ByteSequence"" ) ) { out . println ( ""        tightMarshalByteSequence2("" + getter + "", dataOut, bs);"" ) ; } else if ( propertyType . isArrayType ( ) ) { if ( size != null ) { out . println ( ""        tightMarshalObjectArrayConstSize2(wireFormat, "" + getter + "", dataOut, bs, "" + size . asInt ( ) + "");"" ) ; } else { out . println ( ""        tightMarshalObjectArray2(wireFormat, "" + getter + "", dataOut, bs);"" ) ; } } else if ( isThrowable ( propertyType ) ) { out . println ( ""        tightMarshalThrowable2(wireFormat, "" + getter + "", dataOut, bs);"" ) ; } else { if ( isCachedProperty ( property ) ) { out . println ( ""        tightMarshalCachedObject2(wireFormat, (DataStructure)"" + getter + "", dataOut, bs);"" ) ; } else { out . println ( ""        tightMarshalNestedObject2(wireFormat, (DataStructure)"" + getter + "", dataOut, bs);"" ) ; } } } } protected void generateLooseMarshalBody ( PrintWriter out ) { List properties = getProperties ( ) ; for ( Iterator iter = properties . iterator ( ) ; iter . hasNext ( ) ; ) { JProperty property = ( JProperty ) iter . next ( ) ; JAnnotation annotation = property . getAnnotation ( ""openwire:property"" ) ; JAnnotationValue size = annotation . getValue ( ""size"" ) ; JClass propertyType = property . getType ( ) ; String type = propertyType . getSimpleName ( ) ; String getter = ""info."" + property . getGetter ( ) . getSimpleName ( ) + ""()"" ; if ( type . equals ( ""boolean"" ) ) { out . println ( ""        dataOut.writeBoolean("" + getter + "");"" ) ; } else if ( type . equals ( ""byte"" ) ) { out . println ( ""        dataOut.writeByte("" + getter + "");"" ) ; } else if ( type . equals ( ""char"" ) ) { out . println ( ""        dataOut.writeChar("" + getter + "");"" ) ; } else if ( type . equals ( ""short"" ) ) { out . println ( ""        dataOut.writeShort("" + getter + "");"" ) ; } else if ( type . equals ( ""int"" ) ) { out . println ( ""        dataOut.writeInt("" + getter + "");"" ) ; } else if ( type . equals ( ""long"" ) ) { out . println ( ""        looseMarshalLong(wireFormat, "" + getter + "", dataOut);"" ) ; } else if ( type . equals ( ""String"" ) ) { out . println ( ""        looseMarshalString("" + getter + "", dataOut);"" ) ; } else if ( type . equals ( ""byte[]"" ) ) { if ( size != null ) { out . println ( ""        looseMarshalConstByteArray(wireFormat, "" + getter + "", dataOut, "" + size . asInt ( ) + "");"" ) ; } else { out . println ( ""        looseMarshalByteArray(wireFormat, "" + getter + "", dataOut);"" ) ; } } else if ( type . equals ( ""ByteSequence"" ) ) { out . println ( ""        looseMarshalByteSequence(wireFormat, "" + getter + "", dataOut);"" ) ; } else if ( propertyType . isArrayType ( ) ) { if ( size != null ) { out . println ( ""        looseMarshalObjectArrayConstSize(wireFormat, "" + getter + "", dataOut, "" + size . asInt ( ) + "");"" ) ; } else { out . println ( ""        looseMarshalObjectArray(wireFormat, "" + getter + "", dataOut);"" ) ; } } else if ( isThrowable ( propertyType ) ) { out . println ( ""        looseMarshalThrowable(wireFormat, "" + getter + "", dataOut);"" ) ; } else { if ( isCachedProperty ( property ) ) { out . println ( ""        looseMarshalCachedObject(wireFormat, (DataStructure)"" + getter + "", dataOut);"" ) ; } else { out . println ( ""        looseMarshalNestedObject(wireFormat, (DataStructure)"" + getter + "", dataOut);"" ) ; } } } } protected void generateLooseUnmarshalBody ( PrintWriter out ) { List properties = getProperties ( ) ; for ( Iterator iter = properties . iterator ( ) ; iter . hasNext ( ) ; ) { JProperty property = ( JProperty ) iter . next ( ) ; JAnnotation annotation = property . getAnnotation ( ""openwire:property"" ) ; JAnnotationValue size = annotation . getValue ( ""size"" ) ; JClass propertyType = property . getType ( ) ; String propertyTypeName = propertyType . getSimpleName ( ) ; if ( propertyType . isArrayType ( ) && ! propertyTypeName . equals ( ""byte[]"" ) ) { generateLooseUnmarshalBodyForArrayProperty ( out , property , size ) ; } else { generateLooseUnmarshalBodyForProperty ( out , property , size ) ; } } } protected void generateLooseUnmarshalBodyForProperty ( PrintWriter out , JProperty property , JAnnotationValue size ) { String setter = property . getSetter ( ) . getSimpleName ( ) ; String type = property . getType ( ) . getSimpleName ( ) ; if ( type . equals ( ""boolean"" ) ) { out . println ( ""        info."" + setter + ""(dataIn.readBoolean());"" ) ; } else if ( type . equals ( ""byte"" ) ) { out . println ( ""        info."" + setter + ""(dataIn.readByte());"" ) ; } else if ( type . equals ( ""char"" ) ) { out . println ( ""        info."" + setter + ""(dataIn.readChar());"" ) ; } else if ( type . equals ( ""short"" ) ) { out . println ( ""        info."" + setter + ""(dataIn.readShort());"" ) ; } else if ( type . equals ( ""int"" ) ) { out . println ( ""        info."" + setter + ""(dataIn.readInt());"" ) ; } else if ( type . equals ( ""long"" ) ) { out . println ( ""        info."" + setter + ""(looseUnmarshalLong(wireFormat, dataIn));"" ) ; } else if ( type . equals ( ""String"" ) ) { out . println ( ""        info."" + setter + ""(looseUnmarshalString(dataIn));"" ) ; } else if ( type . equals ( ""byte[]"" ) ) { if ( size != null ) { out . println ( ""        info."" + setter + ""(looseUnmarshalConstByteArray(dataIn, "" + size . asInt ( ) + ""));"" ) ; } else { out . println ( ""        info."" + setter + ""(looseUnmarshalByteArray(dataIn));"" ) ; } } else if ( type . equals ( ""ByteSequence"" ) ) { out . println ( ""        info."" + setter + ""(looseUnmarshalByteSequence(dataIn));"" ) ; } else if ( isThrowable ( property . getType ( ) ) ) { out . println ( ""        info."" + setter + ""(("" + property . getType ( ) . getQualifiedName ( ) + "") looseUnmarsalThrowable(wireFormat, dataIn));"" ) ; } else if ( isCachedProperty ( property ) ) { out . println ( ""        info."" + setter + ""(("" + property . getType ( ) . getQualifiedName ( ) + "") looseUnmarsalCachedObject(wireFormat, dataIn));"" ) ; } else { out . println ( ""        info."" + setter + ""(("" + property . getType ( ) . getQualifiedName ( ) + "") looseUnmarsalNestedObject(wireFormat, dataIn));"" ) ; } } protected void generateLooseUnmarshalBodyForArrayProperty ( PrintWriter out , JProperty property , JAnnotationValue size ) { JClass propertyType = property . getType ( ) ; String arrayType = propertyType . getArrayComponentType ( ) . getQualifiedName ( ) ; String setter = property . getSetter ( ) . getSimpleName ( ) ; out . println ( ) ; if ( size != null ) { out . println ( ""        {"" ) ; out . println ( ""            "" + arrayType + "" value[] = new "" + arrayType + ""["" + size . asInt ( ) + ""];"" ) ; out . println ( ""            "" + ""for( int i=0; i < "" + size . asInt ( ) + ""; i++ ) {"" ) ; out . println ( ""                value[i] = ("" + arrayType + "") looseUnmarsalNestedObject(wireFormat,dataIn);"" ) ; out . println ( ""            }"" ) ; out . println ( ""            info."" + setter + ""(value);"" ) ; out . println ( ""        }"" ) ; } else { out . println ( ""        if (dataIn.readBoolean()) {"" ) ; out . println ( ""            short size = dataIn.readShort();"" ) ; out . println ( ""            "" + arrayType + "" value[] = new "" + arrayType + ""[size];"" ) ; out . println ( ""            for( int i=0; i < size; i++ ) {"" ) ; out . println ( ""                value[i] = ("" + arrayType + "") looseUnmarsalNestedObject(wireFormat,dataIn);"" ) ; out . println ( ""            }"" ) ; out . println ( ""            info."" + setter + ""(value);"" ) ; out . println ( ""        }"" ) ; out . println ( ""        else {"" ) ; out . println ( ""            info."" + setter + ""(null);"" ) ; out . println ( ""        }"" ) ; } } protected String getMandatoryFlag ( JAnnotation annotation ) { JAnnotationValue value = annotation . getValue ( ""mandatory"" ) ; if ( value != null ) { String text = value . asString ( ) ; if ( text != null && text . equalsIgnoreCase ( ""true"" ) ) { return ""true"" ; } } return ""false"" ; } public List < JClass > getConcreteClasses ( ) { return concreteClasses ; } public void setConcreteClasses ( List < JClass > concreteClasses ) { this . concreteClasses = concreteClasses ; } public File getFactoryFile ( ) { return factoryFile ; } public void setFactoryFile ( File factoryFile ) { this . factoryFile = factoryFile ; } public String getFactoryFileName ( ) { return factoryFileName ; } public void setFactoryFileName ( String factoryFileName ) { this . factoryFileName = factoryFileName ; } public String getIndent ( ) { return indent ; } public void setIndent ( String indent ) { this . indent = indent ; } public String getTargetDir ( ) { return targetDir ; } public void setTargetDir ( String sourceDir ) { this . targetDir = sourceDir ; } }",Smelly
"public class BatchMessageAckerTest { private static final int BATCH_SIZE = 10 ; private BatchMessageAcker acker ; @ BeforeMethod public void setup ( ) { acker = BatchMessageAcker . newAcker ( 10 ) ; } @ Test public void testAckers ( ) { assertEquals ( BATCH_SIZE , acker . getOutstandingAcks ( ) ) ; assertEquals ( BATCH_SIZE , acker . getBatchSize ( ) ) ; assertFalse ( acker . ackIndividual ( 4 ) ) ; for ( int i = 0 ; i < BATCH_SIZE ; i ++ ) { if ( 4 == i ) { assertFalse ( acker . getBitSet ( ) . get ( i ) ) ; } else { assertTrue ( acker . getBitSet ( ) . get ( i ) ) ; } } assertFalse ( acker . ackCumulative ( 6 ) ) ; for ( int i = 0 ; i < BATCH_SIZE ; i ++ ) { if ( i <= 6 ) { assertFalse ( acker . getBitSet ( ) . get ( i ) ) ; } else { assertTrue ( acker . getBitSet ( ) . get ( i ) ) ; } } for ( int i = BATCH_SIZE - 1 ; i >= 8 ; i -- ) { assertFalse ( acker . ackIndividual ( i ) ) ; assertFalse ( acker . getBitSet ( ) . get ( i ) ) ; } assertTrue ( acker . ackIndividual ( 7 ) ) ; assertEquals ( 0 , acker . getOutstandingAcks ( ) ) ; } }",No
public class ControllerFactoryImpl extends AbstractFactory implements ControllerFactory { public Controller get ( Model model ) { if ( model instanceof UnmodifiableSet ) { model = ( Model ) ( ( UnmodifiableSet ) model ) . getModifiableSet ( ) ; } return ( Controller ) model ; } },No
"public class ImageValidator implements ConstraintValidator < ImageConstraint , Image > { private List < ImageType > allowedTypes = null ; public void initialize ( ImageConstraint constraint ) { allowedTypes = Arrays . asList ( constraint . value ( ) ) ; } public boolean isValid ( Image value , ConstraintValidatorContext context ) { if ( value == null ) { return true ; } byte [ ] data = value . getData ( ) ; String fileName = value . getFileName ( ) ; ImageType type = value . getType ( ) ; if ( allowedTypes . contains ( ImageType . GIF ) && type == ImageType . GIF && fileName . endsWith ( "".gif"" ) ) { if ( data != null && data . length >= 6 ) { String gifHeader = new String ( data , 0 , 6 ) ; if ( gifHeader . equalsIgnoreCase ( ""GIF87a"" ) || gifHeader . equalsIgnoreCase ( ""GIF89a"" ) ) { return true ; } } } if ( allowedTypes . contains ( ImageType . JPEG ) && value . getType ( ) == ImageType . JPEG && ( fileName . endsWith ( "".jpg"" ) || fileName . endsWith ( "".jpeg"" ) ) ) { if ( data . length >= 4 && data [ 0 ] == 0xff && data [ 1 ] == 0xd8 && data [ data . length - 2 ] == 0xff && data [ data . length - 1 ] == 0xd9 ) { return true ; } } return false ; } }",No
"class DummyOptimizer extends AbstractLeastSquaresOptimizer { public DummyOptimizer ( ) { super ( null ) ; } @ Override public PointVectorValuePair doOptimize ( ) { final double [ ] params = getStartPoint ( ) ; final double [ ] res = computeResiduals ( computeObjectiveValue ( params ) ) ; setCost ( computeCost ( res ) ) ; return new PointVectorValuePair ( params , null ) ; } }",No
"public class PageBreaker extends AbstractBreaker { private boolean firstPart = true ; private boolean pageBreakHandled ; private boolean needColumnBalancing ; private PageProvider pageProvider ; private Block separatorArea ; private boolean spanAllActive ; private boolean layoutRedone ; private int previousIndex ; private boolean handlingStartOfFloat ; private boolean handlingEndOfFloat ; private int floatHeight ; private int floatYOffset ; private List relayedFootnotesList ; private List relayedLengthList ; private int relayedTotalFootnotesLength ; private int relayedInsertedFootnotesLength ; private boolean relayedFootnotesPending ; private boolean relayedNewFootnotes ; private int relayedFirstNewFootnoteIndex ; private int relayedFootnoteListIndex ; private int relayedFootnoteElementIndex = - 1 ; private MinOptMax relayedFootnoteSeparatorLength ; private int previousFootnoteListIndex = - 2 ; private int previousFootnoteElementIndex = - 2 ; private FlowLayoutManager childFLM ; private StaticContentLayoutManager footnoteSeparatorLM ; public PageBreaker ( PageSequenceLayoutManager pslm ) { this . pslm = pslm ; this . pageProvider = pslm . getPageProvider ( ) ; this . childFLM = pslm . getLayoutManagerMaker ( ) . makeFlowLayoutManager ( pslm , pslm . getPageSequence ( ) . getMainFlow ( ) ) ; } protected void updateLayoutContext ( LayoutContext context ) { int flowIPD = pslm . getCurrentColumnWidth ( ) ; context . setRefIPD ( flowIPD ) ; } protected LayoutManager getTopLevelLM ( ) { return pslm ; } protected PageProvider getPageProvider ( ) { return pslm . getPageProvider ( ) ; } boolean doLayout ( int flowBPD ) { return doLayout ( flowBPD , false ) ; } protected PageBreakingLayoutListener createLayoutListener ( ) { return new PageBreakingLayoutListener ( ) { public void notifyOverflow ( int part , int amount , FObj obj ) { Page p = pageProvider . getPageFromColumnIndex ( part ) ; RegionBody body = ( RegionBody ) p . getSimplePageMaster ( ) . getRegion ( Region . FO_REGION_BODY ) ; BlockLevelEventProducer eventProducer = BlockLevelEventProducer . Provider . get ( body . getUserAgent ( ) . getEventBroadcaster ( ) ) ; boolean canRecover = ( body . getOverflow ( ) != Constants . EN_ERROR_IF_OVERFLOW ) ; boolean needClip = ( body . getOverflow ( ) == Constants . EN_HIDDEN || body . getOverflow ( ) == Constants . EN_ERROR_IF_OVERFLOW ) ; eventProducer . regionOverflow ( this , body . getName ( ) , p . getPageViewport ( ) . getPageNumberString ( ) , amount , needClip , canRecover , body . getLocator ( ) ) ; } } ; } protected int handleSpanChange ( LayoutContext childLC , int nextSequenceStartsOn ) { needColumnBalancing = false ; if ( childLC . getNextSpan ( ) != Constants . NOT_SET ) { nextSequenceStartsOn = childLC . getNextSpan ( ) ; needColumnBalancing = childLC . getNextSpan ( ) == Constants . EN_ALL && childLC . getDisableColumnBalancing ( ) == Constants . EN_FALSE ; } if ( needColumnBalancing ) { log . debug ( ""Column balancing necessary for the next element list!!!"" ) ; } return nextSequenceStartsOn ; } protected int getNextBlockList ( LayoutContext childLC , int nextSequenceStartsOn ) { return getNextBlockList ( childLC , nextSequenceStartsOn , null , null , null ) ; } protected int getNextBlockList ( LayoutContext childLC , int nextSequenceStartsOn , Position positionAtIPDChange , LayoutManager restartLM , List firstElements ) { if ( ! layoutRedone && ! handlingFloat ( ) ) { if ( ! firstPart ) { handleBreakTrait ( nextSequenceStartsOn ) ; } firstPart = false ; pageBreakHandled = true ; pageProvider . setStartOfNextElementList ( pslm . getCurrentPageNum ( ) , pslm . getCurrentPV ( ) . getCurrentSpan ( ) . getCurrentFlowIndex ( ) , this . spanAllActive ) ; } return super . getNextBlockList ( childLC , nextSequenceStartsOn , positionAtIPDChange , restartLM , firstElements ) ; } private boolean containsFootnotes ( List contentList , LayoutContext context ) { boolean containsFootnotes = false ; if ( contentList != null ) { for ( Object aContentList : contentList ) { ListElement element = ( ListElement ) aContentList ; if ( element instanceof KnuthBlockBox && ( ( KnuthBlockBox ) element ) . hasAnchors ( ) ) { containsFootnotes = true ; KnuthBlockBox box = ( KnuthBlockBox ) element ; List < List < KnuthElement > > footnotes = getFootnoteKnuthElements ( childFLM , context , box . getFootnoteBodyLMs ( ) ) ; for ( List < KnuthElement > footnote : footnotes ) { box . addElementList ( footnote ) ; } } } } return containsFootnotes ; } public static List < List < KnuthElement > > getFootnoteKnuthElements ( FlowLayoutManager flowLM , LayoutContext context , List < FootnoteBodyLayoutManager > footnoteBodyLMs ) { List < List < KnuthElement > > footnotes = new ArrayList < List < KnuthElement > > ( ) ; LayoutContext footnoteContext = LayoutContext . copyOf ( context ) ; footnoteContext . setStackLimitBP ( context . getStackLimitBP ( ) ) ; footnoteContext . setRefIPD ( flowLM . getPSLM ( ) . getCurrentPV ( ) . getRegionReference ( Constants . FO_REGION_BODY ) . getIPD ( ) ) ; for ( FootnoteBodyLayoutManager fblm : footnoteBodyLMs ) { fblm . setParent ( flowLM ) ; fblm . initialize ( ) ; List < KnuthElement > footnote = fblm . getNextKnuthElements ( footnoteContext , Constants . EN_START ) ; SpaceResolver . resolveElementList ( footnote ) ; footnotes . add ( footnote ) ; } return footnotes ; } private void handleFootnoteSeparator ( ) { StaticContent footnoteSeparator ; footnoteSeparator = pslm . getPageSequence ( ) . getStaticContent ( ""xsl-footnote-separator"" ) ; if ( footnoteSeparator != null ) { separatorArea = new Block ( ) ; separatorArea . setIPD ( pslm . getCurrentPV ( ) . getRegionReference ( Constants . FO_REGION_BODY ) . getIPD ( ) ) ; footnoteSeparatorLM = pslm . getLayoutManagerMaker ( ) . makeStaticContentLayoutManager ( pslm , footnoteSeparator , separatorArea ) ; footnoteSeparatorLM . doLayout ( ) ; footnoteSeparatorLength = MinOptMax . getInstance ( separatorArea . getBPD ( ) ) ; } } protected List getNextKnuthElements ( LayoutContext context , int alignment ) { List contentList = null ; while ( ! childFLM . isFinished ( ) && contentList == null ) { contentList = childFLM . getNextKnuthElements ( context , alignment ) ; } if ( containsFootnotes ( contentList , context ) ) { handleFootnoteSeparator ( ) ; } return contentList ; } protected List getNextKnuthElements ( LayoutContext context , int alignment , Position positionAtIPDChange , LayoutManager restartAtLM ) { List contentList = null ; do { contentList = childFLM . getNextKnuthElements ( context , alignment , positionAtIPDChange , restartAtLM ) ; } while ( ! childFLM . isFinished ( ) && contentList == null ) ; if ( containsFootnotes ( contentList , context ) ) { handleFootnoteSeparator ( ) ; } return contentList ; } protected int getCurrentDisplayAlign ( ) { return pslm . getCurrentPage ( ) . getSimplePageMaster ( ) . getRegion ( Constants . FO_REGION_BODY ) . getDisplayAlign ( ) ; } protected boolean hasMoreContent ( ) { return ! childFLM . isFinished ( ) ; } protected void addAreas ( PositionIterator posIter , LayoutContext context ) { if ( footnoteSeparatorLM != null ) { StaticContent footnoteSeparator = pslm . getPageSequence ( ) . getStaticContent ( ""xsl-footnote-separator"" ) ; separatorArea = new Block ( ) ; separatorArea . setIPD ( pslm . getCurrentPV ( ) . getRegionReference ( Constants . FO_REGION_BODY ) . getIPD ( ) ) ; footnoteSeparatorLM = pslm . getLayoutManagerMaker ( ) . makeStaticContentLayoutManager ( pslm , footnoteSeparator , separatorArea ) ; footnoteSeparatorLM . doLayout ( ) ; } childFLM . addAreas ( posIter , context ) ; } protected void doPhase3 ( PageBreakingAlgorithm alg , int partCount , BlockSequence originalList , BlockSequence effectiveList ) { if ( needColumnBalancing ) { redoLayout ( alg , partCount , originalList , effectiveList ) ; return ; } if ( shouldRedoLayout ( partCount ) ) { redoLayout ( alg , partCount , originalList , effectiveList ) ; return ; } addAreas ( alg , partCount , originalList , effectiveList ) ; } protected void prepareToRedoLayout ( PageBreakingAlgorithm alg , int partCount , BlockSequence originalList , BlockSequence effectiveList ) { int newStartPos = 0 ; int restartPoint = pageProvider . getStartingPartIndexForLastPage ( partCount ) ; if ( restartPoint > 0 && ! layoutRedone ) { addAreas ( alg , restartPoint , originalList , effectiveList ) ; PageBreakPosition pbp = alg . getPageBreaks ( ) . get ( restartPoint - 1 ) ; newStartPos = alg . par . getFirstBoxIndex ( pbp . getLeafPos ( ) + 1 ) ; if ( newStartPos > 0 ) { handleBreakTrait ( Constants . EN_PAGE ) ; } } pageBreakHandled = true ; int currentPageNum = pslm . getCurrentPageNum ( ) ; int currentColumn = pslm . getCurrentPV ( ) . getCurrentSpan ( ) . getCurrentFlowIndex ( ) ; pageProvider . setStartOfNextElementList ( currentPageNum , currentColumn , spanAllActive ) ; effectiveList . ignoreAtStart = newStartPos ; if ( ! layoutRedone ) { setLastPageIndex ( currentPageNum ) ; pslm . setCurrentPage ( pageProvider . getPage ( false , currentPageNum ) ) ; previousIndex = pageProvider . getIndexOfCachedLastPage ( ) ; } else { setLastPageIndex ( currentPageNum + 1 ) ; pageProvider . discardCacheStartingWith ( previousIndex ) ; pslm . setCurrentPage ( pageProvider . getPage ( false , currentPageNum ) ) ; } layoutRedone = true ; } private void redoLayout ( PageBreakingAlgorithm alg , int partCount , BlockSequence originalList , BlockSequence effectiveList ) { int newStartPos = 0 ; int restartPoint = pageProvider . getStartingPartIndexForLastPage ( partCount ) ; if ( restartPoint > 0 ) { addAreas ( alg , restartPoint , originalList , effectiveList ) ; PageBreakPosition pbp = alg . getPageBreaks ( ) . get ( restartPoint - 1 ) ; newStartPos = alg . par . getFirstBoxIndex ( pbp . getLeafPos ( ) + 1 ) ; if ( newStartPos > 0 ) { handleBreakTrait ( Constants . EN_PAGE ) ; } } log . debug ( ""Restarting at "" + restartPoint + "", new start position: "" + newStartPos ) ; pageBreakHandled = true ; int currentPageNum = pslm . getCurrentPageNum ( ) ; pageProvider . setStartOfNextElementList ( currentPageNum , pslm . getCurrentPV ( ) . getCurrentSpan ( ) . getCurrentFlowIndex ( ) , this . spanAllActive ) ; effectiveList . ignoreAtStart = newStartPos ; PageBreakingAlgorithm algRestart ; if ( needColumnBalancing ) { log . debug ( ""Column balancing now!!!"" ) ; log . debug ( ""==================================================="" ) ; algRestart = new BalancingColumnBreakingAlgorithm ( getTopLevelLM ( ) , getPageProvider ( ) , createLayoutListener ( ) , alignment , Constants . EN_START , footnoteSeparatorLength , isPartOverflowRecoveryActivated ( ) , pslm . getCurrentPV ( ) . getBodyRegion ( ) . getColumnCount ( ) ) ; log . debug ( ""==================================================="" ) ; } else { BodyRegion currentBody = pageProvider . getPage ( false , currentPageNum ) . getPageViewport ( ) . getBodyRegion ( ) ; setLastPageIndex ( currentPageNum ) ; BodyRegion lastBody = pageProvider . getPage ( false , currentPageNum ) . getPageViewport ( ) . getBodyRegion ( ) ; lastBody . getMainReference ( ) . setSpans ( currentBody . getMainReference ( ) . getSpans ( ) ) ; log . debug ( ""Last page handling now!!!"" ) ; log . debug ( ""==================================================="" ) ; algRestart = new PageBreakingAlgorithm ( getTopLevelLM ( ) , getPageProvider ( ) , createLayoutListener ( ) , alg . getAlignment ( ) , alg . getAlignmentLast ( ) , footnoteSeparatorLength , isPartOverflowRecoveryActivated ( ) , false , false ) ; log . debug ( ""==================================================="" ) ; } int optimalPageCount = algRestart . findBreakingPoints ( effectiveList , newStartPos , 1 , true , BreakingAlgorithm . ALL_BREAKS ) ; log . debug ( ""restart: optimalPageCount= "" + optimalPageCount + "" pageBreaks.size()= "" + algRestart . getPageBreaks ( ) . size ( ) ) ; boolean fitsOnePage = optimalPageCount <= pslm . getCurrentPV ( ) . getBodyRegion ( ) . getMainReference ( ) . getCurrentSpan ( ) . getColumnCount ( ) ; if ( needColumnBalancing ) { if ( ! fitsOnePage ) { log . warn ( ""Breaking algorithm produced more columns than are available."" ) ; } } else { boolean ipdChange = algRestart . getIPDdifference ( ) != 0 ; if ( fitsOnePage && ! ipdChange ) { pslm . setCurrentPage ( pageProvider . getPage ( false , currentPageNum ) ) ; } else { addAreas ( alg , restartPoint , partCount - restartPoint , originalList , effectiveList ) ; if ( ! ipdChange ) { setLastPageIndex ( currentPageNum + 1 ) ; pslm . setCurrentPage ( pslm . makeNewPage ( true ) ) ; } return ; } } addAreas ( algRestart , optimalPageCount , originalList , effectiveList ) ; } private void setLastPageIndex ( int currentPageNum ) { int lastPageIndex = pslm . getForcedLastPageNum ( currentPageNum ) ; pageProvider . setLastPageIndex ( lastPageIndex ) ; } protected void startPart ( BlockSequence list , int breakClass , boolean emptyContent ) { log . debug ( ""startPart() breakClass="" + getBreakClassName ( breakClass ) ) ; if ( pslm . getCurrentPage ( ) == null ) { throw new IllegalStateException ( ""curPage must not be null"" ) ; } if ( ! pageBreakHandled ) { if ( ! firstPart ) { handleBreakTrait ( breakClass , emptyContent ) ; } pageProvider . setStartOfNextElementList ( pslm . getCurrentPageNum ( ) , pslm . getCurrentPV ( ) . getCurrentSpan ( ) . getCurrentFlowIndex ( ) , this . spanAllActive ) ; } pageBreakHandled = false ; firstPart = false ; } protected void handleEmptyContent ( ) { pslm . getCurrentPV ( ) . getPage ( ) . fakeNonEmpty ( ) ; } protected void finishPart ( PageBreakingAlgorithm alg , PageBreakPosition pbp ) { if ( ! pslm . getTableHeaderFootnotes ( ) . isEmpty ( ) || pbp . footnoteFirstListIndex < pbp . footnoteLastListIndex || pbp . footnoteFirstElementIndex <= pbp . footnoteLastElementIndex || ! pslm . getTableFooterFootnotes ( ) . isEmpty ( ) ) { for ( List < KnuthElement > footnote : pslm . getTableHeaderFootnotes ( ) ) { addFootnoteAreas ( footnote ) ; } for ( int i = pbp . footnoteFirstListIndex ; i <= pbp . footnoteLastListIndex ; i ++ ) { List elementList = alg . getFootnoteList ( i ) ; int firstIndex = ( i == pbp . footnoteFirstListIndex ? pbp . footnoteFirstElementIndex : 0 ) ; int lastIndex = ( i == pbp . footnoteLastListIndex ? pbp . footnoteLastElementIndex : elementList . size ( ) - 1 ) ; addFootnoteAreas ( elementList , firstIndex , lastIndex + 1 ) ; } for ( List < KnuthElement > footnote : pslm . getTableFooterFootnotes ( ) ) { addFootnoteAreas ( footnote ) ; } Footnote parentArea = pslm . getCurrentPV ( ) . getBodyRegion ( ) . getFootnote ( ) ; int topOffset = pslm . getCurrentPV ( ) . getBodyRegion ( ) . getBPD ( ) - parentArea . getBPD ( ) ; if ( separatorArea != null ) { topOffset -= separatorArea . getBPD ( ) ; } parentArea . setTop ( topOffset ) ; parentArea . setSeparator ( separatorArea ) ; } pslm . getCurrentPV ( ) . getCurrentSpan ( ) . notifyFlowsFinished ( ) ; pslm . clearTableHeadingFootnotes ( ) ; } private void addFootnoteAreas ( List < KnuthElement > footnote ) { addFootnoteAreas ( footnote , 0 , footnote . size ( ) ) ; } private void addFootnoteAreas ( List < KnuthElement > footnote , int startIndex , int endIndex ) { SpaceResolver . performConditionalsNotification ( footnote , startIndex , endIndex - 1 , - 1 ) ; LayoutContext childLC = LayoutContext . newInstance ( ) ; AreaAdditionUtil . addAreas ( null , new KnuthPossPosIter ( footnote , startIndex , endIndex ) , childLC ) ; } protected FlowLayoutManager getCurrentChildLM ( ) { return childFLM ; } protected void observeElementList ( List elementList ) { ElementListObserver . observe ( elementList , ""breaker"" , pslm . getFObj ( ) . getId ( ) ) ; } private void handleBreakTrait ( int breakVal ) { handleBreakTrait ( breakVal , false ) ; } private void handleBreakTrait ( int breakVal , boolean emptyContent ) { Page curPage = pslm . getCurrentPage ( ) ; switch ( breakVal ) { case Constants . EN_ALL : curPage . getPageViewport ( ) . createSpan ( true ) ; this . spanAllActive = true ; return ; case Constants . EN_NONE : curPage . getPageViewport ( ) . createSpan ( false ) ; this . spanAllActive = false ; return ; case Constants . EN_COLUMN : case Constants . EN_AUTO : case Constants . EN_PAGE : case - 1 : PageViewport pv = curPage . getPageViewport ( ) ; boolean forceNewPageWithSpan = false ; RegionBody rb = ( RegionBody ) curPage . getSimplePageMaster ( ) . getRegion ( Constants . FO_REGION_BODY ) ; forceNewPageWithSpan = ( rb . getColumnCount ( ) > 1 && pv . getCurrentSpan ( ) . getColumnCount ( ) == 1 ) ; if ( forceNewPageWithSpan ) { log . trace ( ""Forcing new page with span"" ) ; curPage = pslm . makeNewPage ( false ) ; curPage . getPageViewport ( ) . createSpan ( true ) ; } else { if ( breakVal == Constants . EN_PAGE ) { handleBreakBeforeFollowingPage ( breakVal ) ; } else { if ( pv . getCurrentSpan ( ) . hasMoreFlows ( ) ) { log . trace ( ""Moving to next flow"" ) ; pv . getCurrentSpan ( ) . moveToNextFlow ( ) ; } else { log . trace ( ""Making new page"" ) ; pslm . makeNewPage ( false , emptyContent ) ; } } } return ; default : handleBreakBeforeFollowingPage ( breakVal ) ; } } private void handleBreakBeforeFollowingPage ( int breakVal ) { log . debug ( ""handling break-before after page "" + pslm . getCurrentPageNum ( ) + "" breakVal="" + getBreakClassName ( breakVal ) ) ; if ( needBlankPageBeforeNew ( breakVal ) ) { log . trace ( ""Inserting blank page"" ) ; pslm . makeNewPage ( true ) ; } if ( needNewPage ( breakVal ) ) { log . trace ( ""Making new page"" ) ; pslm . makeNewPage ( false ) ; } } private boolean needBlankPageBeforeNew ( int breakVal ) { if ( breakVal == Constants . EN_PAGE || ( pslm . getCurrentPage ( ) . getPageViewport ( ) . getPage ( ) . isEmpty ( ) ) ) { return false ; } else { if ( pslm . getCurrentPageNum ( ) % 2 == 0 ) { return ( breakVal == Constants . EN_EVEN_PAGE ) ; } else { return ( breakVal == Constants . EN_ODD_PAGE ) ; } } } private boolean needNewPage ( int breakVal ) { if ( pslm . getCurrentPage ( ) . getPageViewport ( ) . getPage ( ) . isEmpty ( ) ) { if ( breakVal == Constants . EN_PAGE ) { return false ; } else if ( pslm . getCurrentPageNum ( ) % 2 == 0 ) { return ( breakVal == Constants . EN_ODD_PAGE ) ; } else { return ( breakVal == Constants . EN_EVEN_PAGE ) ; } } else { return true ; } } protected boolean shouldRedoLayout ( ) { return shouldRedoLayout ( - 1 ) ; } protected boolean shouldRedoLayout ( int partCount ) { boolean lastPageMasterDefined = pslm . getPageSequence ( ) . hasPagePositionLast ( ) ; if ( ! lastPageMasterDefined && partCount != - 1 ) { lastPageMasterDefined = pslm . getPageSequence ( ) . hasPagePositionOnly ( ) && pslm . isOnFirstPage ( partCount - 1 ) ; } return ( ! hasMoreContent ( ) && lastPageMasterDefined && ! layoutRedone ) ; } protected boolean wasLayoutRedone ( ) { return layoutRedone ; } protected boolean lastPageHasIPDChange ( ) { boolean lastPageMasterDefined = pslm . getPageSequence ( ) . hasPagePositionLast ( ) ; boolean onlyPageMasterDefined = pslm . getPageSequence ( ) . hasPagePositionOnly ( ) ; if ( lastPageMasterDefined && ! onlyPageMasterDefined ) { int currentIPD = this . pageProvider . getCurrentIPD ( ) ; int lastPageIPD = this . pageProvider . getLastPageIPD ( ) ; if ( lastPageIPD != - 1 && currentIPD != lastPageIPD ) { return true ; } } return false ; } protected boolean handlingStartOfFloat ( ) { return handlingStartOfFloat ; } protected void handleStartOfFloat ( int fHeight , int fYOffset ) { handlingStartOfFloat = true ; handlingEndOfFloat = false ; floatHeight = fHeight ; floatYOffset = fYOffset ; childFLM . handleFloatOn ( ) ; } protected int getFloatHeight ( ) { return floatHeight ; } protected int getFloatYOffset ( ) { return floatYOffset ; } protected boolean handlingEndOfFloat ( ) { return handlingEndOfFloat ; } protected void handleEndOfFloat ( int fHeight ) { handlingEndOfFloat = true ; handlingStartOfFloat = false ; floatHeight = fHeight ; childFLM . handleFloatOff ( ) ; } protected boolean handlingFloat ( ) { return ( handlingStartOfFloat || handlingEndOfFloat ) ; } public int getOffsetDueToFloat ( ) { handlingEndOfFloat = false ; return floatHeight + floatYOffset ; } protected int handleFloatLayout ( PageBreakingAlgorithm alg , int optimalPageCount , BlockSequence blockList , LayoutContext childLC ) { pageBreakHandled = true ; List firstElements = Collections . EMPTY_LIST ; KnuthNode floatNode = alg . getBestFloatEdgeNode ( ) ; int floatPosition = floatNode . position ; KnuthElement floatElem = alg . getElement ( floatPosition ) ; Position positionAtBreak = floatElem . getPosition ( ) ; if ( ! ( positionAtBreak instanceof SpaceResolver . SpaceHandlingBreakPosition ) ) { throw new UnsupportedOperationException ( ""Don't know how to restart at position"" + positionAtBreak ) ; } positionAtBreak = positionAtBreak . getPosition ( ) ; addAreas ( alg , optimalPageCount , blockList , blockList ) ; blockLists . clear ( ) ; blockListIndex = - 1 ; LayoutManager restartAtLM = null ; if ( positionAtBreak != null && positionAtBreak . getIndex ( ) == - 1 ) { if ( positionAtBreak instanceof ListItemLayoutManager . ListItemPosition ) { restartAtLM = positionAtBreak . getLM ( ) ; } else { Position position ; Iterator iter = blockList . listIterator ( floatPosition + 1 ) ; do { KnuthElement nextElement = ( KnuthElement ) iter . next ( ) ; position = nextElement . getPosition ( ) ; } while ( position == null || position instanceof SpaceResolver . SpaceHandlingPosition || position instanceof SpaceResolver . SpaceHandlingBreakPosition && position . getPosition ( ) . getIndex ( ) == - 1 ) ; LayoutManager surroundingLM = positionAtBreak . getLM ( ) ; while ( position . getLM ( ) != surroundingLM ) { position = position . getPosition ( ) ; } restartAtLM = position . getPosition ( ) . getLM ( ) ; } } int nextSequenceStartsOn = getNextBlockList ( childLC , Constants . EN_COLUMN , positionAtBreak , restartAtLM , firstElements ) ; return nextSequenceStartsOn ; } protected void addAreasForFloats ( PageBreakingAlgorithm alg , int startPart , int partCount , BlockSequence originalList , BlockSequence effectiveList , final LayoutContext childLC , int lastBreak , int startElementIndex , int endElementIndex ) { FloatPosition pbp = alg . getFloatPosition ( ) ; int lastBreakClass ; if ( startElementIndex == 0 ) { lastBreakClass = effectiveList . getStartOn ( ) ; } else { ListElement lastBreakElement = effectiveList . getElement ( endElementIndex ) ; if ( lastBreakElement . isPenalty ( ) ) { KnuthPenalty pen = ( KnuthPenalty ) lastBreakElement ; if ( pen . getPenalty ( ) == KnuthPenalty . INFINITE ) { lastBreakClass = Constants . EN_COLUMN ; } else { lastBreakClass = pen . getBreakClass ( ) ; } } else { lastBreakClass = Constants . EN_COLUMN ; } } endElementIndex = pbp . getLeafPos ( ) ; startElementIndex += ( startElementIndex == 0 ) ? effectiveList . ignoreAtStart : 0 ; log . debug ( ""PLM> part: "" + ( startPart + partCount + 1 ) + "", start at pos "" + startElementIndex + "", break at pos "" + endElementIndex + "", break class = "" + getBreakClassName ( lastBreakClass ) ) ; startPart ( effectiveList , lastBreakClass , false ) ; int displayAlign = getCurrentDisplayAlign ( ) ; int notificationEndElementIndex = endElementIndex ; endElementIndex -= ( endElementIndex == ( originalList . size ( ) - 1 ) ) ? effectiveList . ignoreAtEnd : 0 ; if ( ( ( KnuthElement ) effectiveList . get ( endElementIndex ) ) . isGlue ( ) ) { endElementIndex -- ; } startElementIndex = alg . par . getFirstBoxIndex ( startElementIndex ) ; if ( startElementIndex <= endElementIndex ) { if ( log . isDebugEnabled ( ) ) { log . debug ( ""     addAreas from "" + startElementIndex + "" to "" + endElementIndex ) ; } childLC . setSpaceAdjust ( pbp . bpdAdjust ) ; if ( pbp . difference != 0 && displayAlign == Constants . EN_CENTER ) { childLC . setSpaceBefore ( pbp . difference / 2 ) ; } else if ( pbp . difference != 0 && displayAlign == Constants . EN_AFTER ) { childLC . setSpaceBefore ( pbp . difference ) ; } SpaceResolver . performConditionalsNotification ( effectiveList , startElementIndex , notificationEndElementIndex , lastBreak ) ; addAreas ( new KnuthPossPosIter ( effectiveList , startElementIndex , endElementIndex + 1 ) , childLC ) ; if ( alg . handlingStartOfFloat ( ) ) { for ( int k = startElementIndex ; k < endElementIndex + 1 ; k ++ ) { ListElement le = effectiveList . getElement ( k ) ; if ( le instanceof KnuthBlockBox ) { KnuthBlockBox kbb = ( KnuthBlockBox ) le ; for ( FloatContentLayoutManager fclm : kbb . getFloatContentLMs ( ) ) { fclm . processAreas ( childLC ) ; int floatHeight = fclm . getFloatHeight ( ) ; int floatYOffset = fclm . getFloatYOffset ( ) ; PageSequenceLayoutManager pslm = ( PageSequenceLayoutManager ) getTopLevelLM ( ) ; pslm . recordStartOfFloat ( floatHeight , floatYOffset ) ; } } } } if ( alg . handlingEndOfFloat ( ) ) { PageSequenceLayoutManager pslm = ( PageSequenceLayoutManager ) getTopLevelLM ( ) ; pslm . setEndIntrusionAdjustment ( 0 ) ; pslm . setStartIntrusionAdjustment ( 0 ) ; int effectiveFloatHeight = alg . getFloatHeight ( ) ; pslm . recordEndOfFloat ( effectiveFloatHeight ) ; } if ( alg . handlingFloat ( ) ) { PageSequenceLayoutManager pslm = ( PageSequenceLayoutManager ) getTopLevelLM ( ) ; alg . relayFootnotes ( pslm ) ; } } else { handleEmptyContent ( ) ; } pageBreakHandled = true ; } public void holdFootnotes ( List fl , List ll , int tfl , int ifl , boolean fp , boolean nf , int fnfi , int fli , int fei , MinOptMax fsl , int pfli , int pfei ) { relayedFootnotesList = fl ; relayedLengthList = ll ; relayedTotalFootnotesLength = tfl ; relayedInsertedFootnotesLength = ifl ; relayedFootnotesPending = fp ; relayedNewFootnotes = nf ; relayedFirstNewFootnoteIndex = fnfi ; relayedFootnoteListIndex = fli ; relayedFootnoteElementIndex = fei ; relayedFootnoteSeparatorLength = fsl ; previousFootnoteListIndex = pfli ; previousFootnoteElementIndex = pfei ; } public void retrieveFootones ( PageBreakingAlgorithm alg ) { if ( relayedFootnotesList != null && relayedFootnotesList . size ( ) > 0 ) { alg . loadFootnotes ( relayedFootnotesList , relayedLengthList , relayedTotalFootnotesLength , relayedInsertedFootnotesLength , relayedFootnotesPending , relayedNewFootnotes , relayedFirstNewFootnoteIndex , relayedFootnoteListIndex , relayedFootnoteElementIndex , relayedFootnoteSeparatorLength , previousFootnoteListIndex , previousFootnoteElementIndex ) ; relayedFootnotesList = null ; relayedLengthList = null ; relayedTotalFootnotesLength = 0 ; relayedInsertedFootnotesLength = 0 ; relayedFootnotesPending = false ; relayedNewFootnotes = false ; relayedFirstNewFootnoteIndex = 0 ; relayedFootnoteListIndex = 0 ; relayedFootnoteElementIndex = - 1 ; relayedFootnoteSeparatorLength = null ; } } }",Smelly
"@ SelfDiagnosisRuleDefinition ( category = ""base"" , name = ""CheckHadoopRuntimeVersionRule"" , priority = 0 ) @ SelfDiagnosisRuleVisibility . Public public class CheckHadoopRuntimeVersionRule implements SelfDiagnosisRule { private Log LOG = LogFactory . getLog ( getClass ( ) ) ; private final Properties versionInfo ; public CheckHadoopRuntimeVersionRule ( ) { InputStream is = ClassLoader . getSystemResourceAsStream ( ""common-version-info.properties"" ) ; versionInfo = new Properties ( ) ; try { versionInfo . load ( is ) ; } catch ( IOException e ) { LOG . warn ( e . getMessage ( ) , e ) ; } finally { IOUtils . closeStream ( is ) ; } } private int [ ] getVersion ( ) { int [ ] version = new int [ 0 ] ; String versionString = versionInfo . getProperty ( ""version"" ) . split ( ""-"" ) [ 0 ] ; if ( versionString != null && ! versionString . isEmpty ( ) ) { Validators . patternMatch ( ""\\d+\\.\\d+\\.\\d+.*"" ) . validate ( versionString , true ) ; String [ ] versionArray = versionString . split ( ""\\."" ) ; version = new int [ versionArray . length ] ; for ( int idx = 0 ; idx < versionArray . length ; idx ++ ) { version [ idx ] = Integer . parseInt ( versionArray [ idx ] ) ; } } return version ; } private int compareVersion ( int [ ] left , int [ ] right ) { int returnValue = 0 ; int minLength = Math . min ( left . length , right . length ) ; for ( int idx = 0 ; idx < minLength ; idx ++ ) { returnValue = ( int ) Math . signum ( left [ idx ] - right [ idx ] ) ; if ( returnValue != 0 ) { break ; } } if ( returnValue == 0 ) { returnValue = ( int ) Math . signum ( left . length - right . length ) ; } return returnValue ; } @ Override public EvaluationResult evaluate ( EvaluationContext context ) { EvaluationResult evalResult = new EvaluationResult ( ) ; try { int compared = compareVersion ( getVersion ( ) , new int [ ] { 2 , 3 , 0 } ) ; if ( compared >= 0 ) { evalResult . setReturnCode ( EvaluationResultCode . OK ) ; evalResult . setMessage ( ""Version test for hadoop common has passed."" ) ; } else { evalResult . setReturnCode ( EvaluationResultCode . ERROR ) ; evalResult . setMessage ( ""Checking the version of hadoop common component has failed.\n"" + ""Current version : "" + versionInfo . getProperty ( ""version"" ) ) ; } } catch ( Exception e ) { evalResult . setReturnCode ( EvaluationResultCode . ERROR ) ; evalResult . setThrowable ( e ) ; evalResult . setMessage ( ""Checking the version of hadoop common component has failed."" ) ; } return evalResult ; } }",No
"public class PropertyValidateFacetViaMethod extends PropertyValidateFacetAbstract implements ImperativeFacet { private final Method method ; private final TranslationService translationService ; private final String translationContext ; public PropertyValidateFacetViaMethod ( final Method method , final TranslationService translationService , final String translationContext , final FacetHolder holder ) { super ( holder ) ; this . method = method ; this . translationService = translationService ; this . translationContext = translationContext ; } @ Override public List < Method > getMethods ( ) { return Collections . singletonList ( method ) ; } @ Override public Intent getIntent ( final Method method ) { return Intent . CHECK_IF_VALID ; } @ Override public String invalidReason ( final ObjectAdapter owningAdapter , final ObjectAdapter proposedAdapter ) { final Object returnValue = ObjectAdapter . InvokeUtils . invoke ( method , owningAdapter , proposedAdapter ) ; if ( returnValue instanceof String ) { return ( String ) returnValue ; } if ( returnValue instanceof TranslatableString ) { final TranslatableString ts = ( TranslatableString ) returnValue ; return ts . translate ( translationService , translationContext ) ; } return null ; } @ Override protected String toStringValues ( ) { return ""method="" + method ; } }",No
"public class FilterTableFunctionTransposeRule extends RelOptRule { public static final FilterTableFunctionTransposeRule INSTANCE = new FilterTableFunctionTransposeRule ( RelFactories . LOGICAL_BUILDER ) ; public FilterTableFunctionTransposeRule ( RelBuilderFactory relBuilderFactory ) { super ( operand ( LogicalFilter . class , operand ( LogicalTableFunctionScan . class , any ( ) ) ) , relBuilderFactory , null ) ; } public void onMatch ( RelOptRuleCall call ) { LogicalFilter filter = call . rel ( 0 ) ; LogicalTableFunctionScan funcRel = call . rel ( 1 ) ; Set < RelColumnMapping > columnMappings = funcRel . getColumnMappings ( ) ; if ( columnMappings == null || columnMappings . isEmpty ( ) ) { return ; } List < RelNode > funcInputs = funcRel . getInputs ( ) ; if ( funcInputs . size ( ) != 1 ) { return ; } if ( funcRel . getRowType ( ) . getFieldCount ( ) != funcInputs . get ( 0 ) . getRowType ( ) . getFieldCount ( ) ) { return ; } for ( RelColumnMapping mapping : columnMappings ) { if ( mapping . iInputColumn != mapping . iOutputColumn ) { return ; } if ( mapping . derived ) { return ; } } final List < RelNode > newFuncInputs = new ArrayList < > ( ) ; final RelOptCluster cluster = funcRel . getCluster ( ) ; final RexNode condition = filter . getCondition ( ) ; RexBuilder rexBuilder = filter . getCluster ( ) . getRexBuilder ( ) ; List < RelDataTypeField > origFields = funcRel . getRowType ( ) . getFieldList ( ) ; int [ ] adjustments = new int [ origFields . size ( ) ] ; for ( RelNode funcInput : funcInputs ) { RexNode newCondition = condition . accept ( new RelOptUtil . RexInputConverter ( rexBuilder , origFields , funcInput . getRowType ( ) . getFieldList ( ) , adjustments ) ) ; newFuncInputs . add ( LogicalFilter . create ( funcInput , newCondition ) ) ; } LogicalTableFunctionScan newFuncRel = LogicalTableFunctionScan . create ( cluster , newFuncInputs , funcRel . getCall ( ) , funcRel . getElementType ( ) , funcRel . getRowType ( ) , columnMappings ) ; call . transformTo ( newFuncRel ) ; } }",No
"public class DefaultCryptoModule implements CryptoModule { private static final String ENCRYPTION_HEADER_MARKER_V1 = ""---Log File Encrypted (v1)---"" ; private static final String ENCRYPTION_HEADER_MARKER_V2 = ""---Log File Encrypted (v2)---"" ; private static final Logger log = LoggerFactory . getLogger ( DefaultCryptoModule . class ) ; public DefaultCryptoModule ( ) { } @ Override public CryptoModuleParameters initializeCipher ( CryptoModuleParameters params ) { String cipherTransformation = getCipherTransformation ( params ) ; log . trace ( String . format ( ""Using cipher suite \""%s\"" with key length %d with RNG \""%s\"" and RNG provider \""%s\"" and key encryption strategy \""%s\"""" , cipherTransformation , params . getKeyLength ( ) , params . getRandomNumberGenerator ( ) , params . getRandomNumberGeneratorProvider ( ) , params . getKeyEncryptionStrategyClass ( ) ) ) ; if ( params . getSecureRandom ( ) == null ) { SecureRandom secureRandom = DefaultCryptoModuleUtils . getSecureRandom ( params . getRandomNumberGenerator ( ) , params . getRandomNumberGeneratorProvider ( ) ) ; params . setSecureRandom ( secureRandom ) ; } Cipher cipher = DefaultCryptoModuleUtils . getCipher ( cipherTransformation ) ; if ( params . getInitializationVector ( ) == null ) { try { cipher . init ( Cipher . ENCRYPT_MODE , new SecretKeySpec ( params . getPlaintextKey ( ) , params . getAlgorithmName ( ) ) , params . getSecureRandom ( ) ) ; } catch ( InvalidKeyException e ) { log . error ( ""Accumulo encountered an unknown error in generating the secret key object (SecretKeySpec) for an encrypted stream"" ) ; throw new RuntimeException ( e ) ; } params . setInitializationVector ( cipher . getIV ( ) ) ; } else { try { cipher . init ( Cipher . ENCRYPT_MODE , new SecretKeySpec ( params . getPlaintextKey ( ) , params . getAlgorithmName ( ) ) , new IvParameterSpec ( params . getInitializationVector ( ) ) ) ; } catch ( InvalidKeyException e ) { log . error ( ""Accumulo encountered an unknown error in generating the secret key object (SecretKeySpec) for an encrypted stream"" ) ; throw new RuntimeException ( e ) ; } catch ( InvalidAlgorithmParameterException e ) { log . error ( ""Accumulo encountered an unknown error in setting up the initialization vector for an encrypted stream"" ) ; throw new RuntimeException ( e ) ; } } params . setCipher ( cipher ) ; return params ; } private String getCipherTransformation ( CryptoModuleParameters params ) { String cipherSuite = params . getAlgorithmName ( ) + ""/"" + params . getEncryptionMode ( ) + ""/"" + params . getPadding ( ) ; return cipherSuite ; } private String [ ] parseCipherSuite ( String cipherSuite ) { return cipherSuite . split ( ""/"" ) ; } private boolean validateNotEmpty ( String givenValue , boolean allIsWell , StringBuilder buf , String errorMessage ) { if ( givenValue == null || givenValue . equals ( """" ) ) { buf . append ( errorMessage ) ; buf . append ( ""\n"" ) ; return false ; } return true && allIsWell ; } private boolean validateNotNull ( Object givenValue , boolean allIsWell , StringBuilder buf , String errorMessage ) { if ( givenValue == null ) { buf . append ( errorMessage ) ; buf . append ( ""\n"" ) ; return false ; } return true && allIsWell ; } private boolean validateNotZero ( int givenValue , boolean allIsWell , StringBuilder buf , String errorMessage ) { if ( givenValue == 0 ) { buf . append ( errorMessage ) ; buf . append ( ""\n"" ) ; return false ; } return true && allIsWell ; } private boolean validateParamsObject ( CryptoModuleParameters params , int cipherMode ) { if ( cipherMode == Cipher . ENCRYPT_MODE ) { StringBuilder errorBuf = new StringBuilder ( ""The following problems were found with the CryptoModuleParameters object you provided for an encrypt operation:\n"" ) ; boolean allIsWell = true ; allIsWell = validateNotEmpty ( params . getAlgorithmName ( ) , allIsWell , errorBuf , ""No algorithm name was specified."" ) ; if ( allIsWell && params . getAlgorithmName ( ) . equals ( ""NullCipher"" ) ) { return true ; } allIsWell = validateNotEmpty ( params . getPadding ( ) , allIsWell , errorBuf , ""No padding was specified."" ) ; allIsWell = validateNotZero ( params . getKeyLength ( ) , allIsWell , errorBuf , ""No key length was specified."" ) ; allIsWell = validateNotEmpty ( params . getEncryptionMode ( ) , allIsWell , errorBuf , ""No encryption mode was specified."" ) ; allIsWell = validateNotEmpty ( params . getRandomNumberGenerator ( ) , allIsWell , errorBuf , ""No random number generator was specified."" ) ; allIsWell = validateNotEmpty ( params . getRandomNumberGeneratorProvider ( ) , allIsWell , errorBuf , ""No random number generate provider was specified."" ) ; allIsWell = validateNotNull ( params . getPlaintextOutputStream ( ) , allIsWell , errorBuf , ""No plaintext output stream was specified."" ) ; if ( ! allIsWell ) { log . error ( ""CryptoModulesParameters object is not valid."" ) ; log . error ( errorBuf . toString ( ) ) ; throw new RuntimeException ( ""CryptoModulesParameters object is not valid."" ) ; } return allIsWell ; } else if ( cipherMode == Cipher . DECRYPT_MODE ) { StringBuilder errorBuf = new StringBuilder ( ""The following problems were found with the CryptoModuleParameters object you provided for a decrypt operation:\n"" ) ; boolean allIsWell = true ; allIsWell = validateNotEmpty ( params . getPadding ( ) , allIsWell , errorBuf , ""No padding was specified."" ) ; allIsWell = validateNotZero ( params . getKeyLength ( ) , allIsWell , errorBuf , ""No key length was specified."" ) ; allIsWell = validateNotEmpty ( params . getEncryptionMode ( ) , allIsWell , errorBuf , ""No encryption mode was specified."" ) ; allIsWell = validateNotEmpty ( params . getRandomNumberGenerator ( ) , allIsWell , errorBuf , ""No random number generator was specified."" ) ; allIsWell = validateNotEmpty ( params . getRandomNumberGeneratorProvider ( ) , allIsWell , errorBuf , ""No random number generate provider was specified."" ) ; allIsWell = validateNotNull ( params . getEncryptedInputStream ( ) , allIsWell , errorBuf , ""No encrypted input stream was specified."" ) ; allIsWell = validateNotNull ( params . getInitializationVector ( ) , allIsWell , errorBuf , ""No initialization vector was specified."" ) ; allIsWell = validateNotNull ( params . getEncryptedKey ( ) , allIsWell , errorBuf , ""No encrypted key was specified."" ) ; if ( params . getKeyEncryptionStrategyClass ( ) != null && ! params . getKeyEncryptionStrategyClass ( ) . equals ( ""NullSecretKeyEncryptionStrategy"" ) ) { allIsWell = validateNotEmpty ( params . getOpaqueKeyEncryptionKeyID ( ) , allIsWell , errorBuf , ""No opqaue key encryption ID was specified."" ) ; } if ( ! allIsWell ) { log . error ( ""CryptoModulesParameters object is not valid."" ) ; log . error ( errorBuf . toString ( ) ) ; throw new RuntimeException ( ""CryptoModulesParameters object is not valid."" ) ; } return allIsWell ; } return false ; } @ Override public CryptoModuleParameters getEncryptingOutputStream ( CryptoModuleParameters params ) throws IOException { log . trace ( ""Initializing crypto output stream (new style)"" ) ; boolean allParamsOK = validateParamsObject ( params , Cipher . ENCRYPT_MODE ) ; if ( ! allParamsOK ) { log . error ( ""CryptoModuleParameters was not valid."" ) ; throw new RuntimeException ( ""Invalid CryptoModuleParameters"" ) ; } if ( params . getAlgorithmName ( ) . equals ( ""NullCipher"" ) ) { params . setEncryptedOutputStream ( params . getPlaintextOutputStream ( ) ) ; return params ; } SecureRandom secureRandom = DefaultCryptoModuleUtils . getSecureRandom ( params . getRandomNumberGenerator ( ) , params . getRandomNumberGeneratorProvider ( ) ) ; if ( params . getPlaintextKey ( ) == null ) { byte [ ] randomKey = new byte [ params . getKeyLength ( ) / 8 ] ; secureRandom . nextBytes ( randomKey ) ; params . setPlaintextKey ( randomKey ) ; } SecretKeyEncryptionStrategy keyEncryptionStrategy = CryptoModuleFactory . getSecretKeyEncryptionStrategy ( params . getKeyEncryptionStrategyClass ( ) ) ; params = keyEncryptionStrategy . encryptSecretKey ( params ) ; if ( ! params . getCloseUnderylingStreamAfterCryptoStreamClose ( ) ) { params . setPlaintextOutputStream ( new DiscardCloseOutputStream ( params . getPlaintextOutputStream ( ) ) ) ; } Cipher cipher = params . getCipher ( ) ; if ( cipher == null ) { initializeCipher ( params ) ; cipher = params . getCipher ( ) ; } if ( 0 == cipher . getBlockSize ( ) ) { throw new RuntimeException ( ""Encryption cipher must be a block cipher"" ) ; } CipherOutputStream cipherOutputStream = new CipherOutputStream ( params . getPlaintextOutputStream ( ) , cipher ) ; BlockedOutputStream blockedOutputStream = new BlockedOutputStream ( cipherOutputStream , cipher . getBlockSize ( ) , params . getBlockStreamSize ( ) ) ; params . setEncryptedOutputStream ( blockedOutputStream ) ; if ( params . getRecordParametersToStream ( ) ) { DataOutputStream dataOut = new DataOutputStream ( params . getPlaintextOutputStream ( ) ) ; dataOut . writeUTF ( ENCRYPTION_HEADER_MARKER_V2 ) ; dataOut . writeInt ( params . getAllOptions ( ) . size ( ) ) ; for ( String key : params . getAllOptions ( ) . keySet ( ) ) { dataOut . writeUTF ( key ) ; dataOut . writeUTF ( params . getAllOptions ( ) . get ( key ) ) ; } dataOut . writeUTF ( getCipherTransformation ( params ) ) ; dataOut . writeUTF ( params . getAlgorithmName ( ) ) ; dataOut . writeInt ( params . getInitializationVector ( ) . length ) ; dataOut . write ( params . getInitializationVector ( ) ) ; dataOut . writeUTF ( params . getOpaqueKeyEncryptionKeyID ( ) ) ; dataOut . writeInt ( params . getEncryptedKey ( ) . length ) ; dataOut . write ( params . getEncryptedKey ( ) ) ; dataOut . writeInt ( params . getBlockStreamSize ( ) ) ; } return params ; } @ Override public CryptoModuleParameters getDecryptingInputStream ( CryptoModuleParameters params ) throws IOException { log . trace ( ""About to initialize decryption stream (new style)"" ) ; if ( params . getRecordParametersToStream ( ) ) { DataInputStream dataIn = new DataInputStream ( params . getEncryptedInputStream ( ) ) ; log . trace ( ""About to read encryption parameters from underlying stream"" ) ; String marker = dataIn . readUTF ( ) ; if ( marker . equals ( ENCRYPTION_HEADER_MARKER_V1 ) || marker . equals ( ENCRYPTION_HEADER_MARKER_V2 ) ) { Map < String , String > paramsFromFile = new HashMap < > ( ) ; int paramsCount = dataIn . readInt ( ) ; for ( int i = 0 ; i < paramsCount ; i ++ ) { String key = dataIn . readUTF ( ) ; String value = dataIn . readUTF ( ) ; paramsFromFile . put ( key , value ) ; } String cipherSuiteFromFile = dataIn . readUTF ( ) ; String algorithmNameFromFile = dataIn . readUTF ( ) ; String [ ] cipherSuiteParts = parseCipherSuite ( cipherSuiteFromFile ) ; params . setAlgorithmName ( algorithmNameFromFile ) ; params . setEncryptionMode ( cipherSuiteParts [ 1 ] ) ; params . setPadding ( cipherSuiteParts [ 2 ] ) ; int initVectorLength = dataIn . readInt ( ) ; byte [ ] initVector = new byte [ initVectorLength ] ; dataIn . readFully ( initVector ) ; params . setInitializationVector ( initVector ) ; String opaqueId = dataIn . readUTF ( ) ; params . setOpaqueKeyEncryptionKeyID ( opaqueId ) ; int encryptedSecretKeyLength = dataIn . readInt ( ) ; byte [ ] encryptedSecretKey = new byte [ encryptedSecretKeyLength ] ; dataIn . readFully ( encryptedSecretKey ) ; params . setEncryptedKey ( encryptedSecretKey ) ; if ( params . getOverrideStreamsSecretKeyEncryptionStrategy ( ) ) { for ( String name : paramsFromFile . keySet ( ) ) { if ( ! name . equals ( Property . CRYPTO_SECRET_KEY_ENCRYPTION_STRATEGY_CLASS . getKey ( ) ) ) { params . getAllOptions ( ) . put ( name , paramsFromFile . get ( name ) ) ; } } params . setKeyEncryptionStrategyClass ( params . getAllOptions ( ) . get ( Property . CRYPTO_SECRET_KEY_ENCRYPTION_STRATEGY_CLASS . getKey ( ) ) ) ; } else { params = CryptoModuleFactory . fillParamsObjectFromStringMap ( params , paramsFromFile ) ; } SecretKeyEncryptionStrategy keyEncryptionStrategy = CryptoModuleFactory . getSecretKeyEncryptionStrategy ( params . getKeyEncryptionStrategyClass ( ) ) ; params = keyEncryptionStrategy . decryptSecretKey ( params ) ; if ( marker . equals ( ENCRYPTION_HEADER_MARKER_V2 ) ) params . setBlockStreamSize ( dataIn . readInt ( ) ) ; else params . setBlockStreamSize ( 0 ) ; } else { log . trace ( ""Read something off of the encrypted input stream that was not the encryption header marker, so pushing back bytes and returning the given stream"" ) ; ByteArrayOutputStream tempByteOut = new ByteArrayOutputStream ( ) ; DataOutputStream tempOut = new DataOutputStream ( tempByteOut ) ; tempOut . writeUTF ( marker ) ; byte [ ] bytesToPutBack = tempByteOut . toByteArray ( ) ; PushbackInputStream pushbackStream = new PushbackInputStream ( params . getEncryptedInputStream ( ) , bytesToPutBack . length ) ; pushbackStream . unread ( bytesToPutBack ) ; params . setPlaintextInputStream ( pushbackStream ) ; return params ; } } boolean allParamsOK = validateParamsObject ( params , Cipher . DECRYPT_MODE ) ; if ( ! allParamsOK ) { log . error ( ""CryptoModuleParameters object failed validation for decrypt"" ) ; throw new RuntimeException ( ""CryptoModuleParameters object failed validation for decrypt"" ) ; } Cipher cipher = DefaultCryptoModuleUtils . getCipher ( getCipherTransformation ( params ) ) ; try { cipher . init ( Cipher . DECRYPT_MODE , new SecretKeySpec ( params . getPlaintextKey ( ) , params . getAlgorithmName ( ) ) , new IvParameterSpec ( params . getInitializationVector ( ) ) ) ; } catch ( InvalidKeyException e ) { log . error ( ""Error when trying to initialize cipher with secret key"" ) ; throw new RuntimeException ( e ) ; } catch ( InvalidAlgorithmParameterException e ) { log . error ( ""Error when trying to initialize cipher with initialization vector"" ) ; throw new RuntimeException ( e ) ; } InputStream blockedDecryptingInputStream = new CipherInputStream ( params . getEncryptedInputStream ( ) , cipher ) ; if ( params . getBlockStreamSize ( ) > 0 ) blockedDecryptingInputStream = new BlockedInputStream ( blockedDecryptingInputStream , cipher . getBlockSize ( ) , params . getBlockStreamSize ( ) ) ; log . trace ( ""Initialized cipher input stream with transformation ["" + getCipherTransformation ( params ) + ""]"" ) ; params . setPlaintextInputStream ( blockedDecryptingInputStream ) ; return params ; } @ Override public CryptoModuleParameters generateNewRandomSessionKey ( CryptoModuleParameters params ) { if ( params . getSecureRandom ( ) == null ) { params . setSecureRandom ( DefaultCryptoModuleUtils . getSecureRandom ( params . getRandomNumberGenerator ( ) , params . getRandomNumberGeneratorProvider ( ) ) ) ; } byte [ ] newSessionKey = new byte [ params . getKeyLength ( ) / 8 ] ; params . getSecureRandom ( ) . nextBytes ( newSessionKey ) ; params . setPlaintextKey ( newSessionKey ) ; return params ; } }",No
" public static class MultipleRoundRecoveryEventHook extends RecoveryServiceHook { public static final String MULTIPLE_ROUND_SHUTDOWN_CONDITION = ""tez.test.recovery.multiple_round_shutdown_condition"" ; private MultipleRoundShutdownCondition shutdownCondition ; private int attemptId ; public MultipleRoundRecoveryEventHook ( RecoveryServiceWithEventHandlingHook recoveryService , AppContext appContext ) { super ( recoveryService , appContext ) ; this . shutdownCondition = new MultipleRoundShutdownCondition ( ) ; try { Preconditions . checkArgument ( recoveryService . getConfig ( ) . get ( MULTIPLE_ROUND_SHUTDOWN_CONDITION ) != null , MULTIPLE_ROUND_SHUTDOWN_CONDITION + "" is not set in TezConfiguration"" ) ; this . shutdownCondition . deserialize ( recoveryService . getConfig ( ) . get ( MULTIPLE_ROUND_SHUTDOWN_CONDITION ) ) ; } catch ( IOException e ) { throw new TezUncheckedException ( ""Can not initialize MultipleRoundShutdownCondition"" , e ) ; } this . attemptId = appContext . getApplicationAttemptId ( ) . getAttemptId ( ) ; } @ Override public void preHandleRecoveryEvent ( DAGHistoryEvent event ) throws IOException { if ( attemptId <= shutdownCondition . size ( ) ) { SimpleShutdownCondition condition = shutdownCondition . getSimpleShutdownCondition ( attemptId - 1 ) ; if ( condition . timing . equals ( TIMING . PRE ) && condition . match ( event . getHistoryEvent ( ) ) ) { recoveryService . shutdown ( ) ; } } } @ Override public void postHandleRecoveryEvent ( DAGHistoryEvent event ) throws IOException { for ( int i = 0 ; i < shutdownCondition . size ( ) ; ++ i ) { SimpleShutdownCondition condition = shutdownCondition . getSimpleShutdownCondition ( i ) ; LOG . info ( ""condition:"" + condition . getEvent ( ) . getEventType ( ) + "":"" + condition . getHistoryEvent ( ) ) ; } if ( attemptId <= shutdownCondition . size ( ) ) { SimpleShutdownCondition condition = shutdownCondition . getSimpleShutdownCondition ( attemptId - 1 ) ; LOG . info ( ""event:"" + event . getHistoryEvent ( ) . getEventType ( ) ) ; if ( condition . timing . equals ( TIMING . POST ) && condition . match ( event . getHistoryEvent ( ) ) ) { recoveryService . shutdown ( ) ; } } } @ Override public void preHandleSummaryEvent ( HistoryEventType eventType , SummaryEvent summaryEvent ) throws IOException { } @ Override public void postHandleSummaryEvent ( HistoryEventType eventType , SummaryEvent summaryEvent ) throws IOException { } ",No
"public class FormatterSimpleHSQL extends FormatterSimple { private static Logger log = LoggerFactory . getLogger ( FormatterSimpleHSQL . class ) ; private static final String colDecl = ""VARCHAR"" ; public FormatterSimpleHSQL ( SDBConnection connection ) { super ( connection ) ; } @ Override public void truncate ( ) { try { connection ( ) . exec ( ""DELETE FROM Triples"" ) ; } catch ( SQLException ex ) { log . warn ( ""Exception truncating tables"" ) ; throw new SDBException ( ""SQLException truncating tables"" , ex ) ; } } @ Override public void format ( ) { reformatPrefixesWorker ( false ) ; reformatDataWorker ( ) ; } private void reformatPrefixesWorker ( ) { reformatPrefixesWorker ( false ) ; } private void reformatPrefixesWorker ( boolean loadPrefixes ) { try { connection ( ) . exec ( ""DROP TABLE IF EXISTS Prefixes"" ) ; connection ( ) . exec ( sqlStr ( ""CREATE CACHED TABLE Prefixes ("" , ""    prefix VARCHAR  NOT NULL ,"" , ""    uri    VARCHAR  NOT NULL ,"" , ""PRIMARY KEY(prefix)"" , "")"" ) ) ; if ( loadPrefixes ) { connection ( ) . execUpdate ( ""INSERT INTO Prefixes VALUES ('x',       'http://example/')"" ) ; connection ( ) . execUpdate ( ""INSERT INTO Prefixes VALUES ('ex',      'http://example.org/')"" ) ; connection ( ) . execUpdate ( ""INSERT INTO Prefixes VALUES ('rdf',     'http://www.w3.org/1999/02/22-rdf-syntax-ns#')"" ) ; connection ( ) . execUpdate ( ""INSERT INTO Prefixes VALUES ('rdfs',    'http://www.w3.org/2000/01/rdf-schema#')"" ) ; connection ( ) . execUpdate ( ""INSERT INTO Prefixes VALUES ('xsd',     'http://www.w3.org/2001/XMLSchema#')"" ) ; connection ( ) . execUpdate ( ""INSERT INTO Prefixes VALUES ('owl' ,    'http://www.w3.org/2002/07/owl#')"" ) ; connection ( ) . execUpdate ( ""INSERT INTO Prefixes VALUES ('foaf',    'http://xmlns.com/foaf/0.1/')"" ) ; connection ( ) . execUpdate ( ""INSERT INTO Prefixes VALUES ('dc',      'http://purl.org/dc/elements/1.1/')"" ) ; connection ( ) . execUpdate ( ""INSERT INTO Prefixes VALUES ('dcterms', 'http://purl.org/dc/terms/')"" ) ; } } catch ( SQLException ex ) { log . warn ( ""Exception resetting table 'Prefixes'"" ) ; throw new SDBException ( ""SQLException resetting table 'Prefixes'"" , ex ) ; } } private void reformatDataWorker ( ) { try { connection ( ) . exec ( ""DROP TABLE IF EXISTS Triples"" ) ; connection ( ) . exec ( sqlStr ( ""CREATE CACHED TABLE Triples"" , ""("" , ""  s "" + colDecl + "" ,"" , ""  p "" + colDecl + "" ,"" , ""  o "" + colDecl + "" ,"" , ""  PRIMARY KEY (s,p,o)"" , "")"" ) ) ; } catch ( SQLException ex ) { log . warn ( ""Exception resetting table 'Triples'"" ) ; throw new SDBException ( ""SQLException resetting table 'Triples'"" , ex ) ; } } @ Override public void dropIndexes ( ) { try { connection ( ) . exec ( ""DROP INDEX PredObj IF EXISTS"" ) ; connection ( ) . exec ( ""DROP INDEX ObjSubj IF EXISTS"" ) ; } catch ( SQLException ex ) { throw new SDBExceptionSQL ( ""SQLException dropping indexes for table 'Triples'"" , ex ) ; } } }",No
"public class Textifier extends Printer { public static final int INTERNAL_NAME = 0 ; public static final int FIELD_DESCRIPTOR = 1 ; public static final int FIELD_SIGNATURE = 2 ; public static final int METHOD_DESCRIPTOR = 3 ; public static final int METHOD_SIGNATURE = 4 ; public static final int CLASS_SIGNATURE = 5 ; public static final int TYPE_DECLARATION = 6 ; public static final int CLASS_DECLARATION = 7 ; public static final int PARAMETERS_DECLARATION = 8 ; public static final int HANDLE_DESCRIPTOR = 9 ; protected String tab = ""  "" ; protected String tab2 = ""    "" ; protected String tab3 = ""      "" ; protected String ltab = ""   "" ; protected Map < Label , String > labelNames ; private int valueNumber = 0 ; public Textifier ( ) { this ( Opcodes . ASM4 ) ; } protected Textifier ( final int api ) { super ( api ) ; } public static void main ( final String [ ] args ) throws Exception { int i = 0 ; int flags = ClassReader . SKIP_DEBUG ; boolean ok = true ; if ( args . length < 1 || args . length > 2 ) { ok = false ; } if ( ok && ""-debug"" . equals ( args [ 0 ] ) ) { i = 1 ; flags = 0 ; if ( args . length != 2 ) { ok = false ; } } if ( ! ok ) { System . err . println ( ""Prints a disassembled view of the given class."" ) ; System . err . println ( ""Usage: Textifier [-debug] "" + ""<fully qualified class name or class file name>"" ) ; return ; } ClassReader cr ; if ( args [ i ] . endsWith ( "".class"" ) || args [ i ] . indexOf ( '\\' ) > - 1 || args [ i ] . indexOf ( '/' ) > - 1 ) { cr = new ClassReader ( new FileInputStream ( args [ i ] ) ) ; } else { cr = new ClassReader ( args [ i ] ) ; } cr . accept ( new TraceClassVisitor ( new PrintWriter ( System . out ) ) , flags ) ; } @ Override public void visit ( final int version , final int access , final String name , final String signature , final String superName , final String [ ] interfaces ) { int major = version & 0xFFFF ; int minor = version > > > 16 ; buf . setLength ( 0 ) ; buf . append ( ""// class version "" ) . append ( major ) . append ( '.' ) . append ( minor ) . append ( "" ("" ) . append ( version ) . append ( "")\n"" ) ; if ( ( access & Opcodes . ACC_DEPRECATED ) != 0 ) { buf . append ( ""// DEPRECATED\n"" ) ; } buf . append ( ""// access flags 0x"" ) . append ( Integer . toHexString ( access ) . toUpperCase ( ) ) . append ( '\n' ) ; appendDescriptor ( CLASS_SIGNATURE , signature ) ; if ( signature != null ) { TraceSignatureVisitor sv = new TraceSignatureVisitor ( access ) ; SignatureReader r = new SignatureReader ( signature ) ; r . accept ( sv ) ; buf . append ( ""// declaration: "" ) . append ( name ) . append ( sv . getDeclaration ( ) ) . append ( '\n' ) ; } appendAccess ( access & ~ Opcodes . ACC_SUPER ) ; if ( ( access & Opcodes . ACC_ANNOTATION ) != 0 ) { buf . append ( ""@interface "" ) ; } else if ( ( access & Opcodes . ACC_INTERFACE ) != 0 ) { buf . append ( ""interface "" ) ; } else if ( ( access & Opcodes . ACC_ENUM ) == 0 ) { buf . append ( ""class "" ) ; } appendDescriptor ( INTERNAL_NAME , name ) ; if ( superName != null && ! ""java/lang/Object"" . equals ( superName ) ) { buf . append ( "" extends "" ) ; appendDescriptor ( INTERNAL_NAME , superName ) ; buf . append ( ' ' ) ; } if ( interfaces != null && interfaces . length > 0 ) { buf . append ( "" implements "" ) ; for ( int i = 0 ; i < interfaces . length ; ++ i ) { appendDescriptor ( INTERNAL_NAME , interfaces [ i ] ) ; buf . append ( ' ' ) ; } } buf . append ( "" {\n\n"" ) ; text . add ( buf . toString ( ) ) ; } @ Override public void visitSource ( final String file , final String debug ) { buf . setLength ( 0 ) ; if ( file != null ) { buf . append ( tab ) . append ( ""// compiled from: "" ) . append ( file ) . append ( '\n' ) ; } if ( debug != null ) { buf . append ( tab ) . append ( ""// debug info: "" ) . append ( debug ) . append ( '\n' ) ; } if ( buf . length ( ) > 0 ) { text . add ( buf . toString ( ) ) ; } } @ Override public void visitOuterClass ( final String owner , final String name , final String desc ) { buf . setLength ( 0 ) ; buf . append ( tab ) . append ( ""OUTERCLASS "" ) ; appendDescriptor ( INTERNAL_NAME , owner ) ; buf . append ( ' ' ) ; if ( name != null ) { buf . append ( name ) . append ( ' ' ) ; } appendDescriptor ( METHOD_DESCRIPTOR , desc ) ; buf . append ( '\n' ) ; text . add ( buf . toString ( ) ) ; } @ Override public Textifier visitClassAnnotation ( final String desc , final boolean visible ) { text . add ( ""\n"" ) ; return visitAnnotation ( desc , visible ) ; } @ Override public void visitClassAttribute ( final Attribute attr ) { text . add ( ""\n"" ) ; visitAttribute ( attr ) ; } @ Override public void visitInnerClass ( final String name , final String outerName , final String innerName , final int access ) { buf . setLength ( 0 ) ; buf . append ( tab ) . append ( ""// access flags 0x"" ) ; buf . append ( Integer . toHexString ( access & ~ Opcodes . ACC_SUPER ) . toUpperCase ( ) ) . append ( '\n' ) ; buf . append ( tab ) ; appendAccess ( access ) ; buf . append ( ""INNERCLASS "" ) ; appendDescriptor ( INTERNAL_NAME , name ) ; buf . append ( ' ' ) ; appendDescriptor ( INTERNAL_NAME , outerName ) ; buf . append ( ' ' ) ; appendDescriptor ( INTERNAL_NAME , innerName ) ; buf . append ( '\n' ) ; text . add ( buf . toString ( ) ) ; } @ Override public Textifier visitField ( final int access , final String name , final String desc , final String signature , final Object value ) { buf . setLength ( 0 ) ; buf . append ( '\n' ) ; if ( ( access & Opcodes . ACC_DEPRECATED ) != 0 ) { buf . append ( tab ) . append ( ""// DEPRECATED\n"" ) ; } buf . append ( tab ) . append ( ""// access flags 0x"" ) . append ( Integer . toHexString ( access ) . toUpperCase ( ) ) . append ( '\n' ) ; if ( signature != null ) { buf . append ( tab ) ; appendDescriptor ( FIELD_SIGNATURE , signature ) ; TraceSignatureVisitor sv = new TraceSignatureVisitor ( 0 ) ; SignatureReader r = new SignatureReader ( signature ) ; r . acceptType ( sv ) ; buf . append ( tab ) . append ( ""// declaration: "" ) . append ( sv . getDeclaration ( ) ) . append ( '\n' ) ; } buf . append ( tab ) ; appendAccess ( access ) ; appendDescriptor ( FIELD_DESCRIPTOR , desc ) ; buf . append ( ' ' ) . append ( name ) ; if ( value != null ) { buf . append ( "" = "" ) ; if ( value instanceof String ) { buf . append ( '\""' ) . append ( value ) . append ( '\""' ) ; } else { buf . append ( value ) ; } } buf . append ( '\n' ) ; text . add ( buf . toString ( ) ) ; Textifier t = createTextifier ( ) ; text . add ( t . getText ( ) ) ; return t ; } @ Override public Textifier visitMethod ( final int access , final String name , final String desc , final String signature , final String [ ] exceptions ) { buf . setLength ( 0 ) ; buf . append ( '\n' ) ; if ( ( access & Opcodes . ACC_DEPRECATED ) != 0 ) { buf . append ( tab ) . append ( ""// DEPRECATED\n"" ) ; } buf . append ( tab ) . append ( ""// access flags 0x"" ) . append ( Integer . toHexString ( access ) . toUpperCase ( ) ) . append ( '\n' ) ; if ( signature != null ) { buf . append ( tab ) ; appendDescriptor ( METHOD_SIGNATURE , signature ) ; TraceSignatureVisitor v = new TraceSignatureVisitor ( 0 ) ; SignatureReader r = new SignatureReader ( signature ) ; r . accept ( v ) ; String genericDecl = v . getDeclaration ( ) ; String genericReturn = v . getReturnType ( ) ; String genericExceptions = v . getExceptions ( ) ; buf . append ( tab ) . append ( ""// declaration: "" ) . append ( genericReturn ) . append ( ' ' ) . append ( name ) . append ( genericDecl ) ; if ( genericExceptions != null ) { buf . append ( "" throws "" ) . append ( genericExceptions ) ; } buf . append ( '\n' ) ; } buf . append ( tab ) ; appendAccess ( access ) ; if ( ( access & Opcodes . ACC_NATIVE ) != 0 ) { buf . append ( ""native "" ) ; } if ( ( access & Opcodes . ACC_VARARGS ) != 0 ) { buf . append ( ""varargs "" ) ; } if ( ( access & Opcodes . ACC_BRIDGE ) != 0 ) { buf . append ( ""bridge "" ) ; } buf . append ( name ) ; appendDescriptor ( METHOD_DESCRIPTOR , desc ) ; if ( exceptions != null && exceptions . length > 0 ) { buf . append ( "" throws "" ) ; for ( int i = 0 ; i < exceptions . length ; ++ i ) { appendDescriptor ( INTERNAL_NAME , exceptions [ i ] ) ; buf . append ( ' ' ) ; } } buf . append ( '\n' ) ; text . add ( buf . toString ( ) ) ; Textifier t = createTextifier ( ) ; text . add ( t . getText ( ) ) ; return t ; } @ Override public void visitClassEnd ( ) { text . add ( ""}\n"" ) ; } @ Override public void visit ( final String name , final Object value ) { buf . setLength ( 0 ) ; appendComa ( valueNumber ++ ) ; if ( name != null ) { buf . append ( name ) . append ( '=' ) ; } if ( value instanceof String ) { visitString ( ( String ) value ) ; } else if ( value instanceof Type ) { visitType ( ( Type ) value ) ; } else if ( value instanceof Byte ) { visitByte ( ( ( Byte ) value ) . byteValue ( ) ) ; } else if ( value instanceof Boolean ) { visitBoolean ( ( ( Boolean ) value ) . booleanValue ( ) ) ; } else if ( value instanceof Short ) { visitShort ( ( ( Short ) value ) . shortValue ( ) ) ; } else if ( value instanceof Character ) { visitChar ( ( ( Character ) value ) . charValue ( ) ) ; } else if ( value instanceof Integer ) { visitInt ( ( ( Integer ) value ) . intValue ( ) ) ; } else if ( value instanceof Float ) { visitFloat ( ( ( Float ) value ) . floatValue ( ) ) ; } else if ( value instanceof Long ) { visitLong ( ( ( Long ) value ) . longValue ( ) ) ; } else if ( value instanceof Double ) { visitDouble ( ( ( Double ) value ) . doubleValue ( ) ) ; } else if ( value . getClass ( ) . isArray ( ) ) { buf . append ( '{' ) ; if ( value instanceof byte [ ] ) { byte [ ] v = ( byte [ ] ) value ; for ( int i = 0 ; i < v . length ; i ++ ) { appendComa ( i ) ; visitByte ( v [ i ] ) ; } } else if ( value instanceof boolean [ ] ) { boolean [ ] v = ( boolean [ ] ) value ; for ( int i = 0 ; i < v . length ; i ++ ) { appendComa ( i ) ; visitBoolean ( v [ i ] ) ; } } else if ( value instanceof short [ ] ) { short [ ] v = ( short [ ] ) value ; for ( int i = 0 ; i < v . length ; i ++ ) { appendComa ( i ) ; visitShort ( v [ i ] ) ; } } else if ( value instanceof char [ ] ) { char [ ] v = ( char [ ] ) value ; for ( int i = 0 ; i < v . length ; i ++ ) { appendComa ( i ) ; visitChar ( v [ i ] ) ; } } else if ( value instanceof int [ ] ) { int [ ] v = ( int [ ] ) value ; for ( int i = 0 ; i < v . length ; i ++ ) { appendComa ( i ) ; visitInt ( v [ i ] ) ; } } else if ( value instanceof long [ ] ) { long [ ] v = ( long [ ] ) value ; for ( int i = 0 ; i < v . length ; i ++ ) { appendComa ( i ) ; visitLong ( v [ i ] ) ; } } else if ( value instanceof float [ ] ) { float [ ] v = ( float [ ] ) value ; for ( int i = 0 ; i < v . length ; i ++ ) { appendComa ( i ) ; visitFloat ( v [ i ] ) ; } } else if ( value instanceof double [ ] ) { double [ ] v = ( double [ ] ) value ; for ( int i = 0 ; i < v . length ; i ++ ) { appendComa ( i ) ; visitDouble ( v [ i ] ) ; } } buf . append ( '}' ) ; } text . add ( buf . toString ( ) ) ; } private void visitInt ( final int value ) { buf . append ( value ) ; } private void visitLong ( final long value ) { buf . append ( value ) . append ( 'L' ) ; } private void visitFloat ( final float value ) { buf . append ( value ) . append ( 'F' ) ; } private void visitDouble ( final double value ) { buf . append ( value ) . append ( 'D' ) ; } private void visitChar ( final char value ) { buf . append ( ""(char)"" ) . append ( ( int ) value ) ; } private void visitShort ( final short value ) { buf . append ( ""(short)"" ) . append ( value ) ; } private void visitByte ( final byte value ) { buf . append ( ""(byte)"" ) . append ( value ) ; } private void visitBoolean ( final boolean value ) { buf . append ( value ) ; } private void visitString ( final String value ) { appendString ( buf , value ) ; } private void visitType ( final Type value ) { buf . append ( value . getClassName ( ) ) . append ( "".class"" ) ; } @ Override public void visitEnum ( final String name , final String desc , final String value ) { buf . setLength ( 0 ) ; appendComa ( valueNumber ++ ) ; if ( name != null ) { buf . append ( name ) . append ( '=' ) ; } appendDescriptor ( FIELD_DESCRIPTOR , desc ) ; buf . append ( '.' ) . append ( value ) ; text . add ( buf . toString ( ) ) ; } @ Override public Textifier visitAnnotation ( final String name , final String desc ) { buf . setLength ( 0 ) ; appendComa ( valueNumber ++ ) ; if ( name != null ) { buf . append ( name ) . append ( '=' ) ; } buf . append ( '@' ) ; appendDescriptor ( FIELD_DESCRIPTOR , desc ) ; buf . append ( '(' ) ; text . add ( buf . toString ( ) ) ; Textifier t = createTextifier ( ) ; text . add ( t . getText ( ) ) ; text . add ( "")"" ) ; return t ; } @ Override public Textifier visitArray ( final String name ) { buf . setLength ( 0 ) ; appendComa ( valueNumber ++ ) ; if ( name != null ) { buf . append ( name ) . append ( '=' ) ; } buf . append ( '{' ) ; text . add ( buf . toString ( ) ) ; Textifier t = createTextifier ( ) ; text . add ( t . getText ( ) ) ; text . add ( ""}"" ) ; return t ; } @ Override public void visitAnnotationEnd ( ) { } @ Override public Textifier visitFieldAnnotation ( final String desc , final boolean visible ) { return visitAnnotation ( desc , visible ) ; } @ Override public void visitFieldAttribute ( final Attribute attr ) { visitAttribute ( attr ) ; } @ Override public void visitFieldEnd ( ) { } @ Override public Textifier visitAnnotationDefault ( ) { text . add ( tab2 + ""default="" ) ; Textifier t = createTextifier ( ) ; text . add ( t . getText ( ) ) ; text . add ( ""\n"" ) ; return t ; } @ Override public Textifier visitMethodAnnotation ( final String desc , final boolean visible ) { return visitAnnotation ( desc , visible ) ; } @ Override public Textifier visitParameterAnnotation ( final int parameter , final String desc , final boolean visible ) { buf . setLength ( 0 ) ; buf . append ( tab2 ) . append ( '@' ) ; appendDescriptor ( FIELD_DESCRIPTOR , desc ) ; buf . append ( '(' ) ; text . add ( buf . toString ( ) ) ; Textifier t = createTextifier ( ) ; text . add ( t . getText ( ) ) ; text . add ( visible ? "") // parameter "" : "") // invisible, parameter "" ) ; text . add ( new Integer ( parameter ) ) ; text . add ( ""\n"" ) ; return t ; } @ Override public void visitMethodAttribute ( final Attribute attr ) { buf . setLength ( 0 ) ; buf . append ( tab ) . append ( ""ATTRIBUTE "" ) ; appendDescriptor ( - 1 , attr . type ) ; if ( attr instanceof Textifiable ) { ( ( Textifiable ) attr ) . textify ( buf , labelNames ) ; } else { buf . append ( "" : unknown\n"" ) ; } text . add ( buf . toString ( ) ) ; } @ Override public void visitCode ( ) { } @ Override public void visitFrame ( final int type , final int nLocal , final Object [ ] local , final int nStack , final Object [ ] stack ) { buf . setLength ( 0 ) ; buf . append ( ltab ) ; buf . append ( ""FRAME "" ) ; switch ( type ) { case Opcodes . F_NEW : case Opcodes . F_FULL : buf . append ( ""FULL ["" ) ; appendFrameTypes ( nLocal , local ) ; buf . append ( ""] ["" ) ; appendFrameTypes ( nStack , stack ) ; buf . append ( ']' ) ; break ; case Opcodes . F_APPEND : buf . append ( ""APPEND ["" ) ; appendFrameTypes ( nLocal , local ) ; buf . append ( ']' ) ; break ; case Opcodes . F_CHOP : buf . append ( ""CHOP "" ) . append ( nLocal ) ; break ; case Opcodes . F_SAME : buf . append ( ""SAME"" ) ; break ; case Opcodes . F_SAME1 : buf . append ( ""SAME1 "" ) ; appendFrameTypes ( 1 , stack ) ; break ; } buf . append ( '\n' ) ; text . add ( buf . toString ( ) ) ; } @ Override public void visitInsn ( final int opcode ) { buf . setLength ( 0 ) ; buf . append ( tab2 ) . append ( OPCODES [ opcode ] ) . append ( '\n' ) ; text . add ( buf . toString ( ) ) ; } @ Override public void visitIntInsn ( final int opcode , final int operand ) { buf . setLength ( 0 ) ; buf . append ( tab2 ) . append ( OPCODES [ opcode ] ) . append ( ' ' ) . append ( opcode == Opcodes . NEWARRAY ? TYPES [ operand ] : Integer . toString ( operand ) ) . append ( '\n' ) ; text . add ( buf . toString ( ) ) ; } @ Override public void visitVarInsn ( final int opcode , final int var ) { buf . setLength ( 0 ) ; buf . append ( tab2 ) . append ( OPCODES [ opcode ] ) . append ( ' ' ) . append ( var ) . append ( '\n' ) ; text . add ( buf . toString ( ) ) ; } @ Override public void visitTypeInsn ( final int opcode , final String type ) { buf . setLength ( 0 ) ; buf . append ( tab2 ) . append ( OPCODES [ opcode ] ) . append ( ' ' ) ; appendDescriptor ( INTERNAL_NAME , type ) ; buf . append ( '\n' ) ; text . add ( buf . toString ( ) ) ; } @ Override public void visitFieldInsn ( final int opcode , final String owner , final String name , final String desc ) { buf . setLength ( 0 ) ; buf . append ( tab2 ) . append ( OPCODES [ opcode ] ) . append ( ' ' ) ; appendDescriptor ( INTERNAL_NAME , owner ) ; buf . append ( '.' ) . append ( name ) . append ( "" : "" ) ; appendDescriptor ( FIELD_DESCRIPTOR , desc ) ; buf . append ( '\n' ) ; text . add ( buf . toString ( ) ) ; } @ Override public void visitMethodInsn ( final int opcode , final String owner , final String name , final String desc ) { buf . setLength ( 0 ) ; buf . append ( tab2 ) . append ( OPCODES [ opcode ] ) . append ( ' ' ) ; appendDescriptor ( INTERNAL_NAME , owner ) ; buf . append ( '.' ) . append ( name ) . append ( ' ' ) ; appendDescriptor ( METHOD_DESCRIPTOR , desc ) ; buf . append ( '\n' ) ; text . add ( buf . toString ( ) ) ; } @ Override public void visitInvokeDynamicInsn ( String name , String desc , Handle bsm , Object ... bsmArgs ) { buf . setLength ( 0 ) ; buf . append ( tab2 ) . append ( ""INVOKEDYNAMIC"" ) . append ( ' ' ) ; buf . append ( name ) ; appendDescriptor ( METHOD_DESCRIPTOR , desc ) ; buf . append ( "" ["" ) ; appendHandle ( bsm ) ; buf . append ( tab3 ) . append ( ""// arguments:"" ) ; if ( bsmArgs . length == 0 ) { buf . append ( "" none"" ) ; } else { buf . append ( '\n' ) . append ( tab3 ) ; for ( int i = 0 ; i < bsmArgs . length ; i ++ ) { Object cst = bsmArgs [ i ] ; if ( cst instanceof String ) { Printer . appendString ( buf , ( String ) cst ) ; } else if ( cst instanceof Type ) { buf . append ( ( ( Type ) cst ) . getDescriptor ( ) ) . append ( "".class"" ) ; } else if ( cst instanceof Handle ) { appendHandle ( ( Handle ) cst ) ; } else { buf . append ( cst ) ; } buf . append ( "", "" ) ; } buf . setLength ( buf . length ( ) - 2 ) ; } buf . append ( '\n' ) ; buf . append ( tab2 ) . append ( ""]\n"" ) ; text . add ( buf . toString ( ) ) ; } @ Override public void visitJumpInsn ( final int opcode , final Label label ) { buf . setLength ( 0 ) ; buf . append ( tab2 ) . append ( OPCODES [ opcode ] ) . append ( ' ' ) ; appendLabel ( label ) ; buf . append ( '\n' ) ; text . add ( buf . toString ( ) ) ; } @ Override public void visitLabel ( final Label label ) { buf . setLength ( 0 ) ; buf . append ( ltab ) ; appendLabel ( label ) ; buf . append ( '\n' ) ; text . add ( buf . toString ( ) ) ; } @ Override public void visitLdcInsn ( final Object cst ) { buf . setLength ( 0 ) ; buf . append ( tab2 ) . append ( ""LDC "" ) ; if ( cst instanceof String ) { Printer . appendString ( buf , ( String ) cst ) ; } else if ( cst instanceof Type ) { buf . append ( ( ( Type ) cst ) . getDescriptor ( ) ) . append ( "".class"" ) ; } else { buf . append ( cst ) ; } buf . append ( '\n' ) ; text . add ( buf . toString ( ) ) ; } @ Override public void visitIincInsn ( final int var , final int increment ) { buf . setLength ( 0 ) ; buf . append ( tab2 ) . append ( ""IINC "" ) . append ( var ) . append ( ' ' ) . append ( increment ) . append ( '\n' ) ; text . add ( buf . toString ( ) ) ; } @ Override public void visitTableSwitchInsn ( final int min , final int max , final Label dflt , final Label ... labels ) { buf . setLength ( 0 ) ; buf . append ( tab2 ) . append ( ""TABLESWITCH\n"" ) ; for ( int i = 0 ; i < labels . length ; ++ i ) { buf . append ( tab3 ) . append ( min + i ) . append ( "": "" ) ; appendLabel ( labels [ i ] ) ; buf . append ( '\n' ) ; } buf . append ( tab3 ) . append ( ""default: "" ) ; appendLabel ( dflt ) ; buf . append ( '\n' ) ; text . add ( buf . toString ( ) ) ; } @ Override public void visitLookupSwitchInsn ( final Label dflt , final int [ ] keys , final Label [ ] labels ) { buf . setLength ( 0 ) ; buf . append ( tab2 ) . append ( ""LOOKUPSWITCH\n"" ) ; for ( int i = 0 ; i < labels . length ; ++ i ) { buf . append ( tab3 ) . append ( keys [ i ] ) . append ( "": "" ) ; appendLabel ( labels [ i ] ) ; buf . append ( '\n' ) ; } buf . append ( tab3 ) . append ( ""default: "" ) ; appendLabel ( dflt ) ; buf . append ( '\n' ) ; text . add ( buf . toString ( ) ) ; } @ Override public void visitMultiANewArrayInsn ( final String desc , final int dims ) { buf . setLength ( 0 ) ; buf . append ( tab2 ) . append ( ""MULTIANEWARRAY "" ) ; appendDescriptor ( FIELD_DESCRIPTOR , desc ) ; buf . append ( ' ' ) . append ( dims ) . append ( '\n' ) ; text . add ( buf . toString ( ) ) ; } @ Override public void visitTryCatchBlock ( final Label start , final Label end , final Label handler , final String type ) { buf . setLength ( 0 ) ; buf . append ( tab2 ) . append ( ""TRYCATCHBLOCK "" ) ; appendLabel ( start ) ; buf . append ( ' ' ) ; appendLabel ( end ) ; buf . append ( ' ' ) ; appendLabel ( handler ) ; buf . append ( ' ' ) ; appendDescriptor ( INTERNAL_NAME , type ) ; buf . append ( '\n' ) ; text . add ( buf . toString ( ) ) ; } @ Override public void visitLocalVariable ( final String name , final String desc , final String signature , final Label start , final Label end , final int index ) { buf . setLength ( 0 ) ; buf . append ( tab2 ) . append ( ""LOCALVARIABLE "" ) . append ( name ) . append ( ' ' ) ; appendDescriptor ( FIELD_DESCRIPTOR , desc ) ; buf . append ( ' ' ) ; appendLabel ( start ) ; buf . append ( ' ' ) ; appendLabel ( end ) ; buf . append ( ' ' ) . append ( index ) . append ( '\n' ) ; if ( signature != null ) { buf . append ( tab2 ) ; appendDescriptor ( FIELD_SIGNATURE , signature ) ; TraceSignatureVisitor sv = new TraceSignatureVisitor ( 0 ) ; SignatureReader r = new SignatureReader ( signature ) ; r . acceptType ( sv ) ; buf . append ( tab2 ) . append ( ""// declaration: "" ) . append ( sv . getDeclaration ( ) ) . append ( '\n' ) ; } text . add ( buf . toString ( ) ) ; } @ Override public void visitLineNumber ( final int line , final Label start ) { buf . setLength ( 0 ) ; buf . append ( tab2 ) . append ( ""LINENUMBER "" ) . append ( line ) . append ( ' ' ) ; appendLabel ( start ) ; buf . append ( '\n' ) ; text . add ( buf . toString ( ) ) ; } @ Override public void visitMaxs ( final int maxStack , final int maxLocals ) { buf . setLength ( 0 ) ; buf . append ( tab2 ) . append ( ""MAXSTACK = "" ) . append ( maxStack ) . append ( '\n' ) ; text . add ( buf . toString ( ) ) ; buf . setLength ( 0 ) ; buf . append ( tab2 ) . append ( ""MAXLOCALS = "" ) . append ( maxLocals ) . append ( '\n' ) ; text . add ( buf . toString ( ) ) ; } @ Override public void visitMethodEnd ( ) { } public Textifier visitAnnotation ( final String desc , final boolean visible ) { buf . setLength ( 0 ) ; buf . append ( tab ) . append ( '@' ) ; appendDescriptor ( FIELD_DESCRIPTOR , desc ) ; buf . append ( '(' ) ; text . add ( buf . toString ( ) ) ; Textifier t = createTextifier ( ) ; text . add ( t . getText ( ) ) ; text . add ( visible ? "")\n"" : "") // invisible\n"" ) ; return t ; } public void visitAttribute ( final Attribute attr ) { buf . setLength ( 0 ) ; buf . append ( tab ) . append ( ""ATTRIBUTE "" ) ; appendDescriptor ( - 1 , attr . type ) ; if ( attr instanceof Textifiable ) { ( ( Textifiable ) attr ) . textify ( buf , null ) ; } else { buf . append ( "" : unknown\n"" ) ; } text . add ( buf . toString ( ) ) ; } protected Textifier createTextifier ( ) { return new Textifier ( ) ; } protected void appendDescriptor ( final int type , final String desc ) { if ( type == CLASS_SIGNATURE || type == FIELD_SIGNATURE || type == METHOD_SIGNATURE ) { if ( desc != null ) { buf . append ( ""// signature "" ) . append ( desc ) . append ( '\n' ) ; } } else { buf . append ( desc ) ; } } protected void appendLabel ( final Label l ) { if ( labelNames == null ) { labelNames = new HashMap < Label , String > ( ) ; } String name = labelNames . get ( l ) ; if ( name == null ) { name = ""L"" + labelNames . size ( ) ; labelNames . put ( l , name ) ; } buf . append ( name ) ; } protected void appendHandle ( final Handle h ) { buf . append ( '\n' ) . append ( tab3 ) ; int tag = h . getTag ( ) ; buf . append ( ""// handle kind 0x"" ) . append ( Integer . toHexString ( tag ) ) . append ( "" : "" ) ; switch ( tag ) { case Opcodes . H_GETFIELD : buf . append ( ""GETFIELD"" ) ; break ; case Opcodes . H_GETSTATIC : buf . append ( ""GETSTATIC"" ) ; break ; case Opcodes . H_PUTFIELD : buf . append ( ""PUTFIELD"" ) ; break ; case Opcodes . H_PUTSTATIC : buf . append ( ""PUTSTATIC"" ) ; break ; case Opcodes . H_INVOKEINTERFACE : buf . append ( ""INVOKEINTERFACE"" ) ; break ; case Opcodes . H_INVOKESPECIAL : buf . append ( ""INVOKESPECIAL"" ) ; break ; case Opcodes . H_INVOKESTATIC : buf . append ( ""INVOKESTATIC"" ) ; break ; case Opcodes . H_INVOKEVIRTUAL : buf . append ( ""INVOKEVIRTUAL"" ) ; break ; case Opcodes . H_NEWINVOKESPECIAL : buf . append ( ""NEWINVOKESPECIAL"" ) ; break ; } buf . append ( '\n' ) ; buf . append ( tab3 ) ; appendDescriptor ( INTERNAL_NAME , h . getOwner ( ) ) ; buf . append ( '.' ) ; buf . append ( h . getName ( ) ) ; buf . append ( '(' ) ; appendDescriptor ( HANDLE_DESCRIPTOR , h . getDesc ( ) ) ; buf . append ( ')' ) . append ( '\n' ) ; } private void appendAccess ( final int access ) { if ( ( access & Opcodes . ACC_PUBLIC ) != 0 ) { buf . append ( ""public "" ) ; } if ( ( access & Opcodes . ACC_PRIVATE ) != 0 ) { buf . append ( ""private "" ) ; } if ( ( access & Opcodes . ACC_PROTECTED ) != 0 ) { buf . append ( ""protected "" ) ; } if ( ( access & Opcodes . ACC_FINAL ) != 0 ) { buf . append ( ""final "" ) ; } if ( ( access & Opcodes . ACC_STATIC ) != 0 ) { buf . append ( ""static "" ) ; } if ( ( access & Opcodes . ACC_SYNCHRONIZED ) != 0 ) { buf . append ( ""synchronized "" ) ; } if ( ( access & Opcodes . ACC_VOLATILE ) != 0 ) { buf . append ( ""volatile "" ) ; } if ( ( access & Opcodes . ACC_TRANSIENT ) != 0 ) { buf . append ( ""transient "" ) ; } if ( ( access & Opcodes . ACC_ABSTRACT ) != 0 ) { buf . append ( ""abstract "" ) ; } if ( ( access & Opcodes . ACC_STRICT ) != 0 ) { buf . append ( ""strictfp "" ) ; } if ( ( access & Opcodes . ACC_SYNTHETIC ) != 0 ) { buf . append ( ""synthetic "" ) ; } if ( ( access & Opcodes . ACC_ENUM ) != 0 ) { buf . append ( ""enum "" ) ; } } private void appendComa ( final int i ) { if ( i != 0 ) { buf . append ( "", "" ) ; } } private void appendFrameTypes ( final int n , final Object [ ] o ) { for ( int i = 0 ; i < n ; ++ i ) { if ( i > 0 ) { buf . append ( ' ' ) ; } if ( o [ i ] instanceof String ) { String desc = ( String ) o [ i ] ; if ( desc . startsWith ( ""["" ) ) { appendDescriptor ( FIELD_DESCRIPTOR , desc ) ; } else { appendDescriptor ( INTERNAL_NAME , desc ) ; } } else if ( o [ i ] instanceof Integer ) { switch ( ( ( Integer ) o [ i ] ) . intValue ( ) ) { case 0 : appendDescriptor ( FIELD_DESCRIPTOR , ""T"" ) ; break ; case 1 : appendDescriptor ( FIELD_DESCRIPTOR , ""I"" ) ; break ; case 2 : appendDescriptor ( FIELD_DESCRIPTOR , ""F"" ) ; break ; case 3 : appendDescriptor ( FIELD_DESCRIPTOR , ""D"" ) ; break ; case 4 : appendDescriptor ( FIELD_DESCRIPTOR , ""J"" ) ; break ; case 5 : appendDescriptor ( FIELD_DESCRIPTOR , ""N"" ) ; break ; case 6 : appendDescriptor ( FIELD_DESCRIPTOR , ""U"" ) ; break ; } } else { appendLabel ( ( Label ) o [ i ] ) ; } } } }",Smelly
"public abstract class SyntaxTreeNode implements Constants { private Parser _parser ; protected SyntaxTreeNode _parent ; private Stylesheet _stylesheet ; private Template _template ; private final Vector _contents = new Vector ( 2 ) ; protected QName _qname ; private int _line ; protected AttributeList _attributes = null ; private Hashtable _prefixMapping = null ; static final SyntaxTreeNode Dummy = new AbsolutePathPattern ( null ) ; protected static final int IndentIncrement = 4 ; private static final char [ ] _spaces = ""                                                       "" . toCharArray ( ) ; public SyntaxTreeNode ( ) { _line = 0 ; _qname = null ; } public SyntaxTreeNode ( int line ) { _line = line ; _qname = null ; } public SyntaxTreeNode ( String uri , String prefix , String local ) { _line = 0 ; setQName ( uri , prefix , local ) ; } protected final void setLineNumber ( int line ) { _line = line ; } public final int getLineNumber ( ) { if ( _line > 0 ) return _line ; SyntaxTreeNode parent = getParent ( ) ; return ( parent != null ) ? parent . getLineNumber ( ) : 0 ; } protected void setQName ( QName qname ) { _qname = qname ; } protected void setQName ( String uri , String prefix , String localname ) { _qname = new QName ( uri , prefix , localname ) ; } protected QName getQName ( ) { return ( _qname ) ; } protected void setAttributes ( AttributeList attributes ) { _attributes = attributes ; } protected String getAttribute ( String qname ) { if ( _attributes == null ) { return EMPTYSTRING ; } final String value = _attributes . getValue ( qname ) ; return ( value == null || value . equals ( EMPTYSTRING ) ) ? EMPTYSTRING : value ; } protected String getAttribute ( String prefix , String localName ) { return getAttribute ( prefix + ':' + localName ) ; } protected boolean hasAttribute ( String qname ) { return ( _attributes != null && _attributes . getValue ( qname ) != null ) ; } protected void addAttribute ( String qname , String value ) { _attributes . add ( qname , value ) ; } protected Attributes getAttributes ( ) { return ( _attributes ) ; } protected void setPrefixMapping ( Hashtable mapping ) { _prefixMapping = mapping ; } protected Hashtable getPrefixMapping ( ) { return _prefixMapping ; } protected void addPrefixMapping ( String prefix , String uri ) { if ( _prefixMapping == null ) _prefixMapping = new Hashtable ( ) ; _prefixMapping . put ( prefix , uri ) ; } protected String lookupNamespace ( String prefix ) { String uri = null ; if ( _prefixMapping != null ) uri = ( String ) _prefixMapping . get ( prefix ) ; if ( ( uri == null ) && ( _parent != null ) ) { uri = _parent . lookupNamespace ( prefix ) ; if ( ( prefix == Constants . EMPTYSTRING ) && ( uri == null ) ) uri = Constants . EMPTYSTRING ; } return ( uri ) ; } protected String lookupPrefix ( String uri ) { String prefix = null ; if ( ( _prefixMapping != null ) && ( _prefixMapping . contains ( uri ) ) ) { Enumeration prefixes = _prefixMapping . keys ( ) ; while ( prefixes . hasMoreElements ( ) ) { prefix = ( String ) prefixes . nextElement ( ) ; String mapsTo = ( String ) _prefixMapping . get ( prefix ) ; if ( mapsTo . equals ( uri ) ) return ( prefix ) ; } } else if ( _parent != null ) { prefix = _parent . lookupPrefix ( uri ) ; if ( ( uri == Constants . EMPTYSTRING ) && ( prefix == null ) ) prefix = Constants . EMPTYSTRING ; } return ( prefix ) ; } protected void setParser ( Parser parser ) { _parser = parser ; } public final Parser getParser ( ) { return _parser ; } protected void setParent ( SyntaxTreeNode parent ) { if ( _parent == null ) _parent = parent ; } protected final SyntaxTreeNode getParent ( ) { return _parent ; } protected final boolean isDummy ( ) { return this == Dummy ; } protected int getImportPrecedence ( ) { Stylesheet stylesheet = getStylesheet ( ) ; if ( stylesheet == null ) return Integer . MIN_VALUE ; return stylesheet . getImportPrecedence ( ) ; } public Stylesheet getStylesheet ( ) { if ( _stylesheet == null ) { SyntaxTreeNode parent = this ; while ( parent != null ) { if ( parent instanceof Stylesheet ) return ( ( Stylesheet ) parent ) ; parent = parent . getParent ( ) ; } _stylesheet = ( Stylesheet ) parent ; } return ( _stylesheet ) ; } protected Template getTemplate ( ) { if ( _template == null ) { SyntaxTreeNode parent = this ; while ( ( parent != null ) && ( ! ( parent instanceof Template ) ) ) parent = parent . getParent ( ) ; _template = ( Template ) parent ; } return ( _template ) ; } protected final XSLTC getXSLTC ( ) { return _parser . getXSLTC ( ) ; } protected final SymbolTable getSymbolTable ( ) { return ( _parser == null ) ? null : _parser . getSymbolTable ( ) ; } public void parseContents ( Parser parser ) { parseChildren ( parser ) ; } protected final void parseChildren ( Parser parser ) { Vector locals = null ; final int count = _contents . size ( ) ; for ( int i = 0 ; i < count ; i ++ ) { SyntaxTreeNode child = ( SyntaxTreeNode ) _contents . elementAt ( i ) ; parser . getSymbolTable ( ) . setCurrentNode ( child ) ; child . parseContents ( parser ) ; final QName varOrParamName = updateScope ( parser , child ) ; if ( varOrParamName != null ) { if ( locals == null ) { locals = new Vector ( 2 ) ; } locals . addElement ( varOrParamName ) ; } } parser . getSymbolTable ( ) . setCurrentNode ( this ) ; if ( locals != null ) { final int nLocals = locals . size ( ) ; for ( int i = 0 ; i < nLocals ; i ++ ) { parser . removeVariable ( ( QName ) locals . elementAt ( i ) ) ; } } } protected QName updateScope ( Parser parser , SyntaxTreeNode node ) { if ( node instanceof Variable ) { final Variable var = ( Variable ) node ; parser . addVariable ( var ) ; return var . getName ( ) ; } else if ( node instanceof Param ) { final Param param = ( Param ) node ; parser . addParameter ( param ) ; return param . getName ( ) ; } else { return null ; } } public abstract Type typeCheck ( SymbolTable stable ) throws TypeCheckError ; protected Type typeCheckContents ( SymbolTable stable ) throws TypeCheckError { final int n = elementCount ( ) ; for ( int i = 0 ; i < n ; i ++ ) { SyntaxTreeNode item = ( SyntaxTreeNode ) _contents . elementAt ( i ) ; item . typeCheck ( stable ) ; } return Type . Void ; } public abstract void translate ( ClassGenerator classGen , MethodGenerator methodGen ) ; protected void translateContents ( ClassGenerator classGen , MethodGenerator methodGen ) { final int n = elementCount ( ) ; for ( int i = 0 ; i < n ; i ++ ) { final SyntaxTreeNode item = ( SyntaxTreeNode ) _contents . elementAt ( i ) ; item . translate ( classGen , methodGen ) ; } for ( int i = 0 ; i < n ; i ++ ) { if ( _contents . elementAt ( i ) instanceof VariableBase ) { final VariableBase var = ( VariableBase ) _contents . elementAt ( i ) ; var . unmapRegister ( methodGen ) ; } } } private boolean isSimpleRTF ( SyntaxTreeNode node ) { Vector contents = node . getContents ( ) ; for ( int i = 0 ; i < contents . size ( ) ; i ++ ) { SyntaxTreeNode item = ( SyntaxTreeNode ) contents . elementAt ( i ) ; if ( ! isTextElement ( item , false ) ) return false ; } return true ; } private boolean isAdaptiveRTF ( SyntaxTreeNode node ) { Vector contents = node . getContents ( ) ; for ( int i = 0 ; i < contents . size ( ) ; i ++ ) { SyntaxTreeNode item = ( SyntaxTreeNode ) contents . elementAt ( i ) ; if ( ! isTextElement ( item , true ) ) return false ; } return true ; } private boolean isTextElement ( SyntaxTreeNode node , boolean doExtendedCheck ) { if ( node instanceof ValueOf || node instanceof Number || node instanceof Text ) { return true ; } else if ( node instanceof If ) { return doExtendedCheck ? isAdaptiveRTF ( node ) : isSimpleRTF ( node ) ; } else if ( node instanceof Choose ) { Vector contents = node . getContents ( ) ; for ( int i = 0 ; i < contents . size ( ) ; i ++ ) { SyntaxTreeNode item = ( SyntaxTreeNode ) contents . elementAt ( i ) ; if ( item instanceof Text || ( ( item instanceof When || item instanceof Otherwise ) && ( ( doExtendedCheck && isAdaptiveRTF ( item ) ) || ( ! doExtendedCheck && isSimpleRTF ( item ) ) ) ) ) continue ; else return false ; } return true ; } else if ( doExtendedCheck && ( node instanceof CallTemplate || node instanceof ApplyTemplates ) ) return true ; else return false ; } protected void compileResultTree ( ClassGenerator classGen , MethodGenerator methodGen ) { final ConstantPoolGen cpg = classGen . getConstantPool ( ) ; final InstructionList il = methodGen . getInstructionList ( ) ; final Stylesheet stylesheet = classGen . getStylesheet ( ) ; boolean isSimple = isSimpleRTF ( this ) ; boolean isAdaptive = false ; if ( ! isSimple ) { isAdaptive = isAdaptiveRTF ( this ) ; } int rtfType = isSimple ? DOM . SIMPLE_RTF : ( isAdaptive ? DOM . ADAPTIVE_RTF : DOM . TREE_RTF ) ; il . append ( methodGen . loadHandler ( ) ) ; final String DOM_CLASS = classGen . getDOMClass ( ) ; il . append ( methodGen . loadDOM ( ) ) ; int index = cpg . addInterfaceMethodref ( DOM_INTF , ""getResultTreeFrag"" , ""(IIZ)"" + DOM_INTF_SIG ) ; il . append ( new PUSH ( cpg , RTF_INITIAL_SIZE ) ) ; il . append ( new PUSH ( cpg , rtfType ) ) ; il . append ( new PUSH ( cpg , stylesheet . callsNodeset ( ) ) ) ; il . append ( new INVOKEINTERFACE ( index , 4 ) ) ; il . append ( DUP ) ; index = cpg . addInterfaceMethodref ( DOM_INTF , ""getOutputDomBuilder"" , ""()"" + TRANSLET_OUTPUT_SIG ) ; il . append ( new INVOKEINTERFACE ( index , 1 ) ) ; il . append ( DUP ) ; il . append ( methodGen . storeHandler ( ) ) ; il . append ( methodGen . startDocument ( ) ) ; translateContents ( classGen , methodGen ) ; il . append ( methodGen . loadHandler ( ) ) ; il . append ( methodGen . endDocument ( ) ) ; if ( stylesheet . callsNodeset ( ) && ! DOM_CLASS . equals ( DOM_IMPL_CLASS ) ) { index = cpg . addMethodref ( DOM_ADAPTER_CLASS , ""<init>"" , ""("" + DOM_INTF_SIG + ""["" + STRING_SIG + ""["" + STRING_SIG + ""[I"" + ""["" + STRING_SIG + "")V"" ) ; il . append ( new NEW ( cpg . addClass ( DOM_ADAPTER_CLASS ) ) ) ; il . append ( new DUP_X1 ( ) ) ; il . append ( SWAP ) ; if ( ! stylesheet . callsNodeset ( ) ) { il . append ( new ICONST ( 0 ) ) ; il . append ( new ANEWARRAY ( cpg . addClass ( STRING ) ) ) ; il . append ( DUP ) ; il . append ( DUP ) ; il . append ( new ICONST ( 0 ) ) ; il . append ( new NEWARRAY ( BasicType . INT ) ) ; il . append ( SWAP ) ; il . append ( new INVOKESPECIAL ( index ) ) ; } else { il . append ( ALOAD_0 ) ; il . append ( new GETFIELD ( cpg . addFieldref ( TRANSLET_CLASS , NAMES_INDEX , NAMES_INDEX_SIG ) ) ) ; il . append ( ALOAD_0 ) ; il . append ( new GETFIELD ( cpg . addFieldref ( TRANSLET_CLASS , URIS_INDEX , URIS_INDEX_SIG ) ) ) ; il . append ( ALOAD_0 ) ; il . append ( new GETFIELD ( cpg . addFieldref ( TRANSLET_CLASS , TYPES_INDEX , TYPES_INDEX_SIG ) ) ) ; il . append ( ALOAD_0 ) ; il . append ( new GETFIELD ( cpg . addFieldref ( TRANSLET_CLASS , NAMESPACE_INDEX , NAMESPACE_INDEX_SIG ) ) ) ; il . append ( new INVOKESPECIAL ( index ) ) ; il . append ( DUP ) ; il . append ( methodGen . loadDOM ( ) ) ; il . append ( new CHECKCAST ( cpg . addClass ( classGen . getDOMClass ( ) ) ) ) ; il . append ( SWAP ) ; index = cpg . addMethodref ( MULTI_DOM_CLASS , ""addDOMAdapter"" , ""("" + DOM_ADAPTER_SIG + "")I"" ) ; il . append ( new INVOKEVIRTUAL ( index ) ) ; il . append ( POP ) ; } } il . append ( SWAP ) ; il . append ( methodGen . storeHandler ( ) ) ; } protected boolean contextDependent ( ) { return true ; } protected boolean dependentContents ( ) { final int n = elementCount ( ) ; for ( int i = 0 ; i < n ; i ++ ) { final SyntaxTreeNode item = ( SyntaxTreeNode ) _contents . elementAt ( i ) ; if ( item . contextDependent ( ) ) { return true ; } } return false ; } protected final void addElement ( SyntaxTreeNode element ) { _contents . addElement ( element ) ; element . setParent ( this ) ; } protected final void setFirstElement ( SyntaxTreeNode element ) { _contents . insertElementAt ( element , 0 ) ; element . setParent ( this ) ; } protected final void removeElement ( SyntaxTreeNode element ) { _contents . remove ( element ) ; element . setParent ( null ) ; } protected final Vector getContents ( ) { return _contents ; } protected final boolean hasContents ( ) { return elementCount ( ) > 0 ; } protected final int elementCount ( ) { return _contents . size ( ) ; } protected final Enumeration elements ( ) { return _contents . elements ( ) ; } protected final Object elementAt ( int pos ) { return _contents . elementAt ( pos ) ; } protected final SyntaxTreeNode lastChild ( ) { if ( _contents . size ( ) == 0 ) return null ; return ( SyntaxTreeNode ) _contents . lastElement ( ) ; } public void display ( int indent ) { displayContents ( indent ) ; } protected void displayContents ( int indent ) { final int n = elementCount ( ) ; for ( int i = 0 ; i < n ; i ++ ) { SyntaxTreeNode item = ( SyntaxTreeNode ) _contents . elementAt ( i ) ; item . display ( indent ) ; } } protected final void indent ( int indent ) { System . out . print ( new String ( _spaces , 0 , indent ) ) ; } protected void reportError ( SyntaxTreeNode element , Parser parser , String errorCode , String message ) { final ErrorMsg error = new ErrorMsg ( errorCode , message , element ) ; parser . reportError ( Constants . ERROR , error ) ; } protected void reportWarning ( SyntaxTreeNode element , Parser parser , String errorCode , String message ) { final ErrorMsg error = new ErrorMsg ( errorCode , message , element ) ; parser . reportError ( Constants . WARNING , error ) ; } }",Smelly
"public class BasicEvalNodeVisitor < CONTEXT , RESULT > implements EvalNodeVisitor2 < CONTEXT , RESULT > { @ Override public RESULT visit ( CONTEXT context , EvalNode evalNode , Stack < EvalNode > stack ) { RESULT result ; switch ( evalNode . getType ( ) ) { case CONST : result = visitConst ( context , ( ConstEval ) evalNode , stack ) ; break ; case ROW_CONSTANT : result = visitRowConstant ( context , ( RowConstantEval ) evalNode , stack ) ; break ; case FIELD : result = visitField ( context , stack , ( FieldEval ) evalNode ) ; break ; case PLUS : result = visitPlus ( context , ( BinaryEval ) evalNode , stack ) ; break ; case MINUS : result = visitMinus ( context , ( BinaryEval ) evalNode , stack ) ; break ; case MULTIPLY : result = visitMultiply ( context , ( BinaryEval ) evalNode , stack ) ; break ; case DIVIDE : result = visitDivide ( context , ( BinaryEval ) evalNode , stack ) ; break ; case MODULAR : result = visitModular ( context , ( BinaryEval ) evalNode , stack ) ; break ; case AND : result = visitAnd ( context , ( BinaryEval ) evalNode , stack ) ; break ; case OR : result = visitOr ( context , ( BinaryEval ) evalNode , stack ) ; break ; case NOT : result = visitNot ( context , ( NotEval ) evalNode , stack ) ; break ; case EQUAL : result = visitEqual ( context , ( BinaryEval ) evalNode , stack ) ; break ; case NOT_EQUAL : result = visitNotEqual ( context , ( BinaryEval ) evalNode , stack ) ; break ; case LTH : result = visitLessThan ( context , ( BinaryEval ) evalNode , stack ) ; break ; case LEQ : result = visitLessThanOrEqual ( context , ( BinaryEval ) evalNode , stack ) ; break ; case GTH : result = visitGreaterThan ( context , ( BinaryEval ) evalNode , stack ) ; break ; case GEQ : result = visitGreaterThanOrEqual ( context , ( BinaryEval ) evalNode , stack ) ; break ; case IS_NULL : result = visitIsNull ( context , ( IsNullEval ) evalNode , stack ) ; break ; case BETWEEN : result = visitBetween ( context , ( BetweenPredicateEval ) evalNode , stack ) ; break ; case CASE : result = visitCaseWhen ( context , ( CaseWhenEval ) evalNode , stack ) ; break ; case IF_THEN : result = visitIfThen ( context , ( CaseWhenEval . IfThenEval ) evalNode , stack ) ; break ; case IN : result = visitInPredicate ( context , ( InEval ) evalNode , stack ) ; break ; case LIKE : result = visitLike ( context , ( LikePredicateEval ) evalNode , stack ) ; break ; case SIMILAR_TO : result = visitSimilarTo ( context , ( SimilarToPredicateEval ) evalNode , stack ) ; break ; case REGEX : result = visitRegex ( context , ( RegexPredicateEval ) evalNode , stack ) ; break ; case CONCATENATE : result = visitConcatenate ( context , ( BinaryEval ) evalNode , stack ) ; break ; case FUNCTION : result = visitFuncCall ( context , ( GeneralFunctionEval ) evalNode , stack ) ; break ; case AGG_FUNCTION : result = visitAggrFuncCall ( context , ( AggregationFunctionCallEval ) evalNode , stack ) ; break ; case WINDOW_FUNCTION : result = visitWindowFunc ( context , ( WindowFunctionEval ) evalNode , stack ) ; break ; case SIGNED : result = visitSigned ( context , ( SignedEval ) evalNode , stack ) ; break ; case CAST : result = visitCast ( context , ( CastEval ) evalNode , stack ) ; break ; case SUBQUERY : result = visitSubquery ( context , ( SubqueryEval ) evalNode , stack ) ; break ; default : throw new TajoRuntimeException ( new UnsupportedException ( ""EvalType '"" + evalNode + ""'"" ) ) ; } return result ; } private RESULT visitDefaultUnaryEval ( CONTEXT context , UnaryEval unaryEval , Stack < EvalNode > stack ) { stack . push ( unaryEval ) ; RESULT result = visit ( context , unaryEval . getChild ( ) , stack ) ; stack . pop ( ) ; return result ; } private RESULT visitDefaultBinaryEval ( CONTEXT context , BinaryEval binaryEval , Stack < EvalNode > stack ) { stack . push ( binaryEval ) ; RESULT result = visit ( context , binaryEval . getLeftExpr ( ) , stack ) ; visit ( context , binaryEval . getRightExpr ( ) , stack ) ; stack . pop ( ) ; return result ; } private RESULT visitDefaultFunctionEval ( CONTEXT context , FunctionEval functionEval , Stack < EvalNode > stack ) { RESULT result = null ; stack . push ( functionEval ) ; if ( functionEval . getArgs ( ) != null ) { for ( EvalNode arg : functionEval . getArgs ( ) ) { result = visit ( context , arg , stack ) ; } } stack . pop ( ) ; return result ; } @ Override public RESULT visitConst ( CONTEXT context , ConstEval evalNode , Stack < EvalNode > stack ) { return null ; } @ Override public RESULT visitRowConstant ( CONTEXT context , RowConstantEval evalNode , Stack < EvalNode > stack ) { return null ; } @ Override public RESULT visitField ( CONTEXT context , Stack < EvalNode > stack , FieldEval evalNode ) { return null ; } @ Override public RESULT visitPlus ( CONTEXT context , BinaryEval evalNode , Stack < EvalNode > stack ) { return visitDefaultBinaryEval ( context , evalNode , stack ) ; } @ Override public RESULT visitMinus ( CONTEXT context , BinaryEval evalNode , Stack < EvalNode > stack ) { return visitDefaultBinaryEval ( context , evalNode , stack ) ; } @ Override public RESULT visitMultiply ( CONTEXT context , BinaryEval evalNode , Stack < EvalNode > stack ) { return visitDefaultBinaryEval ( context , evalNode , stack ) ; } @ Override public RESULT visitDivide ( CONTEXT context , BinaryEval evalNode , Stack < EvalNode > stack ) { return visitDefaultBinaryEval ( context , evalNode , stack ) ; } @ Override public RESULT visitModular ( CONTEXT context , BinaryEval evalNode , Stack < EvalNode > stack ) { return visitDefaultBinaryEval ( context , evalNode , stack ) ; } @ Override public RESULT visitAnd ( CONTEXT context , BinaryEval evalNode , Stack < EvalNode > stack ) { return visitDefaultBinaryEval ( context , evalNode , stack ) ; } @ Override public RESULT visitOr ( CONTEXT context , BinaryEval evalNode , Stack < EvalNode > stack ) { return visitDefaultBinaryEval ( context , evalNode , stack ) ; } @ Override public RESULT visitNot ( CONTEXT context , NotEval evalNode , Stack < EvalNode > stack ) { return visitDefaultUnaryEval ( context , evalNode , stack ) ; } @ Override public RESULT visitEqual ( CONTEXT context , BinaryEval evalNode , Stack < EvalNode > stack ) { return visitDefaultBinaryEval ( context , evalNode , stack ) ; } @ Override public RESULT visitNotEqual ( CONTEXT context , BinaryEval evalNode , Stack < EvalNode > stack ) { return visitDefaultBinaryEval ( context , evalNode , stack ) ; } @ Override public RESULT visitLessThan ( CONTEXT context , BinaryEval evalNode , Stack < EvalNode > stack ) { return visitDefaultBinaryEval ( context , evalNode , stack ) ; } @ Override public RESULT visitLessThanOrEqual ( CONTEXT context , BinaryEval evalNode , Stack < EvalNode > stack ) { return visitDefaultBinaryEval ( context , evalNode , stack ) ; } @ Override public RESULT visitGreaterThan ( CONTEXT context , BinaryEval evalNode , Stack < EvalNode > stack ) { return visitDefaultBinaryEval ( context , evalNode , stack ) ; } @ Override public RESULT visitGreaterThanOrEqual ( CONTEXT context , BinaryEval evalNode , Stack < EvalNode > stack ) { return visitDefaultBinaryEval ( context , evalNode , stack ) ; } @ Override public RESULT visitIsNull ( CONTEXT context , IsNullEval evalNode , Stack < EvalNode > stack ) { return visitDefaultUnaryEval ( context , evalNode , stack ) ; } @ Override public RESULT visitBetween ( CONTEXT context , BetweenPredicateEval evalNode , Stack < EvalNode > stack ) { stack . push ( evalNode ) ; RESULT result = visit ( context , evalNode . getPredicand ( ) , stack ) ; visit ( context , evalNode . getBegin ( ) , stack ) ; visit ( context , evalNode . getEnd ( ) , stack ) ; return result ; } @ Override public RESULT visitCaseWhen ( CONTEXT context , CaseWhenEval evalNode , Stack < EvalNode > stack ) { RESULT result = null ; stack . push ( evalNode ) ; for ( CaseWhenEval . IfThenEval ifThenEval : evalNode . getIfThenEvals ( ) ) { result = visitIfThen ( context , ifThenEval , stack ) ; } if ( evalNode . hasElse ( ) ) { result = visit ( context , evalNode . getElse ( ) , stack ) ; } stack . pop ( ) ; return result ; } @ Override public RESULT visitIfThen ( CONTEXT context , CaseWhenEval . IfThenEval evalNode , Stack < EvalNode > stack ) { RESULT result ; stack . push ( evalNode ) ; result = visit ( context , evalNode . getCondition ( ) , stack ) ; visit ( context , evalNode . getResult ( ) , stack ) ; stack . pop ( ) ; return result ; } @ Override public RESULT visitInPredicate ( CONTEXT context , InEval evalNode , Stack < EvalNode > stack ) { return visitDefaultBinaryEval ( context , evalNode , stack ) ; } @ Override public RESULT visitLike ( CONTEXT context , LikePredicateEval evalNode , Stack < EvalNode > stack ) { return visitDefaultBinaryEval ( context , evalNode , stack ) ; } @ Override public RESULT visitSimilarTo ( CONTEXT context , SimilarToPredicateEval evalNode , Stack < EvalNode > stack ) { return visitDefaultBinaryEval ( context , evalNode , stack ) ; } @ Override public RESULT visitRegex ( CONTEXT context , RegexPredicateEval evalNode , Stack < EvalNode > stack ) { return visitDefaultBinaryEval ( context , evalNode , stack ) ; } @ Override public RESULT visitConcatenate ( CONTEXT context , BinaryEval evalNode , Stack < EvalNode > stack ) { return visitDefaultBinaryEval ( context , evalNode , stack ) ; } @ Override public RESULT visitFuncCall ( CONTEXT context , GeneralFunctionEval evalNode , Stack < EvalNode > stack ) { return visitDefaultFunctionEval ( context , evalNode , stack ) ; } @ Override public RESULT visitAggrFuncCall ( CONTEXT context , AggregationFunctionCallEval evalNode , Stack < EvalNode > stack ) { return visitDefaultFunctionEval ( context , evalNode , stack ) ; } @ Override public RESULT visitWindowFunc ( CONTEXT context , WindowFunctionEval evalNode , Stack < EvalNode > stack ) { return visitDefaultFunctionEval ( context , evalNode , stack ) ; } @ Override public RESULT visitSigned ( CONTEXT context , SignedEval signedEval , Stack < EvalNode > stack ) { return visitDefaultUnaryEval ( context , signedEval , stack ) ; } @ Override public RESULT visitCast ( CONTEXT context , CastEval castEval , Stack < EvalNode > stack ) { return visitDefaultUnaryEval ( context , castEval , stack ) ; } @ Override public RESULT visitSubquery ( CONTEXT context , SubqueryEval signedEval , Stack < EvalNode > stack ) { return null ; } }",Smelly
"public class MySQLPkGenerator extends JdbcPkGenerator { private static final Logger logger = LoggerFactory . getLogger ( MySQLPkGenerator . class ) ; public MySQLPkGenerator ( ) { super ( ) ; } MySQLPkGenerator ( JdbcAdapter adapter ) { super ( adapter ) ; } @ Override protected long longPkFromDatabase ( DataNode node , DbEntity entity ) throws Exception { SQLException exception = null ; long pk = - 1L ; Transaction transaction = BaseTransaction . getThreadTransaction ( ) ; if ( transaction != null && transaction . isExternal ( ) ) { logger . warn ( ""Using MysqlPkGenerator with external transaction manager may lead to inconsistent state."" ) ; } BaseTransaction . bindThreadTransaction ( null ) ; try ( Connection con = node . getDataSource ( ) . getConnection ( ) ) { if ( con . getAutoCommit ( ) ) { con . setAutoCommit ( false ) ; } try ( Statement st = con . createStatement ( ) ) { try { pk = getLongPrimaryKey ( st , entity . getName ( ) ) ; con . commit ( ) ; } catch ( SQLException pkEx ) { try { con . rollback ( ) ; } catch ( SQLException ignored ) { } exception = processSQLException ( pkEx , null ) ; } finally { try { String unlockString = ""UNLOCK TABLES"" ; adapter . getJdbcEventLogger ( ) . log ( unlockString ) ; st . execute ( unlockString ) ; } catch ( SQLException unlockEx ) { exception = processSQLException ( unlockEx , exception ) ; } } } } catch ( SQLException otherEx ) { exception = processSQLException ( otherEx , null ) ; } finally { BaseTransaction . bindThreadTransaction ( transaction ) ; } if ( exception != null ) { throw exception ; } return pk ; } protected SQLException processSQLException ( SQLException exception , SQLException parent ) { if ( parent == null ) { return exception ; } parent . setNextException ( exception ) ; return parent ; } @ Override protected String dropAutoPkString ( ) { return ""DROP TABLE IF EXISTS AUTO_PK_SUPPORT"" ; } @ Override protected String pkTableCreateString ( ) { return ""CREATE TABLE IF NOT EXISTS AUTO_PK_SUPPORT "" + ""(TABLE_NAME CHAR(100) NOT NULL, NEXT_ID BIGINT NOT NULL, UNIQUE (TABLE_NAME)) "" + ""ENGINE="" + MySQLAdapter . DEFAULT_STORAGE_ENGINE ; } protected long getLongPrimaryKey ( Statement statement , String entityName ) throws SQLException { String lockString = ""LOCK TABLES AUTO_PK_SUPPORT WRITE"" ; adapter . getJdbcEventLogger ( ) . log ( lockString ) ; statement . execute ( lockString ) ; String selectString = super . pkSelectString ( entityName ) ; adapter . getJdbcEventLogger ( ) . log ( selectString ) ; long pk ; try ( ResultSet rs = statement . executeQuery ( selectString ) ) { if ( ! rs . next ( ) ) { throw new SQLException ( ""No rows for '"" + entityName + ""'"" ) ; } pk = rs . getLong ( 1 ) ; if ( rs . next ( ) ) { throw new SQLException ( ""More than one row for '"" + entityName + ""'"" ) ; } } String updateString = super . pkUpdateString ( entityName ) + "" AND NEXT_ID = "" + pk ; adapter . getJdbcEventLogger ( ) . log ( updateString ) ; int updated = statement . executeUpdate ( updateString ) ; if ( updated != 1 ) { throw new SQLException ( ""Error updating PK count '"" + entityName + ""': "" + updated ) ; } return pk ; } }",No
"@ RunWith ( JUnit4 . class ) public class CopyOnAccessInMemoryStateInternalsTest { @ Rule public final TestPipeline pipeline = TestPipeline . create ( ) ; @ Rule public ExpectedException thrown = ExpectedException . none ( ) ; private String key = ""foo"" ; @ Test public void testGetWithEmpty ( ) { CopyOnAccessInMemoryStateInternals < String > internals = CopyOnAccessInMemoryStateInternals . withUnderlying ( key , null ) ; StateNamespace namespace = new StateNamespaceForTest ( ""foo"" ) ; StateTag < BagState < String > > bagTag = StateTags . bag ( ""foo"" , StringUtf8Coder . of ( ) ) ; BagState < String > stringBag = internals . state ( namespace , bagTag ) ; assertThat ( stringBag . read ( ) , emptyIterable ( ) ) ; stringBag . add ( ""bar"" ) ; stringBag . add ( ""baz"" ) ; assertThat ( stringBag . read ( ) , containsInAnyOrder ( ""baz"" , ""bar"" ) ) ; BagState < String > reReadStringBag = internals . state ( namespace , bagTag ) ; assertThat ( reReadStringBag . read ( ) , containsInAnyOrder ( ""baz"" , ""bar"" ) ) ; } @ Test public void testGetWithAbsentInUnderlying ( ) { CopyOnAccessInMemoryStateInternals < String > underlying = CopyOnAccessInMemoryStateInternals . withUnderlying ( key , null ) ; CopyOnAccessInMemoryStateInternals < String > internals = CopyOnAccessInMemoryStateInternals . withUnderlying ( key , underlying ) ; StateNamespace namespace = new StateNamespaceForTest ( ""foo"" ) ; StateTag < BagState < String > > bagTag = StateTags . bag ( ""foo"" , StringUtf8Coder . of ( ) ) ; BagState < String > stringBag = internals . state ( namespace , bagTag ) ; assertThat ( stringBag . read ( ) , emptyIterable ( ) ) ; stringBag . add ( ""bar"" ) ; stringBag . add ( ""baz"" ) ; assertThat ( stringBag . read ( ) , containsInAnyOrder ( ""baz"" , ""bar"" ) ) ; BagState < String > reReadVoidBag = internals . state ( namespace , bagTag ) ; assertThat ( reReadVoidBag . read ( ) , containsInAnyOrder ( ""baz"" , ""bar"" ) ) ; BagState < String > underlyingState = underlying . state ( namespace , bagTag ) ; assertThat ( underlyingState . read ( ) , emptyIterable ( ) ) ; } @ Test public void testGetWithPresentInUnderlying ( ) { CopyOnAccessInMemoryStateInternals < String > underlying = CopyOnAccessInMemoryStateInternals . withUnderlying ( key , null ) ; StateNamespace namespace = new StateNamespaceForTest ( ""foo"" ) ; StateTag < ValueState < String > > valueTag = StateTags . value ( ""foo"" , StringUtf8Coder . of ( ) ) ; ValueState < String > underlyingValue = underlying . state ( namespace , valueTag ) ; assertThat ( underlyingValue . read ( ) , nullValue ( String . class ) ) ; underlyingValue . write ( ""bar"" ) ; assertThat ( underlyingValue . read ( ) , equalTo ( ""bar"" ) ) ; CopyOnAccessInMemoryStateInternals < String > internals = CopyOnAccessInMemoryStateInternals . withUnderlying ( key , underlying ) ; ValueState < String > copyOnAccessState = internals . state ( namespace , valueTag ) ; assertThat ( copyOnAccessState . read ( ) , equalTo ( ""bar"" ) ) ; copyOnAccessState . write ( ""baz"" ) ; assertThat ( copyOnAccessState . read ( ) , equalTo ( ""baz"" ) ) ; assertThat ( underlyingValue . read ( ) , equalTo ( ""bar"" ) ) ; ValueState < String > reReadUnderlyingValue = underlying . state ( namespace , valueTag ) ; assertThat ( underlyingValue . read ( ) , equalTo ( reReadUnderlyingValue . read ( ) ) ) ; } @ Test public void testBagStateWithUnderlying ( ) { CopyOnAccessInMemoryStateInternals < String > underlying = CopyOnAccessInMemoryStateInternals . withUnderlying ( key , null ) ; StateNamespace namespace = new StateNamespaceForTest ( ""foo"" ) ; StateTag < BagState < Integer > > valueTag = StateTags . bag ( ""foo"" , VarIntCoder . of ( ) ) ; BagState < Integer > underlyingValue = underlying . state ( namespace , valueTag ) ; assertThat ( underlyingValue . read ( ) , emptyIterable ( ) ) ; underlyingValue . add ( 1 ) ; assertThat ( underlyingValue . read ( ) , containsInAnyOrder ( 1 ) ) ; CopyOnAccessInMemoryStateInternals < String > internals = CopyOnAccessInMemoryStateInternals . withUnderlying ( key , underlying ) ; BagState < Integer > copyOnAccessState = internals . state ( namespace , valueTag ) ; assertThat ( copyOnAccessState . read ( ) , containsInAnyOrder ( 1 ) ) ; copyOnAccessState . add ( 4 ) ; assertThat ( copyOnAccessState . read ( ) , containsInAnyOrder ( 4 , 1 ) ) ; assertThat ( underlyingValue . read ( ) , containsInAnyOrder ( 1 ) ) ; BagState < Integer > reReadUnderlyingValue = underlying . state ( namespace , valueTag ) ; assertThat ( Lists . newArrayList ( underlyingValue . read ( ) ) , equalTo ( Lists . newArrayList ( reReadUnderlyingValue . read ( ) ) ) ) ; } @ Test public void testSetStateWithUnderlying ( ) { CopyOnAccessInMemoryStateInternals < String > underlying = CopyOnAccessInMemoryStateInternals . withUnderlying ( key , null ) ; StateNamespace namespace = new StateNamespaceForTest ( ""foo"" ) ; StateTag < SetState < Integer > > valueTag = StateTags . set ( ""foo"" , VarIntCoder . of ( ) ) ; SetState < Integer > underlyingValue = underlying . state ( namespace , valueTag ) ; assertThat ( underlyingValue . read ( ) , emptyIterable ( ) ) ; underlyingValue . add ( 1 ) ; assertThat ( underlyingValue . read ( ) , containsInAnyOrder ( 1 ) ) ; CopyOnAccessInMemoryStateInternals < String > internals = CopyOnAccessInMemoryStateInternals . withUnderlying ( key , underlying ) ; SetState < Integer > copyOnAccessState = internals . state ( namespace , valueTag ) ; assertThat ( copyOnAccessState . read ( ) , containsInAnyOrder ( 1 ) ) ; copyOnAccessState . add ( 4 ) ; assertThat ( copyOnAccessState . read ( ) , containsInAnyOrder ( 4 , 1 ) ) ; assertThat ( underlyingValue . read ( ) , containsInAnyOrder ( 1 ) ) ; SetState < Integer > reReadUnderlyingValue = underlying . state ( namespace , valueTag ) ; assertThat ( underlyingValue . read ( ) , equalTo ( reReadUnderlyingValue . read ( ) ) ) ; } @ Test public void testMapStateWithUnderlying ( ) { CopyOnAccessInMemoryStateInternals < String > underlying = CopyOnAccessInMemoryStateInternals . withUnderlying ( key , null ) ; StateNamespace namespace = new StateNamespaceForTest ( ""foo"" ) ; StateTag < MapState < String , Integer > > valueTag = StateTags . map ( ""foo"" , StringUtf8Coder . of ( ) , VarIntCoder . of ( ) ) ; MapState < String , Integer > underlyingValue = underlying . state ( namespace , valueTag ) ; assertThat ( underlyingValue . entries ( ) . read ( ) , emptyIterable ( ) ) ; underlyingValue . put ( ""hello"" , 1 ) ; assertThat ( underlyingValue . get ( ""hello"" ) . read ( ) , equalTo ( 1 ) ) ; CopyOnAccessInMemoryStateInternals < String > internals = CopyOnAccessInMemoryStateInternals . withUnderlying ( key , underlying ) ; MapState < String , Integer > copyOnAccessState = internals . state ( namespace , valueTag ) ; assertThat ( copyOnAccessState . get ( ""hello"" ) . read ( ) , equalTo ( 1 ) ) ; copyOnAccessState . put ( ""world"" , 4 ) ; assertThat ( copyOnAccessState . get ( ""hello"" ) . read ( ) , equalTo ( 1 ) ) ; assertThat ( copyOnAccessState . get ( ""world"" ) . read ( ) , equalTo ( 4 ) ) ; assertThat ( underlyingValue . get ( ""hello"" ) . read ( ) , equalTo ( 1 ) ) ; assertNull ( underlyingValue . get ( ""world"" ) . read ( ) ) ; MapState < String , Integer > reReadUnderlyingValue = underlying . state ( namespace , valueTag ) ; assertThat ( underlyingValue . entries ( ) . read ( ) , equalTo ( reReadUnderlyingValue . entries ( ) . read ( ) ) ) ; } @ Test public void testAccumulatorCombiningStateWithUnderlying ( ) throws CannotProvideCoderException { CopyOnAccessInMemoryStateInternals < String > underlying = CopyOnAccessInMemoryStateInternals . withUnderlying ( key , null ) ; CombineFn < Long , long [ ] , Long > sumLongFn = Sum . ofLongs ( ) ; StateNamespace namespace = new StateNamespaceForTest ( ""foo"" ) ; CoderRegistry reg = pipeline . getCoderRegistry ( ) ; StateTag < CombiningState < Long , long [ ] , Long > > stateTag = StateTags . combiningValue ( ""summer"" , sumLongFn . getAccumulatorCoder ( reg , reg . getCoder ( Long . class ) ) , sumLongFn ) ; GroupingState < Long , Long > underlyingValue = underlying . state ( namespace , stateTag ) ; assertThat ( underlyingValue . read ( ) , equalTo ( 0L ) ) ; underlyingValue . add ( 1L ) ; assertThat ( underlyingValue . read ( ) , equalTo ( 1L ) ) ; CopyOnAccessInMemoryStateInternals < String > internals = CopyOnAccessInMemoryStateInternals . withUnderlying ( key , underlying ) ; GroupingState < Long , Long > copyOnAccessState = internals . state ( namespace , stateTag ) ; assertThat ( copyOnAccessState . read ( ) , equalTo ( 1L ) ) ; copyOnAccessState . add ( 4L ) ; assertThat ( copyOnAccessState . read ( ) , equalTo ( 5L ) ) ; assertThat ( underlyingValue . read ( ) , equalTo ( 1L ) ) ; GroupingState < Long , Long > reReadUnderlyingValue = underlying . state ( namespace , stateTag ) ; assertThat ( underlyingValue . read ( ) , equalTo ( reReadUnderlyingValue . read ( ) ) ) ; } @ Test public void testWatermarkHoldStateWithUnderlying ( ) { CopyOnAccessInMemoryStateInternals < String > underlying = CopyOnAccessInMemoryStateInternals . withUnderlying ( key , null ) ; TimestampCombiner timestampCombiner = TimestampCombiner . EARLIEST ; StateNamespace namespace = new StateNamespaceForTest ( ""foo"" ) ; StateTag < WatermarkHoldState > stateTag = StateTags . watermarkStateInternal ( ""wmstate"" , timestampCombiner ) ; WatermarkHoldState underlyingValue = underlying . state ( namespace , stateTag ) ; assertThat ( underlyingValue . read ( ) , nullValue ( ) ) ; underlyingValue . add ( new Instant ( 250L ) ) ; assertThat ( underlyingValue . read ( ) , equalTo ( new Instant ( 250L ) ) ) ; CopyOnAccessInMemoryStateInternals < String > internals = CopyOnAccessInMemoryStateInternals . withUnderlying ( key , underlying ) ; WatermarkHoldState copyOnAccessState = internals . state ( namespace , stateTag ) ; assertThat ( copyOnAccessState . read ( ) , equalTo ( new Instant ( 250L ) ) ) ; copyOnAccessState . add ( new Instant ( 100L ) ) ; assertThat ( copyOnAccessState . read ( ) , equalTo ( new Instant ( 100L ) ) ) ; assertThat ( underlyingValue . read ( ) , equalTo ( new Instant ( 250L ) ) ) ; copyOnAccessState . add ( new Instant ( 500L ) ) ; assertThat ( copyOnAccessState . read ( ) , equalTo ( new Instant ( 100L ) ) ) ; WatermarkHoldState reReadUnderlyingValue = underlying . state ( namespace , stateTag ) ; assertThat ( underlyingValue . read ( ) , equalTo ( reReadUnderlyingValue . read ( ) ) ) ; } @ Test public void testCommitWithoutUnderlying ( ) { CopyOnAccessInMemoryStateInternals < String > internals = CopyOnAccessInMemoryStateInternals . withUnderlying ( key , null ) ; StateNamespace namespace = new StateNamespaceForTest ( ""foo"" ) ; StateTag < BagState < String > > bagTag = StateTags . bag ( ""foo"" , StringUtf8Coder . of ( ) ) ; BagState < String > stringBag = internals . state ( namespace , bagTag ) ; assertThat ( stringBag . read ( ) , emptyIterable ( ) ) ; stringBag . add ( ""bar"" ) ; stringBag . add ( ""baz"" ) ; assertThat ( stringBag . read ( ) , containsInAnyOrder ( ""baz"" , ""bar"" ) ) ; internals . commit ( ) ; BagState < String > reReadStringBag = internals . state ( namespace , bagTag ) ; assertThat ( reReadStringBag . read ( ) , containsInAnyOrder ( ""baz"" , ""bar"" ) ) ; assertThat ( internals . isEmpty ( ) , is ( false ) ) ; } @ Test public void testCommitWithUnderlying ( ) { CopyOnAccessInMemoryStateInternals < String > underlying = CopyOnAccessInMemoryStateInternals . withUnderlying ( key , null ) ; CopyOnAccessInMemoryStateInternals < String > internals = CopyOnAccessInMemoryStateInternals . withUnderlying ( key , underlying ) ; StateNamespace namespace = new StateNamespaceForTest ( ""foo"" ) ; StateTag < BagState < String > > bagTag = StateTags . bag ( ""foo"" , StringUtf8Coder . of ( ) ) ; BagState < String > stringBag = underlying . state ( namespace , bagTag ) ; assertThat ( stringBag . read ( ) , emptyIterable ( ) ) ; stringBag . add ( ""bar"" ) ; stringBag . add ( ""baz"" ) ; internals . commit ( ) ; BagState < String > reReadStringBag = internals . state ( namespace , bagTag ) ; assertThat ( reReadStringBag . read ( ) , containsInAnyOrder ( ""baz"" , ""bar"" ) ) ; reReadStringBag . add ( ""spam"" ) ; BagState < String > underlyingState = underlying . state ( namespace , bagTag ) ; assertThat ( underlyingState . read ( ) , containsInAnyOrder ( ""spam"" , ""bar"" , ""baz"" ) ) ; assertThat ( underlyingState , is ( theInstance ( stringBag ) ) ) ; assertThat ( internals . isEmpty ( ) , is ( false ) ) ; } @ Test public void testCommitWithClearedInUnderlying ( ) { CopyOnAccessInMemoryStateInternals < String > underlying = CopyOnAccessInMemoryStateInternals . withUnderlying ( key , null ) ; CopyOnAccessInMemoryStateInternals < String > secondUnderlying = spy ( CopyOnAccessInMemoryStateInternals . withUnderlying ( key , underlying ) ) ; CopyOnAccessInMemoryStateInternals < String > internals = CopyOnAccessInMemoryStateInternals . withUnderlying ( key , secondUnderlying ) ; StateNamespace namespace = new StateNamespaceForTest ( ""foo"" ) ; StateTag < BagState < String > > bagTag = StateTags . bag ( ""foo"" , StringUtf8Coder . of ( ) ) ; BagState < String > stringBag = underlying . state ( namespace , bagTag ) ; assertThat ( stringBag . read ( ) , emptyIterable ( ) ) ; stringBag . add ( ""bar"" ) ; stringBag . add ( ""baz"" ) ; stringBag . clear ( ) ; secondUnderlying . commit ( ) ; stringBag . add ( ""foo"" ) ; internals . commit ( ) ; BagState < String > internalsStringBag = internals . state ( namespace , bagTag ) ; assertThat ( internalsStringBag . read ( ) , emptyIterable ( ) ) ; verify ( secondUnderlying , never ( ) ) . state ( namespace , bagTag ) ; assertThat ( internals . isEmpty ( ) , is ( false ) ) ; } @ Test public void testCommitWithOverwrittenUnderlying ( ) { CopyOnAccessInMemoryStateInternals < String > underlying = CopyOnAccessInMemoryStateInternals . withUnderlying ( key , null ) ; CopyOnAccessInMemoryStateInternals < String > internals = CopyOnAccessInMemoryStateInternals . withUnderlying ( key , underlying ) ; StateNamespace namespace = new StateNamespaceForTest ( ""foo"" ) ; StateTag < BagState < String > > bagTag = StateTags . bag ( ""foo"" , StringUtf8Coder . of ( ) ) ; BagState < String > stringBag = underlying . state ( namespace , bagTag ) ; assertThat ( stringBag . read ( ) , emptyIterable ( ) ) ; stringBag . add ( ""bar"" ) ; stringBag . add ( ""baz"" ) ; BagState < String > internalsState = internals . state ( namespace , bagTag ) ; internalsState . add ( ""eggs"" ) ; internalsState . add ( ""ham"" ) ; internalsState . add ( ""0x00ff00"" ) ; internalsState . add ( ""&"" ) ; internals . commit ( ) ; BagState < String > reReadInternalState = internals . state ( namespace , bagTag ) ; assertThat ( reReadInternalState . read ( ) , containsInAnyOrder ( ""bar"" , ""baz"" , ""0x00ff00"" , ""eggs"" , ""&"" , ""ham"" ) ) ; BagState < String > reReadUnderlyingState = underlying . state ( namespace , bagTag ) ; assertThat ( reReadUnderlyingState . read ( ) , containsInAnyOrder ( ""bar"" , ""baz"" ) ) ; } @ Test public void testCommitWithAddedUnderlying ( ) { CopyOnAccessInMemoryStateInternals < String > underlying = CopyOnAccessInMemoryStateInternals . withUnderlying ( key , null ) ; CopyOnAccessInMemoryStateInternals < String > internals = CopyOnAccessInMemoryStateInternals . withUnderlying ( key , underlying ) ; internals . commit ( ) ; StateNamespace namespace = new StateNamespaceForTest ( ""foo"" ) ; StateTag < BagState < String > > bagTag = StateTags . bag ( ""foo"" , StringUtf8Coder . of ( ) ) ; BagState < String > stringBag = underlying . state ( namespace , bagTag ) ; assertThat ( stringBag . read ( ) , emptyIterable ( ) ) ; stringBag . add ( ""bar"" ) ; stringBag . add ( ""baz"" ) ; BagState < String > internalState = internals . state ( namespace , bagTag ) ; assertThat ( internalState . read ( ) , emptyIterable ( ) ) ; BagState < String > reReadUnderlyingState = underlying . state ( namespace , bagTag ) ; assertThat ( reReadUnderlyingState . read ( ) , containsInAnyOrder ( ""bar"" , ""baz"" ) ) ; } @ Test public void testCommitWithEmptyTableIsEmpty ( ) { CopyOnAccessInMemoryStateInternals < String > internals = CopyOnAccessInMemoryStateInternals . withUnderlying ( key , null ) ; internals . commit ( ) ; assertThat ( internals . isEmpty ( ) , is ( true ) ) ; } @ Test public void testCommitWithOnlyClearedValuesIsEmpty ( ) { CopyOnAccessInMemoryStateInternals < String > internals = CopyOnAccessInMemoryStateInternals . withUnderlying ( key , null ) ; StateNamespace namespace = new StateNamespaceForTest ( ""foo"" ) ; StateTag < BagState < String > > bagTag = StateTags . bag ( ""foo"" , StringUtf8Coder . of ( ) ) ; BagState < String > stringBag = internals . state ( namespace , bagTag ) ; assertThat ( stringBag . read ( ) , emptyIterable ( ) ) ; stringBag . add ( ""foo"" ) ; stringBag . clear ( ) ; internals . commit ( ) ; assertThat ( internals . isEmpty ( ) , is ( true ) ) ; } @ Test public void testCommitWithEmptyNewAndFullUnderlyingIsNotEmpty ( ) { CopyOnAccessInMemoryStateInternals < String > underlying = CopyOnAccessInMemoryStateInternals . withUnderlying ( key , null ) ; CopyOnAccessInMemoryStateInternals < String > internals = CopyOnAccessInMemoryStateInternals . withUnderlying ( key , underlying ) ; StateNamespace namespace = new StateNamespaceForTest ( ""foo"" ) ; StateTag < BagState < String > > bagTag = StateTags . bag ( ""foo"" , StringUtf8Coder . of ( ) ) ; BagState < String > stringBag = underlying . state ( namespace , bagTag ) ; assertThat ( stringBag . read ( ) , emptyIterable ( ) ) ; stringBag . add ( ""bar"" ) ; stringBag . add ( ""baz"" ) ; internals . commit ( ) ; assertThat ( internals . isEmpty ( ) , is ( false ) ) ; } @ Test public void testGetEarliestWatermarkHoldAfterCommit ( ) { BoundedWindow first = new BoundedWindow ( ) { @ Override public Instant maxTimestamp ( ) { return new Instant ( 2048L ) ; } } ; BoundedWindow second = new BoundedWindow ( ) { @ Override public Instant maxTimestamp ( ) { return new Instant ( 689743L ) ; } } ; CopyOnAccessInMemoryStateInternals < String > internals = CopyOnAccessInMemoryStateInternals . withUnderlying ( ""foo"" , null ) ; StateTag < WatermarkHoldState > firstHoldAddress = StateTags . watermarkStateInternal ( ""foo"" , TimestampCombiner . EARLIEST ) ; WatermarkHoldState firstHold = internals . state ( StateNamespaces . window ( null , first ) , firstHoldAddress ) ; firstHold . add ( new Instant ( 22L ) ) ; StateTag < WatermarkHoldState > secondHoldAddress = StateTags . watermarkStateInternal ( ""foo"" , TimestampCombiner . EARLIEST ) ; WatermarkHoldState secondHold = internals . state ( StateNamespaces . window ( null , second ) , secondHoldAddress ) ; secondHold . add ( new Instant ( 2L ) ) ; internals . commit ( ) ; assertThat ( internals . getEarliestWatermarkHold ( ) , equalTo ( new Instant ( 2L ) ) ) ; } @ Test public void testGetEarliestWatermarkHoldWithEarliestInUnderlyingTable ( ) { BoundedWindow first = new BoundedWindow ( ) { @ Override public Instant maxTimestamp ( ) { return new Instant ( 2048L ) ; } } ; BoundedWindow second = new BoundedWindow ( ) { @ Override public Instant maxTimestamp ( ) { return new Instant ( 689743L ) ; } } ; CopyOnAccessInMemoryStateInternals < String > underlying = CopyOnAccessInMemoryStateInternals . withUnderlying ( ""foo"" , null ) ; StateTag < WatermarkHoldState > firstHoldAddress = StateTags . watermarkStateInternal ( ""foo"" , TimestampCombiner . EARLIEST ) ; WatermarkHoldState firstHold = underlying . state ( StateNamespaces . window ( null , first ) , firstHoldAddress ) ; firstHold . add ( new Instant ( 22L ) ) ; CopyOnAccessInMemoryStateInternals < String > internals = CopyOnAccessInMemoryStateInternals . withUnderlying ( ""foo"" , underlying . commit ( ) ) ; StateTag < WatermarkHoldState > secondHoldAddress = StateTags . watermarkStateInternal ( ""foo"" , TimestampCombiner . EARLIEST ) ; WatermarkHoldState secondHold = internals . state ( StateNamespaces . window ( null , second ) , secondHoldAddress ) ; secondHold . add ( new Instant ( 244L ) ) ; internals . commit ( ) ; assertThat ( internals . getEarliestWatermarkHold ( ) , equalTo ( new Instant ( 22L ) ) ) ; } @ Test public void testGetEarliestWatermarkHoldWithEarliestInNewTable ( ) { BoundedWindow first = new BoundedWindow ( ) { @ Override public Instant maxTimestamp ( ) { return new Instant ( 2048L ) ; } } ; BoundedWindow second = new BoundedWindow ( ) { @ Override public Instant maxTimestamp ( ) { return new Instant ( 689743L ) ; } } ; CopyOnAccessInMemoryStateInternals < String > underlying = CopyOnAccessInMemoryStateInternals . withUnderlying ( ""foo"" , null ) ; StateTag < WatermarkHoldState > firstHoldAddress = StateTags . watermarkStateInternal ( ""foo"" , TimestampCombiner . EARLIEST ) ; WatermarkHoldState firstHold = underlying . state ( StateNamespaces . window ( null , first ) , firstHoldAddress ) ; firstHold . add ( new Instant ( 224L ) ) ; CopyOnAccessInMemoryStateInternals < String > internals = CopyOnAccessInMemoryStateInternals . withUnderlying ( ""foo"" , underlying . commit ( ) ) ; StateTag < WatermarkHoldState > secondHoldAddress = StateTags . watermarkStateInternal ( ""foo"" , TimestampCombiner . EARLIEST ) ; WatermarkHoldState secondHold = internals . state ( StateNamespaces . window ( null , second ) , secondHoldAddress ) ; secondHold . add ( new Instant ( 24L ) ) ; internals . commit ( ) ; assertThat ( internals . getEarliestWatermarkHold ( ) , equalTo ( new Instant ( 24L ) ) ) ; } @ Test public void testGetEarliestHoldBeforeCommit ( ) { CopyOnAccessInMemoryStateInternals < String > internals = CopyOnAccessInMemoryStateInternals . withUnderlying ( key , null ) ; internals . state ( StateNamespaces . global ( ) , StateTags . watermarkStateInternal ( ""foo"" , TimestampCombiner . EARLIEST ) ) . add ( new Instant ( 1234L ) ) ; thrown . expect ( IllegalStateException . class ) ; thrown . expectMessage ( CopyOnAccessInMemoryStateInternals . class . getSimpleName ( ) ) ; thrown . expectMessage ( ""Can't get the earliest watermark hold"" ) ; thrown . expectMessage ( ""before it is committed"" ) ; internals . getEarliestWatermarkHold ( ) ; } }",Smelly
"@ SuppressWarnings ( ""unchecked"" ) public final class DoubleByteBuf extends AbstractReferenceCountedByteBuf { private ByteBuf b1 ; private ByteBuf b2 ; private final Handle < DoubleByteBuf > recyclerHandle ; private static final Recycler < DoubleByteBuf > RECYCLER = new Recycler < DoubleByteBuf > ( ) { @ Override protected DoubleByteBuf newObject ( Recycler . Handle < DoubleByteBuf > handle ) { return new DoubleByteBuf ( handle ) ; } } ; private DoubleByteBuf ( Handle < DoubleByteBuf > recyclerHandle ) { super ( Integer . MAX_VALUE ) ; this . recyclerHandle = recyclerHandle ; } public static ByteBuf get ( ByteBuf b1 , ByteBuf b2 ) { DoubleByteBuf buf = RECYCLER . get ( ) ; buf . setRefCnt ( 1 ) ; buf . b1 = b1 . retain ( ) ; buf . b2 = b2 . retain ( ) ; buf . setIndex ( 0 , b1 . readableBytes ( ) + b2 . readableBytes ( ) ) ; return toLeakAwareBuffer ( buf ) ; } public ByteBuf getFirst ( ) { return b1 ; } public ByteBuf getSecond ( ) { return b2 ; } @ Override public boolean isDirect ( ) { return b1 . isDirect ( ) && b2 . isDirect ( ) ; } @ Override public boolean hasArray ( ) { return false ; } @ Override public byte [ ] array ( ) { throw new UnsupportedOperationException ( ) ; } @ Override public int arrayOffset ( ) { throw new UnsupportedOperationException ( ) ; } @ Override public boolean hasMemoryAddress ( ) { return false ; } @ Override public long memoryAddress ( ) { throw new UnsupportedOperationException ( ) ; } @ Override public int capacity ( ) { return b1 . capacity ( ) + b2 . capacity ( ) ; } @ Override public int readableBytes ( ) { return b1 . readableBytes ( ) + b2 . readableBytes ( ) ; } @ Override public int writableBytes ( ) { return 0 ; } @ Override public DoubleByteBuf capacity ( int newCapacity ) { throw new UnsupportedOperationException ( ) ; } @ Override public ByteBufAllocator alloc ( ) { return PooledByteBufAllocator . DEFAULT ; } @ Override @ Deprecated public ByteOrder order ( ) { return ByteOrder . BIG_ENDIAN ; } @ Override public byte getByte ( int index ) { if ( index < b1 . writerIndex ( ) ) { return b1 . getByte ( index ) ; } else { return b2 . getByte ( index - b1 . writerIndex ( ) ) ; } } @ Override protected byte _getByte ( int index ) { throw new UnsupportedOperationException ( ) ; } @ Override protected short _getShort ( int index ) { throw new UnsupportedOperationException ( ) ; } @ Override protected short _getShortLE ( int index ) { throw new UnsupportedOperationException ( ) ; } @ Override protected int _getUnsignedMediumLE ( int index ) { throw new UnsupportedOperationException ( ) ; } @ Override protected int _getIntLE ( int index ) { throw new UnsupportedOperationException ( ) ; } @ Override protected long _getLongLE ( int index ) { throw new UnsupportedOperationException ( ) ; } @ Override protected void _setShortLE ( int index , int value ) { throw new UnsupportedOperationException ( ) ; } @ Override protected void _setMediumLE ( int index , int value ) { throw new UnsupportedOperationException ( ) ; } @ Override protected void _setIntLE ( int index , int value ) { throw new UnsupportedOperationException ( ) ; } @ Override protected void _setLongLE ( int index , long value ) { throw new UnsupportedOperationException ( ) ; } @ Override public int getBytes ( int index , FileChannel out , long position , int length ) throws IOException { throw new UnsupportedOperationException ( ) ; } @ Override public int setBytes ( int index , FileChannel in , long position , int length ) throws IOException { throw new UnsupportedOperationException ( ) ; } @ Override protected int _getUnsignedMedium ( int index ) { throw new UnsupportedOperationException ( ) ; } @ Override protected int _getInt ( int index ) { throw new UnsupportedOperationException ( ) ; } @ Override protected long _getLong ( int index ) { throw new UnsupportedOperationException ( ) ; } @ Override public DoubleByteBuf getBytes ( int index , byte [ ] dst , int dstIndex , int length ) { return getBytes ( index , Unpooled . wrappedBuffer ( dst ) , dstIndex , length ) ; } @ Override public ByteBuf getBytes ( int index , ByteBuffer dst ) { throw new UnsupportedOperationException ( ) ; } @ Override public DoubleByteBuf getBytes ( int index , ByteBuf dst , int dstIndex , int length ) { checkDstIndex ( index , length , dstIndex , dst . capacity ( ) ) ; if ( length == 0 ) { return this ; } int b1Length = Math . min ( length , b1 . readableBytes ( ) - index ) ; if ( b1Length > 0 ) { b1 . getBytes ( b1 . readerIndex ( ) + index , dst , dstIndex , b1Length ) ; dstIndex += b1Length ; length -= b1Length ; index = 0 ; } else { index -= b1 . readableBytes ( ) ; } if ( length > 0 ) { int b2Length = Math . min ( length , b2 . readableBytes ( ) - index ) ; b2 . getBytes ( b2 . readerIndex ( ) + index , dst , dstIndex , b2Length ) ; } return this ; } @ Override public int getBytes ( int index , GatheringByteChannel out , int length ) throws IOException { throw new UnsupportedOperationException ( ) ; } @ Override public DoubleByteBuf getBytes ( int index , OutputStream out , int length ) throws IOException { throw new UnsupportedOperationException ( ) ; } @ Override public DoubleByteBuf setByte ( int index , int value ) { throw new UnsupportedOperationException ( ) ; } @ Override protected void _setByte ( int index , int value ) { throw new UnsupportedOperationException ( ) ; } @ Override public DoubleByteBuf setShort ( int index , int value ) { throw new UnsupportedOperationException ( ) ; } @ Override protected void _setShort ( int index , int value ) { throw new UnsupportedOperationException ( ) ; } @ Override public DoubleByteBuf setMedium ( int index , int value ) { throw new UnsupportedOperationException ( ) ; } @ Override protected void _setMedium ( int index , int value ) { throw new UnsupportedOperationException ( ) ; } @ Override public DoubleByteBuf setInt ( int index , int value ) { return ( DoubleByteBuf ) super . setInt ( index , value ) ; } @ Override protected void _setInt ( int index , int value ) { throw new UnsupportedOperationException ( ) ; } @ Override public DoubleByteBuf setLong ( int index , long value ) { throw new UnsupportedOperationException ( ) ; } @ Override protected void _setLong ( int index , long value ) { throw new UnsupportedOperationException ( ) ; } @ Override public DoubleByteBuf setBytes ( int index , byte [ ] src , int srcIndex , int length ) { throw new UnsupportedOperationException ( ) ; } @ Override public DoubleByteBuf setBytes ( int index , ByteBuffer src ) { throw new UnsupportedOperationException ( ) ; } @ Override public DoubleByteBuf setBytes ( int index , ByteBuf src , int srcIndex , int length ) { throw new UnsupportedOperationException ( ) ; } @ Override public int setBytes ( int index , InputStream in , int length ) throws IOException { throw new UnsupportedOperationException ( ) ; } @ Override public int setBytes ( int index , ScatteringByteChannel in , int length ) throws IOException { throw new UnsupportedOperationException ( ) ; } @ Override public ByteBuf copy ( int index , int length ) { throw new UnsupportedOperationException ( ) ; } @ Override public int nioBufferCount ( ) { return b1 . nioBufferCount ( ) + b2 . nioBufferCount ( ) ; } @ Override public ByteBuffer internalNioBuffer ( int index , int length ) { throw new UnsupportedOperationException ( ) ; } @ Override public ByteBuffer nioBuffer ( int index , int length ) { ByteBuffer dst = ByteBuffer . allocate ( length ) ; ByteBuf b = Unpooled . wrappedBuffer ( dst ) ; b . writerIndex ( 0 ) ; getBytes ( index , b , length ) ; return dst ; } @ Override public ByteBuffer [ ] nioBuffers ( int index , int length ) { return new ByteBuffer [ ] { nioBuffer ( index , length ) } ; } @ Override public DoubleByteBuf discardReadBytes ( ) { throw new UnsupportedOperationException ( ) ; } @ Override public String toString ( ) { String result = super . toString ( ) ; result = result . substring ( 0 , result . length ( ) - 1 ) ; return result + "", components=2)"" ; } @ Override public ByteBuffer [ ] nioBuffers ( ) { return nioBuffers ( readerIndex ( ) , readableBytes ( ) ) ; } @ Override protected void deallocate ( ) { b1 . release ( 2 ) ; b2 . release ( 2 ) ; b1 = b2 = null ; recyclerHandle . recycle ( this ) ; } @ Override public ByteBuf unwrap ( ) { return null ; } private static final Logger log = LoggerFactory . getLogger ( DoubleByteBuf . class ) ; private static final ResourceLeakDetector < DoubleByteBuf > leakDetector = ResourceLeakDetectorFactory . instance ( ) . newResourceLeakDetector ( DoubleByteBuf . class ) ; private static final Constructor < ByteBuf > simpleLeakAwareByteBufConstructor ; private static final Constructor < ByteBuf > advancedLeakAwareByteBufConstructor ; static { Constructor < ByteBuf > _simpleLeakAwareByteBufConstructor = null ; Constructor < ByteBuf > _advancedLeakAwareByteBufConstructor = null ; try { Class < ? > simpleLeakAwareByteBufClass = Class . forName ( ""io.netty.buffer.SimpleLeakAwareByteBuf"" ) ; _simpleLeakAwareByteBufConstructor = ( Constructor < ByteBuf > ) simpleLeakAwareByteBufClass . getDeclaredConstructor ( ByteBuf . class , ResourceLeakTracker . class ) ; _simpleLeakAwareByteBufConstructor . setAccessible ( true ) ; Class < ? > advancedLeakAwareByteBufClass = Class . forName ( ""io.netty.buffer.AdvancedLeakAwareByteBuf"" ) ; _advancedLeakAwareByteBufConstructor = ( Constructor < ByteBuf > ) advancedLeakAwareByteBufClass . getDeclaredConstructor ( ByteBuf . class , ResourceLeakTracker . class ) ; _advancedLeakAwareByteBufConstructor . setAccessible ( true ) ; } catch ( Throwable t ) { log . error ( ""Failed to use reflection to enable leak detection"" , t ) ; } finally { simpleLeakAwareByteBufConstructor = _simpleLeakAwareByteBufConstructor ; advancedLeakAwareByteBufConstructor = _advancedLeakAwareByteBufConstructor ; } } private static ByteBuf toLeakAwareBuffer ( DoubleByteBuf buf ) { try { ResourceLeakTracker < DoubleByteBuf > leak ; switch ( ResourceLeakDetector . getLevel ( ) ) { case DISABLED : break ; case SIMPLE : leak = leakDetector . track ( buf ) ; if ( leak != null ) { return simpleLeakAwareByteBufConstructor . newInstance ( buf , leak ) ; } break ; case ADVANCED : case PARANOID : leak = leakDetector . track ( buf ) ; if ( leak != null ) { return advancedLeakAwareByteBufConstructor . newInstance ( buf , leak ) ; } break ; } return buf ; } catch ( Throwable t ) { throw new RuntimeException ( t ) ; } } }",Smelly
"@ SuppressWarnings ( ""deprecation"" ) public class MapUtils { @ SuppressWarnings ( ""rawtypes"" ) public static final SortedMap EMPTY_SORTED_MAP = UnmodifiableSortedMap . unmodifiableSortedMap ( new TreeMap < > ( ) ) ; private static final String INDENT_STRING = ""    "" ; private MapUtils ( ) { } public static < K , V > V getObject ( final Map < ? super K , V > map , final K key ) { if ( map != null ) { return map . get ( key ) ; } return null ; } public static < K > String getString ( final Map < ? super K , ? > map , final K key ) { if ( map != null ) { final Object answer = map . get ( key ) ; if ( answer != null ) { return answer . toString ( ) ; } } return null ; } public static < K > Boolean getBoolean ( final Map < ? super K , ? > map , final K key ) { if ( map != null ) { final Object answer = map . get ( key ) ; if ( answer != null ) { if ( answer instanceof Boolean ) { return ( Boolean ) answer ; } if ( answer instanceof String ) { return Boolean . valueOf ( ( String ) answer ) ; } if ( answer instanceof Number ) { final Number n = ( Number ) answer ; return n . intValue ( ) != 0 ? Boolean . TRUE : Boolean . FALSE ; } } } return null ; } public static < K > Number getNumber ( final Map < ? super K , ? > map , final K key ) { if ( map != null ) { final Object answer = map . get ( key ) ; if ( answer != null ) { if ( answer instanceof Number ) { return ( Number ) answer ; } if ( answer instanceof String ) { try { final String text = ( String ) answer ; return NumberFormat . getInstance ( ) . parse ( text ) ; } catch ( final ParseException e ) { } } } } return null ; } public static < K > Byte getByte ( final Map < ? super K , ? > map , final K key ) { final Number answer = getNumber ( map , key ) ; if ( answer == null ) { return null ; } if ( answer instanceof Byte ) { return ( Byte ) answer ; } return Byte . valueOf ( answer . byteValue ( ) ) ; } public static < K > Short getShort ( final Map < ? super K , ? > map , final K key ) { final Number answer = getNumber ( map , key ) ; if ( answer == null ) { return null ; } if ( answer instanceof Short ) { return ( Short ) answer ; } return Short . valueOf ( answer . shortValue ( ) ) ; } public static < K > Integer getInteger ( final Map < ? super K , ? > map , final K key ) { final Number answer = getNumber ( map , key ) ; if ( answer == null ) { return null ; } if ( answer instanceof Integer ) { return ( Integer ) answer ; } return Integer . valueOf ( answer . intValue ( ) ) ; } public static < K > Long getLong ( final Map < ? super K , ? > map , final K key ) { final Number answer = getNumber ( map , key ) ; if ( answer == null ) { return null ; } if ( answer instanceof Long ) { return ( Long ) answer ; } return Long . valueOf ( answer . longValue ( ) ) ; } public static < K > Float getFloat ( final Map < ? super K , ? > map , final K key ) { final Number answer = getNumber ( map , key ) ; if ( answer == null ) { return null ; } if ( answer instanceof Float ) { return ( Float ) answer ; } return Float . valueOf ( answer . floatValue ( ) ) ; } public static < K > Double getDouble ( final Map < ? super K , ? > map , final K key ) { final Number answer = getNumber ( map , key ) ; if ( answer == null ) { return null ; } if ( answer instanceof Double ) { return ( Double ) answer ; } return Double . valueOf ( answer . doubleValue ( ) ) ; } public static < K > Map < ? , ? > getMap ( final Map < ? super K , ? > map , final K key ) { if ( map != null ) { final Object answer = map . get ( key ) ; if ( answer != null && answer instanceof Map ) { return ( Map < ? , ? > ) answer ; } } return null ; } public static < K , V > V getObject ( final Map < K , V > map , final K key , final V defaultValue ) { if ( map != null ) { final V answer = map . get ( key ) ; if ( answer != null ) { return answer ; } } return defaultValue ; } public static < K > String getString ( final Map < ? super K , ? > map , final K key , final String defaultValue ) { String answer = getString ( map , key ) ; if ( answer == null ) { answer = defaultValue ; } return answer ; } public static < K > Boolean getBoolean ( final Map < ? super K , ? > map , final K key , final Boolean defaultValue ) { Boolean answer = getBoolean ( map , key ) ; if ( answer == null ) { answer = defaultValue ; } return answer ; } public static < K > Number getNumber ( final Map < ? super K , ? > map , final K key , final Number defaultValue ) { Number answer = getNumber ( map , key ) ; if ( answer == null ) { answer = defaultValue ; } return answer ; } public static < K > Byte getByte ( final Map < ? super K , ? > map , final K key , final Byte defaultValue ) { Byte answer = getByte ( map , key ) ; if ( answer == null ) { answer = defaultValue ; } return answer ; } public static < K > Short getShort ( final Map < ? super K , ? > map , final K key , final Short defaultValue ) { Short answer = getShort ( map , key ) ; if ( answer == null ) { answer = defaultValue ; } return answer ; } public static < K > Integer getInteger ( final Map < ? super K , ? > map , final K key , final Integer defaultValue ) { Integer answer = getInteger ( map , key ) ; if ( answer == null ) { answer = defaultValue ; } return answer ; } public static < K > Long getLong ( final Map < ? super K , ? > map , final K key , final Long defaultValue ) { Long answer = getLong ( map , key ) ; if ( answer == null ) { answer = defaultValue ; } return answer ; } public static < K > Float getFloat ( final Map < ? super K , ? > map , final K key , final Float defaultValue ) { Float answer = getFloat ( map , key ) ; if ( answer == null ) { answer = defaultValue ; } return answer ; } public static < K > Double getDouble ( final Map < ? super K , ? > map , final K key , final Double defaultValue ) { Double answer = getDouble ( map , key ) ; if ( answer == null ) { answer = defaultValue ; } return answer ; } public static < K > Map < ? , ? > getMap ( final Map < ? super K , ? > map , final K key , final Map < ? , ? > defaultValue ) { Map < ? , ? > answer = getMap ( map , key ) ; if ( answer == null ) { answer = defaultValue ; } return answer ; } public static < K > boolean getBooleanValue ( final Map < ? super K , ? > map , final K key ) { return Boolean . TRUE . equals ( getBoolean ( map , key ) ) ; } public static < K > byte getByteValue ( final Map < ? super K , ? > map , final K key ) { final Byte byteObject = getByte ( map , key ) ; if ( byteObject == null ) { return 0 ; } return byteObject . byteValue ( ) ; } public static < K > short getShortValue ( final Map < ? super K , ? > map , final K key ) { final Short shortObject = getShort ( map , key ) ; if ( shortObject == null ) { return 0 ; } return shortObject . shortValue ( ) ; } public static < K > int getIntValue ( final Map < ? super K , ? > map , final K key ) { final Integer integerObject = getInteger ( map , key ) ; if ( integerObject == null ) { return 0 ; } return integerObject . intValue ( ) ; } public static < K > long getLongValue ( final Map < ? super K , ? > map , final K key ) { final Long longObject = getLong ( map , key ) ; if ( longObject == null ) { return 0L ; } return longObject . longValue ( ) ; } public static < K > float getFloatValue ( final Map < ? super K , ? > map , final K key ) { final Float floatObject = getFloat ( map , key ) ; if ( floatObject == null ) { return 0f ; } return floatObject . floatValue ( ) ; } public static < K > double getDoubleValue ( final Map < ? super K , ? > map , final K key ) { final Double doubleObject = getDouble ( map , key ) ; if ( doubleObject == null ) { return 0d ; } return doubleObject . doubleValue ( ) ; } public static < K > boolean getBooleanValue ( final Map < ? super K , ? > map , final K key , final boolean defaultValue ) { final Boolean booleanObject = getBoolean ( map , key ) ; if ( booleanObject == null ) { return defaultValue ; } return booleanObject . booleanValue ( ) ; } public static < K > byte getByteValue ( final Map < ? super K , ? > map , final K key , final byte defaultValue ) { final Byte byteObject = getByte ( map , key ) ; if ( byteObject == null ) { return defaultValue ; } return byteObject . byteValue ( ) ; } public static < K > short getShortValue ( final Map < ? super K , ? > map , final K key , final short defaultValue ) { final Short shortObject = getShort ( map , key ) ; if ( shortObject == null ) { return defaultValue ; } return shortObject . shortValue ( ) ; } public static < K > int getIntValue ( final Map < ? super K , ? > map , final K key , final int defaultValue ) { final Integer integerObject = getInteger ( map , key ) ; if ( integerObject == null ) { return defaultValue ; } return integerObject . intValue ( ) ; } public static < K > long getLongValue ( final Map < ? super K , ? > map , final K key , final long defaultValue ) { final Long longObject = getLong ( map , key ) ; if ( longObject == null ) { return defaultValue ; } return longObject . longValue ( ) ; } public static < K > float getFloatValue ( final Map < ? super K , ? > map , final K key , final float defaultValue ) { final Float floatObject = getFloat ( map , key ) ; if ( floatObject == null ) { return defaultValue ; } return floatObject . floatValue ( ) ; } public static < K > double getDoubleValue ( final Map < ? super K , ? > map , final K key , final double defaultValue ) { final Double doubleObject = getDouble ( map , key ) ; if ( doubleObject == null ) { return defaultValue ; } return doubleObject . doubleValue ( ) ; } public static < K , V > Properties toProperties ( final Map < K , V > map ) { final Properties answer = new Properties ( ) ; if ( map != null ) { for ( final Entry < K , V > entry2 : map . entrySet ( ) ) { final Map . Entry < ? , ? > entry = entry2 ; final Object key = entry . getKey ( ) ; final Object value = entry . getValue ( ) ; answer . put ( key , value ) ; } } return answer ; } public static Map < String , Object > toMap ( final ResourceBundle resourceBundle ) { final Enumeration < String > enumeration = resourceBundle . getKeys ( ) ; final Map < String , Object > map = new HashMap < > ( ) ; while ( enumeration . hasMoreElements ( ) ) { final String key = enumeration . nextElement ( ) ; final Object value = resourceBundle . getObject ( key ) ; map . put ( key , value ) ; } return map ; } public static void verbosePrint ( final PrintStream out , final Object label , final Map < ? , ? > map ) { verbosePrintInternal ( out , label , map , new ArrayDeque < Map < ? , ? > > ( ) , false ) ; } public static void debugPrint ( final PrintStream out , final Object label , final Map < ? , ? > map ) { verbosePrintInternal ( out , label , map , new ArrayDeque < Map < ? , ? > > ( ) , true ) ; } private static void verbosePrintInternal ( final PrintStream out , final Object label , final Map < ? , ? > map , final Deque < Map < ? , ? > > lineage , final boolean debug ) { printIndent ( out , lineage . size ( ) ) ; if ( map == null ) { if ( label != null ) { out . print ( label ) ; out . print ( "" = "" ) ; } out . println ( ""null"" ) ; return ; } if ( label != null ) { out . print ( label ) ; out . println ( "" = "" ) ; } printIndent ( out , lineage . size ( ) ) ; out . println ( ""{"" ) ; lineage . addLast ( map ) ; for ( final Map . Entry < ? , ? > entry : map . entrySet ( ) ) { final Object childKey = entry . getKey ( ) ; final Object childValue = entry . getValue ( ) ; if ( childValue instanceof Map && ! lineage . contains ( childValue ) ) { verbosePrintInternal ( out , childKey == null ? ""null"" : childKey , ( Map < ? , ? > ) childValue , lineage , debug ) ; } else { printIndent ( out , lineage . size ( ) ) ; out . print ( childKey ) ; out . print ( "" = "" ) ; final int lineageIndex = IterableUtils . indexOf ( lineage , PredicateUtils . equalPredicate ( childValue ) ) ; if ( lineageIndex == - 1 ) { out . print ( childValue ) ; } else if ( lineage . size ( ) - 1 == lineageIndex ) { out . print ( ""(this Map)"" ) ; } else { out . print ( ""(ancestor["" + ( lineage . size ( ) - 1 - lineageIndex - 1 ) + ""] Map)"" ) ; } if ( debug && childValue != null ) { out . print ( ' ' ) ; out . println ( childValue . getClass ( ) . getName ( ) ) ; } else { out . println ( ) ; } } } lineage . removeLast ( ) ; printIndent ( out , lineage . size ( ) ) ; out . println ( debug ? ""} "" + map . getClass ( ) . getName ( ) : ""}"" ) ; } private static void printIndent ( final PrintStream out , final int indent ) { for ( int i = 0 ; i < indent ; i ++ ) { out . print ( INDENT_STRING ) ; } } public static < K , V > Map < V , K > invertMap ( final Map < K , V > map ) { final Map < V , K > out = new HashMap < > ( map . size ( ) ) ; for ( final Entry < K , V > entry : map . entrySet ( ) ) { out . put ( entry . getValue ( ) , entry . getKey ( ) ) ; } return out ; } public static < K > void safeAddToMap ( final Map < ? super K , Object > map , final K key , final Object value ) throws NullPointerException { map . put ( key , value == null ? """" : value ) ; } @ SuppressWarnings ( ""unchecked"" ) public static < K , V > Map < K , V > putAll ( final Map < K , V > map , final Object [ ] array ) { if ( map == null ) { throw new NullPointerException ( ""The map must not be null"" ) ; } if ( array == null || array . length == 0 ) { return map ; } final Object obj = array [ 0 ] ; if ( obj instanceof Map . Entry ) { for ( final Object element : array ) { final Map . Entry < K , V > entry = ( Map . Entry < K , V > ) element ; map . put ( entry . getKey ( ) , entry . getValue ( ) ) ; } } else if ( obj instanceof KeyValue ) { for ( final Object element : array ) { final KeyValue < K , V > keyval = ( KeyValue < K , V > ) element ; map . put ( keyval . getKey ( ) , keyval . getValue ( ) ) ; } } else if ( obj instanceof Object [ ] ) { for ( int i = 0 ; i < array . length ; i ++ ) { final Object [ ] sub = ( Object [ ] ) array [ i ] ; if ( sub == null || sub . length < 2 ) { throw new IllegalArgumentException ( ""Invalid array element: "" + i ) ; } map . put ( ( K ) sub [ 0 ] , ( V ) sub [ 1 ] ) ; } } else { for ( int i = 0 ; i < array . length - 1 ; ) { map . put ( ( K ) array [ i ++ ] , ( V ) array [ i ++ ] ) ; } } return map ; } public static < K , V > Map < K , V > emptyIfNull ( final Map < K , V > map ) { return map == null ? Collections . < K , V > emptyMap ( ) : map ; } public static boolean isEmpty ( final Map < ? , ? > map ) { return map == null || map . isEmpty ( ) ; } public static boolean isNotEmpty ( final Map < ? , ? > map ) { return ! MapUtils . isEmpty ( map ) ; } public static < K , V > Map < K , V > synchronizedMap ( final Map < K , V > map ) { return Collections . synchronizedMap ( map ) ; } public static < K , V > Map < K , V > unmodifiableMap ( final Map < ? extends K , ? extends V > map ) { return UnmodifiableMap . unmodifiableMap ( map ) ; } public static < K , V > IterableMap < K , V > predicatedMap ( final Map < K , V > map , final Predicate < ? super K > keyPred , final Predicate < ? super V > valuePred ) { return PredicatedMap . predicatedMap ( map , keyPred , valuePred ) ; } public static < K , V > IterableMap < K , V > transformedMap ( final Map < K , V > map , final Transformer < ? super K , ? extends K > keyTransformer , final Transformer < ? super V , ? extends V > valueTransformer ) { return TransformedMap . transformingMap ( map , keyTransformer , valueTransformer ) ; } public static < K , V > IterableMap < K , V > fixedSizeMap ( final Map < K , V > map ) { return FixedSizeMap . fixedSizeMap ( map ) ; } public static < K , V > IterableMap < K , V > lazyMap ( final Map < K , V > map , final Factory < ? extends V > factory ) { return LazyMap . lazyMap ( map , factory ) ; } public static < K , V > IterableMap < K , V > lazyMap ( final Map < K , V > map , final Transformer < ? super K , ? extends V > transformerFactory ) { return LazyMap . lazyMap ( map , transformerFactory ) ; } public static < K , V > OrderedMap < K , V > orderedMap ( final Map < K , V > map ) { return ListOrderedMap . listOrderedMap ( map ) ; } @ Deprecated public static < K , V > MultiValueMap < K , V > multiValueMap ( final Map < K , ? super Collection < V > > map ) { return MultiValueMap . < K , V > multiValueMap ( map ) ; } @ Deprecated public static < K , V , C extends Collection < V > > MultiValueMap < K , V > multiValueMap ( final Map < K , C > map , final Class < C > collectionClass ) { return MultiValueMap . multiValueMap ( map , collectionClass ) ; } @ Deprecated public static < K , V , C extends Collection < V > > MultiValueMap < K , V > multiValueMap ( final Map < K , C > map , final Factory < C > collectionFactory ) { return MultiValueMap . multiValueMap ( map , collectionFactory ) ; } public static < K , V > SortedMap < K , V > synchronizedSortedMap ( final SortedMap < K , V > map ) { return Collections . synchronizedSortedMap ( map ) ; } public static < K , V > SortedMap < K , V > unmodifiableSortedMap ( final SortedMap < K , ? extends V > map ) { return UnmodifiableSortedMap . unmodifiableSortedMap ( map ) ; } public static < K , V > SortedMap < K , V > predicatedSortedMap ( final SortedMap < K , V > map , final Predicate < ? super K > keyPred , final Predicate < ? super V > valuePred ) { return PredicatedSortedMap . predicatedSortedMap ( map , keyPred , valuePred ) ; } public static < K , V > SortedMap < K , V > transformedSortedMap ( final SortedMap < K , V > map , final Transformer < ? super K , ? extends K > keyTransformer , final Transformer < ? super V , ? extends V > valueTransformer ) { return TransformedSortedMap . transformingSortedMap ( map , keyTransformer , valueTransformer ) ; } public static < K , V > SortedMap < K , V > fixedSizeSortedMap ( final SortedMap < K , V > map ) { return FixedSizeSortedMap . fixedSizeSortedMap ( map ) ; } public static < K , V > SortedMap < K , V > lazySortedMap ( final SortedMap < K , V > map , final Factory < ? extends V > factory ) { return LazySortedMap . lazySortedMap ( map , factory ) ; } public static < K , V > SortedMap < K , V > lazySortedMap ( final SortedMap < K , V > map , final Transformer < ? super K , ? extends V > transformerFactory ) { return LazySortedMap . lazySortedMap ( map , transformerFactory ) ; } public static < K , V > void populateMap ( final Map < K , V > map , final Iterable < ? extends V > elements , final Transformer < V , K > keyTransformer ) { populateMap ( map , elements , keyTransformer , TransformerUtils . < V > nopTransformer ( ) ) ; } public static < K , V , E > void populateMap ( final Map < K , V > map , final Iterable < ? extends E > elements , final Transformer < E , K > keyTransformer , final Transformer < E , V > valueTransformer ) { final Iterator < ? extends E > iter = elements . iterator ( ) ; while ( iter . hasNext ( ) ) { final E temp = iter . next ( ) ; map . put ( keyTransformer . transform ( temp ) , valueTransformer . transform ( temp ) ) ; } } public static < K , V > void populateMap ( final MultiMap < K , V > map , final Iterable < ? extends V > elements , final Transformer < V , K > keyTransformer ) { populateMap ( map , elements , keyTransformer , TransformerUtils . < V > nopTransformer ( ) ) ; } public static < K , V , E > void populateMap ( final MultiMap < K , V > map , final Iterable < ? extends E > elements , final Transformer < E , K > keyTransformer , final Transformer < E , V > valueTransformer ) { final Iterator < ? extends E > iter = elements . iterator ( ) ; while ( iter . hasNext ( ) ) { final E temp = iter . next ( ) ; map . put ( keyTransformer . transform ( temp ) , valueTransformer . transform ( temp ) ) ; } } public static < K , V > IterableMap < K , V > iterableMap ( final Map < K , V > map ) { if ( map == null ) { throw new NullPointerException ( ""Map must not be null"" ) ; } return map instanceof IterableMap ? ( IterableMap < K , V > ) map : new AbstractMapDecorator < K , V > ( map ) { } ; } public static < K , V > IterableSortedMap < K , V > iterableSortedMap ( final SortedMap < K , V > sortedMap ) { if ( sortedMap == null ) { throw new NullPointerException ( ""Map must not be null"" ) ; } return sortedMap instanceof IterableSortedMap ? ( IterableSortedMap < K , V > ) sortedMap : new AbstractSortedMapDecorator < K , V > ( sortedMap ) { } ; } public static int size ( final Map < ? , ? > map ) { return map == null ? 0 : map . size ( ) ; } }",Smelly
"public class TestDatum { @ Test public final void testPlusDatumDatum ( ) { Datum x ; Datum y ; Datum z ; x = DatumFactory . createInt4 ( 1 ) ; y = DatumFactory . createInt4 ( 2 ) ; z = x . plus ( y ) ; assertEquals ( z . type ( ) , Type . INT4 ) ; assertEquals ( z . asInt4 ( ) , 3 ) ; z = y . plus ( x ) ; assertEquals ( z . type ( ) , Type . INT4 ) ; assertEquals ( z . asInt4 ( ) , 3 ) ; x = DatumFactory . createInt4 ( 1 ) ; y = DatumFactory . createInt8 ( 2l ) ; z = x . plus ( y ) ; assertEquals ( z . type ( ) , Type . INT8 ) ; assertEquals ( z . asInt8 ( ) , 3l ) ; z = y . plus ( x ) ; assertEquals ( z . type ( ) , Type . INT8 ) ; assertEquals ( z . asInt8 ( ) , 3l ) ; y = DatumFactory . createFloat4 ( 2.5f ) ; z = x . plus ( y ) ; assertEquals ( z . type ( ) , Type . FLOAT4 ) ; assertTrue ( z . asFloat4 ( ) == 3.5f ) ; z = y . plus ( x ) ; assertEquals ( z . type ( ) , Type . FLOAT4 ) ; assertEquals ( z . asInt4 ( ) , 3 ) ; y = DatumFactory . createFloat8 ( 4.5d ) ; z = x . plus ( y ) ; assertEquals ( z . type ( ) , Type . FLOAT8 ) ; assertTrue ( z . asFloat8 ( ) == 5.5d ) ; z = y . plus ( x ) ; assertEquals ( z . type ( ) , Type . FLOAT8 ) ; assertTrue ( z . asFloat8 ( ) == 5.5d ) ; } @ Test public final void testMinusDatumDatum ( ) { Datum x ; Datum y ; Datum z ; x = DatumFactory . createInt4 ( 5 ) ; y = DatumFactory . createInt4 ( 2 ) ; z = x . minus ( y ) ; assertEquals ( z . type ( ) , Type . INT4 ) ; assertEquals ( z . asInt4 ( ) , 3 ) ; z = y . minus ( x ) ; assertEquals ( z . type ( ) , Type . INT4 ) ; assertEquals ( z . asInt4 ( ) , - 3 ) ; y = DatumFactory . createInt8 ( 2l ) ; z = x . minus ( y ) ; assertEquals ( z . type ( ) , Type . INT8 ) ; assertEquals ( z . asInt8 ( ) , 3l ) ; z = y . minus ( x ) ; assertEquals ( z . type ( ) , Type . INT8 ) ; assertEquals ( z . asInt8 ( ) , - 3l ) ; y = DatumFactory . createFloat4 ( 2.5f ) ; z = x . minus ( y ) ; assertEquals ( z . type ( ) , Type . FLOAT4 ) ; assertTrue ( z . asFloat4 ( ) == 2.5f ) ; z = y . minus ( x ) ; assertEquals ( z . type ( ) , Type . FLOAT4 ) ; assertTrue ( z . asFloat4 ( ) == - 2.5f ) ; y = DatumFactory . createFloat8 ( 4.5d ) ; z = x . minus ( y ) ; assertEquals ( z . type ( ) , Type . FLOAT8 ) ; assertTrue ( z . asFloat8 ( ) == 0.5d ) ; z = y . minus ( x ) ; assertEquals ( z . type ( ) , Type . FLOAT8 ) ; assertTrue ( z . asFloat8 ( ) == - 0.5d ) ; } @ Test public final void testMultiplyDatumDatum ( ) { Datum x ; Datum y ; Datum z ; x = DatumFactory . createInt4 ( 5 ) ; y = DatumFactory . createInt4 ( 2 ) ; z = x . multiply ( y ) ; assertEquals ( z . type ( ) , Type . INT4 ) ; assertEquals ( z . asInt4 ( ) , 10 ) ; z = y . multiply ( x ) ; assertEquals ( z . type ( ) , Type . INT4 ) ; assertEquals ( z . asInt4 ( ) , 10 ) ; y = DatumFactory . createInt8 ( 2l ) ; z = x . multiply ( y ) ; assertEquals ( z . type ( ) , Type . INT8 ) ; assertEquals ( z . asInt8 ( ) , 10l ) ; z = y . multiply ( x ) ; assertEquals ( z . type ( ) , Type . INT8 ) ; assertEquals ( z . asInt8 ( ) , 10l ) ; y = DatumFactory . createFloat4 ( 2.5f ) ; z = x . multiply ( y ) ; assertEquals ( z . type ( ) , Type . FLOAT4 ) ; assertTrue ( z . asFloat4 ( ) == 12.5f ) ; z = y . multiply ( x ) ; assertEquals ( z . type ( ) , Type . FLOAT4 ) ; assertTrue ( z . asFloat4 ( ) == 12.5f ) ; y = DatumFactory . createFloat8 ( 4.5d ) ; z = x . multiply ( y ) ; assertEquals ( z . type ( ) , Type . FLOAT8 ) ; assertTrue ( z . asFloat8 ( ) == 22.5d ) ; z = y . multiply ( x ) ; assertEquals ( z . type ( ) , Type . FLOAT8 ) ; assertTrue ( z . asFloat8 ( ) == 22.5d ) ; } @ Test public final void testDivideDatumDatum ( ) { Datum x ; Datum y ; Datum z ; x = DatumFactory . createInt4 ( 6 ) ; y = DatumFactory . createInt4 ( 3 ) ; z = x . divide ( y ) ; assertEquals ( z . type ( ) , Type . INT4 ) ; assertEquals ( z . asInt4 ( ) , 2 ) ; z = y . divide ( x ) ; assertEquals ( z . type ( ) , Type . INT4 ) ; assertTrue ( z . asInt4 ( ) == 0 ) ; y = DatumFactory . createInt8 ( 3l ) ; z = x . divide ( y ) ; assertEquals ( z . type ( ) , Type . INT8 ) ; assertEquals ( z . asInt8 ( ) , 2l ) ; z = y . divide ( x ) ; assertEquals ( z . type ( ) , Type . INT8 ) ; assertEquals ( z . asInt8 ( ) , 0l ) ; y = DatumFactory . createFloat4 ( 3f ) ; z = x . divide ( y ) ; assertEquals ( z . type ( ) , Type . FLOAT4 ) ; assertTrue ( z . asFloat4 ( ) == 2.0f ) ; z = y . divide ( x ) ; assertEquals ( z . type ( ) , Type . FLOAT4 ) ; assertTrue ( z . asFloat4 ( ) == 0.5f ) ; y = DatumFactory . createFloat8 ( 3d ) ; z = x . divide ( y ) ; assertEquals ( z . type ( ) , Type . FLOAT8 ) ; assertTrue ( z . asFloat8 ( ) == 2.0d ) ; z = y . divide ( x ) ; assertEquals ( z . type ( ) , Type . FLOAT8 ) ; assertTrue ( z . asFloat8 ( ) == 0.5d ) ; } @ Test public final void testEqualToDatum ( ) { Datum x ; Datum y ; Datum z ; x = DatumFactory . createInt4 ( 6 ) ; y = DatumFactory . createInt4 ( 3 ) ; z = x . equalsTo ( y ) ; assertEquals ( z . type ( ) , Type . BOOLEAN ) ; assertEquals ( z . asBool ( ) , false ) ; z = y . equalsTo ( x ) ; assertEquals ( z . type ( ) , Type . BOOLEAN ) ; assertEquals ( z . asBool ( ) , false ) ; x = DatumFactory . createFloat4 ( 3.27f ) ; y = DatumFactory . createFloat4 ( 3.27f ) ; z = x . equalsTo ( y ) ; assertEquals ( z . type ( ) , Type . BOOLEAN ) ; assertEquals ( z . asBool ( ) , true ) ; z = y . equalsTo ( x ) ; assertEquals ( z . type ( ) , Type . BOOLEAN ) ; assertEquals ( z . asBool ( ) , true ) ; x = DatumFactory . createInt8 ( 123456789012345l ) ; y = DatumFactory . createInt8 ( 123456789012345l ) ; z = x . equalsTo ( y ) ; assertEquals ( z . type ( ) , Type . BOOLEAN ) ; assertEquals ( z . asBool ( ) , true ) ; z = y . equalsTo ( x ) ; assertEquals ( z . type ( ) , Type . BOOLEAN ) ; assertEquals ( z . asBool ( ) , true ) ; } @ Test public final void testLessThanDatum ( ) { Datum x ; Datum y ; Datum z ; x = DatumFactory . createInt4 ( 6 ) ; y = DatumFactory . createInt4 ( 3 ) ; z = x . lessThan ( y ) ; assertEquals ( z . type ( ) , Type . BOOLEAN ) ; assertEquals ( z . asBool ( ) , false ) ; z = y . lessThan ( x ) ; assertEquals ( z . type ( ) , Type . BOOLEAN ) ; assertEquals ( z . asBool ( ) , true ) ; } @ Test public final void testLessThanEqualsDatum ( ) { Datum x ; Datum y ; Datum z ; x = DatumFactory . createInt4 ( 6 ) ; y = DatumFactory . createInt4 ( 3 ) ; z = x . lessThanEqual ( y ) ; assertEquals ( z . type ( ) , Type . BOOLEAN ) ; assertEquals ( z . asBool ( ) , false ) ; z = y . lessThanEqual ( x ) ; assertEquals ( z . type ( ) , Type . BOOLEAN ) ; assertEquals ( z . asBool ( ) , true ) ; x = DatumFactory . createInt4 ( 6 ) ; y = DatumFactory . createInt4 ( 6 ) ; z = x . lessThanEqual ( y ) ; assertEquals ( z . type ( ) , Type . BOOLEAN ) ; assertEquals ( z . asBool ( ) , true ) ; z = y . lessThanEqual ( x ) ; assertEquals ( z . type ( ) , Type . BOOLEAN ) ; assertEquals ( z . asBool ( ) , true ) ; } @ Test public final void testgreaterThanDatum ( ) { Datum x ; Datum y ; Datum z ; x = DatumFactory . createInt4 ( 6 ) ; y = DatumFactory . createInt4 ( 3 ) ; z = x . greaterThan ( y ) ; assertEquals ( z . type ( ) , Type . BOOLEAN ) ; assertEquals ( z . asBool ( ) , true ) ; z = y . greaterThan ( x ) ; assertEquals ( z . type ( ) , Type . BOOLEAN ) ; assertEquals ( z . asBool ( ) , false ) ; x = DatumFactory . createInt4 ( 6 ) ; y = DatumFactory . createInt4 ( 6 ) ; z = x . greaterThan ( y ) ; assertEquals ( z . type ( ) , Type . BOOLEAN ) ; assertEquals ( z . asBool ( ) , false ) ; z = y . greaterThan ( x ) ; assertEquals ( z . type ( ) , Type . BOOLEAN ) ; assertEquals ( z . asBool ( ) , false ) ; } @ Test public final void testgreaterThanEqualsDatum ( ) { Datum x ; Datum y ; Datum z ; x = DatumFactory . createInt4 ( 6 ) ; y = DatumFactory . createInt4 ( 3 ) ; z = x . greaterThanEqual ( y ) ; assertEquals ( z . type ( ) , Type . BOOLEAN ) ; assertEquals ( z . asBool ( ) , true ) ; z = y . greaterThanEqual ( x ) ; assertEquals ( z . type ( ) , Type . BOOLEAN ) ; assertEquals ( z . asBool ( ) , false ) ; x = DatumFactory . createInt4 ( 6 ) ; y = DatumFactory . createInt4 ( 6 ) ; z = x . greaterThanEqual ( y ) ; assertEquals ( z . type ( ) , Type . BOOLEAN ) ; assertEquals ( z . asBool ( ) , true ) ; z = y . greaterThanEqual ( x ) ; assertEquals ( z . type ( ) , Type . BOOLEAN ) ; assertEquals ( z . asBool ( ) , true ) ; } }",Smelly
"public class SystemQueryOptionITCase extends AbstractParamTecSvcITCase { private static final String PROPERTY_INT16 = ""PropertyInt16"" ; private static final String ES_SERVER_SIDE_PAGING = ""ESServerSidePaging"" ; private static final String ES_ALL_PRIM = ""ESAllPrim"" ; @ Test public void countSimple ( ) { ODataEntitySetRequest < ClientEntitySet > request = getClient ( ) . getRetrieveRequestFactory ( ) . getEntitySetRequest ( getClient ( ) . newURIBuilder ( SERVICE_URI ) . appendEntitySetSegment ( ES_ALL_PRIM ) . count ( true ) . build ( ) ) ; setCookieHeader ( request ) ; ODataRetrieveResponse < ClientEntitySet > response = request . execute ( ) ; saveCookieHeader ( response ) ; assertEquals ( Integer . valueOf ( 3 ) , response . getBody ( ) . getCount ( ) ) ; assertEquals ( 3 , response . getBody ( ) . getEntities ( ) . size ( ) ) ; } @ Test public void serverSidePagingCount ( ) { ODataEntitySetRequest < ClientEntitySet > request = getClient ( ) . getRetrieveRequestFactory ( ) . getEntitySetRequest ( getClient ( ) . newURIBuilder ( SERVICE_URI ) . appendEntitySetSegment ( ES_SERVER_SIDE_PAGING ) . count ( true ) . build ( ) ) ; setCookieHeader ( request ) ; ODataRetrieveResponse < ClientEntitySet > response = request . execute ( ) ; saveCookieHeader ( response ) ; assertEquals ( 10 , response . getBody ( ) . getEntities ( ) . size ( ) ) ; assertEquals ( Integer . valueOf ( 503 ) , response . getBody ( ) . getCount ( ) ) ; } @ Test public void topSimple ( ) { ODataEntitySetRequest < ClientEntitySet > request = getClient ( ) . getRetrieveRequestFactory ( ) . getEntitySetRequest ( getClient ( ) . newURIBuilder ( SERVICE_URI ) . appendEntitySetSegment ( ES_SERVER_SIDE_PAGING ) . top ( 5 ) . build ( ) ) ; setCookieHeader ( request ) ; ODataRetrieveResponse < ClientEntitySet > response = request . execute ( ) ; saveCookieHeader ( response ) ; assertEquals ( 5 , response . getBody ( ) . getEntities ( ) . size ( ) ) ; for ( int i = 0 ; i < 5 ; i ++ ) { ClientEntity entity = response . getBody ( ) . getEntities ( ) . get ( i ) ; assertShortOrInt ( i + 1 , entity . getProperty ( PROPERTY_INT16 ) . getPrimitiveValue ( ) . toValue ( ) ) ; } } @ Test public void skipSimple ( ) { ODataEntitySetRequest < ClientEntitySet > request = getClient ( ) . getRetrieveRequestFactory ( ) . getEntitySetRequest ( getClient ( ) . newURIBuilder ( SERVICE_URI ) . appendEntitySetSegment ( ES_SERVER_SIDE_PAGING ) . skip ( 5 ) . build ( ) ) ; setCookieHeader ( request ) ; ODataRetrieveResponse < ClientEntitySet > response = request . execute ( ) ; saveCookieHeader ( response ) ; assertEquals ( 10 , response . getBody ( ) . getEntities ( ) . size ( ) ) ; for ( int i = 0 ; i < 10 ; i ++ ) { ClientEntity entity = response . getBody ( ) . getEntities ( ) . get ( i ) ; assertShortOrInt ( i + 6 , entity . getProperty ( PROPERTY_INT16 ) . getPrimitiveValue ( ) . toValue ( ) ) ; } } @ Test public void topNothing ( ) { ODataEntitySetRequest < ClientEntitySet > request = getClient ( ) . getRetrieveRequestFactory ( ) . getEntitySetRequest ( getClient ( ) . newURIBuilder ( SERVICE_URI ) . appendEntitySetSegment ( ES_SERVER_SIDE_PAGING ) . top ( 20 ) . skip ( 503 ) . build ( ) ) ; setCookieHeader ( request ) ; ODataRetrieveResponse < ClientEntitySet > response = request . execute ( ) ; saveCookieHeader ( response ) ; assertTrue ( response . getBody ( ) . getEntities ( ) . isEmpty ( ) ) ; } @ Test public void skipNothing ( ) { ODataEntitySetRequest < ClientEntitySet > request = getClient ( ) . getRetrieveRequestFactory ( ) . getEntitySetRequest ( getClient ( ) . newURIBuilder ( SERVICE_URI ) . appendEntitySetSegment ( ES_SERVER_SIDE_PAGING ) . skip ( 10000 ) . build ( ) ) ; setCookieHeader ( request ) ; ODataRetrieveResponse < ClientEntitySet > response = request . execute ( ) ; saveCookieHeader ( response ) ; assertTrue ( response . getBody ( ) . getEntities ( ) . isEmpty ( ) ) ; } @ Test public void searchAndFilterWithTopSkipOrderByAndServerSidePaging ( ) { ODataEntitySetRequest < ClientEntitySet > request = getClient ( ) . getRetrieveRequestFactory ( ) . getEntitySetRequest ( getClient ( ) . newURIBuilder ( SERVICE_URI ) . appendEntitySetSegment ( ES_SERVER_SIDE_PAGING ) . search ( ""\""Number:\"" AND NOT \""106\"""" ) . filter ( ""PropertyInt16 le 106"" ) . orderBy ( ""PropertyInt16 desc"" ) . count ( true ) . skip ( 3 ) . top ( 43 ) . build ( ) ) ; setCookieHeader ( request ) ; ODataRetrieveResponse < ClientEntitySet > response = request . execute ( ) ; saveCookieHeader ( response ) ; assertEquals ( Integer . valueOf ( 105 ) , response . getBody ( ) . getCount ( ) ) ; assertEquals ( 10 , response . getBody ( ) . getEntities ( ) . size ( ) ) ; int id = 102 ; for ( int i = 0 ; i < 10 ; i ++ ) { ClientEntity entity = response . getBody ( ) . getEntities ( ) . get ( i ) ; assertShortOrInt ( id , entity . getProperty ( PROPERTY_INT16 ) . getPrimitiveValue ( ) . toValue ( ) ) ; id -- ; } for ( int j = 0 ; j < 3 ; j ++ ) { request = getClient ( ) . getRetrieveRequestFactory ( ) . getEntitySetRequest ( response . getBody ( ) . getNext ( ) ) ; setCookieHeader ( request ) ; response = request . execute ( ) ; saveCookieHeader ( response ) ; assertEquals ( Integer . valueOf ( 105 ) , response . getBody ( ) . getCount ( ) ) ; assertEquals ( 10 , response . getBody ( ) . getEntities ( ) . size ( ) ) ; for ( int i = 0 ; i < 10 ; i ++ ) { ClientEntity entity = response . getBody ( ) . getEntities ( ) . get ( i ) ; assertShortOrInt ( id , entity . getProperty ( PROPERTY_INT16 ) . getPrimitiveValue ( ) . toValue ( ) ) ; id -- ; } } request = getClient ( ) . getRetrieveRequestFactory ( ) . getEntitySetRequest ( response . getBody ( ) . getNext ( ) ) ; setCookieHeader ( request ) ; response = request . execute ( ) ; saveCookieHeader ( response ) ; assertEquals ( Integer . valueOf ( 105 ) , response . getBody ( ) . getCount ( ) ) ; assertEquals ( 3 , response . getBody ( ) . getEntities ( ) . size ( ) ) ; for ( int i = 0 ; i < 3 ; i ++ ) { ClientEntity entity = response . getBody ( ) . getEntities ( ) . get ( i ) ; assertShortOrInt ( id , entity . getProperty ( PROPERTY_INT16 ) . getPrimitiveValue ( ) . toValue ( ) ) ; id -- ; } assertNull ( response . getBody ( ) . getNext ( ) ) ; } @ Test public void nextLinkFormat ( ) { ODataEntitySetRequest < ClientEntitySet > request = getClient ( ) . getRetrieveRequestFactory ( ) . getEntitySetRequest ( getClient ( ) . newURIBuilder ( SERVICE_URI ) . appendEntitySetSegment ( ES_SERVER_SIDE_PAGING ) . build ( ) ) ; setCookieHeader ( request ) ; ODataRetrieveResponse < ClientEntitySet > response = request . execute ( ) ; saveCookieHeader ( response ) ; URI nextLink = response . getBody ( ) . getNext ( ) ; assertEquals ( SERVICE_URI + ""ESServerSidePaging?%24skiptoken=1%2A10"" , nextLink . toASCIIString ( ) ) ; request = getClient ( ) . getRetrieveRequestFactory ( ) . getEntitySetRequest ( nextLink ) ; setCookieHeader ( request ) ; response = request . execute ( ) ; saveCookieHeader ( response ) ; nextLink = response . getBody ( ) . getNext ( ) ; assertEquals ( SERVICE_URI + ""ESServerSidePaging?%24skiptoken=2%2A10"" , nextLink . toASCIIString ( ) ) ; } @ Test public void nextLinkFormatWithQueryOptions ( ) { ODataEntitySetRequest < ClientEntitySet > request = getClient ( ) . getRetrieveRequestFactory ( ) . getEntitySetRequest ( getClient ( ) . newURIBuilder ( SERVICE_URI ) . appendEntitySetSegment ( ES_SERVER_SIDE_PAGING ) . count ( true ) . build ( ) ) ; setCookieHeader ( request ) ; ODataRetrieveResponse < ClientEntitySet > response = request . execute ( ) ; saveCookieHeader ( response ) ; URI nextLink = response . getBody ( ) . getNext ( ) ; assertEquals ( SERVICE_URI + ""ESServerSidePaging?%24count=true&%24skiptoken=1%2A10"" , nextLink . toASCIIString ( ) ) ; int token = 1 ; while ( nextLink != null ) { token ++ ; request = getClient ( ) . getRetrieveRequestFactory ( ) . getEntitySetRequest ( nextLink ) ; setCookieHeader ( request ) ; response = request . execute ( ) ; saveCookieHeader ( response ) ; nextLink = response . getBody ( ) . getNext ( ) ; if ( nextLink != null ) { assertEquals ( SERVICE_URI + ""ESServerSidePaging?%24count=true&%24skiptoken="" + token + ""%2A10"" , nextLink . toASCIIString ( ) ) ; } } assertEquals ( 50 + 1 , token ) ; } @ Test public void nextLinkFormatWithClientPageSize ( ) { final URI uri = getClient ( ) . newURIBuilder ( SERVICE_URI ) . appendEntitySetSegment ( ES_SERVER_SIDE_PAGING ) . build ( ) ; ODataEntitySetRequest < ClientEntitySet > request = getClient ( ) . getRetrieveRequestFactory ( ) . getEntitySetRequest ( uri ) ; request . setPrefer ( getClient ( ) . newPreferences ( ) . maxPageSize ( 7 ) ) ; setCookieHeader ( request ) ; final ODataRetrieveResponse < ClientEntitySet > response = request . execute ( ) ; saveCookieHeader ( response ) ; assertEquals ( ""odata.maxpagesize=7"" , response . getHeader ( HttpHeader . PREFERENCE_APPLIED ) . iterator ( ) . next ( ) ) ; assertEquals ( SERVICE_URI + ES_SERVER_SIDE_PAGING + ""?%24skiptoken=1%2A"" + 7 , response . getBody ( ) . getNext ( ) . toASCIIString ( ) ) ; } @ Test public void negativeSkip ( ) { ODataEntitySetRequest < ClientEntitySet > request = getClient ( ) . getRetrieveRequestFactory ( ) . getEntitySetRequest ( getClient ( ) . newURIBuilder ( SERVICE_URI ) . appendEntitySetSegment ( ES_ALL_PRIM ) . skip ( - 5 ) . build ( ) ) ; setCookieHeader ( request ) ; try { request . execute ( ) ; fail ( ) ; } catch ( ODataClientErrorException e ) { assertEquals ( HttpStatusCode . BAD_REQUEST . getStatusCode ( ) , e . getStatusLine ( ) . getStatusCode ( ) ) ; } } @ Test public void negativeTop ( ) { ODataEntitySetRequest < ClientEntitySet > request = getClient ( ) . getRetrieveRequestFactory ( ) . getEntitySetRequest ( getClient ( ) . newURIBuilder ( SERVICE_URI ) . appendEntitySetSegment ( ES_ALL_PRIM ) . top ( - 5 ) . build ( ) ) ; setCookieHeader ( request ) ; try { request . execute ( ) ; fail ( ) ; } catch ( ODataClientErrorException e ) { assertEquals ( HttpStatusCode . BAD_REQUEST . getStatusCode ( ) , e . getStatusLine ( ) . getStatusCode ( ) ) ; } } @ Test public void basicSearch ( ) { ODataEntitySetRequest < ClientEntitySet > request = getClient ( ) . getRetrieveRequestFactory ( ) . getEntitySetRequest ( getClient ( ) . newURIBuilder ( SERVICE_URI ) . appendEntitySetSegment ( ES_ALL_PRIM ) . search ( ""Second"" ) . build ( ) ) ; setCookieHeader ( request ) ; final ODataRetrieveResponse < ClientEntitySet > response = request . execute ( ) ; assertEquals ( 1 , response . getBody ( ) . getEntities ( ) . size ( ) ) ; } @ Test public void basicSearchPhrase ( ) { ODataEntitySetRequest < ClientEntitySet > request = getClient ( ) . getRetrieveRequestFactory ( ) . getEntitySetRequest ( getClient ( ) . newURIBuilder ( SERVICE_URI ) . appendEntitySetSegment ( ES_ALL_PRIM ) . search ( ""\""This is a \\\""$imple\\\""\\\\Phras~\"" AND "" + ""AnUnicodeWordLl\u01E3Lm\u02B5Lo\u00AALt\u01F2Lu\u03D3Nl\u216F"" ) . build ( ) ) ; setCookieHeader ( request ) ; final ODataRetrieveResponse < ClientEntitySet > response = request . execute ( ) ; assertTrue ( response . getBody ( ) . getEntities ( ) . isEmpty ( ) ) ; } @ Test public void andSearch ( ) { ODataEntitySetRequest < ClientEntitySet > request = getClient ( ) . getRetrieveRequestFactory ( ) . getEntitySetRequest ( getClient ( ) . newURIBuilder ( SERVICE_URI ) . appendEntitySetSegment ( ES_ALL_PRIM ) . search ( ""Second AND positive"" ) . build ( ) ) ; setCookieHeader ( request ) ; final ODataRetrieveResponse < ClientEntitySet > response = request . execute ( ) ; assertTrue ( response . getBody ( ) . getEntities ( ) . isEmpty ( ) ) ; } @ Test public void orSearch ( ) { ODataEntitySetRequest < ClientEntitySet > request = getClient ( ) . getRetrieveRequestFactory ( ) . getEntitySetRequest ( getClient ( ) . newURIBuilder ( SERVICE_URI ) . appendEntitySetSegment ( ES_ALL_PRIM ) . search ( ""Second OR positive"" ) . build ( ) ) ; setCookieHeader ( request ) ; ODataRetrieveResponse < ClientEntitySet > response = request . execute ( ) ; assertEquals ( 2 , response . getBody ( ) . getEntities ( ) . size ( ) ) ; } }",Smelly
"public class ReduceSender < T > implements Reduce . Sender < T > , EventHandler < GroupCommunicationMessage > { private static final Logger LOG = Logger . getLogger ( ReduceSender . class . getName ( ) ) ; private final Class < ? extends Name < String > > groupName ; private final Class < ? extends Name < String > > operName ; private final CommGroupNetworkHandler commGroupNetworkHandler ; private final Codec < T > dataCodec ; private final NetworkService < GroupCommunicationMessage > netService ; private final Sender sender ; private final ReduceFunction < T > reduceFunction ; private final OperatorTopology topology ; private final CommunicationGroupServiceClient commGroupClient ; private final AtomicBoolean init = new AtomicBoolean ( false ) ; private final int version ; @ Inject public ReduceSender ( @ Parameter ( CommunicationGroupName . class ) final String groupName , @ Parameter ( OperatorName . class ) final String operName , @ Parameter ( TaskConfigurationOptions . Identifier . class ) final String selfId , @ Parameter ( DataCodec . class ) final Codec < T > dataCodec , @ Parameter ( ReduceFunctionParam . class ) final ReduceFunction < T > reduceFunction , @ Parameter ( DriverIdentifierGroupComm . class ) final String driverId , @ Parameter ( TaskVersion . class ) final int version , final CommGroupNetworkHandler commGroupNetworkHandler , final NetworkService < GroupCommunicationMessage > netService , final CommunicationGroupServiceClient commGroupClient ) { super ( ) ; LOG . log ( Level . FINEST , ""{0} has CommGroupHandler-{1}"" , new Object [ ] { operName , commGroupNetworkHandler } ) ; this . version = version ; this . groupName = Utils . getClass ( groupName ) ; this . operName = Utils . getClass ( operName ) ; this . dataCodec = dataCodec ; this . reduceFunction = reduceFunction ; this . commGroupNetworkHandler = commGroupNetworkHandler ; this . netService = netService ; this . sender = new Sender ( this . netService ) ; this . topology = new OperatorTopologyImpl ( this . groupName , this . operName , selfId , driverId , sender , version ) ; this . commGroupNetworkHandler . register ( this . operName , this ) ; this . commGroupClient = commGroupClient ; } @ Override public int getVersion ( ) { return version ; } @ Override public void initialize ( ) throws ParentDeadException { topology . initialize ( ) ; } @ Override public Class < ? extends Name < String > > getOperName ( ) { return operName ; } @ Override public Class < ? extends Name < String > > getGroupName ( ) { return groupName ; } @ Override public String toString ( ) { return Utils . simpleName ( groupName ) + "":"" + Utils . simpleName ( operName ) + "":"" + version ; } @ Override public void onNext ( final GroupCommunicationMessage msg ) { topology . handle ( msg ) ; } @ Override public void send ( final T myData ) throws NetworkException , InterruptedException { LOG . entering ( ""ReduceSender"" , ""send"" , this ) ; LOG . fine ( ""I am "" + this ) ; if ( init . compareAndSet ( false , true ) ) { commGroupClient . initialize ( ) ; } LOG . finest ( ""Waiting for children"" ) ; try { final T reducedValueOfChildren = topology . recvFromChildren ( reduceFunction , dataCodec ) ; final List < T > vals = new ArrayList < > ( 2 ) ; vals . add ( myData ) ; if ( reducedValueOfChildren != null ) { vals . add ( reducedValueOfChildren ) ; } final T reducedValue = reduceFunction . apply ( vals ) ; topology . sendToParent ( dataCodec . encode ( reducedValue ) , ReefNetworkGroupCommProtos . GroupCommMessage . Type . Reduce ) ; } catch ( final ParentDeadException e ) { throw new RuntimeException ( ""ParentDeadException"" , e ) ; } LOG . exiting ( ""ReduceSender"" , ""send"" , this ) ; } @ Override public ReduceFunction < T > getReduceFunction ( ) { return reduceFunction ; } }",Smelly
"public class PortletURLModule extends AbstractInputModule implements ThreadSafe { public static final String NAME_RENDER = ""render"" ; public static final String NAME_RESOURCE = ""resource"" ; public static final String NAME_ACTION = ""action"" ; private static final String PREFIX_RENDER = NAME_RENDER + "":"" ; private static final String PREFIX_RESOURCE = NAME_RESOURCE + "":"" ; private static final String PREFIX_ACTION = NAME_ACTION + "":"" ; private static final List returnNames ; static { List tmp = new ArrayList ( ) ; tmp . add ( NAME_RENDER ) ; tmp . add ( NAME_RESOURCE ) ; tmp . add ( NAME_ACTION ) ; returnNames = tmp ; } public Iterator getAttributeNames ( Configuration modeConf , Map objectModel ) throws ConfigurationException { return PortletURLModule . returnNames . iterator ( ) ; } public Object getAttribute ( String name , Configuration modeConf , Map objectModel ) throws ConfigurationException { if ( name == null ) { throw new NullPointerException ( ""Attribute name is null"" ) ; } Request request = ObjectModelHelper . getRequest ( objectModel ) ; RenderResponse renderResponse = PortletObjectModelHelper . getRenderResponse ( objectModel ) ; if ( renderResponse != null ) { PortletURL url = null ; if ( name . startsWith ( PREFIX_RENDER ) ) { url = renderResponse . createRenderURL ( ) ; name = name . substring ( PREFIX_RENDER . length ( ) ) ; if ( name . length ( ) > 0 && name . charAt ( 0 ) == '/' ) { name = name . substring ( 1 ) ; } } else if ( name . startsWith ( PREFIX_RESOURCE ) ) { name = name . substring ( PREFIX_RESOURCE . length ( ) ) ; if ( name . length ( ) == 0 || name . charAt ( 0 ) != '/' ) { String uri = request . getContextPath ( ) + ""/"" + request . getServletPath ( ) ; name = NetUtils . absolutize ( uri , name ) ; } return renderResponse . encodeURL ( name ) ; } else if ( name . startsWith ( PREFIX_ACTION ) ) { url = renderResponse . createActionURL ( ) ; name = name . substring ( PREFIX_ACTION . length ( ) ) ; if ( name . length ( ) > 0 && name . charAt ( 0 ) == '/' ) { name = name . substring ( 1 ) ; } } else { throw new IllegalArgumentException ( ""Invalid attribute name '"" + name + ""' for '"" + getClass ( ) . getName ( ) + ""'"" ) ; } Map parameters = new HashMap ( 7 ) ; name = NetUtils . deparameterize ( name , parameters ) ; if ( name . length ( ) > 0 ) { parameters . put ( PortletEnvironment . PARAMETER_PATH_INFO , name ) ; } for ( Iterator i = parameters . keySet ( ) . iterator ( ) ; i . hasNext ( ) ; ) { String param = ( String ) i . next ( ) ; Object values = parameters . get ( param ) ; if ( values instanceof String ) { url . setParameter ( param , ( String ) values ) ; } else { url . setParameter ( param , ( String [ ] ) values ) ; } } return url . toString ( ) ; } else { if ( name . startsWith ( PREFIX_RENDER ) ) { return name . substring ( PREFIX_RENDER . length ( ) ) ; } else if ( name . startsWith ( PREFIX_RESOURCE ) ) { return name . substring ( PREFIX_RESOURCE . length ( ) ) ; } else if ( name . startsWith ( PREFIX_ACTION ) ) { return name . substring ( PREFIX_ACTION . length ( ) ) ; } else { throw new IllegalArgumentException ( ""Invalid attribute name '"" + name + ""' for '"" + getClass ( ) . getName ( ) + ""'"" ) ; } } } public Object [ ] getAttributeValues ( String name , Configuration modeConf , Map objectModel ) throws ConfigurationException { Object result = getAttribute ( name , modeConf , objectModel ) ; if ( result != null ) { return new Object [ ] { result } ; } return null ; } }",No
 public static class InjectionTargetReplacer implements Extension { public void replaceInjectionTarget ( @ Observes ProcessInjectionTarget < IJBean > event ) { event . setInjectionTarget ( new MyInjectionTarget ( event . getInjectionTarget ( ) ) ) ; } ,No
"public class CgenConfigHandler extends NamespaceAwareNestedTagHandler { public static final String CONFIG_TAG = ""cgen"" ; private static final String OUTPUT_DIRECTORY_TAG = ""destDir"" ; private static final String GENERATION_MODE_TAG = ""mode"" ; private static final String SUBCLASS_TEMPLATE_TAG = ""template"" ; private static final String SUPERCLASS_TEMPLATE_TAG = ""superTemplate"" ; private static final String OUTPUT_PATTERN_TAG = ""outputPattern"" ; private static final String MAKE_PAIRS_TAG = ""makePairs"" ; private static final String USE_PKG_PATH_TAG = ""usePkgPath"" ; private static final String OVERWRITE_SUBCLASSES_TAG = ""overwrite"" ; private static final String CREATE_PROPERTY_NAMES_TAG = ""createPropertyNames"" ; private static final String EXCLUDE_ENTITIES_TAG = ""excludeEntities"" ; private static final String EXCLUDE_EMBEDDABLES_TAG = ""excludeEmbeddables"" ; private static final String CREATE_PK_PROPERTIES = ""createPKProperties"" ; private static final String CLIENT_TAG = ""client"" ; private static final String SUPER_PKG_TAG = ""superPkg"" ; public static final String TRUE = ""true"" ; private DataChannelMetaData metaData ; private CgenConfiguration configuration ; CgenConfigHandler ( NamespaceAwareNestedTagHandler parentHandler , DataChannelMetaData metaData ) { super ( parentHandler ) ; this . metaData = metaData ; this . targetNamespace = CgenExtension . NAMESPACE ; this . configuration = new CgenConfiguration ( ) ; } @ Override protected boolean processElement ( String namespaceURI , String localName , Attributes attributes ) throws SAXException { switch ( localName ) { case CONFIG_TAG : createConfig ( ) ; return true ; } return false ; } @ Override protected void processCharData ( String localName , String data ) { switch ( localName ) { case OUTPUT_DIRECTORY_TAG : createOutputDir ( data ) ; break ; case GENERATION_MODE_TAG : createGenerationMode ( data ) ; break ; case EXCLUDE_ENTITIES_TAG : createExcludeEntities ( data ) ; break ; case EXCLUDE_EMBEDDABLES_TAG : createExcludeEmbeddables ( data ) ; break ; case SUBCLASS_TEMPLATE_TAG : createSubclassTemplate ( data ) ; break ; case SUPERCLASS_TEMPLATE_TAG : createSuperclassTemplate ( data ) ; break ; case OUTPUT_PATTERN_TAG : createOutputPattern ( data ) ; break ; case MAKE_PAIRS_TAG : createMakePairs ( data ) ; break ; case USE_PKG_PATH_TAG : createUsePkgPath ( data ) ; break ; case OVERWRITE_SUBCLASSES_TAG : createOverwriteSubclasses ( data ) ; break ; case CREATE_PROPERTY_NAMES_TAG : createPropertyNamesTag ( data ) ; break ; case CREATE_PK_PROPERTIES : createPkPropertiesTag ( data ) ; break ; case CLIENT_TAG : createClient ( data ) ; break ; case SUPER_PKG_TAG : createSuperPkg ( data ) ; break ; } } private void createOutputDir ( String path ) { if ( path . trim ( ) . length ( ) == 0 ) { return ; } configuration . setRelPath ( Paths . get ( path ) ) ; } private void createGenerationMode ( String mode ) { if ( mode . trim ( ) . length ( ) == 0 ) { return ; } configuration . setArtifactsGenerationMode ( mode ) ; } private void createExcludeEntities ( String entities ) { if ( entities . trim ( ) . length ( ) == 0 ) { return ; } configuration . loadEntities ( entities ) ; } private void createExcludeEmbeddables ( String embeddables ) { if ( embeddables . trim ( ) . length ( ) == 0 ) { return ; } configuration . loadEmbeddables ( embeddables ) ; } private void createSubclassTemplate ( String template ) { if ( template . trim ( ) . length ( ) == 0 ) { return ; } configuration . setTemplate ( template ) ; } private void createSuperclassTemplate ( String template ) { if ( template . trim ( ) . length ( ) == 0 ) { return ; } configuration . setSuperTemplate ( template ) ; } private void createOutputPattern ( String pattern ) { if ( pattern . trim ( ) . length ( ) == 0 ) { return ; } configuration . setOutputPattern ( pattern ) ; } private void createMakePairs ( String makePairs ) { if ( makePairs . trim ( ) . length ( ) == 0 ) { return ; } if ( makePairs . equals ( TRUE ) ) { configuration . setMakePairs ( true ) ; } else { configuration . setMakePairs ( false ) ; } } private void createUsePkgPath ( String data ) { if ( data . trim ( ) . length ( ) == 0 ) { return ; } if ( data . equals ( TRUE ) ) { configuration . setUsePkgPath ( true ) ; } else { configuration . setUsePkgPath ( false ) ; } } private void createOverwriteSubclasses ( String data ) { if ( data . trim ( ) . length ( ) == 0 ) { return ; } if ( data . equals ( TRUE ) ) { configuration . setOverwrite ( true ) ; } else { configuration . setOverwrite ( false ) ; } } private void createPropertyNamesTag ( String data ) { if ( data . trim ( ) . length ( ) == 0 ) { return ; } if ( data . equals ( TRUE ) ) { configuration . setCreatePropertyNames ( true ) ; } else { configuration . setCreatePropertyNames ( false ) ; } } private void createPkPropertiesTag ( String data ) { if ( data . trim ( ) . length ( ) == 0 ) { return ; } if ( data . equals ( TRUE ) ) { configuration . setCreatePKProperties ( true ) ; } else { configuration . setCreatePKProperties ( false ) ; } } private void createClient ( String data ) { if ( data . trim ( ) . length ( ) == 0 ) { return ; } if ( data . equals ( TRUE ) ) { configuration . setClient ( true ) ; } else { configuration . setClient ( false ) ; } } private void createSuperPkg ( String data ) { if ( data . trim ( ) . length ( ) == 0 ) { return ; } configuration . setSuperPkg ( data ) ; } private void createConfig ( ) { loaderContext . addDataMapListener ( dataMap -> { configuration . setDataMap ( dataMap ) ; configuration . setRootPath ( buildRootPath ( dataMap ) ) ; configuration . resolveExcludeEntities ( ) ; configuration . resolveExcludeEmbeddables ( ) ; CgenConfigHandler . this . metaData . add ( dataMap , configuration ) ; } ) ; } private Path buildRootPath ( DataMap dataMap ) { URL url = dataMap . getConfigurationSource ( ) . getURL ( ) ; Path resourcePath = Paths . get ( url . getPath ( ) ) ; if ( Files . isRegularFile ( resourcePath ) ) { resourcePath = resourcePath . getParent ( ) ; } return resourcePath ; } }",Smelly
"public class DefaultExchange implements Exchange { private static final UuidGenerator DEFAULT_ID_GENERATOR = new UuidGenerator ( ) ; protected final CamelContext context ; private Map < String , Object > properties ; private Message in ; private Message out ; private Message fault ; private Throwable exception ; private String exchangeId ; private UnitOfWork unitOfWork ; private ExchangePattern pattern ; public DefaultExchange ( CamelContext context ) { this ( context , ExchangePattern . InOnly ) ; } public DefaultExchange ( CamelContext context , ExchangePattern pattern ) { this . context = context ; this . pattern = pattern ; } public DefaultExchange ( DefaultExchange parent ) { this ( parent . getContext ( ) , parent . getPattern ( ) ) ; this . unitOfWork = parent . getUnitOfWork ( ) ; } @ Override public String toString ( ) { return ""Exchange["" + in + ""]"" ; } public Exchange copy ( ) { Exchange exchange = newInstance ( ) ; exchange . copyFrom ( this ) ; return exchange ; } public void copyFrom ( Exchange exchange ) { if ( exchange == this ) { return ; } setProperties ( safeCopy ( exchange . getProperties ( ) ) ) ; safeCopy ( getIn ( ) , exchange , exchange . getIn ( ) ) ; Message copyOut = exchange . getOut ( false ) ; if ( copyOut != null ) { safeCopy ( getOut ( true ) , exchange , copyOut ) ; } Message copyFault = exchange . getFault ( false ) ; if ( copyFault != null ) { safeCopy ( getFault ( true ) , exchange , copyFault ) ; } setException ( exchange . getException ( ) ) ; unitOfWork = exchange . getUnitOfWork ( ) ; pattern = exchange . getPattern ( ) ; } private static void safeCopy ( Message message , Exchange exchange , Message that ) { if ( message != null ) { message . copyFrom ( that ) ; } } private static Map < String , Object > safeCopy ( Map < String , Object > properties ) { if ( properties == null ) { return null ; } return new ConcurrentHashMap < String , Object > ( properties ) ; } private static Message safeCopy ( Exchange exchange , Message message ) { if ( message == null ) { return null ; } Message answer = message . copy ( ) ; if ( answer instanceof MessageSupport ) { MessageSupport messageSupport = ( MessageSupport ) answer ; messageSupport . setExchange ( exchange ) ; } return answer ; } public Exchange newInstance ( ) { return new DefaultExchange ( this ) ; } public CamelContext getContext ( ) { return context ; } public Object getProperty ( String name ) { if ( properties != null ) { return properties . get ( name ) ; } return null ; } public < T > T getProperty ( String name , Class < T > type ) { Object value = getProperty ( name ) ; ExchangeProperty < ? > property = ExchangeProperty . getByName ( name ) ; if ( property != null ) { validateExchangePropertyIsExpectedType ( property , type , value ) ; } return getContext ( ) . getTypeConverter ( ) . convertTo ( type , this , value ) ; } public void setProperty ( String name , Object value ) { ExchangeProperty < ? > property = ExchangeProperty . getByName ( name ) ; if ( property != null ) { Class type = value . getClass ( ) ; validateExchangePropertyIsExpectedType ( property , type , value ) ; } if ( value != null ) { getProperties ( ) . put ( name , value ) ; } else { if ( name != null ) { getProperties ( ) . remove ( name ) ; } } } private < T > void validateExchangePropertyIsExpectedType ( ExchangeProperty < ? > property , Class < T > type , Object value ) { if ( value != null && property != null && ! property . type ( ) . isAssignableFrom ( type ) ) { throw new RuntimeCamelException ( ""Type cast exception while getting an "" + ""Exchange Property value '"" + value . toString ( ) + ""' on Exchange "" + this + "" for a well known Exchange Property with these traits: "" + property ) ; } } public Object removeProperty ( String name ) { return getProperties ( ) . remove ( name ) ; } public Map < String , Object > getProperties ( ) { if ( properties == null ) { properties = new ConcurrentHashMap < String , Object > ( ) ; } return properties ; } public void setProperties ( Map < String , Object > properties ) { this . properties = properties ; } public Message getIn ( ) { if ( in == null ) { in = createInMessage ( ) ; configureMessage ( in ) ; } return in ; } public void setIn ( Message in ) { this . in = in ; configureMessage ( in ) ; } public Message getOut ( ) { return getOut ( true ) ; } public Message getOut ( boolean lazyCreate ) { if ( out == null && lazyCreate ) { out = createOutMessage ( ) ; configureMessage ( out ) ; } return out ; } public void setOut ( Message out ) { this . out = out ; configureMessage ( out ) ; } public Throwable getException ( ) { return exception ; } public void setException ( Throwable exception ) { this . exception = exception ; } public ExchangePattern getPattern ( ) { return pattern ; } public void setPattern ( ExchangePattern pattern ) { this . pattern = pattern ; } public void throwException ( ) throws Exception { if ( exception == null ) { return ; } if ( exception instanceof RuntimeException ) { throw ( RuntimeException ) exception ; } if ( exception instanceof Exception ) { throw ( Exception ) exception ; } throw wrapRuntimeCamelException ( exception ) ; } public Message getFault ( ) { return getFault ( true ) ; } public Message getFault ( boolean lazyCreate ) { if ( fault == null && lazyCreate ) { fault = createFaultMessage ( ) ; configureMessage ( fault ) ; } return fault ; } public void setFault ( Message fault ) { this . fault = fault ; configureMessage ( fault ) ; } public String getExchangeId ( ) { if ( exchangeId == null ) { exchangeId = DefaultExchange . DEFAULT_ID_GENERATOR . generateId ( ) ; } return exchangeId ; } public void setExchangeId ( String id ) { this . exchangeId = id ; } public boolean isFailed ( ) { Message faultMessage = getFault ( false ) ; if ( faultMessage != null ) { Object faultBody = faultMessage . getBody ( ) ; if ( faultBody != null ) { return true ; } } return getException ( ) != null ; } public boolean isTransacted ( ) { ExchangeProperty < ? > property = ExchangeProperty . get ( ""transacted"" ) ; return property != null && property . get ( this ) == Boolean . TRUE ; } public UnitOfWork getUnitOfWork ( ) { return unitOfWork ; } public void setUnitOfWork ( UnitOfWork unitOfWork ) { this . unitOfWork = unitOfWork ; } protected Message createInMessage ( ) { return new DefaultMessage ( ) ; } protected Message createOutMessage ( ) { return new DefaultMessage ( ) ; } protected Message createFaultMessage ( ) { return new DefaultMessage ( ) ; } protected void configureMessage ( Message message ) { if ( message instanceof MessageSupport ) { MessageSupport messageSupport = ( MessageSupport ) message ; messageSupport . setExchange ( this ) ; } } }",Smelly
"public class AppInterfaceUtil { public static ApplicationInterfaceDescription createAppInterface ( String applicationName , List < String > appModules , List < InputDataObjectType > appInputs , List < OutputDataObjectType > appOutputs ) { ApplicationInterfaceDescription interfaceDescription = new ApplicationInterfaceDescription ( ) ; interfaceDescription . setApplicationName ( applicationName ) ; interfaceDescription . setApplicationModules ( appModules ) ; interfaceDescription . setApplicationInputs ( appInputs ) ; interfaceDescription . setApplicationOutputs ( appOutputs ) ; return interfaceDescription ; } public static InputDataObjectType createApplicationInput ( String name , String value , DataType type , String applicationArgument , int order , boolean standardInput , String userFriendlyDesc , String metadata ) { InputDataObjectType appInput = new InputDataObjectType ( ) ; appInput . setName ( name ) ; appInput . setValue ( value ) ; appInput . setType ( type ) ; appInput . setMetaData ( metadata ) ; appInput . setApplicationArgument ( applicationArgument ) ; appInput . setInputOrder ( order ) ; appInput . setUserFriendlyDescription ( userFriendlyDesc ) ; appInput . setStandardInput ( standardInput ) ; return appInput ; } public static OutputDataObjectType createApplicationOutput ( String name , String value , DataType type ) { OutputDataObjectType appOutput = new OutputDataObjectType ( ) ; appOutput . setName ( name ) ; appOutput . setValue ( value ) ; appOutput . setType ( type ) ; return appOutput ; } }",No
"public class Mmap { public static final int APR_MMAP_READ = 1 ; public static final int APR_MMAP_WRITE = 2 ; public static native long create ( long file , long offset , long size , int flag , long pool ) throws Error ; public static native long dup ( long mmap , long pool ) throws Error ; public static native int delete ( long mm ) ; public static native long offset ( long mm , long offset ) throws Error ; }",No
"public class SumLogTest extends StorelessUnivariateStatisticAbstractTest { protected SumOfLogs stat ; @ Override public UnivariateStatistic getUnivariateStatistic ( ) { return new SumOfLogs ( ) ; } @ Override public double expectedValue ( ) { return this . sumLog ; } @ Test public void testSpecialValues ( ) { SumOfLogs sum = new SumOfLogs ( ) ; Assert . assertEquals ( 0 , sum . getResult ( ) , 0 ) ; sum . increment ( 1d ) ; Assert . assertFalse ( Double . isNaN ( sum . getResult ( ) ) ) ; sum . increment ( 0d ) ; Assert . assertEquals ( Double . NEGATIVE_INFINITY , sum . getResult ( ) , 0 ) ; sum . increment ( Double . POSITIVE_INFINITY ) ; Assert . assertTrue ( Double . isNaN ( sum . getResult ( ) ) ) ; sum . clear ( ) ; Assert . assertEquals ( 0 , sum . getResult ( ) , 0 ) ; sum . increment ( Double . POSITIVE_INFINITY ) ; Assert . assertEquals ( Double . POSITIVE_INFINITY , sum . getResult ( ) , 0 ) ; sum . increment ( - 2d ) ; Assert . assertTrue ( Double . isNaN ( sum . getResult ( ) ) ) ; } @ Override protected void checkClearValue ( StorelessUnivariateStatistic statistic ) { Assert . assertEquals ( 0 , statistic . getResult ( ) , 0 ) ; } }",No
" class ConsoleEventHandler < T > implements EventHandler < T > { private final String name ; private final Monitor monitor ; private final AtomicInteger counter ; private final int finalSize ; ConsoleEventHandler ( final String name , final Monitor monitor , final AtomicInteger counter , final int finalSize ) { this . name = name ; this . monitor = monitor ; this . counter = counter ; this . finalSize = finalSize ; } @ Override public void onNext ( final T value ) { System . out . println ( this . getClass ( ) + "" "" + name + "" "" + value ) ; if ( counter . incrementAndGet ( ) == finalSize ) { System . out . println ( this . getClass ( ) + "" notify counter: "" + counter . get ( ) ) ; monitor . mnotify ( ) ; } } ",No
"public class RemoteFileConfiguration implements Cloneable { private String protocol ; private String username ; private String host ; private int port ; private String password ; private String file ; private boolean binary ; private boolean directory = true ; private FTPClientConfig ftpClientConfig ; private Expression expression ; private boolean passiveMode ; private String knownHosts ; private String privateKeyFile ; private String privateKeyFilePassphrase ; public RemoteFileConfiguration ( ) { } public RemoteFileConfiguration ( URI uri ) { configure ( uri ) ; } public RemoteFileConfiguration copy ( ) { try { return ( RemoteFileConfiguration ) clone ( ) ; } catch ( CloneNotSupportedException e ) { throw new RuntimeCamelException ( e ) ; } } public String toString ( ) { return remoteServerInformation ( ) + ""/"" + file ; } public String remoteServerInformation ( ) { return protocol + ""://"" + ( username != null ? username : ""anonymous"" ) + ""@"" + host + "":"" + port ; } public void configure ( URI uri ) { setProtocol ( uri . getScheme ( ) ) ; setDefaultPort ( ) ; setUsername ( uri . getUserInfo ( ) ) ; setHost ( uri . getHost ( ) ) ; setPort ( uri . getPort ( ) ) ; setFile ( uri . getPath ( ) ) ; } protected void setDefaultPort ( ) { if ( ""ftp"" . equalsIgnoreCase ( protocol ) ) { setPort ( 21 ) ; } else if ( ""sftp"" . equalsIgnoreCase ( protocol ) ) { setPort ( 22 ) ; } } public String getFile ( ) { return file ; } public void setFile ( String file ) { if ( file . startsWith ( ""/"" ) ) { file = file . substring ( 1 ) ; } this . file = file ; } public String getKnownHosts ( ) { return knownHosts ; } public void setKnownHosts ( String knownHosts ) { this . knownHosts = knownHosts ; } public String getHost ( ) { return host ; } public void setHost ( String host ) { this . host = host ; } public int getPort ( ) { return port ; } public void setPort ( int port ) { if ( port != - 1 ) { this . port = port ; } } public String getPassword ( ) { return password ; } public void setPassword ( String password ) { this . password = password ; } public String getProtocol ( ) { return protocol ; } public void setProtocol ( String protocol ) { this . protocol = protocol ; } public String getUsername ( ) { return username ; } public void setUsername ( String username ) { this . username = username ; } public boolean isBinary ( ) { return binary ; } public void setBinary ( boolean binary ) { this . binary = binary ; } public boolean isDirectory ( ) { return directory ; } public void setDirectory ( boolean directory ) { this . directory = directory ; } public FTPClientConfig getFtpClientConfig ( ) { return ftpClientConfig ; } public void setFtpClientConfig ( FTPClientConfig ftpClientConfig ) { this . ftpClientConfig = ftpClientConfig ; } public Expression getExpression ( ) { return expression ; } public void setExpression ( Expression expression ) { this . expression = expression ; } public void setExpression ( String fileLanguageExpression ) { this . expression = FileLanguage . file ( fileLanguageExpression ) ; } public boolean isPassiveMode ( ) { return passiveMode ; } public void setPassiveMode ( boolean passiveMode ) { this . passiveMode = passiveMode ; } public String getPrivateKeyFile ( ) { return privateKeyFile ; } public void setPrivateKeyFile ( String privateKeyFile ) { this . privateKeyFile = privateKeyFile ; } public String getPrivateKeyFilePassphrase ( ) { return privateKeyFilePassphrase ; } public void setPrivateKeyFilePassphrase ( String privateKeyFilePassphrase ) { this . privateKeyFilePassphrase = privateKeyFilePassphrase ; } }",Smelly
" public static class BNodeIso implements EqualityTest { private NodeIsomorphismMap mapping ; private EqualityTest literalTest ; public BNodeIso ( EqualityTest literalTest ) { this . mapping = new NodeIsomorphismMap ( ) ; this . literalTest = literalTest ; } @ Override public boolean equal ( Node n1 , Node n2 ) { if ( n1 == null && n2 == null ) return true ; if ( n1 == null ) return false ; if ( n2 == null ) return false ; if ( n1 . isURI ( ) && n2 . isURI ( ) ) return n1 . equals ( n2 ) ; if ( n1 . isLiteral ( ) && n2 . isLiteral ( ) ) return literalTest . equal ( n1 , n2 ) ; if ( n1 . isBlank ( ) && n2 . isBlank ( ) ) return mapping . makeIsomorphic ( n1 , n2 ) ; if ( n1 . isVariable ( ) && n2 . isVariable ( ) ) return mapping . makeIsomorphic ( n1 , n2 ) ; return false ; } } ",No
"public class PutParquetTest { static final String DIRECTORY = ""target"" ; static final String TEST_CONF_PATH = ""src/test/resources/core-site.xml"" ; private Schema schema ; private Configuration testConf ; private PutParquet proc ; private MockRecordParser readerFactory ; private TestRunner testRunner ; @ BeforeClass public static void setupLogging ( ) { BasicConfigurator . configure ( ) ; } @ Before public void setup ( ) throws IOException , InitializationException { final String avroSchema = IOUtils . toString ( new FileInputStream ( ""src/test/resources/avro/user.avsc"" ) , StandardCharsets . UTF_8 ) ; schema = new Schema . Parser ( ) . parse ( avroSchema ) ; testConf = new Configuration ( ) ; testConf . addResource ( new Path ( TEST_CONF_PATH ) ) ; proc = new PutParquet ( ) ; } private void configure ( final PutParquet putParquet , final int numUsers ) throws InitializationException { testRunner = TestRunners . newTestRunner ( putParquet ) ; testRunner . setProperty ( PutParquet . HADOOP_CONFIGURATION_RESOURCES , TEST_CONF_PATH ) ; testRunner . setProperty ( PutParquet . DIRECTORY , DIRECTORY ) ; readerFactory = new MockRecordParser ( ) ; final RecordSchema recordSchema = AvroTypeUtil . createSchema ( schema ) ; for ( final RecordField recordField : recordSchema . getFields ( ) ) { readerFactory . addSchemaField ( recordField . getFieldName ( ) , recordField . getDataType ( ) . getFieldType ( ) ) ; } for ( int i = 0 ; i < numUsers ; i ++ ) { readerFactory . addRecord ( ""name"" + i , i , ""blue"" + i ) ; } testRunner . addControllerService ( ""mock-reader-factory"" , readerFactory ) ; testRunner . enableControllerService ( readerFactory ) ; testRunner . setProperty ( PutParquet . RECORD_READER , ""mock-reader-factory"" ) ; } @ Test public void testWriteAvroParquetWithDefaults ( ) throws IOException , InitializationException { configure ( proc , 100 ) ; final String filename = ""testWriteAvroWithDefaults-"" + System . currentTimeMillis ( ) ; final Map < String , String > flowFileAttributes = new HashMap < > ( ) ; flowFileAttributes . put ( CoreAttributes . FILENAME . key ( ) , filename ) ; testRunner . enqueue ( ""trigger"" , flowFileAttributes ) ; testRunner . run ( ) ; testRunner . assertAllFlowFilesTransferred ( PutParquet . REL_SUCCESS , 1 ) ; final Path avroParquetFile = new Path ( DIRECTORY + ""/"" + filename ) ; final MockFlowFile mockFlowFile = testRunner . getFlowFilesForRelationship ( PutParquet . REL_SUCCESS ) . get ( 0 ) ; mockFlowFile . assertAttributeEquals ( PutParquet . ABSOLUTE_HDFS_PATH_ATTRIBUTE , avroParquetFile . getParent ( ) . toString ( ) ) ; mockFlowFile . assertAttributeEquals ( CoreAttributes . FILENAME . key ( ) , filename ) ; mockFlowFile . assertAttributeEquals ( PutParquet . RECORD_COUNT_ATTR , ""100"" ) ; final List < ProvenanceEventRecord > provEvents = testRunner . getProvenanceEvents ( ) ; Assert . assertEquals ( 1 , provEvents . size ( ) ) ; final ProvenanceEventRecord provEvent = provEvents . get ( 0 ) ; Assert . assertEquals ( ProvenanceEventType . SEND , provEvent . getEventType ( ) ) ; Assert . assertTrue ( provEvent . getTransitUri ( ) . endsWith ( DIRECTORY + ""/"" + filename ) ) ; verifyAvroParquetUsers ( avroParquetFile , 100 ) ; final File tempAvroParquetFile = new File ( DIRECTORY + ""/."" + filename ) ; Assert . assertFalse ( tempAvroParquetFile . exists ( ) ) ; final File crcAvroParquetFile = new File ( DIRECTORY + ""/."" + filename + "".crc"" ) ; Assert . assertTrue ( crcAvroParquetFile . exists ( ) ) ; } @ Test public void testWriteAvroAndRemoveCRCFiles ( ) throws IOException , InitializationException { configure ( proc , 100 ) ; testRunner . setProperty ( PutParquet . REMOVE_CRC_FILES , ""true"" ) ; final String filename = ""testWriteAvroAndRemoveCRCFiles-"" + System . currentTimeMillis ( ) ; final Map < String , String > flowFileAttributes = new HashMap < > ( ) ; flowFileAttributes . put ( CoreAttributes . FILENAME . key ( ) , filename ) ; testRunner . enqueue ( ""trigger"" , flowFileAttributes ) ; testRunner . run ( ) ; testRunner . assertAllFlowFilesTransferred ( PutParquet . REL_SUCCESS , 1 ) ; final File tempAvroParquetFile = new File ( DIRECTORY + ""/."" + filename ) ; Assert . assertFalse ( tempAvroParquetFile . exists ( ) ) ; final File crcAvroParquetFile = new File ( DIRECTORY + ""/."" + filename + "".crc"" ) ; Assert . assertFalse ( crcAvroParquetFile . exists ( ) ) ; } @ Test public void testWriteAvroWithGZIPCompression ( ) throws IOException , InitializationException { configure ( proc , 100 ) ; testRunner . setProperty ( ParquetUtils . COMPRESSION_TYPE , CompressionCodecName . GZIP . name ( ) ) ; final String filename = ""testWriteAvroWithGZIPCompression-"" + System . currentTimeMillis ( ) ; final Map < String , String > flowFileAttributes = new HashMap < > ( ) ; flowFileAttributes . put ( CoreAttributes . FILENAME . key ( ) , filename ) ; testRunner . enqueue ( ""trigger"" , flowFileAttributes ) ; testRunner . run ( ) ; testRunner . assertAllFlowFilesTransferred ( PutParquet . REL_SUCCESS , 1 ) ; final Path avroParquetFile = new Path ( DIRECTORY + ""/"" + filename ) ; verifyAvroParquetUsers ( avroParquetFile , 100 ) ; } @ Test public void testInvalidAvroShouldRouteToFailure ( ) throws InitializationException , SchemaNotFoundException , MalformedRecordException , IOException { configure ( proc , 0 ) ; final RecordReaderFactory readerFactory = Mockito . mock ( RecordReaderFactory . class ) ; when ( readerFactory . getIdentifier ( ) ) . thenReturn ( ""mock-reader-factory"" ) ; when ( readerFactory . createRecordReader ( any ( FlowFile . class ) , any ( InputStream . class ) , any ( ComponentLog . class ) ) ) . thenThrow ( new IOException ( ""NOT AVRO"" ) ) ; testRunner . addControllerService ( ""mock-reader-factory"" , readerFactory ) ; testRunner . enableControllerService ( readerFactory ) ; testRunner . setProperty ( PutParquet . RECORD_READER , ""mock-reader-factory"" ) ; final String filename = ""testInvalidAvroShouldRouteToFailure-"" + System . currentTimeMillis ( ) ; final Map < String , String > flowFileAttributes = new HashMap < > ( ) ; flowFileAttributes . put ( CoreAttributes . FILENAME . key ( ) , filename ) ; testRunner . enqueue ( ""trigger"" , flowFileAttributes ) ; testRunner . run ( ) ; testRunner . assertAllFlowFilesTransferred ( PutParquet . REL_FAILURE , 1 ) ; } @ Test public void testCreateDirectoryIOExceptionShouldRouteToRetry ( ) throws InitializationException , IOException { final PutParquet proc = new PutParquet ( ) { @ Override protected void createDirectory ( FileSystem fileSystem , Path directory , String remoteOwner , String remoteGroup ) throws IOException , FailureException { throw new IOException ( ""IOException creating directory"" ) ; } } ; configure ( proc , 10 ) ; final String filename = ""testCreateDirectoryIOExceptionShouldRouteToRetry-"" + System . currentTimeMillis ( ) ; final Map < String , String > flowFileAttributes = new HashMap < > ( ) ; flowFileAttributes . put ( CoreAttributes . FILENAME . key ( ) , filename ) ; testRunner . enqueue ( ""trigger"" , flowFileAttributes ) ; testRunner . run ( ) ; testRunner . assertAllFlowFilesTransferred ( PutParquet . REL_RETRY , 1 ) ; } @ Test public void testCreateDirectoryFailureExceptionShouldRouteToFailure ( ) throws InitializationException , IOException { final PutParquet proc = new PutParquet ( ) { @ Override protected void createDirectory ( FileSystem fileSystem , Path directory , String remoteOwner , String remoteGroup ) throws IOException , FailureException { throw new FailureException ( ""FailureException creating directory"" ) ; } } ; configure ( proc , 10 ) ; final String filename = ""testCreateDirectoryFailureExceptionShouldRouteToFailure-"" + System . currentTimeMillis ( ) ; final Map < String , String > flowFileAttributes = new HashMap < > ( ) ; flowFileAttributes . put ( CoreAttributes . FILENAME . key ( ) , filename ) ; testRunner . enqueue ( ""trigger"" , flowFileAttributes ) ; testRunner . run ( ) ; testRunner . assertAllFlowFilesTransferred ( PutParquet . REL_FAILURE , 1 ) ; } @ Test public void testDestinationExistsWithoutOverwriteShouldRouteFailure ( ) throws IOException , InitializationException { configure ( proc , 10 ) ; testRunner . setProperty ( PutParquet . OVERWRITE , ""false"" ) ; final String filename = ""testDestinationExistsWithoutOverwriteShouldRouteFailure-"" + System . currentTimeMillis ( ) ; final File avroParquetFile = new File ( DIRECTORY + ""/"" + filename ) ; Assert . assertTrue ( avroParquetFile . createNewFile ( ) ) ; final Map < String , String > flowFileAttributes = new HashMap < > ( ) ; flowFileAttributes . put ( CoreAttributes . FILENAME . key ( ) , filename ) ; testRunner . enqueue ( ""trigger"" , flowFileAttributes ) ; testRunner . run ( ) ; testRunner . assertAllFlowFilesTransferred ( PutParquet . REL_FAILURE , 1 ) ; } @ Test public void testTempDestinationExistsWithoutOverwriteShouldRouteFailure ( ) throws IOException , InitializationException { configure ( proc , 10 ) ; testRunner . setProperty ( PutParquet . OVERWRITE , ""false"" ) ; final String filename = "".testDestinationExistsWithoutOverwriteShouldRouteFailure-"" + System . currentTimeMillis ( ) ; final File avroParquetFile = new File ( DIRECTORY + ""/"" + filename ) ; Assert . assertTrue ( avroParquetFile . createNewFile ( ) ) ; final Map < String , String > flowFileAttributes = new HashMap < > ( ) ; flowFileAttributes . put ( CoreAttributes . FILENAME . key ( ) , filename ) ; testRunner . enqueue ( ""trigger"" , flowFileAttributes ) ; testRunner . run ( ) ; testRunner . assertAllFlowFilesTransferred ( PutParquet . REL_FAILURE , 1 ) ; } @ Test public void testDestinationExistsWithOverwriteShouldBeSuccessful ( ) throws InitializationException , IOException { configure ( proc , 10 ) ; testRunner . setProperty ( PutParquet . OVERWRITE , ""true"" ) ; final String filename = ""testDestinationExistsWithOverwriteShouldBeSuccessful-"" + System . currentTimeMillis ( ) ; final File avroParquetFile = new File ( DIRECTORY + ""/"" + filename ) ; Assert . assertTrue ( avroParquetFile . createNewFile ( ) ) ; final Map < String , String > flowFileAttributes = new HashMap < > ( ) ; flowFileAttributes . put ( CoreAttributes . FILENAME . key ( ) , filename ) ; testRunner . enqueue ( ""trigger"" , flowFileAttributes ) ; testRunner . run ( ) ; testRunner . assertAllFlowFilesTransferred ( PutParquet . REL_SUCCESS , 1 ) ; } @ Test public void testValidSchemaWithELShouldBeSuccessful ( ) throws InitializationException , IOException { configure ( proc , 10 ) ; final String filename = ""testValidSchemaWithELShouldBeSuccessful-"" + System . currentTimeMillis ( ) ; final Map < String , String > flowFileAttributes = new HashMap < > ( ) ; flowFileAttributes . put ( CoreAttributes . FILENAME . key ( ) , filename ) ; flowFileAttributes . put ( ""my.schema"" , schema . toString ( ) ) ; testRunner . enqueue ( ""trigger"" , flowFileAttributes ) ; testRunner . run ( ) ; testRunner . assertAllFlowFilesTransferred ( PutParquet . REL_SUCCESS , 1 ) ; } @ Test public void testMalformedRecordExceptionFromReaderShouldRouteToFailure ( ) throws InitializationException , IOException , MalformedRecordException , SchemaNotFoundException { configure ( proc , 10 ) ; final RecordReader recordReader = Mockito . mock ( RecordReader . class ) ; when ( recordReader . nextRecord ( ) ) . thenThrow ( new MalformedRecordException ( ""ERROR"" ) ) ; final RecordReaderFactory readerFactory = Mockito . mock ( RecordReaderFactory . class ) ; when ( readerFactory . getIdentifier ( ) ) . thenReturn ( ""mock-reader-factory"" ) ; when ( readerFactory . createRecordReader ( any ( FlowFile . class ) , any ( InputStream . class ) , any ( ComponentLog . class ) ) ) . thenReturn ( recordReader ) ; testRunner . addControllerService ( ""mock-reader-factory"" , readerFactory ) ; testRunner . enableControllerService ( readerFactory ) ; testRunner . setProperty ( PutParquet . RECORD_READER , ""mock-reader-factory"" ) ; final String filename = ""testMalformedRecordExceptionShouldRouteToFailure-"" + System . currentTimeMillis ( ) ; final Map < String , String > flowFileAttributes = new HashMap < > ( ) ; flowFileAttributes . put ( CoreAttributes . FILENAME . key ( ) , filename ) ; testRunner . enqueue ( ""trigger"" , flowFileAttributes ) ; testRunner . run ( ) ; testRunner . assertAllFlowFilesTransferred ( PutParquet . REL_FAILURE , 1 ) ; } @ Test public void testIOExceptionCreatingWriterShouldRouteToRetry ( ) throws InitializationException , IOException , MalformedRecordException { final PutParquet proc = new PutParquet ( ) { @ Override public HDFSRecordWriter createHDFSRecordWriter ( ProcessContext context , FlowFile flowFile , Configuration conf , Path path , RecordSchema schema ) throws IOException , SchemaNotFoundException { throw new IOException ( ""IOException"" ) ; } } ; configure ( proc , 0 ) ; final String filename = ""testMalformedRecordExceptionShouldRouteToFailure-"" + System . currentTimeMillis ( ) ; final Map < String , String > flowFileAttributes = new HashMap < > ( ) ; flowFileAttributes . put ( CoreAttributes . FILENAME . key ( ) , filename ) ; testRunner . enqueue ( ""trigger"" , flowFileAttributes ) ; testRunner . run ( ) ; testRunner . assertAllFlowFilesTransferred ( PutParquet . REL_RETRY , 1 ) ; } @ Test public void testIOExceptionFromReaderShouldRouteToRetry ( ) throws InitializationException , IOException , MalformedRecordException , SchemaNotFoundException { configure ( proc , 10 ) ; final RecordSet recordSet = Mockito . mock ( RecordSet . class ) ; when ( recordSet . next ( ) ) . thenThrow ( new IOException ( ""ERROR"" ) ) ; final RecordReader recordReader = Mockito . mock ( RecordReader . class ) ; when ( recordReader . createRecordSet ( ) ) . thenReturn ( recordSet ) ; when ( recordReader . getSchema ( ) ) . thenReturn ( AvroTypeUtil . createSchema ( schema ) ) ; final RecordReaderFactory readerFactory = Mockito . mock ( RecordReaderFactory . class ) ; when ( readerFactory . getIdentifier ( ) ) . thenReturn ( ""mock-reader-factory"" ) ; when ( readerFactory . createRecordReader ( any ( FlowFile . class ) , any ( InputStream . class ) , any ( ComponentLog . class ) ) ) . thenReturn ( recordReader ) ; testRunner . addControllerService ( ""mock-reader-factory"" , readerFactory ) ; testRunner . enableControllerService ( readerFactory ) ; testRunner . setProperty ( PutParquet . RECORD_READER , ""mock-reader-factory"" ) ; final String filename = ""testMalformedRecordExceptionShouldRouteToFailure-"" + System . currentTimeMillis ( ) ; final Map < String , String > flowFileAttributes = new HashMap < > ( ) ; flowFileAttributes . put ( CoreAttributes . FILENAME . key ( ) , filename ) ; testRunner . enqueue ( ""trigger"" , flowFileAttributes ) ; testRunner . run ( ) ; testRunner . assertAllFlowFilesTransferred ( PutParquet . REL_RETRY , 1 ) ; } @ Test public void testIOExceptionRenamingShouldRouteToRetry ( ) throws InitializationException , IOException { final PutParquet proc = new PutParquet ( ) { @ Override protected void rename ( FileSystem fileSystem , Path srcFile , Path destFile ) throws IOException , InterruptedException , FailureException { throw new IOException ( ""IOException renaming"" ) ; } } ; configure ( proc , 10 ) ; final String filename = ""testIOExceptionRenamingShouldRouteToRetry-"" + System . currentTimeMillis ( ) ; final Map < String , String > flowFileAttributes = new HashMap < > ( ) ; flowFileAttributes . put ( CoreAttributes . FILENAME . key ( ) , filename ) ; testRunner . enqueue ( ""trigger"" , flowFileAttributes ) ; testRunner . run ( ) ; testRunner . assertAllFlowFilesTransferred ( PutParquet . REL_RETRY , 1 ) ; final File tempAvroParquetFile = new File ( DIRECTORY + ""/."" + filename ) ; Assert . assertFalse ( tempAvroParquetFile . exists ( ) ) ; } @ Test public void testFailureExceptionRenamingShouldRouteToFailure ( ) throws InitializationException , IOException { final PutParquet proc = new PutParquet ( ) { @ Override protected void rename ( FileSystem fileSystem , Path srcFile , Path destFile ) throws IOException , InterruptedException , FailureException { throw new FailureException ( ""FailureException renaming"" ) ; } } ; configure ( proc , 10 ) ; final String filename = ""testFailureExceptionRenamingShouldRouteToFailure-"" + System . currentTimeMillis ( ) ; final Map < String , String > flowFileAttributes = new HashMap < > ( ) ; flowFileAttributes . put ( CoreAttributes . FILENAME . key ( ) , filename ) ; testRunner . enqueue ( ""trigger"" , flowFileAttributes ) ; testRunner . run ( ) ; testRunner . assertAllFlowFilesTransferred ( PutParquet . REL_FAILURE , 1 ) ; final File tempAvroParquetFile = new File ( DIRECTORY + ""/."" + filename ) ; Assert . assertFalse ( tempAvroParquetFile . exists ( ) ) ; } @ Test public void testRowGroupSize ( ) throws IOException , InitializationException { configure ( proc , 10 ) ; testRunner . setProperty ( ParquetUtils . ROW_GROUP_SIZE , ""1024 B"" ) ; final String filename = ""testRowGroupSize-"" + System . currentTimeMillis ( ) ; final Map < String , String > flowFileAttributes = new HashMap < > ( ) ; flowFileAttributes . put ( CoreAttributes . FILENAME . key ( ) , filename ) ; testRunner . enqueue ( ""trigger"" , flowFileAttributes ) ; testRunner . run ( ) ; testRunner . assertAllFlowFilesTransferred ( PutParquet . REL_SUCCESS , 1 ) ; } @ Test public void testInvalidRowGroupSizeFromELShouldRouteToFailure ( ) throws IOException , InitializationException { configure ( proc , 10 ) ; testRunner . setProperty ( ParquetUtils . ROW_GROUP_SIZE , ""${row.group.size}"" ) ; final String filename = ""testInvalidRowGroupSizeFromELShouldRouteToFailure"" + System . currentTimeMillis ( ) ; final Map < String , String > flowFileAttributes = new HashMap < > ( ) ; flowFileAttributes . put ( CoreAttributes . FILENAME . key ( ) , filename ) ; flowFileAttributes . put ( ""row.group.size"" , ""NOT A DATA SIZE"" ) ; testRunner . enqueue ( ""trigger"" , flowFileAttributes ) ; testRunner . run ( ) ; testRunner . assertAllFlowFilesTransferred ( PutParquet . REL_FAILURE , 1 ) ; } @ Test public void testPageSize ( ) throws IOException , InitializationException { configure ( proc , 10 ) ; testRunner . setProperty ( ParquetUtils . PAGE_SIZE , ""1024 B"" ) ; final String filename = ""testPageGroupSize-"" + System . currentTimeMillis ( ) ; final Map < String , String > flowFileAttributes = new HashMap < > ( ) ; flowFileAttributes . put ( CoreAttributes . FILENAME . key ( ) , filename ) ; testRunner . enqueue ( ""trigger"" , flowFileAttributes ) ; testRunner . run ( ) ; testRunner . assertAllFlowFilesTransferred ( PutParquet . REL_SUCCESS , 1 ) ; } @ Test public void testInvalidPageSizeFromELShouldRouteToFailure ( ) throws IOException , InitializationException { configure ( proc , 10 ) ; testRunner . setProperty ( ParquetUtils . PAGE_SIZE , ""${page.size}"" ) ; final String filename = ""testInvalidPageSizeFromELShouldRouteToFailure"" + System . currentTimeMillis ( ) ; final Map < String , String > flowFileAttributes = new HashMap < > ( ) ; flowFileAttributes . put ( CoreAttributes . FILENAME . key ( ) , filename ) ; flowFileAttributes . put ( ""page.size"" , ""NOT A DATA SIZE"" ) ; testRunner . enqueue ( ""trigger"" , flowFileAttributes ) ; testRunner . run ( ) ; testRunner . assertAllFlowFilesTransferred ( PutParquet . REL_FAILURE , 1 ) ; } @ Test public void testDictionaryPageSize ( ) throws IOException , InitializationException { configure ( proc , 10 ) ; testRunner . setProperty ( ParquetUtils . DICTIONARY_PAGE_SIZE , ""1024 B"" ) ; final String filename = ""testDictionaryPageGroupSize-"" + System . currentTimeMillis ( ) ; final Map < String , String > flowFileAttributes = new HashMap < > ( ) ; flowFileAttributes . put ( CoreAttributes . FILENAME . key ( ) , filename ) ; testRunner . enqueue ( ""trigger"" , flowFileAttributes ) ; testRunner . run ( ) ; testRunner . assertAllFlowFilesTransferred ( PutParquet . REL_SUCCESS , 1 ) ; } @ Test public void testInvalidDictionaryPageSizeFromELShouldRouteToFailure ( ) throws IOException , InitializationException { configure ( proc , 10 ) ; testRunner . setProperty ( ParquetUtils . DICTIONARY_PAGE_SIZE , ""${dictionary.page.size}"" ) ; final String filename = ""testInvalidDictionaryPageSizeFromELShouldRouteToFailure"" + System . currentTimeMillis ( ) ; final Map < String , String > flowFileAttributes = new HashMap < > ( ) ; flowFileAttributes . put ( CoreAttributes . FILENAME . key ( ) , filename ) ; flowFileAttributes . put ( ""dictionary.page.size"" , ""NOT A DATA SIZE"" ) ; testRunner . enqueue ( ""trigger"" , flowFileAttributes ) ; testRunner . run ( ) ; testRunner . assertAllFlowFilesTransferred ( PutParquet . REL_FAILURE , 1 ) ; } @ Test public void testMaxPaddingPageSize ( ) throws IOException , InitializationException { configure ( proc , 10 ) ; testRunner . setProperty ( ParquetUtils . MAX_PADDING_SIZE , ""1024 B"" ) ; final String filename = ""testMaxPaddingSize-"" + System . currentTimeMillis ( ) ; final Map < String , String > flowFileAttributes = new HashMap < > ( ) ; flowFileAttributes . put ( CoreAttributes . FILENAME . key ( ) , filename ) ; testRunner . enqueue ( ""trigger"" , flowFileAttributes ) ; testRunner . run ( ) ; testRunner . assertAllFlowFilesTransferred ( PutParquet . REL_SUCCESS , 1 ) ; } @ Test public void testInvalidMaxPaddingSizeFromELShouldRouteToFailure ( ) throws IOException , InitializationException { configure ( proc , 10 ) ; testRunner . setProperty ( ParquetUtils . MAX_PADDING_SIZE , ""${max.padding.size}"" ) ; final String filename = ""testInvalidMaxPaddingSizeFromELShouldRouteToFailure"" + System . currentTimeMillis ( ) ; final Map < String , String > flowFileAttributes = new HashMap < > ( ) ; flowFileAttributes . put ( CoreAttributes . FILENAME . key ( ) , filename ) ; flowFileAttributes . put ( ""max.padding.size"" , ""NOT A DATA SIZE"" ) ; testRunner . enqueue ( ""trigger"" , flowFileAttributes ) ; testRunner . run ( ) ; testRunner . assertAllFlowFilesTransferred ( PutParquet . REL_FAILURE , 1 ) ; } @ Test public void testReadAsStringAndWriteAsInt ( ) throws InitializationException , IOException { configure ( proc , 0 ) ; readerFactory . addRecord ( ""name0"" , ""0"" , ""blue0"" ) ; final String filename = ""testReadAsStringAndWriteAsInt-"" + System . currentTimeMillis ( ) ; final Map < String , String > flowFileAttributes = new HashMap < > ( ) ; flowFileAttributes . put ( CoreAttributes . FILENAME . key ( ) , filename ) ; testRunner . enqueue ( ""trigger"" , flowFileAttributes ) ; testRunner . run ( ) ; testRunner . assertAllFlowFilesTransferred ( PutParquet . REL_SUCCESS , 1 ) ; final Path avroParquetFile = new Path ( DIRECTORY + ""/"" + filename ) ; verifyAvroParquetUsers ( avroParquetFile , 1 ) ; } private void verifyAvroParquetUsers ( final Path avroParquetUsers , final int numExpectedUsers ) throws IOException { final ParquetReader . Builder < GenericRecord > readerBuilder = AvroParquetReader . < GenericRecord > builder ( avroParquetUsers ) . withConf ( testConf ) ; int currUser = 0 ; try ( final ParquetReader < GenericRecord > reader = readerBuilder . build ( ) ) { GenericRecord nextRecord ; while ( ( nextRecord = reader . read ( ) ) != null ) { Assert . assertNotNull ( nextRecord ) ; Assert . assertEquals ( ""name"" + currUser , nextRecord . get ( ""name"" ) . toString ( ) ) ; Assert . assertEquals ( currUser , nextRecord . get ( ""favorite_number"" ) ) ; Assert . assertEquals ( ""blue"" + currUser , nextRecord . get ( ""favorite_color"" ) . toString ( ) ) ; currUser ++ ; } } Assert . assertEquals ( numExpectedUsers , currUser ) ; } }",Smelly
"@ Repository public class JPAAnyObjectDAO extends AbstractAnyDAO < AnyObject > implements AnyObjectDAO { private UserDAO userDAO ; private GroupDAO groupDAO ; private UserDAO userDAO ( ) { synchronized ( this ) { if ( userDAO == null ) { userDAO = ApplicationContextProvider . getApplicationContext ( ) . getBean ( UserDAO . class ) ; } } return userDAO ; } private GroupDAO groupDAO ( ) { synchronized ( this ) { if ( groupDAO == null ) { groupDAO = ApplicationContextProvider . getApplicationContext ( ) . getBean ( GroupDAO . class ) ; } } return groupDAO ; } @ Override protected AnyUtils init ( ) { return new JPAAnyUtilsFactory ( ) . getInstance ( AnyTypeKind . ANY_OBJECT ) ; } @ Override public Date findLastChange ( final String key ) { return findLastChange ( key , JPAAnyObject . TABLE ) ; } @ Override public Map < AnyType , Integer > countByType ( ) { Query query = entityManager ( ) . createQuery ( ""SELECT e.type, COUNT(e) AS countByType FROM  "" + JPAAnyObject . class . getSimpleName ( ) + "" e "" + ""GROUP BY e.type ORDER BY countByType DESC"" ) ; @ SuppressWarnings ( ""unchecked"" ) List < Object [ ] > results = query . getResultList ( ) ; Map < AnyType , Integer > countByRealm = new LinkedHashMap < > ( results . size ( ) ) ; for ( Object [ ] result : results ) { countByRealm . put ( ( AnyType ) result [ 0 ] , ( ( Number ) result [ 1 ] ) . intValue ( ) ) ; } return Collections . unmodifiableMap ( countByRealm ) ; } @ Override public Map < String , Integer > countByRealm ( final AnyType anyType ) { Query query = entityManager ( ) . createQuery ( ""SELECT e.realm, COUNT(e) FROM  "" + JPAAnyObject . class . getSimpleName ( ) + "" e "" + ""WHERE e.type=:type GROUP BY e.realm"" ) ; query . setParameter ( ""type"" , anyType ) ; @ SuppressWarnings ( ""unchecked"" ) List < Object [ ] > results = query . getResultList ( ) ; Map < String , Integer > countByRealm = new HashMap < > ( results . size ( ) ) ; for ( Object [ ] result : results ) { countByRealm . put ( ( ( Realm ) result [ 0 ] ) . getFullPath ( ) , ( ( Number ) result [ 1 ] ) . intValue ( ) ) ; } return Collections . unmodifiableMap ( countByRealm ) ; } @ Override protected void securityChecks ( final AnyObject anyObject ) { Set < String > authRealms = AuthContextUtils . getAuthorizations ( ) . get ( AnyEntitlement . READ . getFor ( anyObject . getType ( ) . getKey ( ) ) ) ; boolean authorized = IterableUtils . matchesAny ( authRealms , new Predicate < String > ( ) { @ Override public boolean evaluate ( final String realm ) { return anyObject . getRealm ( ) . getFullPath ( ) . startsWith ( realm ) ; } } ) ; if ( ! authorized ) { authorized = ! CollectionUtils . intersection ( findDynRealms ( anyObject . getKey ( ) ) , authRealms ) . isEmpty ( ) ; } if ( authRealms == null || authRealms . isEmpty ( ) || ! authorized ) { throw new DelegatedAdministrationException ( anyObject . getRealm ( ) . getFullPath ( ) , AnyTypeKind . ANY_OBJECT , anyObject . getKey ( ) ) ; } } @ Override public AnyObject findByName ( final String name ) { TypedQuery < AnyObject > query = entityManager ( ) . createQuery ( ""SELECT e FROM "" + JPAAnyObject . class . getSimpleName ( ) + "" e WHERE e.name = :name"" , AnyObject . class ) ; query . setParameter ( ""name"" , name ) ; AnyObject result = null ; try { result = query . getSingleResult ( ) ; } catch ( NoResultException e ) { LOG . debug ( ""No any object found with name {}"" , name , e ) ; } return result ; } @ Override public AnyObject authFindByName ( final String name ) { if ( name == null ) { throw new NotFoundException ( ""Null name"" ) ; } AnyObject anyObject = findByName ( name ) ; if ( anyObject == null ) { throw new NotFoundException ( ""Any Object "" + name ) ; } securityChecks ( anyObject ) ; return anyObject ; } @ Override public List < ARelationship > findAllRelationships ( final AnyObject anyObject ) { TypedQuery < ARelationship > query = entityManager ( ) . createQuery ( ""SELECT e FROM "" + JPAARelationship . class . getSimpleName ( ) + "" e WHERE e.rightEnd=:anyObject OR e.leftEnd=:anyObject"" , ARelationship . class ) ; query . setParameter ( ""anyObject"" , anyObject ) ; return query . getResultList ( ) ; } @ Override public int count ( ) { Query query = entityManager ( ) . createQuery ( ""SELECT COUNT(e) FROM  "" + JPAAnyObject . class . getSimpleName ( ) + "" e"" ) ; return ( ( Number ) query . getSingleResult ( ) ) . intValue ( ) ; } @ Override public List < AnyObject > findAll ( final int page , final int itemsPerPage ) { TypedQuery < AnyObject > query = entityManager ( ) . createQuery ( ""SELECT e FROM  "" + JPAAnyObject . class . getSimpleName ( ) + "" e"" , AnyObject . class ) ; query . setFirstResult ( itemsPerPage * ( page <= 0 ? 0 : page - 1 ) ) ; query . setMaxResults ( itemsPerPage ) ; return query . getResultList ( ) ; } @ Override public AnyObject save ( final AnyObject anyObject ) { AnyObject merged = super . save ( anyObject ) ; publisher . publishEvent ( new AnyCreatedUpdatedEvent < > ( this , merged , AuthContextUtils . getDomain ( ) ) ) ; groupDAO ( ) . refreshDynMemberships ( merged ) ; dynRealmDAO ( ) . refreshDynMemberships ( merged ) ; return merged ; } private List < ARelationship > findARelationships ( final AnyObject anyObject ) { TypedQuery < ARelationship > query = entityManager ( ) . createQuery ( ""SELECT e FROM "" + JPAARelationship . class . getSimpleName ( ) + "" e WHERE e.rightEnd=:anyObject"" , ARelationship . class ) ; query . setParameter ( ""anyObject"" , anyObject ) ; return query . getResultList ( ) ; } private List < URelationship > findURelationships ( final AnyObject anyObject ) { TypedQuery < URelationship > query = entityManager ( ) . createQuery ( ""SELECT e FROM "" + JPAURelationship . class . getSimpleName ( ) + "" e WHERE e.rightEnd=:anyObject"" , URelationship . class ) ; query . setParameter ( ""anyObject"" , anyObject ) ; return query . getResultList ( ) ; } @ Override public void delete ( final AnyObject anyObject ) { groupDAO ( ) . removeDynMemberships ( anyObject ) ; dynRealmDAO ( ) . removeDynMemberships ( anyObject . getKey ( ) ) ; for ( ARelationship relationship : findARelationships ( anyObject ) ) { relationship . getLeftEnd ( ) . getRelationships ( ) . remove ( relationship ) ; save ( relationship . getLeftEnd ( ) ) ; entityManager ( ) . remove ( relationship ) ; } for ( URelationship relationship : findURelationships ( anyObject ) ) { relationship . getLeftEnd ( ) . getRelationships ( ) . remove ( relationship ) ; userDAO ( ) . save ( relationship . getLeftEnd ( ) ) ; entityManager ( ) . remove ( relationship ) ; } entityManager ( ) . remove ( anyObject ) ; publisher . publishEvent ( new AnyDeletedEvent ( this , AnyTypeKind . ANY_OBJECT , anyObject . getKey ( ) , AuthContextUtils . getDomain ( ) ) ) ; } @ Transactional ( propagation = Propagation . REQUIRES_NEW , readOnly = true ) @ Override public List < Group > findDynGroups ( final String key ) { Query query = entityManager ( ) . createNativeQuery ( ""SELECT group_id FROM "" + JPAGroupDAO . ADYNMEMB_TABLE + "" WHERE any_id=?"" ) ; query . setParameter ( 1 , key ) ; List < Group > result = new ArrayList < > ( ) ; for ( Object resultKey : query . getResultList ( ) ) { String actualKey = resultKey instanceof Object [ ] ? ( String ) ( ( Object [ ] ) resultKey ) [ 0 ] : ( ( String ) resultKey ) ; Group group = groupDAO ( ) . find ( actualKey ) ; if ( group == null ) { LOG . error ( ""Could not find group with id {}, even though returned by the native query"" , actualKey ) ; } else if ( ! result . contains ( group ) ) { result . add ( group ) ; } } return result ; } @ Transactional ( propagation = Propagation . REQUIRES_NEW , readOnly = true ) @ Override public Collection < Group > findAllGroups ( final AnyObject anyObject ) { return CollectionUtils . union ( CollectionUtils . collect ( anyObject . getMemberships ( ) , new Transformer < AMembership , Group > ( ) { @ Override public Group transform ( final AMembership input ) { return input . getRightEnd ( ) ; } } , new ArrayList < Group > ( ) ) , findDynGroups ( anyObject . getKey ( ) ) ) ; } @ Transactional ( propagation = Propagation . REQUIRES_NEW , readOnly = true ) @ Override public Collection < String > findAllGroupKeys ( final AnyObject anyObject ) { return CollectionUtils . collect ( findAllGroups ( anyObject ) , EntityUtils . < Group > keyTransformer ( ) ) ; } @ Transactional ( propagation = Propagation . REQUIRES_NEW , readOnly = true ) @ Override public Collection < ExternalResource > findAllResources ( final AnyObject anyObject ) { Set < ExternalResource > result = new HashSet < > ( ) ; result . addAll ( anyObject . getResources ( ) ) ; for ( Group group : findAllGroups ( anyObject ) ) { result . addAll ( group . getResources ( ) ) ; } return result ; } @ Transactional ( readOnly = true ) @ Override public Collection < String > findAllResourceKeys ( final String key ) { return CollectionUtils . collect ( findAllResources ( authFind ( key ) ) , EntityUtils . < ExternalResource > keyTransformer ( ) ) ; } }",Smelly
"public class AMQ2764Test extends TestCase { private static final Logger LOG = LoggerFactory . getLogger ( AMQ2764Test . class ) ; private BrokerService brokerOne ; private BrokerService brokerTwo ; private Destination destination ; private ArrayList < Connection > connections = new ArrayList < Connection > ( ) ; public void testInactivityMonitor ( ) throws Exception { startBrokerTwo ( ) ; brokerTwo . waitUntilStarted ( ) ; startBrokerOne ( ) ; brokerOne . waitUntilStarted ( ) ; Thread . sleep ( 2000 ) ; ActiveMQConnectionFactory secondProducerConnectionFactory = createBrokerTwoHttpConnectionFactory ( ) ; ActiveMQConnectionFactory consumerConnectionFactory = createBrokerOneHttpConnectionFactory ( ) ; MessageConsumer consumer = createConsumer ( consumerConnectionFactory ) ; AtomicInteger counter = createConsumerCounter ( consumerConnectionFactory ) ; waitForConsumerToArrive ( counter ) ; Connection connection = secondProducerConnectionFactory . createConnection ( ) ; Session session = connection . createSession ( false , Session . AUTO_ACKNOWLEDGE ) ; MessageProducer producer = session . createProducer ( destination ) ; producer . setDeliveryMode ( DeliveryMode . NON_PERSISTENT ) ; final int expectedMessagesReceived = 2000 ; for ( int i = 0 ; i < expectedMessagesReceived ; i ++ ) { Message message = session . createMessage ( ) ; producer . send ( message ) ; LOG . info ( ""sent message "" + i ) ; } for ( int i = 0 ; i < expectedMessagesReceived ; i ++ ) { Message message = consumer . receive ( 2000 ) ; if ( message == null ) { fail ( ""Didn't receive a message"" ) ; } LOG . info ( ""received message "" + i ) ; } } public void testBrokerRestart ( ) throws Exception { startBrokerTwo ( ) ; brokerTwo . waitUntilStarted ( ) ; startBrokerOne ( ) ; brokerOne . waitUntilStarted ( ) ; Thread . sleep ( 5000 ) ; ActiveMQConnectionFactory producerConnectionFactory = createBrokerOneConnectionFactory ( ) ; ActiveMQConnectionFactory secondProducerConnectionFactory = createBrokerTwoConnectionFactory ( ) ; ActiveMQConnectionFactory consumerConnectionFactory = createBrokerOneConnectionFactory ( ) ; MessageConsumer consumer = createConsumer ( consumerConnectionFactory ) ; AtomicInteger counter = createConsumerCounter ( consumerConnectionFactory ) ; waitForConsumerToArrive ( counter ) ; final int expectedMessagesReceived = 25 ; int actualMessagesReceived = doSendMessage ( expectedMessagesReceived , consumer , producerConnectionFactory ) ; assertEquals ( ""Didn't receive the right amount of messages directly connected"" , expectedMessagesReceived , actualMessagesReceived ) ; assertNull ( ""Had extra messages"" , consumer . receiveNoWait ( ) ) ; actualMessagesReceived = doSendMessage ( expectedMessagesReceived , consumer , secondProducerConnectionFactory ) ; assertEquals ( ""Didn't receive the right amount of messages via network"" , expectedMessagesReceived , actualMessagesReceived ) ; assertNull ( ""Had extra messages"" , consumer . receiveNoWait ( ) ) ; LOG . info ( ""Stopping broker one"" ) ; stopBrokerOne ( ) ; TimeUnit . SECONDS . sleep ( 1 ) ; LOG . info ( ""Restarting broker"" ) ; startBrokerOne ( ) ; consumer = createConsumer ( consumerConnectionFactory ) ; counter = createConsumerCounter ( consumerConnectionFactory ) ; waitForConsumerToArrive ( counter ) ; actualMessagesReceived = doSendMessage ( expectedMessagesReceived , consumer , secondProducerConnectionFactory ) ; assertEquals ( ""Didn't receive the right amount of messages via network after restart"" , expectedMessagesReceived , actualMessagesReceived ) ; assertNull ( ""Had extra messages"" , consumer . receiveNoWait ( ) ) ; stopBrokerOne ( ) ; stopBrokerTwo ( ) ; } protected int doSendMessage ( int expectedMessagesReceived , MessageConsumer consumer , ActiveMQConnectionFactory connectionFactory ) throws Exception { int messagesReceived = 0 ; for ( int i = 0 ; i < expectedMessagesReceived ; i ++ ) { String messageId = sendMessage ( connectionFactory ) ; Message message = consumer . receive ( 5000 ) ; if ( message != null ) { messagesReceived ++ ; } } return messagesReceived ; } protected String sendMessage ( ActiveMQConnectionFactory connectionFactory ) throws JMSException { Connection connection = null ; try { connection = connectionFactory . createConnection ( ) ; Session session = connection . createSession ( false , Session . AUTO_ACKNOWLEDGE ) ; MessageProducer producer = session . createProducer ( destination ) ; Message message = session . createMessage ( ) ; producer . send ( message ) ; return message . getJMSMessageID ( ) ; } finally { try { connection . close ( ) ; } catch ( Throwable ignore ) { } } } protected BrokerService createFirstBroker ( ) throws Exception { return BrokerFactory . createBroker ( new URI ( ""xbean:org/apache/activemq/bugs/amq2764/reconnect-broker1.xml"" ) ) ; } protected BrokerService createSecondBroker ( ) throws Exception { return BrokerFactory . createBroker ( new URI ( ""xbean:org/apache/activemq/bugs/amq2764/reconnect-broker2.xml"" ) ) ; } protected ActiveMQConnectionFactory createBrokerOneConnectionFactory ( ) { return new ActiveMQConnectionFactory ( ""vm://broker1"" ) ; } protected ActiveMQConnectionFactory createBrokerTwoConnectionFactory ( ) { return new ActiveMQConnectionFactory ( ""vm://broker2"" ) ; } protected ActiveMQConnectionFactory createBrokerOneHttpConnectionFactory ( ) { return new ActiveMQConnectionFactory ( ""http://localhost:61616"" ) ; } protected ActiveMQConnectionFactory createBrokerTwoHttpConnectionFactory ( ) { return new ActiveMQConnectionFactory ( ""http://localhost:61617"" ) ; } protected void setUp ( ) throws Exception { LOG . info ( ""==============================================================================="" ) ; LOG . info ( ""Running Test Case: "" + getName ( ) ) ; LOG . info ( ""==============================================================================="" ) ; destination = new ActiveMQQueue ( ""RECONNECT.TEST.QUEUE"" ) ; } protected void tearDown ( ) throws Exception { disposeConsumerConnections ( ) ; try { stopBrokerOne ( ) ; } catch ( Throwable e ) { } try { stopBrokerTwo ( ) ; } catch ( Throwable e ) { } } protected void disposeConsumerConnections ( ) { for ( Iterator < Connection > iter = connections . iterator ( ) ; iter . hasNext ( ) ; ) { Connection connection = iter . next ( ) ; try { connection . close ( ) ; } catch ( Throwable ignore ) { } } } protected void startBrokerOne ( ) throws Exception { if ( brokerOne == null ) { brokerOne = createFirstBroker ( ) ; brokerOne . start ( ) ; brokerOne . waitUntilStarted ( ) ; WaitForJettyListener . waitForJettySocketToAccept ( ""http://localhost:61616"" ) ; } } protected void stopBrokerOne ( ) throws Exception { if ( brokerOne != null ) { brokerOne . stop ( ) ; brokerOne = null ; } } protected void startBrokerTwo ( ) throws Exception { if ( brokerTwo == null ) { brokerTwo = createSecondBroker ( ) ; brokerTwo . start ( ) ; brokerTwo . waitUntilStarted ( ) ; WaitForJettyListener . waitForJettySocketToAccept ( ""http://localhost:61617"" ) ; } } protected void stopBrokerTwo ( ) throws Exception { if ( brokerTwo != null ) { brokerTwo . stop ( ) ; brokerTwo = null ; } } protected MessageConsumer createConsumer ( ActiveMQConnectionFactory consumerConnectionFactory ) throws JMSException { Connection connection = consumerConnectionFactory . createConnection ( ) ; connections . add ( connection ) ; connection . start ( ) ; Session session = connection . createSession ( false , Session . AUTO_ACKNOWLEDGE ) ; return session . createConsumer ( destination ) ; } protected AtomicInteger createConsumerCounter ( ActiveMQConnectionFactory cf ) throws Exception { final AtomicInteger rc = new AtomicInteger ( 0 ) ; Connection connection = cf . createConnection ( ) ; connections . add ( connection ) ; connection . start ( ) ; ConsumerEventSource source = new ConsumerEventSource ( connection , destination ) ; source . setConsumerListener ( new ConsumerListener ( ) { public void onConsumerEvent ( ConsumerEvent event ) { rc . set ( event . getConsumerCount ( ) ) ; } } ) ; source . start ( ) ; return rc ; } protected void waitForConsumerToArrive ( AtomicInteger consumerCounter ) throws InterruptedException { for ( int i = 0 ; i < 100 ; i ++ ) { if ( consumerCounter . get ( ) > 0 ) { return ; } Thread . sleep ( 100 ) ; } fail ( ""The consumer did not arrive."" ) ; } protected void waitForConsumerToLeave ( AtomicInteger consumerCounter ) throws InterruptedException { for ( int i = 0 ; i < 100 ; i ++ ) { if ( consumerCounter . get ( ) == 0 ) { return ; } Thread . sleep ( 100 ) ; } fail ( ""The consumer did not leave."" ) ; } }",Smelly
"public class UUID_V4_Gen implements UUIDFactory { static final int versionHere = 4 ; static final int variantHere = JenaUUID . Var_Std ; private Random random = null ; public UUID_V4_Gen ( ) { } @ Override public JenaUUID generate ( ) { return generateV4 ( ) ; } public UUID_V4 generateV4 ( ) { init ( ) ; long mostSigBits = random . nextLong ( ) ; long leastSigBits = random . nextLong ( ) ; mostSigBits = BitsLong . pack ( mostSigBits , versionHere , 12 , 16 ) ; leastSigBits = BitsLong . pack ( leastSigBits , variantHere , 62 , 64 ) ; return new UUID_V4 ( mostSigBits , leastSigBits ) ; } @ Override public JenaUUID parse ( String s ) { return parseV4 ( s ) ; } public UUID_V4 parseV4 ( String s ) { s = s . toLowerCase ( Locale . ENGLISH ) ; if ( s . length ( ) != 36 ) throw new UUIDFormatException ( ""UUID string is not 36 chars long: it's "" + s . length ( ) + "" ["" + s + ""]"" ) ; if ( s . charAt ( 8 ) != '-' && s . charAt ( 13 ) != '-' && s . charAt ( 18 ) != '-' && s . charAt ( 23 ) != '-' ) throw new UUIDFormatException ( ""String does not have dashes in the right places: "" + s ) ; UUID_V4 u = parse$ ( s ) ; if ( u . getVersion ( ) != versionHere ) throw new UUIDFormatException ( ""Wrong version (Expected: "" + versionHere + ""Got: "" + u . getVersion ( ) + ""): "" + s ) ; if ( u . getVariant ( ) != variantHere ) throw new UUIDFormatException ( ""Wrong version (Expected: "" + variantHere + ""Got: "" + u . getVariant ( ) + ""): "" + s ) ; return u ; } static UUID_V4 parse$ ( String s ) { long mostSigBits = BitsLong . unpack ( s , 0 , 8 ) ; mostSigBits = mostSigBits < < 16 | BitsLong . unpack ( s , 9 , 13 ) ; mostSigBits = mostSigBits < < 16 | BitsLong . unpack ( s , 14 , 18 ) ; long leastSigBits = BitsLong . unpack ( s , 19 , 23 ) ; leastSigBits = leastSigBits < < 48 | BitsLong . unpack ( s , 24 , 36 ) ; return new UUID_V4 ( mostSigBits , leastSigBits ) ; } private void init ( ) { if ( random == null ) reset ( ) ; } @ Override public void reset ( ) { random = LibUUID . makeRandom ( ) ; } }",No
 private static class ColumnUpdateTupleSchemeFactory implements SchemeFactory { public ColumnUpdateTupleScheme getScheme ( ) { return new ColumnUpdateTupleScheme ( ) ; } ,No
"public class Train { public static String replacefirstoccuranceof ( String tomatch , String line ) { int index = line . indexOf ( tomatch ) ; if ( index == - 1 ) { return line ; } else { return line . substring ( 0 , index ) + line . substring ( index + tomatch . length ( ) ) ; } } public static void updateHashMap ( HashMap < String , Integer > dict , String key ) { if ( ! key . equals ( """" ) ) { if ( dict . containsKey ( key ) ) dict . put ( key , dict . get ( key ) + 1 ) ; else dict . put ( key , 1 ) ; } } public static String flattenHashMap ( HashMap < String , Integer > dict ) { String result = """" ; for ( String key : dict . keySet ( ) ) { result += key + "":"" + dict . get ( key ) + "","" ; } result = result . substring ( 0 , result . length ( ) - 1 ) ; return result ; } public static void start ( String filepath ) throws IOException { int numof_ir = 0 ; int numof_r = 0 ; int numwords_ir = 0 ; int numwords_r = 0 ; HashSet < String > uniquewords = new HashSet < String > ( ) ; HashMap < String , Integer > wordfreq_ir = new HashMap < String , Integer > ( ) ; HashMap < String , Integer > wordfreq_r = new HashMap < String , Integer > ( ) ; String line = """" ; String target = """" ; String [ ] linearray = null ; Configuration configuration = new Configuration ( ) ; FileSystem fs = FileSystem . get ( configuration ) ; BufferedReader bufferedReader = new BufferedReader ( configuration . getConfResourceAsReader ( filepath ) ) ; while ( ( line = bufferedReader . readLine ( ) ) != null ) { target = line . split ( ""\t"" ) [ 0 ] ; line = replacefirstoccuranceof ( target + ""\t"" , line ) ; linearray = line . replaceAll ( ""[^a-zA-Z ]"" , """" ) . toLowerCase ( ) . split ( "" "" ) ; if ( target . equals ( ""0"" ) ) { numof_ir += 1 ; numwords_ir += linearray . length ; for ( int i = 0 ; i < linearray . length ; i ++ ) { uniquewords . add ( linearray [ i ] ) ; updateHashMap ( wordfreq_ir , linearray [ i ] ) ; } } else { numof_r += 1 ; numwords_r += linearray . length ; for ( int i = 0 ; i < linearray . length ; i ++ ) { uniquewords . add ( linearray [ i ] ) ; updateHashMap ( wordfreq_r , linearray [ i ] ) ; } } } Path path = new Path ( ""naivebayes-model"" ) ; Writer writer = new BufferedWriter ( new OutputStreamWriter ( fs . create ( path , true ) ) ) ; writer . write ( String . valueOf ( uniquewords . size ( ) ) + ""\n"" ) ; writer . write ( ""0\n"" ) ; writer . write ( String . valueOf ( numof_ir ) + ""\n"" ) ; writer . write ( String . valueOf ( numwords_ir ) + ""\n"" ) ; writer . write ( flattenHashMap ( wordfreq_ir ) + ""\n"" ) ; writer . write ( ""1\n"" ) ; writer . write ( String . valueOf ( numof_r ) + ""\n"" ) ; writer . write ( String . valueOf ( numwords_r ) + ""\n"" ) ; writer . write ( flattenHashMap ( wordfreq_r ) + ""\n"" ) ; writer . close ( ) ; bufferedReader . close ( ) ; } }",No
public abstract class Node_Fluid extends Node { protected Node_Fluid ( Object label ) { super ( label ) ; } @ Override public boolean isConcrete ( ) { return false ; } },No
"public class GenericTypeValidator implements Serializable { private static final long serialVersionUID = 5487162314134261703L ; private static final Log LOG = LogFactory . getLog ( GenericTypeValidator . class ) ; public static Byte formatByte ( String value ) { if ( value == null ) { return null ; } try { return Byte . valueOf ( value ) ; } catch ( NumberFormatException e ) { return null ; } } public static Byte formatByte ( String value , Locale locale ) { Byte result = null ; if ( value != null ) { NumberFormat formatter = null ; if ( locale != null ) { formatter = NumberFormat . getNumberInstance ( locale ) ; } else { formatter = NumberFormat . getNumberInstance ( Locale . getDefault ( ) ) ; } formatter . setParseIntegerOnly ( true ) ; ParsePosition pos = new ParsePosition ( 0 ) ; Number num = formatter . parse ( value , pos ) ; if ( pos . getErrorIndex ( ) == - 1 && pos . getIndex ( ) == value . length ( ) && num . doubleValue ( ) >= Byte . MIN_VALUE && num . doubleValue ( ) <= Byte . MAX_VALUE ) { result = Byte . valueOf ( num . byteValue ( ) ) ; } } return result ; } public static Short formatShort ( String value ) { if ( value == null ) { return null ; } try { return Short . valueOf ( value ) ; } catch ( NumberFormatException e ) { return null ; } } public static Short formatShort ( String value , Locale locale ) { Short result = null ; if ( value != null ) { NumberFormat formatter = null ; if ( locale != null ) { formatter = NumberFormat . getNumberInstance ( locale ) ; } else { formatter = NumberFormat . getNumberInstance ( Locale . getDefault ( ) ) ; } formatter . setParseIntegerOnly ( true ) ; ParsePosition pos = new ParsePosition ( 0 ) ; Number num = formatter . parse ( value , pos ) ; if ( pos . getErrorIndex ( ) == - 1 && pos . getIndex ( ) == value . length ( ) && num . doubleValue ( ) >= Short . MIN_VALUE && num . doubleValue ( ) <= Short . MAX_VALUE ) { result = Short . valueOf ( num . shortValue ( ) ) ; } } return result ; } public static Integer formatInt ( String value ) { if ( value == null ) { return null ; } try { return Integer . valueOf ( value ) ; } catch ( NumberFormatException e ) { return null ; } } public static Integer formatInt ( String value , Locale locale ) { Integer result = null ; if ( value != null ) { NumberFormat formatter = null ; if ( locale != null ) { formatter = NumberFormat . getNumberInstance ( locale ) ; } else { formatter = NumberFormat . getNumberInstance ( Locale . getDefault ( ) ) ; } formatter . setParseIntegerOnly ( true ) ; ParsePosition pos = new ParsePosition ( 0 ) ; Number num = formatter . parse ( value , pos ) ; if ( pos . getErrorIndex ( ) == - 1 && pos . getIndex ( ) == value . length ( ) && num . doubleValue ( ) >= Integer . MIN_VALUE && num . doubleValue ( ) <= Integer . MAX_VALUE ) { result = Integer . valueOf ( num . intValue ( ) ) ; } } return result ; } public static Long formatLong ( String value ) { if ( value == null ) { return null ; } try { return Long . valueOf ( value ) ; } catch ( NumberFormatException e ) { return null ; } } public static Long formatLong ( String value , Locale locale ) { Long result = null ; if ( value != null ) { NumberFormat formatter = null ; if ( locale != null ) { formatter = NumberFormat . getNumberInstance ( locale ) ; } else { formatter = NumberFormat . getNumberInstance ( Locale . getDefault ( ) ) ; } formatter . setParseIntegerOnly ( true ) ; ParsePosition pos = new ParsePosition ( 0 ) ; Number num = formatter . parse ( value , pos ) ; if ( pos . getErrorIndex ( ) == - 1 && pos . getIndex ( ) == value . length ( ) && num . doubleValue ( ) >= Long . MIN_VALUE && num . doubleValue ( ) <= Long . MAX_VALUE ) { result = Long . valueOf ( num . longValue ( ) ) ; } } return result ; } public static Float formatFloat ( String value ) { if ( value == null ) { return null ; } try { return new Float ( value ) ; } catch ( NumberFormatException e ) { return null ; } } public static Float formatFloat ( String value , Locale locale ) { Float result = null ; if ( value != null ) { NumberFormat formatter = null ; if ( locale != null ) { formatter = NumberFormat . getInstance ( locale ) ; } else { formatter = NumberFormat . getInstance ( Locale . getDefault ( ) ) ; } ParsePosition pos = new ParsePosition ( 0 ) ; Number num = formatter . parse ( value , pos ) ; if ( pos . getErrorIndex ( ) == - 1 && pos . getIndex ( ) == value . length ( ) && num . doubleValue ( ) >= ( Float . MAX_VALUE * - 1 ) && num . doubleValue ( ) <= Float . MAX_VALUE ) { result = new Float ( num . floatValue ( ) ) ; } } return result ; } public static Double formatDouble ( String value ) { if ( value == null ) { return null ; } try { return new Double ( value ) ; } catch ( NumberFormatException e ) { return null ; } } public static Double formatDouble ( String value , Locale locale ) { Double result = null ; if ( value != null ) { NumberFormat formatter = null ; if ( locale != null ) { formatter = NumberFormat . getInstance ( locale ) ; } else { formatter = NumberFormat . getInstance ( Locale . getDefault ( ) ) ; } ParsePosition pos = new ParsePosition ( 0 ) ; Number num = formatter . parse ( value , pos ) ; if ( pos . getErrorIndex ( ) == - 1 && pos . getIndex ( ) == value . length ( ) && num . doubleValue ( ) >= ( Double . MAX_VALUE * - 1 ) && num . doubleValue ( ) <= Double . MAX_VALUE ) { result = new Double ( num . doubleValue ( ) ) ; } } return result ; } public static Date formatDate ( String value , Locale locale ) { Date date = null ; if ( value == null ) { return null ; } try { DateFormat formatterShort = null ; DateFormat formatterDefault = null ; if ( locale != null ) { formatterShort = DateFormat . getDateInstance ( DateFormat . SHORT , locale ) ; formatterDefault = DateFormat . getDateInstance ( DateFormat . DEFAULT , locale ) ; } else { formatterShort = DateFormat . getDateInstance ( DateFormat . SHORT , Locale . getDefault ( ) ) ; formatterDefault = DateFormat . getDateInstance ( DateFormat . DEFAULT , Locale . getDefault ( ) ) ; } formatterShort . setLenient ( false ) ; formatterDefault . setLenient ( false ) ; try { date = formatterShort . parse ( value ) ; } catch ( ParseException e ) { date = formatterDefault . parse ( value ) ; } } catch ( ParseException e ) { if ( LOG . isDebugEnabled ( ) ) { LOG . debug ( ""Date parse failed value=["" + value + ""], "" + ""locale=["" + locale + ""] "" + e ) ; } } return date ; } public static Date formatDate ( String value , String datePattern , boolean strict ) { Date date = null ; if ( value == null || datePattern == null || datePattern . length ( ) == 0 ) { return null ; } try { SimpleDateFormat formatter = new SimpleDateFormat ( datePattern ) ; formatter . setLenient ( false ) ; date = formatter . parse ( value ) ; if ( strict && datePattern . length ( ) != value . length ( ) ) { date = null ; } } catch ( ParseException e ) { if ( LOG . isDebugEnabled ( ) ) { LOG . debug ( ""Date parse failed value=["" + value + ""], "" + ""pattern=["" + datePattern + ""], "" + ""strict=["" + strict + ""] "" + e ) ; } } return date ; } public static Long formatCreditCard ( String value ) { return GenericValidator . isCreditCard ( value ) ? Long . valueOf ( value ) : null ; } }",Smelly
"public class RangerAuthorizationCoprocessor implements MasterObserver , RegionObserver , RegionServerObserver , BulkLoadObserver , AccessControlProtos . AccessControlService . Interface , CoprocessorService , Coprocessor { public static final Log LOG = LogFactory . getLog ( RangerAuthorizationCoprocessor . class ) ; private static final String RANGER_PLUGIN_TYPE = ""hbase"" ; private static final String RANGER_HBASE_AUTHORIZER_IMPL_CLASSNAME = ""org.apache.ranger.authorization.hbase.RangerAuthorizationCoprocessor"" ; private static RangerPluginClassLoader rangerPluginClassLoader = null ; private Object impl = null ; private MasterObserver implMasterObserver = null ; private RegionObserver implRegionObserver = null ; private RegionServerObserver implRegionServerObserver = null ; private BulkLoadObserver implBulkLoadObserver = null ; private AccessControlProtos . AccessControlService . Interface implAccessControlService = null ; private CoprocessorService implCoprocessorService = null ; public RangerAuthorizationCoprocessor ( ) { if ( LOG . isDebugEnabled ( ) ) { LOG . debug ( ""==> RangerAuthorizationCoprocessor.RangerAuthorizationCoprocessor()"" ) ; } this . init ( ) ; if ( LOG . isDebugEnabled ( ) ) { LOG . debug ( ""<== RangerAuthorizationCoprocessor.RangerAuthorizationCoprocessor()"" ) ; } } private void init ( ) { if ( LOG . isDebugEnabled ( ) ) { LOG . debug ( ""==> RangerAuthorizationCoprocessor.init()"" ) ; } try { rangerPluginClassLoader = RangerPluginClassLoader . getInstance ( RANGER_PLUGIN_TYPE , this . getClass ( ) ) ; @ SuppressWarnings ( ""unchecked"" ) Class < ? > cls = Class . forName ( RANGER_HBASE_AUTHORIZER_IMPL_CLASSNAME , true , rangerPluginClassLoader ) ; activatePluginClassLoader ( ) ; impl = cls . newInstance ( ) ; implMasterObserver = ( MasterObserver ) impl ; implRegionObserver = ( RegionObserver ) impl ; implRegionServerObserver = ( RegionServerObserver ) impl ; implBulkLoadObserver = ( BulkLoadObserver ) impl ; implAccessControlService = ( AccessControlProtos . AccessControlService . Interface ) impl ; implCoprocessorService = ( CoprocessorService ) impl ; } catch ( Exception e ) { LOG . error ( ""Error Enabling RangerHbasePlugin"" , e ) ; } finally { deactivatePluginClassLoader ( ) ; } if ( LOG . isDebugEnabled ( ) ) { LOG . debug ( ""<== RangerAuthorizationCoprocessor.init()"" ) ; } } @ Override public Service getService ( ) { if ( LOG . isDebugEnabled ( ) ) { LOG . debug ( ""==> RangerAuthorizationCoprocessor.getService()"" ) ; } final Service ret ; try { activatePluginClassLoader ( ) ; ret = implCoprocessorService . getService ( ) ; } finally { deactivatePluginClassLoader ( ) ; } if ( LOG . isDebugEnabled ( ) ) { LOG . debug ( ""<== RangerAuthorizationCoprocessor.getService()"" + ret ) ; } return ret ; } @ Override public void postScannerClose ( ObserverContext < RegionCoprocessorEnvironment > c , InternalScanner s ) throws IOException { if ( LOG . isDebugEnabled ( ) ) { LOG . debug ( ""==> RangerAuthorizationCoprocessor.postScannerClose()"" ) ; } try { activatePluginClassLoader ( ) ; implRegionObserver . postScannerClose ( c , s ) ; } finally { deactivatePluginClassLoader ( ) ; } if ( LOG . isDebugEnabled ( ) ) { LOG . debug ( ""<== RangerAuthorizationCoprocessor.postScannerClose()"" ) ; } } @ Override public RegionScanner postScannerOpen ( ObserverContext < RegionCoprocessorEnvironment > c , Scan scan , RegionScanner s ) throws IOException { final RegionScanner ret ; if ( LOG . isDebugEnabled ( ) ) { LOG . debug ( ""==> RangerAuthorizationCoprocessor.postScannerOpen()"" ) ; } try { activatePluginClassLoader ( ) ; ret = implRegionObserver . postScannerOpen ( c , scan , s ) ; } finally { deactivatePluginClassLoader ( ) ; } if ( LOG . isDebugEnabled ( ) ) { LOG . debug ( ""<== RangerAuthorizationCoprocessor.postScannerOpen()"" ) ; } return ret ; } @ Override public void postStartMaster ( ObserverContext < MasterCoprocessorEnvironment > ctx ) throws IOException { if ( LOG . isDebugEnabled ( ) ) { LOG . debug ( ""==> RangerAuthorizationCoprocessor.postStartMaster()"" ) ; } try { activatePluginClassLoader ( ) ; implMasterObserver . postStartMaster ( ctx ) ; } finally { deactivatePluginClassLoader ( ) ; } if ( LOG . isDebugEnabled ( ) ) { LOG . debug ( ""<== RangerAuthorizationCoprocessor.postStartMaster()"" ) ; } } @ Override public void preAddColumn ( ObserverContext < MasterCoprocessorEnvironment > c , TableName tableName , HColumnDescriptor column ) throws IOException { if ( LOG . isDebugEnabled ( ) ) { LOG . debug ( ""==> RangerAuthorizationCoprocessor.preAddColumn()"" ) ; } try { activatePluginClassLoader ( ) ; implMasterObserver . preAddColumn ( c , tableName , column ) ; } finally { deactivatePluginClassLoader ( ) ; } if ( LOG . isDebugEnabled ( ) ) { LOG . debug ( ""<== RangerAuthorizationCoprocessor.preAddColumn()"" ) ; } } @ Override public Result preAppend ( ObserverContext < RegionCoprocessorEnvironment > c , Append append ) throws IOException { final Result ret ; if ( LOG . isDebugEnabled ( ) ) { LOG . debug ( ""==> RangerAuthorizationCoprocessor.preAppend()"" ) ; } try { activatePluginClassLoader ( ) ; ret = implRegionObserver . preAppend ( c , append ) ; } finally { deactivatePluginClassLoader ( ) ; } if ( LOG . isDebugEnabled ( ) ) { LOG . debug ( ""<== RangerAuthorizationCoprocessor.preAppend()"" ) ; } return ret ; } @ Override public void preAssign ( ObserverContext < MasterCoprocessorEnvironment > c , HRegionInfo regionInfo ) throws IOException { if ( LOG . isDebugEnabled ( ) ) { LOG . debug ( ""==> RangerAuthorizationCoprocessor.preAssign()"" ) ; } try { activatePluginClassLoader ( ) ; implMasterObserver . preAssign ( c , regionInfo ) ; } finally { deactivatePluginClassLoader ( ) ; } if ( LOG . isDebugEnabled ( ) ) { LOG . debug ( ""<== RangerAuthorizationCoprocessor.preAssign()"" ) ; } } @ Override public void preBalance ( ObserverContext < MasterCoprocessorEnvironment > c ) throws IOException { if ( LOG . isDebugEnabled ( ) ) { LOG . debug ( ""==> RangerAuthorizationCoprocessor.preBalance()"" ) ; } try { activatePluginClassLoader ( ) ; implMasterObserver . preBalance ( c ) ; } finally { deactivatePluginClassLoader ( ) ; } if ( LOG . isDebugEnabled ( ) ) { LOG . debug ( ""<== RangerAuthorizationCoprocessor.preBalance()"" ) ; } } @ Override public boolean preBalanceSwitch ( ObserverContext < MasterCoprocessorEnvironment > c , boolean newValue ) throws IOException { final boolean ret ; if ( LOG . isDebugEnabled ( ) ) { LOG . debug ( ""==> RangerAuthorizationCoprocessor.preBalanceSwitch()"" ) ; } try { activatePluginClassLoader ( ) ; ret = implMasterObserver . preBalanceSwitch ( c , newValue ) ; } finally { deactivatePluginClassLoader ( ) ; } if ( LOG . isDebugEnabled ( ) ) { LOG . debug ( ""<== RangerAuthorizationCoprocessor.preBalanceSwitch()"" ) ; } return ret ; } @ Override public void preBulkLoadHFile ( ObserverContext < RegionCoprocessorEnvironment > ctx , List < Pair < byte [ ] , String > > familyPaths ) throws IOException { if ( LOG . isDebugEnabled ( ) ) { LOG . debug ( ""==> RangerAuthorizationCoprocessor.preBulkLoadHFile()"" ) ; } try { activatePluginClassLoader ( ) ; implRegionObserver . preBulkLoadHFile ( ctx , familyPaths ) ; } finally { deactivatePluginClassLoader ( ) ; } if ( LOG . isDebugEnabled ( ) ) { LOG . debug ( ""<== RangerAuthorizationCoprocessor.preBulkLoadHFile()"" ) ; } } @ Override public boolean preCheckAndDelete ( ObserverContext < RegionCoprocessorEnvironment > c , byte [ ] row , byte [ ] family , byte [ ] qualifier , CompareOp compareOp , ByteArrayComparable comparator , Delete delete , boolean result ) throws IOException { final boolean ret ; if ( LOG . isDebugEnabled ( ) ) { LOG . debug ( ""==> RangerAuthorizationCoprocessor.preCheckAndDelete()"" ) ; } try { activatePluginClassLoader ( ) ; ret = implRegionObserver . preCheckAndDelete ( c , row , family , qualifier , compareOp , comparator , delete , result ) ; } finally { deactivatePluginClassLoader ( ) ; } if ( LOG . isDebugEnabled ( ) ) { LOG . debug ( ""<== RangerAuthorizationCoprocessor.preCheckAndDelete()"" ) ; } return ret ; } @ Override public boolean preCheckAndPut ( ObserverContext < RegionCoprocessorEnvironment > c , byte [ ] row , byte [ ] family , byte [ ] qualifier , CompareOp compareOp , ByteArrayComparable comparator , Put put , boolean result ) throws IOException { final boolean ret ; if ( LOG . isDebugEnabled ( ) ) { LOG . debug ( ""==> RangerAuthorizationCoprocessor.preCheckAndPut()"" ) ; } try { activatePluginClassLoader ( ) ; ret = implRegionObserver . preCheckAndPut ( c , row , family , qualifier , compareOp , comparator , put , result ) ; } finally { deactivatePluginClassLoader ( ) ; } if ( LOG . isDebugEnabled ( ) ) { LOG . debug ( ""<== RangerAuthorizationCoprocessor.preCheckAndPut()"" ) ; } return ret ; } @ Override public void preCloneSnapshot ( ObserverContext < MasterCoprocessorEnvironment > ctx , SnapshotDescription snapshot , HTableDescriptor hTableDescriptor ) throws IOException { if ( LOG . isDebugEnabled ( ) ) { LOG . debug ( ""==> RangerAuthorizationCoprocessor.preCloneSnapshot()"" ) ; } try { activatePluginClassLoader ( ) ; implMasterObserver . preCloneSnapshot ( ctx , snapshot , hTableDescriptor ) ; } finally { deactivatePluginClassLoader ( ) ; } if ( LOG . isDebugEnabled ( ) ) { LOG . debug ( ""<== RangerAuthorizationCoprocessor.preCloneSnapshot()"" ) ; } } @ Override public void preClose ( ObserverContext < RegionCoprocessorEnvironment > e , boolean abortRequested ) throws IOException { if ( LOG . isDebugEnabled ( ) ) { LOG . debug ( ""==> RangerAuthorizationCoprocessor.preClose()"" ) ; } try { activatePluginClassLoader ( ) ; implRegionObserver . preClose ( e , abortRequested ) ; } finally { deactivatePluginClassLoader ( ) ; } if ( LOG . isDebugEnabled ( ) ) { LOG . debug ( ""<== RangerAuthorizationCoprocessor.preClose()"" ) ; } } @ Override public InternalScanner preCompact ( ObserverContext < RegionCoprocessorEnvironment > e , Store store , InternalScanner scanner , ScanType scanType ) throws IOException { final InternalScanner ret ; if ( LOG . isDebugEnabled ( ) ) { LOG . debug ( ""==> RangerAuthorizationCoprocessor.preCompact()"" ) ; } try { activatePluginClassLoader ( ) ; ret = implRegionObserver . preCompact ( e , store , scanner , scanType ) ; } finally { deactivatePluginClassLoader ( ) ; } if ( LOG . isDebugEnabled ( ) ) { LOG . debug ( ""<== RangerAuthorizationCoprocessor.preCompact()"" ) ; } return ret ; } @ Override public void preCompactSelection ( ObserverContext < RegionCoprocessorEnvironment > e , Store store , List < StoreFile > candidates ) throws IOException { if ( LOG . isDebugEnabled ( ) ) { LOG . debug ( ""==> RangerAuthorizationCoprocessor.preCompactSelection()"" ) ; } try { activatePluginClassLoader ( ) ; implRegionObserver . preCompactSelection ( e , store , candidates ) ; } finally { deactivatePluginClassLoader ( ) ; } if ( LOG . isDebugEnabled ( ) ) { LOG . debug ( ""<== RangerAuthorizationCoprocessor.preCompactSelection()"" ) ; } } @ Override public void preCreateTable ( ObserverContext < MasterCoprocessorEnvironment > c , HTableDescriptor desc , HRegionInfo [ ] regions ) throws IOException { if ( LOG . isDebugEnabled ( ) ) { LOG . debug ( ""==> RangerAuthorizationCoprocessor.preCreateTable()"" ) ; } try { activatePluginClassLoader ( ) ; implMasterObserver . preCreateTable ( c , desc , regions ) ; } finally { deactivatePluginClassLoader ( ) ; } if ( LOG . isDebugEnabled ( ) ) { LOG . debug ( ""<== RangerAuthorizationCoprocessor.preCreateTable()"" ) ; } } @ Override public void preDelete ( ObserverContext < RegionCoprocessorEnvironment > c , Delete delete , WALEdit edit , Durability durability ) throws IOException { if ( LOG . isDebugEnabled ( ) ) { LOG . debug ( ""==> RangerAuthorizationCoprocessor.preDelete()"" ) ; } try { activatePluginClassLoader ( ) ; implRegionObserver . preDelete ( c , delete , edit , durability ) ; } finally { deactivatePluginClassLoader ( ) ; } if ( LOG . isDebugEnabled ( ) ) { LOG . debug ( ""<== RangerAuthorizationCoprocessor.preDelete()"" ) ; } } @ Override public void preDeleteColumn ( ObserverContext < MasterCoprocessorEnvironment > c , TableName tableName , byte [ ] col ) throws IOException { if ( LOG . isDebugEnabled ( ) ) { LOG . debug ( ""==> RangerAuthorizationCoprocessor.preDeleteColumn()"" ) ; } try { activatePluginClassLoader ( ) ; implMasterObserver . preDeleteColumn ( c , tableName , col ) ; } finally { deactivatePluginClassLoader ( ) ; } if ( LOG . isDebugEnabled ( ) ) { LOG . debug ( ""<== RangerAuthorizationCoprocessor.preDeleteColumn()"" ) ; } } @ Override public void preDeleteSnapshot ( ObserverContext < MasterCoprocessorEnvironment > ctx , SnapshotDescription snapshot ) throws IOException { if ( LOG . isDebugEnabled ( ) ) { LOG . debug ( ""==> RangerAuthorizationCoprocessor.preDeleteSnapshot()"" ) ; } try { activatePluginClassLoader ( ) ; implMasterObserver . preDeleteSnapshot ( ctx , snapshot ) ; } finally { deactivatePluginClassLoader ( ) ; } if ( LOG . isDebugEnabled ( ) ) { LOG . debug ( ""<== RangerAuthorizationCoprocessor.preDeleteSnapshot()"" ) ; } } @ Override public void preDeleteTable ( ObserverContext < MasterCoprocessorEnvironment > c , TableName tableName ) throws IOException { if ( LOG . isDebugEnabled ( ) ) { LOG . debug ( ""==> RangerAuthorizationCoprocessor.preDeleteTable()"" ) ; } try { activatePluginClassLoader ( ) ; implMasterObserver . preDeleteTable ( c , tableName ) ; } finally { deactivatePluginClassLoader ( ) ; } if ( LOG . isDebugEnabled ( ) ) { LOG . debug ( ""<== RangerAuthorizationCoprocessor.preDeleteTable()"" ) ; } } @ Override public void preDisableTable ( ObserverContext < MasterCoprocessorEnvironment > c , TableName tableName ) throws IOException { if ( LOG . isDebugEnabled ( ) ) { LOG . debug ( ""==> RangerAuthorizationCoprocessor.preDisableTable()"" ) ; } try { activatePluginClassLoader ( ) ; implMasterObserver . preDisableTable ( c , tableName ) ; } finally { deactivatePluginClassLoader ( ) ; } if ( LOG . isDebugEnabled ( ) ) { LOG . debug ( ""<== RangerAuthorizationCoprocessor.preDisableTable()"" ) ; } } @ Override public void preEnableTable ( ObserverContext < MasterCoprocessorEnvironment > c , TableName tableName ) throws IOException { if ( LOG . isDebugEnabled ( ) ) { LOG . debug ( ""==> RangerAuthorizationCoprocessor.preEnableTable()"" ) ; } try { activatePluginClassLoader ( ) ; implMasterObserver . preEnableTable ( c , tableName ) ; } finally { deactivatePluginClassLoader ( ) ; } if ( LOG . isDebugEnabled ( ) ) { LOG . debug ( ""<== RangerAuthorizationCoprocessor.preEnableTable()"" ) ; } } @ Override public boolean preExists ( ObserverContext < RegionCoprocessorEnvironment > c , Get get , boolean exists ) throws IOException { final boolean ret ; if ( LOG . isDebugEnabled ( ) ) { LOG . debug ( ""==> RangerAuthorizationCoprocessor.preExists()"" ) ; } try { activatePluginClassLoader ( ) ; ret = implRegionObserver . preExists ( c , get , exists ) ; } finally { deactivatePluginClassLoader ( ) ; } if ( LOG . isDebugEnabled ( ) ) { LOG . debug ( ""<== RangerAuthorizationCoprocessor.preExists()"" ) ; } return ret ; } @ Override public void preFlush ( ObserverContext < RegionCoprocessorEnvironment > e ) throws IOException { if ( LOG . isDebugEnabled ( ) ) { LOG . debug ( ""==> RangerAuthorizationCoprocessor.preFlush()"" ) ; } try { activatePluginClassLoader ( ) ; implRegionObserver . preFlush ( e ) ; } finally { deactivatePluginClassLoader ( ) ; } if ( LOG . isDebugEnabled ( ) ) { LOG . debug ( ""<== RangerAuthorizationCoprocessor.preFlush()"" ) ; } } @ Override public void preGetClosestRowBefore ( ObserverContext < RegionCoprocessorEnvironment > c , byte [ ] row , byte [ ] family , Result result ) throws IOException { if ( LOG . isDebugEnabled ( ) ) { LOG . debug ( ""==> RangerAuthorizationCoprocessor.preGetClosestRowBefore()"" ) ; } try { activatePluginClassLoader ( ) ; implRegionObserver . preGetClosestRowBefore ( c , row , family , result ) ; } finally { deactivatePluginClassLoader ( ) ; } if ( LOG . isDebugEnabled ( ) ) { LOG . debug ( ""<== RangerAuthorizationCoprocessor.preGetClosestRowBefore()"" ) ; } } @ Override public Result preIncrement ( ObserverContext < RegionCoprocessorEnvironment > c , Increment increment ) throws IOException { final Result ret ; if ( LOG . isDebugEnabled ( ) ) { LOG . debug ( ""==> RangerAuthorizationCoprocessor.preIncrement()"" ) ; } try { activatePluginClassLoader ( ) ; ret = implRegionObserver . preIncrement ( c , increment ) ; } finally { deactivatePluginClassLoader ( ) ; } if ( LOG . isDebugEnabled ( ) ) { LOG . debug ( ""<== RangerAuthorizationCoprocessor.preIncrement()"" ) ; } return ret ; } @ Override public long preIncrementColumnValue ( ObserverContext < RegionCoprocessorEnvironment > c , byte [ ] row , byte [ ] family , byte [ ] qualifier , long amount , boolean writeToWAL ) throws IOException { final long ret ; if ( LOG . isDebugEnabled ( ) ) { LOG . debug ( ""==> RangerAuthorizationCoprocessor.preIncrementColumnValue()"" ) ; } try { activatePluginClassLoader ( ) ; ret = implRegionObserver . preIncrementColumnValue ( c , row , family , qualifier , amount , writeToWAL ) ; } finally { deactivatePluginClassLoader ( ) ; } if ( LOG . isDebugEnabled ( ) ) { LOG . debug ( ""<== RangerAuthorizationCoprocessor.preIncrementColumnValue()"" ) ; } return ret ; } @ Override public void preModifyColumn ( ObserverContext < MasterCoprocessorEnvironment > c , TableName tableName , HColumnDescriptor descriptor ) throws IOException { if ( LOG . isDebugEnabled ( ) ) { LOG . debug ( ""==> RangerAuthorizationCoprocessor.preModifyColumn()"" ) ; } try { activatePluginClassLoader ( ) ; implMasterObserver . preModifyColumn ( c , tableName , descriptor ) ; } finally { deactivatePluginClassLoader ( ) ; } if ( LOG . isDebugEnabled ( ) ) { LOG . debug ( ""<== RangerAuthorizationCoprocessor.preModifyColumn()"" ) ; } } @ Override public void preModifyTable ( ObserverContext < MasterCoprocessorEnvironment > c , TableName tableName , HTableDescriptor htd ) throws IOException { if ( LOG . isDebugEnabled ( ) ) { LOG . debug ( ""==> RangerAuthorizationCoprocessor.preModifyTable()"" ) ; } try { activatePluginClassLoader ( ) ; implMasterObserver . preModifyTable ( c , tableName , htd ) ; } finally { deactivatePluginClassLoader ( ) ; } if ( LOG . isDebugEnabled ( ) ) { LOG . debug ( ""<== RangerAuthorizationCoprocessor.preModifyTable()"" ) ; } } @ Override public void preMove ( ObserverContext < MasterCoprocessorEnvironment > c , HRegionInfo region , ServerName srcServer , ServerName destServer ) throws IOException { if ( LOG . isDebugEnabled ( ) ) { LOG . debug ( ""==> RangerAuthorizationCoprocessor.preMove()"" ) ; } try { activatePluginClassLoader ( ) ; implMasterObserver . preMove ( c , region , srcServer , destServer ) ; } finally { deactivatePluginClassLoader ( ) ; } if ( LOG . isDebugEnabled ( ) ) { LOG . debug ( ""<== RangerAuthorizationCoprocessor.preMove()"" ) ; } } @ Override public void preOpen ( ObserverContext < RegionCoprocessorEnvironment > e ) throws IOException { if ( LOG . isDebugEnabled ( ) ) { LOG . debug ( ""==> RangerAuthorizationCoprocessor.preOpen()"" ) ; } try { activatePluginClassLoader ( ) ; implRegionObserver . preOpen ( e ) ; } finally { deactivatePluginClassLoader ( ) ; } if ( LOG . isDebugEnabled ( ) ) { LOG . debug ( ""<== RangerAuthorizationCoprocessor.preOpen()"" ) ; } } @ Override public void preRestoreSnapshot ( ObserverContext < MasterCoprocessorEnvironment > ctx , SnapshotDescription snapshot , HTableDescriptor hTableDescriptor ) throws IOException { if ( LOG . isDebugEnabled ( ) ) { LOG . debug ( ""==> RangerAuthorizationCoprocessor.preRestoreSnapshot()"" ) ; } try { activatePluginClassLoader ( ) ; implMasterObserver . preRestoreSnapshot ( ctx , snapshot , hTableDescriptor ) ; } finally { deactivatePluginClassLoader ( ) ; } if ( LOG . isDebugEnabled ( ) ) { LOG . debug ( ""<== RangerAuthorizationCoprocessor.preRestoreSnapshot()"" ) ; } } @ Override public void preScannerClose ( ObserverContext < RegionCoprocessorEnvironment > c , InternalScanner s ) throws IOException { if ( LOG . isDebugEnabled ( ) ) { LOG . debug ( ""==> RangerAuthorizationCoprocessor.preScannerClose()"" ) ; } try { activatePluginClassLoader ( ) ; implRegionObserver . preScannerClose ( c , s ) ; } finally { deactivatePluginClassLoader ( ) ; } if ( LOG . isDebugEnabled ( ) ) { LOG . debug ( ""<== RangerAuthorizationCoprocessor.preScannerClose()"" ) ; } } @ Override public boolean preScannerNext ( ObserverContext < RegionCoprocessorEnvironment > c , InternalScanner s , List < Result > result , int limit , boolean hasNext ) throws IOException { final boolean ret ; if ( LOG . isDebugEnabled ( ) ) { LOG . debug ( ""==> RangerAuthorizationCoprocessor.preScannerNext()"" ) ; } try { activatePluginClassLoader ( ) ; ret = implRegionObserver . preScannerNext ( c , s , result , limit , hasNext ) ; } finally { deactivatePluginClassLoader ( ) ; } if ( LOG . isDebugEnabled ( ) ) { LOG . debug ( ""<== RangerAuthorizationCoprocessor.preScannerNext()"" ) ; } return ret ; } @ Override public RegionScanner preScannerOpen ( ObserverContext < RegionCoprocessorEnvironment > c , Scan scan , RegionScanner s ) throws IOException { final RegionScanner ret ; if ( LOG . isDebugEnabled ( ) ) { LOG . debug ( ""==> RangerAuthorizationCoprocessor.preScannerOpen()"" ) ; } try { activatePluginClassLoader ( ) ; ret = implRegionObserver . preScannerOpen ( c , scan , s ) ; } finally { deactivatePluginClassLoader ( ) ; } if ( LOG . isDebugEnabled ( ) ) { LOG . debug ( ""<== RangerAuthorizationCoprocessor.preScannerOpen()"" ) ; } return ret ; } @ Override public void preShutdown ( ObserverContext < MasterCoprocessorEnvironment > c ) throws IOException { if ( LOG . isDebugEnabled ( ) ) { LOG . debug ( ""==> RangerAuthorizationCoprocessor.preShutdown()"" ) ; } try { activatePluginClassLoader ( ) ; implMasterObserver . preShutdown ( c ) ; } finally { deactivatePluginClassLoader ( ) ; } if ( LOG . isDebugEnabled ( ) ) { LOG . debug ( ""<== RangerAuthorizationCoprocessor.preShutdown()"" ) ; } } @ Override public void preSnapshot ( ObserverContext < MasterCoprocessorEnvironment > ctx , SnapshotDescription snapshot , HTableDescriptor hTableDescriptor ) throws IOException { if ( LOG . isDebugEnabled ( ) ) { LOG . debug ( ""==> RangerAuthorizationCoprocessor.preSnapshot()"" ) ; } try { activatePluginClassLoader ( ) ; implMasterObserver . preSnapshot ( ctx , snapshot , hTableDescriptor ) ; } finally { deactivatePluginClassLoader ( ) ; } if ( LOG . isDebugEnabled ( ) ) { LOG . debug ( ""<== RangerAuthorizationCoprocessor.preSnapshot()"" ) ; } } @ Override public void preSplit ( ObserverContext < RegionCoprocessorEnvironment > e ) throws IOException { if ( LOG . isDebugEnabled ( ) ) { LOG . debug ( ""==> RangerAuthorizationCoprocessor.preSplit()"" ) ; } try { activatePluginClassLoader ( ) ; implRegionObserver . preSplit ( e ) ; } finally { deactivatePluginClassLoader ( ) ; } if ( LOG . isDebugEnabled ( ) ) { LOG . debug ( ""<== RangerAuthorizationCoprocessor.preSplit()"" ) ; } } @ Override public void preStopMaster ( ObserverContext < MasterCoprocessorEnvironment > c ) throws IOException { if ( LOG . isDebugEnabled ( ) ) { LOG . debug ( ""==> RangerAuthorizationCoprocessor.preStopMaster()"" ) ; } try { activatePluginClassLoader ( ) ; implMasterObserver . preStopMaster ( c ) ; } finally { deactivatePluginClassLoader ( ) ; } if ( LOG . isDebugEnabled ( ) ) { LOG . debug ( ""<== RangerAuthorizationCoprocessor.preStopMaster()"" ) ; } } @ Override public void preStopRegionServer ( ObserverContext < RegionServerCoprocessorEnvironment > env ) throws IOException { if ( LOG . isDebugEnabled ( ) ) { LOG . debug ( ""==> RangerAuthorizationCoprocessor.preStopRegionServer()"" ) ; } try { activatePluginClassLoader ( ) ; implRegionServerObserver . preStopRegionServer ( env ) ; } finally { deactivatePluginClassLoader ( ) ; } if ( LOG . isDebugEnabled ( ) ) { LOG . debug ( ""<== RangerAuthorizationCoprocessor.preStopRegionServer()"" ) ; } } @ Override public void preUnassign ( ObserverContext < MasterCoprocessorEnvironment > c , HRegionInfo regionInfo , boolean force ) throws IOException { if ( LOG . isDebugEnabled ( ) ) { LOG . debug ( ""==> RangerAuthorizationCoprocessor.preUnassign()"" ) ; } try { activatePluginClassLoader ( ) ; implMasterObserver . preUnassign ( c , regionInfo , force ) ; } finally { deactivatePluginClassLoader ( ) ; } if ( LOG . isDebugEnabled ( ) ) { LOG . debug ( ""<== RangerAuthorizationCoprocessor.preUnassign()"" ) ; } } @ Override public void preSetUserQuota ( ObserverContext < MasterCoprocessorEnvironment > ctx , String userName , Quotas quotas ) throws IOException { if ( LOG . isDebugEnabled ( ) ) { LOG . debug ( ""==> RangerAuthorizationCoprocessor.preSetUserQuota()"" ) ; } try { activatePluginClassLoader ( ) ; implMasterObserver . preSetUserQuota ( ctx , userName , quotas ) ; } finally { deactivatePluginClassLoader ( ) ; } if ( LOG . isDebugEnabled ( ) ) { LOG . debug ( ""<== RangerAuthorizationCoprocessor.preSetUserQuota()"" ) ; } } @ Override public void preSetUserQuota ( ObserverContext < MasterCoprocessorEnvironment > ctx , String userName , TableName tableName , Quotas quotas ) throws IOException { if ( LOG . isDebugEnabled ( ) ) { LOG . debug ( ""==> RangerAuthorizationCoprocessor.preSetUserQuota()"" ) ; } try { activatePluginClassLoader ( ) ; implMasterObserver . preSetUserQuota ( ctx , userName , tableName , quotas ) ; } finally { deactivatePluginClassLoader ( ) ; } if ( LOG . isDebugEnabled ( ) ) { LOG . debug ( ""<== RangerAuthorizationCoprocessor.preSetUserQuota()"" ) ; } } @ Override public void preSetUserQuota ( ObserverContext < MasterCoprocessorEnvironment > ctx , String userName , String namespace , Quotas quotas ) throws IOException { if ( LOG . isDebugEnabled ( ) ) { LOG . debug ( ""==> RangerAuthorizationCoprocessor.preSetUserQuota()"" ) ; } try { activatePluginClassLoader ( ) ; implMasterObserver . preSetUserQuota ( ctx , userName , namespace , quotas ) ; } finally { deactivatePluginClassLoader ( ) ; } if ( LOG . isDebugEnabled ( ) ) { LOG . debug ( ""<== RangerAuthorizationCoprocessor.preSetUserQuota()"" ) ; } } @ Override public void preSetTableQuota ( ObserverContext < MasterCoprocessorEnvironment > ctx , TableName tableName , Quotas quotas ) throws IOException { if ( LOG . isDebugEnabled ( ) ) { LOG . debug ( ""==> RangerAuthorizationCoprocessor.preSetTableQuota()"" ) ; } try { activatePluginClassLoader ( ) ; implMasterObserver . preSetTableQuota ( ctx , tableName , quotas ) ; } finally { deactivatePluginClassLoader ( ) ; } if ( LOG . isDebugEnabled ( ) ) { LOG . debug ( ""<== RangerAuthorizationCoprocessor.preSetTableQuota()"" ) ; } } @ Override public void preSetNamespaceQuota ( ObserverContext < MasterCoprocessorEnvironment > ctx , String namespace , Quotas quotas ) throws IOException { if ( LOG . isDebugEnabled ( ) ) { LOG . debug ( ""==> RangerAuthorizationCoprocessor.preSetNamespaceQuota()"" ) ; } try { activatePluginClassLoader ( ) ; implMasterObserver . preSetNamespaceQuota ( ctx , namespace , quotas ) ; } finally { deactivatePluginClassLoader ( ) ; } if ( LOG . isDebugEnabled ( ) ) { LOG . debug ( ""<== RangerAuthorizationCoprocessor.preSetNamespaceQuota()"" ) ; } } @ Override public void start ( CoprocessorEnvironment env ) throws IOException { if ( LOG . isDebugEnabled ( ) ) { LOG . debug ( ""==> RangerAuthorizationCoprocessor.start()"" ) ; } try { activatePluginClassLoader ( ) ; implMasterObserver . start ( env ) ; } finally { deactivatePluginClassLoader ( ) ; } if ( LOG . isDebugEnabled ( ) ) { LOG . debug ( ""<== RangerAuthorizationCoprocessor.start()"" ) ; } } @ Override public void prePut ( ObserverContext < RegionCoprocessorEnvironment > c , Put put , WALEdit edit , Durability durability ) throws IOException { if ( LOG . isDebugEnabled ( ) ) { LOG . debug ( ""==> RangerAuthorizationCoprocessor.prePut()"" ) ; } try { activatePluginClassLoader ( ) ; implRegionObserver . prePut ( c , put , edit , durability ) ; } finally { deactivatePluginClassLoader ( ) ; } if ( LOG . isDebugEnabled ( ) ) { LOG . debug ( ""<== RangerAuthorizationCoprocessor.prePut()"" ) ; } } @ Override public void preGetOp ( ObserverContext < RegionCoprocessorEnvironment > rEnv , Get get , List < Cell > result ) throws IOException { if ( LOG . isDebugEnabled ( ) ) { LOG . debug ( ""==> RangerAuthorizationCoprocessor.preGetOp()"" ) ; } try { activatePluginClassLoader ( ) ; implRegionObserver . preGetOp ( rEnv , get , result ) ; } finally { deactivatePluginClassLoader ( ) ; } if ( LOG . isDebugEnabled ( ) ) { LOG . debug ( ""<== RangerAuthorizationCoprocessor.preGetOp()"" ) ; } } @ Override public void preRegionOffline ( ObserverContext < MasterCoprocessorEnvironment > c , HRegionInfo regionInfo ) throws IOException { if ( LOG . isDebugEnabled ( ) ) { LOG . debug ( ""==> RangerAuthorizationCoprocessor.preRegionOffline()"" ) ; } try { activatePluginClassLoader ( ) ; implMasterObserver . preRegionOffline ( c , regionInfo ) ; } finally { deactivatePluginClassLoader ( ) ; } if ( LOG . isDebugEnabled ( ) ) { LOG . debug ( ""<== RangerAuthorizationCoprocessor.preRegionOffline()"" ) ; } } @ Override public void preCreateNamespace ( ObserverContext < MasterCoprocessorEnvironment > ctx , NamespaceDescriptor ns ) throws IOException { if ( LOG . isDebugEnabled ( ) ) { LOG . debug ( ""==> RangerAuthorizationCoprocessor.preCreateNamespace()"" ) ; } try { activatePluginClassLoader ( ) ; implMasterObserver . preCreateNamespace ( ctx , ns ) ; } finally { deactivatePluginClassLoader ( ) ; } if ( LOG . isDebugEnabled ( ) ) { LOG . debug ( ""<== RangerAuthorizationCoprocessor.preCreateNamespace()"" ) ; } } @ Override public void preDeleteNamespace ( ObserverContext < MasterCoprocessorEnvironment > ctx , String namespace ) throws IOException { if ( LOG . isDebugEnabled ( ) ) { LOG . debug ( ""==> RangerAuthorizationCoprocessor.preDeleteNamespace()"" ) ; } try { activatePluginClassLoader ( ) ; implMasterObserver . preDeleteNamespace ( ctx , namespace ) ; } finally { deactivatePluginClassLoader ( ) ; } if ( LOG . isDebugEnabled ( ) ) { LOG . debug ( ""<== RangerAuthorizationCoprocessor.preDeleteNamespace()"" ) ; } } @ Override public void preModifyNamespace ( ObserverContext < MasterCoprocessorEnvironment > ctx , NamespaceDescriptor ns ) throws IOException { if ( LOG . isDebugEnabled ( ) ) { LOG . debug ( ""==> RangerAuthorizationCoprocessor.preModifyNamespace()"" ) ; } try { activatePluginClassLoader ( ) ; implMasterObserver . preModifyNamespace ( ctx , ns ) ; } finally { deactivatePluginClassLoader ( ) ; } if ( LOG . isDebugEnabled ( ) ) { LOG . debug ( ""<== RangerAuthorizationCoprocessor.preModifyNamespace()"" ) ; } } @ Override public void postGetTableDescriptors ( ObserverContext < MasterCoprocessorEnvironment > ctx , List < TableName > tableNamesList , List < HTableDescriptor > descriptors , String regex ) throws IOException { if ( LOG . isDebugEnabled ( ) ) { LOG . debug ( ""==> RangerAuthorizationCoprocessor.postGetTableDescriptors()"" ) ; } try { activatePluginClassLoader ( ) ; implMasterObserver . postGetTableDescriptors ( ctx , tableNamesList , descriptors , regex ) ; } finally { deactivatePluginClassLoader ( ) ; } if ( LOG . isDebugEnabled ( ) ) { LOG . debug ( ""<== RangerAuthorizationCoprocessor.postGetTableDescriptors()"" ) ; } } @ Override public void preMerge ( ObserverContext < RegionServerCoprocessorEnvironment > ctx , Region regionA , Region regionB ) throws IOException { if ( LOG . isDebugEnabled ( ) ) { LOG . debug ( ""==> RangerAuthorizationCoprocessor.preMerge()"" ) ; } try { activatePluginClassLoader ( ) ; implRegionServerObserver . preMerge ( ctx , regionA , regionB ) ; } finally { deactivatePluginClassLoader ( ) ; } if ( LOG . isDebugEnabled ( ) ) { LOG . debug ( ""<== RangerAuthorizationCoprocessor.preMerge()"" ) ; } } @ Override public void prePrepareBulkLoad ( ObserverContext < RegionCoprocessorEnvironment > ctx , PrepareBulkLoadRequest request ) throws IOException { if ( LOG . isDebugEnabled ( ) ) { LOG . debug ( ""==> RangerAuthorizationCoprocessor.prePrepareBulkLoad()"" ) ; } try { activatePluginClassLoader ( ) ; implBulkLoadObserver . prePrepareBulkLoad ( ctx , request ) ; } finally { deactivatePluginClassLoader ( ) ; } if ( LOG . isDebugEnabled ( ) ) { LOG . debug ( ""<== RangerAuthorizationCoprocessor.prePrepareBulkLoad()"" ) ; } } @ Override public void preCleanupBulkLoad ( ObserverContext < RegionCoprocessorEnvironment > ctx , CleanupBulkLoadRequest request ) throws IOException { if ( LOG . isDebugEnabled ( ) ) { LOG . debug ( ""==> RangerAuthorizationCoprocessor.preCleanupBulkLoad()"" ) ; } try { activatePluginClassLoader ( ) ; implBulkLoadObserver . preCleanupBulkLoad ( ctx , request ) ; } finally { deactivatePluginClassLoader ( ) ; } if ( LOG . isDebugEnabled ( ) ) { LOG . debug ( ""<== RangerAuthorizationCoprocessor.preCleanupBulkLoad()"" ) ; } } @ Override public void grant ( RpcController controller , GrantRequest request , RpcCallback < GrantResponse > done ) { if ( LOG . isDebugEnabled ( ) ) { LOG . debug ( ""==> RangerAuthorizationCoprocessor.grant()"" ) ; } try { activatePluginClassLoader ( ) ; implAccessControlService . grant ( controller , request , done ) ; } finally { deactivatePluginClassLoader ( ) ; } if ( LOG . isDebugEnabled ( ) ) { LOG . debug ( ""<== RangerAuthorizationCoprocessor.grant()"" ) ; } } @ Override public void revoke ( RpcController controller , RevokeRequest request , RpcCallback < RevokeResponse > done ) { if ( LOG . isDebugEnabled ( ) ) { LOG . debug ( ""==> RangerAuthorizationCoprocessor.revoke()"" ) ; } try { activatePluginClassLoader ( ) ; implAccessControlService . revoke ( controller , request , done ) ; } finally { deactivatePluginClassLoader ( ) ; } if ( LOG . isDebugEnabled ( ) ) { LOG . debug ( ""<== RangerAuthorizationCoprocessor.revoke()"" ) ; } } @ Override public void checkPermissions ( RpcController controller , CheckPermissionsRequest request , RpcCallback < CheckPermissionsResponse > done ) { if ( LOG . isDebugEnabled ( ) ) { LOG . debug ( ""==> RangerAuthorizationCoprocessor.checkPermissions()"" ) ; } try { activatePluginClassLoader ( ) ; implAccessControlService . checkPermissions ( controller , request , done ) ; } finally { deactivatePluginClassLoader ( ) ; } if ( LOG . isDebugEnabled ( ) ) { LOG . debug ( ""<== RangerAuthorizationCoprocessor.checkPermissions()"" ) ; } } @ Override public void getUserPermissions ( RpcController controller , GetUserPermissionsRequest request , RpcCallback < GetUserPermissionsResponse > done ) { if ( LOG . isDebugEnabled ( ) ) { LOG . debug ( ""==> RangerAuthorizationCoprocessor.getUserPermissions()"" ) ; } try { activatePluginClassLoader ( ) ; implAccessControlService . getUserPermissions ( controller , request , done ) ; } finally { deactivatePluginClassLoader ( ) ; } if ( LOG . isDebugEnabled ( ) ) { LOG . debug ( ""<== RangerAuthorizationCoprocessor.getUserPermissions()"" ) ; } } @ Override public void stop ( CoprocessorEnvironment env ) throws IOException { if ( LOG . isDebugEnabled ( ) ) { LOG . debug ( ""==> RangerAuthorizationCoprocessor.stop()"" ) ; } try { activatePluginClassLoader ( ) ; implMasterObserver . stop ( env ) ; } finally { deactivatePluginClassLoader ( ) ; } if ( LOG . isDebugEnabled ( ) ) { LOG . debug ( ""<== RangerAuthorizationCoprocessor.stop()"" ) ; } } @ Override public void postMerge ( ObserverContext < RegionServerCoprocessorEnvironment > c , Region regionA , Region regionB , Region mergedRegion ) throws IOException { if ( LOG . isDebugEnabled ( ) ) { LOG . debug ( ""==> RangerAuthorizationCoprocessor.postMerge()"" ) ; } try { activatePluginClassLoader ( ) ; implRegionServerObserver . postMerge ( c , regionA , regionB , mergedRegion ) ; } finally { deactivatePluginClassLoader ( ) ; } if ( LOG . isDebugEnabled ( ) ) { LOG . debug ( ""<== RangerAuthorizationCoprocessor.postMerge()"" ) ; } } @ Override public void preMergeCommit ( ObserverContext < RegionServerCoprocessorEnvironment > ctx , Region regionA , Region regionB , List < Mutation > metaEntries ) throws IOException { if ( LOG . isDebugEnabled ( ) ) { LOG . debug ( ""==> RangerAuthorizationCoprocessor.preMergeCommit()"" ) ; } try { activatePluginClassLoader ( ) ; implRegionServerObserver . preMergeCommit ( ctx , regionA , regionB , metaEntries ) ; } finally { deactivatePluginClassLoader ( ) ; } if ( LOG . isDebugEnabled ( ) ) { LOG . debug ( ""<== RangerAuthorizationCoprocessor.preMergeCommit()"" ) ; } } @ Override public void postMergeCommit ( ObserverContext < RegionServerCoprocessorEnvironment > ctx , Region regionA , Region regionB , Region mergedRegion ) throws IOException { if ( LOG . isDebugEnabled ( ) ) { LOG . debug ( ""==> RangerAuthorizationCoprocessor.postMergeCommit()"" ) ; } try { activatePluginClassLoader ( ) ; implRegionServerObserver . postMergeCommit ( ctx , regionA , regionB , mergedRegion ) ; } finally { deactivatePluginClassLoader ( ) ; } if ( LOG . isDebugEnabled ( ) ) { LOG . debug ( ""<== RangerAuthorizationCoprocessor.postMergeCommit()"" ) ; } } @ Override public void preRollBackMerge ( ObserverContext < RegionServerCoprocessorEnvironment > ctx , Region regionA , Region regionB ) throws IOException { if ( LOG . isDebugEnabled ( ) ) { LOG . debug ( ""==> RangerAuthorizationCoprocessor.preRollBackMerge()"" ) ; } try { activatePluginClassLoader ( ) ; implRegionServerObserver . preRollBackMerge ( ctx , regionA , regionB ) ; } finally { deactivatePluginClassLoader ( ) ; } if ( LOG . isDebugEnabled ( ) ) { LOG . debug ( ""<== RangerAuthorizationCoprocessor.preRollBackMerge()"" ) ; } } @ Override public void postRollBackMerge ( ObserverContext < RegionServerCoprocessorEnvironment > ctx , Region regionA , Region regionB ) throws IOException { if ( LOG . isDebugEnabled ( ) ) { LOG . debug ( ""==> RangerAuthorizationCoprocessor.postRollBackMerge()"" ) ; } try { activatePluginClassLoader ( ) ; implRegionServerObserver . postRollBackMerge ( ctx , regionA , regionB ) ; } finally { deactivatePluginClassLoader ( ) ; } if ( LOG . isDebugEnabled ( ) ) { LOG . debug ( ""<== RangerAuthorizationCoprocessor.postRollBackMerge()"" ) ; } } @ Override public void preRollWALWriterRequest ( ObserverContext < RegionServerCoprocessorEnvironment > ctx ) throws IOException { if ( LOG . isDebugEnabled ( ) ) { LOG . debug ( ""==> RangerAuthorizationCoprocessor.preRollWALWriterRequest()"" ) ; } try { activatePluginClassLoader ( ) ; implRegionServerObserver . preRollWALWriterRequest ( ctx ) ; } finally { deactivatePluginClassLoader ( ) ; } if ( LOG . isDebugEnabled ( ) ) { LOG . debug ( ""<== RangerAuthorizationCoprocessor.preRollWALWriterRequest()"" ) ; } } @ Override public void postRollWALWriterRequest ( ObserverContext < RegionServerCoprocessorEnvironment > ctx ) throws IOException { if ( LOG . isDebugEnabled ( ) ) { LOG . debug ( ""==> RangerAuthorizationCoprocessor.postRollWALWriterRequest()"" ) ; } try { activatePluginClassLoader ( ) ; implRegionServerObserver . postRollWALWriterRequest ( ctx ) ; } finally { deactivatePluginClassLoader ( ) ; } if ( LOG . isDebugEnabled ( ) ) { LOG . debug ( ""<== RangerAuthorizationCoprocessor.postRollWALWriterRequest()"" ) ; } } @ Override public ReplicationEndpoint postCreateReplicationEndPoint ( ObserverContext < RegionServerCoprocessorEnvironment > ctx , ReplicationEndpoint endpoint ) { final ReplicationEndpoint ret ; if ( LOG . isDebugEnabled ( ) ) { LOG . debug ( ""==> RangerAuthorizationCoprocessor.postCreateReplicationEndPoint()"" ) ; } try { activatePluginClassLoader ( ) ; ret = implRegionServerObserver . postCreateReplicationEndPoint ( ctx , endpoint ) ; } finally { deactivatePluginClassLoader ( ) ; } if ( LOG . isDebugEnabled ( ) ) { LOG . debug ( ""<== RangerAuthorizationCoprocessor.postCreateReplicationEndPoint()"" ) ; } return ret ; } @ Override public void preReplicateLogEntries ( ObserverContext < RegionServerCoprocessorEnvironment > ctx , List < WALEntry > entries , CellScanner cells ) throws IOException { if ( LOG . isDebugEnabled ( ) ) { LOG . debug ( ""==> RangerAuthorizationCoprocessor.preReplicateLogEntries()"" ) ; } try { activatePluginClassLoader ( ) ; implRegionServerObserver . preReplicateLogEntries ( ctx , entries , cells ) ; } finally { deactivatePluginClassLoader ( ) ; } if ( LOG . isDebugEnabled ( ) ) { LOG . debug ( ""<== RangerAuthorizationCoprocessor.preReplicateLogEntries()"" ) ; } } @ Override public void postReplicateLogEntries ( ObserverContext < RegionServerCoprocessorEnvironment > ctx , List < WALEntry > entries , CellScanner cells ) throws IOException { if ( LOG . isDebugEnabled ( ) ) { LOG . debug ( ""==> RangerAuthorizationCoprocessor.postReplicateLogEntries()"" ) ; } try { activatePluginClassLoader ( ) ; implRegionServerObserver . postReplicateLogEntries ( ctx , entries , cells ) ; } finally { deactivatePluginClassLoader ( ) ; } if ( LOG . isDebugEnabled ( ) ) { LOG . debug ( ""<== RangerAuthorizationCoprocessor.postReplicateLogEntries()"" ) ; } } @ Override public void postOpen ( ObserverContext < RegionCoprocessorEnvironment > c ) { if ( LOG . isDebugEnabled ( ) ) { LOG . debug ( ""==> RangerAuthorizationCoprocessor.postOpen()"" ) ; } try { activatePluginClassLoader ( ) ; implRegionObserver . postOpen ( c ) ; } finally { deactivatePluginClassLoader ( ) ; } if ( LOG . isDebugEnabled ( ) ) { LOG . debug ( ""<== RangerAuthorizationCoprocessor.postOpen()"" ) ; } } @ Override public void postLogReplay ( ObserverContext < RegionCoprocessorEnvironment > c ) { if ( LOG . isDebugEnabled ( ) ) { LOG . debug ( ""==> RangerAuthorizationCoprocessor.postLogReplay()"" ) ; } try { activatePluginClassLoader ( ) ; implRegionObserver . postLogReplay ( c ) ; } finally { deactivatePluginClassLoader ( ) ; } if ( LOG . isDebugEnabled ( ) ) { LOG . debug ( ""<== RangerAuthorizationCoprocessor.postLogReplay()"" ) ; } } @ Override public InternalScanner preFlushScannerOpen ( ObserverContext < RegionCoprocessorEnvironment > c , Store store , KeyValueScanner memstoreScanner , InternalScanner s ) throws IOException { final InternalScanner ret ; if ( LOG . isDebugEnabled ( ) ) { LOG . debug ( ""==> RangerAuthorizationCoprocessor.preFlushScannerOpen()"" ) ; } try { activatePluginClassLoader ( ) ; ret = implRegionObserver . preFlushScannerOpen ( c , store , memstoreScanner , s ) ; } finally { deactivatePluginClassLoader ( ) ; } if ( LOG . isDebugEnabled ( ) ) { LOG . debug ( ""<== RangerAuthorizationCoprocessor.preFlushScannerOpen()"" ) ; } return ret ; } @ Override public InternalScanner preFlush ( ObserverContext < RegionCoprocessorEnvironment > c , Store store , InternalScanner scanner ) throws IOException { final InternalScanner ret ; if ( LOG . isDebugEnabled ( ) ) { LOG . debug ( ""==> RangerAuthorizationCoprocessor.preFlush()"" ) ; } try { activatePluginClassLoader ( ) ; ret = implRegionObserver . preFlush ( c , store , scanner ) ; } finally { deactivatePluginClassLoader ( ) ; } if ( LOG . isDebugEnabled ( ) ) { LOG . debug ( ""<== RangerAuthorizationCoprocessor.preFlush()"" ) ; } return ret ; } @ Override public void postFlush ( ObserverContext < RegionCoprocessorEnvironment > c ) throws IOException { if ( LOG . isDebugEnabled ( ) ) { LOG . debug ( ""==> RangerAuthorizationCoprocessor.postFlush()"" ) ; } try { activatePluginClassLoader ( ) ; implRegionObserver . postFlush ( c ) ; } finally { deactivatePluginClassLoader ( ) ; } if ( LOG . isDebugEnabled ( ) ) { LOG . debug ( ""<== RangerAuthorizationCoprocessor.postFlush()"" ) ; } } @ Override public void postFlush ( ObserverContext < RegionCoprocessorEnvironment > c , Store store , StoreFile resultFile ) throws IOException { if ( LOG . isDebugEnabled ( ) ) { LOG . debug ( ""==> RangerAuthorizationCoprocessor.postFlush()"" ) ; } try { activatePluginClassLoader ( ) ; implRegionObserver . postFlush ( c , store , resultFile ) ; } finally { deactivatePluginClassLoader ( ) ; } if ( LOG . isDebugEnabled ( ) ) { LOG . debug ( ""<== RangerAuthorizationCoprocessor.postFlush()"" ) ; } } @ Override public void preCompactSelection ( ObserverContext < RegionCoprocessorEnvironment > c , Store store , List < StoreFile > candidates , CompactionRequest request ) throws IOException { if ( LOG . isDebugEnabled ( ) ) { LOG . debug ( ""==> RangerAuthorizationCoprocessor.preCompactSelection()"" ) ; } try { activatePluginClassLoader ( ) ; implRegionObserver . preCompactSelection ( c , store , candidates , request ) ; } finally { deactivatePluginClassLoader ( ) ; } if ( LOG . isDebugEnabled ( ) ) { LOG . debug ( ""<== RangerAuthorizationCoprocessor.preCompactSelection()"" ) ; } } @ Override public void postCompactSelection ( ObserverContext < RegionCoprocessorEnvironment > c , Store store , ImmutableList < StoreFile > selected , CompactionRequest request ) { if ( LOG . isDebugEnabled ( ) ) { LOG . debug ( ""==> RangerAuthorizationCoprocessor.postCompactSelection()"" ) ; } try { activatePluginClassLoader ( ) ; implRegionObserver . postCompactSelection ( c , store , selected , request ) ; } finally { deactivatePluginClassLoader ( ) ; } if ( LOG . isDebugEnabled ( ) ) { LOG . debug ( ""<== RangerAuthorizationCoprocessor.postCompactSelection()"" ) ; } } @ Override public void postCompactSelection ( ObserverContext < RegionCoprocessorEnvironment > c , Store store , ImmutableList < StoreFile > selected ) { if ( LOG . isDebugEnabled ( ) ) { LOG . debug ( ""==> RangerAuthorizationCoprocessor.postCompactSelection()"" ) ; } try { activatePluginClassLoader ( ) ; implRegionObserver . postCompactSelection ( c , store , selected ) ; } finally { deactivatePluginClassLoader ( ) ; } if ( LOG . isDebugEnabled ( ) ) { LOG . debug ( ""<== RangerAuthorizationCoprocessor.postCompactSelection()"" ) ; } } @ Override public InternalScanner preCompact ( ObserverContext < RegionCoprocessorEnvironment > c , Store store , InternalScanner scanner , ScanType scanType , CompactionRequest request ) throws IOException { final InternalScanner ret ; if ( LOG . isDebugEnabled ( ) ) { LOG . debug ( ""==> RangerAuthorizationCoprocessor.preCompact()"" ) ; } try { activatePluginClassLoader ( ) ; ret = implRegionObserver . preCompact ( c , store , scanner , scanType , request ) ; } finally { deactivatePluginClassLoader ( ) ; } if ( LOG . isDebugEnabled ( ) ) { LOG . debug ( ""<== RangerAuthorizationCoprocessor.preCompact()"" ) ; } return ret ; } @ Override public InternalScanner preCompactScannerOpen ( ObserverContext < RegionCoprocessorEnvironment > c , Store store , List < ? extends KeyValueScanner > scanners , ScanType scanType , long earliestPutTs , InternalScanner s , CompactionRequest request ) throws IOException { final InternalScanner ret ; if ( LOG . isDebugEnabled ( ) ) { LOG . debug ( ""==> RangerAuthorizationCoprocessor.preCompactScannerOpen()"" ) ; } try { activatePluginClassLoader ( ) ; ret = implRegionObserver . preCompactScannerOpen ( c , store , scanners , scanType , earliestPutTs , s , request ) ; } finally { deactivatePluginClassLoader ( ) ; } if ( LOG . isDebugEnabled ( ) ) { LOG . debug ( ""<== RangerAuthorizationCoprocessor.preCompactScannerOpen()"" ) ; } return ret ; } @ Override public InternalScanner preCompactScannerOpen ( ObserverContext < RegionCoprocessorEnvironment > c , Store store , List < ? extends KeyValueScanner > scanners , ScanType scanType , long earliestPutTs , InternalScanner s ) throws IOException { final InternalScanner ret ; if ( LOG . isDebugEnabled ( ) ) { LOG . debug ( ""==> RangerAuthorizationCoprocessor.preCompactScannerOpen()"" ) ; } try { activatePluginClassLoader ( ) ; ret = implRegionObserver . preCompactScannerOpen ( c , store , scanners , scanType , earliestPutTs , s ) ; } finally { deactivatePluginClassLoader ( ) ; } if ( LOG . isDebugEnabled ( ) ) { LOG . debug ( ""<== RangerAuthorizationCoprocessor.preCompactScannerOpen()"" ) ; } return ret ; } @ Override public void postCompact ( ObserverContext < RegionCoprocessorEnvironment > c , Store store , StoreFile resultFile , CompactionRequest request ) throws IOException { if ( LOG . isDebugEnabled ( ) ) { LOG . debug ( ""==> RangerAuthorizationCoprocessor.postCompact()"" ) ; } try { activatePluginClassLoader ( ) ; implRegionObserver . postCompact ( c , store , resultFile , request ) ; } finally { deactivatePluginClassLoader ( ) ; } if ( LOG . isDebugEnabled ( ) ) { LOG . debug ( ""<== RangerAuthorizationCoprocessor.postCompact()"" ) ; } } @ Override public void postCompact ( ObserverContext < RegionCoprocessorEnvironment > c , Store store , StoreFile resultFile ) throws IOException { if ( LOG . isDebugEnabled ( ) ) { LOG . debug ( ""==> RangerAuthorizationCoprocessor.postCompact()"" ) ; } try { activatePluginClassLoader ( ) ; implRegionObserver . postCompact ( c , store , resultFile ) ; } finally { deactivatePluginClassLoader ( ) ; } if ( LOG . isDebugEnabled ( ) ) { LOG . debug ( ""<== RangerAuthorizationCoprocessor.postCompact()"" ) ; } } @ Override public void preSplit ( ObserverContext < RegionCoprocessorEnvironment > c , byte [ ] splitRow ) throws IOException { if ( LOG . isDebugEnabled ( ) ) { LOG . debug ( ""==> RangerAuthorizationCoprocessor.preSplit()"" ) ; } try { activatePluginClassLoader ( ) ; implRegionObserver . preSplit ( c , splitRow ) ; } finally { deactivatePluginClassLoader ( ) ; } if ( LOG . isDebugEnabled ( ) ) { LOG . debug ( ""<== RangerAuthorizationCoprocessor.preSplit()"" ) ; } } @ Override public void postSplit ( ObserverContext < RegionCoprocessorEnvironment > c , Region l , Region r ) throws IOException { if ( LOG . isDebugEnabled ( ) ) { LOG . debug ( ""==> RangerAuthorizationCoprocessor.postSplit()"" ) ; } try { activatePluginClassLoader ( ) ; implRegionObserver . postSplit ( c , l , r ) ; } finally { deactivatePluginClassLoader ( ) ; } if ( LOG . isDebugEnabled ( ) ) { LOG . debug ( ""<== RangerAuthorizationCoprocessor.postSplit()"" ) ; } } @ Override public void preSplitBeforePONR ( ObserverContext < RegionCoprocessorEnvironment > ctx , byte [ ] splitKey , List < Mutation > metaEntries ) throws IOException { if ( LOG . isDebugEnabled ( ) ) { LOG . debug ( ""==> RangerAuthorizationCoprocessor.preSplitBeforePONR()"" ) ; } try { activatePluginClassLoader ( ) ; implRegionObserver . preSplitBeforePONR ( ctx , splitKey , metaEntries ) ; } finally { deactivatePluginClassLoader ( ) ; } if ( LOG . isDebugEnabled ( ) ) { LOG . debug ( ""<== RangerAuthorizationCoprocessor.preSplitBeforePONR()"" ) ; } } @ Override public void preSplitAfterPONR ( ObserverContext < RegionCoprocessorEnvironment > ctx ) throws IOException { if ( LOG . isDebugEnabled ( ) ) { LOG . debug ( ""==> RangerAuthorizationCoprocessor.preSplitAfterPONR()"" ) ; } try { activatePluginClassLoader ( ) ; implRegionObserver . preSplitAfterPONR ( ctx ) ; } finally { deactivatePluginClassLoader ( ) ; } if ( LOG . isDebugEnabled ( ) ) { LOG . debug ( ""<== RangerAuthorizationCoprocessor.preSplitAfterPONR()"" ) ; } } @ Override public void preRollBackSplit ( ObserverContext < RegionCoprocessorEnvironment > ctx ) throws IOException { if ( LOG . isDebugEnabled ( ) ) { LOG . debug ( ""==> RangerAuthorizationCoprocessor.preRollBackSplit()"" ) ; } try { activatePluginClassLoader ( ) ; implRegionObserver . preRollBackSplit ( ctx ) ; } finally { deactivatePluginClassLoader ( ) ; } if ( LOG . isDebugEnabled ( ) ) { LOG . debug ( ""<== RangerAuthorizationCoprocessor.preRollBackSplit()"" ) ; } } @ Override public void postRollBackSplit ( ObserverContext < RegionCoprocessorEnvironment > ctx ) throws IOException { if ( LOG . isDebugEnabled ( ) ) { LOG . debug ( ""==> RangerAuthorizationCoprocessor.postRollBackSplit()"" ) ; } try { activatePluginClassLoader ( ) ; implRegionObserver . postRollBackSplit ( ctx ) ; } finally { deactivatePluginClassLoader ( ) ; } if ( LOG . isDebugEnabled ( ) ) { LOG . debug ( ""<== RangerAuthorizationCoprocessor.postRollBackSplit()"" ) ; } } @ Override public void postCompleteSplit ( ObserverContext < RegionCoprocessorEnvironment > ctx ) throws IOException { if ( LOG . isDebugEnabled ( ) ) { LOG . debug ( ""==> RangerAuthorizationCoprocessor.postCompleteSplit()"" ) ; } try { activatePluginClassLoader ( ) ; implRegionObserver . postCompleteSplit ( ctx ) ; } finally { deactivatePluginClassLoader ( ) ; } if ( LOG . isDebugEnabled ( ) ) { LOG . debug ( ""<== RangerAuthorizationCoprocessor.postCompleteSplit()"" ) ; } } @ Override public void postClose ( ObserverContext < RegionCoprocessorEnvironment > c , boolean abortRequested ) { if ( LOG . isDebugEnabled ( ) ) { LOG . debug ( ""==> RangerAuthorizationCoprocessor.postClose()"" ) ; } try { activatePluginClassLoader ( ) ; implRegionObserver . postClose ( c , abortRequested ) ; } finally { deactivatePluginClassLoader ( ) ; } if ( LOG . isDebugEnabled ( ) ) { LOG . debug ( ""<== RangerAuthorizationCoprocessor.postClose()"" ) ; } } @ Override public void postGetClosestRowBefore ( ObserverContext < RegionCoprocessorEnvironment > c , byte [ ] row , byte [ ] family , Result result ) throws IOException { if ( LOG . isDebugEnabled ( ) ) { LOG . debug ( ""==> RangerAuthorizationCoprocessor.postGetClosestRowBefore()"" ) ; } try { activatePluginClassLoader ( ) ; implRegionObserver . postGetClosestRowBefore ( c , row , family , result ) ; } finally { deactivatePluginClassLoader ( ) ; } if ( LOG . isDebugEnabled ( ) ) { LOG . debug ( ""<== RangerAuthorizationCoprocessor.postGetClosestRowBefore()"" ) ; } } @ Override public void postGetOp ( ObserverContext < RegionCoprocessorEnvironment > c , Get get , List < Cell > result ) throws IOException { if ( LOG . isDebugEnabled ( ) ) { LOG . debug ( ""==> RangerAuthorizationCoprocessor.postGetOp()"" ) ; } try { activatePluginClassLoader ( ) ; implRegionObserver . postGetOp ( c , get , result ) ; } finally { deactivatePluginClassLoader ( ) ; } if ( LOG . isDebugEnabled ( ) ) { LOG . debug ( ""<== RangerAuthorizationCoprocessor.postGetOp()"" ) ; } } @ Override public boolean postExists ( ObserverContext < RegionCoprocessorEnvironment > c , Get get , boolean exists ) throws IOException { final boolean ret ; if ( LOG . isDebugEnabled ( ) ) { LOG . debug ( ""==> RangerAuthorizationCoprocessor.postExists()"" ) ; } try { activatePluginClassLoader ( ) ; ret = implRegionObserver . postExists ( c , get , exists ) ; } finally { deactivatePluginClassLoader ( ) ; } if ( LOG . isDebugEnabled ( ) ) { LOG . debug ( ""<== RangerAuthorizationCoprocessor.postExists()"" ) ; } return ret ; } @ Override public void postPut ( ObserverContext < RegionCoprocessorEnvironment > c , Put put , WALEdit edit , Durability durability ) throws IOException { if ( LOG . isDebugEnabled ( ) ) { LOG . debug ( ""==> RangerAuthorizationCoprocessor.postPut()"" ) ; } try { activatePluginClassLoader ( ) ; implRegionObserver . postPut ( c , put , edit , durability ) ; } finally { deactivatePluginClassLoader ( ) ; } if ( LOG . isDebugEnabled ( ) ) { LOG . debug ( ""<== RangerAuthorizationCoprocessor.postPut()"" ) ; } } @ Override public void prePrepareTimeStampForDeleteVersion ( ObserverContext < RegionCoprocessorEnvironment > c , Mutation mutation , Cell cell , byte [ ] byteNow , Get get ) throws IOException { if ( LOG . isDebugEnabled ( ) ) { LOG . debug ( ""==> RangerAuthorizationCoprocessor.prePrepareTimeStampForDeleteVersion()"" ) ; } try { activatePluginClassLoader ( ) ; implRegionObserver . prePrepareTimeStampForDeleteVersion ( c , mutation , cell , byteNow , get ) ; } finally { deactivatePluginClassLoader ( ) ; } if ( LOG . isDebugEnabled ( ) ) { LOG . debug ( ""<== RangerAuthorizationCoprocessor.prePrepareTimeStampForDeleteVersion()"" ) ; } } @ Override public void postDelete ( ObserverContext < RegionCoprocessorEnvironment > c , Delete delete , WALEdit edit , Durability durability ) throws IOException { if ( LOG . isDebugEnabled ( ) ) { LOG . debug ( ""==> RangerAuthorizationCoprocessor.postDelete()"" ) ; } try { activatePluginClassLoader ( ) ; implRegionObserver . postDelete ( c , delete , edit , durability ) ; } finally { deactivatePluginClassLoader ( ) ; } if ( LOG . isDebugEnabled ( ) ) { LOG . debug ( ""<== RangerAuthorizationCoprocessor.postDelete()"" ) ; } } @ Override public void preBatchMutate ( ObserverContext < RegionCoprocessorEnvironment > c , MiniBatchOperationInProgress < Mutation > miniBatchOp ) throws IOException { if ( LOG . isDebugEnabled ( ) ) { LOG . debug ( ""==> RangerAuthorizationCoprocessor.preBatchMutate()"" ) ; } try { activatePluginClassLoader ( ) ; implRegionObserver . preBatchMutate ( c , miniBatchOp ) ; } finally { deactivatePluginClassLoader ( ) ; } if ( LOG . isDebugEnabled ( ) ) { LOG . debug ( ""<== RangerAuthorizationCoprocessor.preBatchMutate()"" ) ; } } @ Override public void postBatchMutate ( ObserverContext < RegionCoprocessorEnvironment > c , MiniBatchOperationInProgress < Mutation > miniBatchOp ) throws IOException { if ( LOG . isDebugEnabled ( ) ) { LOG . debug ( ""==> RangerAuthorizationCoprocessor.postBatchMutate()"" ) ; } try { activatePluginClassLoader ( ) ; implRegionObserver . postBatchMutate ( c , miniBatchOp ) ; } finally { deactivatePluginClassLoader ( ) ; } if ( LOG . isDebugEnabled ( ) ) { LOG . debug ( ""<== RangerAuthorizationCoprocessor.postBatchMutate()"" ) ; } } @ Override public void postStartRegionOperation ( ObserverContext < RegionCoprocessorEnvironment > ctx , Operation operation ) throws IOException { if ( LOG . isDebugEnabled ( ) ) { LOG . debug ( ""==> RangerAuthorizationCoprocessor.postStartRegionOperation()"" ) ; } try { activatePluginClassLoader ( ) ; implRegionObserver . postStartRegionOperation ( ctx , operation ) ; } finally { deactivatePluginClassLoader ( ) ; } if ( LOG . isDebugEnabled ( ) ) { LOG . debug ( ""<== RangerAuthorizationCoprocessor.postStartRegionOperation()"" ) ; } } @ Override public void postCloseRegionOperation ( ObserverContext < RegionCoprocessorEnvironment > ctx , Operation operation ) throws IOException { if ( LOG . isDebugEnabled ( ) ) { LOG . debug ( ""==> RangerAuthorizationCoprocessor.postCloseRegionOperation()"" ) ; } try { activatePluginClassLoader ( ) ; implRegionObserver . postCloseRegionOperation ( ctx , operation ) ; } finally { deactivatePluginClassLoader ( ) ; } if ( LOG . isDebugEnabled ( ) ) { LOG . debug ( ""<== RangerAuthorizationCoprocessor.postCloseRegionOperation()"" ) ; } } @ Override public void postBatchMutateIndispensably ( ObserverContext < RegionCoprocessorEnvironment > ctx , MiniBatchOperationInProgress < Mutation > miniBatchOp , boolean success ) throws IOException { if ( LOG . isDebugEnabled ( ) ) { LOG . debug ( ""==> RangerAuthorizationCoprocessor.postBatchMutateIndispensably()"" ) ; } try { activatePluginClassLoader ( ) ; implRegionObserver . postBatchMutateIndispensably ( ctx , miniBatchOp , success ) ; } finally { deactivatePluginClassLoader ( ) ; } if ( LOG . isDebugEnabled ( ) ) { LOG . debug ( ""<== RangerAuthorizationCoprocessor.postBatchMutateIndispensably()"" ) ; } } @ Override public boolean preCheckAndPutAfterRowLock ( ObserverContext < RegionCoprocessorEnvironment > c , byte [ ] row , byte [ ] family , byte [ ] qualifier , CompareOp compareOp , ByteArrayComparable comparator , Put put , boolean result ) throws IOException { final boolean ret ; if ( LOG . isDebugEnabled ( ) ) { LOG . debug ( ""==> RangerAuthorizationCoprocessor.preCheckAndPutAfterRowLock()"" ) ; } try { activatePluginClassLoader ( ) ; ret = implRegionObserver . preCheckAndPutAfterRowLock ( c , row , family , qualifier , compareOp , comparator , put , result ) ; } finally { deactivatePluginClassLoader ( ) ; } if ( LOG . isDebugEnabled ( ) ) { LOG . debug ( ""<== RangerAuthorizationCoprocessor.preCheckAndPutAfterRowLock()"" ) ; } return ret ; } @ Override public boolean postCheckAndPut ( ObserverContext < RegionCoprocessorEnvironment > c , byte [ ] row , byte [ ] family , byte [ ] qualifier , CompareOp compareOp , ByteArrayComparable comparator , Put put , boolean result ) throws IOException { final boolean ret ; if ( LOG . isDebugEnabled ( ) ) { LOG . debug ( ""==> RangerAuthorizationCoprocessor.postCheckAndPut()"" ) ; } try { activatePluginClassLoader ( ) ; ret = implRegionObserver . postCheckAndPut ( c , row , family , qualifier , compareOp , comparator , put , result ) ; } finally { deactivatePluginClassLoader ( ) ; } if ( LOG . isDebugEnabled ( ) ) { LOG . debug ( ""<== RangerAuthorizationCoprocessor.postCheckAndPut()"" ) ; } return ret ; } @ Override public boolean preCheckAndDeleteAfterRowLock ( ObserverContext < RegionCoprocessorEnvironment > c , byte [ ] row , byte [ ] family , byte [ ] qualifier , CompareOp compareOp , ByteArrayComparable comparator , Delete delete , boolean result ) throws IOException { final boolean ret ; if ( LOG . isDebugEnabled ( ) ) { LOG . debug ( ""==> RangerAuthorizationCoprocessor.preCheckAndDeleteAfterRowLock()"" ) ; } try { activatePluginClassLoader ( ) ; ret = implRegionObserver . preCheckAndDeleteAfterRowLock ( c , row , family , qualifier , compareOp , comparator , delete , result ) ; } finally { deactivatePluginClassLoader ( ) ; } if ( LOG . isDebugEnabled ( ) ) { LOG . debug ( ""<== RangerAuthorizationCoprocessor.preCheckAndDeleteAfterRowLock()"" ) ; } return ret ; } @ Override public boolean postCheckAndDelete ( ObserverContext < RegionCoprocessorEnvironment > c , byte [ ] row , byte [ ] family , byte [ ] qualifier , CompareOp compareOp , ByteArrayComparable comparator , Delete delete , boolean result ) throws IOException { final boolean ret ; if ( LOG . isDebugEnabled ( ) ) { LOG . debug ( ""==> RangerAuthorizationCoprocessor.postCheckAndDelete()"" ) ; } try { activatePluginClassLoader ( ) ; ret = implRegionObserver . postCheckAndDelete ( c , row , family , qualifier , compareOp , comparator , delete , result ) ; } finally { deactivatePluginClassLoader ( ) ; } if ( LOG . isDebugEnabled ( ) ) { LOG . debug ( ""<== RangerAuthorizationCoprocessor.postCheckAndDelete()"" ) ; } return ret ; } @ Override public long postIncrementColumnValue ( ObserverContext < RegionCoprocessorEnvironment > c , byte [ ] row , byte [ ] family , byte [ ] qualifier , long amount , boolean writeToWAL , long result ) throws IOException { final long ret ; if ( LOG . isDebugEnabled ( ) ) { LOG . debug ( ""==> RangerAuthorizationCoprocessor.postIncrementColumnValue()"" ) ; } try { activatePluginClassLoader ( ) ; ret = implRegionObserver . postIncrementColumnValue ( c , row , family , qualifier , amount , writeToWAL , result ) ; } finally { deactivatePluginClassLoader ( ) ; } if ( LOG . isDebugEnabled ( ) ) { LOG . debug ( ""<== RangerAuthorizationCoprocessor.postIncrementColumnValue()"" ) ; } return ret ; } @ Override public Result preAppendAfterRowLock ( ObserverContext < RegionCoprocessorEnvironment > c , Append append ) throws IOException { final Result ret ; if ( LOG . isDebugEnabled ( ) ) { LOG . debug ( ""==> RangerAuthorizationCoprocessor.preAppendAfterRowLock()"" ) ; } try { activatePluginClassLoader ( ) ; ret = implRegionObserver . preAppendAfterRowLock ( c , append ) ; } finally { deactivatePluginClassLoader ( ) ; } if ( LOG . isDebugEnabled ( ) ) { LOG . debug ( ""<== RangerAuthorizationCoprocessor.preAppendAfterRowLock()"" ) ; } return ret ; } @ Override public Result postAppend ( ObserverContext < RegionCoprocessorEnvironment > c , Append append , Result result ) throws IOException { final Result ret ; if ( LOG . isDebugEnabled ( ) ) { LOG . debug ( ""==> RangerAuthorizationCoprocessor.postAppend()"" ) ; } try { activatePluginClassLoader ( ) ; ret = implRegionObserver . postAppend ( c , append , result ) ; } finally { deactivatePluginClassLoader ( ) ; } if ( LOG . isDebugEnabled ( ) ) { LOG . debug ( ""<== RangerAuthorizationCoprocessor.postAppend()"" ) ; } return ret ; } @ Override public Result preIncrementAfterRowLock ( ObserverContext < RegionCoprocessorEnvironment > c , Increment increment ) throws IOException { final Result ret ; if ( LOG . isDebugEnabled ( ) ) { LOG . debug ( ""==> RangerAuthorizationCoprocessor.preIncrementAfterRowLock()"" ) ; } try { activatePluginClassLoader ( ) ; ret = implRegionObserver . preIncrementAfterRowLock ( c , increment ) ; } finally { deactivatePluginClassLoader ( ) ; } if ( LOG . isDebugEnabled ( ) ) { LOG . debug ( ""<== RangerAuthorizationCoprocessor.preIncrementAfterRowLock()"" ) ; } return ret ; } @ Override public Result postIncrement ( ObserverContext < RegionCoprocessorEnvironment > c , Increment increment , Result result ) throws IOException { final Result ret ; if ( LOG . isDebugEnabled ( ) ) { LOG . debug ( ""==> RangerAuthorizationCoprocessor.postIncrement()"" ) ; } try { activatePluginClassLoader ( ) ; ret = implRegionObserver . postIncrement ( c , increment , result ) ; } finally { deactivatePluginClassLoader ( ) ; } if ( LOG . isDebugEnabled ( ) ) { LOG . debug ( ""<== RangerAuthorizationCoprocessor.postIncrement()"" ) ; } return ret ; } @ Override public KeyValueScanner preStoreScannerOpen ( ObserverContext < RegionCoprocessorEnvironment > c , Store store , Scan scan , NavigableSet < byte [ ] > targetCols , KeyValueScanner s ) throws IOException { final KeyValueScanner ret ; if ( LOG . isDebugEnabled ( ) ) { LOG . debug ( ""==> RangerAuthorizationCoprocessor.preStoreScannerOpen()"" ) ; } try { activatePluginClassLoader ( ) ; ret = implRegionObserver . preStoreScannerOpen ( c , store , scan , targetCols , s ) ; } finally { deactivatePluginClassLoader ( ) ; } if ( LOG . isDebugEnabled ( ) ) { LOG . debug ( ""<== RangerAuthorizationCoprocessor.preStoreScannerOpen()"" ) ; } return ret ; } @ Override public boolean postScannerNext ( ObserverContext < RegionCoprocessorEnvironment > c , InternalScanner s , List < Result > result , int limit , boolean hasNext ) throws IOException { final boolean ret ; if ( LOG . isDebugEnabled ( ) ) { LOG . debug ( ""==> RangerAuthorizationCoprocessor.postScannerNext()"" ) ; } try { activatePluginClassLoader ( ) ; ret = implRegionObserver . postScannerNext ( c , s , result , limit , hasNext ) ; } finally { deactivatePluginClassLoader ( ) ; } if ( LOG . isDebugEnabled ( ) ) { LOG . debug ( ""<== RangerAuthorizationCoprocessor.postScannerNext()"" ) ; } return ret ; } @ Override public boolean postScannerFilterRow ( ObserverContext < RegionCoprocessorEnvironment > c , InternalScanner s , byte [ ] currentRow , int offset , short length , boolean hasMore ) throws IOException { final boolean ret ; if ( LOG . isDebugEnabled ( ) ) { LOG . debug ( ""==> RangerAuthorizationCoprocessor.postScannerFilterRow()"" ) ; } try { activatePluginClassLoader ( ) ; ret = implRegionObserver . postScannerFilterRow ( c , s , currentRow , offset , length , hasMore ) ; } finally { deactivatePluginClassLoader ( ) ; } if ( LOG . isDebugEnabled ( ) ) { LOG . debug ( ""<== RangerAuthorizationCoprocessor.postScannerFilterRow()"" ) ; } return ret ; } @ Override public void preWALRestore ( ObserverContext < ? extends RegionCoprocessorEnvironment > ctx , HRegionInfo info , WALKey logKey , WALEdit logEdit ) throws IOException { if ( LOG . isDebugEnabled ( ) ) { LOG . debug ( ""==> RangerAuthorizationCoprocessor.preWALRestore()"" ) ; } try { activatePluginClassLoader ( ) ; implRegionObserver . preWALRestore ( ctx , info , logKey , logEdit ) ; } finally { deactivatePluginClassLoader ( ) ; } if ( LOG . isDebugEnabled ( ) ) { LOG . debug ( ""<== RangerAuthorizationCoprocessor.preWALRestore()"" ) ; } } @ Override public void postWALRestore ( ObserverContext < ? extends RegionCoprocessorEnvironment > ctx , HRegionInfo info , WALKey logKey , WALEdit logEdit ) throws IOException { if ( LOG . isDebugEnabled ( ) ) { LOG . debug ( ""==> RangerAuthorizationCoprocessor.postWALRestore()"" ) ; } try { activatePluginClassLoader ( ) ; implRegionObserver . postWALRestore ( ctx , info , logKey , logEdit ) ; } finally { deactivatePluginClassLoader ( ) ; } if ( LOG . isDebugEnabled ( ) ) { LOG . debug ( ""<== RangerAuthorizationCoprocessor.postWALRestore()"" ) ; } } @ Override public boolean postBulkLoadHFile ( ObserverContext < RegionCoprocessorEnvironment > ctx , List < Pair < byte [ ] , String > > familyPaths , boolean hasLoaded ) throws IOException { final boolean ret ; if ( LOG . isDebugEnabled ( ) ) { LOG . debug ( ""==> RangerAuthorizationCoprocessor.postBulkLoadHFile()"" ) ; } try { activatePluginClassLoader ( ) ; ret = implRegionObserver . postBulkLoadHFile ( ctx , familyPaths , hasLoaded ) ; } finally { deactivatePluginClassLoader ( ) ; } if ( LOG . isDebugEnabled ( ) ) { LOG . debug ( ""<== RangerAuthorizationCoprocessor.postBulkLoadHFile()"" ) ; } return ret ; } @ Override public Reader preStoreFileReaderOpen ( ObserverContext < RegionCoprocessorEnvironment > ctx , FileSystem fs , Path p , FSDataInputStreamWrapper in , long size , CacheConfig cacheConf , Reference r , Reader reader ) throws IOException { final Reader ret ; if ( LOG . isDebugEnabled ( ) ) { LOG . debug ( ""==> RangerAuthorizationCoprocessor.preStoreFileReaderOpen()"" ) ; } try { activatePluginClassLoader ( ) ; ret = implRegionObserver . preStoreFileReaderOpen ( ctx , fs , p , in , size , cacheConf , r , reader ) ; } finally { deactivatePluginClassLoader ( ) ; } if ( LOG . isDebugEnabled ( ) ) { LOG . debug ( ""<== RangerAuthorizationCoprocessor.preStoreFileReaderOpen()"" ) ; } return ret ; } @ Override public Reader postStoreFileReaderOpen ( ObserverContext < RegionCoprocessorEnvironment > ctx , FileSystem fs , Path p , FSDataInputStreamWrapper in , long size , CacheConfig cacheConf , Reference r , Reader reader ) throws IOException { final Reader ret ; if ( LOG . isDebugEnabled ( ) ) { LOG . debug ( ""==> RangerAuthorizationCoprocessor.postStoreFileReaderOpen()"" ) ; } try { activatePluginClassLoader ( ) ; ret = implRegionObserver . postStoreFileReaderOpen ( ctx , fs , p , in , size , cacheConf , r , reader ) ; } finally { deactivatePluginClassLoader ( ) ; } if ( LOG . isDebugEnabled ( ) ) { LOG . debug ( ""<== RangerAuthorizationCoprocessor.postStoreFileReaderOpen()"" ) ; } return ret ; } @ Override public Cell postMutationBeforeWAL ( ObserverContext < RegionCoprocessorEnvironment > ctx , MutationType opType , Mutation mutation , Cell oldCell , Cell newCell ) throws IOException { final Cell ret ; if ( LOG . isDebugEnabled ( ) ) { LOG . debug ( ""==> RangerAuthorizationCoprocessor.postMutationBeforeWAL()"" ) ; } try { activatePluginClassLoader ( ) ; ret = implRegionObserver . postMutationBeforeWAL ( ctx , opType , mutation , oldCell , newCell ) ; } finally { deactivatePluginClassLoader ( ) ; } if ( LOG . isDebugEnabled ( ) ) { LOG . debug ( ""<== RangerAuthorizationCoprocessor.postMutationBeforeWAL()"" ) ; } return ret ; } @ Override public DeleteTracker postInstantiateDeleteTracker ( ObserverContext < RegionCoprocessorEnvironment > ctx , DeleteTracker delTracker ) throws IOException { final DeleteTracker ret ; if ( LOG . isDebugEnabled ( ) ) { LOG . debug ( ""==> RangerAuthorizationCoprocessor.postInstantiateDeleteTracker()"" ) ; } try { activatePluginClassLoader ( ) ; ret = implRegionObserver . postInstantiateDeleteTracker ( ctx , delTracker ) ; } finally { deactivatePluginClassLoader ( ) ; } if ( LOG . isDebugEnabled ( ) ) { LOG . debug ( ""<== RangerAuthorizationCoprocessor.postInstantiateDeleteTracker()"" ) ; } return ret ; } @ Override public void postCreateTable ( ObserverContext < MasterCoprocessorEnvironment > ctx , HTableDescriptor desc , HRegionInfo [ ] regions ) throws IOException { if ( LOG . isDebugEnabled ( ) ) { LOG . debug ( ""==> RangerAuthorizationCoprocessor.postCreateTable()"" ) ; } try { activatePluginClassLoader ( ) ; implMasterObserver . postCreateTable ( ctx , desc , regions ) ; } finally { deactivatePluginClassLoader ( ) ; } if ( LOG . isDebugEnabled ( ) ) { LOG . debug ( ""<== RangerAuthorizationCoprocessor.postCreateTable()"" ) ; } } @ Override public void preCreateTableHandler ( ObserverContext < MasterCoprocessorEnvironment > ctx , HTableDescriptor desc , HRegionInfo [ ] regions ) throws IOException { if ( LOG . isDebugEnabled ( ) ) { LOG . debug ( ""==> RangerAuthorizationCoprocessor.preCreateTableHandler()"" ) ; } try { activatePluginClassLoader ( ) ; implMasterObserver . preCreateTableHandler ( ctx , desc , regions ) ; } finally { deactivatePluginClassLoader ( ) ; } if ( LOG . isDebugEnabled ( ) ) { LOG . debug ( ""<== RangerAuthorizationCoprocessor.preCreateTableHandler()"" ) ; } } @ Override public void postCreateTableHandler ( ObserverContext < MasterCoprocessorEnvironment > ctx , HTableDescriptor desc , HRegionInfo [ ] regions ) throws IOException { if ( LOG . isDebugEnabled ( ) ) { LOG . debug ( ""==> RangerAuthorizationCoprocessor.postCreateTableHandler()"" ) ; } try { activatePluginClassLoader ( ) ; implMasterObserver . postCreateTableHandler ( ctx , desc , regions ) ; } finally { deactivatePluginClassLoader ( ) ; } if ( LOG . isDebugEnabled ( ) ) { LOG . debug ( ""<== RangerAuthorizationCoprocessor.postCreateTableHandler()"" ) ; } } @ Override public void postDeleteTable ( ObserverContext < MasterCoprocessorEnvironment > ctx , TableName tableName ) throws IOException { if ( LOG . isDebugEnabled ( ) ) { LOG . debug ( ""==> RangerAuthorizationCoprocessor.postDeleteTable()"" ) ; } try { activatePluginClassLoader ( ) ; implMasterObserver . postDeleteTable ( ctx , tableName ) ; } finally { deactivatePluginClassLoader ( ) ; } if ( LOG . isDebugEnabled ( ) ) { LOG . debug ( ""<== RangerAuthorizationCoprocessor.postDeleteTable()"" ) ; } } @ Override public void preDeleteTableHandler ( ObserverContext < MasterCoprocessorEnvironment > ctx , TableName tableName ) throws IOException { if ( LOG . isDebugEnabled ( ) ) { LOG . debug ( ""==> RangerAuthorizationCoprocessor.preDeleteTableHandler()"" ) ; } try { activatePluginClassLoader ( ) ; implMasterObserver . preDeleteTableHandler ( ctx , tableName ) ; } finally { deactivatePluginClassLoader ( ) ; } if ( LOG . isDebugEnabled ( ) ) { LOG . debug ( ""<== RangerAuthorizationCoprocessor.preDeleteTableHandler()"" ) ; } } @ Override public void postDeleteTableHandler ( ObserverContext < MasterCoprocessorEnvironment > ctx , TableName tableName ) throws IOException { if ( LOG . isDebugEnabled ( ) ) { LOG . debug ( ""==> RangerAuthorizationCoprocessor.postDeleteTableHandler()"" ) ; } try { activatePluginClassLoader ( ) ; implMasterObserver . postDeleteTableHandler ( ctx , tableName ) ; } finally { deactivatePluginClassLoader ( ) ; } if ( LOG . isDebugEnabled ( ) ) { LOG . debug ( ""<== RangerAuthorizationCoprocessor.postDeleteTableHandler()"" ) ; } } @ Override public void preTruncateTable ( ObserverContext < MasterCoprocessorEnvironment > ctx , TableName tableName ) throws IOException { if ( LOG . isDebugEnabled ( ) ) { LOG . debug ( ""==> RangerAuthorizationCoprocessor.preTruncateTable()"" ) ; } try { activatePluginClassLoader ( ) ; implMasterObserver . preTruncateTable ( ctx , tableName ) ; } finally { deactivatePluginClassLoader ( ) ; } if ( LOG . isDebugEnabled ( ) ) { LOG . debug ( ""<== RangerAuthorizationCoprocessor.preTruncateTable()"" ) ; } } @ Override public void postTruncateTable ( ObserverContext < MasterCoprocessorEnvironment > ctx , TableName tableName ) throws IOException { if ( LOG . isDebugEnabled ( ) ) { LOG . debug ( ""==> RangerAuthorizationCoprocessor.postTruncateTable()"" ) ; } try { activatePluginClassLoader ( ) ; implMasterObserver . postTruncateTable ( ctx , tableName ) ; } finally { deactivatePluginClassLoader ( ) ; } if ( LOG . isDebugEnabled ( ) ) { LOG . debug ( ""<== RangerAuthorizationCoprocessor.postTruncateTable()"" ) ; } } @ Override public void preTruncateTableHandler ( ObserverContext < MasterCoprocessorEnvironment > ctx , TableName tableName ) throws IOException { if ( LOG . isDebugEnabled ( ) ) { LOG . debug ( ""==> RangerAuthorizationCoprocessor.preTruncateTableHandler()"" ) ; } try { activatePluginClassLoader ( ) ; implMasterObserver . preTruncateTableHandler ( ctx , tableName ) ; } finally { deactivatePluginClassLoader ( ) ; } if ( LOG . isDebugEnabled ( ) ) { LOG . debug ( ""<== RangerAuthorizationCoprocessor.preTruncateTableHandler()"" ) ; } } @ Override public void postTruncateTableHandler ( ObserverContext < MasterCoprocessorEnvironment > ctx , TableName tableName ) throws IOException { if ( LOG . isDebugEnabled ( ) ) { LOG . debug ( ""==> RangerAuthorizationCoprocessor.postTruncateTableHandler()"" ) ; } try { activatePluginClassLoader ( ) ; implMasterObserver . postTruncateTableHandler ( ctx , tableName ) ; } finally { deactivatePluginClassLoader ( ) ; } if ( LOG . isDebugEnabled ( ) ) { LOG . debug ( ""<== RangerAuthorizationCoprocessor.postTruncateTableHandler()"" ) ; } } @ Override public void postModifyTable ( ObserverContext < MasterCoprocessorEnvironment > ctx , TableName tableName , HTableDescriptor htd ) throws IOException { if ( LOG . isDebugEnabled ( ) ) { LOG . debug ( ""==> RangerAuthorizationCoprocessor.postModifyTable()"" ) ; } try { activatePluginClassLoader ( ) ; implMasterObserver . postModifyTable ( ctx , tableName , htd ) ; } finally { deactivatePluginClassLoader ( ) ; } if ( LOG . isDebugEnabled ( ) ) { LOG . debug ( ""<== RangerAuthorizationCoprocessor.postModifyTable()"" ) ; } } @ Override public void preModifyTableHandler ( ObserverContext < MasterCoprocessorEnvironment > ctx , TableName tableName , HTableDescriptor htd ) throws IOException { if ( LOG . isDebugEnabled ( ) ) { LOG . debug ( ""==> RangerAuthorizationCoprocessor.preModifyTableHandler()"" ) ; } try { activatePluginClassLoader ( ) ; implMasterObserver . preModifyTableHandler ( ctx , tableName , htd ) ; } finally { deactivatePluginClassLoader ( ) ; } if ( LOG . isDebugEnabled ( ) ) { LOG . debug ( ""<== RangerAuthorizationCoprocessor.preModifyTableHandler()"" ) ; } } @ Override public void postModifyTableHandler ( ObserverContext < MasterCoprocessorEnvironment > ctx , TableName tableName , HTableDescriptor htd ) throws IOException { if ( LOG . isDebugEnabled ( ) ) { LOG . debug ( ""==> RangerAuthorizationCoprocessor.postModifyTableHandler()"" ) ; } try { activatePluginClassLoader ( ) ; implMasterObserver . postModifyTableHandler ( ctx , tableName , htd ) ; } finally { deactivatePluginClassLoader ( ) ; } if ( LOG . isDebugEnabled ( ) ) { LOG . debug ( ""<== RangerAuthorizationCoprocessor.postModifyTableHandler()"" ) ; } } @ Override public void postAddColumn ( ObserverContext < MasterCoprocessorEnvironment > ctx , TableName tableName , HColumnDescriptor column ) throws IOException { if ( LOG . isDebugEnabled ( ) ) { LOG . debug ( ""==> RangerAuthorizationCoprocessor.postAddColumn()"" ) ; } try { activatePluginClassLoader ( ) ; implMasterObserver . postAddColumn ( ctx , tableName , column ) ; } finally { deactivatePluginClassLoader ( ) ; } if ( LOG . isDebugEnabled ( ) ) { LOG . debug ( ""<== RangerAuthorizationCoprocessor.postAddColumn()"" ) ; } } @ Override public void preAddColumnHandler ( ObserverContext < MasterCoprocessorEnvironment > ctx , TableName tableName , HColumnDescriptor column ) throws IOException { if ( LOG . isDebugEnabled ( ) ) { LOG . debug ( ""==> RangerAuthorizationCoprocessor.preAddColumnHandler()"" ) ; } try { activatePluginClassLoader ( ) ; implMasterObserver . preAddColumnHandler ( ctx , tableName , column ) ; } finally { deactivatePluginClassLoader ( ) ; } if ( LOG . isDebugEnabled ( ) ) { LOG . debug ( ""<== RangerAuthorizationCoprocessor.preAddColumnHandler()"" ) ; } } @ Override public void postAddColumnHandler ( ObserverContext < MasterCoprocessorEnvironment > ctx , TableName tableName , HColumnDescriptor column ) throws IOException { if ( LOG . isDebugEnabled ( ) ) { LOG . debug ( ""==> RangerAuthorizationCoprocessor.postAddColumnHandler()"" ) ; } try { activatePluginClassLoader ( ) ; implMasterObserver . postAddColumnHandler ( ctx , tableName , column ) ; } finally { deactivatePluginClassLoader ( ) ; } if ( LOG . isDebugEnabled ( ) ) { LOG . debug ( ""<== RangerAuthorizationCoprocessor.postAddColumnHandler()"" ) ; } } @ Override public void postModifyColumn ( ObserverContext < MasterCoprocessorEnvironment > ctx , TableName tableName , HColumnDescriptor descriptor ) throws IOException { if ( LOG . isDebugEnabled ( ) ) { LOG . debug ( ""==> RangerAuthorizationCoprocessor.postModifyColumn()"" ) ; } try { activatePluginClassLoader ( ) ; implMasterObserver . postModifyColumn ( ctx , tableName , descriptor ) ; } finally { deactivatePluginClassLoader ( ) ; } if ( LOG . isDebugEnabled ( ) ) { LOG . debug ( ""<== RangerAuthorizationCoprocessor.postModifyColumn()"" ) ; } } @ Override public void preModifyColumnHandler ( ObserverContext < MasterCoprocessorEnvironment > ctx , TableName tableName , HColumnDescriptor descriptor ) throws IOException { if ( LOG . isDebugEnabled ( ) ) { LOG . debug ( ""==> RangerAuthorizationCoprocessor.preModifyColumnHandler()"" ) ; } try { activatePluginClassLoader ( ) ; implMasterObserver . preModifyColumnHandler ( ctx , tableName , descriptor ) ; } finally { deactivatePluginClassLoader ( ) ; } if ( LOG . isDebugEnabled ( ) ) { LOG . debug ( ""<== RangerAuthorizationCoprocessor.preModifyColumnHandler()"" ) ; } } @ Override public void postModifyColumnHandler ( ObserverContext < MasterCoprocessorEnvironment > ctx , TableName tableName , HColumnDescriptor descriptor ) throws IOException { if ( LOG . isDebugEnabled ( ) ) { LOG . debug ( ""==> RangerAuthorizationCoprocessor.postModifyColumnHandler()"" ) ; } try { activatePluginClassLoader ( ) ; implMasterObserver . postModifyColumnHandler ( ctx , tableName , descriptor ) ; } finally { deactivatePluginClassLoader ( ) ; } if ( LOG . isDebugEnabled ( ) ) { LOG . debug ( ""<== RangerAuthorizationCoprocessor.postModifyColumnHandler()"" ) ; } } @ Override public void postDeleteColumn ( ObserverContext < MasterCoprocessorEnvironment > ctx , TableName tableName , byte [ ] c ) throws IOException { if ( LOG . isDebugEnabled ( ) ) { LOG . debug ( ""==> RangerAuthorizationCoprocessor.postDeleteColumn()"" ) ; } try { activatePluginClassLoader ( ) ; implMasterObserver . postDeleteColumn ( ctx , tableName , c ) ; } finally { deactivatePluginClassLoader ( ) ; } if ( LOG . isDebugEnabled ( ) ) { LOG . debug ( ""<== RangerAuthorizationCoprocessor.postDeleteColumn()"" ) ; } } @ Override public void preDeleteColumnHandler ( ObserverContext < MasterCoprocessorEnvironment > ctx , TableName tableName , byte [ ] c ) throws IOException { if ( LOG . isDebugEnabled ( ) ) { LOG . debug ( ""==> RangerAuthorizationCoprocessor.preDeleteColumnHandler()"" ) ; } try { activatePluginClassLoader ( ) ; implMasterObserver . preDeleteColumnHandler ( ctx , tableName , c ) ; } finally { deactivatePluginClassLoader ( ) ; } if ( LOG . isDebugEnabled ( ) ) { LOG . debug ( ""<== RangerAuthorizationCoprocessor.preDeleteColumnHandler()"" ) ; } } @ Override public void postDeleteColumnHandler ( ObserverContext < MasterCoprocessorEnvironment > ctx , TableName tableName , byte [ ] c ) throws IOException { if ( LOG . isDebugEnabled ( ) ) { LOG . debug ( ""==> RangerAuthorizationCoprocessor.postDeleteColumnHandler()"" ) ; } try { activatePluginClassLoader ( ) ; implMasterObserver . postDeleteColumnHandler ( ctx , tableName , c ) ; } finally { deactivatePluginClassLoader ( ) ; } if ( LOG . isDebugEnabled ( ) ) { LOG . debug ( ""<== RangerAuthorizationCoprocessor.postDeleteColumnHandler()"" ) ; } } @ Override public void postEnableTable ( ObserverContext < MasterCoprocessorEnvironment > ctx , TableName tableName ) throws IOException { if ( LOG . isDebugEnabled ( ) ) { LOG . debug ( ""==> RangerAuthorizationCoprocessor.postEnableTable()"" ) ; } try { activatePluginClassLoader ( ) ; implMasterObserver . postEnableTable ( ctx , tableName ) ; } finally { deactivatePluginClassLoader ( ) ; } if ( LOG . isDebugEnabled ( ) ) { LOG . debug ( ""<== RangerAuthorizationCoprocessor.postEnableTable()"" ) ; } } @ Override public void preEnableTableHandler ( ObserverContext < MasterCoprocessorEnvironment > ctx , TableName tableName ) throws IOException { if ( LOG . isDebugEnabled ( ) ) { LOG . debug ( ""==> RangerAuthorizationCoprocessor.preEnableTableHandler()"" ) ; } try { activatePluginClassLoader ( ) ; implMasterObserver . preEnableTableHandler ( ctx , tableName ) ; } finally { deactivatePluginClassLoader ( ) ; } if ( LOG . isDebugEnabled ( ) ) { LOG . debug ( ""<== RangerAuthorizationCoprocessor.preEnableTableHandler()"" ) ; } } @ Override public void postEnableTableHandler ( ObserverContext < MasterCoprocessorEnvironment > ctx , TableName tableName ) throws IOException { if ( LOG . isDebugEnabled ( ) ) { LOG . debug ( ""==> RangerAuthorizationCoprocessor.postEnableTableHandler()"" ) ; } try { activatePluginClassLoader ( ) ; implMasterObserver . postEnableTableHandler ( ctx , tableName ) ; } finally { deactivatePluginClassLoader ( ) ; } if ( LOG . isDebugEnabled ( ) ) { LOG . debug ( ""<== RangerAuthorizationCoprocessor.postEnableTableHandler()"" ) ; } } @ Override public void postDisableTable ( ObserverContext < MasterCoprocessorEnvironment > ctx , TableName tableName ) throws IOException { if ( LOG . isDebugEnabled ( ) ) { LOG . debug ( ""==> RangerAuthorizationCoprocessor.postDisableTable()"" ) ; } try { activatePluginClassLoader ( ) ; implMasterObserver . postDisableTable ( ctx , tableName ) ; } finally { deactivatePluginClassLoader ( ) ; } if ( LOG . isDebugEnabled ( ) ) { LOG . debug ( ""<== RangerAuthorizationCoprocessor.postDisableTable()"" ) ; } } @ Override public void preDisableTableHandler ( ObserverContext < MasterCoprocessorEnvironment > ctx , TableName tableName ) throws IOException { if ( LOG . isDebugEnabled ( ) ) { LOG . debug ( ""==> RangerAuthorizationCoprocessor.preDisableTableHandler()"" ) ; } try { activatePluginClassLoader ( ) ; implMasterObserver . preDisableTableHandler ( ctx , tableName ) ; } finally { deactivatePluginClassLoader ( ) ; } if ( LOG . isDebugEnabled ( ) ) { LOG . debug ( ""<== RangerAuthorizationCoprocessor.preDisableTableHandler()"" ) ; } } @ Override public void postDisableTableHandler ( ObserverContext < MasterCoprocessorEnvironment > ctx , TableName tableName ) throws IOException { if ( LOG . isDebugEnabled ( ) ) { LOG . debug ( ""==> RangerAuthorizationCoprocessor.postDisableTableHandler()"" ) ; } try { activatePluginClassLoader ( ) ; implMasterObserver . postDisableTableHandler ( ctx , tableName ) ; } finally { deactivatePluginClassLoader ( ) ; } if ( LOG . isDebugEnabled ( ) ) { LOG . debug ( ""<== RangerAuthorizationCoprocessor.postDisableTableHandler()"" ) ; } } @ Override public void postMove ( ObserverContext < MasterCoprocessorEnvironment > ctx , HRegionInfo region , ServerName srcServer , ServerName destServer ) throws IOException { if ( LOG . isDebugEnabled ( ) ) { LOG . debug ( ""==> RangerAuthorizationCoprocessor.postMove()"" ) ; } try { activatePluginClassLoader ( ) ; implMasterObserver . postMove ( ctx , region , srcServer , destServer ) ; } finally { deactivatePluginClassLoader ( ) ; } if ( LOG . isDebugEnabled ( ) ) { LOG . debug ( ""<== RangerAuthorizationCoprocessor.postMove()"" ) ; } } @ Override public void preAbortProcedure ( ObserverContext < MasterCoprocessorEnvironment > observerContext , ProcedureExecutor < MasterProcedureEnv > procEnv , long procId ) throws IOException { if ( LOG . isDebugEnabled ( ) ) { LOG . debug ( ""==> RangerAuthorizationCoprocessor.preAbortProcedure()"" ) ; } try { activatePluginClassLoader ( ) ; implMasterObserver . preAbortProcedure ( observerContext , procEnv , procId ) ; } finally { deactivatePluginClassLoader ( ) ; } if ( LOG . isDebugEnabled ( ) ) { LOG . debug ( ""<== RangerAuthorizationCoprocessor.preAbortProcedure()"" ) ; } } @ Override public void postAbortProcedure ( ObserverContext < MasterCoprocessorEnvironment > observerContext ) throws IOException { if ( LOG . isDebugEnabled ( ) ) { LOG . debug ( ""==> RangerAuthorizationCoprocessor.postAbortProcedure()"" ) ; } try { activatePluginClassLoader ( ) ; implMasterObserver . postAbortProcedure ( observerContext ) ; } finally { deactivatePluginClassLoader ( ) ; } if ( LOG . isDebugEnabled ( ) ) { LOG . debug ( ""<== RangerAuthorizationCoprocessor.postAbortProcedure()"" ) ; } } @ Override public void preListProcedures ( ObserverContext < MasterCoprocessorEnvironment > observerContext ) throws IOException { if ( LOG . isDebugEnabled ( ) ) { LOG . debug ( ""==> RangerAuthorizationCoprocessor.preListProcedures()"" ) ; } try { activatePluginClassLoader ( ) ; implMasterObserver . preListProcedures ( observerContext ) ; } finally { deactivatePluginClassLoader ( ) ; } if ( LOG . isDebugEnabled ( ) ) { LOG . debug ( ""<== RangerAuthorizationCoprocessor.preListProcedures()"" ) ; } } @ Override public void postListProcedures ( ObserverContext < MasterCoprocessorEnvironment > observerContext , List < ProcedureInfo > procInfoList ) throws IOException { if ( LOG . isDebugEnabled ( ) ) { LOG . debug ( ""==> RangerAuthorizationCoprocessor.postListProcedures()"" ) ; } try { activatePluginClassLoader ( ) ; implMasterObserver . postListProcedures ( observerContext , procInfoList ) ; } finally { deactivatePluginClassLoader ( ) ; } if ( LOG . isDebugEnabled ( ) ) { LOG . debug ( ""<== RangerAuthorizationCoprocessor.postListProcedures()"" ) ; } } @ Override public void postAssign ( ObserverContext < MasterCoprocessorEnvironment > ctx , HRegionInfo regionInfo ) throws IOException { if ( LOG . isDebugEnabled ( ) ) { LOG . debug ( ""==> RangerAuthorizationCoprocessor.postAssign()"" ) ; } try { activatePluginClassLoader ( ) ; implMasterObserver . postAssign ( ctx , regionInfo ) ; } finally { deactivatePluginClassLoader ( ) ; } if ( LOG . isDebugEnabled ( ) ) { LOG . debug ( ""<== RangerAuthorizationCoprocessor.postAssign()"" ) ; } } @ Override public void postUnassign ( ObserverContext < MasterCoprocessorEnvironment > ctx , HRegionInfo regionInfo , boolean force ) throws IOException { if ( LOG . isDebugEnabled ( ) ) { LOG . debug ( ""==> RangerAuthorizationCoprocessor.postUnassign()"" ) ; } try { activatePluginClassLoader ( ) ; implMasterObserver . postUnassign ( ctx , regionInfo , force ) ; } finally { deactivatePluginClassLoader ( ) ; } if ( LOG . isDebugEnabled ( ) ) { LOG . debug ( ""<== RangerAuthorizationCoprocessor.postUnassign()"" ) ; } } @ Override public void postRegionOffline ( ObserverContext < MasterCoprocessorEnvironment > ctx , HRegionInfo regionInfo ) throws IOException { if ( LOG . isDebugEnabled ( ) ) { LOG . debug ( ""==> RangerAuthorizationCoprocessor.postRegionOffline()"" ) ; } try { activatePluginClassLoader ( ) ; implMasterObserver . postRegionOffline ( ctx , regionInfo ) ; } finally { deactivatePluginClassLoader ( ) ; } if ( LOG . isDebugEnabled ( ) ) { LOG . debug ( ""<== RangerAuthorizationCoprocessor.postRegionOffline()"" ) ; } } @ Override public void postBalance ( ObserverContext < MasterCoprocessorEnvironment > ctx , List < RegionPlan > plans ) throws IOException { if ( LOG . isDebugEnabled ( ) ) { LOG . debug ( ""==> RangerAuthorizationCoprocessor.postBalance()"" ) ; } try { activatePluginClassLoader ( ) ; implMasterObserver . postBalance ( ctx , plans ) ; } finally { deactivatePluginClassLoader ( ) ; } if ( LOG . isDebugEnabled ( ) ) { LOG . debug ( ""<== RangerAuthorizationCoprocessor.postBalance()"" ) ; } } @ Override public void postBalanceSwitch ( ObserverContext < MasterCoprocessorEnvironment > ctx , boolean oldValue , boolean newValue ) throws IOException { if ( LOG . isDebugEnabled ( ) ) { LOG . debug ( ""==> RangerAuthorizationCoprocessor.postBalanceSwitch()"" ) ; } try { activatePluginClassLoader ( ) ; implMasterObserver . postBalanceSwitch ( ctx , oldValue , newValue ) ; } finally { deactivatePluginClassLoader ( ) ; } if ( LOG . isDebugEnabled ( ) ) { LOG . debug ( ""<== RangerAuthorizationCoprocessor.postBalanceSwitch()"" ) ; } } @ Override public void preMasterInitialization ( ObserverContext < MasterCoprocessorEnvironment > ctx ) throws IOException { if ( LOG . isDebugEnabled ( ) ) { LOG . debug ( ""==> RangerAuthorizationCoprocessor.preMasterInitialization()"" ) ; } try { activatePluginClassLoader ( ) ; implMasterObserver . preMasterInitialization ( ctx ) ; } finally { deactivatePluginClassLoader ( ) ; } if ( LOG . isDebugEnabled ( ) ) { LOG . debug ( ""<== RangerAuthorizationCoprocessor.preMasterInitialization()"" ) ; } } @ Override public void postSnapshot ( ObserverContext < MasterCoprocessorEnvironment > ctx , SnapshotDescription snapshot , HTableDescriptor hTableDescriptor ) throws IOException { if ( LOG . isDebugEnabled ( ) ) { LOG . debug ( ""==> RangerAuthorizationCoprocessor.postSnapshot()"" ) ; } try { activatePluginClassLoader ( ) ; implMasterObserver . postSnapshot ( ctx , snapshot , hTableDescriptor ) ; } finally { deactivatePluginClassLoader ( ) ; } if ( LOG . isDebugEnabled ( ) ) { LOG . debug ( ""<== RangerAuthorizationCoprocessor.postSnapshot()"" ) ; } } @ Override public void preListSnapshot ( ObserverContext < MasterCoprocessorEnvironment > ctx , SnapshotDescription snapshot ) throws IOException { if ( LOG . isDebugEnabled ( ) ) { LOG . debug ( ""==> RangerAuthorizationCoprocessor.preListSnapshot()"" ) ; } try { activatePluginClassLoader ( ) ; implMasterObserver . preListSnapshot ( ctx , snapshot ) ; } finally { deactivatePluginClassLoader ( ) ; } if ( LOG . isDebugEnabled ( ) ) { LOG . debug ( ""<== RangerAuthorizationCoprocessor.preListSnapshot()"" ) ; } } @ Override public void postListSnapshot ( ObserverContext < MasterCoprocessorEnvironment > ctx , SnapshotDescription snapshot ) throws IOException { if ( LOG . isDebugEnabled ( ) ) { LOG . debug ( ""==> RangerAuthorizationCoprocessor.postListSnapshot()"" ) ; } try { activatePluginClassLoader ( ) ; implMasterObserver . postListSnapshot ( ctx , snapshot ) ; } finally { deactivatePluginClassLoader ( ) ; } if ( LOG . isDebugEnabled ( ) ) { LOG . debug ( ""<== RangerAuthorizationCoprocessor.postListSnapshot()"" ) ; } } @ Override public void postCloneSnapshot ( ObserverContext < MasterCoprocessorEnvironment > ctx , SnapshotDescription snapshot , HTableDescriptor hTableDescriptor ) throws IOException { if ( LOG . isDebugEnabled ( ) ) { LOG . debug ( ""==> RangerAuthorizationCoprocessor.postCloneSnapshot()"" ) ; } try { activatePluginClassLoader ( ) ; implMasterObserver . postCloneSnapshot ( ctx , snapshot , hTableDescriptor ) ; } finally { deactivatePluginClassLoader ( ) ; } if ( LOG . isDebugEnabled ( ) ) { LOG . debug ( ""<== RangerAuthorizationCoprocessor.postCloneSnapshot()"" ) ; } } @ Override public void postRestoreSnapshot ( ObserverContext < MasterCoprocessorEnvironment > ctx , SnapshotDescription snapshot , HTableDescriptor hTableDescriptor ) throws IOException { if ( LOG . isDebugEnabled ( ) ) { LOG . debug ( ""==> RangerAuthorizationCoprocessor.postRestoreSnapshot()"" ) ; } try { activatePluginClassLoader ( ) ; implMasterObserver . postRestoreSnapshot ( ctx , snapshot , hTableDescriptor ) ; } finally { deactivatePluginClassLoader ( ) ; } if ( LOG . isDebugEnabled ( ) ) { LOG . debug ( ""<== RangerAuthorizationCoprocessor.postRestoreSnapshot()"" ) ; } } @ Override public void postDeleteSnapshot ( ObserverContext < MasterCoprocessorEnvironment > ctx , SnapshotDescription snapshot ) throws IOException { if ( LOG . isDebugEnabled ( ) ) { LOG . debug ( ""==> RangerAuthorizationCoprocessor.postDeleteSnapshot()"" ) ; } try { activatePluginClassLoader ( ) ; implMasterObserver . postDeleteSnapshot ( ctx , snapshot ) ; } finally { deactivatePluginClassLoader ( ) ; } if ( LOG . isDebugEnabled ( ) ) { LOG . debug ( ""<== RangerAuthorizationCoprocessor.postDeleteSnapshot()"" ) ; } } @ Override public void preGetTableDescriptors ( ObserverContext < MasterCoprocessorEnvironment > ctx , List < TableName > tableNamesList , List < HTableDescriptor > descriptors ) throws IOException { if ( LOG . isDebugEnabled ( ) ) { LOG . debug ( ""==> RangerAuthorizationCoprocessor.preGetTableDescriptors()"" ) ; } try { activatePluginClassLoader ( ) ; implMasterObserver . preGetTableDescriptors ( ctx , tableNamesList , descriptors ) ; } finally { deactivatePluginClassLoader ( ) ; } if ( LOG . isDebugEnabled ( ) ) { LOG . debug ( ""<== RangerAuthorizationCoprocessor.preGetTableDescriptors()"" ) ; } } @ Override public void postGetTableDescriptors ( ObserverContext < MasterCoprocessorEnvironment > ctx , List < HTableDescriptor > descriptors ) throws IOException { if ( LOG . isDebugEnabled ( ) ) { LOG . debug ( ""==> RangerAuthorizationCoprocessor.postGetTableDescriptors()"" ) ; } try { activatePluginClassLoader ( ) ; implMasterObserver . postGetTableDescriptors ( ctx , descriptors ) ; } finally { deactivatePluginClassLoader ( ) ; } if ( LOG . isDebugEnabled ( ) ) { LOG . debug ( ""<== RangerAuthorizationCoprocessor.postGetTableDescriptors()"" ) ; } } @ Override public void preGetTableDescriptors ( ObserverContext < MasterCoprocessorEnvironment > ctx , List < TableName > tableNamesList , List < HTableDescriptor > descriptors , String regex ) throws IOException { if ( LOG . isDebugEnabled ( ) ) { LOG . debug ( ""==> RangerAuthorizationCoprocessor.preGetTableDescriptors()"" ) ; } try { activatePluginClassLoader ( ) ; implMasterObserver . preGetTableDescriptors ( ctx , tableNamesList , descriptors , regex ) ; } finally { deactivatePluginClassLoader ( ) ; } if ( LOG . isDebugEnabled ( ) ) { LOG . debug ( ""<== RangerAuthorizationCoprocessor.preGetTableDescriptors()"" ) ; } } @ Override public void preGetTableNames ( ObserverContext < MasterCoprocessorEnvironment > ctx , List < HTableDescriptor > descriptors , String regex ) throws IOException { if ( LOG . isDebugEnabled ( ) ) { LOG . debug ( ""==> RangerAuthorizationCoprocessor.preGetTableNames()"" ) ; } try { activatePluginClassLoader ( ) ; implMasterObserver . preGetTableNames ( ctx , descriptors , regex ) ; } finally { deactivatePluginClassLoader ( ) ; } if ( LOG . isDebugEnabled ( ) ) { LOG . debug ( ""<== RangerAuthorizationCoprocessor.preGetTableNames()"" ) ; } } @ Override public void postGetTableNames ( ObserverContext < MasterCoprocessorEnvironment > ctx , List < HTableDescriptor > descriptors , String regex ) throws IOException { if ( LOG . isDebugEnabled ( ) ) { LOG . debug ( ""==> RangerAuthorizationCoprocessor.postGetTableNames()"" ) ; } try { activatePluginClassLoader ( ) ; implMasterObserver . postGetTableNames ( ctx , descriptors , regex ) ; } finally { deactivatePluginClassLoader ( ) ; } if ( LOG . isDebugEnabled ( ) ) { LOG . debug ( ""<== RangerAuthorizationCoprocessor.postGetTableNames()"" ) ; } } @ Override public void postCreateNamespace ( ObserverContext < MasterCoprocessorEnvironment > ctx , NamespaceDescriptor ns ) throws IOException { if ( LOG . isDebugEnabled ( ) ) { LOG . debug ( ""==> RangerAuthorizationCoprocessor.postCreateNamespace()"" ) ; } try { activatePluginClassLoader ( ) ; implMasterObserver . postCreateNamespace ( ctx , ns ) ; } finally { deactivatePluginClassLoader ( ) ; } if ( LOG . isDebugEnabled ( ) ) { LOG . debug ( ""<== RangerAuthorizationCoprocessor.postCreateNamespace()"" ) ; } } @ Override public void postDeleteNamespace ( ObserverContext < MasterCoprocessorEnvironment > ctx , String namespace ) throws IOException { if ( LOG . isDebugEnabled ( ) ) { LOG . debug ( ""==> RangerAuthorizationCoprocessor.postDeleteNamespace()"" ) ; } try { activatePluginClassLoader ( ) ; implMasterObserver . postDeleteNamespace ( ctx , namespace ) ; } finally { deactivatePluginClassLoader ( ) ; } if ( LOG . isDebugEnabled ( ) ) { LOG . debug ( ""<== RangerAuthorizationCoprocessor.postDeleteNamespace()"" ) ; } } @ Override public void postModifyNamespace ( ObserverContext < MasterCoprocessorEnvironment > ctx , NamespaceDescriptor ns ) throws IOException { if ( LOG . isDebugEnabled ( ) ) { LOG . debug ( ""==> RangerAuthorizationCoprocessor.postModifyNamespace()"" ) ; } try { activatePluginClassLoader ( ) ; implMasterObserver . postModifyNamespace ( ctx , ns ) ; } finally { deactivatePluginClassLoader ( ) ; } if ( LOG . isDebugEnabled ( ) ) { LOG . debug ( ""<== RangerAuthorizationCoprocessor.postModifyNamespace()"" ) ; } } @ Override public void preGetNamespaceDescriptor ( ObserverContext < MasterCoprocessorEnvironment > ctx , String namespace ) throws IOException { if ( LOG . isDebugEnabled ( ) ) { LOG . debug ( ""==> RangerAuthorizationCoprocessor.preGetNamespaceDescriptor()"" ) ; } try { activatePluginClassLoader ( ) ; implMasterObserver . preGetNamespaceDescriptor ( ctx , namespace ) ; } finally { deactivatePluginClassLoader ( ) ; } if ( LOG . isDebugEnabled ( ) ) { LOG . debug ( ""<== RangerAuthorizationCoprocessor.preGetNamespaceDescriptor()"" ) ; } } @ Override public void postGetNamespaceDescriptor ( ObserverContext < MasterCoprocessorEnvironment > ctx , NamespaceDescriptor ns ) throws IOException { if ( LOG . isDebugEnabled ( ) ) { LOG . debug ( ""==> RangerAuthorizationCoprocessor.postGetNamespaceDescriptor()"" ) ; } try { activatePluginClassLoader ( ) ; implMasterObserver . postGetNamespaceDescriptor ( ctx , ns ) ; } finally { deactivatePluginClassLoader ( ) ; } if ( LOG . isDebugEnabled ( ) ) { LOG . debug ( ""<== RangerAuthorizationCoprocessor.postGetNamespaceDescriptor()"" ) ; } } @ Override public void preListNamespaceDescriptors ( ObserverContext < MasterCoprocessorEnvironment > ctx , List < NamespaceDescriptor > descriptors ) throws IOException { if ( LOG . isDebugEnabled ( ) ) { LOG . debug ( ""==> RangerAuthorizationCoprocessor.preListNamespaceDescriptors()"" ) ; } try { activatePluginClassLoader ( ) ; implMasterObserver . preListNamespaceDescriptors ( ctx , descriptors ) ; } finally { deactivatePluginClassLoader ( ) ; } if ( LOG . isDebugEnabled ( ) ) { LOG . debug ( ""<== RangerAuthorizationCoprocessor.preListNamespaceDescriptors()"" ) ; } } @ Override public void postListNamespaceDescriptors ( ObserverContext < MasterCoprocessorEnvironment > ctx , List < NamespaceDescriptor > descriptors ) throws IOException { if ( LOG . isDebugEnabled ( ) ) { LOG . debug ( ""==> RangerAuthorizationCoprocessor.postListNamespaceDescriptors()"" ) ; } try { activatePluginClassLoader ( ) ; implMasterObserver . postListNamespaceDescriptors ( ctx , descriptors ) ; } finally { deactivatePluginClassLoader ( ) ; } if ( LOG . isDebugEnabled ( ) ) { LOG . debug ( ""<== RangerAuthorizationCoprocessor.postListNamespaceDescriptors()"" ) ; } } @ Override public void preTableFlush ( ObserverContext < MasterCoprocessorEnvironment > ctx , TableName tableName ) throws IOException { if ( LOG . isDebugEnabled ( ) ) { LOG . debug ( ""==> RangerAuthorizationCoprocessor.preTableFlush()"" ) ; } try { activatePluginClassLoader ( ) ; implMasterObserver . preTableFlush ( ctx , tableName ) ; } finally { deactivatePluginClassLoader ( ) ; } if ( LOG . isDebugEnabled ( ) ) { LOG . debug ( ""<== RangerAuthorizationCoprocessor.preTableFlush()"" ) ; } } @ Override public void postTableFlush ( ObserverContext < MasterCoprocessorEnvironment > ctx , TableName tableName ) throws IOException { if ( LOG . isDebugEnabled ( ) ) { LOG . debug ( ""==> RangerAuthorizationCoprocessor.postTableFlush()"" ) ; } try { activatePluginClassLoader ( ) ; implMasterObserver . postTableFlush ( ctx , tableName ) ; } finally { deactivatePluginClassLoader ( ) ; } if ( LOG . isDebugEnabled ( ) ) { LOG . debug ( ""<== RangerAuthorizationCoprocessor.postTableFlush()"" ) ; } } @ Override public void postSetUserQuota ( ObserverContext < MasterCoprocessorEnvironment > ctx , String userName , Quotas quotas ) throws IOException { if ( LOG . isDebugEnabled ( ) ) { LOG . debug ( ""==> RangerAuthorizationCoprocessor.postSetUserQuota()"" ) ; } try { activatePluginClassLoader ( ) ; implMasterObserver . postSetUserQuota ( ctx , userName , quotas ) ; } finally { deactivatePluginClassLoader ( ) ; } if ( LOG . isDebugEnabled ( ) ) { LOG . debug ( ""<== RangerAuthorizationCoprocessor.postSetUserQuota()"" ) ; } } @ Override public void postSetUserQuota ( ObserverContext < MasterCoprocessorEnvironment > ctx , String userName , TableName tableName , Quotas quotas ) throws IOException { if ( LOG . isDebugEnabled ( ) ) { LOG . debug ( ""==> RangerAuthorizationCoprocessor.postSetUserQuota()"" ) ; } try { activatePluginClassLoader ( ) ; implMasterObserver . postSetUserQuota ( ctx , userName , tableName , quotas ) ; } finally { deactivatePluginClassLoader ( ) ; } if ( LOG . isDebugEnabled ( ) ) { LOG . debug ( ""<== RangerAuthorizationCoprocessor.postSetUserQuota()"" ) ; } } @ Override public void postSetUserQuota ( ObserverContext < MasterCoprocessorEnvironment > ctx , String userName , String namespace , Quotas quotas ) throws IOException { if ( LOG . isDebugEnabled ( ) ) { LOG . debug ( ""==> RangerAuthorizationCoprocessor.postSetUserQuota()"" ) ; } try { activatePluginClassLoader ( ) ; implMasterObserver . postSetUserQuota ( ctx , userName , quotas ) ; } finally { deactivatePluginClassLoader ( ) ; } if ( LOG . isDebugEnabled ( ) ) { LOG . debug ( ""<== RangerAuthorizationCoprocessor.postSetUserQuota()"" ) ; } } @ Override public void postSetTableQuota ( ObserverContext < MasterCoprocessorEnvironment > ctx , TableName tableName , Quotas quotas ) throws IOException { if ( LOG . isDebugEnabled ( ) ) { LOG . debug ( ""==> RangerAuthorizationCoprocessor.postSetTableQuota()"" ) ; } try { activatePluginClassLoader ( ) ; implMasterObserver . postSetTableQuota ( ctx , tableName , quotas ) ; } finally { deactivatePluginClassLoader ( ) ; } if ( LOG . isDebugEnabled ( ) ) { LOG . debug ( ""<== RangerAuthorizationCoprocessor.postSetTableQuota()"" ) ; } } @ Override public void postSetNamespaceQuota ( ObserverContext < MasterCoprocessorEnvironment > ctx , String namespace , Quotas quotas ) throws IOException { if ( LOG . isDebugEnabled ( ) ) { LOG . debug ( ""==> RangerAuthorizationCoprocessor.postSetNamespaceQuota()"" ) ; } try { activatePluginClassLoader ( ) ; implMasterObserver . postSetNamespaceQuota ( ctx , namespace , quotas ) ; } finally { deactivatePluginClassLoader ( ) ; } if ( LOG . isDebugEnabled ( ) ) { LOG . debug ( ""<== RangerAuthorizationCoprocessor.postSetNamespaceQuota()"" ) ; } } @ Override public void preWALRestore ( ObserverContext < RegionCoprocessorEnvironment > ctx , HRegionInfo info , HLogKey logKey , WALEdit logEdit ) throws IOException { if ( LOG . isDebugEnabled ( ) ) { LOG . debug ( ""==> RangerAuthorizationCoprocessor.preWALRestore()"" ) ; } try { activatePluginClassLoader ( ) ; implRegionObserver . preWALRestore ( ctx , info , logKey , logEdit ) ; } finally { deactivatePluginClassLoader ( ) ; } if ( LOG . isDebugEnabled ( ) ) { LOG . debug ( ""<== RangerAuthorizationCoprocessor.preWALRestore()"" ) ; } } @ Override public void postWALRestore ( ObserverContext < RegionCoprocessorEnvironment > ctx , HRegionInfo info , HLogKey logKey , WALEdit logEdit ) throws IOException { if ( LOG . isDebugEnabled ( ) ) { LOG . debug ( ""==> RangerAuthorizationCoprocessor.postWALRestore()"" ) ; } try { activatePluginClassLoader ( ) ; implRegionObserver . postWALRestore ( ctx , info , logKey , logEdit ) ; } finally { deactivatePluginClassLoader ( ) ; } if ( LOG . isDebugEnabled ( ) ) { LOG . debug ( ""<== RangerAuthorizationCoprocessor.postWALRestore()"" ) ; } } private void activatePluginClassLoader ( ) { if ( rangerPluginClassLoader != null ) { rangerPluginClassLoader . activate ( ) ; } } private void deactivatePluginClassLoader ( ) { if ( rangerPluginClassLoader != null ) { rangerPluginClassLoader . deactivate ( ) ; } } public void preMoveServers ( final ObserverContext < MasterCoprocessorEnvironment > ctx , Set < HostAndPort > servers , String targetGroup ) throws IOException { } public void postMoveServers ( ObserverContext < MasterCoprocessorEnvironment > ctx , Set < HostAndPort > servers , String targetGroup ) throws IOException { } public void preMoveTables ( final ObserverContext < MasterCoprocessorEnvironment > ctx , Set < TableName > tables , String targetGroup ) throws IOException { } public void postMoveTables ( final ObserverContext < MasterCoprocessorEnvironment > ctx , Set < TableName > tables , String targetGroup ) throws IOException { } public void preRemoveRSGroup ( final ObserverContext < MasterCoprocessorEnvironment > ctx , String name ) throws IOException { } public void postRemoveRSGroup ( final ObserverContext < MasterCoprocessorEnvironment > ctx , String name ) throws IOException { } public void preBalanceRSGroup ( final ObserverContext < MasterCoprocessorEnvironment > ctx , String groupName ) throws IOException { } public void postBalanceRSGroup ( final ObserverContext < MasterCoprocessorEnvironment > ctx , String groupName , boolean balancerRan ) throws IOException { } public void preAddRSGroup ( ObserverContext < MasterCoprocessorEnvironment > ctx , String name ) throws IOException { } public void postAddRSGroup ( ObserverContext < MasterCoprocessorEnvironment > ctx , String name ) throws IOException { } }",Smelly
"public final class DefaultTraversalMetrics implements TraversalMetrics , Serializable { private static final String [ ] HEADERS = { ""Step"" , ""Count"" , ""Traversers"" , ""Time (ms)"" , ""% Dur"" } ; private final Map < String , ImmutableMetrics > stepIndexedMetrics = new HashMap < > ( ) ; private long totalStepDuration ; private Map < Integer , ImmutableMetrics > positionIndexedMetrics = new HashMap < > ( ) ; private volatile boolean finalized = false ; public DefaultTraversalMetrics ( ) { } public DefaultTraversalMetrics ( final long totalStepDurationNs , final List < MutableMetrics > orderedMetrics ) { totalStepDuration = totalStepDurationNs ; int ix = 0 ; for ( final MutableMetrics metric : orderedMetrics ) { stepIndexedMetrics . put ( metric . getId ( ) , metric . getImmutableClone ( ) ) ; positionIndexedMetrics . put ( ix ++ , metric . getImmutableClone ( ) ) ; } } @ Override public long getDuration ( final TimeUnit unit ) { return unit . convert ( this . totalStepDuration , MutableMetrics . SOURCE_UNIT ) ; } @ Override public Metrics getMetrics ( final int index ) { return this . positionIndexedMetrics . get ( index ) ; } @ Override public Metrics getMetrics ( final String id ) { return this . stepIndexedMetrics . get ( id ) ; } @ Override public Collection < ImmutableMetrics > getMetrics ( ) { return positionIndexedMetrics . entrySet ( ) . stream ( ) . sorted ( Map . Entry . comparingByKey ( ) ) . collect ( Collectors . toMap ( Map . Entry :: getKey , Map . Entry :: getValue , ( oldValue , newValue ) -> oldValue , LinkedHashMap :: new ) ) . values ( ) ; } public boolean isFinalized ( ) { return finalized ; } @ Override public String toString ( ) { final StringBuilder sb = new StringBuilder ( ""Traversal Metrics\n"" ) . append ( String . format ( ""%-50s %21s %11s %15s %8s"" , HEADERS ) ) ; sb . append ( ""\n============================================================================================================="" ) ; appendMetrics ( this . positionIndexedMetrics . values ( ) , sb , 0 ) ; sb . append ( String . format ( ""%n%50s %21s %11s %15.3f %8s"" , "">TOTAL"" , ""-"" , ""-"" , getDuration ( TimeUnit . MICROSECONDS ) / 1000.0 , ""-"" ) ) ; return sb . toString ( ) ; } public synchronized void setMetrics ( final Traversal . Admin traversal , final boolean onGraphComputer ) { if ( finalized ) throw new IllegalStateException ( ""Metrics have been finalized and cannot be modified"" ) ; finalized = true ; handleNestedTraversals ( traversal , null , onGraphComputer ) ; addTopLevelMetrics ( traversal , onGraphComputer ) ; } private void addTopLevelMetrics ( final Traversal . Admin traversal , final boolean onGraphComputer ) { this . totalStepDuration = 0 ; final List < ProfileStep > profileSteps = TraversalHelper . getStepsOfClass ( ProfileStep . class , traversal ) ; final List < Pair < Integer , MutableMetrics > > tempMetrics = new ArrayList < > ( profileSteps . size ( ) ) ; for ( int ii = 0 ; ii < profileSteps . size ( ) ; ii ++ ) { final ProfileStep step = profileSteps . get ( ii ) ; final MutableMetrics stepMetrics = onGraphComputer ? traversal . getSideEffects ( ) . get ( step . getId ( ) ) : step . getMetrics ( ) ; this . totalStepDuration += stepMetrics . getDuration ( MutableMetrics . SOURCE_UNIT ) ; tempMetrics . add ( Pair . with ( ii , stepMetrics . clone ( ) ) ) ; } tempMetrics . forEach ( m -> { final double dur = m . getValue1 ( ) . getDuration ( TimeUnit . NANOSECONDS ) * 100.d / this . totalStepDuration ; m . getValue1 ( ) . setAnnotation ( PERCENT_DURATION_KEY , dur ) ; } ) ; tempMetrics . forEach ( p -> { this . stepIndexedMetrics . put ( p . getValue1 ( ) . getId ( ) , p . getValue1 ( ) . getImmutableClone ( ) ) ; this . positionIndexedMetrics . put ( p . getValue0 ( ) , p . getValue1 ( ) . getImmutableClone ( ) ) ; } ) ; } private void handleNestedTraversals ( final Traversal . Admin traversal , final MutableMetrics parentMetrics , final boolean onGraphComputer ) { long prevDur = 0 ; for ( int i = 0 ; i < traversal . getSteps ( ) . size ( ) ; i ++ ) { final Step step = ( Step ) traversal . getSteps ( ) . get ( i ) ; if ( ! ( step instanceof ProfileStep ) ) continue ; final MutableMetrics metrics = onGraphComputer ? traversal . getSideEffects ( ) . get ( step . getId ( ) ) : ( ( ProfileStep ) step ) . getMetrics ( ) ; if ( null != metrics ) { if ( ! onGraphComputer ) { final long durBeforeAdjustment = metrics . getDuration ( TimeUnit . NANOSECONDS ) ; metrics . setDuration ( metrics . getDuration ( TimeUnit . NANOSECONDS ) - prevDur , TimeUnit . NANOSECONDS ) ; prevDur = durBeforeAdjustment ; } if ( parentMetrics != null ) { parentMetrics . addNested ( metrics ) ; } if ( step . getPreviousStep ( ) instanceof TraversalParent ) { for ( Traversal . Admin < ? , ? > t : ( ( TraversalParent ) step . getPreviousStep ( ) ) . getLocalChildren ( ) ) { handleNestedTraversals ( t , metrics , onGraphComputer ) ; } for ( Traversal . Admin < ? , ? > t : ( ( TraversalParent ) step . getPreviousStep ( ) ) . getGlobalChildren ( ) ) { handleNestedTraversals ( t , metrics , onGraphComputer ) ; } } } } } private void appendMetrics ( final Collection < ? extends Metrics > metrics , final StringBuilder sb , final int indent ) { for ( Metrics m : metrics ) { final StringBuilder metricName = new StringBuilder ( ) ; for ( int ii = 0 ; ii < indent ; ii ++ ) { metricName . append ( ""  "" ) ; } metricName . append ( m . getName ( ) ) ; final StringBuilder rowName = new StringBuilder ( StringUtils . abbreviate ( metricName . toString ( ) , 50 ) ) ; final Long itemCount = m . getCount ( ELEMENT_COUNT_ID ) ; final Long traverserCount = m . getCount ( TRAVERSER_COUNT_ID ) ; final Double percentDur = ( Double ) m . getAnnotation ( PERCENT_DURATION_KEY ) ; sb . append ( String . format ( ""%n%-50s"" , rowName . toString ( ) ) ) ; if ( itemCount != null ) { sb . append ( String . format ( "" %21d"" , itemCount ) ) ; } else { sb . append ( String . format ( "" %21s"" , """" ) ) ; } if ( traverserCount != null ) { sb . append ( String . format ( "" %11d"" , traverserCount ) ) ; } else { sb . append ( String . format ( "" %11s"" , """" ) ) ; } sb . append ( String . format ( "" %15.3f"" , m . getDuration ( TimeUnit . MICROSECONDS ) / 1000.0 ) ) ; if ( percentDur != null ) { sb . append ( String . format ( "" %8.2f"" , percentDur ) ) ; } final Map < String , Object > annotations = m . getAnnotations ( ) ; if ( ! annotations . isEmpty ( ) ) { annotations . entrySet ( ) . stream ( ) . filter ( kv -> ! kv . getKey ( ) . equals ( PERCENT_DURATION_KEY ) ) . forEach ( kv -> { final String prefix = ""    \\_"" ; final String separator = ""="" ; final String k = prefix + StringUtils . abbreviate ( kv . getKey ( ) , 30 ) ; final int valueIndentLen = separator . length ( ) + k . length ( ) + indent ; final int leftover = 110 - valueIndentLen ; final String [ ] splitValues = splitOnSize ( kv . getValue ( ) . toString ( ) , leftover ) ; for ( int ix = 0 ; ix < splitValues . length ; ix ++ ) { if ( ix == 0 ) { sb . append ( String . format ( ""%n%s"" , k + separator + splitValues [ ix ] ) ) ; } else { sb . append ( String . format ( ""%n%s"" , padLeft ( splitValues [ ix ] , valueIndentLen - 1 ) ) ) ; } } } ) ; } appendMetrics ( m . getNested ( ) , sb , indent + 1 ) ; } } private static String [ ] splitOnSize ( final String text , final int size ) { final String [ ] ret = new String [ ( text . length ( ) + size - 1 ) / size ] ; int counter = 0 ; for ( int start = 0 ; start < text . length ( ) ; start += size ) { ret [ counter ] = text . substring ( start , Math . min ( text . length ( ) , start + size ) ) ; counter ++ ; } return ret ; } private static String padLeft ( final String text , final int amountToPad ) { final StringBuilder newText = new StringBuilder ( ) ; for ( int ix = 0 ; ix < amountToPad ; ix ++ ) { newText . append ( "" "" ) ; } newText . append ( text ) ; return newText . toString ( ) ; } }",Smelly
"public class ValidatorComponent extends ResourceBasedComponent { protected Endpoint < Exchange > createEndpoint ( String uri , String remaining , Map parameters ) throws Exception { SpringValidator validator = new SpringValidator ( ) ; Resource resource = resolveMandatoryResource ( remaining ) ; validator . setSchemaResource ( resource ) ; if ( log . isDebugEnabled ( ) ) { log . debug ( this + "" using schema resource: "" + resource ) ; } configureValidator ( validator , uri , remaining , parameters ) ; return new ProcessorEndpoint ( uri , this , validator ) ; } protected void configureValidator ( SpringValidator validator , String uri , String remaining , Map parameters ) throws Exception { setProperties ( validator , parameters ) ; } }",No
"public class CommentServlet extends HttpServlet { private static Log log = LogFactory . getLog ( CommentServlet . class ) ; private CommentAuthenticator authenticator = null ; private CommentValidationManager commentValidationManager = null ; private GenericThrottle commentThrottle = null ; @ Override public void init ( ServletConfig servletConfig ) throws ServletException { super . init ( servletConfig ) ; log . info ( ""Initializing CommentServlet"" ) ; try { String name = WebloggerConfig . getProperty ( ""comment.authenticator.classname"" ) ; Class clazz = Class . forName ( name ) ; this . authenticator = ( CommentAuthenticator ) clazz . newInstance ( ) ; } catch ( Exception e ) { log . error ( e ) ; this . authenticator = new DefaultCommentAuthenticator ( ) ; } commentValidationManager = new CommentValidationManager ( ) ; if ( WebloggerConfig . getBooleanProperty ( ""comment.throttle.enabled"" ) ) { int threshold = 25 ; try { threshold = Integer . parseInt ( WebloggerConfig . getProperty ( ""comment.throttle.threshold"" ) ) ; } catch ( Exception e ) { log . warn ( ""bad input for config property comment.throttle.threshold"" , e ) ; } int interval = RollerConstants . MIN_IN_MS ; try { interval = Integer . parseInt ( WebloggerConfig . getProperty ( ""comment.throttle.interval"" ) ) ; interval = interval * RollerConstants . SEC_IN_MS ; } catch ( Exception e ) { log . warn ( ""bad input for config property comment.throttle.interval"" , e ) ; } int maxEntries = 250 ; try { maxEntries = Integer . parseInt ( WebloggerConfig . getProperty ( ""comment.throttle.maxentries"" ) ) ; } catch ( Exception e ) { log . warn ( ""bad input for config property comment.throttle.maxentries"" , e ) ; } commentThrottle = new GenericThrottle ( threshold , interval , maxEntries ) ; log . info ( ""Comment Throttling ENABLED"" ) ; } else { log . info ( ""Comment Throttling DISABLED"" ) ; } } @ Override public void doGet ( HttpServletRequest request , HttpServletResponse response ) throws IOException , ServletException { response . sendError ( HttpServletResponse . SC_NOT_FOUND ) ; } @ Override public void doPost ( HttpServletRequest request , HttpServletResponse response ) throws IOException , ServletException { String error = null ; String dispatch_url ; Weblog weblog ; WeblogEntry entry ; String message = null ; RollerMessages messages = new RollerMessages ( ) ; String method = request . getParameter ( ""method"" ) ; final boolean preview ; if ( method != null && method . equals ( ""preview"" ) ) { preview = true ; messages . addMessage ( ""commentServlet.previewCommentOnly"" ) ; log . debug ( ""Handling comment preview post"" ) ; } else { preview = false ; log . debug ( ""Handling regular comment post"" ) ; } if ( commentThrottle != null && commentThrottle . processHit ( request . getRemoteAddr ( ) ) ) { log . debug ( ""ABUSIVE "" + request . getRemoteAddr ( ) ) ; IPBanList . getInstance ( ) . addBannedIp ( request . getRemoteAddr ( ) ) ; response . sendError ( HttpServletResponse . SC_NOT_FOUND ) ; return ; } WeblogCommentRequest commentRequest ; try { commentRequest = new WeblogCommentRequest ( request ) ; weblog = WebloggerFactory . getWeblogger ( ) . getWeblogManager ( ) . getWeblogByHandle ( commentRequest . getWeblogHandle ( ) ) ; if ( weblog == null ) { throw new WebloggerException ( ""unable to lookup weblog: "" + commentRequest . getWeblogHandle ( ) ) ; } entry = commentRequest . getWeblogEntry ( ) ; if ( entry == null ) { throw new WebloggerException ( ""unable to lookup entry: "" + commentRequest . getWeblogAnchor ( ) ) ; } dispatch_url = ""/roller-ui/rendering/page/"" + weblog . getHandle ( ) ; if ( commentRequest . getLocale ( ) != null ) { dispatch_url += ""/"" + commentRequest . getLocale ( ) ; } dispatch_url += ""/entry/"" + URLUtilities . encode ( commentRequest . getWeblogAnchor ( ) ) ; } catch ( Exception e ) { log . debug ( ""error creating page request"" , e ) ; response . sendError ( HttpServletResponse . SC_NOT_FOUND ) ; return ; } log . debug ( ""Doing comment posting for entry = "" + entry . getPermalink ( ) ) ; WeblogEntryComment comment = new WeblogEntryComment ( ) ; comment . setName ( commentRequest . getName ( ) ) ; comment . setEmail ( commentRequest . getEmail ( ) ) ; if ( StringUtils . isNotEmpty ( commentRequest . getUrl ( ) ) ) { String theUrl = commentRequest . getUrl ( ) . trim ( ) . toLowerCase ( ) ; StringBuilder url = new StringBuilder ( ) ; if ( theUrl . startsWith ( ""http://"" ) ) { url . append ( theUrl ) ; } else if ( theUrl . startsWith ( ""https://"" ) ) { url . append ( theUrl ) ; } else { url . append ( ""http://"" ) . append ( theUrl ) ; } comment . setUrl ( url . toString ( ) ) ; } else { comment . setUrl ( """" ) ; } comment . setContent ( commentRequest . getContent ( ) ) ; comment . setNotify ( commentRequest . isNotify ( ) ) ; comment . setWeblogEntry ( entry ) ; comment . setRemoteHost ( request . getRemoteHost ( ) ) ; comment . setPostTime ( new Timestamp ( System . currentTimeMillis ( ) ) ) ; if ( WebloggerRuntimeConfig . getBooleanProperty ( ""users.comments.htmlenabled"" ) ) { comment . setContentType ( ""text/html"" ) ; } else { comment . setContentType ( ""text/plain"" ) ; } comment . setPlugins ( WebloggerRuntimeConfig . getProperty ( ""users.comments.plugins"" ) ) ; WeblogEntryCommentForm cf = new WeblogEntryCommentForm ( ) ; cf . setData ( comment ) ; if ( preview ) { cf . setPreview ( comment ) ; } I18nMessages messageUtils = I18nMessages . getMessages ( commentRequest . getLocaleInstance ( ) ) ; if ( ! entry . getCommentsStillAllowed ( ) || ! entry . isPublished ( ) ) { error = messageUtils . getString ( ""comments.disabled"" ) ; } else if ( StringUtils . isEmpty ( commentRequest . getEmail ( ) ) || StringUtils . isNotEmpty ( commentRequest . getEmail ( ) ) && ! Utilities . isValidEmailAddress ( commentRequest . getEmail ( ) ) ) { error = messageUtils . getString ( ""error.commentPostFailedEmailAddress"" ) ; log . debug ( ""Email Adddress is invalid : "" + commentRequest . getEmail ( ) ) ; } else if ( StringUtils . isNotEmpty ( comment . getUrl ( ) ) && ! new UrlValidator ( new String [ ] { ""http"" , ""https"" } ) . isValid ( comment . getUrl ( ) ) ) { error = messageUtils . getString ( ""error.commentPostFailedURL"" ) ; log . debug ( ""URL is invalid : "" + comment . getUrl ( ) ) ; } else if ( ! preview && ! this . authenticator . authenticate ( request ) ) { String [ ] msg = { request . getParameter ( ""answer"" ) } ; error = messageUtils . getString ( ""error.commentAuthFailed"" , msg ) ; log . debug ( ""Comment failed authentication"" ) ; } if ( error != null ) { cf . setError ( error ) ; request . setAttribute ( ""commentForm"" , cf ) ; RequestDispatcher dispatcher = request . getRequestDispatcher ( dispatch_url ) ; dispatcher . forward ( request , response ) ; return ; } int validationScore = commentValidationManager . validateComment ( comment , messages ) ; log . debug ( ""Comment Validation score: "" + validationScore ) ; if ( ! preview ) { if ( validationScore == RollerConstants . PERCENT_100 && weblog . getCommentModerationRequired ( ) ) { comment . setStatus ( ApprovalStatus . PENDING ) ; message = messageUtils . getString ( ""commentServlet.submittedToModerator"" ) ; } else if ( validationScore == RollerConstants . PERCENT_100 ) { comment . setStatus ( ApprovalStatus . APPROVED ) ; message = messageUtils . getString ( ""commentServlet.commentAccepted"" ) ; } else { log . debug ( ""Comment marked as spam"" ) ; comment . setStatus ( ApprovalStatus . SPAM ) ; error = messageUtils . getString ( ""commentServlet.commentMarkedAsSpam"" ) ; if ( messages . getErrorCount ( ) > 0 ) { Iterator errors = messages . getErrors ( ) ; RollerMessage errorKey ; StringBuilder buf = new StringBuilder ( ) ; buf . append ( ""<ul>"" ) ; while ( errors . hasNext ( ) ) { errorKey = ( RollerMessage ) errors . next ( ) ; buf . append ( ""<li>"" ) ; if ( errorKey . getArgs ( ) != null ) { buf . append ( messageUtils . getString ( errorKey . getKey ( ) , errorKey . getArgs ( ) ) ) ; } else { buf . append ( messageUtils . getString ( errorKey . getKey ( ) ) ) ; } buf . append ( ""</li>"" ) ; } buf . append ( ""</ul>"" ) ; error += buf . toString ( ) ; } } try { if ( ! ApprovalStatus . SPAM . equals ( comment . getStatus ( ) ) || ! WebloggerRuntimeConfig . getBooleanProperty ( ""comments.ignoreSpam.enabled"" ) ) { WeblogEntryManager mgr = WebloggerFactory . getWeblogger ( ) . getWeblogEntryManager ( ) ; mgr . saveComment ( comment ) ; WebloggerFactory . getWeblogger ( ) . flush ( ) ; boolean notifySubscribers = ( validationScore == RollerConstants . PERCENT_100 ) ; MailUtil . sendEmailNotification ( comment , messages , messageUtils , notifySubscribers ) ; if ( ! weblog . getCommentModerationRequired ( ) ) { IndexManager manager = WebloggerFactory . getWeblogger ( ) . getIndexManager ( ) ; manager . removeEntryIndexOperation ( entry ) ; if ( entry . isPublished ( ) ) { manager . addEntryIndexOperation ( entry ) ; } CacheManager . invalidate ( comment ) ; } cf = new WeblogEntryCommentForm ( ) ; } } catch ( WebloggerException re ) { log . error ( ""Error saving comment"" , re ) ; error = re . getMessage ( ) ; } } if ( error != null ) { cf . setError ( error ) ; } if ( message != null ) { cf . setMessage ( message ) ; } request . setAttribute ( ""commentForm"" , cf ) ; log . debug ( ""comment processed, forwarding to "" + dispatch_url ) ; RequestDispatcher dispatcher = request . getRequestDispatcher ( dispatch_url ) ; dispatcher . forward ( request , response ) ; } }",Smelly
"class WikipediaTokenizerImpl { public static final int YYEOF = - 1 ; private static final int ZZ_BUFFERSIZE = 16384 ; public static final int DOUBLE_BRACE_STATE = 8 ; public static final int INTERNAL_LINK_STATE = 2 ; public static final int TWO_SINGLE_QUOTES_STATE = 4 ; public static final int CATEGORY_STATE = 1 ; public static final int FIVE_SINGLE_QUOTES_STATE = 6 ; public static final int STRING = 9 ; public static final int YYINITIAL = 0 ; public static final int DOUBLE_EQUALS_STATE = 7 ; public static final int THREE_SINGLE_QUOTES_STATE = 5 ; public static final int EXTERNAL_LINK_STATE = 3 ; private static final String ZZ_CMAP_PACKED = ""\11\0\1\24\1\23\1\0\1\24\1\22\22\0\1\24\1\0\1\12"" + ""\1\53\2\0\1\3\1\1\4\0\1\14\1\5\1\2\1\10\12\16"" + ""\1\27\1\0\1\7\1\11\1\13\1\53\1\4\2\15\1\30\5\15"" + ""\1\41\21\15\1\25\1\0\1\26\1\0\1\6\1\0\1\31\1\43"" + ""\2\15\1\33\1\40\1\34\1\50\1\41\4\15\1\42\1\35\1\51"" + ""\1\15\1\36\1\52\1\32\3\15\1\44\1\37\1\15\1\45\1\47"" + ""\1\46\102\0\27\15\1\0\37\15\1\0\u0568\15\12\17\206\15\12\17"" + ""\u026c\15\12\17\166\15\12\17\166\15\12\17\166\15\12\17\166\15\12\17"" + ""\167\15\11\17\166\15\12\17\166\15\12\17\166\15\12\17\340\15\12\17"" + ""\166\15\12\17\u0166\15\12\17\266\15\u0100\15\u0e00\15\u1040\0\u0150\21\140\0"" + ""\20\21\u0100\0\200\21\200\0\u19c0\21\100\0\u5200\21\u0c00\0\u2bb0\20\u2150\0"" + ""\u0200\21\u0465\0\73\21\75\15\43\0"" ; private static final char [ ] ZZ_CMAP = zzUnpackCMap ( ZZ_CMAP_PACKED ) ; private static final int [ ] ZZ_ACTION = zzUnpackAction ( ) ; private static final String ZZ_ACTION_PACKED_0 = ""\12\0\4\1\4\2\1\3\1\1\1\4\1\1\2\5"" + ""\1\6\2\5\1\7\1\5\2\10\1\11\1\12\1\11"" + ""\1\13\1\14\1\10\1\15\1\16\1\15\1\17\1\20"" + ""\1\10\1\21\1\10\4\22\1\23\1\22\1\24\1\25"" + ""\1\26\3\0\1\27\14\0\1\30\1\31\1\32\1\33"" + ""\1\11\1\0\1\34\1\35\1\0\1\36\1\0\1\37"" + ""\3\0\1\40\1\41\2\42\1\41\2\43\2\0\1\42"" + ""\1\0\14\42\1\41\3\0\1\11\1\44\3\0\1\45"" + ""\1\46\5\0\1\47\4\0\1\47\2\0\2\47\2\0"" + ""\1\11\5\0\1\31\1\41\1\42\1\50\3\0\1\11"" + ""\2\0\1\51\30\0\1\52\2\0\1\53\1\54\1\55"" ; private static int [ ] zzUnpackAction ( ) { int [ ] result = new int [ 183 ] ; int offset = 0 ; offset = zzUnpackAction ( ZZ_ACTION_PACKED_0 , offset , result ) ; return result ; } private static int zzUnpackAction ( String packed , int offset , int [ ] result ) { int i = 0 ; int j = offset ; int l = packed . length ( ) ; while ( i < l ) { int count = packed . charAt ( i ++ ) ; int value = packed . charAt ( i ++ ) ; do result [ j ++ ] = value ; while ( -- count > 0 ) ; } return j ; } private static final int [ ] ZZ_ROWMAP = zzUnpackRowMap ( ) ; private static final String ZZ_ROWMAP_PACKED_0 = ""\0\0\0\54\0\130\0\204\0\260\0\334\0\u0108\0\u0134"" + ""\0\u0160\0\u018c\0\u01b8\0\u01e4\0\u0210\0\u023c\0\u0268\0\u0294"" + ""\0\u02c0\0\u02ec\0\u01b8\0\u0318\0\u0344\0\u0370\0\u01b8\0\u039c"" + ""\0\u03c8\0\u03f4\0\u0420\0\u044c\0\u0478\0\u01b8\0\u039c\0\u04a4"" + ""\0\u01b8\0\u04d0\0\u04fc\0\u0528\0\u0554\0\u0580\0\u05ac\0\u05d8"" + ""\0\u0604\0\u0630\0\u065c\0\u0688\0\u06b4\0\u01b8\0\u06e0\0\u039c"" + ""\0\u070c\0\u0738\0\u0764\0\u0790\0\u01b8\0\u01b8\0\u07bc\0\u07e8"" + ""\0\u0814\0\u01b8\0\u0840\0\u086c\0\u0898\0\u08c4\0\u08f0\0\u091c"" + ""\0\u0948\0\u0974\0\u09a0\0\u09cc\0\u09f8\0\u0a24\0\u0a50\0\u0a7c"" + ""\0\u01b8\0\u01b8\0\u0aa8\0\u0ad4\0\u0b00\0\u0b00\0\u0b2c\0\u0b58"" + ""\0\u0b84\0\u0bb0\0\u0bdc\0\u0c08\0\u0c34\0\u0c60\0\u0c8c\0\u0cb8"" + ""\0\u0ce4\0\u0d10\0\u0898\0\u0d3c\0\u0d68\0\u0d94\0\u0dc0\0\u0dec"" + ""\0\u0e18\0\u0e44\0\u0e70\0\u0e9c\0\u0ec8\0\u0ef4\0\u0f20\0\u0f4c"" + ""\0\u0f78\0\u0fa4\0\u0fd0\0\u0ffc\0\u1028\0\u1054\0\u1080\0\u10ac"" + ""\0\u10d8\0\u01b8\0\u1104\0\u1130\0\u115c\0\u1188\0\u01b8\0\u11b4"" + ""\0\u11e0\0\u120c\0\u1238\0\u1264\0\u1290\0\u12bc\0\u12e8\0\u1314"" + ""\0\u1340\0\u136c\0\u1398\0\u13c4\0\u086c\0\u09f8\0\u13f0\0\u141c"" + ""\0\u1448\0\u1474\0\u14a0\0\u14cc\0\u14f8\0\u1524\0\u01b8\0\u1550"" + ""\0\u157c\0\u15a8\0\u15d4\0\u1600\0\u162c\0\u1658\0\u1684\0\u16b0"" + ""\0\u01b8\0\u16dc\0\u1708\0\u1734\0\u1760\0\u178c\0\u17b8\0\u17e4"" + ""\0\u1810\0\u183c\0\u1868\0\u1894\0\u18c0\0\u18ec\0\u1918\0\u1944"" + ""\0\u1970\0\u199c\0\u19c8\0\u19f4\0\u1a20\0\u1a4c\0\u1a78\0\u1aa4"" + ""\0\u1ad0\0\u1afc\0\u1b28\0\u1b54\0\u01b8\0\u01b8\0\u01b8"" ; private static int [ ] zzUnpackRowMap ( ) { int [ ] result = new int [ 183 ] ; int offset = 0 ; offset = zzUnpackRowMap ( ZZ_ROWMAP_PACKED_0 , offset , result ) ; return result ; } private static int zzUnpackRowMap ( String packed , int offset , int [ ] result ) { int i = 0 ; int j = offset ; int l = packed . length ( ) ; while ( i < l ) { int high = packed . charAt ( i ++ ) < < 16 ; result [ j ++ ] = high | packed . charAt ( i ++ ) ; } return j ; } private static final int [ ] ZZ_TRANS = zzUnpackTrans ( ) ; private static final String ZZ_TRANS_PACKED_0 = ""\1\13\1\14\5\13\1\15\1\13\1\16\3\13\1\17"" + ""\1\20\1\21\1\22\1\23\1\24\2\13\1\25\2\13"" + ""\15\17\1\26\2\13\3\17\1\13\7\27\1\30\5\27"" + ""\4\31\1\27\1\32\3\27\1\33\1\27\15\31\3\27"" + ""\3\31\10\27\1\30\5\27\4\34\1\27\1\32\3\27"" + ""\1\35\1\27\15\34\3\27\3\34\1\27\7\36\1\37"" + ""\5\36\4\40\1\36\1\32\2\27\1\36\1\41\1\36"" + ""\15\40\3\36\1\42\2\40\2\36\1\43\5\36\1\37"" + ""\5\36\4\44\1\36\1\45\2\36\1\46\2\36\15\44"" + ""\3\36\3\44\10\36\1\37\5\36\4\47\1\36\1\45"" + ""\2\36\1\46\2\36\15\47\3\36\3\47\10\36\1\37"" + ""\5\36\4\47\1\36\1\45\2\36\1\50\2\36\15\47"" + ""\3\36\3\47\10\36\1\37\1\36\1\51\3\36\4\52"" + ""\1\36\1\45\5\36\15\52\3\36\3\52\10\36\1\53"" + ""\5\36\4\54\1\36\1\45\5\36\15\54\1\36\1\55"" + ""\1\36\3\54\1\36\1\56\1\57\5\56\1\60\1\56"" + ""\1\61\3\56\4\62\1\56\1\63\2\56\1\64\2\56"" + ""\15\62\2\56\1\65\3\62\1\56\55\0\1\66\62\0"" + ""\1\67\4\0\4\70\7\0\6\70\1\71\6\70\3\0"" + ""\3\70\12\0\1\72\43\0\1\73\1\74\1\75\1\76"" + ""\2\77\1\0\1\100\3\0\1\100\1\17\1\20\1\21"" + ""\1\22\7\0\15\17\3\0\3\17\3\0\1\101\1\0"" + ""\1\102\2\103\1\0\1\104\3\0\1\104\3\20\1\22"" + ""\7\0\15\20\3\0\3\20\2\0\1\73\1\105\1\75"" + ""\1\76\2\103\1\0\1\104\3\0\1\104\1\21\1\20"" + ""\1\21\1\22\7\0\15\21\3\0\3\21\3\0\1\106"" + ""\1\0\1\102\2\77\1\0\1\100\3\0\1\100\4\22"" + ""\7\0\15\22\3\0\3\22\24\0\1\13\55\0\1\107"" + ""\73\0\1\110\16\0\1\67\4\0\4\70\7\0\15\70"" + ""\3\0\3\70\16\0\4\31\7\0\15\31\3\0\3\31"" + ""\24\0\1\27\56\0\1\111\42\0\4\34\7\0\15\34"" + ""\3\0\3\34\27\0\1\112\42\0\4\40\7\0\15\40"" + ""\3\0\3\40\16\0\4\40\7\0\2\40\1\113\12\40"" + ""\3\0\3\40\2\0\1\114\67\0\4\44\7\0\15\44"" + ""\3\0\3\44\24\0\1\36\55\0\1\115\43\0\4\47"" + ""\7\0\15\47\3\0\3\47\26\0\1\116\37\0\1\111"" + ""\57\0\4\52\7\0\15\52\3\0\3\52\11\0\1\117"" + ""\4\0\4\70\7\0\15\70\3\0\3\70\16\0\4\54"" + ""\7\0\15\54\3\0\3\54\47\0\1\111\6\0\1\120"" + ""\63\0\1\121\57\0\4\62\7\0\15\62\3\0\3\62"" + ""\24\0\1\56\55\0\1\122\43\0\4\70\7\0\15\70"" + ""\3\0\3\70\14\0\1\36\1\0\4\123\1\0\3\124"" + ""\3\0\15\123\3\0\3\123\14\0\1\36\1\0\4\123"" + ""\1\0\3\124\3\0\3\123\1\125\11\123\3\0\3\123"" + ""\16\0\1\126\1\0\1\126\10\0\15\126\3\0\3\126"" + ""\16\0\1\127\1\130\1\131\1\132\7\0\15\127\3\0"" + ""\3\127\16\0\1\133\1\0\1\133\10\0\15\133\3\0"" + ""\3\133\16\0\1\134\1\135\1\134\1\135\7\0\15\134"" + ""\3\0\3\134\16\0\1\136\2\137\1\140\7\0\15\136"" + ""\3\0\3\136\16\0\1\100\2\141\10\0\15\100\3\0"" + ""\3\100\16\0\1\142\2\143\1\144\7\0\15\142\3\0"" + ""\3\142\16\0\4\135\7\0\15\135\3\0\3\135\16\0"" + ""\1\145\2\146\1\147\7\0\15\145\3\0\3\145\16\0"" + ""\1\150\2\151\1\152\7\0\15\150\3\0\3\150\16\0"" + ""\1\153\1\143\1\154\1\144\7\0\15\153\3\0\3\153"" + ""\16\0\1\155\2\130\1\132\7\0\15\155\3\0\3\155"" + ""\30\0\1\156\1\157\64\0\1\160\27\0\4\40\7\0"" + ""\2\40\1\161\12\40\3\0\3\40\2\0\1\162\101\0"" + ""\1\163\1\164\40\0\4\70\7\0\6\70\1\165\6\70"" + ""\3\0\3\70\2\0\1\166\63\0\1\167\71\0\1\170"" + ""\1\171\34\0\1\172\1\0\1\36\1\0\4\123\1\0"" + ""\3\124\3\0\15\123\3\0\3\123\16\0\4\173\1\0"" + ""\3\124\3\0\15\173\3\0\3\173\12\0\1\172\1\0"" + ""\1\36\1\0\4\123\1\0\3\124\3\0\10\123\1\174"" + ""\4\123\3\0\3\123\2\0\1\73\13\0\1\126\1\0"" + ""\1\126\10\0\15\126\3\0\3\126\3\0\1\175\1\0"" + ""\1\102\2\176\6\0\1\127\1\130\1\131\1\132\7\0"" + ""\15\127\3\0\3\127\3\0\1\177\1\0\1\102\2\200"" + ""\1\0\1\201\3\0\1\201\3\130\1\132\7\0\15\130"" + ""\3\0\3\130\3\0\1\202\1\0\1\102\2\200\1\0"" + ""\1\201\3\0\1\201\1\131\1\130\1\131\1\132\7\0"" + ""\15\131\3\0\3\131\3\0\1\203\1\0\1\102\2\176"" + ""\6\0\4\132\7\0\15\132\3\0\3\132\3\0\1\204"" + ""\2\0\1\204\7\0\1\134\1\135\1\134\1\135\7\0"" + ""\15\134\3\0\3\134\3\0\1\204\2\0\1\204\7\0"" + ""\4\135\7\0\15\135\3\0\3\135\3\0\1\176\1\0"" + ""\1\102\2\176\6\0\1\136\2\137\1\140\7\0\15\136"" + ""\3\0\3\136\3\0\1\200\1\0\1\102\2\200\1\0"" + ""\1\201\3\0\1\201\3\137\1\140\7\0\15\137\3\0"" + ""\3\137\3\0\1\176\1\0\1\102\2\176\6\0\4\140"" + ""\7\0\15\140\3\0\3\140\3\0\1\201\2\0\2\201"" + ""\1\0\1\201\3\0\1\201\3\141\10\0\15\141\3\0"" + ""\3\141\3\0\1\106\1\0\1\102\2\77\1\0\1\100"" + ""\3\0\1\100\1\142\2\143\1\144\7\0\15\142\3\0"" + ""\3\142\3\0\1\101\1\0\1\102\2\103\1\0\1\104"" + ""\3\0\1\104\3\143\1\144\7\0\15\143\3\0\3\143"" + ""\3\0\1\106\1\0\1\102\2\77\1\0\1\100\3\0"" + ""\1\100\4\144\7\0\15\144\3\0\3\144\3\0\1\77"" + ""\1\0\1\102\2\77\1\0\1\100\3\0\1\100\1\145"" + ""\2\146\1\147\7\0\15\145\3\0\3\145\3\0\1\103"" + ""\1\0\1\102\2\103\1\0\1\104\3\0\1\104\3\146"" + ""\1\147\7\0\15\146\3\0\3\146\3\0\1\77\1\0"" + ""\1\102\2\77\1\0\1\100\3\0\1\100\4\147\7\0"" + ""\15\147\3\0\3\147\3\0\1\100\2\0\2\100\1\0"" + ""\1\100\3\0\1\100\1\150\2\151\1\152\7\0\15\150"" + ""\3\0\3\150\3\0\1\104\2\0\2\104\1\0\1\104"" + ""\3\0\1\104\3\151\1\152\7\0\15\151\3\0\3\151"" + ""\3\0\1\100\2\0\2\100\1\0\1\100\3\0\1\100"" + ""\4\152\7\0\15\152\3\0\3\152\3\0\1\205\1\0"" + ""\1\102\2\77\1\0\1\100\3\0\1\100\1\153\1\143"" + ""\1\154\1\144\7\0\15\153\3\0\3\153\3\0\1\206"" + ""\1\0\1\102\2\103\1\0\1\104\3\0\1\104\1\154"" + ""\1\143\1\154\1\144\7\0\15\154\3\0\3\154\3\0"" + ""\1\203\1\0\1\102\2\176\6\0\1\155\2\130\1\132"" + ""\7\0\15\155\3\0\3\155\31\0\1\157\54\0\1\207"" + ""\64\0\1\210\26\0\4\40\7\0\15\40\3\0\1\40"" + ""\1\211\1\40\31\0\1\164\54\0\1\212\35\0\1\36"" + ""\1\0\4\123\1\0\3\124\3\0\3\123\1\213\11\123"" + ""\3\0\3\123\2\0\1\214\102\0\1\171\54\0\1\215"" + ""\34\0\1\216\52\0\1\172\3\0\4\173\7\0\15\173"" + ""\3\0\3\173\12\0\1\172\1\0\1\217\1\0\4\123"" + ""\1\0\3\124\3\0\15\123\3\0\3\123\16\0\1\220"" + ""\1\132\1\220\1\132\7\0\15\220\3\0\3\220\16\0"" + ""\4\140\7\0\15\140\3\0\3\140\16\0\4\144\7\0"" + ""\15\144\3\0\3\144\16\0\4\147\7\0\15\147\3\0"" + ""\3\147\16\0\4\152\7\0\15\152\3\0\3\152\16\0"" + ""\1\221\1\144\1\221\1\144\7\0\15\221\3\0\3\221"" + ""\16\0\4\132\7\0\15\132\3\0\3\132\16\0\4\222"" + ""\7\0\15\222\3\0\3\222\33\0\1\223\61\0\1\224"" + ""\30\0\4\40\6\0\1\225\15\40\3\0\2\40\1\226"" + ""\33\0\1\227\32\0\1\172\1\0\1\36\1\0\4\123"" + ""\1\0\3\124\3\0\10\123\1\230\4\123\3\0\3\123"" + ""\2\0\1\231\104\0\1\232\36\0\4\233\7\0\15\233"" + ""\3\0\3\233\3\0\1\175\1\0\1\102\2\176\6\0"" + ""\1\220\1\132\1\220\1\132\7\0\15\220\3\0\3\220"" + ""\3\0\1\205\1\0\1\102\2\77\1\0\1\100\3\0"" + ""\1\100\1\221\1\144\1\221\1\144\7\0\15\221\3\0"" + ""\3\221\3\0\1\204\2\0\1\204\7\0\4\222\7\0"" + ""\15\222\3\0\3\222\34\0\1\234\55\0\1\235\26\0"" + ""\1\236\60\0\4\40\6\0\1\225\15\40\3\0\3\40"" + ""\34\0\1\237\31\0\1\172\1\0\1\111\1\0\4\123"" + ""\1\0\3\124\3\0\15\123\3\0\3\123\34\0\1\240"" + ""\32\0\1\241\2\0\4\233\7\0\15\233\3\0\3\233"" + ""\35\0\1\242\62\0\1\243\20\0\1\244\77\0\1\245"" + ""\53\0\1\246\32\0\1\36\1\0\4\173\1\0\3\124"" + ""\3\0\15\173\3\0\3\173\36\0\1\247\53\0\1\250"" + ""\33\0\4\251\7\0\15\251\3\0\3\251\36\0\1\252"" + ""\53\0\1\253\54\0\1\254\61\0\1\255\11\0\1\256"" + ""\12\0\4\251\7\0\15\251\3\0\3\251\37\0\1\257"" + ""\53\0\1\260\54\0\1\261\22\0\1\13\62\0\4\262"" + ""\7\0\15\262\3\0\3\262\40\0\1\263\53\0\1\264"" + ""\43\0\1\265\26\0\2\262\1\0\2\262\1\0\2\262"" + ""\2\0\5\262\7\0\15\262\3\0\4\262\27\0\1\266"" + ""\53\0\1\267\24\0"" ; private static int [ ] zzUnpackTrans ( ) { int [ ] result = new int [ 7040 ] ; int offset = 0 ; offset = zzUnpackTrans ( ZZ_TRANS_PACKED_0 , offset , result ) ; return result ; } private static int zzUnpackTrans ( String packed , int offset , int [ ] result ) { int i = 0 ; int j = offset ; int l = packed . length ( ) ; while ( i < l ) { int count = packed . charAt ( i ++ ) ; int value = packed . charAt ( i ++ ) ; value -- ; do result [ j ++ ] = value ; while ( -- count > 0 ) ; } return j ; } private static final int ZZ_UNKNOWN_ERROR = 0 ; private static final int ZZ_NO_MATCH = 1 ; private static final int ZZ_PUSHBACK_2BIG = 2 ; private static final String ZZ_ERROR_MSG [ ] = { ""Unkown internal scanner error"" , ""Error: could not match input"" , ""Error: pushback value was too large"" } ; private static final int [ ] ZZ_ATTRIBUTE = zzUnpackAttribute ( ) ; private static final String ZZ_ATTRIBUTE_PACKED_0 = ""\12\0\1\11\7\1\1\11\3\1\1\11\6\1\1\11"" + ""\2\1\1\11\14\1\1\11\6\1\2\11\3\0\1\11"" + ""\14\0\2\1\2\11\1\1\1\0\2\1\1\0\1\1"" + ""\1\0\1\1\3\0\7\1\2\0\1\1\1\0\15\1"" + ""\3\0\1\1\1\11\3\0\1\1\1\11\5\0\1\1"" + ""\4\0\1\1\2\0\2\1\2\0\1\1\5\0\1\11"" + ""\3\1\3\0\1\1\2\0\1\11\30\0\1\1\2\0"" + ""\3\11"" ; private static int [ ] zzUnpackAttribute ( ) { int [ ] result = new int [ 183 ] ; int offset = 0 ; offset = zzUnpackAttribute ( ZZ_ATTRIBUTE_PACKED_0 , offset , result ) ; return result ; } private static int zzUnpackAttribute ( String packed , int offset , int [ ] result ) { int i = 0 ; int j = offset ; int l = packed . length ( ) ; while ( i < l ) { int count = packed . charAt ( i ++ ) ; int value = packed . charAt ( i ++ ) ; do result [ j ++ ] = value ; while ( -- count > 0 ) ; } return j ; } private java . io . Reader zzReader ; private int zzState ; private int zzLexicalState = YYINITIAL ; private char zzBuffer [ ] = new char [ ZZ_BUFFERSIZE ] ; private int zzMarkedPos ; private int zzPushbackPos ; private int zzCurrentPos ; private int zzStartRead ; private int zzEndRead ; private int yyline ; private int yychar ; private int yycolumn ; private boolean zzAtBOL = true ; private boolean zzAtEOF ; public static final int ALPHANUM = WikipediaTokenizer . ALPHANUM_ID ; public static final int APOSTROPHE = WikipediaTokenizer . APOSTROPHE_ID ; public static final int ACRONYM = WikipediaTokenizer . ACRONYM_ID ; public static final int COMPANY = WikipediaTokenizer . COMPANY_ID ; public static final int EMAIL = WikipediaTokenizer . EMAIL_ID ; public static final int HOST = WikipediaTokenizer . HOST_ID ; public static final int NUM = WikipediaTokenizer . NUM_ID ; public static final int CJ = WikipediaTokenizer . CJ_ID ; public static final int INTERNAL_LINK = WikipediaTokenizer . INTERNAL_LINK_ID ; public static final int EXTERNAL_LINK = WikipediaTokenizer . EXTERNAL_LINK_ID ; public static final int CITATION = WikipediaTokenizer . CITATION_ID ; public static final int CATEGORY = WikipediaTokenizer . CATEGORY_ID ; public static final int BOLD = WikipediaTokenizer . BOLD_ID ; public static final int ITALICS = WikipediaTokenizer . ITALICS_ID ; public static final int BOLD_ITALICS = WikipediaTokenizer . BOLD_ITALICS_ID ; public static final int HEADING = WikipediaTokenizer . HEADING_ID ; public static final int SUB_HEADING = WikipediaTokenizer . SUB_HEADING_ID ; public static final int EXTERNAL_LINK_URL = WikipediaTokenizer . EXTERNAL_LINK_URL_ID ; private int currentTokType ; private int numBalanced = 0 ; private int positionInc = 1 ; private int numLinkToks = 0 ; private int numWikiTokensSeen = 0 ; public static final String [ ] TOKEN_TYPES = WikipediaTokenizer . TOKEN_TYPES ; public final int getNumWikiTokensSeen ( ) { return numWikiTokensSeen ; } public final int yychar ( ) { return yychar ; } public final int getPositionIncrement ( ) { return positionInc ; } final void getText ( Token t ) { t . setTermBuffer ( zzBuffer , zzStartRead , zzMarkedPos - zzStartRead ) ; } final int setText ( StringBuffer buffer ) { int length = zzMarkedPos - zzStartRead ; buffer . append ( zzBuffer , zzStartRead , length ) ; return length ; } WikipediaTokenizerImpl ( java . io . Reader in ) { this . zzReader = in ; } WikipediaTokenizerImpl ( java . io . InputStream in ) { this ( new java . io . InputStreamReader ( in ) ) ; } private static char [ ] zzUnpackCMap ( String packed ) { char [ ] map = new char [ 0x10000 ] ; int i = 0 ; int j = 0 ; while ( i < 230 ) { int count = packed . charAt ( i ++ ) ; char value = packed . charAt ( i ++ ) ; do map [ j ++ ] = value ; while ( -- count > 0 ) ; } return map ; } private boolean zzRefill ( ) throws java . io . IOException { if ( zzStartRead > 0 ) { System . arraycopy ( zzBuffer , zzStartRead , zzBuffer , 0 , zzEndRead - zzStartRead ) ; zzEndRead -= zzStartRead ; zzCurrentPos -= zzStartRead ; zzMarkedPos -= zzStartRead ; zzPushbackPos -= zzStartRead ; zzStartRead = 0 ; } if ( zzCurrentPos >= zzBuffer . length ) { char newBuffer [ ] = new char [ zzCurrentPos * 2 ] ; System . arraycopy ( zzBuffer , 0 , newBuffer , 0 , zzBuffer . length ) ; zzBuffer = newBuffer ; } int numRead = zzReader . read ( zzBuffer , zzEndRead , zzBuffer . length - zzEndRead ) ; if ( numRead < 0 ) { return true ; } else { zzEndRead += numRead ; return false ; } } public final void yyclose ( ) throws java . io . IOException { zzAtEOF = true ; zzEndRead = zzStartRead ; if ( zzReader != null ) zzReader . close ( ) ; } public final void yyreset ( java . io . Reader reader ) { zzReader = reader ; zzAtBOL = true ; zzAtEOF = false ; zzEndRead = zzStartRead = 0 ; zzCurrentPos = zzMarkedPos = zzPushbackPos = 0 ; yyline = yychar = yycolumn = 0 ; zzLexicalState = YYINITIAL ; } public final int yystate ( ) { return zzLexicalState ; } public final void yybegin ( int newState ) { zzLexicalState = newState ; } public final String yytext ( ) { return new String ( zzBuffer , zzStartRead , zzMarkedPos - zzStartRead ) ; } public final char yycharat ( int pos ) { return zzBuffer [ zzStartRead + pos ] ; } public final int yylength ( ) { return zzMarkedPos - zzStartRead ; } private void zzScanError ( int errorCode ) { String message ; try { message = ZZ_ERROR_MSG [ errorCode ] ; } catch ( ArrayIndexOutOfBoundsException e ) { message = ZZ_ERROR_MSG [ ZZ_UNKNOWN_ERROR ] ; } throw new Error ( message ) ; } public void yypushback ( int number ) { if ( number > yylength ( ) ) zzScanError ( ZZ_PUSHBACK_2BIG ) ; zzMarkedPos -= number ; } public int getNextToken ( ) throws java . io . IOException { int zzInput ; int zzAction ; int zzCurrentPosL ; int zzMarkedPosL ; int zzEndReadL = zzEndRead ; char [ ] zzBufferL = zzBuffer ; char [ ] zzCMapL = ZZ_CMAP ; int [ ] zzTransL = ZZ_TRANS ; int [ ] zzRowMapL = ZZ_ROWMAP ; int [ ] zzAttrL = ZZ_ATTRIBUTE ; while ( true ) { zzMarkedPosL = zzMarkedPos ; yychar += zzMarkedPosL - zzStartRead ; zzAction = - 1 ; zzCurrentPosL = zzCurrentPos = zzStartRead = zzMarkedPosL ; zzState = zzLexicalState ; zzForAction : { while ( true ) { if ( zzCurrentPosL < zzEndReadL ) zzInput = zzBufferL [ zzCurrentPosL ++ ] ; else if ( zzAtEOF ) { zzInput = YYEOF ; break zzForAction ; } else { zzCurrentPos = zzCurrentPosL ; zzMarkedPos = zzMarkedPosL ; boolean eof = zzRefill ( ) ; zzCurrentPosL = zzCurrentPos ; zzMarkedPosL = zzMarkedPos ; zzBufferL = zzBuffer ; zzEndReadL = zzEndRead ; if ( eof ) { zzInput = YYEOF ; break zzForAction ; } else { zzInput = zzBufferL [ zzCurrentPosL ++ ] ; } } int zzNext = zzTransL [ zzRowMapL [ zzState ] + zzCMapL [ zzInput ] ] ; if ( zzNext == - 1 ) break zzForAction ; zzState = zzNext ; int zzAttributes = zzAttrL [ zzState ] ; if ( ( zzAttributes & 1 ) == 1 ) { zzAction = zzState ; zzMarkedPosL = zzCurrentPosL ; if ( ( zzAttributes & 8 ) == 8 ) break zzForAction ; } } } zzMarkedPos = zzMarkedPosL ; switch ( zzAction < 0 ? zzAction : ZZ_ACTION [ zzAction ] ) { case 8 : { } case 46 : break ; case 28 : { currentTokType = INTERNAL_LINK ; numWikiTokensSeen = 0 ; yybegin ( INTERNAL_LINK_STATE ) ; } case 47 : break ; case 3 : { positionInc = 1 ; return CJ ; } case 48 : break ; case 30 : { numBalanced = 0 ; currentTokType = ALPHANUM ; yybegin ( YYINITIAL ) ; } case 49 : break ; case 10 : { numLinkToks = 0 ; positionInc = 0 ; yybegin ( YYINITIAL ) ; } case 50 : break ; case 41 : { numBalanced = 0 ; currentTokType = ALPHANUM ; yybegin ( YYINITIAL ) ; } case 51 : break ; case 7 : { yybegin ( INTERNAL_LINK_STATE ) ; numWikiTokensSeen ++ ; return currentTokType ; } case 52 : break ; case 23 : { numWikiTokensSeen = 0 ; positionInc = 1 ; yybegin ( DOUBLE_EQUALS_STATE ) ; } case 53 : break ; case 38 : { numBalanced = 0 ; currentTokType = ALPHANUM ; yybegin ( YYINITIAL ) ; } case 54 : break ; case 17 : { yybegin ( DOUBLE_BRACE_STATE ) ; numWikiTokensSeen = 0 ; return currentTokType ; } case 55 : break ; case 24 : { numWikiTokensSeen = 0 ; positionInc = 1 ; currentTokType = INTERNAL_LINK ; yybegin ( INTERNAL_LINK_STATE ) ; } case 56 : break ; case 14 : { yybegin ( STRING ) ; numWikiTokensSeen ++ ; return currentTokType ; } case 57 : break ; case 5 : { positionInc = 1 ; } case 58 : break ; case 43 : { numWikiTokensSeen = 0 ; positionInc = 1 ; currentTokType = CATEGORY ; yybegin ( CATEGORY_STATE ) ; } case 59 : break ; case 26 : { yybegin ( YYINITIAL ) ; } case 60 : break ; case 20 : { numBalanced = 0 ; numWikiTokensSeen = 0 ; currentTokType = EXTERNAL_LINK ; yybegin ( EXTERNAL_LINK_STATE ) ; } case 61 : break ; case 1 : { numWikiTokensSeen = 0 ; positionInc = 1 ; } case 62 : break ; case 40 : { positionInc = 1 ; return EMAIL ; } case 63 : break ; case 25 : { numWikiTokensSeen = 0 ; positionInc = 1 ; currentTokType = CITATION ; yybegin ( DOUBLE_BRACE_STATE ) ; } case 64 : break ; case 39 : { positionInc = 1 ; return ACRONYM ; } case 65 : break ; case 9 : { if ( numLinkToks == 0 ) { positionInc = 0 ; } else { positionInc = 1 ; } numWikiTokensSeen ++ ; currentTokType = EXTERNAL_LINK ; yybegin ( EXTERNAL_LINK_STATE ) ; numLinkToks ++ ; return currentTokType ; } case 66 : break ; case 22 : { numWikiTokensSeen = 0 ; positionInc = 1 ; if ( numBalanced == 0 ) { numBalanced ++ ; yybegin ( TWO_SINGLE_QUOTES_STATE ) ; } else { numBalanced = 0 ; } } case 67 : break ; case 31 : { numBalanced = 0 ; numWikiTokensSeen = 0 ; currentTokType = INTERNAL_LINK ; yybegin ( INTERNAL_LINK_STATE ) ; } case 68 : break ; case 15 : { currentTokType = SUB_HEADING ; numWikiTokensSeen = 0 ; yybegin ( STRING ) ; } case 69 : break ; case 18 : { } case 70 : break ; case 42 : { positionInc = 1 ; numWikiTokensSeen ++ ; yybegin ( EXTERNAL_LINK_STATE ) ; return currentTokType ; } case 71 : break ; case 21 : { yybegin ( STRING ) ; return currentTokType ; } case 72 : break ; case 37 : { numBalanced = 0 ; currentTokType = ALPHANUM ; yybegin ( YYINITIAL ) ; } case 73 : break ; case 33 : { positionInc = 1 ; return HOST ; } case 74 : break ; case 45 : { numBalanced = 0 ; numWikiTokensSeen = 0 ; currentTokType = CATEGORY ; yybegin ( CATEGORY_STATE ) ; } case 75 : break ; case 36 : { currentTokType = BOLD_ITALICS ; yybegin ( FIVE_SINGLE_QUOTES_STATE ) ; } case 76 : break ; case 13 : { currentTokType = EXTERNAL_LINK ; numWikiTokensSeen = 0 ; yybegin ( EXTERNAL_LINK_STATE ) ; } case 77 : break ; case 16 : { currentTokType = HEADING ; yybegin ( DOUBLE_EQUALS_STATE ) ; numWikiTokensSeen ++ ; return currentTokType ; } case 78 : break ; case 12 : { currentTokType = ITALICS ; numWikiTokensSeen ++ ; yybegin ( STRING ) ; return currentTokType ; } case 79 : break ; case 6 : { yybegin ( CATEGORY_STATE ) ; numWikiTokensSeen ++ ; return currentTokType ; } case 80 : break ; case 32 : { positionInc = 1 ; return APOSTROPHE ; } case 81 : break ; case 19 : { yybegin ( STRING ) ; numWikiTokensSeen ++ ; return currentTokType ; } case 82 : break ; case 34 : { positionInc = 1 ; return NUM ; } case 83 : break ; case 44 : { currentTokType = CATEGORY ; numWikiTokensSeen = 0 ; yybegin ( CATEGORY_STATE ) ; } case 84 : break ; case 2 : { positionInc = 1 ; return ALPHANUM ; } case 85 : break ; case 35 : { positionInc = 1 ; return COMPANY ; } case 86 : break ; case 11 : { currentTokType = BOLD ; yybegin ( THREE_SINGLE_QUOTES_STATE ) ; } case 87 : break ; case 29 : { currentTokType = INTERNAL_LINK ; numWikiTokensSeen = 0 ; yybegin ( INTERNAL_LINK_STATE ) ; } case 88 : break ; case 4 : { numWikiTokensSeen = 0 ; positionInc = 1 ; currentTokType = EXTERNAL_LINK_URL ; yybegin ( EXTERNAL_LINK_STATE ) ; } case 89 : break ; case 27 : { numLinkToks = 0 ; yybegin ( YYINITIAL ) ; } case 90 : break ; default : if ( zzInput == YYEOF && zzStartRead == zzCurrentPos ) { zzAtEOF = true ; return YYEOF ; } else { zzScanError ( ZZ_NO_MATCH ) ; } } } } }",Smelly
" private static class SaslClientCallbackHandler implements CallbackHandler { private final String userName ; private final char [ ] userPassword ; public SaslClientCallbackHandler ( Token < ? extends TokenIdentifier > token ) { this . userName = SaslRpcServer . encodeIdentifier ( token . getIdentifier ( ) ) ; this . userPassword = SaslRpcServer . encodePassword ( token . getPassword ( ) ) ; } @ Override public void handle ( Callback [ ] callbacks ) throws UnsupportedCallbackException { NameCallback nc = null ; PasswordCallback pc = null ; RealmCallback rc = null ; for ( Callback callback : callbacks ) { if ( callback instanceof RealmChoiceCallback ) { continue ; } else if ( callback instanceof NameCallback ) { nc = ( NameCallback ) callback ; } else if ( callback instanceof PasswordCallback ) { pc = ( PasswordCallback ) callback ; } else if ( callback instanceof RealmCallback ) { rc = ( RealmCallback ) callback ; } else { throw new UnsupportedCallbackException ( callback , ""Unrecognized SASL client callback"" ) ; } } if ( nc != null ) { if ( LOG . isDebugEnabled ( ) ) LOG . debug ( ""SASL client callback: setting username: "" + userName ) ; nc . setName ( userName ) ; } if ( pc != null ) { if ( LOG . isDebugEnabled ( ) ) LOG . debug ( ""SASL client callback: setting userPassword"" ) ; pc . setPassword ( userPassword ) ; } if ( rc != null ) { if ( LOG . isDebugEnabled ( ) ) LOG . debug ( ""SASL client callback: setting realm: "" + rc . getDefaultText ( ) ) ; rc . setText ( rc . getDefaultText ( ) ) ; } } } ",No
"public class TestRuleSetAssembler extends AssemblerTestBase { public TestRuleSetAssembler ( String name ) { super ( name ) ; } @ Override protected Class < ? extends Assembler > getAssemblerClass ( ) { return RuleSetAssembler . class ; } public void testRuleSetVocabulary ( ) { assertSubclassOf ( JA . RuleSet , JA . HasRules ) ; assertDomain ( JA . HasRules , JA . rule ) ; assertDomain ( JA . HasRules , JA . rulesFrom ) ; assertDomain ( JA . HasRules , JA . rules ) ; assertRange ( JA . RuleSet , JA . rules ) ; } public void testRuleSetAssemblerType ( ) { testDemandsMinimalType ( new RuleSetAssembler ( ) , JA . RuleSet ) ; } public void testEmptyRuleSet ( ) { Assembler a = new RuleSetAssembler ( ) ; Resource root = resourceInModel ( ""x rdf:type ja:RuleSet"" ) ; assertEquals ( RuleSet . empty , a . open ( root ) ) ; } public void testSingleRuleString ( ) { Assembler a = new RuleSetAssembler ( ) ; String ruleString = ""[(?a P ?b) -> (?a Q ?b)]"" ; Resource root = resourceInModel ( ""x rdf:type ja:RuleSet; x ja:rule '"" + ruleString . replaceAll ( "" "" , ""\\\\s"" ) + ""'"" ) ; RuleSet rules = ( RuleSet ) a . open ( root ) ; Set < Rule > expected = new HashSet < > ( Rule . parseRules ( ruleString ) ) ; assertEquals ( expected , new HashSet < > ( rules . getRules ( ) ) ) ; } public void testMultipleRuleStrings ( ) { Assembler a = new RuleSetAssembler ( ) ; String ruleStringA = ""[(?a P ?b) -> (?a Q ?b)]"" ; String ruleStringB = ""[(?a R ?b) -> (?a S ?b)]"" ; Resource root = resourceInModel ( ""x rdf:type ja:RuleSet"" + ""; x ja:rule '"" + ruleStringA . replaceAll ( "" "" , ""\\\\s"" ) + ""'"" + ""; x ja:rule '"" + ruleStringB . replaceAll ( "" "" , ""\\\\s"" ) + ""'"" ) ; RuleSet rules = ( RuleSet ) a . open ( root ) ; Set < Rule > expected = new HashSet < > ( Rule . parseRules ( ruleStringA ) ) ; expected . addAll ( Rule . parseRules ( ruleStringB ) ) ; assertEquals ( expected , new HashSet < > ( rules . getRules ( ) ) ) ; } public void testRulesFrom ( ) { Assembler a = new RuleSetAssembler ( ) ; String rulesA = file ( ""example.rules"" ) ; Resource root = resourceInModel ( ""x rdf:type ja:RuleSet; x ja:rulesFrom "" + rulesA ) ; Set < Rule > expected = new HashSet < > ( Rule . rulesFromURL ( rulesA ) ) ; RuleSet rules = ( RuleSet ) a . open ( root ) ; assertEquals ( expected , new HashSet < > ( rules . getRules ( ) ) ) ; } public void testSubRules ( ) { Assembler a = new RuleSetAssembler ( ) ; String ruleStringA = ""[(?a P ?b) -> (?a Q ?b)]"" ; Resource root = resourceInModel ( ""x rdf:type ja:RuleSet; x ja:rules y"" + ""; y rdf:type ja:RuleSet; y ja:rule '"" + ruleStringA . replaceAll ( "" "" , ""\\\\s"" ) + ""'"" ) ; Set < Rule > expected = new HashSet < > ( Rule . parseRules ( ruleStringA ) ) ; RuleSet rules = ( RuleSet ) a . open ( root ) ; assertEquals ( expected , new HashSet < > ( rules . getRules ( ) ) ) ; } public void testTrapsBadRulesObject ( ) { testTrapsBadRuleObject ( ""ja:rules"" , ""'y'"" ) ; testTrapsBadRuleObject ( ""ja:rulesFrom"" , ""17"" ) ; testTrapsBadRuleObject ( ""ja:rule"" , ""aResource"" ) ; testTrapsBadRuleObject ( ""ja:rule"" , ""17"" ) ; testTrapsBadRuleObject ( ""ja:rule"" , ""'something'xsd:else"" ) ; } private void testTrapsBadRuleObject ( String property , String value ) { Assembler a = new RuleSetAssembler ( ) ; Resource root = resourceInModel ( ""x rdf:type ja:RuleSet; x <property> <value>"" . replaceAll ( ""<property>"" , property ) . replaceAll ( ""<value>"" , value ) ) ; try { a . open ( root ) ; fail ( ""should trap bad rules object "" + value + "" for property "" + property ) ; } catch ( BadObjectException e ) { Model m = e . getRoot ( ) . getModel ( ) ; assertEquals ( resource ( ""x"" ) , e . getRoot ( ) ) ; assertEquals ( rdfNode ( m , value ) , e . getObject ( ) ) ; } } protected static String file ( String name ) { return ""file:testing/modelspecs/"" + name ; } }",No
"public class BetaDistribution extends AbstractRealDistribution { public static final double DEFAULT_INVERSE_ABSOLUTE_ACCURACY = 1e-9 ; private static final long serialVersionUID = - 1221965979403477668L ; private final double alpha ; private final double beta ; private double z ; private final double solverAbsoluteAccuracy ; public BetaDistribution ( double alpha , double beta ) { this ( alpha , beta , DEFAULT_INVERSE_ABSOLUTE_ACCURACY ) ; } public BetaDistribution ( double alpha , double beta , double inverseCumAccuracy ) { this ( new Well19937c ( ) , alpha , beta , inverseCumAccuracy ) ; } public BetaDistribution ( RandomGenerator rng , double alpha , double beta ) { this ( rng , alpha , beta , DEFAULT_INVERSE_ABSOLUTE_ACCURACY ) ; } public BetaDistribution ( RandomGenerator rng , double alpha , double beta , double inverseCumAccuracy ) { super ( rng ) ; this . alpha = alpha ; this . beta = beta ; z = Double . NaN ; solverAbsoluteAccuracy = inverseCumAccuracy ; } public double getAlpha ( ) { return alpha ; } public double getBeta ( ) { return beta ; } private void recomputeZ ( ) { if ( Double . isNaN ( z ) ) { z = Gamma . logGamma ( alpha ) + Gamma . logGamma ( beta ) - Gamma . logGamma ( alpha + beta ) ; } } public double density ( double x ) { final double logDensity = logDensity ( x ) ; return logDensity == Double . NEGATIVE_INFINITY ? 0 : FastMath . exp ( logDensity ) ; } @ Override public double logDensity ( double x ) { recomputeZ ( ) ; if ( x < 0 || x > 1 ) { return Double . NEGATIVE_INFINITY ; } else if ( x == 0 ) { if ( alpha < 1 ) { throw new NumberIsTooSmallException ( LocalizedFormats . CANNOT_COMPUTE_BETA_DENSITY_AT_0_FOR_SOME_ALPHA , alpha , 1 , false ) ; } return Double . NEGATIVE_INFINITY ; } else if ( x == 1 ) { if ( beta < 1 ) { throw new NumberIsTooSmallException ( LocalizedFormats . CANNOT_COMPUTE_BETA_DENSITY_AT_1_FOR_SOME_BETA , beta , 1 , false ) ; } return Double . NEGATIVE_INFINITY ; } else { double logX = FastMath . log ( x ) ; double log1mX = FastMath . log1p ( - x ) ; return ( alpha - 1 ) * logX + ( beta - 1 ) * log1mX - z ; } } public double cumulativeProbability ( double x ) { if ( x <= 0 ) { return 0 ; } else if ( x >= 1 ) { return 1 ; } else { return Beta . regularizedBeta ( x , alpha , beta ) ; } } @ Override protected double getSolverAbsoluteAccuracy ( ) { return solverAbsoluteAccuracy ; } public double getNumericalMean ( ) { final double a = getAlpha ( ) ; return a / ( a + getBeta ( ) ) ; } public double getNumericalVariance ( ) { final double a = getAlpha ( ) ; final double b = getBeta ( ) ; final double alphabetasum = a + b ; return ( a * b ) / ( ( alphabetasum * alphabetasum ) * ( alphabetasum + 1 ) ) ; } public double getSupportLowerBound ( ) { return 0 ; } public double getSupportUpperBound ( ) { return 1 ; } public boolean isSupportLowerBoundInclusive ( ) { return false ; } public boolean isSupportUpperBoundInclusive ( ) { return false ; } public boolean isSupportConnected ( ) { return true ; } }",No
"@ RunWith ( Parameterized . class ) public class TestReadingWritingDataInEvolvedSchemas { private static final String RECORD_A = ""RecordA"" ; private static final String FIELD_A = ""fieldA"" ; private static final char LATIN_SMALL_LETTER_O_WITH_DIARESIS = '\u00F6' ; @ Rule public ExpectedException expectedException = ExpectedException . none ( ) ; private static final Schema DOUBLE_RECORD = SchemaBuilder . record ( RECORD_A ) . fields ( ) . name ( FIELD_A ) . type ( ) . doubleType ( ) . noDefault ( ) . endRecord ( ) ; private static final Schema FLOAT_RECORD = SchemaBuilder . record ( RECORD_A ) . fields ( ) . name ( FIELD_A ) . type ( ) . floatType ( ) . noDefault ( ) . endRecord ( ) ; private static final Schema LONG_RECORD = SchemaBuilder . record ( RECORD_A ) . fields ( ) . name ( FIELD_A ) . type ( ) . longType ( ) . noDefault ( ) . endRecord ( ) ; private static final Schema INT_RECORD = SchemaBuilder . record ( RECORD_A ) . fields ( ) . name ( FIELD_A ) . type ( ) . intType ( ) . noDefault ( ) . endRecord ( ) ; private static final Schema UNION_INT_LONG_FLOAT_DOUBLE_RECORD = SchemaBuilder . record ( RECORD_A ) . fields ( ) . name ( FIELD_A ) . type ( ) . unionOf ( ) . doubleType ( ) . and ( ) . floatType ( ) . and ( ) . longType ( ) . and ( ) . intType ( ) . endUnion ( ) . noDefault ( ) . endRecord ( ) ; private static final Schema STRING_RECORD = SchemaBuilder . record ( RECORD_A ) . fields ( ) . name ( FIELD_A ) . type ( ) . stringType ( ) . noDefault ( ) . endRecord ( ) ; private static final Schema BYTES_RECORD = SchemaBuilder . record ( RECORD_A ) . fields ( ) . name ( FIELD_A ) . type ( ) . bytesType ( ) . noDefault ( ) . endRecord ( ) ; private static final Schema UNION_STRING_BYTES_RECORD = SchemaBuilder . record ( RECORD_A ) . fields ( ) . name ( FIELD_A ) . type ( ) . unionOf ( ) . stringType ( ) . and ( ) . bytesType ( ) . endUnion ( ) . noDefault ( ) . endRecord ( ) ; private static final Schema ENUM_AB_RECORD = SchemaBuilder . record ( RECORD_A ) . fields ( ) . name ( FIELD_A ) . type ( ) . enumeration ( ""Enum1"" ) . symbols ( ""A"" , ""B"" ) . noDefault ( ) . endRecord ( ) ; private static final Schema ENUM_ABC_RECORD = SchemaBuilder . record ( RECORD_A ) . fields ( ) . name ( FIELD_A ) . type ( ) . enumeration ( ""Enum1"" ) . symbols ( ""A"" , ""B"" , ""C"" ) . noDefault ( ) . endRecord ( ) ; private static final Schema UNION_INT_RECORD = SchemaBuilder . record ( RECORD_A ) . fields ( ) . name ( FIELD_A ) . type ( ) . unionOf ( ) . intType ( ) . endUnion ( ) . noDefault ( ) . endRecord ( ) ; private static final Schema UNION_LONG_RECORD = SchemaBuilder . record ( RECORD_A ) . fields ( ) . name ( FIELD_A ) . type ( ) . unionOf ( ) . longType ( ) . endUnion ( ) . noDefault ( ) . endRecord ( ) ; private static final Schema UNION_FLOAT_RECORD = SchemaBuilder . record ( RECORD_A ) . fields ( ) . name ( FIELD_A ) . type ( ) . unionOf ( ) . floatType ( ) . endUnion ( ) . noDefault ( ) . endRecord ( ) ; private static final Schema UNION_DOUBLE_RECORD = SchemaBuilder . record ( RECORD_A ) . fields ( ) . name ( FIELD_A ) . type ( ) . unionOf ( ) . doubleType ( ) . endUnion ( ) . noDefault ( ) . endRecord ( ) ; private static final Schema UNION_LONG_FLOAT_RECORD = SchemaBuilder . record ( RECORD_A ) . fields ( ) . name ( FIELD_A ) . type ( ) . unionOf ( ) . floatType ( ) . and ( ) . longType ( ) . endUnion ( ) . noDefault ( ) . endRecord ( ) ; private static final Schema UNION_FLOAT_DOUBLE_RECORD = SchemaBuilder . record ( RECORD_A ) . fields ( ) . name ( FIELD_A ) . type ( ) . unionOf ( ) . floatType ( ) . and ( ) . doubleType ( ) . endUnion ( ) . noDefault ( ) . endRecord ( ) ; @ Parameters ( name = ""encoder = {0}"" ) public static Collection < Object [ ] > data ( ) { return Arrays . asList ( new EncoderType [ ] [ ] { { EncoderType . BINARY } , { EncoderType . JSON } } ) ; } public TestReadingWritingDataInEvolvedSchemas ( EncoderType encoderType ) { this . encoderType = encoderType ; } private final EncoderType encoderType ; enum EncoderType { BINARY , JSON } @ Test public void doubleWrittenWithUnionSchemaIsConvertedToDoubleSchema ( ) throws Exception { Schema writer = UNION_INT_LONG_FLOAT_DOUBLE_RECORD ; Record record = defaultRecordWithSchema ( writer , FIELD_A , 42.0 ) ; byte [ ] encoded = encodeGenericBlob ( record ) ; Record decoded = decodeGenericBlob ( DOUBLE_RECORD , writer , encoded ) ; assertEquals ( 42.0 , decoded . get ( FIELD_A ) ) ; } @ Test public void longWrittenWithUnionSchemaIsConvertedToUnionLongFloatSchema ( ) throws Exception { Schema writer = UNION_LONG_RECORD ; Record record = defaultRecordWithSchema ( writer , FIELD_A , 42L ) ; byte [ ] encoded = encodeGenericBlob ( record ) ; Record decoded = decodeGenericBlob ( UNION_LONG_FLOAT_RECORD , writer , encoded ) ; assertEquals ( 42L , decoded . get ( FIELD_A ) ) ; } @ Test public void longWrittenWithUnionSchemaIsConvertedToDoubleSchema ( ) throws Exception { Schema writer = UNION_LONG_RECORD ; Record record = defaultRecordWithSchema ( writer , FIELD_A , 42L ) ; byte [ ] encoded = encodeGenericBlob ( record ) ; Record decoded = decodeGenericBlob ( UNION_DOUBLE_RECORD , writer , encoded ) ; assertEquals ( 42.0 , decoded . get ( FIELD_A ) ) ; } @ Test public void intWrittenWithUnionSchemaIsConvertedToDoubleSchema ( ) throws Exception { Schema writer = UNION_INT_RECORD ; Record record = defaultRecordWithSchema ( writer , FIELD_A , 42 ) ; byte [ ] encoded = encodeGenericBlob ( record ) ; Record decoded = decodeGenericBlob ( UNION_DOUBLE_RECORD , writer , encoded ) ; assertEquals ( 42.0 , decoded . get ( FIELD_A ) ) ; } @ Test public void intWrittenWithUnionSchemaIsReadableByFloatSchema ( ) throws Exception { Schema writer = UNION_INT_RECORD ; Record record = defaultRecordWithSchema ( writer , FIELD_A , 42 ) ; byte [ ] encoded = encodeGenericBlob ( record ) ; Record decoded = decodeGenericBlob ( FLOAT_RECORD , writer , encoded ) ; assertEquals ( 42.0f , decoded . get ( FIELD_A ) ) ; } @ Test public void intWrittenWithUnionSchemaIsReadableByFloatUnionSchema ( ) throws Exception { Schema writer = UNION_INT_RECORD ; Record record = defaultRecordWithSchema ( writer , FIELD_A , 42 ) ; byte [ ] encoded = encodeGenericBlob ( record ) ; Record decoded = decodeGenericBlob ( UNION_FLOAT_RECORD , writer , encoded ) ; assertEquals ( 42.0f , decoded . get ( FIELD_A ) ) ; } @ Test public void longWrittenWithUnionSchemaIsReadableByFloatSchema ( ) throws Exception { Schema writer = UNION_LONG_RECORD ; Record record = defaultRecordWithSchema ( writer , FIELD_A , 42L ) ; byte [ ] encoded = encodeGenericBlob ( record ) ; Record decoded = decodeGenericBlob ( FLOAT_RECORD , writer , encoded ) ; assertEquals ( 42.0f , decoded . get ( FIELD_A ) ) ; } @ Test public void longWrittenWithUnionSchemaIsReadableByFloatUnionSchema ( ) throws Exception { Schema writer = UNION_LONG_RECORD ; Record record = defaultRecordWithSchema ( writer , FIELD_A , 42L ) ; byte [ ] encoded = encodeGenericBlob ( record ) ; Record decoded = decodeGenericBlob ( UNION_FLOAT_RECORD , writer , encoded ) ; assertEquals ( 42.0f , decoded . get ( FIELD_A ) ) ; } @ Test public void longWrittenWithUnionSchemaIsConvertedToLongFloatUnionSchema ( ) throws Exception { Schema writer = UNION_LONG_RECORD ; Record record = defaultRecordWithSchema ( writer , FIELD_A , 42L ) ; byte [ ] encoded = encodeGenericBlob ( record ) ; Record decoded = decodeGenericBlob ( UNION_LONG_FLOAT_RECORD , writer , encoded ) ; assertEquals ( 42L , decoded . get ( FIELD_A ) ) ; } @ Test public void longWrittenWithUnionSchemaIsConvertedToFloatDoubleUnionSchema ( ) throws Exception { Schema writer = UNION_LONG_RECORD ; Record record = defaultRecordWithSchema ( writer , FIELD_A , 42L ) ; byte [ ] encoded = encodeGenericBlob ( record ) ; Record decoded = decodeGenericBlob ( UNION_FLOAT_DOUBLE_RECORD , writer , encoded ) ; assertEquals ( 42.0F , decoded . get ( FIELD_A ) ) ; } @ Test public void doubleWrittenWithUnionSchemaIsNotConvertedToFloatSchema ( ) throws Exception { expectedException . expect ( AvroTypeException . class ) ; expectedException . expectMessage ( ""Found double, expecting float"" ) ; Schema writer = UNION_INT_LONG_FLOAT_DOUBLE_RECORD ; Record record = defaultRecordWithSchema ( writer , FIELD_A , 42.0 ) ; byte [ ] encoded = encodeGenericBlob ( record ) ; decodeGenericBlob ( FLOAT_RECORD , writer , encoded ) ; } @ Test public void floatWrittenWithUnionSchemaIsNotConvertedToLongSchema ( ) throws Exception { expectedException . expect ( AvroTypeException . class ) ; expectedException . expectMessage ( ""Found float, expecting long"" ) ; Schema writer = UNION_INT_LONG_FLOAT_DOUBLE_RECORD ; Record record = defaultRecordWithSchema ( writer , FIELD_A , 42.0f ) ; byte [ ] encoded = encodeGenericBlob ( record ) ; decodeGenericBlob ( LONG_RECORD , writer , encoded ) ; } @ Test public void longWrittenWithUnionSchemaIsNotConvertedToIntSchema ( ) throws Exception { expectedException . expect ( AvroTypeException . class ) ; expectedException . expectMessage ( ""Found long, expecting int"" ) ; Schema writer = UNION_INT_LONG_FLOAT_DOUBLE_RECORD ; Record record = defaultRecordWithSchema ( writer , FIELD_A , 42L ) ; byte [ ] encoded = encodeGenericBlob ( record ) ; decodeGenericBlob ( INT_RECORD , writer , encoded ) ; } @ Test public void intWrittenWithUnionSchemaIsConvertedToAllNumberSchemas ( ) throws Exception { Schema writer = UNION_INT_LONG_FLOAT_DOUBLE_RECORD ; Record record = defaultRecordWithSchema ( writer , FIELD_A , 42 ) ; byte [ ] encoded = encodeGenericBlob ( record ) ; assertEquals ( 42.0 , decodeGenericBlob ( DOUBLE_RECORD , writer , encoded ) . get ( FIELD_A ) ) ; assertEquals ( 42.0f , decodeGenericBlob ( FLOAT_RECORD , writer , encoded ) . get ( FIELD_A ) ) ; assertEquals ( 42L , decodeGenericBlob ( LONG_RECORD , writer , encoded ) . get ( FIELD_A ) ) ; assertEquals ( 42 , decodeGenericBlob ( INT_RECORD , writer , encoded ) . get ( FIELD_A ) ) ; } @ Test public void asciiStringWrittenWithUnionSchemaIsConvertedToBytesSchema ( ) throws Exception { Schema writer = UNION_STRING_BYTES_RECORD ; Record record = defaultRecordWithSchema ( writer , FIELD_A , ""42"" ) ; byte [ ] encoded = encodeGenericBlob ( record ) ; ByteBuffer actual = ( ByteBuffer ) decodeGenericBlob ( BYTES_RECORD , writer , encoded ) . get ( FIELD_A ) ; assertArrayEquals ( ""42"" . getBytes ( StandardCharsets . UTF_8 ) , actual . array ( ) ) ; } @ Test public void utf8StringWrittenWithUnionSchemaIsConvertedToBytesSchema ( ) throws Exception { String goeran = String . format ( ""G%sran"" , LATIN_SMALL_LETTER_O_WITH_DIARESIS ) ; Schema writer = UNION_STRING_BYTES_RECORD ; Record record = defaultRecordWithSchema ( writer , FIELD_A , goeran ) ; byte [ ] encoded = encodeGenericBlob ( record ) ; ByteBuffer actual = ( ByteBuffer ) decodeGenericBlob ( BYTES_RECORD , writer , encoded ) . get ( FIELD_A ) ; assertArrayEquals ( goeran . getBytes ( StandardCharsets . UTF_8 ) , actual . array ( ) ) ; } @ Test public void asciiBytesWrittenWithUnionSchemaIsConvertedToStringSchema ( ) throws Exception { Schema writer = UNION_STRING_BYTES_RECORD ; ByteBuffer buf = ByteBuffer . wrap ( ""42"" . getBytes ( StandardCharsets . UTF_8 ) ) ; Record record = defaultRecordWithSchema ( writer , FIELD_A , buf ) ; byte [ ] encoded = encodeGenericBlob ( record ) ; CharSequence read = ( CharSequence ) decodeGenericBlob ( STRING_RECORD , writer , encoded ) . get ( FIELD_A ) ; assertEquals ( ""42"" , read . toString ( ) ) ; } @ Test public void utf8BytesWrittenWithUnionSchemaIsConvertedToStringSchema ( ) throws Exception { String goeran = String . format ( ""G%sran"" , LATIN_SMALL_LETTER_O_WITH_DIARESIS ) ; Schema writer = UNION_STRING_BYTES_RECORD ; Record record = defaultRecordWithSchema ( writer , FIELD_A , goeran ) ; byte [ ] encoded = encodeGenericBlob ( record ) ; CharSequence read = ( CharSequence ) decodeGenericBlob ( STRING_RECORD , writer , encoded ) . get ( FIELD_A ) ; assertEquals ( goeran , read . toString ( ) ) ; } @ Test public void enumRecordCanBeReadWithExtendedEnumSchema ( ) throws Exception { Schema writer = ENUM_AB_RECORD ; Record record = defaultRecordWithSchema ( writer , FIELD_A , new EnumSymbol ( writer , ""A"" ) ) ; byte [ ] encoded = encodeGenericBlob ( record ) ; Record decoded = decodeGenericBlob ( ENUM_ABC_RECORD , writer , encoded ) ; assertEquals ( ""A"" , decoded . get ( FIELD_A ) . toString ( ) ) ; } @ Test public void enumRecordWithExtendedSchemaCanBeReadWithOriginalEnumSchemaIfOnlyOldValues ( ) throws Exception { Schema writer = ENUM_ABC_RECORD ; Record record = defaultRecordWithSchema ( writer , FIELD_A , new EnumSymbol ( writer , ""A"" ) ) ; byte [ ] encoded = encodeGenericBlob ( record ) ; Record decoded = decodeGenericBlob ( ENUM_AB_RECORD , writer , encoded ) ; assertEquals ( ""A"" , decoded . get ( FIELD_A ) . toString ( ) ) ; } @ Test public void enumRecordWithExtendedSchemaCanNotBeReadIfNewValuesAreUsed ( ) throws Exception { expectedException . expect ( AvroTypeException . class ) ; expectedException . expectMessage ( ""No match for C"" ) ; Schema writer = ENUM_ABC_RECORD ; Record record = defaultRecordWithSchema ( writer , FIELD_A , new EnumSymbol ( writer , ""C"" ) ) ; byte [ ] encoded = encodeGenericBlob ( record ) ; decodeGenericBlob ( ENUM_AB_RECORD , writer , encoded ) ; } @ Test public void recordWrittenWithExtendedSchemaCanBeReadWithOriginalSchemaButLossOfData ( ) throws Exception { Schema writer = SchemaBuilder . record ( RECORD_A ) . fields ( ) . name ( ""newTopField"" ) . type ( ) . stringType ( ) . noDefault ( ) . name ( FIELD_A ) . type ( ) . intType ( ) . noDefault ( ) . endRecord ( ) ; Record record = defaultRecordWithSchema ( writer , FIELD_A , 42 ) ; record . put ( ""newTopField"" , ""not decoded"" ) ; byte [ ] encoded = encodeGenericBlob ( record ) ; Record decoded = decodeGenericBlob ( INT_RECORD , writer , encoded ) ; assertEquals ( 42 , decoded . get ( FIELD_A ) ) ; assertNull ( decoded . get ( ""newTopField"" ) ) ; } @ Test public void readerWithoutDefaultValueThrowsException ( ) throws Exception { expectedException . expect ( AvroTypeException . class ) ; expectedException . expectMessage ( ""missing required field newField"" ) ; Schema reader = SchemaBuilder . record ( RECORD_A ) . fields ( ) . name ( ""newField"" ) . type ( ) . intType ( ) . noDefault ( ) . name ( FIELD_A ) . type ( ) . intType ( ) . noDefault ( ) . endRecord ( ) ; Record record = defaultRecordWithSchema ( INT_RECORD , FIELD_A , 42 ) ; byte [ ] encoded = encodeGenericBlob ( record ) ; decodeGenericBlob ( reader , INT_RECORD , encoded ) ; } @ Test public void readerWithDefaultValueIsApplied ( ) throws Exception { Schema reader = SchemaBuilder . record ( RECORD_A ) . fields ( ) . name ( ""newFieldWithDefault"" ) . type ( ) . intType ( ) . intDefault ( 314 ) . name ( FIELD_A ) . type ( ) . intType ( ) . noDefault ( ) . endRecord ( ) ; Record record = defaultRecordWithSchema ( INT_RECORD , FIELD_A , 42 ) ; byte [ ] encoded = encodeGenericBlob ( record ) ; Record decoded = decodeGenericBlob ( reader , INT_RECORD , encoded ) ; assertEquals ( 42 , decoded . get ( FIELD_A ) ) ; assertEquals ( 314 , decoded . get ( ""newFieldWithDefault"" ) ) ; } @ Test public void aliasesInSchema ( ) throws Exception { Schema writer = new Schema . Parser ( ) . parse ( ""{\""namespace\"": \""example.avro\"", \""type\"": \""record\"", \""name\"": \""User\"", \""fields\"": ["" + ""{\""name\"": \""name\"", \""type\"": \""int\""}\n"" + ""]}\n"" ) ; Schema reader = new Schema . Parser ( ) . parse ( ""{\""namespace\"": \""example.avro\"", \""type\"": \""record\"", \""name\"": \""User\"", \""fields\"": ["" + ""{\""name\"": \""fname\"", \""type\"": \""int\"", \""aliases\"" : [ \""name\"" ]}\n"" + ""]}\n"" ) ; GenericData . Record record = defaultRecordWithSchema ( writer , ""name"" , 1 ) ; byte [ ] encoded = encodeGenericBlob ( record ) ; GenericData . Record decoded = decodeGenericBlob ( reader , reader , encoded ) ; assertEquals ( 1 , decoded . get ( ""fname"" ) ) ; } private < T > Record defaultRecordWithSchema ( Schema schema , String key , T value ) { Record data = new GenericData . Record ( schema ) ; data . put ( key , value ) ; return data ; } private byte [ ] encodeGenericBlob ( GenericRecord data ) throws IOException { DatumWriter < GenericRecord > writer = new GenericDatumWriter < > ( data . getSchema ( ) ) ; ByteArrayOutputStream outStream = new ByteArrayOutputStream ( ) ; Encoder encoder = encoderType == EncoderType . BINARY ? EncoderFactory . get ( ) . binaryEncoder ( outStream , null ) : EncoderFactory . get ( ) . jsonEncoder ( data . getSchema ( ) , outStream ) ; writer . write ( data , encoder ) ; encoder . flush ( ) ; outStream . close ( ) ; return outStream . toByteArray ( ) ; } private Record decodeGenericBlob ( Schema expectedSchema , Schema schemaOfBlob , byte [ ] blob ) throws IOException { if ( blob == null ) { return null ; } GenericDatumReader < Record > reader = new GenericDatumReader < > ( ) ; reader . setExpected ( expectedSchema ) ; reader . setSchema ( schemaOfBlob ) ; Decoder decoder = encoderType == EncoderType . BINARY ? DecoderFactory . get ( ) . binaryDecoder ( blob , null ) : DecoderFactory . get ( ) . jsonDecoder ( schemaOfBlob , new ByteArrayInputStream ( blob ) ) ; return reader . read ( null , decoder ) ; } }",Smelly
"public class QuartzDriverDelegate implements DriverDelegate { private Logger logger ; private ServiceManager manager ; private Context context ; private DriverDelegate delegate ; public QuartzDriverDelegate ( Logger logger , ServiceManager manager , Context context , DriverDelegate delegate ) { this . logger = logger ; this . manager = manager ; this . context = context ; this . delegate = delegate ; } public int insertJobDetail ( Connection conn , JobDetail job ) throws IOException , SQLException { removeTransientData ( job ) ; return delegate . insertJobDetail ( conn , job ) ; } public int updateJobDetail ( Connection conn , JobDetail job ) throws IOException , SQLException { removeTransientData ( job ) ; return delegate . updateJobDetail ( conn , job ) ; } public int updateJobData ( Connection conn , JobDetail job ) throws IOException , SQLException { removeTransientData ( job ) ; return delegate . updateJobData ( conn , job ) ; } private void removeTransientData ( JobDetail job ) { JobDataMap map = job . getJobDataMap ( ) ; if ( map != null ) { this . logger . debug ( ""QuartzDriverDelegate: Removing transient data"" ) ; map . remove ( QuartzJobScheduler . DATA_MAP_LOGGER ) ; map . remove ( QuartzJobScheduler . DATA_MAP_CONTEXT ) ; map . remove ( QuartzJobScheduler . DATA_MAP_MANAGER ) ; } } public JobDetail selectJobDetail ( Connection conn , String jobName , String groupName , ClassLoadHelper loadHelper ) throws ClassNotFoundException , IOException , SQLException { JobDetail job = delegate . selectJobDetail ( conn , jobName , groupName , loadHelper ) ; if ( job != null ) { JobDataMap map = job . getJobDataMap ( ) ; if ( map != null ) { this . logger . debug ( ""QuartzDriverDelegate: Adding transient data"" ) ; map . put ( QuartzJobScheduler . DATA_MAP_LOGGER , this . logger ) ; map . put ( QuartzJobScheduler . DATA_MAP_CONTEXT , this . context ) ; map . put ( QuartzJobScheduler . DATA_MAP_MANAGER , this . manager ) ; } } return job ; } public int updateTriggerStatesFromOtherStates ( Connection conn , String newState , String oldState1 , String oldState2 ) throws SQLException { return delegate . updateTriggerStatesFromOtherStates ( conn , newState , oldState1 , oldState2 ) ; } public Key [ ] selectMisfiredTriggers ( Connection conn , long ts ) throws SQLException { return delegate . selectMisfiredTriggers ( conn , ts ) ; } public Key [ ] selectMisfiredTriggersInState ( Connection conn , String state , long ts ) throws SQLException { return delegate . selectMisfiredTriggersInState ( conn , state , ts ) ; } public Key [ ] selectMisfiredTriggersInGroupInState ( Connection conn , String groupName , String state , long ts ) throws SQLException { return delegate . selectMisfiredTriggersInGroupInState ( conn , groupName , state , ts ) ; } public Trigger [ ] selectTriggersForRecoveringJobs ( Connection conn ) throws SQLException { return delegate . selectTriggersForRecoveringJobs ( conn ) ; } public int deleteFiredTriggers ( Connection conn ) throws SQLException { return delegate . deleteFiredTriggers ( conn ) ; } public int deleteFiredTriggers ( Connection conn , String instanceId ) throws SQLException { return delegate . deleteFiredTriggers ( conn , instanceId ) ; } public int deleteVolatileFiredTriggers ( Connection conn ) throws SQLException { return delegate . deleteVolatileFiredTriggers ( conn ) ; } public Key [ ] selectVolatileTriggers ( Connection conn ) throws SQLException { return delegate . selectVolatileTriggers ( conn ) ; } public Key [ ] selectVolatileJobs ( Connection conn ) throws SQLException { return delegate . selectVolatileJobs ( conn ) ; } public Key [ ] selectTriggerNamesForJob ( Connection conn , String jobName , String groupName ) throws SQLException { return delegate . selectTriggerNamesForJob ( conn , jobName , groupName ) ; } public int deleteJobListeners ( Connection conn , String jobName , String groupName ) throws SQLException { return delegate . deleteJobListeners ( conn , jobName , groupName ) ; } public int deleteJobDetail ( Connection conn , String jobName , String groupName ) throws SQLException { return delegate . deleteJobDetail ( conn , jobName , groupName ) ; } public boolean isJobStateful ( Connection conn , String jobName , String groupName ) throws SQLException { return delegate . isJobStateful ( conn , jobName , groupName ) ; } public boolean jobExists ( Connection conn , String jobName , String groupName ) throws SQLException { return delegate . jobExists ( conn , jobName , groupName ) ; } public int insertJobListener ( Connection conn , JobDetail job , String listener ) throws SQLException { return delegate . insertJobListener ( conn , job , listener ) ; } public String [ ] selectJobListeners ( Connection conn , String jobName , String groupName ) throws SQLException { return delegate . selectJobListeners ( conn , jobName , groupName ) ; } public int selectNumJobs ( Connection conn ) throws SQLException { return delegate . selectNumJobs ( conn ) ; } public String [ ] selectJobGroups ( Connection conn ) throws SQLException { return delegate . selectJobGroups ( conn ) ; } public String [ ] selectJobsInGroup ( Connection conn , String groupName ) throws SQLException { return delegate . selectJobsInGroup ( conn , groupName ) ; } public int insertTrigger ( Connection conn , Trigger trigger , String state , JobDetail jobDetail ) throws SQLException , IOException { return delegate . insertTrigger ( conn , trigger , state , jobDetail ) ; } public int insertSimpleTrigger ( Connection conn , SimpleTrigger trigger ) throws SQLException { return delegate . insertSimpleTrigger ( conn , trigger ) ; } public int insertBlobTrigger ( Connection conn , Trigger trigger ) throws SQLException , IOException { return delegate . insertBlobTrigger ( conn , trigger ) ; } public int insertCronTrigger ( Connection conn , CronTrigger trigger ) throws SQLException { return delegate . insertCronTrigger ( conn , trigger ) ; } public int updateTrigger ( Connection conn , Trigger trigger , String state , JobDetail jobDetail ) throws SQLException , IOException { return delegate . updateTrigger ( conn , trigger , state , jobDetail ) ; } public int updateSimpleTrigger ( Connection conn , SimpleTrigger trigger ) throws SQLException { return delegate . updateSimpleTrigger ( conn , trigger ) ; } public int updateCronTrigger ( Connection conn , CronTrigger trigger ) throws SQLException { return delegate . updateCronTrigger ( conn , trigger ) ; } public int updateBlobTrigger ( Connection conn , Trigger trigger ) throws SQLException , IOException { return delegate . updateBlobTrigger ( conn , trigger ) ; } public boolean triggerExists ( Connection conn , String triggerName , String groupName ) throws SQLException { return delegate . triggerExists ( conn , triggerName , groupName ) ; } public int updateTriggerState ( Connection conn , String triggerName , String groupName , String state ) throws SQLException { return delegate . updateTriggerState ( conn , triggerName , groupName , state ) ; } public int updateTriggerStateFromOtherState ( Connection conn , String triggerName , String groupName , String newState , String oldState ) throws SQLException { return delegate . updateTriggerStateFromOtherState ( conn , triggerName , groupName , newState , oldState ) ; } public int updateTriggerStateFromOtherStates ( Connection conn , String triggerName , String groupName , String newState , String oldState1 , String oldState2 , String oldState3 ) throws SQLException { return delegate . updateTriggerStateFromOtherStates ( conn , triggerName , groupName , newState , oldState1 , oldState2 , oldState3 ) ; } public int updateTriggerStateFromOtherStatesBeforeTime ( Connection conn , String newState , String oldState1 , String oldState2 , long time ) throws SQLException { return delegate . updateTriggerStateFromOtherStatesBeforeTime ( conn , newState , oldState1 , oldState2 , time ) ; } public int updateTriggerGroupStateFromOtherStates ( Connection conn , String groupName , String newState , String oldState1 , String oldState2 , String oldState3 ) throws SQLException { return delegate . updateTriggerGroupStateFromOtherStates ( conn , groupName , newState , oldState1 , oldState2 , oldState3 ) ; } public int updateTriggerGroupStateFromOtherState ( Connection conn , String groupName , String newState , String oldState ) throws SQLException { return delegate . updateTriggerGroupStateFromOtherState ( conn , groupName , newState , oldState ) ; } public int updateTriggerStatesForJob ( Connection conn , String jobName , String groupName , String state ) throws SQLException { return delegate . updateTriggerStatesForJob ( conn , jobName , groupName , state ) ; } public int updateTriggerStatesForJobFromOtherState ( Connection conn , String jobName , String groupName , String state , String oldState ) throws SQLException { return delegate . updateTriggerStatesForJobFromOtherState ( conn , jobName , groupName , state , oldState ) ; } public int deleteTriggerListeners ( Connection conn , String triggerName , String groupName ) throws SQLException { return delegate . deleteTriggerListeners ( conn , triggerName , groupName ) ; } public int insertTriggerListener ( Connection conn , Trigger trigger , String listener ) throws SQLException { return delegate . insertTriggerListener ( conn , trigger , listener ) ; } public String [ ] selectTriggerListeners ( Connection conn , String triggerName , String groupName ) throws SQLException { return delegate . selectTriggerListeners ( conn , triggerName , groupName ) ; } public int deleteSimpleTrigger ( Connection conn , String triggerName , String groupName ) throws SQLException { return delegate . deleteSimpleTrigger ( conn , triggerName , groupName ) ; } public int deleteBlobTrigger ( Connection conn , String triggerName , String groupName ) throws SQLException { return delegate . deleteBlobTrigger ( conn , triggerName , groupName ) ; } public int deleteCronTrigger ( Connection conn , String triggerName , String groupName ) throws SQLException { return delegate . deleteCronTrigger ( conn , triggerName , groupName ) ; } public int deleteTrigger ( Connection conn , String triggerName , String groupName ) throws SQLException { return delegate . deleteTrigger ( conn , triggerName , groupName ) ; } public int selectNumTriggersForJob ( Connection conn , String jobName , String groupName ) throws SQLException { return delegate . selectNumTriggersForJob ( conn , jobName , groupName ) ; } public JobDetail selectJobForTrigger ( Connection conn , String triggerName , String groupName ) throws SQLException { return delegate . selectJobForTrigger ( conn , triggerName , groupName ) ; } public List selectStatefulJobsOfTriggerGroup ( Connection conn , String groupName ) throws SQLException { return delegate . selectStatefulJobsOfTriggerGroup ( conn , groupName ) ; } public Trigger [ ] selectTriggersForJob ( Connection conn , String jobName , String groupName ) throws SQLException , ClassNotFoundException , IOException { return delegate . selectTriggersForJob ( conn , jobName , groupName ) ; } public Trigger [ ] selectTriggersForCalendar ( Connection conn , String calName ) throws SQLException , ClassNotFoundException , IOException { return delegate . selectTriggersForCalendar ( conn , calName ) ; } public Trigger selectTrigger ( Connection conn , String triggerName , String groupName ) throws SQLException , ClassNotFoundException , IOException { return delegate . selectTrigger ( conn , triggerName , groupName ) ; } public String selectTriggerState ( Connection conn , String triggerName , String groupName ) throws SQLException { return delegate . selectTriggerState ( conn , triggerName , groupName ) ; } public TriggerStatus selectTriggerStatus ( Connection conn , String triggerName , String groupName ) throws SQLException { return delegate . selectTriggerStatus ( conn , triggerName , groupName ) ; } public int selectNumTriggers ( Connection conn ) throws SQLException { return delegate . selectNumTriggers ( conn ) ; } public String [ ] selectTriggerGroups ( Connection conn ) throws SQLException { return delegate . selectTriggerGroups ( conn ) ; } public String [ ] selectTriggersInGroup ( Connection conn , String groupName ) throws SQLException { return delegate . selectTriggersInGroup ( conn , groupName ) ; } public Key [ ] selectTriggersInState ( Connection conn , String state ) throws SQLException { return delegate . selectTriggersInState ( conn , state ) ; } public int insertPausedTriggerGroup ( Connection conn , String groupName ) throws SQLException { return delegate . insertPausedTriggerGroup ( conn , groupName ) ; } public int deletePausedTriggerGroup ( Connection conn , String groupName ) throws SQLException { return delegate . deletePausedTriggerGroup ( conn , groupName ) ; } public int deleteAllPausedTriggerGroups ( Connection conn ) throws SQLException { return delegate . deleteAllPausedTriggerGroups ( conn ) ; } public boolean isTriggerGroupPaused ( Connection conn , String groupName ) throws SQLException { return delegate . isTriggerGroupPaused ( conn , groupName ) ; } public Set selectPausedTriggerGroups ( Connection conn ) throws SQLException { return delegate . selectPausedTriggerGroups ( conn ) ; } public boolean isExistingTriggerGroup ( Connection conn , String groupName ) throws SQLException { return delegate . isExistingTriggerGroup ( conn , groupName ) ; } public int insertCalendar ( Connection conn , String calendarName , Calendar calendar ) throws IOException , SQLException { return delegate . insertCalendar ( conn , calendarName , calendar ) ; } public int updateCalendar ( Connection conn , String calendarName , Calendar calendar ) throws IOException , SQLException { return delegate . updateCalendar ( conn , calendarName , calendar ) ; } public boolean calendarExists ( Connection conn , String calendarName ) throws SQLException { return delegate . calendarExists ( conn , calendarName ) ; } public Calendar selectCalendar ( Connection conn , String calendarName ) throws ClassNotFoundException , IOException , SQLException { return delegate . selectCalendar ( conn , calendarName ) ; } public boolean calendarIsReferenced ( Connection conn , String calendarName ) throws SQLException { return delegate . calendarIsReferenced ( conn , calendarName ) ; } public int deleteCalendar ( Connection conn , String calendarName ) throws SQLException { return delegate . deleteCalendar ( conn , calendarName ) ; } public int selectNumCalendars ( Connection conn ) throws SQLException { return delegate . selectNumCalendars ( conn ) ; } public String [ ] selectCalendars ( Connection conn ) throws SQLException { return delegate . selectCalendars ( conn ) ; } public long selectNextFireTime ( Connection conn ) throws SQLException { return delegate . selectNextFireTime ( conn ) ; } public Key selectTriggerForFireTime ( Connection conn , long fireTime ) throws SQLException { return delegate . selectTriggerForFireTime ( conn , fireTime ) ; } public int insertFiredTrigger ( Connection conn , Trigger trigger , String state , JobDetail jobDetail ) throws SQLException { return delegate . insertFiredTrigger ( conn , trigger , state , jobDetail ) ; } public List selectFiredTriggerRecords ( Connection conn , String triggerName , String groupName ) throws SQLException { return delegate . selectFiredTriggerRecords ( conn , triggerName , groupName ) ; } public List selectFiredTriggerRecordsByJob ( Connection conn , String jobName , String groupName ) throws SQLException { return delegate . selectFiredTriggerRecordsByJob ( conn , jobName , groupName ) ; } public List selectInstancesFiredTriggerRecords ( Connection conn , String instanceName ) throws SQLException { return delegate . selectInstancesFiredTriggerRecords ( conn , instanceName ) ; } public int deleteFiredTrigger ( Connection conn , String entryId ) throws SQLException { return delegate . deleteFiredTrigger ( conn , entryId ) ; } public int selectJobExecutionCount ( Connection conn , String jobName , String jobGroup ) throws SQLException { return delegate . selectJobExecutionCount ( conn , jobName , jobGroup ) ; } public int insertSchedulerState ( Connection conn , String instanceId , long checkInTime , long interval , String recoverer ) throws SQLException { return delegate . insertSchedulerState ( conn , instanceId , checkInTime , interval , recoverer ) ; } public int deleteSchedulerState ( Connection conn , String instanceId ) throws SQLException { return delegate . deleteSchedulerState ( conn , instanceId ) ; } public List selectSchedulerStateRecords ( Connection conn , String instanceId ) throws SQLException { return delegate . selectSchedulerStateRecords ( conn , instanceId ) ; } }",Smelly
"public class AtmosphereTesterTest extends Assert { final AtomicBoolean updateTimeCalled = new AtomicBoolean ( false ) ; final AtomicBoolean receiveMessageCalled = new AtomicBoolean ( false ) ; @ Test public void atmospherePush ( ) { final String updateTimeIsExecuted = ""updateTime is executed!"" ; WicketTester tester = new WicketTester ( ) ; HomePage page = new HomePage ( new PageParameters ( ) ) { @ Subscribe public void updateTime ( AjaxRequestTarget target , Date event ) { super . updateTime ( target , event ) ; updateTimeCalled . set ( true ) ; target . appendJavaScript ( updateTimeIsExecuted ) ; } @ Subscribe ( contextAwareFilter = ReceiverFilter . class ) public void receiveMessage ( AjaxRequestTarget target , ChatMessage message ) { super . receiveMessage ( target , message ) ; receiveMessageCalled . set ( true ) ; } } ; AtmosphereTester waTester = new AtmosphereTester ( tester , page ) ; assertThat ( updateTimeCalled . get ( ) , is ( false ) ) ; assertThat ( receiveMessageCalled . get ( ) , is ( false ) ) ; Date payload = new Date ( ) ; waTester . post ( payload ) ; assertThat ( updateTimeCalled . get ( ) , is ( true ) ) ; assertThat ( receiveMessageCalled . get ( ) , is ( false ) ) ; tester . assertContains ( updateTimeIsExecuted ) ; final FormTester form = tester . newFormTester ( ""form"" ) ; form . setValue ( ""input"" , ""Atmosphere rocks!"" ) ; form . submit ( ""send"" ) ; assertThat ( updateTimeCalled . get ( ) , is ( true ) ) ; assertThat ( receiveMessageCalled . get ( ) , is ( true ) ) ; String atmosphereResponse = waTester . getPushedResponse ( ) ; assertThat ( atmosphereResponse , is ( not ( equalTo ( ""<?xml version=\""1.0\"" encoding=\""UTF-8\""?><ajax-response></ajax-response>"" ) ) ) ) ; waTester . switchOnTestMode ( ) ; tester . assertComponentOnAjaxResponse ( ""message"" ) ; waTester . switchOffTestMode ( ) ; tester . assertLabel ( ""message"" , ""Atmosphere rocks!"" ) ; tester . destroy ( ) ; } }",No
"@ NoJSR250Annotations ( unlessNull = ""bus"" ) public class PolicyEngineImpl implements PolicyEngine , BusExtension { private static final Logger LOG = LogUtils . getL7dLogger ( PolicyEngineImpl . class ) ; private static final String POLICY_INFO_REQUEST_SERVER = ""policy-engine-info-serve-request"" ; private static final String POLICY_INFO_FAULT_SERVER = ""policy-engine-info-serve-fault"" ; private static final String POLICY_INFO_RESPONSE_SERVER = ""policy-engine-info-serve-response"" ; private static final String POLICY_INFO_ENDPOINT_SERVER = ""policy-engine-info-serve-rendpoint"" ; private static final String POLICY_INFO_REQUEST_CLIENT = ""policy-engine-info-client-request"" ; private static final String POLICY_INFO_FAULT_CLIENT = ""policy-engine-info-client-fault"" ; private static final String POLICY_INFO_RESPONSE_CLIENT = ""policy-engine-info-client-response"" ; private static final String POLICY_INFO_ENDPOINT_CLIENT = ""policy-engine-info-client-endpoint"" ; private Bus bus ; private PolicyRegistry registry ; private Collection < PolicyProvider > policyProviders ; private Collection < PolicyProvider > preSetPolicyProviders = new LinkedList < PolicyProvider > ( ) ; private boolean enabled = true ; private Boolean ignoreUnknownAssertions ; private boolean addedBusInterceptors ; private AlternativeSelector alternativeSelector ; public PolicyEngineImpl ( ) { init ( ) ; } public PolicyEngineImpl ( boolean en ) { enabled = en ; init ( ) ; } public PolicyEngineImpl ( Bus b ) { init ( ) ; setBus ( b ) ; } public boolean isEnabled ( ) { return enabled ; } @ Resource public final void setBus ( Bus b ) { if ( this . bus == b ) { return ; } bus = b ; addBusInterceptors ( ) ; FactoryBeanListenerManager fblm = bus . getExtension ( FactoryBeanListenerManager . class ) ; if ( fblm != null ) { for ( FactoryBeanListener l : fblm . getListeners ( ) ) { if ( l instanceof PolicyAnnotationListener ) { return ; } } fblm . addListener ( new PolicyAnnotationListener ( bus ) ) ; } } public Bus getBus ( ) { return bus ; } public void setPolicyProviders ( Collection < PolicyProvider > p ) { policyProviders = new CopyOnWriteArrayList < PolicyProvider > ( p ) ; } public synchronized void addPolicyProvider ( PolicyProvider p ) { if ( policyProviders != null ) { policyProviders . add ( p ) ; } else { preSetPolicyProviders . add ( p ) ; } } public synchronized Collection < PolicyProvider > getPolicyProviders ( ) { if ( policyProviders == null ) { policyProviders = new CopyOnWriteArrayList < PolicyProvider > ( ) ; if ( bus != null ) { ConfiguredBeanLocator loc = bus . getExtension ( ConfiguredBeanLocator . class ) ; if ( loc != null ) { loc . getBeansOfType ( PolicyProvider . class ) ; } } policyProviders . addAll ( preSetPolicyProviders ) ; preSetPolicyProviders = null ; } return policyProviders ; } public void setRegistry ( PolicyRegistry r ) { registry = r ; } public PolicyRegistry getRegistry ( ) { return registry ; } public synchronized void setEnabled ( boolean e ) { enabled = e ; if ( enabled && ! addedBusInterceptors ) { addBusInterceptors ( ) ; } else if ( ! enabled && addedBusInterceptors ) { removeBusInterceptors ( ) ; } } public synchronized AlternativeSelector getAlternativeSelector ( ) { if ( alternativeSelector == null && enabled ) { alternativeSelector = new MinimalAlternativeSelector ( ) ; } return alternativeSelector ; } public void setAlternativeSelector ( AlternativeSelector as ) { alternativeSelector = as ; } public boolean isIgnoreUnknownAssertions ( ) { return ignoreUnknownAssertions == null ? true : ignoreUnknownAssertions ; } public void setIgnoreUnknownAssertions ( boolean ignore ) { ignoreUnknownAssertions = ignore ; } public Class < ? > getRegistrationType ( ) { return PolicyEngine . class ; } public EffectivePolicy getEffectiveClientRequestPolicy ( EndpointInfo ei , BindingOperationInfo boi , Conduit c ) { EffectivePolicy effectivePolicy = ( EffectivePolicy ) boi . getProperty ( POLICY_INFO_REQUEST_CLIENT ) ; if ( null == effectivePolicy ) { EffectivePolicyImpl epi = createOutPolicyInfo ( ) ; Assertor assertor = PolicyUtils . createAsserter ( c ) ; epi . initialise ( ei , boi , this , assertor , true , true ) ; boi . setProperty ( POLICY_INFO_REQUEST_CLIENT , epi ) ; effectivePolicy = epi ; } return effectivePolicy ; } public void setEffectiveClientRequestPolicy ( EndpointInfo ei , BindingOperationInfo boi , EffectivePolicy ep ) { boi . setProperty ( POLICY_INFO_REQUEST_CLIENT , ep ) ; } public EffectivePolicy getEffectiveServerResponsePolicy ( EndpointInfo ei , BindingOperationInfo boi , Destination d , List < List < Assertion > > incoming ) { if ( incoming == null ) { EffectivePolicy effectivePolicy = ( EffectivePolicy ) boi . getProperty ( POLICY_INFO_RESPONSE_SERVER ) ; if ( null == effectivePolicy ) { EffectivePolicyImpl epi = createOutPolicyInfo ( ) ; Assertor assertor = PolicyUtils . createAsserter ( d ) ; epi . initialise ( ei , boi , this , assertor , false , false , incoming ) ; boi . setProperty ( POLICY_INFO_RESPONSE_SERVER , epi ) ; effectivePolicy = epi ; } return effectivePolicy ; } EffectivePolicyImpl epi = createOutPolicyInfo ( ) ; Assertor assertor = PolicyUtils . createAsserter ( d ) ; epi . initialise ( ei , boi , this , assertor , false , false , incoming ) ; return epi ; } public void setEffectiveServerResponsePolicy ( EndpointInfo ei , BindingOperationInfo boi , EffectivePolicy ep ) { boi . setProperty ( POLICY_INFO_RESPONSE_SERVER , ep ) ; } public EffectivePolicy getEffectiveServerFaultPolicy ( EndpointInfo ei , BindingOperationInfo boi , BindingFaultInfo bfi , Destination d ) { if ( bfi == null ) { EffectivePolicyImpl epi = createOutPolicyInfo ( ) ; Assertor assertor = PolicyUtils . createAsserter ( d ) ; epi . initialise ( ei , boi , bfi , this , assertor ) ; return epi ; } bfi = mapToWrappedBindingFaultInfo ( bfi ) ; EffectivePolicy effectivePolicy = ( EffectivePolicy ) bfi . getProperty ( POLICY_INFO_FAULT_SERVER ) ; if ( null == effectivePolicy ) { EffectivePolicyImpl epi = createOutPolicyInfo ( ) ; Assertor assertor = PolicyUtils . createAsserter ( d ) ; epi . initialise ( ei , boi , bfi , this , assertor ) ; bfi . setProperty ( POLICY_INFO_FAULT_SERVER , epi ) ; effectivePolicy = epi ; } return effectivePolicy ; } private BindingFaultInfo mapToWrappedBindingFaultInfo ( BindingFaultInfo bfi ) { BindingOperationInfo boi = bfi . getBindingOperation ( ) ; if ( boi != null && boi . isUnwrapped ( ) ) { boi = boi . getWrappedOperation ( ) ; for ( BindingFaultInfo bf2 : boi . getFaults ( ) ) { if ( bf2 . getFaultInfo ( ) . getName ( ) . equals ( bfi . getFaultInfo ( ) . getName ( ) ) ) { return bf2 ; } } } return bfi ; } public void setEffectiveServerFaultPolicy ( EndpointInfo ei , BindingFaultInfo bfi , EffectivePolicy ep ) { bfi . setProperty ( POLICY_INFO_FAULT_SERVER , ep ) ; } public EndpointPolicy getClientEndpointPolicy ( EndpointInfo ei , Conduit conduit ) { Assertor assertor = PolicyUtils . createAsserter ( conduit ) ; return getEndpointPolicy ( ei , true , assertor ) ; } public EndpointPolicy getServerEndpointPolicy ( EndpointInfo ei , Destination destination ) { Assertor assertor = PolicyUtils . createAsserter ( destination ) ; return getEndpointPolicy ( ei , false , assertor ) ; } private EndpointPolicy getEndpointPolicy ( EndpointInfo ei , boolean isRequestor , Assertor assertor ) { EndpointPolicy ep = ( EndpointPolicy ) ei . getProperty ( isRequestor ? POLICY_INFO_ENDPOINT_CLIENT : POLICY_INFO_ENDPOINT_SERVER ) ; if ( null != ep ) { return ep ; } return createEndpointPolicyInfo ( ei , isRequestor , assertor ) ; } public void setClientEndpointPolicy ( EndpointInfo ei , EndpointPolicy ep ) { ei . setProperty ( POLICY_INFO_ENDPOINT_CLIENT , ep ) ; } public void setServerEndpointPolicy ( EndpointInfo ei , EndpointPolicy ep ) { ei . setProperty ( POLICY_INFO_ENDPOINT_SERVER , ep ) ; } public EffectivePolicy getEffectiveServerRequestPolicy ( EndpointInfo ei , BindingOperationInfo boi ) { EffectivePolicy effectivePolicy = ( EffectivePolicy ) boi . getProperty ( POLICY_INFO_REQUEST_SERVER ) ; if ( null == effectivePolicy ) { EffectivePolicyImpl epi = createOutPolicyInfo ( ) ; epi . initialise ( ei , boi , this , false , true ) ; boi . setProperty ( POLICY_INFO_REQUEST_SERVER , epi ) ; effectivePolicy = epi ; } return effectivePolicy ; } public void setEffectiveServerRequestPolicy ( EndpointInfo ei , BindingOperationInfo boi , EffectivePolicy ep ) { boi . setProperty ( POLICY_INFO_REQUEST_SERVER , ep ) ; } public EffectivePolicy getEffectiveClientResponsePolicy ( EndpointInfo ei , BindingOperationInfo boi ) { EffectivePolicy effectivePolicy = ( EffectivePolicy ) boi . getProperty ( POLICY_INFO_RESPONSE_CLIENT ) ; if ( null == effectivePolicy ) { EffectivePolicyImpl epi = createOutPolicyInfo ( ) ; epi . initialise ( ei , boi , this , true , false ) ; boi . setProperty ( POLICY_INFO_RESPONSE_CLIENT , epi ) ; effectivePolicy = epi ; } return effectivePolicy ; } public void setEffectiveClientResponsePolicy ( EndpointInfo ei , BindingOperationInfo boi , EffectivePolicy ep ) { boi . setProperty ( POLICY_INFO_RESPONSE_CLIENT , ep ) ; } public EffectivePolicy getEffectiveClientFaultPolicy ( EndpointInfo ei , BindingOperationInfo boi , BindingFaultInfo bfi ) { EffectivePolicy effectivePolicy = null ; if ( bfi != null ) { effectivePolicy = ( EffectivePolicy ) bfi . getProperty ( POLICY_INFO_FAULT_CLIENT ) ; } if ( null == effectivePolicy ) { EffectivePolicyImpl epi = createOutPolicyInfo ( ) ; epi . initialisePolicy ( ei , boi , bfi , this ) ; if ( bfi != null ) { bfi . setProperty ( POLICY_INFO_FAULT_CLIENT , epi ) ; } effectivePolicy = epi ; } return effectivePolicy ; } public void setEffectiveClientFaultPolicy ( EndpointInfo ei , BindingFaultInfo bfi , EffectivePolicy ep ) { bfi . setProperty ( POLICY_INFO_FAULT_CLIENT , ep ) ; } protected final void init ( ) { registry = new PolicyRegistryImpl ( ) ; } public synchronized void removeBusInterceptors ( ) { bus . getInInterceptors ( ) . remove ( PolicyInInterceptor . INSTANCE ) ; bus . getOutInterceptors ( ) . remove ( PolicyOutInterceptor . INSTANCE ) ; bus . getInFaultInterceptors ( ) . remove ( ClientPolicyInFaultInterceptor . INSTANCE ) ; bus . getOutFaultInterceptors ( ) . remove ( ServerPolicyOutFaultInterceptor . INSTANCE ) ; bus . getInFaultInterceptors ( ) . remove ( PolicyVerificationInFaultInterceptor . INSTANCE ) ; addedBusInterceptors = false ; } public final synchronized void addBusInterceptors ( ) { if ( null == bus || ! enabled ) { return ; } if ( ignoreUnknownAssertions != null ) { AssertionBuilderRegistry abr = bus . getExtension ( AssertionBuilderRegistry . class ) ; if ( null != abr ) { abr . setIgnoreUnknownAssertions ( ignoreUnknownAssertions ) ; } } bus . getInInterceptors ( ) . add ( PolicyInInterceptor . INSTANCE ) ; bus . getOutInterceptors ( ) . add ( PolicyOutInterceptor . INSTANCE ) ; bus . getInFaultInterceptors ( ) . add ( ClientPolicyInFaultInterceptor . INSTANCE ) ; bus . getOutFaultInterceptors ( ) . add ( ServerPolicyOutFaultInterceptor . INSTANCE ) ; bus . getInFaultInterceptors ( ) . add ( PolicyVerificationInFaultInterceptor . INSTANCE ) ; addedBusInterceptors = true ; } Policy getAggregatedServicePolicy ( ServiceInfo si ) { if ( si == null ) { return new Policy ( ) ; } Policy aggregated = null ; for ( PolicyProvider pp : getPolicyProviders ( ) ) { Policy p = pp . getEffectivePolicy ( si ) ; if ( null == aggregated ) { aggregated = p ; } else if ( p != null ) { aggregated = aggregated . merge ( p ) ; } } return aggregated == null ? new Policy ( ) : aggregated ; } Policy getAggregatedEndpointPolicy ( EndpointInfo ei ) { Policy aggregated = null ; for ( PolicyProvider pp : getPolicyProviders ( ) ) { Policy p = pp . getEffectivePolicy ( ei ) ; if ( null == aggregated ) { aggregated = p ; } else if ( p != null ) { aggregated = aggregated . merge ( p ) ; } } return aggregated == null ? new Policy ( ) : aggregated ; } Policy getAggregatedOperationPolicy ( BindingOperationInfo boi ) { Policy aggregated = null ; for ( PolicyProvider pp : getPolicyProviders ( ) ) { Policy p = pp . getEffectivePolicy ( boi ) ; if ( null == aggregated ) { aggregated = p ; } else if ( p != null ) { aggregated = aggregated . merge ( p ) ; } } return aggregated == null ? new Policy ( ) : aggregated ; } Policy getAggregatedMessagePolicy ( BindingMessageInfo bmi ) { Policy aggregated = null ; for ( PolicyProvider pp : getPolicyProviders ( ) ) { Policy p = pp . getEffectivePolicy ( bmi ) ; if ( null == aggregated ) { aggregated = p ; } else if ( p != null ) { aggregated = aggregated . merge ( p ) ; } } return aggregated == null ? new Policy ( ) : aggregated ; } Policy getAggregatedFaultPolicy ( BindingFaultInfo bfi ) { Policy aggregated = null ; for ( PolicyProvider pp : getPolicyProviders ( ) ) { Policy p = pp . getEffectivePolicy ( bfi ) ; if ( null == aggregated ) { aggregated = p ; } else if ( p != null ) { aggregated = aggregated . merge ( p ) ; } } return aggregated == null ? new Policy ( ) : aggregated ; } Collection < Assertion > getAssertions ( PolicyComponent pc , boolean includeOptional ) { Collection < Assertion > assertions = new ArrayList < Assertion > ( ) ; if ( Constants . TYPE_ASSERTION == pc . getType ( ) ) { Assertion a = ( Assertion ) pc ; if ( includeOptional || ! a . isOptional ( ) ) { assertions . add ( a ) ; } } else { addAssertions ( pc , includeOptional , assertions ) ; } return assertions ; } Collection < Assertion > getAssertions ( EffectivePolicy pc , boolean includeOptional ) { if ( pc == null || pc . getChosenAlternative ( ) == null ) { return null ; } Collection < Assertion > assertions = new ArrayList < Assertion > ( ) ; for ( Assertion assertion : pc . getChosenAlternative ( ) ) { if ( Constants . TYPE_ASSERTION == assertion . getType ( ) ) { if ( includeOptional || ! assertion . isOptional ( ) ) { assertions . add ( assertion ) ; } } else { addAssertions ( assertion , includeOptional , assertions ) ; } } return assertions ; } void addAssertions ( PolicyComponent pc , boolean includeOptional , Collection < Assertion > assertions ) { if ( Constants . TYPE_ASSERTION == pc . getType ( ) ) { Assertion a = ( Assertion ) pc ; if ( includeOptional || ! a . isOptional ( ) ) { assertions . add ( ( Assertion ) pc ) ; } return ; } if ( Constants . TYPE_POLICY_REF == pc . getType ( ) ) { PolicyReference pr = ( PolicyReference ) pc ; pc = pr . normalize ( registry , false ) ; } PolicyOperator po = ( PolicyOperator ) pc ; List < PolicyComponent > pcs = CastUtils . cast ( po . getPolicyComponents ( ) , PolicyComponent . class ) ; for ( PolicyComponent child : pcs ) { addAssertions ( child , includeOptional , assertions ) ; } } Set < QName > getVocabulary ( PolicyComponent pc , boolean includeOptional ) { Collection < Assertion > assertions = getAssertions ( pc , includeOptional ) ; Set < QName > vocabulary = new HashSet < QName > ( ) ; for ( Assertion a : assertions ) { vocabulary . add ( a . getName ( ) ) ; } return vocabulary ; } EndpointPolicyImpl createEndpointPolicyInfo ( EndpointInfo ei , boolean isRequestor , Assertor assertor ) { EndpointPolicyImpl epi = new EndpointPolicyImpl ( ei , this , isRequestor , assertor ) ; epi . initialize ( ) ; ei . setProperty ( isRequestor ? POLICY_INFO_ENDPOINT_CLIENT : POLICY_INFO_ENDPOINT_SERVER , epi ) ; return epi ; } public boolean supportsAlternative ( Collection < ? extends PolicyComponent > alternative , Assertor assertor ) { PolicyInterceptorProviderRegistry pipr = bus . getExtension ( PolicyInterceptorProviderRegistry . class ) ; for ( PolicyComponent pc : alternative ) { if ( pc instanceof Assertion ) { Assertion a = ( Assertion ) pc ; if ( ! ( a . isOptional ( ) || ! pipr . get ( a . getName ( ) ) . isEmpty ( ) || ( null != assertor && assertor . canAssert ( a . getName ( ) ) ) ) ) { LOG . fine ( ""Alternative "" + a . getName ( ) + "" is not supported"" ) ; return false ; } } else { return false ; } } return true ; } EffectivePolicyImpl createOutPolicyInfo ( ) { return new EffectivePolicyImpl ( ) ; } }",Smelly
"@ Transactional ( ""Master"" ) public class AnySearchTest extends AbstractTest { @ Autowired private AnyObjectDAO anyObjectDAO ; @ Autowired private UserDAO userDAO ; @ Autowired private GroupDAO groupDAO ; @ Autowired private AnySearchDAO searchDAO ; @ Autowired private AnyTypeDAO anyTypeDAO ; @ Autowired private RealmDAO realmDAO ; @ Test public void anyObjectMatch ( ) { AnyObject anyObject = anyObjectDAO . find ( ""fc6dbc3a-6c07-4965-8781-921e7401a4a5"" ) ; assertNotNull ( anyObject ) ; RelationshipCond relationshipCond = new RelationshipCond ( ) ; relationshipCond . setAnyObject ( ""Canon MF 8030cn"" ) ; assertTrue ( searchDAO . matches ( anyObject , SearchCond . getLeafCond ( relationshipCond ) ) ) ; RelationshipTypeCond relationshipTypeCond = new RelationshipTypeCond ( ) ; relationshipTypeCond . setRelationshipTypeKey ( ""neighborhood"" ) ; assertTrue ( searchDAO . matches ( anyObject , SearchCond . getLeafCond ( relationshipTypeCond ) ) ) ; } @ Test public void userMatch ( ) { User user = userDAO . find ( ""1417acbe-cbf6-4277-9372-e75e04f97000"" ) ; assertNotNull ( user ) ; MembershipCond groupCond = new MembershipCond ( ) ; groupCond . setGroup ( ""secretary"" ) ; assertFalse ( searchDAO . matches ( user , SearchCond . getLeafCond ( groupCond ) ) ) ; groupCond . setGroup ( ""root"" ) ; assertTrue ( searchDAO . matches ( user , SearchCond . getLeafCond ( groupCond ) ) ) ; RoleCond roleCond = new RoleCond ( ) ; roleCond . setRole ( ""Other"" ) ; assertTrue ( searchDAO . matches ( user , SearchCond . getLeafCond ( roleCond ) ) ) ; user = userDAO . find ( ""c9b2dec2-00a7-4855-97c0-d854842b4b24"" ) ; assertNotNull ( user ) ; RelationshipCond relationshipCond = new RelationshipCond ( ) ; relationshipCond . setAnyObject ( ""fc6dbc3a-6c07-4965-8781-921e7401a4a5"" ) ; assertTrue ( searchDAO . matches ( user , SearchCond . getLeafCond ( relationshipCond ) ) ) ; RelationshipTypeCond relationshipTypeCond = new RelationshipTypeCond ( ) ; relationshipTypeCond . setRelationshipTypeKey ( ""neighborhood"" ) ; assertTrue ( searchDAO . matches ( user , SearchCond . getLeafCond ( relationshipTypeCond ) ) ) ; } @ Test public void groupMatch ( ) { Group group = groupDAO . find ( ""37d15e4c-cdc1-460b-a591-8505c8133806"" ) ; assertNotNull ( group ) ; AttributeCond attrCond = new AttributeCond ( ) ; attrCond . setSchema ( ""show"" ) ; attrCond . setType ( AttributeCond . Type . ISNOTNULL ) ; assertTrue ( searchDAO . matches ( group , SearchCond . getLeafCond ( attrCond ) ) ) ; } @ Test public void searchWithLikeCondition ( ) { AttributeCond fullnameLeafCond = new AttributeCond ( AttributeCond . Type . LIKE ) ; fullnameLeafCond . setSchema ( ""fullname"" ) ; fullnameLeafCond . setExpression ( ""%o%"" ) ; MembershipCond groupCond = new MembershipCond ( ) ; groupCond . setGroup ( ""root"" ) ; AttributeCond loginDateCond = new AttributeCond ( AttributeCond . Type . EQ ) ; loginDateCond . setSchema ( ""loginDate"" ) ; loginDateCond . setExpression ( ""2009-05-26"" ) ; SearchCond subCond = SearchCond . getAndCond ( SearchCond . getLeafCond ( fullnameLeafCond ) , SearchCond . getLeafCond ( groupCond ) ) ; assertTrue ( subCond . isValid ( ) ) ; SearchCond cond = SearchCond . getAndCond ( subCond , SearchCond . getLeafCond ( loginDateCond ) ) ; assertTrue ( cond . isValid ( ) ) ; List < User > users = searchDAO . search ( cond , AnyTypeKind . USER ) ; assertNotNull ( users ) ; assertEquals ( 1 , users . size ( ) ) ; } @ Test public void searchCaseInsensitiveWithLikeCondition ( ) { AttributeCond fullnameLeafCond = new AttributeCond ( AttributeCond . Type . ILIKE ) ; fullnameLeafCond . setSchema ( ""fullname"" ) ; fullnameLeafCond . setExpression ( ""%O%"" ) ; MembershipCond groupCond = new MembershipCond ( ) ; groupCond . setGroup ( ""root"" ) ; AttributeCond loginDateCond = new AttributeCond ( AttributeCond . Type . EQ ) ; loginDateCond . setSchema ( ""loginDate"" ) ; loginDateCond . setExpression ( ""2009-05-26"" ) ; SearchCond subCond = SearchCond . getAndCond ( SearchCond . getLeafCond ( fullnameLeafCond ) , SearchCond . getLeafCond ( groupCond ) ) ; assertTrue ( subCond . isValid ( ) ) ; SearchCond cond = SearchCond . getAndCond ( subCond , SearchCond . getLeafCond ( loginDateCond ) ) ; assertTrue ( cond . isValid ( ) ) ; List < User > users = searchDAO . search ( cond , AnyTypeKind . USER ) ; assertNotNull ( users ) ; assertEquals ( 1 , users . size ( ) ) ; } @ Test public void searchWithNotCondition ( ) { AttributeCond fullnameLeafCond = new AttributeCond ( AttributeCond . Type . EQ ) ; fullnameLeafCond . setSchema ( ""fullname"" ) ; fullnameLeafCond . setExpression ( ""Giuseppe Verdi"" ) ; SearchCond cond = SearchCond . getNotLeafCond ( fullnameLeafCond ) ; assertTrue ( cond . isValid ( ) ) ; List < User > users = searchDAO . search ( cond , AnyTypeKind . USER ) ; assertNotNull ( users ) ; assertEquals ( 4 , users . size ( ) ) ; Set < String > ids = new HashSet < > ( users . size ( ) ) ; for ( User user : users ) { ids . add ( user . getKey ( ) ) ; } assertTrue ( ids . contains ( ""1417acbe-cbf6-4277-9372-e75e04f97000"" ) ) ; assertTrue ( ids . contains ( ""b3cbc78d-32e6-4bd4-92e0-bbe07566a2ee"" ) ) ; } @ Test public void searchCaseInsensitiveWithNotCondition ( ) { AttributeCond fullnameLeafCond = new AttributeCond ( AttributeCond . Type . IEQ ) ; fullnameLeafCond . setSchema ( ""fullname"" ) ; fullnameLeafCond . setExpression ( ""giuseppe verdi"" ) ; SearchCond cond = SearchCond . getNotLeafCond ( fullnameLeafCond ) ; assertTrue ( cond . isValid ( ) ) ; List < User > users = searchDAO . search ( cond , AnyTypeKind . USER ) ; assertNotNull ( users ) ; assertEquals ( 4 , users . size ( ) ) ; Set < String > ids = new HashSet < > ( users . size ( ) ) ; for ( User user : users ) { ids . add ( user . getKey ( ) ) ; } assertTrue ( ids . contains ( ""1417acbe-cbf6-4277-9372-e75e04f97000"" ) ) ; assertTrue ( ids . contains ( ""b3cbc78d-32e6-4bd4-92e0-bbe07566a2ee"" ) ) ; } @ Test public void searchByBoolean ( ) { AttributeCond coolLeafCond = new AttributeCond ( AttributeCond . Type . EQ ) ; coolLeafCond . setSchema ( ""cool"" ) ; coolLeafCond . setExpression ( ""true"" ) ; SearchCond cond = SearchCond . getLeafCond ( coolLeafCond ) ; assertTrue ( cond . isValid ( ) ) ; List < User > users = searchDAO . search ( cond , AnyTypeKind . USER ) ; assertNotNull ( users ) ; assertEquals ( 1 , users . size ( ) ) ; assertEquals ( ""c9b2dec2-00a7-4855-97c0-d854842b4b24"" , users . get ( 0 ) . getKey ( ) ) ; } @ Test public void searchByPageAndSize ( ) { AttributeCond fullnameLeafCond = new AttributeCond ( AttributeCond . Type . LIKE ) ; fullnameLeafCond . setSchema ( ""fullname"" ) ; fullnameLeafCond . setExpression ( ""%o%"" ) ; MembershipCond groupCond = new MembershipCond ( ) ; groupCond . setGroup ( ""root"" ) ; AttributeCond loginDateCond = new AttributeCond ( AttributeCond . Type . EQ ) ; loginDateCond . setSchema ( ""loginDate"" ) ; loginDateCond . setExpression ( ""2009-05-26"" ) ; SearchCond subCond = SearchCond . getAndCond ( SearchCond . getLeafCond ( fullnameLeafCond ) , SearchCond . getLeafCond ( groupCond ) ) ; assertTrue ( subCond . isValid ( ) ) ; SearchCond cond = SearchCond . getAndCond ( subCond , SearchCond . getLeafCond ( loginDateCond ) ) ; assertTrue ( cond . isValid ( ) ) ; List < User > users = searchDAO . search ( SyncopeConstants . FULL_ADMIN_REALMS , cond , 1 , 2 , Collections . < OrderByClause > emptyList ( ) , AnyTypeKind . USER ) ; assertNotNull ( users ) ; assertEquals ( 1 , users . size ( ) ) ; users = searchDAO . search ( SyncopeConstants . FULL_ADMIN_REALMS , cond , 2 , 2 , Collections . < OrderByClause > emptyList ( ) , AnyTypeKind . USER ) ; assertNotNull ( users ) ; assertTrue ( users . isEmpty ( ) ) ; } @ Test public void searchByGroup ( ) { MembershipCond groupCond = new MembershipCond ( ) ; groupCond . setGroup ( ""root"" ) ; List < User > users = searchDAO . search ( SearchCond . getLeafCond ( groupCond ) , AnyTypeKind . USER ) ; assertNotNull ( users ) ; assertEquals ( 2 , users . size ( ) ) ; groupCond = new MembershipCond ( ) ; groupCond . setGroup ( ""secretary"" ) ; users = searchDAO . search ( SearchCond . getNotLeafCond ( groupCond ) , AnyTypeKind . USER ) ; assertNotNull ( users ) ; assertEquals ( 5 , users . size ( ) ) ; } @ Test public void searchByRole ( ) { RoleCond roleCond = new RoleCond ( ) ; roleCond . setRole ( ""Other"" ) ; List < User > users = searchDAO . search ( SearchCond . getLeafCond ( roleCond ) , AnyTypeKind . USER ) ; assertNotNull ( users ) ; assertEquals ( 1 , users . size ( ) ) ; } @ Test public void searchByIsNull ( ) { AttributeCond coolLeafCond = new AttributeCond ( AttributeCond . Type . ISNULL ) ; coolLeafCond . setSchema ( ""cool"" ) ; List < User > users = searchDAO . search ( SearchCond . getLeafCond ( coolLeafCond ) , AnyTypeKind . USER ) ; assertNotNull ( users ) ; assertEquals ( 4 , users . size ( ) ) ; coolLeafCond = new AttributeCond ( AttributeCond . Type . ISNOTNULL ) ; coolLeafCond . setSchema ( ""cool"" ) ; users = searchDAO . search ( SearchCond . getLeafCond ( coolLeafCond ) , AnyTypeKind . USER ) ; assertNotNull ( users ) ; assertEquals ( 1 , users . size ( ) ) ; } @ Test public void searchByResource ( ) { ResourceCond ws2 = new ResourceCond ( ) ; ws2 . setResourceKey ( ""ws-target-resource-2"" ) ; ResourceCond ws1 = new ResourceCond ( ) ; ws1 . setResourceKey ( ""ws-target-resource-list-mappings-2"" ) ; SearchCond searchCondition = SearchCond . getAndCond ( SearchCond . getNotLeafCond ( ws2 ) , SearchCond . getLeafCond ( ws1 ) ) ; assertTrue ( searchCondition . isValid ( ) ) ; List < User > users = searchDAO . search ( searchCondition , AnyTypeKind . USER ) ; assertNotNull ( users ) ; assertEquals ( 1 , users . size ( ) ) ; } @ Test public void searchByBooleanAnyCond ( ) { AttributeCond booleanCond = new AttributeCond ( AnyCond . Type . EQ ) ; booleanCond . setSchema ( ""show"" ) ; booleanCond . setExpression ( ""true"" ) ; List < Group > matchingGroups = searchDAO . search ( SearchCond . getLeafCond ( booleanCond ) , AnyTypeKind . GROUP ) ; assertNotNull ( matchingGroups ) ; assertFalse ( matchingGroups . isEmpty ( ) ) ; } @ Test public void searchByUsernameAndKey ( ) { AnyCond usernameLeafCond = new AnyCond ( AnyCond . Type . LIKE ) ; usernameLeafCond . setSchema ( ""username"" ) ; usernameLeafCond . setExpression ( ""%ini"" ) ; AnyCond idRightCond = new AnyCond ( AnyCond . Type . LT ) ; idRightCond . setSchema ( ""id"" ) ; idRightCond . setExpression ( ""2"" ) ; SearchCond searchCondition = SearchCond . getAndCond ( SearchCond . getLeafCond ( usernameLeafCond ) , SearchCond . getLeafCond ( idRightCond ) ) ; List < User > matching = searchDAO . search ( searchCondition , AnyTypeKind . USER ) ; assertNotNull ( matching ) ; assertEquals ( 1 , matching . size ( ) ) ; assertEquals ( ""rossini"" , matching . iterator ( ) . next ( ) . getUsername ( ) ) ; assertEquals ( ""1417acbe-cbf6-4277-9372-e75e04f97000"" , matching . iterator ( ) . next ( ) . getKey ( ) ) ; } @ Test public void searchByGroupNameAndKey ( ) { AnyCond groupNameLeafCond = new AnyCond ( AnyCond . Type . EQ ) ; groupNameLeafCond . setSchema ( ""name"" ) ; groupNameLeafCond . setExpression ( ""root"" ) ; AnyCond idRightCond = new AnyCond ( AnyCond . Type . EQ ) ; idRightCond . setSchema ( ""id"" ) ; idRightCond . setExpression ( ""37d15e4c-cdc1-460b-a591-8505c8133806"" ) ; SearchCond searchCondition = SearchCond . getAndCond ( SearchCond . getLeafCond ( groupNameLeafCond ) , SearchCond . getLeafCond ( idRightCond ) ) ; assertTrue ( searchCondition . isValid ( ) ) ; List < Group > matching = searchDAO . search ( searchCondition , AnyTypeKind . GROUP ) ; assertNotNull ( matching ) ; assertEquals ( 1 , matching . size ( ) ) ; assertEquals ( ""root"" , matching . iterator ( ) . next ( ) . getName ( ) ) ; assertEquals ( ""37d15e4c-cdc1-460b-a591-8505c8133806"" , matching . iterator ( ) . next ( ) . getKey ( ) ) ; } @ Test public void searchByUsernameAndFullname ( ) { AnyCond usernameLeafCond = new AnyCond ( AnyCond . Type . EQ ) ; usernameLeafCond . setSchema ( ""username"" ) ; usernameLeafCond . setExpression ( ""rossini"" ) ; AttributeCond idRightCond = new AttributeCond ( AttributeCond . Type . LIKE ) ; idRightCond . setSchema ( ""fullname"" ) ; idRightCond . setExpression ( ""Giuseppe V%"" ) ; SearchCond searchCondition = SearchCond . getOrCond ( SearchCond . getLeafCond ( usernameLeafCond ) , SearchCond . getLeafCond ( idRightCond ) ) ; List < User > matchingUsers = searchDAO . search ( searchCondition , AnyTypeKind . USER ) ; assertNotNull ( matchingUsers ) ; assertEquals ( 2 , matchingUsers . size ( ) ) ; } @ Test public void searchByUsernameAndFullnameIgnoreCase ( ) { AnyCond usernameLeafCond = new AnyCond ( AnyCond . Type . IEQ ) ; usernameLeafCond . setSchema ( ""username"" ) ; usernameLeafCond . setExpression ( ""RoSsini"" ) ; AttributeCond idRightCond = new AttributeCond ( AttributeCond . Type . ILIKE ) ; idRightCond . setSchema ( ""fullname"" ) ; idRightCond . setExpression ( ""gIuseppe v%"" ) ; SearchCond searchCondition = SearchCond . getOrCond ( SearchCond . getLeafCond ( usernameLeafCond ) , SearchCond . getLeafCond ( idRightCond ) ) ; List < User > matchingUsers = searchDAO . search ( searchCondition , AnyTypeKind . USER ) ; assertNotNull ( matchingUsers ) ; assertEquals ( 2 , matchingUsers . size ( ) ) ; } @ Test public void searchByKey ( ) { AnyCond idLeafCond = new AnyCond ( AnyCond . Type . EQ ) ; idLeafCond . setSchema ( ""id"" ) ; idLeafCond . setExpression ( ""74cd8ece-715a-44a4-a736-e17b46c4e7e6"" ) ; SearchCond searchCondition = SearchCond . getLeafCond ( idLeafCond ) ; assertTrue ( searchCondition . isValid ( ) ) ; List < User > users = searchDAO . search ( searchCondition , AnyTypeKind . USER ) ; assertNotNull ( users ) ; assertEquals ( 1 , users . size ( ) ) ; assertEquals ( ""74cd8ece-715a-44a4-a736-e17b46c4e7e6"" , users . iterator ( ) . next ( ) . getKey ( ) ) ; } @ Test public void searchByType ( ) { AnyTypeCond tcond = new AnyTypeCond ( ) ; tcond . setAnyTypeKey ( ""PRINTER"" ) ; SearchCond searchCondition = SearchCond . getLeafCond ( tcond ) ; assertTrue ( searchCondition . isValid ( ) ) ; List < AnyObject > printers = searchDAO . search ( searchCondition , AnyTypeKind . ANY_OBJECT ) ; assertNotNull ( printers ) ; assertEquals ( 3 , printers . size ( ) ) ; tcond . setAnyTypeKey ( ""UNEXISTING"" ) ; printers = searchDAO . search ( searchCondition , AnyTypeKind . ANY_OBJECT ) ; assertNotNull ( printers ) ; assertTrue ( printers . isEmpty ( ) ) ; } @ Test public void searchByRelationshipType ( ) { RelationshipTypeCond relationshipTypeCond = new RelationshipTypeCond ( ) ; relationshipTypeCond . setRelationshipTypeKey ( ""neighborhood"" ) ; AnyTypeCond tcond = new AnyTypeCond ( ) ; tcond . setAnyTypeKey ( ""PRINTER"" ) ; SearchCond searchCondition = SearchCond . getAndCond ( SearchCond . getLeafCond ( relationshipTypeCond ) , SearchCond . getLeafCond ( tcond ) ) ; assertTrue ( searchCondition . isValid ( ) ) ; List < AnyObject > matching = searchDAO . search ( searchCondition , AnyTypeKind . ANY_OBJECT ) ; assertNotNull ( matching ) ; assertEquals ( 2 , matching . size ( ) ) ; assertTrue ( IterableUtils . matchesAny ( matching , new Predicate < AnyObject > ( ) { @ Override public boolean evaluate ( final AnyObject any ) { return ""fc6dbc3a-6c07-4965-8781-921e7401a4a5"" . equals ( any . getKey ( ) ) ; } } ) ) ; assertTrue ( IterableUtils . matchesAny ( matching , new Predicate < AnyObject > ( ) { @ Override public boolean evaluate ( final AnyObject any ) { return ""8559d14d-58c2-46eb-a2d4-a7d35161e8f8"" . equals ( any . getKey ( ) ) ; } } ) ) ; searchCondition = SearchCond . getLeafCond ( relationshipTypeCond ) ; matching = searchDAO . search ( searchCondition , AnyTypeKind . USER ) ; assertNotNull ( matching ) ; assertEquals ( 1 , matching . size ( ) ) ; assertTrue ( IterableUtils . matchesAny ( matching , new Predicate < Any < ? > > ( ) { @ Override public boolean evaluate ( final Any < ? > any ) { return ""c9b2dec2-00a7-4855-97c0-d854842b4b24"" . equals ( any . getKey ( ) ) ; } } ) ) ; } @ Test public void userOrderBy ( ) { AnyCond usernameLeafCond = new AnyCond ( AnyCond . Type . EQ ) ; usernameLeafCond . setSchema ( ""username"" ) ; usernameLeafCond . setExpression ( ""rossini"" ) ; AttributeCond idRightCond = new AttributeCond ( AttributeCond . Type . LIKE ) ; idRightCond . setSchema ( ""fullname"" ) ; idRightCond . setExpression ( ""Giuseppe V%"" ) ; SearchCond searchCondition = SearchCond . getOrCond ( SearchCond . getLeafCond ( usernameLeafCond ) , SearchCond . getLeafCond ( idRightCond ) ) ; List < OrderByClause > orderByClauses = new ArrayList < > ( ) ; OrderByClause orderByClause = new OrderByClause ( ) ; orderByClause . setField ( ""username"" ) ; orderByClause . setDirection ( OrderByClause . Direction . DESC ) ; orderByClauses . add ( orderByClause ) ; orderByClause = new OrderByClause ( ) ; orderByClause . setField ( ""fullname"" ) ; orderByClause . setDirection ( OrderByClause . Direction . ASC ) ; orderByClauses . add ( orderByClause ) ; List < User > users = searchDAO . search ( searchCondition , orderByClauses , AnyTypeKind . USER ) ; assertEquals ( searchDAO . count ( SyncopeConstants . FULL_ADMIN_REALMS , searchCondition , AnyTypeKind . USER ) , users . size ( ) ) ; } @ Test public void groupOrderBy ( ) { AnyCond idLeafCond = new AnyCond ( AnyCond . Type . LIKE ) ; idLeafCond . setSchema ( ""name"" ) ; idLeafCond . setExpression ( ""%r"" ) ; SearchCond searchCondition = SearchCond . getLeafCond ( idLeafCond ) ; assertTrue ( searchCondition . isValid ( ) ) ; OrderByClause orderByClause = new OrderByClause ( ) ; orderByClause . setField ( ""name"" ) ; List < Group > groups = searchDAO . search ( searchCondition , Collections . singletonList ( orderByClause ) , AnyTypeKind . GROUP ) ; assertEquals ( searchDAO . count ( SyncopeConstants . FULL_ADMIN_REALMS , searchCondition , AnyTypeKind . GROUP ) , groups . size ( ) ) ; } @ Test public void assignable ( ) { AssignableCond assignableCond = new AssignableCond ( ) ; assignableCond . setRealmFullPath ( ""/even/two"" ) ; SearchCond searchCondition = SearchCond . getLeafCond ( assignableCond ) ; assertTrue ( searchCondition . isValid ( ) ) ; List < Group > groups = searchDAO . search ( searchCondition , AnyTypeKind . GROUP ) ; assertTrue ( IterableUtils . matchesAny ( groups , new Predicate < Group > ( ) { @ Override public boolean evaluate ( final Group group ) { return ""additional"" . equals ( group . getName ( ) ) ; } } ) ) ; assertFalse ( IterableUtils . matchesAny ( groups , new Predicate < Group > ( ) { @ Override public boolean evaluate ( final Group group ) { return ""fake"" . equals ( group . getName ( ) ) ; } } ) ) ; assignableCond = new AssignableCond ( ) ; assignableCond . setRealmFullPath ( ""/odd"" ) ; searchCondition = SearchCond . getLeafCond ( assignableCond ) ; assertTrue ( searchCondition . isValid ( ) ) ; List < AnyObject > anyObjects = searchDAO . search ( searchCondition , AnyTypeKind . ANY_OBJECT ) ; assertFalse ( IterableUtils . matchesAny ( anyObjects , new Predicate < AnyObject > ( ) { @ Override public boolean evaluate ( final AnyObject anyObject ) { return ""9e1d130c-d6a3-48b1-98b3-182477ed0688"" . equals ( anyObject . getKey ( ) ) ; } } ) ) ; } @ Test public void member ( ) { MemberCond memberCond = new MemberCond ( ) ; memberCond . setMember ( ""1417acbe-cbf6-4277-9372-e75e04f97000"" ) ; SearchCond searchCondition = SearchCond . getLeafCond ( memberCond ) ; assertTrue ( searchCondition . isValid ( ) ) ; List < Group > groups = searchDAO . search ( searchCondition , AnyTypeKind . GROUP ) ; assertEquals ( 2 , groups . size ( ) ) ; assertTrue ( groups . contains ( groupDAO . findByName ( ""root"" ) ) ) ; assertTrue ( groups . contains ( groupDAO . findByName ( ""otherchild"" ) ) ) ; } @ Test public void issue202 ( ) { ResourceCond ws2 = new ResourceCond ( ) ; ws2 . setResourceKey ( ""ws-target-resource-2"" ) ; ResourceCond ws1 = new ResourceCond ( ) ; ws1 . setResourceKey ( ""ws-target-resource-list-mappings-1"" ) ; SearchCond searchCondition = SearchCond . getAndCond ( SearchCond . getNotLeafCond ( ws2 ) , SearchCond . getNotLeafCond ( ws1 ) ) ; assertTrue ( searchCondition . isValid ( ) ) ; List < User > users = searchDAO . search ( searchCondition , AnyTypeKind . USER ) ; assertNotNull ( users ) ; assertEquals ( 2 , users . size ( ) ) ; assertTrue ( IterableUtils . matchesAny ( users , new Predicate < User > ( ) { @ Override public boolean evaluate ( final User user ) { return ""c9b2dec2-00a7-4855-97c0-d854842b4b24"" . equals ( user . getKey ( ) ) ; } } ) ) ; } @ Test public void issue242 ( ) { AnyCond cond = new AnyCond ( AttributeCond . Type . LIKE ) ; cond . setSchema ( ""id"" ) ; cond . setExpression ( ""test%"" ) ; SearchCond searchCondition = SearchCond . getLeafCond ( cond ) ; assertTrue ( searchCondition . isValid ( ) ) ; List < User > users = searchDAO . search ( searchCondition , AnyTypeKind . USER ) ; assertNotNull ( users ) ; assertTrue ( users . isEmpty ( ) ) ; } @ Test public void issueSYNCOPE46 ( ) { AnyCond cond = new AnyCond ( AttributeCond . Type . LIKE ) ; cond . setSchema ( ""username"" ) ; cond . setExpression ( ""%ossin%"" ) ; SearchCond searchCondition = SearchCond . getLeafCond ( cond ) ; assertTrue ( searchCondition . isValid ( ) ) ; List < User > users = searchDAO . search ( searchCondition , AnyTypeKind . USER ) ; assertNotNull ( users ) ; assertEquals ( 1 , users . size ( ) ) ; } @ Test public void issueSYNCOPE433 ( ) { AttributeCond isNullCond = new AttributeCond ( AttributeCond . Type . ISNULL ) ; isNullCond . setSchema ( ""loginDate"" ) ; AnyCond likeCond = new AnyCond ( AttributeCond . Type . LIKE ) ; likeCond . setSchema ( ""username"" ) ; likeCond . setExpression ( ""%ossin%"" ) ; SearchCond searchCond = SearchCond . getOrCond ( SearchCond . getLeafCond ( isNullCond ) , SearchCond . getLeafCond ( likeCond ) ) ; Integer count = searchDAO . count ( SyncopeConstants . FULL_ADMIN_REALMS , searchCond , AnyTypeKind . USER ) ; assertNotNull ( count ) ; assertTrue ( count > 0 ) ; } @ Test public void issueSYNCOPE929 ( ) { AttributeCond rossiniCond = new AttributeCond ( AttributeCond . Type . EQ ) ; rossiniCond . setSchema ( ""surname"" ) ; rossiniCond . setExpression ( ""Rossini"" ) ; AttributeCond genderCond = new AttributeCond ( AttributeCond . Type . EQ ) ; genderCond . setSchema ( ""gender"" ) ; genderCond . setExpression ( ""M"" ) ; SearchCond orCond = SearchCond . getOrCond ( SearchCond . getLeafCond ( rossiniCond ) , SearchCond . getLeafCond ( genderCond ) ) ; AttributeCond belliniCond = new AttributeCond ( AttributeCond . Type . EQ ) ; belliniCond . setSchema ( ""surname"" ) ; belliniCond . setExpression ( ""Bellini"" ) ; SearchCond searchCond = SearchCond . getAndCond ( orCond , SearchCond . getLeafCond ( belliniCond ) ) ; List < User > users = searchDAO . search ( searchCond , AnyTypeKind . USER ) ; assertNotNull ( users ) ; assertEquals ( 1 , users . size ( ) ) ; } @ Test public void issueSYNCOPE980 ( ) { AnyType service = entityFactory . newEntity ( AnyType . class ) ; service . setKey ( ""SERVICE"" ) ; service . setKind ( AnyTypeKind . ANY_OBJECT ) ; service = anyTypeDAO . save ( service ) ; Group citizen = groupDAO . findByName ( ""citizen"" ) ; assertNotNull ( citizen ) ; AnyObject anyObject = entityFactory . newEntity ( AnyObject . class ) ; anyObject . setName ( ""one"" ) ; anyObject . setType ( service ) ; anyObject . setRealm ( realmDAO . findByFullPath ( SyncopeConstants . ROOT_REALM ) ) ; AMembership membership = entityFactory . newEntity ( AMembership . class ) ; membership . setRightEnd ( citizen ) ; membership . setLeftEnd ( anyObject ) ; anyObject . add ( membership ) ; anyObjectDAO . save ( anyObject ) ; anyObject = anyObjectDAO . find ( ""fc6dbc3a-6c07-4965-8781-921e7401a4a5"" ) ; membership = entityFactory . newEntity ( AMembership . class ) ; membership . setRightEnd ( citizen ) ; membership . setLeftEnd ( anyObject ) ; anyObject . add ( membership ) ; anyObjectDAO . save ( anyObject ) ; anyObjectDAO . flush ( ) ; MembershipCond groupCond = new MembershipCond ( ) ; groupCond . setGroup ( ""citizen"" ) ; SearchCond searchCondition = SearchCond . getLeafCond ( groupCond ) ; List < AnyObject > matching = searchDAO . search ( searchCondition , AnyTypeKind . ANY_OBJECT ) ; assertEquals ( 2 , matching . size ( ) ) ; AnyTypeCond anyTypeCond = new AnyTypeCond ( ) ; anyTypeCond . setAnyTypeKey ( service . getKey ( ) ) ; searchCondition = SearchCond . getAndCond ( SearchCond . getLeafCond ( groupCond ) , SearchCond . getLeafCond ( anyTypeCond ) ) ; matching = searchDAO . search ( searchCondition , AnyTypeKind . ANY_OBJECT ) ; assertEquals ( 1 , matching . size ( ) ) ; } @ Test public void issueSYNCOPE983 ( ) { AttributeCond fullnameLeafCond = new AttributeCond ( AttributeCond . Type . LIKE ) ; fullnameLeafCond . setSchema ( ""surname"" ) ; fullnameLeafCond . setExpression ( ""%o%"" ) ; List < OrderByClause > orderByClauses = new ArrayList < > ( ) ; OrderByClause orderByClause = new OrderByClause ( ) ; orderByClause . setField ( ""surname"" ) ; orderByClause . setDirection ( OrderByClause . Direction . ASC ) ; orderByClauses . add ( orderByClause ) ; orderByClause = new OrderByClause ( ) ; orderByClause . setField ( ""username"" ) ; orderByClause . setDirection ( OrderByClause . Direction . DESC ) ; orderByClauses . add ( orderByClause ) ; List < User > users = searchDAO . search ( SyncopeConstants . FULL_ADMIN_REALMS , SearchCond . getLeafCond ( fullnameLeafCond ) , - 1 , - 1 , orderByClauses , AnyTypeKind . USER ) ; assertFalse ( users . isEmpty ( ) ) ; } }",Smelly
" public static class LoadCallable implements Callable < Boolean > { private final Future < ? > future ; public LoadCallable ( Future < ? > f ) { future = f ; } @ Override public Boolean call ( ) throws Exception { int colsPerKey = 10 ; int numServers = util . getHBaseClusterInterface ( ) . getInitialClusterMetrics ( ) . getLiveServerMetrics ( ) . size ( ) ; int numKeys = numServers * 5000 ; int writeThreads = 10 ; do { int ret = loadTool . run ( new String [ ] { ""-tn"" , loadTableName . getNameAsString ( ) , ""-write"" , String . format ( ""%d:%d:%d"" , colsPerKey , 500 , writeThreads ) , ""-num_keys"" , String . valueOf ( numKeys ) , ""-skip_init"" } ) ; assertEquals ( ""Load failed"" , 0 , ret ) ; } while ( ! future . isDone ( ) ) ; return true ; } } ",No
 ; public class GuiceServletConfig extends GuiceServletContextListener { @ Override protected Injector getInjector ( ) { return injector ; } ,No
"public class EscherGraphics extends Graphics { private HSSFShapeGroup escherGroup ; private HSSFWorkbook workbook ; private float verticalPointsPerPixel = 1.0f ; private float verticalPixelsPerPoint ; private Color foreground ; private Color background = Color . white ; private Font font ; private static POILogger logger = POILogFactory . getLogger ( EscherGraphics . class ) ; public EscherGraphics ( HSSFShapeGroup escherGroup , HSSFWorkbook workbook , Color forecolor , float verticalPointsPerPixel ) { this . escherGroup = escherGroup ; this . workbook = workbook ; this . verticalPointsPerPixel = verticalPointsPerPixel ; this . verticalPixelsPerPoint = 1 / verticalPointsPerPixel ; this . font = new Font ( ""Arial"" , 0 , 10 ) ; this . foreground = forecolor ; } EscherGraphics ( HSSFShapeGroup escherGroup , HSSFWorkbook workbook , Color foreground , Font font , float verticalPointsPerPixel ) { this . escherGroup = escherGroup ; this . workbook = workbook ; this . foreground = foreground ; this . font = font ; this . verticalPointsPerPixel = verticalPointsPerPixel ; this . verticalPixelsPerPoint = 1 / verticalPointsPerPixel ; } public void clearRect ( int x , int y , int width , int height ) { Color color = foreground ; setColor ( background ) ; fillRect ( x , y , width , height ) ; setColor ( color ) ; } public void clipRect ( int x , int y , int width , int height ) { if ( logger . check ( POILogger . WARN ) ) logger . log ( POILogger . WARN , ""clipRect not supported"" ) ; } public void copyArea ( int x , int y , int width , int height , int dx , int dy ) { if ( logger . check ( POILogger . WARN ) ) logger . log ( POILogger . WARN , ""copyArea not supported"" ) ; } public Graphics create ( ) { EscherGraphics g = new EscherGraphics ( escherGroup , workbook , foreground , font , verticalPointsPerPixel ) ; return g ; } public void dispose ( ) { } public void drawArc ( int x , int y , int width , int height , int startAngle , int arcAngle ) { if ( logger . check ( POILogger . WARN ) ) logger . log ( POILogger . WARN , ""drawArc not supported"" ) ; } public boolean drawImage ( Image img , int dx1 , int dy1 , int dx2 , int dy2 , int sx1 , int sy1 , int sx2 , int sy2 , Color bgcolor , ImageObserver observer ) { if ( logger . check ( POILogger . WARN ) ) logger . log ( POILogger . WARN , ""drawImage not supported"" ) ; return true ; } public boolean drawImage ( Image img , int dx1 , int dy1 , int dx2 , int dy2 , int sx1 , int sy1 , int sx2 , int sy2 , ImageObserver observer ) { if ( logger . check ( POILogger . WARN ) ) logger . log ( POILogger . WARN , ""drawImage not supported"" ) ; return true ; } public boolean drawImage ( Image image , int i , int j , int k , int l , Color color , ImageObserver imageobserver ) { return drawImage ( image , i , j , i + k , j + l , 0 , 0 , image . getWidth ( imageobserver ) , image . getHeight ( imageobserver ) , color , imageobserver ) ; } public boolean drawImage ( Image image , int i , int j , int k , int l , ImageObserver imageobserver ) { return drawImage ( image , i , j , i + k , j + l , 0 , 0 , image . getWidth ( imageobserver ) , image . getHeight ( imageobserver ) , imageobserver ) ; } public boolean drawImage ( Image image , int i , int j , Color color , ImageObserver imageobserver ) { return drawImage ( image , i , j , image . getWidth ( imageobserver ) , image . getHeight ( imageobserver ) , color , imageobserver ) ; } public boolean drawImage ( Image image , int i , int j , ImageObserver imageobserver ) { return drawImage ( image , i , j , image . getWidth ( imageobserver ) , image . getHeight ( imageobserver ) , imageobserver ) ; } public void drawLine ( int x1 , int y1 , int x2 , int y2 ) { drawLine ( x1 , y1 , x2 , y2 , 0 ) ; } public void drawLine ( int x1 , int y1 , int x2 , int y2 , int width ) { HSSFSimpleShape shape = escherGroup . createShape ( new HSSFChildAnchor ( x1 , y1 , x2 , y2 ) ) ; shape . setShapeType ( HSSFSimpleShape . OBJECT_TYPE_LINE ) ; shape . setLineWidth ( width ) ; shape . setLineStyleColor ( foreground . getRed ( ) , foreground . getGreen ( ) , foreground . getBlue ( ) ) ; } public void drawOval ( int x , int y , int width , int height ) { HSSFSimpleShape shape = escherGroup . createShape ( new HSSFChildAnchor ( x , y , x + width , y + height ) ) ; shape . setShapeType ( HSSFSimpleShape . OBJECT_TYPE_OVAL ) ; shape . setLineWidth ( 0 ) ; shape . setLineStyleColor ( foreground . getRed ( ) , foreground . getGreen ( ) , foreground . getBlue ( ) ) ; shape . setNoFill ( true ) ; } public void drawPolygon ( int xPoints [ ] , int yPoints [ ] , int nPoints ) { int right = findBiggest ( xPoints ) ; int bottom = findBiggest ( yPoints ) ; int left = findSmallest ( xPoints ) ; int top = findSmallest ( yPoints ) ; HSSFPolygon shape = escherGroup . createPolygon ( new HSSFChildAnchor ( left , top , right , bottom ) ) ; shape . setPolygonDrawArea ( right - left , bottom - top ) ; shape . setPoints ( addToAll ( xPoints , - left ) , addToAll ( yPoints , - top ) ) ; shape . setLineStyleColor ( foreground . getRed ( ) , foreground . getGreen ( ) , foreground . getBlue ( ) ) ; shape . setLineWidth ( 0 ) ; shape . setNoFill ( true ) ; } private int [ ] addToAll ( int [ ] values , int amount ) { int [ ] result = new int [ values . length ] ; for ( int i = 0 ; i < values . length ; i ++ ) result [ i ] = values [ i ] + amount ; return result ; } public void drawPolyline ( int xPoints [ ] , int yPoints [ ] , int nPoints ) { if ( logger . check ( POILogger . WARN ) ) logger . log ( POILogger . WARN , ""drawPolyline not supported"" ) ; } public void drawRect ( int x , int y , int width , int height ) { if ( logger . check ( POILogger . WARN ) ) logger . log ( POILogger . WARN , ""drawRect not supported"" ) ; } public void drawRoundRect ( int x , int y , int width , int height , int arcWidth , int arcHeight ) { if ( logger . check ( POILogger . WARN ) ) logger . log ( POILogger . WARN , ""drawRoundRect not supported"" ) ; } public void drawString ( String str , int x , int y ) { if ( str == null || str . equals ( """" ) ) return ; Font excelFont = font ; if ( font . getName ( ) . equals ( ""SansSerif"" ) ) { excelFont = new Font ( ""Arial"" , font . getStyle ( ) , ( int ) ( font . getSize ( ) / verticalPixelsPerPoint ) ) ; } else { excelFont = new Font ( font . getName ( ) , font . getStyle ( ) , ( int ) ( font . getSize ( ) / verticalPixelsPerPoint ) ) ; } FontDetails d = StaticFontMetrics . getFontDetails ( excelFont ) ; int width = ( int ) ( ( d . getStringWidth ( str ) * 8 ) + 12 ) ; int height = ( int ) ( ( font . getSize ( ) / verticalPixelsPerPoint ) + 6 ) * 2 ; y -= ( font . getSize ( ) / verticalPixelsPerPoint ) + 2 * verticalPixelsPerPoint ; HSSFTextbox textbox = escherGroup . createTextbox ( new HSSFChildAnchor ( x , y , x + width , y + height ) ) ; textbox . setNoFill ( true ) ; textbox . setLineStyle ( HSSFShape . LINESTYLE_NONE ) ; HSSFRichTextString s = new HSSFRichTextString ( str ) ; HSSFFont hssfFont = matchFont ( excelFont ) ; s . applyFont ( hssfFont ) ; textbox . setString ( s ) ; } private HSSFFont matchFont ( Font font ) { HSSFColor hssfColor = workbook . getCustomPalette ( ) . findColor ( ( byte ) foreground . getRed ( ) , ( byte ) foreground . getGreen ( ) , ( byte ) foreground . getBlue ( ) ) ; if ( hssfColor == null ) hssfColor = workbook . getCustomPalette ( ) . findSimilarColor ( ( byte ) foreground . getRed ( ) , ( byte ) foreground . getGreen ( ) , ( byte ) foreground . getBlue ( ) ) ; boolean bold = ( font . getStyle ( ) & Font . BOLD ) != 0 ; boolean italic = ( font . getStyle ( ) & Font . ITALIC ) != 0 ; HSSFFont hssfFont = workbook . findFont ( bold ? HSSFFont . BOLDWEIGHT_BOLD : 0 , hssfColor . getIndex ( ) , ( short ) ( font . getSize ( ) * 20 ) , font . getName ( ) , italic , false , ( short ) 0 , ( byte ) 0 ) ; if ( hssfFont == null ) { hssfFont = workbook . createFont ( ) ; hssfFont . setBoldweight ( bold ? HSSFFont . BOLDWEIGHT_BOLD : 0 ) ; hssfFont . setColor ( hssfColor . getIndex ( ) ) ; hssfFont . setFontHeight ( ( short ) ( font . getSize ( ) * 20 ) ) ; hssfFont . setFontName ( font . getName ( ) ) ; hssfFont . setItalic ( italic ) ; hssfFont . setStrikeout ( false ) ; hssfFont . setTypeOffset ( ( short ) 0 ) ; hssfFont . setUnderline ( ( byte ) 0 ) ; } return hssfFont ; } public void drawString ( AttributedCharacterIterator iterator , int x , int y ) { if ( logger . check ( POILogger . WARN ) ) logger . log ( POILogger . WARN , ""drawString not supported"" ) ; } public void fillArc ( int x , int y , int width , int height , int startAngle , int arcAngle ) { if ( logger . check ( POILogger . WARN ) ) logger . log ( POILogger . WARN , ""fillArc not supported"" ) ; } public void fillOval ( int x , int y , int width , int height ) { HSSFSimpleShape shape = escherGroup . createShape ( new HSSFChildAnchor ( x , y , x + width , y + height ) ) ; shape . setShapeType ( HSSFSimpleShape . OBJECT_TYPE_OVAL ) ; shape . setLineStyle ( HSSFShape . LINESTYLE_NONE ) ; shape . setFillColor ( foreground . getRed ( ) , foreground . getGreen ( ) , foreground . getBlue ( ) ) ; shape . setLineStyleColor ( foreground . getRed ( ) , foreground . getGreen ( ) , foreground . getBlue ( ) ) ; } public void fillPolygon ( int xPoints [ ] , int yPoints [ ] , int nPoints ) { int right = findBiggest ( xPoints ) ; int bottom = findBiggest ( yPoints ) ; int left = findSmallest ( xPoints ) ; int top = findSmallest ( yPoints ) ; HSSFPolygon shape = escherGroup . createPolygon ( new HSSFChildAnchor ( left , top , right , bottom ) ) ; shape . setPolygonDrawArea ( right - left , bottom - top ) ; shape . setPoints ( addToAll ( xPoints , - left ) , addToAll ( yPoints , - top ) ) ; shape . setLineStyleColor ( foreground . getRed ( ) , foreground . getGreen ( ) , foreground . getBlue ( ) ) ; shape . setFillColor ( foreground . getRed ( ) , foreground . getGreen ( ) , foreground . getBlue ( ) ) ; } private int findBiggest ( int [ ] values ) { int result = Integer . MIN_VALUE ; for ( int i = 0 ; i < values . length ; i ++ ) { if ( values [ i ] > result ) result = values [ i ] ; } return result ; } private int findSmallest ( int [ ] values ) { int result = Integer . MAX_VALUE ; for ( int i = 0 ; i < values . length ; i ++ ) { if ( values [ i ] < result ) result = values [ i ] ; } return result ; } public void fillRect ( int x , int y , int width , int height ) { HSSFSimpleShape shape = escherGroup . createShape ( new HSSFChildAnchor ( x , y , x + width , y + height ) ) ; shape . setShapeType ( HSSFSimpleShape . OBJECT_TYPE_RECTANGLE ) ; shape . setLineStyle ( HSSFShape . LINESTYLE_NONE ) ; shape . setFillColor ( foreground . getRed ( ) , foreground . getGreen ( ) , foreground . getBlue ( ) ) ; shape . setLineStyleColor ( foreground . getRed ( ) , foreground . getGreen ( ) , foreground . getBlue ( ) ) ; } public void fillRoundRect ( int x , int y , int width , int height , int arcWidth , int arcHeight ) { if ( logger . check ( POILogger . WARN ) ) logger . log ( POILogger . WARN , ""fillRoundRect not supported"" ) ; } public Shape getClip ( ) { return getClipBounds ( ) ; } public Rectangle getClipBounds ( ) { return null ; } public Rectangle getClipRect ( ) { return getClipBounds ( ) ; } public Color getColor ( ) { return foreground ; } public Font getFont ( ) { return font ; } public FontMetrics getFontMetrics ( Font f ) { return Toolkit . getDefaultToolkit ( ) . getFontMetrics ( f ) ; } public void setClip ( int x , int y , int width , int height ) { setClip ( ( ( Shape ) ( new Rectangle ( x , y , width , height ) ) ) ) ; } public void setClip ( Shape shape ) { } public void setColor ( Color color ) { foreground = color ; } public void setFont ( Font f ) { font = f ; } public void setPaintMode ( ) { if ( logger . check ( POILogger . WARN ) ) logger . log ( POILogger . WARN , ""setPaintMode not supported"" ) ; } public void setXORMode ( Color color ) { if ( logger . check ( POILogger . WARN ) ) logger . log ( POILogger . WARN , ""setXORMode not supported"" ) ; } public void translate ( int x , int y ) { if ( logger . check ( POILogger . WARN ) ) logger . log ( POILogger . WARN , ""translate not supported"" ) ; } public Color getBackground ( ) { return background ; } public void setBackground ( Color background ) { this . background = background ; } HSSFShapeGroup getEscherGraphics ( ) { return escherGroup ; } }",Smelly
"public class AppConstants extends RangerCommonEnums { public static final int ASSET_UNKNOWN = 0 ; public static final int ASSET_HDFS = 1 ; public static final int ASSET_HBASE = 2 ; public static final int ASSET_HIVE = 3 ; public static final int XAAGENT = 4 ; public static final int ASSET_KNOX = 5 ; public static final int ASSET_STORM = 6 ; public static final int AssetType_MAX = 6 ; public static final int POLICY_INCLUSION = 0 ; public static final int POLICY_EXCLUSION = 1 ; public static final int XA_AUDIT_TYPE_UNKNOWN = 0 ; public static final int XA_AUDIT_TYPE_ALL = 1 ; public static final int XA_AUDIT_TYPE_READ = 2 ; public static final int XA_AUDIT_TYPE_WRITE = 3 ; public static final int XA_AUDIT_TYPE_CREATE = 4 ; public static final int XA_AUDIT_TYPE_DELETE = 5 ; public static final int XA_AUDIT_TYPE_LOGIN = 6 ; public static final int XAAuditType_MAX = 6 ; public static final int RESOURCE_UNKNOWN = 0 ; public static final int RESOURCE_PATH = 1 ; public static final int RESOURCE_DB = 2 ; public static final int RESOURCE_TABLE = 3 ; public static final int RESOURCE_COL_FAM = 4 ; public static final int RESOURCE_COLUMN = 5 ; public static final int RESOURCE_VIEW = 6 ; public static final int RESOURCE_UDF = 7 ; public static final int RESOURCE_VIEW_COL = 8 ; public static final int RESOURCE_TOPOLOGY = 9 ; public static final int RESOURCE_SERVICE_NAME = 10 ; public static final int ResourceType_MAX = 10 ; public static final int XA_GROUP_UNKNOWN = 0 ; public static final int XA_GROUP_USER = 1 ; public static final int XA_GROUP_GROUP = 2 ; public static final int XA_GROUP_ROLE = 3 ; public static final int XAGroupType_MAX = 3 ; public static final int XA_PERM_FOR_UNKNOWN = 0 ; public static final int XA_PERM_FOR_USER = 1 ; public static final int XA_PERM_FOR_GROUP = 2 ; public static final int XAPermForType_MAX = 2 ; public static final int XA_PERM_TYPE_UNKNOWN = 0 ; public static final int XA_PERM_TYPE_RESET = 1 ; public static final int XA_PERM_TYPE_READ = 2 ; public static final int XA_PERM_TYPE_WRITE = 3 ; public static final int XA_PERM_TYPE_CREATE = 4 ; public static final int XA_PERM_TYPE_DELETE = 5 ; public static final int XA_PERM_TYPE_ADMIN = 6 ; public static final int XA_PERM_TYPE_OBFUSCATE = 7 ; public static final int XA_PERM_TYPE_MASK = 8 ; public static final int XA_PERM_TYPE_EXECUTE = 9 ; public static final int XA_PERM_TYPE_SELECT = 10 ; public static final int XA_PERM_TYPE_UPDATE = 11 ; public static final int XA_PERM_TYPE_DROP = 12 ; public static final int XA_PERM_TYPE_ALTER = 13 ; public static final int XA_PERM_TYPE_INDEX = 14 ; public static final int XA_PERM_TYPE_LOCK = 15 ; public static final int XA_PERM_TYPE_ALL = 16 ; public static final int XA_PERM_TYPE_ALLOW = 17 ; public static final int XA_PERM_TYPE_SUBMIT_TOPOLOGY = 18 ; public static final int XA_PERM_TYPE_FILE_UPLOAD = 19 ; public static final int XA_PERM_TYPE_GET_NIMBUS = 20 ; public static final int XA_PERM_TYPE_GET_CLUSTER_INFO = 21 ; public static final int XA_PERM_TYPE_FILE_DOWNLOAD = 22 ; public static final int XA_PERM_TYPE_KILL_TOPOLOGY = 23 ; public static final int XA_PERM_TYPE_REBALANCE = 24 ; public static final int XA_PERM_TYPE_ACTIVATE = 25 ; public static final int XA_PERM_TYPE_DEACTIVATE = 26 ; public static final int XA_PERM_TYPE_GET_TOPOLOGY_CONF = 27 ; public static final int XA_PERM_TYPE_GET_TOPOLOGY = 28 ; public static final int XA_PERM_TYPE_GET_USER_TOPOLOGY = 29 ; public static final int XA_PERM_TYPE_GET_TOPOLOGY_INFO = 30 ; public static final int XA_PERM_TYPE_UPLOAD_NEW_CREDENTIAL = 31 ; public static final int XAPermType_MAX = 31 ; public static final int DB_FLAVOR_UNKNOWN = 0 ; public static final int DB_FLAVOR_MYSQL = 1 ; public static final int DB_FLAVOR_ORACLE = 2 ; public static final int DB_FLAVOR_POSTGRES = 3 ; public static final int DB_FLAVOR_SQLSERVER = 4 ; public static final int DB_FLAVOR_SQLANYWHERE = 5 ; public static final int CLASS_TYPE_XA_ASSET = 1000 ; public static final int CLASS_TYPE_XA_RESOURCE = 1001 ; public static final int CLASS_TYPE_XA_GROUP = 1002 ; public static final int CLASS_TYPE_XA_USER = 1003 ; public static final int CLASS_TYPE_XA_GROUP_USER = 1004 ; public static final int CLASS_TYPE_XA_GROUP_GROUP = 1005 ; public static final int CLASS_TYPE_XA_PERM_MAP = 1006 ; public static final int CLASS_TYPE_XA_AUDIT_MAP = 1007 ; public static final int CLASS_TYPE_XA_CRED_STORE = 1008 ; public static final int CLASS_TYPE_XA_COMN_REF = 1009 ; public static final int CLASS_TYPE_XA_LICENSE = 1010 ; public static final int CLASS_TYPE_XA_POLICY_EXPORT_AUDIT = 1011 ; public static final int CLASS_TYPE_TRX_LOG = 1012 ; public static final int CLASS_TYPE_XA_ACCESS_AUDIT = 1013 ; public static final int CLASS_TYPE_XA_TRANSACTION_LOG_ATTRIBUTE = 1014 ; public static final int CLASS_TYPE_XA_ACCESS_TYPE_DEF = 1015 ; public static final int CLASS_TYPE_XA_ACCESS_TYPE_DEF_GRANTS = 1016 ; public static final int CLASS_TYPE_XA_DATA_HIST = 1017 ; public static final int CLASS_TYPE_XA_ENUM_DEF = 1018 ; public static final int CLASS_TYPE_XA_ENUM_ELEMENT_DEF = 1019 ; public static final int CLASS_TYPE_RANGER_POLICY = 1020 ; public static final int CLASS_TYPE_RANGER_POLICY_CONDITION_DEF = 1021 ; public static final int CLASS_TYPE_RANGER_POLICY_ITEM = 1022 ; public static final int CLASS_TYPE_RANGER_POLICY_ITEM_ACCESS = 1023 ; public static final int CLASS_TYPE_RANGER_POLICY_ITEM_CONDITION = 1024 ; public static final int CLASS_TYPE_RANGER_POLICY_ITEM_GRP_PERM = 1025 ; public static final int CLASS_TYPE_RANGER_POLICY_ITEM_USER_PERM = 1026 ; public static final int CLASS_TYPE_RANGER_POLICY_RESOURCE = 1027 ; public static final int CLASS_TYPE_RANGER_POLICY_RESOURCE_MAP = 1028 ; public static final int CLASS_TYPE_XA_RESOURCE_DEF = 1029 ; public static final int CLASS_TYPE_XA_SERVICE = 1030 ; public static final int CLASS_TYPE_XA_SERVICE_CONFIG_DEF = 1031 ; public static final int CLASS_TYPE_XA_SERVICE_CONFIG_MAP = 1032 ; public static final int CLASS_TYPE_XA_SERVICE_DEF = 1033 ; public static final int CLASS_TYPE_RANGER_MODULE_DEF = 1034 ; public static final int CLASS_TYPE_RANGER_USER_PERMISSION = 1035 ; public static final int CLASS_TYPE_RANGER_GROUP_PERMISSION = 1036 ; public static final int CLASS_TYPE_XA_KMS_KEY = 1037 ; public static final int CLASS_TYPE_RANGER_POLICY_WITH_ASSIGNED_ID = 1038 ; public static final int CLASS_TYPE_RANGER_SERVICE_WITH_ASSIGNED_ID = 1039 ; public static final int CLASS_TYPE_RANGER_SERVICE_DEF_WITH_ASSIGNED_ID = 1040 ; public static final int CLASS_TYPE_XA_TAG_DEF = 1041 ; public static final int CLASS_TYPE_XA_TAG_ATTR_DEF = 1042 ; public static final int CLASS_TYPE_XA_SERVICE_RESOURCE = 1043 ; public static final int CLASS_TYPE_XA_SERVICE_RESOURCE_ELEMENT = 1044 ; public static final int CLASS_TYPE_XA_SERVICE_RESOURCE_ELEMENT_VALUE = 1045 ; public static final int CLASS_TYPE_XA_TAG = 1046 ; public static final int CLASS_TYPE_XA_TAG_ATTR = 1047 ; public static final int CLASS_TYPE_XA_TAG_RESOURCE_MAP = 1048 ; public static final int CLASS_TYPE_XA_DATAMASK_DEF = 1049 ; public static final int CLASS_TYPE_RANGER_POLICY_ITEM_DATAMASK_INFO = 1050 ; public static final int CLASS_TYPE_RANGER_POLICY_ITEM_ROWFILTER_INFO = 1051 ; public static final int CLASS_TYPE_XA_SERVICE_VERSION_INFO = 1052 ; public static final int CLASS_TYPE_XA_ACCESS_AUDIT_V4 = 1053 ; public static final int CLASS_TYPE_XA_ACCESS_AUDIT_V5 = 1054 ; public static final int ClassTypes_MAX = 1054 ; public static final int DEFAULT_SORT_ORDER = 0 ; public static final int HIST_OBJ_STATUS_UNKNOWN = 0 ; public static final int HIST_OBJ_STATUS_CREATED = 1 ; public static final int HIST_OBJ_STATUS_UPDATED = 2 ; public static final int HIST_OBJ_STATUS_DELETED = 3 ; public static final int MAX_HIST_OBJ_STATUS = 3 ; public static final String Masked_String = ""*****"" ; static public String getLabelFor_AssetType ( int elementValue ) { if ( elementValue == 0 ) { return ""Unknown"" ; } if ( elementValue == 1 ) { return ""HDFS"" ; } if ( elementValue == 2 ) { return ""HBase"" ; } if ( elementValue == 3 ) { return ""Hive"" ; } if ( elementValue == 4 ) { return ""XAAGENT"" ; } if ( elementValue == 5 ) { return ""Knox"" ; } if ( elementValue == 6 ) { return ""Storm"" ; } return null ; } static public String getLabelFor_PolicyType ( int elementValue ) { if ( elementValue == 0 ) { return ""Inclusion"" ; } if ( elementValue == 1 ) { return ""Exclusion"" ; } return null ; } static public String getLabelFor_XAAuditType ( int elementValue ) { if ( elementValue == 0 ) { return ""Unknown"" ; } if ( elementValue == 1 ) { return ""All"" ; } if ( elementValue == 2 ) { return ""Read"" ; } if ( elementValue == 3 ) { return ""Write"" ; } if ( elementValue == 4 ) { return ""Create"" ; } if ( elementValue == 5 ) { return ""Delete"" ; } if ( elementValue == 6 ) { return ""Login"" ; } return null ; } static public String getLabelFor_ResourceType ( int elementValue ) { if ( elementValue == 0 ) { return ""Unknown"" ; } if ( elementValue == 1 ) { return ""Path"" ; } if ( elementValue == 2 ) { return ""Database"" ; } if ( elementValue == 3 ) { return ""Table"" ; } if ( elementValue == 4 ) { return ""Column Family"" ; } if ( elementValue == 5 ) { return ""Column"" ; } if ( elementValue == 6 ) { return ""VIEW"" ; } if ( elementValue == 7 ) { return ""UDF"" ; } if ( elementValue == 8 ) { return ""View Column"" ; } if ( elementValue == 9 ) { return ""Topology"" ; } if ( elementValue == 10 ) { return ""Service"" ; } return null ; } static public String getLabelFor_XAGroupType ( int elementValue ) { if ( elementValue == 0 ) { return ""Unknown"" ; } if ( elementValue == 1 ) { return ""User"" ; } if ( elementValue == 2 ) { return ""Group"" ; } if ( elementValue == 3 ) { return ""Role"" ; } return null ; } static public String getLabelFor_XAPermForType ( int elementValue ) { if ( elementValue == 0 ) { return ""Unknown"" ; } if ( elementValue == 1 ) { return ""Permission for Users"" ; } if ( elementValue == 2 ) { return ""Permission for Groups"" ; } return null ; } static public String getLabelFor_XAPermType ( int elementValue ) { if ( elementValue == 0 ) { return ""Unknown"" ; } if ( elementValue == 1 ) { return ""reset"" ; } if ( elementValue == 2 ) { return ""read"" ; } if ( elementValue == 3 ) { return ""write"" ; } if ( elementValue == 4 ) { return ""create"" ; } if ( elementValue == 5 ) { return ""delete"" ; } if ( elementValue == 6 ) { return ""admin"" ; } if ( elementValue == 7 ) { return ""obfuscate"" ; } if ( elementValue == 8 ) { return ""mask"" ; } if ( elementValue == 9 ) { return ""execute"" ; } if ( elementValue == 10 ) { return ""select"" ; } if ( elementValue == 11 ) { return ""update"" ; } if ( elementValue == 12 ) { return ""drop"" ; } if ( elementValue == 13 ) { return ""alter"" ; } if ( elementValue == 14 ) { return ""index"" ; } if ( elementValue == 15 ) { return ""lock"" ; } if ( elementValue == 16 ) { return ""all"" ; } if ( elementValue == 17 ) { return ""allow"" ; } if ( elementValue == 18 ) { return ""submitTopology"" ; } if ( elementValue == 19 ) { return ""fileUpload"" ; } if ( elementValue == 20 ) { return ""getNimbusConf"" ; } if ( elementValue == 21 ) { return ""getClusterInfo"" ; } if ( elementValue == 22 ) { return ""fileDownload"" ; } if ( elementValue == 23 ) { return ""killTopology"" ; } if ( elementValue == 24 ) { return ""rebalance"" ; } if ( elementValue == 25 ) { return ""activate"" ; } if ( elementValue == 26 ) { return ""deactivate"" ; } if ( elementValue == 27 ) { return ""getTopologyConf"" ; } if ( elementValue == 28 ) { return ""getTopology"" ; } if ( elementValue == 29 ) { return ""getUserTopology"" ; } if ( elementValue == 30 ) { return ""getTopologyInfo"" ; } if ( elementValue == 31 ) { return ""uploadNewCredentials"" ; } return null ; } static public String getLabelFor_ClassTypes ( int elementValue ) { if ( elementValue == 1000 ) { return ""Asset"" ; } if ( elementValue == 1001 ) { return ""Resource"" ; } if ( elementValue == 1002 ) { return ""XA Group"" ; } if ( elementValue == 1003 ) { return ""XA User"" ; } if ( elementValue == 1004 ) { return ""XA Group of Users"" ; } if ( elementValue == 1005 ) { return ""XA Group of groups"" ; } if ( elementValue == 1006 ) { return ""XA permissions for resource"" ; } if ( elementValue == 1007 ) { return ""XA audits for resource"" ; } if ( elementValue == 1008 ) { return ""XA credential store"" ; } if ( elementValue == 1009 ) { return ""XA Common Reference"" ; } if ( elementValue == 1010 ) { return ""XA License"" ; } if ( elementValue == 1011 ) { return ""XA Policy Export Audit"" ; } if ( elementValue == 1012 ) { return ""Transaction log"" ; } if ( elementValue == 1013 ) { return ""Access Audit"" ; } if ( elementValue == 1014 ) { return ""Trx Log Attribute"" ; } if ( elementValue == 1015 ) { return ""XA AccessType Def"" ; } if ( elementValue == 1016 ) { return ""XA AccessType Def Grants"" ; } if ( elementValue == 1017 ) { return ""XA Data History"" ; } if ( elementValue == 1018 ) { return ""XA Enum Defination"" ; } if ( elementValue == 1019 ) { return ""XA EnumElement Def"" ; } if ( elementValue == 1020 ) { return ""Ranger Policy"" ; } if ( elementValue == 1021 ) { return ""RangerPolicy Condition Def"" ; } if ( elementValue == 1022 ) { return ""RangerPolicy Item"" ; } if ( elementValue == 1023 ) { return ""RangerPolicy Item Access"" ; } if ( elementValue == 1024 ) { return ""RangerPolicyItem Condition "" ; } if ( elementValue == 1025 ) { return ""RangerPolicy ItemGrp Map"" ; } if ( elementValue == 1026 ) { return ""RangerPolicy ItemUser Map"" ; } if ( elementValue == 1027 ) { return ""RangerPolicy Resource"" ; } if ( elementValue == 1028 ) { return ""RangerPolicy Resource Map"" ; } if ( elementValue == 1029 ) { return ""XA Resource Def"" ; } if ( elementValue == 1030 ) { return ""XA Service"" ; } if ( elementValue == 1031 ) { return ""XA Service Config Def"" ; } if ( elementValue == 1032 ) { return ""XA Service Config Map"" ; } if ( elementValue == 1033 ) { return ""XA Service Def"" ; } if ( elementValue == 1052 ) { return ""XA Service Version Info"" ; } if ( elementValue == 1053 ) { return ""Access Audit V4"" ; } if ( elementValue == 1054 ) { return ""Access Audit V5"" ; } return null ; } static public int getEnumFor_AssetType ( String label ) { if ( label == null ) { return 0 ; } if ( ""Unknown"" . equalsIgnoreCase ( label ) ) { return AppConstants . ASSET_UNKNOWN ; } if ( ""HDFS"" . equalsIgnoreCase ( label ) ) { return AppConstants . ASSET_HDFS ; } if ( ""HBase"" . equalsIgnoreCase ( label ) ) { return AppConstants . ASSET_HBASE ; } if ( ""Hive"" . equalsIgnoreCase ( label ) ) { return AppConstants . ASSET_HIVE ; } if ( ""Knox"" . equalsIgnoreCase ( label ) ) { return AppConstants . ASSET_KNOX ; } if ( ""Storm"" . equalsIgnoreCase ( label ) ) { return AppConstants . ASSET_STORM ; } return 0 ; } static public int getEnumFor_BooleanValue ( boolean label ) { if ( label ) { return AppConstants . BOOL_TRUE ; } else { return AppConstants . BOOL_FALSE ; } } static public boolean getBooleanFor_BooleanValue ( int elementValue ) { if ( elementValue == 1 ) { return true ; } if ( elementValue == 2 ) { return false ; } return false ; } static public int getEnumFor_ResourceType ( String label ) { if ( label == null ) { return 0 ; } if ( ""Unknown"" . equalsIgnoreCase ( label ) ) { return AppConstants . RESOURCE_UNKNOWN ; } if ( ""Path"" . equalsIgnoreCase ( label ) ) { return AppConstants . RESOURCE_PATH ; } if ( ""Database"" . equalsIgnoreCase ( label ) ) { return AppConstants . RESOURCE_DB ; } if ( ""Table"" . equalsIgnoreCase ( label ) ) { return AppConstants . RESOURCE_TABLE ; } if ( ""Column Family"" . equalsIgnoreCase ( label ) ) { return AppConstants . RESOURCE_COL_FAM ; } if ( ""Column"" . equalsIgnoreCase ( label ) ) { return AppConstants . RESOURCE_COLUMN ; } if ( ""VIEW"" . equalsIgnoreCase ( label ) ) { return AppConstants . RESOURCE_VIEW ; } if ( ""UDF"" . equalsIgnoreCase ( label ) ) { return AppConstants . RESOURCE_UDF ; } if ( ""View Column"" . equalsIgnoreCase ( label ) ) { return AppConstants . RESOURCE_VIEW_COL ; } if ( ""Topology"" . equalsIgnoreCase ( label ) ) { return AppConstants . RESOURCE_TOPOLOGY ; } if ( ""Service"" . equalsIgnoreCase ( label ) ) { return AppConstants . RESOURCE_SERVICE_NAME ; } return 0 ; } static public int getEnumFor_XAPermType ( String label ) { if ( label == null ) { return 0 ; } if ( ""Unknown"" . equalsIgnoreCase ( label ) ) { return AppConstants . XA_PERM_TYPE_UNKNOWN ; } if ( ""Reset"" . equalsIgnoreCase ( label ) ) { return AppConstants . XA_PERM_TYPE_RESET ; } if ( ""Read"" . equalsIgnoreCase ( label ) ) { return AppConstants . XA_PERM_TYPE_READ ; } if ( ""Write"" . equalsIgnoreCase ( label ) ) { return AppConstants . XA_PERM_TYPE_WRITE ; } if ( ""Create"" . equalsIgnoreCase ( label ) ) { return AppConstants . XA_PERM_TYPE_CREATE ; } if ( ""Delete"" . equalsIgnoreCase ( label ) ) { return AppConstants . XA_PERM_TYPE_DELETE ; } if ( ""Admin"" . equalsIgnoreCase ( label ) ) { return AppConstants . XA_PERM_TYPE_ADMIN ; } if ( ""Obfuscate"" . equalsIgnoreCase ( label ) ) { return AppConstants . XA_PERM_TYPE_OBFUSCATE ; } if ( ""Mask"" . equalsIgnoreCase ( label ) ) { return AppConstants . XA_PERM_TYPE_MASK ; } if ( ""Execute"" . equalsIgnoreCase ( label ) ) { return AppConstants . XA_PERM_TYPE_EXECUTE ; } if ( ""Select"" . equalsIgnoreCase ( label ) ) { return AppConstants . XA_PERM_TYPE_SELECT ; } if ( ""Update"" . equalsIgnoreCase ( label ) ) { return AppConstants . XA_PERM_TYPE_UPDATE ; } if ( ""Drop"" . equalsIgnoreCase ( label ) ) { return AppConstants . XA_PERM_TYPE_DROP ; } if ( ""Alter"" . equalsIgnoreCase ( label ) ) { return AppConstants . XA_PERM_TYPE_ALTER ; } if ( ""Index"" . equalsIgnoreCase ( label ) ) { return AppConstants . XA_PERM_TYPE_INDEX ; } if ( ""Lock"" . equalsIgnoreCase ( label ) ) { return AppConstants . XA_PERM_TYPE_LOCK ; } if ( ""All"" . equalsIgnoreCase ( label ) ) { return AppConstants . XA_PERM_TYPE_ALL ; } if ( ""Allow"" . equalsIgnoreCase ( label ) ) { return AppConstants . XA_PERM_TYPE_ALLOW ; } if ( ""submitTopology"" . equalsIgnoreCase ( label ) ) { return AppConstants . XA_PERM_TYPE_SUBMIT_TOPOLOGY ; } if ( ""fileUpload"" . equalsIgnoreCase ( label ) ) { return AppConstants . XA_PERM_TYPE_FILE_UPLOAD ; } if ( ""getNimbusConf"" . equalsIgnoreCase ( label ) ) { return AppConstants . XA_PERM_TYPE_GET_NIMBUS ; } if ( ""getClusterInfo"" . equalsIgnoreCase ( label ) ) { return AppConstants . XA_PERM_TYPE_GET_CLUSTER_INFO ; } if ( ""fileDownload"" . equalsIgnoreCase ( label ) ) { return AppConstants . XA_PERM_TYPE_FILE_DOWNLOAD ; } if ( ""killTopology"" . equalsIgnoreCase ( label ) ) { return AppConstants . XA_PERM_TYPE_KILL_TOPOLOGY ; } if ( ""rebalance"" . equalsIgnoreCase ( label ) ) { return AppConstants . XA_PERM_TYPE_REBALANCE ; } if ( ""activate"" . equalsIgnoreCase ( label ) ) { return AppConstants . XA_PERM_TYPE_ACTIVATE ; } if ( ""deactivate"" . equalsIgnoreCase ( label ) ) { return AppConstants . XA_PERM_TYPE_DEACTIVATE ; } if ( ""getTopologyConf"" . equalsIgnoreCase ( label ) ) { return AppConstants . XA_PERM_TYPE_GET_TOPOLOGY_CONF ; } if ( ""getTopology"" . equalsIgnoreCase ( label ) ) { return AppConstants . XA_PERM_TYPE_GET_TOPOLOGY ; } if ( ""getUserTopology"" . equalsIgnoreCase ( label ) ) { return AppConstants . XA_PERM_TYPE_GET_USER_TOPOLOGY ; } if ( ""getTopologyInfo"" . equalsIgnoreCase ( label ) ) { return AppConstants . XA_PERM_TYPE_GET_TOPOLOGY_INFO ; } if ( ""uploadNewCredentials"" . equalsIgnoreCase ( label ) ) { return AppConstants . XA_PERM_TYPE_UPLOAD_NEW_CREDENTIAL ; } return 0 ; } static public int getEnumFor_PolicyType ( String label ) { if ( label == null ) { return 0 ; } if ( ""Inclusion"" . equalsIgnoreCase ( label ) ) { return AppConstants . POLICY_INCLUSION ; } if ( ""Exclusion"" . equalsIgnoreCase ( label ) ) { return AppConstants . POLICY_EXCLUSION ; } return 0 ; } static public int getEnumFor_DatabaseFlavor ( String label ) { if ( label == null ) { return DB_FLAVOR_UNKNOWN ; } if ( ""MYSQL"" . equalsIgnoreCase ( label ) ) { return DB_FLAVOR_MYSQL ; } if ( ""ORACLE"" . equalsIgnoreCase ( label ) ) { return DB_FLAVOR_ORACLE ; } if ( ""POSTGRES"" . equalsIgnoreCase ( label ) ) { return DB_FLAVOR_POSTGRES ; } if ( ""MSSQL"" . equalsIgnoreCase ( label ) ) { return DB_FLAVOR_SQLSERVER ; } if ( ""SQLA"" . equalsIgnoreCase ( label ) ) { return DB_FLAVOR_SQLANYWHERE ; } return DB_FLAVOR_UNKNOWN ; } static public String getLabelFor_DatabaseFlavor ( int elementValue ) { if ( elementValue == DB_FLAVOR_UNKNOWN ) { return ""UNKNOWN"" ; } if ( elementValue == DB_FLAVOR_MYSQL ) { return ""MYSQL"" ; } if ( elementValue == DB_FLAVOR_ORACLE ) { return ""ORACLE"" ; } if ( elementValue == DB_FLAVOR_POSTGRES ) { return ""POSTGRES"" ; } if ( elementValue == DB_FLAVOR_SQLSERVER ) { return ""MSSQL"" ; } if ( elementValue == DB_FLAVOR_SQLANYWHERE ) { return ""SQLA"" ; } return null ; } }",Smelly
" protected abstract class TextVertexWriterToEachLine extends TextVertexWriter { @ SuppressWarnings ( ""unchecked"" ) @ Override public final void writeVertex ( Vertex vertex ) throws IOException , InterruptedException { getRecordWriter ( ) . write ( convertVertexToLine ( vertex ) , null ) ; } protected abstract Text convertVertexToLine ( Vertex < I , V , E > vertex ) throws IOException ; } ",No
"public class SetupException extends DrillException { static final org . slf4j . Logger logger = org . slf4j . LoggerFactory . getLogger ( SetupException . class ) ; public SetupException ( ) { super ( ) ; } public SetupException ( String message , Throwable cause , boolean enableSuppression , boolean writableStackTrace ) { super ( message , cause , enableSuppression , writableStackTrace ) ; } public SetupException ( String message , Throwable cause ) { super ( message , cause ) ; } public SetupException ( String message ) { super ( message ) ; } public SetupException ( Throwable cause ) { super ( cause ) ; } }",No
"@ Path ( ""v2/entity"" ) @ Singleton @ Service public class EntityREST { private static final Logger PERF_LOG = AtlasPerfTracer . getPerfLogger ( ""rest.EntityREST"" ) ; public static final String PREFIX_ATTR = ""attr:"" ; private final AtlasTypeRegistry typeRegistry ; private final AtlasEntityStore entitiesStore ; @ Inject public EntityREST ( AtlasTypeRegistry typeRegistry , AtlasEntityStore entitiesStore ) { this . typeRegistry = typeRegistry ; this . entitiesStore = entitiesStore ; } @ GET @ Path ( ""/guid/{guid}"" ) @ Consumes ( Servlets . JSON_MEDIA_TYPE ) @ Produces ( Servlets . JSON_MEDIA_TYPE ) public AtlasEntityWithExtInfo getById ( @ PathParam ( ""guid"" ) String guid ) throws AtlasBaseException { Servlets . validateQueryParamLength ( ""guid"" , guid ) ; AtlasPerfTracer perf = null ; try { if ( AtlasPerfTracer . isPerfTraceEnabled ( PERF_LOG ) ) { perf = AtlasPerfTracer . getPerfTracer ( PERF_LOG , ""EntityREST.getById("" + guid + "")"" ) ; } return entitiesStore . getById ( guid ) ; } finally { AtlasPerfTracer . log ( perf ) ; } } @ GET @ Path ( ""/uniqueAttribute/type/{typeName}"" ) @ Consumes ( Servlets . JSON_MEDIA_TYPE ) @ Produces ( Servlets . JSON_MEDIA_TYPE ) public AtlasEntityWithExtInfo getByUniqueAttributes ( @ PathParam ( ""typeName"" ) String typeName , @ Context HttpServletRequest servletRequest ) throws AtlasBaseException { Servlets . validateQueryParamLength ( ""typeName"" , typeName ) ; AtlasPerfTracer perf = null ; try { Map < String , Object > attributes = getAttributes ( servletRequest ) ; if ( AtlasPerfTracer . isPerfTraceEnabled ( PERF_LOG ) ) { perf = AtlasPerfTracer . getPerfTracer ( PERF_LOG , ""EntityREST.getByUniqueAttributes("" + typeName + "","" + attributes + "")"" ) ; } AtlasEntityType entityType = ensureEntityType ( typeName ) ; validateUniqueAttribute ( entityType , attributes ) ; return entitiesStore . getByUniqueAttributes ( entityType , attributes ) ; } finally { AtlasPerfTracer . log ( perf ) ; } } @ PUT @ Consumes ( Servlets . JSON_MEDIA_TYPE ) @ Produces ( Servlets . JSON_MEDIA_TYPE ) @ Path ( ""/uniqueAttribute/type/{typeName}"" ) public EntityMutationResponse partialUpdateEntityByUniqueAttrs ( @ PathParam ( ""typeName"" ) String typeName , @ Context HttpServletRequest servletRequest , AtlasEntityWithExtInfo entityInfo ) throws Exception { Servlets . validateQueryParamLength ( ""typeName"" , typeName ) ; AtlasPerfTracer perf = null ; try { Map < String , Object > uniqueAttributes = getAttributes ( servletRequest ) ; if ( AtlasPerfTracer . isPerfTraceEnabled ( PERF_LOG ) ) { perf = AtlasPerfTracer . getPerfTracer ( PERF_LOG , ""EntityREST.partialUpdateEntityByUniqueAttrs("" + typeName + "","" + uniqueAttributes + "")"" ) ; } AtlasEntityType entityType = ensureEntityType ( typeName ) ; validateUniqueAttribute ( entityType , uniqueAttributes ) ; return entitiesStore . updateByUniqueAttributes ( entityType , uniqueAttributes , entityInfo ) ; } finally { AtlasPerfTracer . log ( perf ) ; } } @ DELETE @ Consumes ( Servlets . JSON_MEDIA_TYPE ) @ Produces ( Servlets . JSON_MEDIA_TYPE ) @ Path ( ""/uniqueAttribute/type/{typeName}"" ) public EntityMutationResponse deleteByUniqueAttribute ( @ PathParam ( ""typeName"" ) String typeName , @ Context HttpServletRequest servletRequest ) throws AtlasBaseException { Servlets . validateQueryParamLength ( ""typeName"" , typeName ) ; AtlasPerfTracer perf = null ; try { Map < String , Object > attributes = getAttributes ( servletRequest ) ; if ( AtlasPerfTracer . isPerfTraceEnabled ( PERF_LOG ) ) { perf = AtlasPerfTracer . getPerfTracer ( PERF_LOG , ""EntityREST.deleteByUniqueAttribute("" + typeName + "","" + attributes + "")"" ) ; } AtlasEntityType entityType = ensureEntityType ( typeName ) ; return entitiesStore . deleteByUniqueAttributes ( entityType , attributes ) ; } finally { AtlasPerfTracer . log ( perf ) ; } } @ POST @ Consumes ( Servlets . JSON_MEDIA_TYPE ) @ Produces ( Servlets . JSON_MEDIA_TYPE ) public EntityMutationResponse createOrUpdate ( AtlasEntityWithExtInfo entity ) throws AtlasBaseException { AtlasPerfTracer perf = null ; try { if ( AtlasPerfTracer . isPerfTraceEnabled ( PERF_LOG ) ) { perf = AtlasPerfTracer . getPerfTracer ( PERF_LOG , ""EntityREST.createOrUpdate()"" ) ; } return entitiesStore . createOrUpdate ( new AtlasEntityStream ( entity ) , false ) ; } finally { AtlasPerfTracer . log ( perf ) ; } } @ PUT @ Consumes ( Servlets . JSON_MEDIA_TYPE ) @ Produces ( Servlets . JSON_MEDIA_TYPE ) @ Path ( ""/guid/{guid}"" ) public EntityMutationResponse partialUpdateEntityAttrByGuid ( @ PathParam ( ""guid"" ) String guid , @ QueryParam ( ""name"" ) String attrName , Object attrValue ) throws Exception { Servlets . validateQueryParamLength ( ""guid"" , guid ) ; Servlets . validateQueryParamLength ( ""name"" , attrName ) ; AtlasPerfTracer perf = null ; try { if ( AtlasPerfTracer . isPerfTraceEnabled ( PERF_LOG ) ) { perf = AtlasPerfTracer . getPerfTracer ( PERF_LOG , ""EntityREST.partialUpdateEntityAttrByGuid("" + guid + "","" + attrName + "")"" ) ; } return entitiesStore . updateEntityAttributeByGuid ( guid , attrName , attrValue ) ; } finally { AtlasPerfTracer . log ( perf ) ; } } @ DELETE @ Path ( ""/guid/{guid}"" ) @ Consumes ( { Servlets . JSON_MEDIA_TYPE , MediaType . APPLICATION_JSON } ) @ Produces ( Servlets . JSON_MEDIA_TYPE ) public EntityMutationResponse deleteByGuid ( @ PathParam ( ""guid"" ) final String guid ) throws AtlasBaseException { Servlets . validateQueryParamLength ( ""guid"" , guid ) ; AtlasPerfTracer perf = null ; try { if ( AtlasPerfTracer . isPerfTraceEnabled ( PERF_LOG ) ) { perf = AtlasPerfTracer . getPerfTracer ( PERF_LOG , ""EntityREST.deleteByGuid("" + guid + "")"" ) ; } return entitiesStore . deleteById ( guid ) ; } finally { AtlasPerfTracer . log ( perf ) ; } } @ GET @ Path ( ""/guid/{guid}/classification/{classificationName}"" ) @ Produces ( Servlets . JSON_MEDIA_TYPE ) public AtlasClassification getClassification ( @ PathParam ( ""guid"" ) String guid , @ PathParam ( ""classificationName"" ) final String classificationName ) throws AtlasBaseException { Servlets . validateQueryParamLength ( ""guid"" , guid ) ; Servlets . validateQueryParamLength ( ""classificationName"" , classificationName ) ; AtlasPerfTracer perf = null ; try { if ( AtlasPerfTracer . isPerfTraceEnabled ( PERF_LOG ) ) { perf = AtlasPerfTracer . getPerfTracer ( PERF_LOG , ""EntityREST.getClassification("" + guid + "","" + classificationName + "")"" ) ; } if ( StringUtils . isEmpty ( guid ) ) { throw new AtlasBaseException ( AtlasErrorCode . INSTANCE_GUID_NOT_FOUND , guid ) ; } ensureClassificationType ( classificationName ) ; return entitiesStore . getClassification ( guid , classificationName ) ; } finally { AtlasPerfTracer . log ( perf ) ; } } @ GET @ Path ( ""/guid/{guid}/classifications"" ) @ Produces ( Servlets . JSON_MEDIA_TYPE ) public AtlasClassification . AtlasClassifications getClassifications ( @ PathParam ( ""guid"" ) String guid ) throws AtlasBaseException { Servlets . validateQueryParamLength ( ""guid"" , guid ) ; AtlasPerfTracer perf = null ; try { if ( AtlasPerfTracer . isPerfTraceEnabled ( PERF_LOG ) ) { perf = AtlasPerfTracer . getPerfTracer ( PERF_LOG , ""EntityREST.getClassifications("" + guid + "")"" ) ; } if ( StringUtils . isEmpty ( guid ) ) { throw new AtlasBaseException ( AtlasErrorCode . INSTANCE_GUID_NOT_FOUND , guid ) ; } return new AtlasClassification . AtlasClassifications ( entitiesStore . getClassifications ( guid ) ) ; } finally { AtlasPerfTracer . log ( perf ) ; } } @ POST @ Path ( ""/guid/{guid}/classifications"" ) @ Consumes ( { Servlets . JSON_MEDIA_TYPE , MediaType . APPLICATION_JSON } ) @ Produces ( Servlets . JSON_MEDIA_TYPE ) public void addClassifications ( @ PathParam ( ""guid"" ) final String guid , List < AtlasClassification > classifications ) throws AtlasBaseException { Servlets . validateQueryParamLength ( ""guid"" , guid ) ; AtlasPerfTracer perf = null ; try { if ( AtlasPerfTracer . isPerfTraceEnabled ( PERF_LOG ) ) { perf = AtlasPerfTracer . getPerfTracer ( PERF_LOG , ""EntityREST.addClassifications("" + guid + "")"" ) ; } if ( StringUtils . isEmpty ( guid ) ) { throw new AtlasBaseException ( AtlasErrorCode . INSTANCE_GUID_NOT_FOUND , guid ) ; } entitiesStore . addClassifications ( guid , classifications ) ; } finally { AtlasPerfTracer . log ( perf ) ; } } @ PUT @ Path ( ""/guid/{guid}/classifications"" ) @ Produces ( Servlets . JSON_MEDIA_TYPE ) public void updateClassification ( @ PathParam ( ""guid"" ) final String guid , List < AtlasClassification > classifications ) throws AtlasBaseException { Servlets . validateQueryParamLength ( ""guid"" , guid ) ; AtlasPerfTracer perf = null ; try { if ( AtlasPerfTracer . isPerfTraceEnabled ( PERF_LOG ) ) { perf = AtlasPerfTracer . getPerfTracer ( PERF_LOG , ""EntityREST.updateClassification("" + guid + "")"" ) ; } if ( StringUtils . isEmpty ( guid ) ) { throw new AtlasBaseException ( AtlasErrorCode . INSTANCE_GUID_NOT_FOUND , guid ) ; } entitiesStore . updateClassifications ( guid , classifications ) ; } finally { AtlasPerfTracer . log ( perf ) ; } } @ DELETE @ Path ( ""/guid/{guid}/classification/{classificationName}"" ) @ Produces ( Servlets . JSON_MEDIA_TYPE ) public void deleteClassification ( @ PathParam ( ""guid"" ) String guid , @ PathParam ( ""classificationName"" ) final String classificationName ) throws AtlasBaseException { Servlets . validateQueryParamLength ( ""guid"" , guid ) ; Servlets . validateQueryParamLength ( ""classificationName"" , classificationName ) ; AtlasPerfTracer perf = null ; try { if ( AtlasPerfTracer . isPerfTraceEnabled ( PERF_LOG ) ) { perf = AtlasPerfTracer . getPerfTracer ( PERF_LOG , ""EntityREST.deleteClassification("" + guid + "","" + classificationName + "")"" ) ; } if ( StringUtils . isEmpty ( guid ) ) { throw new AtlasBaseException ( AtlasErrorCode . INSTANCE_GUID_NOT_FOUND , guid ) ; } ensureClassificationType ( classificationName ) ; entitiesStore . deleteClassifications ( guid , new ArrayList < String > ( ) { { add ( classificationName ) ; } } ) ; } finally { AtlasPerfTracer . log ( perf ) ; } } @ GET @ Path ( ""/bulk"" ) @ Consumes ( Servlets . JSON_MEDIA_TYPE ) @ Produces ( Servlets . JSON_MEDIA_TYPE ) public AtlasEntitiesWithExtInfo getByGuids ( @ QueryParam ( ""guid"" ) List < String > guids ) throws AtlasBaseException { if ( CollectionUtils . isNotEmpty ( guids ) ) { for ( String guid : guids ) { Servlets . validateQueryParamLength ( ""guid"" , guid ) ; } } AtlasPerfTracer perf = null ; try { if ( AtlasPerfTracer . isPerfTraceEnabled ( PERF_LOG ) ) { perf = AtlasPerfTracer . getPerfTracer ( PERF_LOG , ""EntityREST.getByGuids("" + guids + "")"" ) ; } if ( CollectionUtils . isEmpty ( guids ) ) { throw new AtlasBaseException ( AtlasErrorCode . INSTANCE_GUID_NOT_FOUND , guids ) ; } return entitiesStore . getByIds ( guids ) ; } finally { AtlasPerfTracer . log ( perf ) ; } } @ POST @ Path ( ""/bulk"" ) @ Consumes ( Servlets . JSON_MEDIA_TYPE ) @ Produces ( Servlets . JSON_MEDIA_TYPE ) public EntityMutationResponse createOrUpdate ( AtlasEntitiesWithExtInfo entities ) throws AtlasBaseException { AtlasPerfTracer perf = null ; try { if ( AtlasPerfTracer . isPerfTraceEnabled ( PERF_LOG ) ) { perf = AtlasPerfTracer . getPerfTracer ( PERF_LOG , ""EntityREST.createOrUpdate(entityCount="" + ( CollectionUtils . isEmpty ( entities . getEntities ( ) ) ? 0 : entities . getEntities ( ) . size ( ) ) + "")"" ) ; } EntityStream entityStream = new AtlasEntityStream ( entities ) ; return entitiesStore . createOrUpdate ( entityStream , false ) ; } finally { AtlasPerfTracer . log ( perf ) ; } } @ DELETE @ Path ( ""/bulk"" ) @ Consumes ( Servlets . JSON_MEDIA_TYPE ) @ Produces ( Servlets . JSON_MEDIA_TYPE ) public EntityMutationResponse deleteByGuids ( @ QueryParam ( ""guid"" ) final List < String > guids ) throws AtlasBaseException { if ( CollectionUtils . isNotEmpty ( guids ) ) { for ( String guid : guids ) { Servlets . validateQueryParamLength ( ""guid"" , guid ) ; } } AtlasPerfTracer perf = null ; try { if ( AtlasPerfTracer . isPerfTraceEnabled ( PERF_LOG ) ) { perf = AtlasPerfTracer . getPerfTracer ( PERF_LOG , ""EntityREST.deleteByGuids("" + guids + "")"" ) ; } return entitiesStore . deleteByIds ( guids ) ; } finally { AtlasPerfTracer . log ( perf ) ; } } @ POST @ Path ( ""/bulk/classification"" ) @ Consumes ( { Servlets . JSON_MEDIA_TYPE , MediaType . APPLICATION_JSON } ) @ Produces ( Servlets . JSON_MEDIA_TYPE ) public void addClassification ( ClassificationAssociateRequest request ) throws AtlasBaseException { AtlasPerfTracer perf = null ; try { if ( AtlasPerfTracer . isPerfTraceEnabled ( PERF_LOG ) ) { perf = AtlasPerfTracer . getPerfTracer ( PERF_LOG , ""EntityREST.addClassification("" + request + "")"" ) ; } AtlasClassification classification = request == null ? null : request . getClassification ( ) ; List < String > entityGuids = request == null ? null : request . getEntityGuids ( ) ; if ( classification == null || StringUtils . isEmpty ( classification . getTypeName ( ) ) ) { throw new AtlasBaseException ( AtlasErrorCode . INVALID_PARAMETERS , ""no classification"" ) ; } if ( CollectionUtils . isEmpty ( entityGuids ) ) { throw new AtlasBaseException ( AtlasErrorCode . INVALID_PARAMETERS , ""empty guid list"" ) ; } entitiesStore . addClassification ( entityGuids , classification ) ; } finally { AtlasPerfTracer . log ( perf ) ; } } private AtlasEntityType ensureEntityType ( String typeName ) throws AtlasBaseException { AtlasEntityType ret = typeRegistry . getEntityTypeByName ( typeName ) ; if ( ret == null ) { throw new AtlasBaseException ( AtlasErrorCode . TYPE_NAME_INVALID , TypeCategory . ENTITY . name ( ) , typeName ) ; } return ret ; } private AtlasClassificationType ensureClassificationType ( String typeName ) throws AtlasBaseException { AtlasClassificationType ret = typeRegistry . getClassificationTypeByName ( typeName ) ; if ( ret == null ) { throw new AtlasBaseException ( AtlasErrorCode . TYPE_NAME_INVALID , TypeCategory . CLASSIFICATION . name ( ) , typeName ) ; } return ret ; } private Map < String , Object > getAttributes ( HttpServletRequest request ) { Map < String , Object > attributes = new HashMap < > ( ) ; if ( MapUtils . isNotEmpty ( request . getParameterMap ( ) ) ) { for ( Map . Entry < String , String [ ] > e : request . getParameterMap ( ) . entrySet ( ) ) { String key = e . getKey ( ) ; if ( key != null && key . startsWith ( PREFIX_ATTR ) ) { String [ ] values = e . getValue ( ) ; String value = values != null && values . length > 0 ? values [ 0 ] : null ; attributes . put ( key . substring ( PREFIX_ATTR . length ( ) ) , value ) ; } } } return attributes ; } private void validateUniqueAttribute ( AtlasEntityType entityType , Map < String , Object > attributes ) throws AtlasBaseException { if ( MapUtils . isEmpty ( attributes ) ) { throw new AtlasBaseException ( AtlasErrorCode . ATTRIBUTE_UNIQUE_INVALID , entityType . getTypeName ( ) , """" ) ; } for ( String attributeName : attributes . keySet ( ) ) { AtlasAttributeDef attribute = entityType . getAttributeDef ( attributeName ) ; if ( attribute == null || ! attribute . getIsUnique ( ) ) { throw new AtlasBaseException ( AtlasErrorCode . ATTRIBUTE_UNIQUE_INVALID , entityType . getTypeName ( ) , attributeName ) ; } } } }",Smelly
public class IntegerResponseTest extends ResponseTest { public static IntegerResponseTest SINGLETON = new IntegerResponseTest ( ) ; public Object createObject ( ) throws Exception { IntegerResponse info = new IntegerResponse ( ) ; populateObject ( info ) ; return info ; } protected void populateObject ( Object object ) throws Exception { super . populateObject ( object ) ; IntegerResponse info = ( IntegerResponse ) object ; info . setResult ( 1 ) ; } },No
" private static class MockReaderIterator extends NativeReader . NativeReaderIterator < Integer > { private final OffsetRangeTracker tracker ; private Exchanger < Integer > exchanger = new Exchanger < > ( ) ; private int current ; private volatile boolean isClosed ; private boolean signalBlockedInAdvance = false ; private CyclicBarrier blockedInAdvanceBarrier = new CyclicBarrier ( 2 ) ; public MockReaderIterator ( int from , int to ) { this . tracker = new OffsetRangeTracker ( from , to ) ; this . current = from - 1 ; } @ Override public boolean start ( ) throws IOException { return advance ( ) ; } @ Override public boolean advance ( ) throws IOException { if ( ! tracker . tryReturnRecordAt ( true , current + 1 ) ) { return false ; } ++ current ; if ( signalBlockedInAdvance ) { signalBlockedInAdvance = false ; try { blockedInAdvanceBarrier . await ( ) ; } catch ( InterruptedException | BrokenBarrierException e ) { throw new RuntimeException ( e ) ; } } exchangeCurrent ( ) ; return true ; } private void exchangeCurrent ( ) { try { current = exchanger . exchange ( current ) ; } catch ( InterruptedException e ) { throw new NoSuchElementException ( ""interrupted"" ) ; } } @ Override public Integer getCurrent ( ) { return current ; } @ Override public NativeReader . Progress getProgress ( ) { Preconditions . checkState ( ! isClosed ) ; return cloudProgressToReaderProgress ( new ApproximateReportedProgress ( ) . setPosition ( new Position ( ) . setRecordIndex ( ( long ) current ) ) . setFractionConsumed ( tracker . getFractionConsumed ( ) ) ) ; } @ Override public NativeReader . DynamicSplitResult requestCheckpoint ( ) { Preconditions . checkState ( ! isClosed ) ; if ( ! tracker . trySplitAtPosition ( current + 1 ) ) { return null ; } return new NativeReader . DynamicSplitResultWithPosition ( cloudPositionToReaderPosition ( positionAtIndex ( current + 1L ) ) ) ; } @ Override public NativeReader . DynamicSplitResult requestDynamicSplit ( NativeReader . DynamicSplitRequest splitRequest ) { Preconditions . checkState ( ! isClosed ) ; ApproximateSplitRequest approximateSplitRequest = splitRequestToApproximateSplitRequest ( splitRequest ) ; int index = approximateSplitRequest . getPosition ( ) . getRecordIndex ( ) . intValue ( ) ; if ( ! tracker . trySplitAtPosition ( index ) ) { return null ; } return new NativeReader . DynamicSplitResultWithPosition ( cloudPositionToReaderPosition ( approximateSplitRequest . getPosition ( ) ) ) ; } public int offerNext ( int next ) { try { return exchanger . exchange ( next ) ; } catch ( InterruptedException e ) { throw new RuntimeException ( e ) ; } } public void blockInNextAdvance ( ) { signalBlockedInAdvance = true ; } public void awaitBlockedInAdvance ( ) { try { blockedInAdvanceBarrier . await ( ) ; } catch ( InterruptedException | BrokenBarrierException e ) { throw new RuntimeException ( ""interrupted"" ) ; } } @ Override public void close ( ) throws IOException { isClosed = true ; } ",No
"public class SymmetricBindingHandler extends AbstractBindingBuilder { SymmetricBinding sbinding ; TokenStore tokenStore ; public SymmetricBindingHandler ( WSSConfig config , SymmetricBinding binding , SOAPMessage saaj , WSSecHeader secHeader , AssertionInfoMap aim , SoapMessage message ) { super ( config , binding , saaj , secHeader , aim , message ) ; this . sbinding = binding ; tokenStore = getTokenStore ( ) ; protectionOrder = binding . getProtectionOrder ( ) ; } private TokenWrapper getSignatureToken ( ) { if ( sbinding . getProtectionToken ( ) != null ) { return sbinding . getProtectionToken ( ) ; } return sbinding . getSignatureToken ( ) ; } private TokenWrapper getEncryptionToken ( ) { if ( sbinding . getProtectionToken ( ) != null ) { return sbinding . getProtectionToken ( ) ; } return sbinding . getEncryptionToken ( ) ; } public void handleBinding ( ) { WSSecTimestamp timestamp = createTimestamp ( ) ; handleLayout ( timestamp ) ; if ( isRequestor ( ) ) { initializeTokens ( ) ; } if ( sbinding . getProtectionOrder ( ) == SPConstants . ProtectionOrder . EncryptBeforeSigning ) { doEncryptBeforeSign ( ) ; } else { doSignBeforeEncrypt ( ) ; } policyAsserted ( SP11Constants . TRUST_10 ) ; policyAsserted ( SP12Constants . TRUST_13 ) ; } private void initializeTokens ( ) { } private void doEncryptBeforeSign ( ) { try { TokenWrapper encryptionWrapper = getEncryptionToken ( ) ; Token encryptionToken = encryptionWrapper . getToken ( ) ; List < WSEncryptionPart > encrParts = getEncryptedParts ( ) ; List < WSEncryptionPart > sigParts = getSignedParts ( ) ; if ( encryptionToken != null && encrParts . size ( ) > 0 ) { String tokenId = null ; SecurityToken tok = null ; if ( encryptionToken instanceof IssuedToken || encryptionToken instanceof KerberosToken || encryptionToken instanceof SecureConversationToken || encryptionToken instanceof SecurityContextToken || encryptionToken instanceof SpnegoContextToken ) { tok = getSecurityToken ( ) ; } else if ( encryptionToken instanceof X509Token ) { if ( isRequestor ( ) ) { tokenId = setupEncryptedKey ( encryptionWrapper , encryptionToken ) ; } else { tokenId = getEncryptedKey ( ) ; } } else if ( encryptionToken instanceof UsernameToken ) { if ( isRequestor ( ) ) { tokenId = setupUTDerivedKey ( ( UsernameToken ) encryptionToken ) ; } else { tokenId = getUTDerivedKey ( ) ; } } if ( tok == null ) { if ( tokenId != null && tokenId . startsWith ( ""#"" ) ) { tokenId = tokenId . substring ( 1 ) ; } tok = tokenStore . getToken ( tokenId ) ; } boolean attached = false ; if ( includeToken ( encryptionToken . getInclusion ( ) ) ) { Element el = tok . getToken ( ) ; this . addEncryptedKeyElement ( cloneElement ( el ) ) ; attached = true ; } else if ( encryptionToken instanceof X509Token && isRequestor ( ) ) { Element el = tok . getToken ( ) ; this . addEncryptedKeyElement ( cloneElement ( el ) ) ; attached = true ; } WSSecBase encr = doEncryption ( encryptionWrapper , tok , attached , encrParts , true ) ; handleEncryptedSignedHeaders ( encrParts , sigParts ) ; if ( timestampEl != null ) { WSEncryptionPart timestampPart = convertToEncryptionPart ( timestampEl . getElement ( ) ) ; sigParts . add ( timestampPart ) ; } if ( isRequestor ( ) ) { this . addSupportingTokens ( sigParts ) ; } else { addSignatureConfirmation ( sigParts ) ; } if ( sigParts . size ( ) > 0 ) { signatures . add ( this . doSignature ( sigParts , encryptionWrapper , encryptionToken , tok , attached ) ) ; } if ( isRequestor ( ) ) { this . doEndorse ( ) ; } if ( sbinding . isSignatureProtection ( ) || encryptedTokensList . size ( ) > 0 && isRequestor ( ) ) { List < WSEncryptionPart > secondEncrParts = new ArrayList < WSEncryptionPart > ( ) ; if ( sbinding . isSignatureProtection ( ) ) { if ( this . mainSigId != null ) { WSEncryptionPart sigPart = new WSEncryptionPart ( this . mainSigId , ""Element"" ) ; sigPart . setElement ( bottomUpElement ) ; secondEncrParts . add ( sigPart ) ; } if ( sigConfList != null && ! sigConfList . isEmpty ( ) ) { secondEncrParts . addAll ( sigConfList ) ; } } if ( isRequestor ( ) ) { secondEncrParts . addAll ( encryptedTokensList ) ; } Element secondRefList = null ; if ( encryptionToken . isDerivedKeys ( ) && ! secondEncrParts . isEmpty ( ) ) { secondRefList = ( ( WSSecDKEncrypt ) encr ) . encryptForExternalRef ( null , secondEncrParts ) ; this . addDerivedKeyElement ( secondRefList ) ; } else if ( ! secondEncrParts . isEmpty ( ) ) { secondRefList = ( ( WSSecEncrypt ) encr ) . encryptForRef ( null , encrParts ) ; this . addDerivedKeyElement ( secondRefList ) ; } } } } catch ( RuntimeException ex ) { throw ex ; } catch ( Exception ex ) { throw new Fault ( ex ) ; } } private void doSignBeforeEncrypt ( ) { TokenWrapper sigTokenWrapper = getSignatureToken ( ) ; Token sigToken = sigTokenWrapper . getToken ( ) ; String sigTokId = null ; Element sigTokElem = null ; try { SecurityToken sigTok = null ; if ( sigToken != null ) { if ( sigToken instanceof SecureConversationToken || sigToken instanceof SecurityContextToken || sigToken instanceof IssuedToken || sigToken instanceof KerberosToken || sigToken instanceof SpnegoContextToken ) { sigTok = getSecurityToken ( ) ; } else if ( sigToken instanceof X509Token ) { if ( isRequestor ( ) ) { sigTokId = setupEncryptedKey ( sigTokenWrapper , sigToken ) ; } else { sigTokId = getEncryptedKey ( ) ; } } else if ( sigToken instanceof UsernameToken ) { if ( isRequestor ( ) ) { sigTokId = setupUTDerivedKey ( ( UsernameToken ) sigToken ) ; } else { sigTokId = getUTDerivedKey ( ) ; } } } else { policyNotAsserted ( sbinding , ""No signature token"" ) ; return ; } if ( sigTok == null && StringUtils . isEmpty ( sigTokId ) ) { policyNotAsserted ( sigTokenWrapper , ""No signature token id"" ) ; return ; } else { policyAsserted ( sigTokenWrapper ) ; } if ( sigTok == null ) { sigTok = tokenStore . getToken ( sigTokId ) ; } boolean tokIncluded = true ; if ( includeToken ( sigToken . getInclusion ( ) ) ) { Element el = sigTok . getToken ( ) ; sigTokElem = cloneElement ( el ) ; this . addEncryptedKeyElement ( sigTokElem ) ; } else if ( isRequestor ( ) && sigToken instanceof X509Token ) { Element el = sigTok . getToken ( ) ; sigTokElem = cloneElement ( el ) ; this . addEncryptedKeyElement ( sigTokElem ) ; } else { tokIncluded = false ; } List < WSEncryptionPart > sigs = getSignedParts ( ) ; if ( timestampEl != null ) { WSEncryptionPart timestampPart = convertToEncryptionPart ( timestampEl . getElement ( ) ) ; sigs . add ( timestampPart ) ; } if ( isRequestor ( ) ) { addSupportingTokens ( sigs ) ; if ( ! sigs . isEmpty ( ) ) { signatures . add ( doSignature ( sigs , sigTokenWrapper , sigToken , sigTok , tokIncluded ) ) ; } doEndorse ( ) ; } else { assertSupportingTokens ( sigs ) ; addSignatureConfirmation ( sigs ) ; if ( ! sigs . isEmpty ( ) ) { doSignature ( sigs , sigTokenWrapper , sigToken , sigTok , tokIncluded ) ; } } TokenWrapper encrTokenWrapper = getEncryptionToken ( ) ; Token encrToken = encrTokenWrapper . getToken ( ) ; SecurityToken encrTok = null ; if ( sigToken . equals ( encrToken ) ) { encrTok = sigTok ; } else { policyNotAsserted ( sbinding , ""Encryption token does not equal signature token"" ) ; return ; } List < WSEncryptionPart > enc = getEncryptedParts ( ) ; if ( sbinding . isSignatureProtection ( ) ) { if ( mainSigId != null ) { WSEncryptionPart sigPart = new WSEncryptionPart ( mainSigId , ""Element"" ) ; sigPart . setElement ( bottomUpElement ) ; enc . add ( sigPart ) ; } if ( sigConfList != null && ! sigConfList . isEmpty ( ) ) { enc . addAll ( sigConfList ) ; } } if ( isRequestor ( ) ) { enc . addAll ( encryptedTokensList ) ; } doEncryption ( encrTokenWrapper , encrTok , tokIncluded , enc , false ) ; } catch ( Exception e ) { throw new Fault ( e ) ; } } private WSSecBase doEncryptionDerived ( TokenWrapper recToken , SecurityToken encrTok , Token encrToken , boolean attached , List < WSEncryptionPart > encrParts , boolean atEnd ) { try { WSSecDKEncrypt dkEncr = new WSSecDKEncrypt ( wssConfig ) ; if ( recToken . getToken ( ) . getSPConstants ( ) == SP12Constants . INSTANCE ) { dkEncr . setWscVersion ( ConversationConstants . VERSION_05_12 ) ; } if ( attached && encrTok . getAttachedReference ( ) != null ) { dkEncr . setExternalKey ( encrTok . getSecret ( ) , cloneElement ( encrTok . getAttachedReference ( ) ) ) ; } else if ( encrTok . getUnattachedReference ( ) != null ) { dkEncr . setExternalKey ( encrTok . getSecret ( ) , cloneElement ( encrTok . getUnattachedReference ( ) ) ) ; } else if ( ! isRequestor ( ) && encrTok . getSHA1 ( ) != null ) { SecurityTokenReference tokenRef = new SecurityTokenReference ( saaj . getSOAPPart ( ) ) ; tokenRef . setKeyIdentifierEncKeySHA1 ( encrTok . getSHA1 ( ) ) ; String tokenType = encrTok . getTokenType ( ) ; if ( tokenType == null ) { tokenType = WSConstants . WSS_ENC_KEY_VALUE_TYPE ; } tokenRef . addTokenType ( tokenType ) ; dkEncr . setExternalKey ( encrTok . getSecret ( ) , tokenRef . getElement ( ) ) ; } else { if ( attached ) { String id = encrTok . getWsuId ( ) ; if ( id == null && ( encrToken instanceof SecureConversationToken || encrToken instanceof SecurityContextToken ) ) { dkEncr . setTokenIdDirectId ( true ) ; id = encrTok . getId ( ) ; } else if ( id == null ) { id = encrTok . getId ( ) ; } if ( id . startsWith ( ""#"" ) ) { id = id . substring ( 1 ) ; } dkEncr . setExternalKey ( encrTok . getSecret ( ) , id ) ; } else { dkEncr . setTokenIdDirectId ( true ) ; dkEncr . setExternalKey ( encrTok . getSecret ( ) , encrTok . getId ( ) ) ; } } if ( encrTok . getSHA1 ( ) != null ) { String tokenType = encrTok . getTokenType ( ) ; if ( tokenType == null ) { tokenType = WSConstants . WSS_ENC_KEY_VALUE_TYPE ; } dkEncr . setCustomValueType ( tokenType ) ; } else { String tokenType = encrTok . getTokenType ( ) ; if ( WSConstants . WSS_SAML_TOKEN_TYPE . equals ( tokenType ) || WSConstants . SAML_NS . equals ( tokenType ) ) { dkEncr . setKeyIdentifierType ( WSConstants . CUSTOM_KEY_IDENTIFIER ) ; dkEncr . setCustomValueType ( WSConstants . WSS_SAML_KI_VALUE_TYPE ) ; } else if ( WSConstants . WSS_SAML2_TOKEN_TYPE . equals ( tokenType ) || WSConstants . SAML2_NS . equals ( tokenType ) ) { dkEncr . setKeyIdentifierType ( WSConstants . CUSTOM_KEY_IDENTIFIER ) ; dkEncr . setCustomValueType ( WSConstants . WSS_SAML2_KI_VALUE_TYPE ) ; } else if ( encrToken instanceof UsernameToken ) { dkEncr . setCustomValueType ( WSConstants . WSS_USERNAME_TOKEN_VALUE_TYPE ) ; } else { dkEncr . setCustomValueType ( tokenType ) ; } } dkEncr . setSymmetricEncAlgorithm ( sbinding . getAlgorithmSuite ( ) . getEncryption ( ) ) ; dkEncr . setDerivedKeyLength ( sbinding . getAlgorithmSuite ( ) . getEncryptionDerivedKeyLength ( ) / 8 ) ; dkEncr . prepare ( saaj . getSOAPPart ( ) ) ; Element encrDKTokenElem = null ; encrDKTokenElem = dkEncr . getdktElement ( ) ; addDerivedKeyElement ( encrDKTokenElem ) ; Element refList = dkEncr . encryptForExternalRef ( null , encrParts ) ; if ( atEnd ) { this . insertBeforeBottomUp ( refList ) ; } else { this . addDerivedKeyElement ( refList ) ; } return dkEncr ; } catch ( Exception e ) { policyNotAsserted ( recToken , e ) ; } return null ; } private WSSecBase doEncryption ( TokenWrapper recToken , SecurityToken encrTok , boolean attached , List < WSEncryptionPart > encrParts , boolean atEnd ) { if ( recToken != null && recToken . getToken ( ) != null && encrParts . size ( ) > 0 ) { Token encrToken = recToken . getToken ( ) ; policyAsserted ( recToken ) ; policyAsserted ( encrToken ) ; AlgorithmSuite algorithmSuite = sbinding . getAlgorithmSuite ( ) ; if ( encrToken . isDerivedKeys ( ) ) { return doEncryptionDerived ( recToken , encrTok , encrToken , attached , encrParts , atEnd ) ; } else { try { WSSecEncrypt encr = new WSSecEncrypt ( wssConfig ) ; String encrTokId = encrTok . getId ( ) ; if ( attached ) { encrTokId = encrTok . getWsuId ( ) ; if ( encrTokId == null && ( encrToken instanceof SecureConversationToken || encrToken instanceof SecurityContextToken ) ) { encr . setEncKeyIdDirectId ( true ) ; encrTokId = encrTok . getId ( ) ; } else if ( encrTokId == null ) { encrTokId = encrTok . getId ( ) ; } if ( encrTokId . startsWith ( ""#"" ) ) { encrTokId = encrTokId . substring ( 1 ) ; } } else { encr . setEncKeyIdDirectId ( true ) ; } if ( encrTok . getTokenType ( ) != null ) { encr . setCustomReferenceValue ( encrTok . getTokenType ( ) ) ; } encr . setEncKeyId ( encrTokId ) ; encr . setEphemeralKey ( encrTok . getSecret ( ) ) ; Crypto crypto = getEncryptionCrypto ( recToken ) ; if ( crypto != null ) { this . message . getExchange ( ) . put ( SecurityConstants . ENCRYPT_CRYPTO , crypto ) ; setEncryptionUser ( encr , recToken , false , crypto ) ; } encr . setDocument ( saaj . getSOAPPart ( ) ) ; encr . setEncryptSymmKey ( false ) ; encr . setSymmetricEncAlgorithm ( algorithmSuite . getEncryption ( ) ) ; if ( encrToken instanceof IssuedToken || encrToken instanceof SpnegoContextToken ) { Element ref ; if ( attached ) { ref = encrTok . getAttachedReference ( ) ; } else { ref = encrTok . getUnattachedReference ( ) ; } String tokenType = encrTok . getTokenType ( ) ; if ( ref != null ) { SecurityTokenReference secRef = new SecurityTokenReference ( cloneElement ( ref ) , false ) ; encr . setSecurityTokenReference ( secRef ) ; } else if ( WSConstants . WSS_SAML_TOKEN_TYPE . equals ( tokenType ) || WSConstants . SAML_NS . equals ( tokenType ) ) { encr . setCustomReferenceValue ( WSConstants . WSS_SAML_KI_VALUE_TYPE ) ; encr . setKeyIdentifierType ( WSConstants . CUSTOM_KEY_IDENTIFIER ) ; } else if ( WSConstants . WSS_SAML2_TOKEN_TYPE . equals ( tokenType ) || WSConstants . SAML2_NS . equals ( tokenType ) ) { encr . setCustomReferenceValue ( WSConstants . WSS_SAML2_KI_VALUE_TYPE ) ; encr . setKeyIdentifierType ( WSConstants . CUSTOM_KEY_IDENTIFIER ) ; } else { encr . setCustomReferenceValue ( tokenType ) ; encr . setKeyIdentifierType ( WSConstants . CUSTOM_KEY_IDENTIFIER ) ; } } else if ( encrToken instanceof UsernameToken ) { encr . setCustomReferenceValue ( WSConstants . WSS_USERNAME_TOKEN_VALUE_TYPE ) ; } else if ( ! isRequestor ( ) ) { if ( encrTok . getSHA1 ( ) != null ) { encr . setCustomReferenceValue ( encrTok . getSHA1 ( ) ) ; encr . setKeyIdentifierType ( WSConstants . ENCRYPTED_KEY_SHA1_IDENTIFIER ) ; } else { encr . setKeyIdentifierType ( WSConstants . EMBED_SECURITY_TOKEN_REF ) ; } } encr . prepare ( saaj . getSOAPPart ( ) , crypto ) ; if ( encr . getBSTTokenId ( ) != null ) { encr . prependBSTElementToHeader ( secHeader ) ; } Element refList = encr . encryptForRef ( null , encrParts ) ; if ( atEnd ) { this . insertBeforeBottomUp ( refList ) ; } else { this . addDerivedKeyElement ( refList ) ; } return encr ; } catch ( WSSecurityException e ) { policyNotAsserted ( recToken , e ) ; } } } return null ; } private byte [ ] doSignatureDK ( List < WSEncryptionPart > sigs , TokenWrapper policyTokenWrapper , Token policyToken , SecurityToken tok , boolean included ) throws WSSecurityException { Document doc = saaj . getSOAPPart ( ) ; WSSecDKSign dkSign = new WSSecDKSign ( wssConfig ) ; if ( policyTokenWrapper . getToken ( ) . getSPConstants ( ) == SP12Constants . INSTANCE ) { dkSign . setWscVersion ( ConversationConstants . VERSION_05_12 ) ; } boolean attached = false ; if ( includeToken ( policyToken . getInclusion ( ) ) ) { attached = true ; } Element ref ; if ( attached ) { ref = tok . getAttachedReference ( ) ; } else { ref = tok . getUnattachedReference ( ) ; } if ( ref != null ) { dkSign . setExternalKey ( tok . getSecret ( ) , cloneElement ( ref ) ) ; } else if ( ! isRequestor ( ) && policyToken . isDerivedKeys ( ) && tok . getSHA1 ( ) != null ) { SecurityTokenReference tokenRef = new SecurityTokenReference ( doc ) ; if ( tok . getSHA1 ( ) != null ) { tokenRef . setKeyIdentifierEncKeySHA1 ( tok . getSHA1 ( ) ) ; String tokenType = tok . getTokenType ( ) ; if ( tokenType == null ) { tokenType = WSConstants . WSS_ENC_KEY_VALUE_TYPE ; } tokenRef . addTokenType ( tokenType ) ; } dkSign . setExternalKey ( tok . getSecret ( ) , tokenRef . getElement ( ) ) ; } else { if ( ( ! attached && ! isRequestor ( ) ) || policyToken instanceof SecureConversationToken || policyToken instanceof SecurityContextToken ) { dkSign . setTokenIdDirectId ( true ) ; } dkSign . setExternalKey ( tok . getSecret ( ) , tok . getId ( ) ) ; } dkSign . setSignatureAlgorithm ( sbinding . getAlgorithmSuite ( ) . getSymmetricSignature ( ) ) ; dkSign . setDerivedKeyLength ( sbinding . getAlgorithmSuite ( ) . getSignatureDerivedKeyLength ( ) / 8 ) ; if ( tok . getSHA1 ( ) != null ) { String tokenType = tok . getTokenType ( ) ; if ( tokenType == null ) { tokenType = WSConstants . WSS_ENC_KEY_VALUE_TYPE ; } dkSign . setCustomValueType ( tokenType ) ; } else { String tokenType = tok . getTokenType ( ) ; if ( WSConstants . WSS_SAML_TOKEN_TYPE . equals ( tokenType ) || WSConstants . SAML_NS . equals ( tokenType ) ) { dkSign . setKeyIdentifierType ( WSConstants . CUSTOM_KEY_IDENTIFIER ) ; dkSign . setCustomValueType ( WSConstants . WSS_SAML_KI_VALUE_TYPE ) ; } else if ( WSConstants . WSS_SAML2_TOKEN_TYPE . equals ( tokenType ) || WSConstants . SAML2_NS . equals ( tokenType ) ) { dkSign . setKeyIdentifierType ( WSConstants . CUSTOM_KEY_IDENTIFIER ) ; dkSign . setCustomValueType ( WSConstants . WSS_SAML2_KI_VALUE_TYPE ) ; } else if ( policyToken instanceof UsernameToken ) { dkSign . setCustomValueType ( WSConstants . WSS_USERNAME_TOKEN_VALUE_TYPE ) ; } else { dkSign . setCustomValueType ( tokenType ) ; } } try { dkSign . prepare ( doc , secHeader ) ; } catch ( ConversationException e ) { throw new WSSecurityException ( e . getMessage ( ) , e ) ; } if ( sbinding . isTokenProtection ( ) ) { String sigTokId = tok . getId ( ) ; if ( included ) { sigTokId = tok . getWsuId ( ) ; if ( sigTokId == null ) { sigTokId = tok . getId ( ) ; } if ( sigTokId . startsWith ( ""#"" ) ) { sigTokId = sigTokId . substring ( 1 ) ; } } sigs . add ( new WSEncryptionPart ( sigTokId ) ) ; } dkSign . setParts ( sigs ) ; List < Reference > referenceList = dkSign . addReferencesToSign ( sigs , secHeader ) ; Element el = dkSign . getdktElement ( ) ; addDerivedKeyElement ( el ) ; if ( bottomUpElement == null ) { dkSign . computeSignature ( referenceList , false , null ) ; } else { dkSign . computeSignature ( referenceList , true , bottomUpElement ) ; } bottomUpElement = dkSign . getSignatureElement ( ) ; this . mainSigId = dkSign . getSignatureId ( ) ; return dkSign . getSignatureValue ( ) ; } private byte [ ] doSignature ( List < WSEncryptionPart > sigs , TokenWrapper policyTokenWrapper , Token policyToken , SecurityToken tok , boolean included ) throws WSSecurityException { if ( policyToken . isDerivedKeys ( ) ) { return doSignatureDK ( sigs , policyTokenWrapper , policyToken , tok , included ) ; } else { WSSecSignature sig = new WSSecSignature ( wssConfig ) ; sig . setWsConfig ( wssConfig ) ; int type = included ? WSConstants . CUSTOM_SYMM_SIGNING : WSConstants . CUSTOM_SYMM_SIGNING_DIRECT ; if ( policyToken instanceof X509Token ) { if ( isRequestor ( ) ) { sig . setCustomTokenValueType ( WSConstants . SOAPMESSAGE_NS11 + ""#"" + WSConstants . ENC_KEY_VALUE_TYPE ) ; sig . setKeyIdentifierType ( type ) ; } else { sig . setEncrKeySha1value ( tok . getSHA1 ( ) ) ; sig . setKeyIdentifierType ( WSConstants . ENCRYPTED_KEY_SHA1_IDENTIFIER ) ; } } else if ( policyToken instanceof UsernameToken ) { sig . setCustomTokenValueType ( WSConstants . WSS_USERNAME_TOKEN_VALUE_TYPE ) ; sig . setKeyIdentifierType ( type ) ; } else { Element ref ; if ( included ) { ref = tok . getAttachedReference ( ) ; } else { ref = tok . getUnattachedReference ( ) ; } if ( ref != null ) { SecurityTokenReference secRef = new SecurityTokenReference ( cloneElement ( ref ) , false ) ; sig . setSecurityTokenReference ( secRef ) ; sig . setKeyIdentifierType ( WSConstants . CUSTOM_KEY_IDENTIFIER ) ; } else { String tokenType = tok . getTokenType ( ) ; if ( WSConstants . WSS_SAML_TOKEN_TYPE . equals ( tokenType ) || WSConstants . SAML_NS . equals ( tokenType ) ) { sig . setCustomTokenValueType ( WSConstants . WSS_SAML_KI_VALUE_TYPE ) ; sig . setKeyIdentifierType ( WSConstants . CUSTOM_KEY_IDENTIFIER ) ; } else if ( WSConstants . WSS_SAML2_TOKEN_TYPE . equals ( tokenType ) || WSConstants . SAML2_NS . equals ( tokenType ) ) { sig . setCustomTokenValueType ( WSConstants . WSS_SAML2_KI_VALUE_TYPE ) ; sig . setKeyIdentifierType ( WSConstants . CUSTOM_KEY_IDENTIFIER ) ; } else { sig . setCustomTokenValueType ( tokenType ) ; sig . setKeyIdentifierType ( type ) ; } } } String sigTokId ; if ( included ) { sigTokId = tok . getWsuId ( ) ; if ( sigTokId == null ) { if ( policyToken instanceof SecureConversationToken || policyToken instanceof SecurityContextToken ) { sig . setKeyIdentifierType ( WSConstants . CUSTOM_SYMM_SIGNING_DIRECT ) ; } sigTokId = tok . getId ( ) ; } if ( sigTokId . startsWith ( ""#"" ) ) { sigTokId = sigTokId . substring ( 1 ) ; } } else { sigTokId = tok . getId ( ) ; } if ( included && sbinding . isTokenProtection ( ) ) { sigs . add ( new WSEncryptionPart ( sigTokId ) ) ; } sig . setCustomTokenId ( sigTokId ) ; sig . setSecretKey ( tok . getSecret ( ) ) ; sig . setSignatureAlgorithm ( sbinding . getAlgorithmSuite ( ) . getSymmetricSignature ( ) ) ; Crypto crypto = null ; if ( sbinding . getProtectionToken ( ) != null ) { crypto = getEncryptionCrypto ( sbinding . getProtectionToken ( ) ) ; } else { crypto = getSignatureCrypto ( policyTokenWrapper ) ; } this . message . getExchange ( ) . put ( SecurityConstants . SIGNATURE_CRYPTO , crypto ) ; sig . prepare ( saaj . getSOAPPart ( ) , crypto , secHeader ) ; sig . setParts ( sigs ) ; List < Reference > referenceList = sig . addReferencesToSign ( sigs , secHeader ) ; if ( bottomUpElement == null ) { sig . computeSignature ( referenceList , false , null ) ; } else { sig . computeSignature ( referenceList , true , bottomUpElement ) ; } bottomUpElement = sig . getSignatureElement ( ) ; this . mainSigId = sig . getId ( ) ; return sig . getSignatureValue ( ) ; } } private String setupEncryptedKey ( TokenWrapper wrapper , Token sigToken ) throws WSSecurityException { WSSecEncryptedKey encrKey = this . getEncryptedKeyBuilder ( wrapper , sigToken ) ; String id = encrKey . getId ( ) ; byte [ ] secret = encrKey . getEphemeralKey ( ) ; Date created = new Date ( ) ; Date expires = new Date ( ) ; expires . setTime ( created . getTime ( ) + 300000 ) ; SecurityToken tempTok = new SecurityToken ( id , encrKey . getEncryptedKeyElement ( ) , created , expires ) ; tempTok . setSecret ( secret ) ; tempTok . setSHA1 ( getSHA1 ( encrKey . getEncryptedEphemeralKey ( ) ) ) ; tokenStore . add ( tempTok ) ; String bstTokenId = encrKey . getBSTTokenId ( ) ; if ( bstTokenId != null && bstTokenId . length ( ) > 0 ) { encrKey . prependBSTElementToHeader ( secHeader ) ; } return id ; } private String setupUTDerivedKey ( UsernameToken sigToken ) throws WSSecurityException { boolean useMac = hasSignedPartsOrElements ( ) ; WSSecUsernameToken usernameToken = addDKUsernameToken ( sigToken , useMac ) ; String id = usernameToken . getId ( ) ; byte [ ] secret = usernameToken . getDerivedKey ( ) ; Date created = new Date ( ) ; Date expires = new Date ( ) ; expires . setTime ( created . getTime ( ) + 300000 ) ; SecurityToken tempTok = new SecurityToken ( id , usernameToken . getUsernameTokenElement ( ) , created , expires ) ; tempTok . setSecret ( secret ) ; tokenStore . add ( tempTok ) ; return id ; } private String getEncryptedKey ( ) { List < WSHandlerResult > results = CastUtils . cast ( ( List < ? > ) message . getExchange ( ) . getInMessage ( ) . get ( WSHandlerConstants . RECV_RESULTS ) ) ; for ( WSHandlerResult rResult : results ) { List < WSSecurityEngineResult > wsSecEngineResults = rResult . getResults ( ) ; for ( WSSecurityEngineResult wser : wsSecEngineResults ) { Integer actInt = ( Integer ) wser . get ( WSSecurityEngineResult . TAG_ACTION ) ; String encryptedKeyID = ( String ) wser . get ( WSSecurityEngineResult . TAG_ID ) ; if ( actInt . intValue ( ) == WSConstants . ENCR && encryptedKeyID != null && encryptedKeyID . length ( ) != 0 ) { Date created = new Date ( ) ; Date expires = new Date ( ) ; expires . setTime ( created . getTime ( ) + 300000 ) ; SecurityToken tempTok = new SecurityToken ( encryptedKeyID , created , expires ) ; tempTok . setSecret ( ( byte [ ] ) wser . get ( WSSecurityEngineResult . TAG_SECRET ) ) ; tempTok . setSHA1 ( getSHA1 ( ( byte [ ] ) wser . get ( WSSecurityEngineResult . TAG_ENCRYPTED_EPHEMERAL_KEY ) ) ) ; tokenStore . add ( tempTok ) ; return encryptedKeyID ; } } } return null ; } private String getUTDerivedKey ( ) throws WSSecurityException { List < WSHandlerResult > results = CastUtils . cast ( ( List < ? > ) message . getExchange ( ) . getInMessage ( ) . get ( WSHandlerConstants . RECV_RESULTS ) ) ; for ( WSHandlerResult rResult : results ) { List < WSSecurityEngineResult > wsSecEngineResults = rResult . getResults ( ) ; for ( WSSecurityEngineResult wser : wsSecEngineResults ) { Integer actInt = ( Integer ) wser . get ( WSSecurityEngineResult . TAG_ACTION ) ; String utID = ( String ) wser . get ( WSSecurityEngineResult . TAG_ID ) ; if ( actInt . intValue ( ) == WSConstants . UT_NOPASSWORD ) { if ( utID == null || utID . length ( ) == 0 ) { utID = wssConfig . getIdAllocator ( ) . createId ( ""UsernameToken-"" , null ) ; } Date created = new Date ( ) ; Date expires = new Date ( ) ; expires . setTime ( created . getTime ( ) + 300000 ) ; SecurityToken tempTok = new SecurityToken ( utID , created , expires ) ; byte [ ] secret = ( byte [ ] ) wser . get ( WSSecurityEngineResult . TAG_SECRET ) ; tempTok . setSecret ( secret ) ; tokenStore . add ( tempTok ) ; return utID ; } } } return null ; } private String getSHA1 ( byte [ ] input ) { try { byte [ ] digestBytes = WSSecurityUtil . generateDigest ( input ) ; return Base64 . encode ( digestBytes ) ; } catch ( WSSecurityException e ) { } return null ; } private boolean hasSignedPartsOrElements ( ) { Collection < AssertionInfo > ais = aim . getAssertionInfo ( SP12Constants . SIGNED_PARTS ) ; if ( ais != null && ais . size ( ) > 0 ) { return true ; } ais = aim . getAssertionInfo ( SP12Constants . SIGNED_ELEMENTS ) ; if ( ais != null && ais . size ( ) > 0 ) { return true ; } return false ; } }",Smelly
"public abstract class AbstractJAXWSHandlerInterceptor < T extends Message > extends AbstractPhaseInterceptor < T > { protected Binding binding ; protected AbstractJAXWSHandlerInterceptor ( Binding b , String phase ) { super ( phase ) ; binding = b ; } protected boolean isOutbound ( T message ) { return isOutbound ( message , message . getExchange ( ) ) ; } private boolean isOutbound ( T message , Exchange ex ) { return message == ex . getOutMessage ( ) || message == ex . getOutFaultMessage ( ) ; } protected HandlerChainInvoker getInvoker ( T message ) { Exchange ex = message . getExchange ( ) ; HandlerChainInvoker invoker = ex . get ( HandlerChainInvoker . class ) ; if ( null == invoker ) { invoker = new HandlerChainInvoker ( binding . getHandlerChain ( ) , isOutbound ( message ) ) ; ex . put ( HandlerChainInvoker . class , invoker ) ; } boolean outbound = isOutbound ( message , ex ) ; if ( outbound ) { invoker . setOutbound ( ) ; } else { invoker . setInbound ( ) ; } invoker . setRequestor ( isRequestor ( message ) ) ; if ( ex . isOneWay ( ) || ( ( isRequestor ( message ) && ! outbound ) || ( ! isRequestor ( message ) && outbound ) ) ) { invoker . setResponseExpected ( false ) ; } else { invoker . setResponseExpected ( true ) ; } return invoker ; } protected Binding getBinding ( ) { return binding ; } public void onCompletion ( T message ) { getInvoker ( message ) . mepComplete ( message ) ; } public boolean isMEPComlete ( T message ) { HandlerChainInvoker invoker = getInvoker ( message ) ; if ( invoker . isRequestor ( ) ) { if ( invoker . isInbound ( ) ) { return true ; } else if ( ! invoker . isResponseExpected ( ) ) { return true ; } } else { if ( ! invoker . isInbound ( ) ) { return true ; } else if ( ! invoker . isResponseExpected ( ) ) { return true ; } } return false ; } protected void setupBindingOperationInfo ( Exchange exch , Object data ) { if ( exch . get ( BindingOperationInfo . class ) == null ) { QName opName = getOpQName ( exch , data ) ; if ( opName == null ) { return ; } BindingOperationInfo bop = ServiceModelUtil . getOperationForWrapperElement ( exch , opName , false ) ; if ( bop == null ) { bop = ServiceModelUtil . getOperation ( exch , opName ) ; } if ( bop != null ) { exch . put ( BindingOperationInfo . class , bop ) ; exch . put ( OperationInfo . class , bop . getOperationInfo ( ) ) ; if ( bop . getOutput ( ) == null ) { exch . setOneWay ( true ) ; } } } } protected QName getOpQName ( Exchange ex , Object data ) { return null ; } }",No
"public class DataTableTag extends UIComponentTag { private String first ; private String rows ; private String value ; private String var ; private String bgcolor ; private String border ; private String cellpadding ; private String cellspacing ; private String columnClasses ; private String dir ; private String footerClass ; private String frame ; private String headerClass ; private String lang ; private String onclick ; private String ondblclick ; private String onkeydown ; private String onkeypress ; private String onkeyup ; private String onmousedown ; private String onmousemove ; private String onmouseout ; private String onmouseover ; private String onmouseup ; private String rowClasses ; private String rules ; private String style ; private String styleClass ; private String summary ; private String title ; private String width ; public void setFirst ( String first ) { this . first = first ; } public void setRows ( String rows ) { this . rows = rows ; } public void setValue ( String value ) { this . value = value ; } public void setVar ( String var ) { this . var = var ; } public void setBgcolor ( String bgcolor ) { this . bgcolor = bgcolor ; } public void setBorder ( String border ) { this . border = border ; } public void setCellpadding ( String cellpadding ) { this . cellpadding = cellpadding ; } public void setCellspacing ( String cellspacing ) { this . cellspacing = cellspacing ; } public void setColumnClasses ( String columnClasses ) { this . columnClasses = columnClasses ; } public void setDir ( String dir ) { this . dir = dir ; } public void setFooterClass ( String footerClass ) { this . footerClass = footerClass ; } public void setFrame ( String frame ) { this . frame = frame ; } public void setHeaderClass ( String headerClass ) { this . headerClass = headerClass ; } public void setLang ( String lang ) { this . lang = lang ; } public void setOnclick ( String onclick ) { this . onclick = onclick ; } public void setOndblclick ( String ondblclick ) { this . ondblclick = ondblclick ; } public void setOnkeydown ( String onkeydown ) { this . onkeydown = onkeydown ; } public void setOnkeypress ( String onkeypress ) { this . onkeypress = onkeypress ; } public void setOnkeyup ( String onkeyup ) { this . onkeyup = onkeyup ; } public void setOnmousedown ( String onmousedown ) { this . onmousedown = onmousedown ; } public void setOnmousemove ( String onmousemove ) { this . onmousemove = onmousemove ; } public void setOnmouseout ( String onmouseout ) { this . onmouseout = onmouseout ; } public void setOnmouseover ( String onmouseover ) { this . onmouseover = onmouseover ; } public void setOnmouseup ( String onmouseup ) { this . onmouseup = onmouseup ; } public void setRowClasses ( String rowClasses ) { this . rowClasses = rowClasses ; } public void setRules ( String rules ) { this . rules = rules ; } public void setStyle ( String style ) { this . style = style ; } public void setStyleClass ( String styleClass ) { this . styleClass = styleClass ; } public void setSummary ( String summary ) { this . summary = summary ; } public void setTitle ( String title ) { this . title = title ; } public void setWidth ( String width ) { this . width = width ; } public String getRendererType ( ) { return ""javax.faces.Table"" ; } public String getComponentType ( ) { return ""javax.faces.HtmlDataTable"" ; } protected void setProperties ( UIComponent component ) { super . setProperties ( component ) ; UIData data ; try { data = ( UIData ) component ; } catch ( ClassCastException cce ) { throw new FacesException ( ""Tag <"" + getClass ( ) . getName ( ) + ""> expected UIData. "" + ""Got <"" + component . getClass ( ) . getName ( ) + "">"" ) ; } if ( first != null ) { if ( FacesUtils . isExpression ( first ) ) { data . setValueBinding ( ""first"" , createValueBinding ( first ) ) ; } else { data . setFirst ( Integer . parseInt ( first ) ) ; } } if ( rows != null ) { if ( FacesUtils . isExpression ( rows ) ) { data . setValueBinding ( ""rows"" , createValueBinding ( rows ) ) ; } else { data . setRows ( Integer . parseInt ( rows ) ) ; } } if ( value != null ) { if ( FacesUtils . isExpression ( value ) ) { data . setValueBinding ( ""value"" , createValueBinding ( value ) ) ; } else { data . setValue ( value ) ; } } data . setVar ( var ) ; setProperty ( component , ""bgcolor"" , bgcolor ) ; setIntegerProperty ( component , ""border"" , border ) ; setProperty ( component , ""cellpadding"" , cellpadding ) ; setProperty ( component , ""cellspacing"" , cellspacing ) ; setProperty ( component , ""columnClasses"" , columnClasses ) ; setProperty ( component , ""dir"" , dir ) ; setProperty ( component , ""footerClass"" , footerClass ) ; setProperty ( component , ""frame"" , frame ) ; setProperty ( component , ""headerClass"" , headerClass ) ; setProperty ( component , ""lang"" , lang ) ; setProperty ( component , ""onclick"" , onclick ) ; setProperty ( component , ""ondblclick"" , ondblclick ) ; setProperty ( component , ""onkeydown"" , onkeydown ) ; setProperty ( component , ""onkeypress"" , onkeypress ) ; setProperty ( component , ""onkeyup"" , onkeyup ) ; setProperty ( component , ""onmousedown"" , onmousedown ) ; setProperty ( component , ""onmousemove"" , onmousemove ) ; setProperty ( component , ""onmouseout"" , onmouseout ) ; setProperty ( component , ""onmouseover"" , onmouseover ) ; setProperty ( component , ""onmouseup"" , onmouseup ) ; setProperty ( component , ""rowClasses"" , rowClasses ) ; setProperty ( component , ""rules"" , rules ) ; setProperty ( component , ""style"" , style ) ; setProperty ( component , ""styleClass"" , styleClass ) ; setProperty ( component , ""summary"" , summary ) ; setProperty ( component , ""title"" , title ) ; setProperty ( component , ""width"" , width ) ; } public void recycle ( ) { super . recycle ( ) ; first = null ; rows = null ; value = null ; var = null ; bgcolor = null ; border = null ; cellpadding = null ; cellspacing = null ; columnClasses = null ; dir = null ; footerClass = null ; frame = null ; headerClass = null ; lang = null ; onclick = null ; ondblclick = null ; onkeydown = null ; onkeypress = null ; onkeyup = null ; onmousedown = null ; onmousemove = null ; onmouseout = null ; onmouseover = null ; onmouseup = null ; rowClasses = null ; rules = null ; style = null ; styleClass = null ; summary = null ; title = null ; width = null ; } }",Smelly
"public class BookmarkTreeNode implements Serializable { private static final long serialVersionUID = 1L ; private static final OidMarshaller OID_MARSHALLER = OidMarshaller . INSTANCE ; private final List < BookmarkTreeNode > children = Lists . newArrayList ( ) ; private final int depth ; private final RootOid oidNoVer ; private final String oidNoVerStr ; private final PageType pageType ; private String title ; private PageParameters pageParameters ; public static BookmarkTreeNode newRoot ( BookmarkableModel < ? > bookmarkableModel ) { return new BookmarkTreeNode ( bookmarkableModel , 0 ) ; } private BookmarkTreeNode ( final BookmarkableModel < ? > bookmarkableModel , final int depth ) { pageParameters = bookmarkableModel . getPageParametersWithoutUiHints ( ) ; RootOid oid = oidFrom ( pageParameters ) ; this . oidNoVerStr = OID_MARSHALLER . marshalNoVersion ( oid ) ; this . oidNoVer = OID_MARSHALLER . unmarshal ( oidNoVerStr , RootOid . class ) ; PageParameterNames . OBJECT_OID . removeFrom ( pageParameters ) ; PageParameterNames . OBJECT_OID . addStringTo ( pageParameters , getOidNoVerStr ( ) ) ; this . title = bookmarkableModel . getTitle ( ) ; this . pageType = bookmarkableModel instanceof EntityModel ? PageType . ENTITY : PageType . ACTION_PROMPT ; this . depth = depth ; } public RootOid getOidNoVer ( ) { return oidNoVer ; } public String getOidNoVerStr ( ) { return oidNoVerStr ; } public String getTitle ( ) { return title ; } private void setTitle ( String title ) { this . title = title ; } public PageType getPageType ( ) { return pageType ; } public List < BookmarkTreeNode > getChildren ( ) { return children ; } public BookmarkTreeNode addChild ( BookmarkableModel < ? > childModel ) { final BookmarkTreeNode childNode = new BookmarkTreeNode ( childModel , depth + 1 ) ; children . add ( childNode ) ; return childNode ; } public boolean matches ( BookmarkableModel < ? > candidateBookmarkableModel ) { if ( candidateBookmarkableModel instanceof EntityModel ) { if ( this . pageType != PageType . ENTITY ) { return false ; } return matchAndUpdateTitleFor ( ( EntityModel ) candidateBookmarkableModel ) ; } else if ( candidateBookmarkableModel instanceof ActionModel ) { if ( this . pageType != PageType . ACTION_PROMPT ) { return false ; } return matchFor ( ( ActionModel ) candidateBookmarkableModel ) ; } else { return false ; } } private boolean matchAndUpdateTitleFor ( final EntityModel candidateEntityModel ) { final String candidateOidStr = oidStrFrom ( candidateEntityModel ) ; boolean inGraph = Objects . equal ( this . oidNoVerStr , candidateOidStr ) ; if ( inGraph ) { this . setTitle ( candidateEntityModel . getTitle ( ) ) ; } if ( candidateEntityModel . hasAsChildPolicy ( ) ) { for ( BookmarkTreeNode childNode : this . getChildren ( ) ) { inGraph = childNode . matches ( candidateEntityModel ) || inGraph ; } if ( ! inGraph ) { inGraph = addToGraphIfParented ( candidateEntityModel ) ; } } return inGraph ; } private boolean matchFor ( final ActionModel candidateActionModel ) { final String candidateOidStr = oidStrFrom ( candidateActionModel ) ; if ( ! Objects . equal ( this . oidNoVerStr , candidateOidStr ) ) { return false ; } List < String > thisArgs = PageParameterNames . ACTION_ARGS . getListFrom ( pageParameters ) ; PageParameters candidatePageParameters = candidateActionModel . getPageParameters ( ) ; List < String > candidateArgs = PageParameterNames . ACTION_ARGS . getListFrom ( candidatePageParameters ) ; if ( ! Objects . equal ( thisArgs , candidateArgs ) ) { return false ; } return true ; } private boolean addToGraphIfParented ( BookmarkableModel < ? > candidateBookmarkableModel ) { boolean whetherAdded = false ; if ( candidateBookmarkableModel instanceof EntityModel ) { EntityModel entityModel = ( EntityModel ) candidateBookmarkableModel ; final ObjectAdapter candidateAdapter = entityModel . getObject ( ) ; final List < ObjectAssociation > properties = candidateAdapter . getSpecification ( ) . getAssociations ( Contributed . EXCLUDED , ObjectAssociation . Filters . REFERENCE_PROPERTIES ) ; for ( ObjectAssociation objectAssoc : properties ) { final ObjectAdapter possibleParentAdapter = objectAssoc . get ( candidateAdapter , InteractionInitiatedBy . USER ) ; if ( possibleParentAdapter == null ) { continue ; } final Oid possibleParentOid = possibleParentAdapter . getOid ( ) ; if ( possibleParentOid == null ) { continue ; } final String possibleParentOidStr = possibleParentOid . enStringNoVersion ( ) ; if ( Objects . equal ( this . oidNoVerStr , possibleParentOidStr ) ) { this . addChild ( candidateBookmarkableModel ) ; whetherAdded = true ; } } } return whetherAdded ; } public void appendGraphTo ( List < BookmarkTreeNode > list ) { list . add ( this ) ; for ( BookmarkTreeNode childNode : children ) { childNode . appendGraphTo ( list ) ; } } public int getDepth ( ) { return depth ; } public PageParameters getPageParameters ( ) { return pageParameters ; } public static RootOid oidFrom ( final PageParameters pageParameters ) { String oidStr = PageParameterNames . OBJECT_OID . getStringFrom ( pageParameters ) ; if ( oidStr == null ) { return null ; } try { return OID_MARSHALLER . unmarshal ( oidStr , RootOid . class ) ; } catch ( Exception ex ) { return null ; } } public static String oidStrFrom ( BookmarkableModel < ? > candidateBookmarkableModel ) { final RootOid oid = oidFrom ( candidateBookmarkableModel . getPageParametersWithoutUiHints ( ) ) ; return oid != null ? OID_MARSHALLER . marshalNoVersion ( oid ) : null ; } }",Smelly
"@ EventDriven @ SupportsBatching @ RequiresInstanceClassLoading @ InputRequirement ( InputRequirement . Requirement . INPUT_REQUIRED ) @ Tags ( { ""put"" , ""database"" , ""NoSQL"" , ""kudu"" , ""HDFS"" , ""record"" } ) @ CapabilityDescription ( ""Reads records from an incoming FlowFile using the provided Record Reader, and writes those records "" + ""to the specified Kudu's table. The schema for the table must be provided in the processor properties or from your source."" + "" If any error occurs while reading records from the input, or writing records to Kudu, the FlowFile will be routed to failure"" ) @ WritesAttribute ( attribute = ""record.count"" , description = ""Number of records written to Kudu"" ) public class PutKudu extends AbstractProcessor { protected static final PropertyDescriptor KUDU_MASTERS = new Builder ( ) . name ( ""Kudu Masters"" ) . description ( ""List all kudu masters's ip with port (e.g. 7051), comma separated"" ) . required ( true ) . addValidator ( StandardValidators . NON_EMPTY_VALIDATOR ) . expressionLanguageSupported ( VARIABLE_REGISTRY ) . build ( ) ; protected static final PropertyDescriptor TABLE_NAME = new Builder ( ) . name ( ""Table Name"" ) . description ( ""The name of the Kudu Table to put data into"" ) . required ( true ) . addValidator ( StandardValidators . NON_EMPTY_VALIDATOR ) . expressionLanguageSupported ( VARIABLE_REGISTRY ) . build ( ) ; static final PropertyDescriptor KERBEROS_CREDENTIALS_SERVICE = new Builder ( ) . name ( ""kerberos-credentials-service"" ) . displayName ( ""Kerberos Credentials Service"" ) . description ( ""Specifies the Kerberos Credentials to use for authentication"" ) . required ( false ) . identifiesControllerService ( KerberosCredentialsService . class ) . build ( ) ; public static final PropertyDescriptor RECORD_READER = new Builder ( ) . name ( ""record-reader"" ) . displayName ( ""Record Reader"" ) . description ( ""The service for reading records from incoming flow files."" ) . identifiesControllerService ( RecordReaderFactory . class ) . required ( true ) . build ( ) ; protected static final PropertyDescriptor SKIP_HEAD_LINE = new Builder ( ) . name ( ""Skip head line"" ) . description ( ""Deprecated. Used to ignore header lines, but this should be handled by a RecordReader "" + ""(e.g. \""Treat First Line as Header\"" property of CSVReader)"" ) . allowableValues ( ""true"" , ""false"" ) . defaultValue ( ""false"" ) . required ( true ) . addValidator ( StandardValidators . NON_EMPTY_VALIDATOR ) . build ( ) ; protected static final PropertyDescriptor INSERT_OPERATION = new Builder ( ) . name ( ""Insert Operation"" ) . description ( ""Specify operationType for this processor. Insert-Ignore will ignore duplicated rows"" ) . allowableValues ( OperationType . values ( ) ) . defaultValue ( OperationType . INSERT . toString ( ) ) . addValidator ( StandardValidators . NON_EMPTY_VALIDATOR ) . build ( ) ; protected static final PropertyDescriptor FLUSH_MODE = new Builder ( ) . name ( ""Flush Mode"" ) . description ( ""Set the new flush mode for a kudu session.\n"" + ""AUTO_FLUSH_SYNC: the call returns when the operation is persisted, else it throws an exception.\n"" + ""AUTO_FLUSH_BACKGROUND: the call returns when the operation has been added to the buffer. This call should normally perform only fast in-memory"" + "" operations but it may have to wait when the buffer is full and there's another buffer being flushed.\n"" + ""MANUAL_FLUSH: the call returns when the operation has been added to the buffer, else it throws a KuduException if the buffer is full."" ) . allowableValues ( SessionConfiguration . FlushMode . values ( ) ) . defaultValue ( SessionConfiguration . FlushMode . AUTO_FLUSH_BACKGROUND . toString ( ) ) . required ( true ) . build ( ) ; protected static final PropertyDescriptor FLOWFILE_BATCH_SIZE = new PropertyDescriptor . Builder ( ) . name ( ""FlowFiles per Batch"" ) . description ( ""The maximum number of FlowFiles to process in a single execution, between 1 - 100000. "" + ""Depending on your memory size, and data size per row set an appropriate batch size "" + ""for the number of FlowFiles to process per client connection setup."" + ""Gradually increase this number, only if your FlowFiles typically contain a few records."" ) . defaultValue ( ""1"" ) . required ( true ) . addValidator ( StandardValidators . createLongValidator ( 1 , 100000 , true ) ) . expressionLanguageSupported ( ExpressionLanguageScope . VARIABLE_REGISTRY ) . build ( ) ; protected static final PropertyDescriptor BATCH_SIZE = new PropertyDescriptor . Builder ( ) . name ( ""Batch Size"" ) . displayName ( ""Max Records per Batch"" ) . description ( ""The maximum number of Records to process in a single Kudu-client batch, between 1 - 100000. "" + ""Depending on your memory size, and data size per row set an appropriate batch size. "" + ""Gradually increase this number to find out the best one for best performances."" ) . defaultValue ( ""100"" ) . required ( true ) . addValidator ( StandardValidators . createLongValidator ( 1 , 100000 , true ) ) . expressionLanguageSupported ( VARIABLE_REGISTRY ) . build ( ) ; protected static final Relationship REL_SUCCESS = new Relationship . Builder ( ) . name ( ""success"" ) . description ( ""A FlowFile is routed to this relationship after it has been successfully stored in Kudu"" ) . build ( ) ; protected static final Relationship REL_FAILURE = new Relationship . Builder ( ) . name ( ""failure"" ) . description ( ""A FlowFile is routed to this relationship if it cannot be sent to Kudu"" ) . build ( ) ; public static final String RECORD_COUNT_ATTR = ""record.count"" ; protected OperationType operationType ; protected SessionConfiguration . FlushMode flushMode ; protected int batchSize = 100 ; protected int ffbatch = 1 ; protected KuduClient kuduClient ; protected KuduTable kuduTable ; private volatile KerberosUser kerberosUser ; @ Override protected List < PropertyDescriptor > getSupportedPropertyDescriptors ( ) { final List < PropertyDescriptor > properties = new ArrayList < > ( ) ; properties . add ( KUDU_MASTERS ) ; properties . add ( TABLE_NAME ) ; properties . add ( KERBEROS_CREDENTIALS_SERVICE ) ; properties . add ( SKIP_HEAD_LINE ) ; properties . add ( RECORD_READER ) ; properties . add ( INSERT_OPERATION ) ; properties . add ( FLUSH_MODE ) ; properties . add ( FLOWFILE_BATCH_SIZE ) ; properties . add ( BATCH_SIZE ) ; return properties ; } @ Override public Set < Relationship > getRelationships ( ) { final Set < Relationship > rels = new HashSet < > ( ) ; rels . add ( REL_SUCCESS ) ; rels . add ( REL_FAILURE ) ; return rels ; } @ OnScheduled public void onScheduled ( final ProcessContext context ) throws IOException , LoginException { final String tableName = context . getProperty ( TABLE_NAME ) . evaluateAttributeExpressions ( ) . getValue ( ) ; final String kuduMasters = context . getProperty ( KUDU_MASTERS ) . evaluateAttributeExpressions ( ) . getValue ( ) ; operationType = OperationType . valueOf ( context . getProperty ( INSERT_OPERATION ) . getValue ( ) ) ; batchSize = context . getProperty ( BATCH_SIZE ) . evaluateAttributeExpressions ( ) . asInteger ( ) ; ffbatch = context . getProperty ( FLOWFILE_BATCH_SIZE ) . evaluateAttributeExpressions ( ) . asInteger ( ) ; flushMode = SessionConfiguration . FlushMode . valueOf ( context . getProperty ( FLUSH_MODE ) . getValue ( ) ) ; getLogger ( ) . debug ( ""Setting up Kudu connection..."" ) ; final KerberosCredentialsService credentialsService = context . getProperty ( KERBEROS_CREDENTIALS_SERVICE ) . asControllerService ( KerberosCredentialsService . class ) ; kuduClient = createClient ( kuduMasters , credentialsService ) ; kuduTable = kuduClient . openTable ( tableName ) ; getLogger ( ) . debug ( ""Kudu connection successfully initialized"" ) ; } protected KuduClient createClient ( final String masters , final KerberosCredentialsService credentialsService ) throws LoginException { if ( credentialsService == null ) { return buildClient ( masters ) ; } final String keytab = credentialsService . getKeytab ( ) ; final String principal = credentialsService . getPrincipal ( ) ; kerberosUser = loginKerberosUser ( principal , keytab ) ; final KerberosAction < KuduClient > kerberosAction = new KerberosAction < > ( kerberosUser , ( ) -> buildClient ( masters ) , getLogger ( ) ) ; return kerberosAction . execute ( ) ; } protected KuduClient buildClient ( final String masters ) { return new KuduClient . KuduClientBuilder ( masters ) . build ( ) ; } protected KerberosUser loginKerberosUser ( final String principal , final String keytab ) throws LoginException { final KerberosUser kerberosUser = new KerberosKeytabUser ( principal , keytab ) ; kerberosUser . login ( ) ; return kerberosUser ; } @ OnStopped public final void closeClient ( ) throws KuduException , LoginException { try { if ( kuduClient != null ) { getLogger ( ) . debug ( ""Closing KuduClient"" ) ; kuduClient . close ( ) ; kuduClient = null ; } } finally { if ( kerberosUser != null ) { kerberosUser . logout ( ) ; kerberosUser = null ; } } } @ Override public void onTrigger ( final ProcessContext context , final ProcessSession session ) throws ProcessException { final List < FlowFile > flowFiles = session . get ( ffbatch ) ; if ( flowFiles . isEmpty ( ) ) { return ; } final KerberosUser user = kerberosUser ; if ( user == null ) { trigger ( context , session , flowFiles ) ; return ; } final PrivilegedExceptionAction < Void > privelegedAction = ( ) -> { trigger ( context , session , flowFiles ) ; return null ; } ; final KerberosAction < Void > action = new KerberosAction < > ( user , privelegedAction , getLogger ( ) ) ; action . execute ( ) ; } private void trigger ( final ProcessContext context , final ProcessSession session , final List < FlowFile > flowFiles ) throws ProcessException { final KuduSession kuduSession = getKuduSession ( kuduClient ) ; final RecordReaderFactory recordReaderFactory = context . getProperty ( RECORD_READER ) . asControllerService ( RecordReaderFactory . class ) ; final Map < FlowFile , Integer > numRecords = new HashMap < > ( ) ; final Map < FlowFile , Object > flowFileFailures = new HashMap < > ( ) ; final Map < Operation , FlowFile > operationFlowFileMap = new HashMap < > ( ) ; int numBuffered = 0 ; final List < RowError > pendingRowErrors = new ArrayList < > ( ) ; for ( FlowFile flowFile : flowFiles ) { try ( final InputStream in = session . read ( flowFile ) ; final RecordReader recordReader = recordReaderFactory . createRecordReader ( flowFile , in , getLogger ( ) ) ) { final List < String > fieldNames = recordReader . getSchema ( ) . getFieldNames ( ) ; final RecordSet recordSet = recordReader . createRecordSet ( ) ; Record record = recordSet . next ( ) ; while ( record != null ) { Operation operation = operationType == OperationType . UPSERT ? upsertRecordToKudu ( kuduTable , record , fieldNames ) : insertRecordToKudu ( kuduTable , record , fieldNames ) ; operationFlowFileMap . put ( operation , flowFile ) ; if ( numBuffered == batchSize && flushMode == SessionConfiguration . FlushMode . MANUAL_FLUSH ) { numBuffered = 0 ; flushKuduSession ( kuduSession , false , pendingRowErrors ) ; } OperationResponse response = kuduSession . apply ( operation ) ; if ( response != null && response . hasRowError ( ) ) { flowFileFailures . put ( flowFile , response . getRowError ( ) ) ; break ; } numBuffered ++ ; numRecords . merge ( flowFile , 1 , Integer :: sum ) ; record = recordSet . next ( ) ; } } catch ( Exception ex ) { flowFileFailures . put ( flowFile , ex ) ; } } if ( numBuffered > 0 ) { try { flushKuduSession ( kuduSession , true , pendingRowErrors ) ; } catch ( final Exception e ) { getLogger ( ) . error ( ""Failed to flush/close Kudu Session"" , e ) ; for ( final FlowFile flowFile : flowFiles ) { session . transfer ( flowFile , REL_FAILURE ) ; } return ; } } final Map < FlowFile , List < RowError > > flowFileRowErrors = pendingRowErrors . stream ( ) . collect ( Collectors . groupingBy ( e -> operationFlowFileMap . get ( e . getOperation ( ) ) ) ) ; long totalCount = 0L ; for ( final FlowFile flowFile : flowFiles ) { final int count = numRecords . getOrDefault ( flowFile , 0 ) ; totalCount += count ; final List < RowError > rowErrors = flowFileRowErrors . get ( flowFile ) ; if ( rowErrors != null ) { rowErrors . forEach ( rowError -> getLogger ( ) . error ( ""Failed to write due to {}"" , new Object [ ] { rowError . toString ( ) } ) ) ; session . putAttribute ( flowFile , RECORD_COUNT_ATTR , String . valueOf ( count - rowErrors . size ( ) ) ) ; session . transfer ( flowFile , REL_FAILURE ) ; } else { session . putAttribute ( flowFile , RECORD_COUNT_ATTR , String . valueOf ( count ) ) ; if ( flowFileFailures . containsKey ( flowFile ) ) { getLogger ( ) . error ( ""Failed to write due to {}"" , new Object [ ] { flowFileFailures . get ( flowFile ) } ) ; session . transfer ( flowFile , REL_FAILURE ) ; } else { session . transfer ( flowFile , REL_SUCCESS ) ; session . getProvenanceReporter ( ) . send ( flowFile , ""Successfully added FlowFile to Kudu"" ) ; } } } session . adjustCounter ( ""Records Inserted"" , totalCount , false ) ; } protected KuduSession getKuduSession ( final KuduClient client ) { final KuduSession kuduSession = client . newSession ( ) ; kuduSession . setMutationBufferSpace ( batchSize ) ; kuduSession . setFlushMode ( flushMode ) ; if ( operationType == OperationType . INSERT_IGNORE ) { kuduSession . setIgnoreAllDuplicateRows ( true ) ; } return kuduSession ; } private void flushKuduSession ( final KuduSession kuduSession , boolean close , final List < RowError > rowErrors ) throws KuduException { final List < OperationResponse > responses = close ? kuduSession . close ( ) : kuduSession . flush ( ) ; if ( kuduSession . getFlushMode ( ) == SessionConfiguration . FlushMode . AUTO_FLUSH_BACKGROUND ) { rowErrors . addAll ( Arrays . asList ( kuduSession . getPendingErrors ( ) . getRowErrors ( ) ) ) ; } else { responses . stream ( ) . filter ( OperationResponse :: hasRowError ) . map ( OperationResponse :: getRowError ) . forEach ( rowErrors :: add ) ; } } protected Upsert upsertRecordToKudu ( KuduTable kuduTable , Record record , List < String > fieldNames ) { Upsert upsert = kuduTable . newUpsert ( ) ; this . buildPartialRow ( kuduTable . getSchema ( ) , upsert . getRow ( ) , record , fieldNames ) ; return upsert ; } protected Insert insertRecordToKudu ( KuduTable kuduTable , Record record , List < String > fieldNames ) { Insert insert = kuduTable . newInsert ( ) ; this . buildPartialRow ( kuduTable . getSchema ( ) , insert . getRow ( ) , record , fieldNames ) ; return insert ; } @ VisibleForTesting void buildPartialRow ( Schema schema , PartialRow row , Record record , List < String > fieldNames ) { for ( String colName : fieldNames ) { int colIdx = this . getColumnIndex ( schema , colName ) ; if ( colIdx != - 1 ) { ColumnSchema colSchema = schema . getColumnByIndex ( colIdx ) ; Type colType = colSchema . getType ( ) ; if ( record . getValue ( colName ) == null ) { row . setNull ( colName ) ; continue ; } switch ( colType . getDataType ( colSchema . getTypeAttributes ( ) ) ) { case BOOL : row . addBoolean ( colIdx , record . getAsBoolean ( colName ) ) ; break ; case FLOAT : row . addFloat ( colIdx , record . getAsFloat ( colName ) ) ; break ; case DOUBLE : row . addDouble ( colIdx , record . getAsDouble ( colName ) ) ; break ; case BINARY : row . addBinary ( colIdx , record . getAsString ( colName ) . getBytes ( ) ) ; break ; case INT8 : row . addByte ( colIdx , record . getAsInt ( colName ) . byteValue ( ) ) ; break ; case INT16 : row . addShort ( colIdx , record . getAsInt ( colName ) . shortValue ( ) ) ; break ; case INT32 : row . addInt ( colIdx , record . getAsInt ( colName ) ) ; break ; case INT64 : case UNIXTIME_MICROS : row . addLong ( colIdx , record . getAsLong ( colName ) ) ; break ; case STRING : row . addString ( colIdx , record . getAsString ( colName ) ) ; break ; case DECIMAL32 : case DECIMAL64 : case DECIMAL128 : row . addDecimal ( colIdx , new BigDecimal ( record . getAsString ( colName ) ) ) ; break ; default : throw new IllegalStateException ( String . format ( ""unknown column type %s"" , colType ) ) ; } } } } private int getColumnIndex ( Schema columns , String colName ) { try { return columns . getColumnIndex ( colName ) ; } catch ( Exception ex ) { return - 1 ; } } }",Smelly
"public class SessionPostTransformer extends SessionPreTransformer { public static final String DELETECONTEXT_ELEMENT = ""deletecontext"" ; public static final String DELETECONTEXT_NAME_ATTRIBUTE = ""name"" ; public static final String SETXML_ELEMENT = ""setxml"" ; public static final String SETXML_CONTEXT_ATTRIBUTE = ""context"" ; public static final String SETXML_PATH_ATTRIBUTE = ""path"" ; public static final String APPENDXML_ELEMENT = ""appendxml"" ; public static final String APPENDXML_CONTEXT_ATTRIBUTE = ""context"" ; public static final String APPENDXML_PATH_ATTRIBUTE = ""path"" ; public static final String REMOVEXML_ELEMENT = ""removexml"" ; public static final String REMOVEXML_CONTEXT_ATTRIBUTE = ""context"" ; public static final String REMOVEXML_PATH_ATTRIBUTE = ""path"" ; public static final String MERGEXML_ELEMENT = ""mergexml"" ; public static final String MERGEXML_CONTEXT_ATTRIBUTE = ""context"" ; public static final String MERGEXML_PATH_ATTRIBUTE = ""path"" ; public static final String SAVECONTEXT_ELEMENT = ""savexml"" ; public static final String SAVECONTEXT_CONTEXT_ATTRIBUTE = ""context"" ; public static final String SAVECONTEXT_PATH_ATTRIBUTE = ""path"" ; public static final String INPUTXML_ELEMENT = ""inputxml"" ; public static final String INPUTXML_CONTEXT_ATTRIBUTE = ""context"" ; public static final String INPUTXML_PATH_ATTRIBUTE = ""path"" ; public static final String INPUTXML_NAME_ATTRIBUTE = ""name"" ; public static final String INPUTXML_TYPE_ATTRIBUTE = ""type"" ; public static final String INPUTXML_VALIDATIONRESULT_ATTRIBUTE = ""valresult"" ; public static final String FORM_ELEMENT = ""form"" ; public static final String FORM_ACTION_ELEMENT = ""action"" ; public static final String FORM_CONTENT_ELEMENT = ""content"" ; public static final String FORM_VALIDATION_ELEMENT = ""validate"" ; public static final String FORM_VALIDATION_SOURCE_ATTRIBUTE = ""src"" ; public static final String FORM_VALIDATESET_ELEMENT = ""constraint-set"" ; private static final int STATE_OUTSIDE = 0 ; private static final int STATE_FORM = 1 ; private int state ; private String formName ; private Map validationResultMap ; public void setupTransforming ( ) throws ProcessingException , SAXException , IOException { super . setupTransforming ( ) ; this . state = STATE_OUTSIDE ; this . formName = null ; } public void startTransformingElement ( String uri , String name , String raw , Attributes attr ) throws ProcessingException , IOException , SAXException { if ( this . getLogger ( ) . isDebugEnabled ( ) ) { this . getLogger ( ) . debug ( ""BEGIN startTransformingElement uri="" + uri + "", name="" + name + "", raw="" + raw + "", attr="" + attr ) ; } if ( name . equals ( DELETECONTEXT_ELEMENT ) ) { this . getContextManager ( ) . deleteContext ( attr . getValue ( DELETECONTEXT_NAME_ATTRIBUTE ) ) ; } else if ( name . equals ( SETXML_ELEMENT ) ) { this . startRecording ( ) ; stack . push ( attr . getValue ( SETXML_CONTEXT_ATTRIBUTE ) ) ; stack . push ( attr . getValue ( SETXML_PATH_ATTRIBUTE ) ) ; } else if ( name . equals ( MERGEXML_ELEMENT ) ) { this . startRecording ( ) ; stack . push ( attr . getValue ( MERGEXML_CONTEXT_ATTRIBUTE ) ) ; stack . push ( attr . getValue ( MERGEXML_PATH_ATTRIBUTE ) ) ; } else if ( name . equals ( APPENDXML_ELEMENT ) ) { this . startRecording ( ) ; stack . push ( attr . getValue ( APPENDXML_CONTEXT_ATTRIBUTE ) ) ; stack . push ( attr . getValue ( APPENDXML_PATH_ATTRIBUTE ) ) ; } else if ( name . equals ( REMOVEXML_ELEMENT ) ) { this . startTextRecording ( ) ; stack . push ( attr . getValue ( REMOVEXML_CONTEXT_ATTRIBUTE ) ) ; stack . push ( attr . getValue ( REMOVEXML_PATH_ATTRIBUTE ) ) ; } else if ( name . equals ( SAVECONTEXT_ELEMENT ) ) { this . startParametersRecording ( ) ; stack . push ( attr . getValue ( SAVECONTEXT_CONTEXT_ATTRIBUTE ) ) ; if ( attr . getValue ( SAVECONTEXT_PATH_ATTRIBUTE ) != null ) { stack . push ( attr . getValue ( SAVECONTEXT_PATH_ATTRIBUTE ) ) ; } else { stack . push ( ""/"" ) ; } } else if ( name . equals ( INPUTXML_ELEMENT ) ) { stack . push ( attr . getValue ( INPUTXML_CONTEXT_ATTRIBUTE ) ) ; String fieldname = attr . getValue ( INPUTXML_NAME_ATTRIBUTE ) ; stack . push ( fieldname ) ; stack . push ( attr . getValue ( INPUTXML_PATH_ATTRIBUTE ) ) ; AttributesImpl newattr = new AttributesImpl ( ) ; newattr . addAttribute ( """" , INPUTXML_NAME_ATTRIBUTE , INPUTXML_NAME_ATTRIBUTE , ""CDATA"" , fieldname ) ; if ( attr . getValue ( INPUTXML_TYPE_ATTRIBUTE ) != null ) { newattr . addAttribute ( """" , INPUTXML_TYPE_ATTRIBUTE , INPUTXML_TYPE_ATTRIBUTE , ""CDATA"" , attr . getValue ( INPUTXML_TYPE_ATTRIBUTE ) ) ; } ValidatorActionResult validationResult = null ; if ( validationResultMap != null && validationResultMap . get ( fieldname ) != null ) { validationResult = ( ValidatorActionResult ) validationResultMap . get ( fieldname ) ; newattr . addAttribute ( """" , INPUTXML_VALIDATIONRESULT_ATTRIBUTE , INPUTXML_VALIDATIONRESULT_ATTRIBUTE , ""CDATA"" , validationResult . toString ( ) ) ; } super . startTransformingElement ( """" , name , name , newattr ) ; this . startRecording ( ) ; } else if ( name . equals ( FORM_ELEMENT ) && this . state == STATE_OUTSIDE ) { String formName = attr . getValue ( ""name"" ) ; if ( formName == null ) { throw new ProcessingException ( ""The name attribute of the form element is required."" ) ; } this . stack . push ( new Integer ( this . state ) ) ; this . state = STATE_FORM ; this . stack . push ( new AttributesImpl ( attr ) ) ; } else if ( name . equals ( FORM_ACTION_ELEMENT ) && this . state == STATE_FORM ) { this . startTextRecording ( ) ; } else if ( name . equals ( FORM_CONTENT_ELEMENT ) && this . state == STATE_FORM ) { validationResultMap = ( Map ) this . getSessionManager ( ) . getSession ( true ) . getAttribute ( this . formName + ""validation-result"" ) ; } else if ( name . equals ( FORM_VALIDATION_ELEMENT ) && this . state == STATE_FORM ) { this . startRecording ( ) ; if ( attr . getValue ( FORM_VALIDATION_SOURCE_ATTRIBUTE ) != null ) { stack . push ( attr . getValue ( FORM_VALIDATION_SOURCE_ATTRIBUTE ) ) ; } else { stack . push ( ""EMPTY"" ) ; } } else { super . startTransformingElement ( uri , name , raw , attr ) ; } if ( this . getLogger ( ) . isDebugEnabled ( ) ) { this . getLogger ( ) . debug ( ""END startTransformingElement"" ) ; } } public void endTransformingElement ( String uri , String name , String raw ) throws ProcessingException , IOException , SAXException { if ( this . getLogger ( ) . isDebugEnabled ( ) ) { this . getLogger ( ) . debug ( ""BEGIN endTransformingElement uri="" + uri + "", name="" + name + "", raw="" + raw ) ; } if ( name . equals ( DELETECONTEXT_ELEMENT ) ) { } else if ( name . equals ( SETXML_ELEMENT ) ) { String path = ( String ) stack . pop ( ) ; String contextName = ( String ) stack . pop ( ) ; this . getSessionManager ( ) . setContextFragment ( contextName , path , this . endRecording ( ) ) ; } else if ( name . equals ( MERGEXML_ELEMENT ) ) { String path = ( String ) stack . pop ( ) ; String contextName = ( String ) stack . pop ( ) ; this . getSessionManager ( ) . mergeContextFragment ( contextName , path , this . endRecording ( ) ) ; } else if ( name . equals ( APPENDXML_ELEMENT ) ) { String path = ( String ) stack . pop ( ) ; String contextName = ( String ) stack . pop ( ) ; this . getSessionManager ( ) . appendContextFragment ( contextName , path , this . endRecording ( ) ) ; } else if ( name . equals ( REMOVEXML_ELEMENT ) ) { String path = ( String ) stack . pop ( ) ; String contextName = ( String ) stack . pop ( ) ; endTextRecording ( ) ; this . getSessionManager ( ) . removeContextFragment ( contextName , path ) ; } else if ( name . equals ( SAVECONTEXT_ELEMENT ) ) { String path = ( String ) stack . pop ( ) ; String contextName = ( String ) stack . pop ( ) ; SourceParameters pars = this . endParametersRecording ( ( SourceParameters ) null ) ; pars . setSingleParameterValue ( ""contextname"" , contextName ) ; pars . setSingleParameterValue ( ""path"" , path ) ; this . getContextManager ( ) . getContext ( contextName ) . saveXML ( path , pars ) ; } else if ( name . equals ( INPUTXML_ELEMENT ) ) { String path = ( String ) this . stack . pop ( ) ; String fieldname = ( String ) this . stack . pop ( ) ; String contextname = ( String ) this . stack . pop ( ) ; DocumentFragment defaultFragment = this . endRecording ( ) ; if ( this . formName == null ) { throw new ProcessingException ( ""The inputxml must be contained inside a form."" ) ; } DocumentFragment value = this . getFormManager ( ) . registerInputField ( contextname , path , fieldname , formName ) ; if ( value == null ) { value = defaultFragment ; } this . sendEvents ( value ) ; super . endTransformingElement ( """" , name , name ) ; } else if ( name . equals ( FORM_ELEMENT ) && this . state == STATE_FORM ) { this . state = ( ( Integer ) this . stack . pop ( ) ) . intValue ( ) ; this . sendEndElementEvent ( ""form"" ) ; this . formName = null ; } else if ( name . equals ( FORM_ACTION_ELEMENT ) && this . state == STATE_FORM ) { String action = this . endTextRecording ( ) ; AttributesImpl a = ( AttributesImpl ) this . stack . pop ( ) ; this . formName = a . getValue ( ""name"" ) ; boolean hasPars = ( action . indexOf ( ""?"" ) != - 1 ) ; action = this . response . encodeURL ( action + ( hasPars ? '&' : '?' ) + SessionConstants . SESSION_FORM_PARAMETER + '=' + this . formName ) ; a . addAttribute ( """" , ""action"" , ""action"" , ""CDATA"" , action ) ; if ( a . getValue ( ""method"" ) == null ) { a . addAttribute ( """" , ""method"" , ""method"" , ""CDATA"" , ""POST"" ) ; } this . sendStartElementEvent ( ""form"" , a ) ; } else if ( name . equals ( FORM_CONTENT_ELEMENT ) && this . state == STATE_FORM ) { } else if ( name . equals ( FORM_VALIDATION_ELEMENT ) && this . state == STATE_FORM ) { if ( this . formName == null ) { throw new ProcessingException ( ""The validate element must be contained inside a form."" ) ; } DocumentFragment validationDoc = this . endRecording ( ) ; String source = ( String ) stack . pop ( ) ; if ( ! source . equals ( ""EMPTY"" ) ) { try { Source resource = this . resolver . resolveURI ( source ) ; SAXConfigurationHandler saxBuilder = new SAXConfigurationHandler ( ) ; SourceUtil . parse ( this . manager , resource , saxBuilder ) ; Configuration conf = saxBuilder . getConfiguration ( ) ; Session session = this . getSessionManager ( ) . getSession ( true ) ; session . setAttribute ( this . formName , conf ) ; if ( validationDoc != null ) { validationDoc . normalize ( ) ; Node validationNode = validationDoc . getFirstChild ( ) ; while ( validationNode . getNodeType ( ) != Node . ELEMENT_NODE ) { validationNode = validationNode . getNextSibling ( ) ; if ( validationNode == null ) { break ; } } if ( validationNode != null && validationNode . getNodeType ( ) == Node . ELEMENT_NODE && validationNode . getNodeName ( ) . equals ( FORM_VALIDATESET_ELEMENT ) ) { Properties props = XMLUtils . createPropertiesForXML ( false ) ; props . put ( OutputKeys . ENCODING , ""ISO-8859-1"" ) ; String validationXML = XMLUtils . serializeNode ( validationNode , props ) ; DefaultConfigurationBuilder builder = new DefaultConfigurationBuilder ( ) ; conf = builder . build ( new ByteArrayInputStream ( validationXML . getBytes ( ) ) ) ; session . setAttribute ( this . formName + ""constraint-set"" , conf ) ; } } } catch ( SourceException se ) { throw new ProcessingException ( ""Cannot resolve"" + source , se ) ; } catch ( ConfigurationException ce ) { throw new ProcessingException ( ""Error building Configuration out of constraint-set element"" , ce ) ; } } else if ( validationDoc != null ) { try { validationDoc . normalize ( ) ; Node validationNode = validationDoc . getFirstChild ( ) ; while ( validationNode . getNodeType ( ) != Node . ELEMENT_NODE ) { validationNode = validationNode . getNextSibling ( ) ; if ( validationNode == null ) { break ; } } if ( validationNode != null && validationNode . getNodeType ( ) == Node . ELEMENT_NODE && validationNode . getNodeName ( ) . equals ( ""root"" ) ) { Properties props = XMLUtils . createPropertiesForXML ( false ) ; props . put ( OutputKeys . ENCODING , ""ISO-8859-1"" ) ; String validationXML = XMLUtils . serializeNode ( validationNode , props ) ; DefaultConfigurationBuilder builder = new DefaultConfigurationBuilder ( ) ; Configuration conf = builder . build ( new ByteArrayInputStream ( validationXML . getBytes ( ) ) ) ; Session session = this . getSessionManager ( ) . getSession ( true ) ; session . setAttribute ( this . formName , conf ) ; session . setAttribute ( this . formName + ""constraint-set"" , conf . getChildren ( ""constraint-set"" ) [ 0 ] ) ; } } catch ( ConfigurationException ce ) { throw new ProcessingException ( ""Error building Configuration out of validation XML"" , ce ) ; } } } else { super . endTransformingElement ( uri , name , raw ) ; } if ( this . getLogger ( ) . isDebugEnabled ( ) ) { this . getLogger ( ) . debug ( ""END endTransformingElement"" ) ; } } }",Smelly
"public class Parser { private static final String ATOM = ""atom"" ; private static final String JSON = ""json"" ; private static final String XML = ""xml"" ; private static final String DOLLAR = ""$"" ; private static final String AT = ""@"" ; private static final String NULL = ""null"" ; private final Edm edm ; private final OData odata ; public Parser ( final Edm edm , final OData odata ) { this . edm = edm ; this . odata = odata ; } public UriInfo parseUri ( final String path , final String query , final String fragment ) throws UriParserException , UriValidationException { UriInfoImpl contextUriInfo = new UriInfoImpl ( ) ; final List < QueryOption > options = query == null ? Collections . < QueryOption > emptyList ( ) : UriDecoder . splitAndDecodeOptions ( query ) ; for ( final QueryOption option : options ) { final String optionName = option . getName ( ) ; final QueryOption parsedOption = parseOption ( optionName , option . getText ( ) ) ; try { contextUriInfo . setQueryOption ( parsedOption == null ? option : parsedOption ) ; } catch ( final ODataRuntimeException e ) { throw new UriParserSyntaxException ( parsedOption instanceof SystemQueryOption ? ""Double system query option!"" : ""Alias already specified! Name: "" + optionName , e , parsedOption instanceof SystemQueryOption ? UriParserSyntaxException . MessageKeys . DOUBLE_SYSTEM_QUERY_OPTION : UriParserSyntaxException . MessageKeys . DUPLICATED_ALIAS , optionName ) ; } } EdmType contextType = null ; boolean contextIsCollection = false ; List < String > pathSegmentsDecoded = UriDecoder . splitAndDecodePath ( path ) ; int numberOfSegments = pathSegmentsDecoded . size ( ) ; if ( numberOfSegments > 1 && pathSegmentsDecoded . get ( 0 ) . isEmpty ( ) ) { pathSegmentsDecoded . remove ( 0 ) ; numberOfSegments -- ; } final String firstSegment = pathSegmentsDecoded . get ( 0 ) ; if ( firstSegment . isEmpty ( ) ) { ensureLastSegment ( firstSegment , 1 , numberOfSegments ) ; contextUriInfo . setKind ( UriInfoKind . service ) ; } else if ( firstSegment . equals ( ""$batch"" ) ) { ensureLastSegment ( firstSegment , 1 , numberOfSegments ) ; contextUriInfo . setKind ( UriInfoKind . batch ) ; } else if ( firstSegment . equals ( ""$metadata"" ) ) { ensureLastSegment ( firstSegment , 1 , numberOfSegments ) ; contextUriInfo . setKind ( UriInfoKind . metadata ) ; contextUriInfo . setFragment ( fragment ) ; } else if ( firstSegment . equals ( ""$all"" ) ) { ensureLastSegment ( firstSegment , 1 , numberOfSegments ) ; contextUriInfo . setKind ( UriInfoKind . all ) ; contextIsCollection = true ; } else if ( firstSegment . equals ( ""$entity"" ) ) { contextUriInfo . setKind ( UriInfoKind . entityId ) ; if ( numberOfSegments > 1 ) { final String typeCastSegment = pathSegmentsDecoded . get ( 1 ) ; ensureLastSegment ( typeCastSegment , 2 , numberOfSegments ) ; contextType = new ResourcePathParser ( edm , contextUriInfo . getAliasMap ( ) ) . parseDollarEntityTypeCast ( typeCastSegment ) ; contextUriInfo . setEntityTypeCast ( ( EdmEntityType ) contextType ) ; } contextIsCollection = false ; } else if ( firstSegment . startsWith ( ""$crossjoin"" ) ) { ensureLastSegment ( firstSegment , 1 , numberOfSegments ) ; contextUriInfo . setKind ( UriInfoKind . crossjoin ) ; final List < String > entitySetNames = new ResourcePathParser ( edm , contextUriInfo . getAliasMap ( ) ) . parseCrossjoinSegment ( firstSegment ) ; for ( final String name : entitySetNames ) { contextUriInfo . addEntitySetName ( name ) ; } contextIsCollection = true ; } else { contextUriInfo . setKind ( UriInfoKind . resource ) ; final ResourcePathParser resourcePathParser = new ResourcePathParser ( edm , contextUriInfo . getAliasMap ( ) ) ; int count = 0 ; UriResource lastSegment = null ; for ( final String pathSegment : pathSegmentsDecoded ) { count ++ ; final UriResource segment = resourcePathParser . parsePathSegment ( pathSegment , lastSegment ) ; if ( segment != null ) { if ( segment instanceof UriResourceCount || segment instanceof UriResourceRef || segment instanceof UriResourceValue ) { ensureLastSegment ( pathSegment , count , numberOfSegments ) ; } else if ( segment instanceof UriResourceAction || segment instanceof UriResourceFunction && ! ( ( UriResourceFunction ) segment ) . getFunction ( ) . isComposable ( ) ) { if ( count < numberOfSegments ) { throw new UriValidationException ( ""The segment of an action or of a non-composable function must be the last resource-path segment."" , UriValidationException . MessageKeys . UNALLOWED_RESOURCE_PATH , pathSegmentsDecoded . get ( count ) ) ; } lastSegment = segment ; } else if ( segment instanceof UriResourceStartingTypeFilterImpl ) { throw new UriParserSemanticException ( ""First resource-path segment must not be namespace-qualified."" , UriParserSemanticException . MessageKeys . NAMESPACE_NOT_ALLOWED_AT_FIRST_ELEMENT ) ; } else { lastSegment = segment ; } contextUriInfo . addResourcePart ( segment ) ; } } if ( lastSegment instanceof UriResourcePartTyped ) { final UriResourcePartTyped typed = ( UriResourcePartTyped ) lastSegment ; contextType = ParserHelper . getTypeInformation ( typed ) ; contextIsCollection = typed . isCollection ( ) ; } } if ( contextType instanceof EdmStructuredType && contextUriInfo . getApplyOption ( ) != null ) { contextType = new DynamicStructuredType ( ( EdmStructuredType ) contextType ) ; } parseApplyOption ( contextUriInfo . getApplyOption ( ) , contextType , contextUriInfo . getEntitySetNames ( ) , contextUriInfo . getAliasMap ( ) ) ; parseFilterOption ( contextUriInfo . getFilterOption ( ) , contextType , contextUriInfo . getEntitySetNames ( ) , contextUriInfo . getAliasMap ( ) ) ; parseOrderByOption ( contextUriInfo . getOrderByOption ( ) , contextType , contextUriInfo . getEntitySetNames ( ) , contextUriInfo . getAliasMap ( ) ) ; parseExpandOption ( contextUriInfo . getExpandOption ( ) , contextType , contextUriInfo . getKind ( ) == UriInfoKind . all , contextUriInfo . getEntitySetNames ( ) , contextUriInfo . getAliasMap ( ) ) ; parseSelectOption ( contextUriInfo . getSelectOption ( ) , contextType , contextIsCollection ) ; return contextUriInfo ; } private QueryOption parseOption ( final String optionName , final String optionValue ) throws UriParserException , UriValidationException { if ( optionName . startsWith ( DOLLAR ) ) { final SystemQueryOptionKind kind = SystemQueryOptionKind . get ( optionName ) ; if ( kind == null ) { throw new UriParserSyntaxException ( ""Unknown system query option!"" , UriParserSyntaxException . MessageKeys . UNKNOWN_SYSTEM_QUERY_OPTION , optionName ) ; } SystemQueryOptionImpl systemOption ; switch ( kind ) { case SEARCH : SearchOption searchOption = new SearchParser ( ) . parse ( optionValue ) ; SearchOptionImpl tmp = new SearchOptionImpl ( ) ; tmp . setSearchExpression ( searchOption . getSearchExpression ( ) ) ; systemOption = tmp ; break ; case FILTER : systemOption = new FilterOptionImpl ( ) ; break ; case COUNT : if ( optionValue . equals ( ""true"" ) || optionValue . equals ( ""false"" ) ) { systemOption = new CountOptionImpl ( ) . setValue ( Boolean . parseBoolean ( optionValue ) ) ; } else { throw new UriParserSyntaxException ( ""Illegal value of $count option!"" , UriParserSyntaxException . MessageKeys . WRONG_VALUE_FOR_SYSTEM_QUERY_OPTION , optionName , optionValue ) ; } break ; case ORDERBY : systemOption = new OrderByOptionImpl ( ) ; break ; case SKIP : systemOption = new SkipOptionImpl ( ) . setValue ( ParserHelper . parseNonNegativeInteger ( optionName , optionValue , true ) ) ; break ; case SKIPTOKEN : if ( optionValue . isEmpty ( ) ) { throw new UriParserSyntaxException ( ""Illegal value of $skiptoken option!"" , UriParserSyntaxException . MessageKeys . WRONG_VALUE_FOR_SYSTEM_QUERY_OPTION , optionName , optionValue ) ; } systemOption = new SkipTokenOptionImpl ( ) . setValue ( optionValue ) ; break ; case TOP : systemOption = new TopOptionImpl ( ) . setValue ( ParserHelper . parseNonNegativeInteger ( optionName , optionValue , true ) ) ; break ; case EXPAND : systemOption = new ExpandOptionImpl ( ) ; break ; case SELECT : systemOption = new SelectOptionImpl ( ) ; break ; case FORMAT : if ( optionValue . equalsIgnoreCase ( JSON ) || optionValue . equalsIgnoreCase ( XML ) || optionValue . equalsIgnoreCase ( ATOM ) || isFormatSyntaxValid ( optionValue ) ) { systemOption = new FormatOptionImpl ( ) . setFormat ( optionValue ) ; } else { throw new UriParserSyntaxException ( ""Illegal value of $format option!"" , UriParserSyntaxException . MessageKeys . WRONG_VALUE_FOR_SYSTEM_QUERY_OPTION_FORMAT , optionValue ) ; } break ; case ID : if ( optionValue . isEmpty ( ) ) { throw new UriParserSyntaxException ( ""Illegal value of $id option!"" , UriParserSyntaxException . MessageKeys . WRONG_VALUE_FOR_SYSTEM_QUERY_OPTION , optionName , optionValue ) ; } systemOption = new IdOptionImpl ( ) . setValue ( optionValue ) ; break ; case LEVELS : throw new UriParserSyntaxException ( ""System query option '$levels' is allowed only inside '$expand'!"" , UriParserSyntaxException . MessageKeys . SYSTEM_QUERY_OPTION_LEVELS_NOT_ALLOWED_HERE ) ; case APPLY : systemOption = new ApplyOptionImpl ( ) ; break ; default : throw new UriParserSyntaxException ( ""System query option '"" + kind + ""' is not known!"" , UriParserSyntaxException . MessageKeys . UNKNOWN_SYSTEM_QUERY_OPTION , optionName ) ; } systemOption . setText ( optionValue ) ; return systemOption ; } else if ( optionName . startsWith ( AT ) ) { return new AliasQueryOptionImpl ( ) . setName ( optionName ) . setText ( NULL . equals ( optionValue ) ? null : optionValue ) ; } else { return null ; } } private void parseFilterOption ( FilterOption filterOption , final EdmType contextType , final List < String > entitySetNames , final Map < String , AliasQueryOption > aliases ) throws UriParserException , UriValidationException { if ( filterOption != null ) { final String optionValue = filterOption . getText ( ) ; UriTokenizer filterTokenizer = new UriTokenizer ( optionValue ) ; ( ( FilterOptionImpl ) filterOption ) . setExpression ( new FilterParser ( edm , odata ) . parse ( filterTokenizer , contextType , entitySetNames , aliases ) . getExpression ( ) ) ; checkOptionEOF ( filterTokenizer , filterOption . getName ( ) , optionValue ) ; } } private void parseOrderByOption ( OrderByOption orderByOption , final EdmType contextType , final List < String > entitySetNames , final Map < String , AliasQueryOption > aliases ) throws UriParserException , UriValidationException { if ( orderByOption != null ) { final String optionValue = orderByOption . getText ( ) ; UriTokenizer orderByTokenizer = new UriTokenizer ( optionValue ) ; final OrderByOption option = new OrderByParser ( edm , odata ) . parse ( orderByTokenizer , contextType instanceof EdmStructuredType ? ( EdmStructuredType ) contextType : null , entitySetNames , aliases ) ; checkOptionEOF ( orderByTokenizer , orderByOption . getName ( ) , optionValue ) ; for ( final OrderByItem item : option . getOrders ( ) ) { ( ( OrderByOptionImpl ) orderByOption ) . addOrder ( item ) ; } } } private void parseExpandOption ( ExpandOption expandOption , final EdmType contextType , final boolean isAll , final List < String > entitySetNames , final Map < String , AliasQueryOption > aliases ) throws UriParserException , UriValidationException { if ( expandOption != null ) { if ( ! ( contextType instanceof EdmStructuredType || isAll || ( entitySetNames != null && ! entitySetNames . isEmpty ( ) ) ) ) { throw new UriValidationException ( ""Expand is only allowed on structured types!"" , UriValidationException . MessageKeys . SYSTEM_QUERY_OPTION_NOT_ALLOWED , expandOption . getName ( ) ) ; } final String optionValue = expandOption . getText ( ) ; UriTokenizer expandTokenizer = new UriTokenizer ( optionValue ) ; final ExpandOption option = new ExpandParser ( edm , odata , aliases , entitySetNames ) . parse ( expandTokenizer , contextType instanceof EdmStructuredType ? ( EdmStructuredType ) contextType : null ) ; checkOptionEOF ( expandTokenizer , expandOption . getName ( ) , optionValue ) ; for ( final ExpandItem item : option . getExpandItems ( ) ) { ( ( ExpandOptionImpl ) expandOption ) . addExpandItem ( item ) ; } } } private void parseSelectOption ( SelectOption selectOption , final EdmType contextType , final boolean contextIsCollection ) throws UriParserException , UriValidationException { if ( selectOption != null ) { final String optionValue = selectOption . getText ( ) ; UriTokenizer selectTokenizer = new UriTokenizer ( optionValue ) ; ( ( SelectOptionImpl ) selectOption ) . setSelectItems ( new SelectParser ( edm ) . parse ( selectTokenizer , contextType instanceof EdmStructuredType ? ( EdmStructuredType ) contextType : null , contextIsCollection ) . getSelectItems ( ) ) ; checkOptionEOF ( selectTokenizer , selectOption . getName ( ) , optionValue ) ; } } private void parseApplyOption ( ApplyOption applyOption , EdmType contextType , final List < String > entitySetNames , final Map < String , AliasQueryOption > aliases ) throws UriParserException , UriValidationException { if ( applyOption != null ) { final String optionValue = applyOption . getText ( ) ; UriTokenizer applyTokenizer = new UriTokenizer ( optionValue ) ; final ApplyOption option = new ApplyParser ( edm , odata ) . parse ( applyTokenizer , contextType instanceof EdmStructuredType ? ( EdmStructuredType ) contextType : null , entitySetNames , aliases ) ; checkOptionEOF ( applyTokenizer , applyOption . getName ( ) , optionValue ) ; for ( final ApplyItem item : option . getApplyItems ( ) ) { ( ( ApplyOptionImpl ) applyOption ) . add ( item ) ; } } } private void ensureLastSegment ( final String segment , final int pos , final int size ) throws UriParserSyntaxException { if ( pos < size ) { throw new UriParserSyntaxException ( segment + "" must be the last segment."" , UriParserSyntaxException . MessageKeys . MUST_BE_LAST_SEGMENT , segment ) ; } } private boolean isFormatSyntaxValid ( final String value ) { final int index = value . indexOf ( '/' ) ; return index > 0 && index < value . length ( ) - 1 && index == value . lastIndexOf ( '/' ) ; } private void checkOptionEOF ( UriTokenizer tokenizer , final String optionName , final String optionValue ) throws UriParserException { if ( ! tokenizer . next ( TokenKind . EOF ) ) { throw new UriParserSyntaxException ( ""Illegal value of '"" + optionName + ""' option!"" , UriParserSyntaxException . MessageKeys . WRONG_VALUE_FOR_SYSTEM_QUERY_OPTION , optionName , optionValue ) ; } } }",Smelly
"public class UnknownElement extends Task { private String elementName ; private String namespace = """" ; private String qname ; private Object realThing ; private List children = null ; private boolean presetDefed = false ; public UnknownElement ( String elementName ) { this . elementName = elementName ; } public List getChildren ( ) { return children ; } public String getTag ( ) { return elementName ; } public String getNamespace ( ) { return namespace ; } public void setNamespace ( String namespace ) { if ( namespace . equals ( ProjectHelper . ANT_CURRENT_URI ) ) { ComponentHelper helper = ComponentHelper . getComponentHelper ( getProject ( ) ) ; namespace = helper . getCurrentAntlibUri ( ) ; } this . namespace = namespace == null ? """" : namespace ; } public String getQName ( ) { return qname ; } public void setQName ( String qname ) { this . qname = qname ; } public RuntimeConfigurable getWrapper ( ) { return super . getWrapper ( ) ; } public void maybeConfigure ( ) throws BuildException { if ( realThing != null ) { return ; } configure ( makeObject ( this , getWrapper ( ) ) ) ; } public void configure ( Object realObject ) { realThing = realObject ; getWrapper ( ) . setProxy ( realThing ) ; Task task = null ; if ( realThing instanceof Task ) { task = ( Task ) realThing ; task . setRuntimeConfigurableWrapper ( getWrapper ( ) ) ; if ( getWrapper ( ) . getId ( ) != null ) { this . getOwningTarget ( ) . replaceChild ( this , ( Task ) realThing ) ; } } if ( task != null ) { task . maybeConfigure ( ) ; } else { getWrapper ( ) . maybeConfigure ( getProject ( ) ) ; } handleChildren ( realThing , getWrapper ( ) ) ; } protected void handleOutput ( String output ) { if ( realThing instanceof Task ) { ( ( Task ) realThing ) . handleOutput ( output ) ; } else { super . handleOutput ( output ) ; } } protected int handleInput ( byte [ ] buffer , int offset , int length ) throws IOException { if ( realThing instanceof Task ) { return ( ( Task ) realThing ) . handleInput ( buffer , offset , length ) ; } else { return super . handleInput ( buffer , offset , length ) ; } } protected void handleFlush ( String output ) { if ( realThing instanceof Task ) { ( ( Task ) realThing ) . handleFlush ( output ) ; } else { super . handleFlush ( output ) ; } } protected void handleErrorOutput ( String output ) { if ( realThing instanceof Task ) { ( ( Task ) realThing ) . handleErrorOutput ( output ) ; } else { super . handleErrorOutput ( output ) ; } } protected void handleErrorFlush ( String output ) { if ( realThing instanceof Task ) { ( ( Task ) realThing ) . handleErrorOutput ( output ) ; } else { super . handleErrorOutput ( output ) ; } } public void execute ( ) { if ( realThing == null ) { throw new BuildException ( ""Could not create task of type: "" + elementName , getLocation ( ) ) ; } if ( realThing instanceof Task ) { ( ( Task ) realThing ) . execute ( ) ; } realThing = null ; getWrapper ( ) . setProxy ( null ) ; } public void addChild ( UnknownElement child ) { if ( children == null ) { children = new ArrayList ( ) ; } children . add ( child ) ; } protected void handleChildren ( Object parent , RuntimeConfigurable parentWrapper ) throws BuildException { if ( parent instanceof TypeAdapter ) { parent = ( ( TypeAdapter ) parent ) . getProxy ( ) ; } String parentUri = getNamespace ( ) ; Class parentClass = parent . getClass ( ) ; IntrospectionHelper ih = IntrospectionHelper . getHelper ( getProject ( ) , parentClass ) ; if ( children != null ) { Iterator it = children . iterator ( ) ; for ( int i = 0 ; it . hasNext ( ) ; i ++ ) { RuntimeConfigurable childWrapper = parentWrapper . getChild ( i ) ; UnknownElement child = ( UnknownElement ) it . next ( ) ; try { if ( ! handleChild ( parentUri , ih , parent , child , childWrapper ) ) { if ( ! ( parent instanceof TaskContainer ) ) { ih . throwNotSupported ( getProject ( ) , parent , child . getTag ( ) ) ; } else { TaskContainer container = ( TaskContainer ) parent ; container . addTask ( child ) ; } } } catch ( UnsupportedElementException ex ) { throw new BuildException ( parentWrapper . getElementTag ( ) + "" doesn't support the nested \"""" + ex . getElement ( ) + ""\"" element."" , ex ) ; } } } } protected String getComponentName ( ) { return ProjectHelper . genComponentName ( getNamespace ( ) , getTag ( ) ) ; } public void applyPreSet ( UnknownElement u ) { if ( presetDefed ) { return ; } getWrapper ( ) . applyPreSet ( u . getWrapper ( ) ) ; if ( u . children != null ) { List newChildren = new ArrayList ( ) ; newChildren . addAll ( u . children ) ; if ( children != null ) { newChildren . addAll ( children ) ; } children = newChildren ; } presetDefed = true ; } protected Object makeObject ( UnknownElement ue , RuntimeConfigurable w ) { ComponentHelper helper = ComponentHelper . getComponentHelper ( getProject ( ) ) ; String name = ue . getComponentName ( ) ; Object o = helper . createComponent ( ue , ue . getNamespace ( ) , name ) ; if ( o == null ) { throw getNotFoundException ( ""task or type"" , name ) ; } if ( o instanceof PreSetDef . PreSetDefinition ) { PreSetDef . PreSetDefinition def = ( PreSetDef . PreSetDefinition ) o ; o = def . createObject ( ue . getProject ( ) ) ; if ( o == null ) { throw getNotFoundException ( ""preset "" + name , def . getPreSets ( ) . getComponentName ( ) ) ; } ue . applyPreSet ( def . getPreSets ( ) ) ; if ( o instanceof Task ) { Task task = ( Task ) o ; task . setTaskType ( ue . getTaskType ( ) ) ; task . setTaskName ( ue . getTaskName ( ) ) ; task . init ( ) ; } } if ( o instanceof UnknownElement ) { o = ( ( UnknownElement ) o ) . makeObject ( ( UnknownElement ) o , w ) ; } if ( o instanceof Task ) { ( ( Task ) o ) . setOwningTarget ( getOwningTarget ( ) ) ; } if ( o instanceof ProjectComponent ) { ( ( ProjectComponent ) o ) . setLocation ( getLocation ( ) ) ; } return o ; } protected Task makeTask ( UnknownElement ue , RuntimeConfigurable w ) { Task task = getProject ( ) . createTask ( ue . getTag ( ) ) ; if ( task != null ) { task . setLocation ( getLocation ( ) ) ; task . setOwningTarget ( getOwningTarget ( ) ) ; task . init ( ) ; } return task ; } protected BuildException getNotFoundException ( String what , String name ) { ComponentHelper helper = ComponentHelper . getComponentHelper ( getProject ( ) ) ; String msg = helper . diagnoseCreationFailure ( name , what ) ; return new BuildException ( msg , getLocation ( ) ) ; } public String getTaskName ( ) { return realThing == null || ! ( realThing instanceof Task ) ? super . getTaskName ( ) : ( ( Task ) realThing ) . getTaskName ( ) ; } public Task getTask ( ) { if ( realThing instanceof Task ) { return ( Task ) realThing ; } return null ; } public Object getRealThing ( ) { return realThing ; } public void setRealThing ( Object realThing ) { this . realThing = realThing ; } private boolean handleChild ( String parentUri , IntrospectionHelper ih , Object parent , UnknownElement child , RuntimeConfigurable childWrapper ) { String childName = ProjectHelper . genComponentName ( child . getNamespace ( ) , child . getTag ( ) ) ; if ( ih . supportsNestedElement ( parentUri , childName ) ) { IntrospectionHelper . Creator creator = ih . getElementCreator ( getProject ( ) , parentUri , parent , childName , child ) ; creator . setPolyType ( childWrapper . getPolyType ( ) ) ; Object realChild = creator . create ( ) ; if ( realChild instanceof PreSetDef . PreSetDefinition ) { PreSetDef . PreSetDefinition def = ( PreSetDef . PreSetDefinition ) realChild ; realChild = creator . getRealObject ( ) ; child . applyPreSet ( def . getPreSets ( ) ) ; } childWrapper . setCreator ( creator ) ; childWrapper . setProxy ( realChild ) ; if ( realChild instanceof Task ) { Task childTask = ( Task ) realChild ; childTask . setRuntimeConfigurableWrapper ( childWrapper ) ; childTask . setTaskName ( childName ) ; childTask . setTaskType ( childName ) ; } if ( realChild instanceof ProjectComponent ) { ( ( ProjectComponent ) realChild ) . setLocation ( child . getLocation ( ) ) ; } childWrapper . maybeConfigure ( getProject ( ) ) ; child . handleChildren ( realChild , childWrapper ) ; creator . store ( ) ; return true ; } return false ; } public boolean similar ( Object obj ) { if ( obj == null ) { return false ; } if ( ! getClass ( ) . getName ( ) . equals ( obj . getClass ( ) . getName ( ) ) ) { return false ; } UnknownElement other = ( UnknownElement ) obj ; if ( ! equalsString ( elementName , other . elementName ) ) { return false ; } if ( ! namespace . equals ( other . namespace ) ) { return false ; } if ( ! qname . equals ( other . qname ) ) { return false ; } if ( ! getWrapper ( ) . getAttributeMap ( ) . equals ( other . getWrapper ( ) . getAttributeMap ( ) ) ) { return false ; } if ( ! getWrapper ( ) . getText ( ) . toString ( ) . equals ( other . getWrapper ( ) . getText ( ) . toString ( ) ) ) { return false ; } if ( children == null || children . size ( ) == 0 ) { return other . children == null || other . children . size ( ) == 0 ; } if ( other . children == null ) { return false ; } if ( children . size ( ) != other . children . size ( ) ) { return false ; } for ( int i = 0 ; i < children . size ( ) ; ++ i ) { UnknownElement child = ( UnknownElement ) children . get ( i ) ; if ( ! child . similar ( other . children . get ( i ) ) ) { return false ; } } return true ; } private static boolean equalsString ( String a , String b ) { return ( a == null ) ? ( b == null ) : a . equals ( b ) ; } public UnknownElement copy ( Project newProject ) { UnknownElement ret = new UnknownElement ( getTag ( ) ) ; ret . setNamespace ( getNamespace ( ) ) ; ret . setProject ( newProject ) ; ret . setQName ( getQName ( ) ) ; ret . setTaskType ( getTaskType ( ) ) ; ret . setTaskName ( getTaskName ( ) ) ; ret . setLocation ( getLocation ( ) ) ; if ( getOwningTarget ( ) == null ) { Target t = new Target ( ) ; t . setProject ( getProject ( ) ) ; ret . setOwningTarget ( t ) ; } else { ret . setOwningTarget ( getOwningTarget ( ) ) ; } RuntimeConfigurable copyRC = new RuntimeConfigurable ( ret , getTaskName ( ) ) ; copyRC . setPolyType ( getWrapper ( ) . getPolyType ( ) ) ; Map m = getWrapper ( ) . getAttributeMap ( ) ; for ( Iterator i = m . entrySet ( ) . iterator ( ) ; i . hasNext ( ) ; ) { Map . Entry entry = ( Map . Entry ) i . next ( ) ; copyRC . setAttribute ( ( String ) entry . getKey ( ) , ( String ) entry . getValue ( ) ) ; } copyRC . addText ( getWrapper ( ) . getText ( ) . toString ( ) ) ; for ( Enumeration e = getWrapper ( ) . getChildren ( ) ; e . hasMoreElements ( ) ; ) { RuntimeConfigurable r = ( RuntimeConfigurable ) e . nextElement ( ) ; UnknownElement ueChild = ( UnknownElement ) r . getProxy ( ) ; UnknownElement copyChild = ueChild . copy ( newProject ) ; copyRC . addChild ( copyChild . getWrapper ( ) ) ; ret . addChild ( copyChild ) ; } return ret ; } }",Smelly
"public class XdrString extends XdrSimple < String > { private int padding ; public XdrString ( ) { this ( ( String ) null ) ; } public XdrString ( String value ) { super ( XdrDataType . STRING , value ) ; } @ Override protected void toBytes ( ) { if ( getValue ( ) != null ) { byte [ ] bytes = new byte [ encodingBodyLength ( ) ] ; int length = bytes . length - padding - 4 ; bytes [ 0 ] = ( byte ) ( length > > 24 ) ; bytes [ 1 ] = ( byte ) ( length > > 16 ) ; bytes [ 2 ] = ( byte ) ( length > > 8 ) ; bytes [ 3 ] = ( byte ) ( length ) ; System . arraycopy ( getValue ( ) . getBytes ( ) , 0 , bytes , 4 , length ) ; setBytes ( bytes ) ; } } @ Override protected int encodingBodyLength ( ) { if ( getValue ( ) != null ) { padding = ( 4 - getValue ( ) . length ( ) % 4 ) % 4 ; return getValue ( ) . length ( ) + padding + 4 ; } return 0 ; } protected void toValue ( ) throws IOException { byte [ ] bytes = getBytes ( ) ; byte [ ] header = new byte [ 4 ] ; System . arraycopy ( bytes , 0 , header , 0 , 4 ) ; int stringLen = ByteBuffer . wrap ( header ) . getInt ( ) ; int paddingBytes = ( 4 - ( stringLen % 4 ) ) % 4 ; validatePaddingBytes ( paddingBytes ) ; setPadding ( paddingBytes ) ; if ( bytes . length != stringLen + 4 + paddingBytes ) { int totalLength = stringLen + paddingBytes + 4 ; byte [ ] stringBytes = ByteBuffer . allocate ( totalLength ) . put ( getBytes ( ) , 0 , totalLength ) . array ( ) ; setBytes ( stringBytes ) ; } byte [ ] content = new byte [ stringLen ] ; if ( bytes . length > 1 ) { System . arraycopy ( bytes , 4 , content , 0 , stringLen ) ; } setValue ( new String ( content , StandardCharsets . US_ASCII ) ) ; } public void setPadding ( int padding ) { this . padding = padding ; } public int getPadding ( ) { return padding ; } public static String fromUTF8ByteArray ( byte [ ] bytes ) { int i = 0 ; int length = 0 ; while ( i < bytes . length ) { length ++ ; if ( ( bytes [ i ] & 0xf0 ) == 0xf0 ) { length ++ ; i += 4 ; } else if ( ( bytes [ i ] & 0xe0 ) == 0xe0 ) { i += 3 ; } else if ( ( bytes [ i ] & 0xc0 ) == 0xc0 ) { i += 2 ; } else { i += 1 ; } } char [ ] cs = new char [ length ] ; i = 0 ; length = 0 ; while ( i < bytes . length ) { char ch ; if ( ( bytes [ i ] & 0xf0 ) == 0xf0 ) { int codePoint = ( ( bytes [ i ] & 0x03 ) < < 18 ) | ( ( bytes [ i + 1 ] & 0x3F ) < < 12 ) | ( ( bytes [ i + 2 ] & 0x3F ) < < 6 ) | ( bytes [ i + 3 ] & 0x3F ) ; int u = codePoint - 0x10000 ; char w1 = ( char ) ( 0xD800 | ( u > > 10 ) ) ; char w2 = ( char ) ( 0xDC00 | ( u & 0x3FF ) ) ; cs [ length ++ ] = w1 ; ch = w2 ; i += 4 ; } else if ( ( bytes [ i ] & 0xe0 ) == 0xe0 ) { ch = ( char ) ( ( ( bytes [ i ] & 0x0f ) < < 12 ) | ( ( bytes [ i + 1 ] & 0x3f ) < < 6 ) | ( bytes [ i + 2 ] & 0x3f ) ) ; i += 3 ; } else if ( ( bytes [ i ] & 0xd0 ) == 0xd0 ) { ch = ( char ) ( ( ( bytes [ i ] & 0x1f ) < < 6 ) | ( bytes [ i + 1 ] & 0x3f ) ) ; i += 2 ; } else if ( ( bytes [ i ] & 0xc0 ) == 0xc0 ) { ch = ( char ) ( ( ( bytes [ i ] & 0x1f ) < < 6 ) | ( bytes [ i + 1 ] & 0x3f ) ) ; i += 2 ; } else { ch = ( char ) ( bytes [ i ] & 0xff ) ; i += 1 ; } cs [ length ++ ] = ch ; } return new String ( cs ) ; } public static byte [ ] toUTF8ByteArray ( String string ) { return toUTF8ByteArray ( string . toCharArray ( ) ) ; } public static byte [ ] toUTF8ByteArray ( char [ ] string ) { ByteArrayOutputStream bOut = new ByteArrayOutputStream ( ) ; try { toUTF8ByteArray ( string , bOut ) ; } catch ( IOException e ) { throw new IllegalStateException ( ""cannot encode string to byte array!"" ) ; } return bOut . toByteArray ( ) ; } public static void toUTF8ByteArray ( char [ ] string , OutputStream sOut ) throws IOException { char [ ] c = string ; int i = 0 ; while ( i < c . length ) { char ch = c [ i ] ; if ( ch < 0x0080 ) { sOut . write ( ch ) ; } else if ( ch < 0x0800 ) { sOut . write ( 0xc0 | ( ch > > 6 ) ) ; sOut . write ( 0x80 | ( ch & 0x3f ) ) ; } else if ( ch >= 0xD800 && ch <= 0xDFFF ) { if ( i + 1 >= c . length ) { throw new IllegalStateException ( ""invalid UTF-16 codepoint"" ) ; } char w1 = ch ; ch = c [ ++ i ] ; char w2 = ch ; if ( w1 > 0xDBFF ) { throw new IllegalStateException ( ""invalid UTF-16 codepoint"" ) ; } int codePoint = ( ( w1 & 0x03FF ) < < 10 ) | ( w2 & 0x03FF ) + 0x10000 ; sOut . write ( 0xf0 | ( codePoint > > 18 ) ) ; sOut . write ( 0x80 | ( ( codePoint > > 12 ) & 0x3F ) ) ; sOut . write ( 0x80 | ( ( codePoint > > 6 ) & 0x3F ) ) ; sOut . write ( 0x80 | ( codePoint & 0x3F ) ) ; } else { sOut . write ( 0xe0 | ( ch > > 12 ) ) ; sOut . write ( 0x80 | ( ( ch > > 6 ) & 0x3F ) ) ; sOut . write ( 0x80 | ( ch & 0x3F ) ) ; } i ++ ; } } public static String toUpperCase ( String string ) { boolean changed = false ; char [ ] chars = string . toCharArray ( ) ; for ( int i = 0 ; i != chars . length ; i ++ ) { char ch = chars [ i ] ; if ( 'a' <= ch && 'z' >= ch ) { changed = true ; chars [ i ] = ( char ) ( ch - 'a' + 'A' ) ; } } if ( changed ) { return new String ( chars ) ; } return string ; } public static String toLowerCase ( String string ) { boolean changed = false ; char [ ] chars = string . toCharArray ( ) ; for ( int i = 0 ; i != chars . length ; i ++ ) { char ch = chars [ i ] ; if ( 'A' <= ch && 'Z' >= ch ) { changed = true ; chars [ i ] = ( char ) ( ch - 'A' + 'a' ) ; } } if ( changed ) { return new String ( chars ) ; } return string ; } public static byte [ ] toByteArray ( char [ ] chars ) { byte [ ] bytes = new byte [ chars . length ] ; for ( int i = 0 ; i != bytes . length ; i ++ ) { bytes [ i ] = ( byte ) chars [ i ] ; } return bytes ; } public static byte [ ] toByteArray ( String string ) { byte [ ] bytes = new byte [ string . length ( ) ] ; for ( int i = 0 ; i != bytes . length ; i ++ ) { char ch = string . charAt ( i ) ; bytes [ i ] = ( byte ) ch ; } return bytes ; } public static String fromByteArray ( byte [ ] bytes ) { return new String ( asCharArray ( bytes ) ) ; } public static char [ ] asCharArray ( byte [ ] bytes ) { char [ ] chars = new char [ bytes . length ] ; for ( int i = 0 ; i != chars . length ; i ++ ) { chars [ i ] = ( char ) ( bytes [ i ] & 0xff ) ; } return chars ; } public static String [ ] split ( String input , char delimiter ) { List < String > v = new ArrayList < String > ( ) ; boolean moreTokens = true ; String subString ; while ( moreTokens ) { int tokenLocation = input . indexOf ( delimiter ) ; if ( tokenLocation > 0 ) { subString = input . substring ( 0 , tokenLocation ) ; v . add ( subString ) ; input = input . substring ( tokenLocation + 1 ) ; } else { moreTokens = false ; v . add ( input ) ; } } return v . toArray ( new String [ v . size ( ) ] ) ; } private void validatePaddingBytes ( int paddingBytes ) throws IOException { if ( paddingBytes < 0 || paddingBytes > 3 ) { throw new IOException ( ""Bad padding number: "" + paddingBytes + "", should be in [0, 3]"" ) ; } } }",Smelly
"public class StrConcat extends BaseBuiltin { @ Override public String getName ( ) { return ""strConcat"" ; } @ Override public int getArgLength ( ) { return 0 ; } @ Override public boolean bodyCall ( Node [ ] args , int length , RuleContext context ) { if ( length < 1 ) throw new BuiltinException ( this , context , ""Must have at least 1 argument to "" + getName ( ) ) ; StringBuilder buff = new StringBuilder ( ) ; for ( int i = 0 ; i < length - 1 ; i ++ ) { buff . append ( lex ( getArg ( i , args , context ) , context ) ) ; } Node result = NodeFactory . createLiteral ( buff . toString ( ) ) ; return context . getEnv ( ) . bind ( args [ length - 1 ] , result ) ; } protected String lex ( Node n , RuleContext context ) { if ( n . isBlank ( ) ) { return n . getBlankNodeLabel ( ) ; } else if ( n . isURI ( ) ) { return n . getURI ( ) ; } else if ( n . isLiteral ( ) ) { return n . getLiteralLexicalForm ( ) ; } else { throw new BuiltinException ( this , context , ""Illegal node type: "" + n ) ; } } }",No
 private static class BooleanColumnStatsDataStandardSchemeFactory implements SchemeFactory { public BooleanColumnStatsDataStandardScheme getScheme ( ) { return new BooleanColumnStatsDataStandardScheme ( ) ; } ,No
 public static class Element implements TaskContainer { private List unknownElements = new ArrayList ( ) ; public void addTask ( Task nestedTask ) { unknownElements . add ( nestedTask ) ; } public List getUnknownElements ( ) { return unknownElements ; } ,Smelly
"public class MAPCodecTest extends Assert { private MAPCodec codec ; private IMocksControl control ; private QName [ ] expectedNames ; private Object [ ] expectedValues ; private String expectedNamespaceURI ; private Map < String , List < String > > mimeHeaders ; private Exchange correlatedExchange ; private boolean expectRelatesTo ; private String nonReplyRelationship ; private boolean expectFaultTo ; @ Before public void setUp ( ) { codec = new MAPCodec ( ) ; control = EasyMock . createNiceControl ( ) ; } @ After public void tearDown ( ) throws Exception { expectedNames = null ; expectedValues = null ; expectedNamespaceURI = null ; mimeHeaders = null ; correlatedExchange = null ; ContextUtils . setJAXBContext ( null ) ; nonReplyRelationship = null ; } @ Test public void testGetHeaders ( ) throws Exception { Set < QName > headers = codec . getUnderstoodHeaders ( ) ; assertTrue ( ""expected From header"" , headers . contains ( Names . WSA_FROM_QNAME ) ) ; assertTrue ( ""expected To header"" , headers . contains ( Names . WSA_TO_QNAME ) ) ; assertTrue ( ""expected ReplyTo header"" , headers . contains ( Names . WSA_REPLYTO_QNAME ) ) ; assertTrue ( ""expected FaultTo header"" , headers . contains ( Names . WSA_FAULTTO_QNAME ) ) ; assertTrue ( ""expected Action header"" , headers . contains ( Names . WSA_ACTION_QNAME ) ) ; assertTrue ( ""expected MessageID header"" , headers . contains ( Names . WSA_MESSAGEID_QNAME ) ) ; } @ Test public void testRequestorInboundNonNative200403 ( ) throws Exception { String uri = VersionTransformer . Names200403 . WSA_NAMESPACE_NAME ; SoapMessage message = setUpMessage ( true , false , false , false , uri ) ; codec . handleMessage ( message ) ; control . verify ( ) ; verifyMessage ( message , true , false , false ) ; } @ Test public void testResponderInboundNonNative200403 ( ) throws Exception { String uri = VersionTransformer . Names200403 . WSA_NAMESPACE_NAME ; SoapMessage message = setUpMessage ( false , false , false , false , uri ) ; codec . handleMessage ( message ) ; control . verify ( ) ; verifyMessage ( message , false , false , false ) ; } @ Test public void testRequestorOutboundNonNative200403 ( ) throws Exception { String uri = VersionTransformer . Names200403 . WSA_NAMESPACE_NAME ; SoapMessage message = setUpMessage ( true , true , false , false , uri ) ; codec . handleMessage ( message ) ; control . verify ( ) ; verifyMessage ( message , true , true , false ) ; } @ Test public void testResponderOutboundNonNative200403 ( ) throws Exception { String uri = VersionTransformer . Names200403 . WSA_NAMESPACE_NAME ; SoapMessage message = setUpMessage ( false , true , false , false , uri ) ; codec . handleMessage ( message ) ; control . verify ( ) ; verifyMessage ( message , false , true , false ) ; } public void testRequestorOutbound ( ) throws Exception { SoapMessage message = setUpMessage ( true , true ) ; codec . handleMessage ( message ) ; control . verify ( ) ; verifyMessage ( message , true , true , true ) ; } @ Test public void testRequestorOutboundPreExistingSOAPAction ( ) throws Exception { SoapMessage message = setUpMessage ( true , true , false , true ) ; codec . handleMessage ( message ) ; verifyAction ( ) ; control . verify ( ) ; verifyMessage ( message , true , true , true ) ; } @ Test public void testRequestorOutboundNonNative ( ) throws Exception { String uri = VersionTransformer . Names200408 . WSA_NAMESPACE_NAME ; SoapMessage message = setUpMessage ( true , true , false , false , uri ) ; codec . handleMessage ( message ) ; control . verify ( ) ; verifyMessage ( message , true , true , false ) ; } @ Test public void testResponderInbound ( ) throws Exception { SoapMessage message = setUpMessage ( false , false ) ; codec . handleMessage ( message ) ; control . verify ( ) ; verifyMessage ( message , false , false , true ) ; } @ Test public void testResponderOutbound ( ) throws Exception { SoapMessage message = setUpMessage ( false , true ) ; codec . handleMessage ( message ) ; control . verify ( ) ; verifyMessage ( message , false , true , true ) ; } @ Test public void testResponderInboundWithRelatesTo ( ) throws Exception { SoapMessage message = setUpMessage ( false , false , false , false , Boolean . TRUE , Names . WSA_NAMESPACE_NAME ) ; for ( String key : codec . uncorrelatedExchanges . keySet ( ) ) { codec . uncorrelatedExchanges . remove ( key ) ; } codec . handleMessage ( message ) ; control . verify ( ) ; verifyMessage ( message , false , false , false ) ; } @ Test public void testResponderInboundNonNative ( ) throws Exception { String uri = VersionTransformer . Names200408 . WSA_NAMESPACE_NAME ; SoapMessage message = setUpMessage ( false , false , false , false , uri ) ; codec . handleMessage ( message ) ; control . verify ( ) ; verifyMessage ( message , false , false , false ) ; } @ Test public void testResponderOutboundInvalidMAP ( ) throws Exception { SoapMessage message = setUpMessage ( false , true , true ) ; try { codec . handleMessage ( message ) ; fail ( ""expected SOAPFaultException on invalid MAP"" ) ; } catch ( SoapFault sfe ) { assertEquals ( ""unexpected fault string"" , ""Duplicate Message ID urn:uuid:12345"" , sfe . getMessage ( ) ) ; } control . verify ( ) ; verifyMessage ( message , false , true , true ) ; } @ Test public void testResponderOutboundPreExistingSOAPAction ( ) throws Exception { SoapMessage message = setUpMessage ( false , true , false , true ) ; codec . handleMessage ( message ) ; verifyAction ( ) ; control . verify ( ) ; verifyMessage ( message , false , true , true ) ; } @ Test public void testResponderOutboundNonNative ( ) throws Exception { String uri = VersionTransformer . Names200408 . WSA_NAMESPACE_NAME ; SoapMessage message = setUpMessage ( false , true , false , false , uri ) ; codec . handleMessage ( message ) ; control . verify ( ) ; verifyMessage ( message , false , true , false ) ; } @ Test public void testRequestorInbound ( ) throws Exception { SoapMessage message = setUpMessage ( true , false ) ; codec . handleMessage ( message ) ; control . verify ( ) ; verifyMessage ( message , true , false , true ) ; } @ Test public void testRequestorInboundNonNative ( ) throws Exception { String uri = VersionTransformer . Names200408 . WSA_NAMESPACE_NAME ; SoapMessage message = setUpMessage ( true , false , false , false , uri ) ; codec . handleMessage ( message ) ; control . verify ( ) ; verifyMessage ( message , true , false , false ) ; } @ Test public void testRequestorInboundNonReply ( ) throws Exception { nonReplyRelationship = ""wsat:correlatedOneway"" ; SoapMessage message = setUpMessage ( true , false ) ; codec . handleMessage ( message ) ; control . verify ( ) ; verifyMessage ( message , true , false , true ) ; } @ Test public void testRequestorInboundNonNativeNonReply ( ) throws Exception { nonReplyRelationship = ""wsat:correlatedOneway"" ; String uri = VersionTransformer . Names200408 . WSA_NAMESPACE_NAME ; SoapMessage message = setUpMessage ( true , false , false , false , uri ) ; codec . handleMessage ( message ) ; control . verify ( ) ; verifyMessage ( message , true , false , false ) ; } private SoapMessage setUpMessage ( boolean requestor , boolean outbound ) throws Exception { return setUpMessage ( requestor , outbound , false ) ; } private SoapMessage setUpMessage ( boolean requestor , boolean outbound , boolean invalidMAP ) throws Exception { return setUpMessage ( requestor , outbound , invalidMAP , false ) ; } private SoapMessage setUpMessage ( boolean requestor , boolean outbound , boolean invalidMAP , boolean preExistingSOAPAction ) throws Exception { return setUpMessage ( requestor , outbound , invalidMAP , preExistingSOAPAction , Names . WSA_NAMESPACE_NAME ) ; } private SoapMessage setUpMessage ( boolean requestor , boolean outbound , boolean invalidMAP , boolean preExistingSOAPAction , String exposeAs ) throws Exception { return setUpMessage ( requestor , outbound , invalidMAP , preExistingSOAPAction , null , exposeAs ) ; } private SoapMessage setUpMessage ( boolean requestor , boolean outbound , boolean invalidMAP , boolean preExistingSOAPAction , Boolean generateRelatesTo , String exposeAs ) throws Exception { SoapMessage message = new SoapMessage ( new MessageImpl ( ) ) ; setUpOutbound ( message , outbound ) ; expectRelatesTo = generateRelatesTo != null ? generateRelatesTo : ( requestor && ! outbound ) || ( ! requestor && outbound ) ; message . put ( REQUESTOR_ROLE , Boolean . valueOf ( requestor ) ) ; String mapProperty = getMAPProperty ( requestor , outbound ) ; AddressingPropertiesImpl maps = getMAPs ( requestor , outbound , exposeAs ) ; final Element header = control . createMock ( Element . class ) ; codec . setHeaderFactory ( new MAPCodec . HeaderFactory ( ) { public Element getHeader ( SoapVersion version ) { return header ; } } ) ; List < Header > headers = message . getHeaders ( ) ; JAXBContext jaxbContext = control . createMock ( JAXBContext . class ) ; ContextUtils . setJAXBContext ( jaxbContext ) ; VersionTransformer . Names200408 . setJAXBContext ( jaxbContext ) ; VersionTransformer . Names200403 . setJAXBContext ( jaxbContext ) ; if ( outbound ) { setUpEncode ( requestor , message , header , maps , mapProperty , invalidMAP , preExistingSOAPAction ) ; } else { setUpDecode ( message , headers , maps , mapProperty , requestor ) ; } control . replay ( ) ; return message ; } private void setUpEncode ( boolean requestor , SoapMessage message , Element header , AddressingPropertiesImpl maps , String mapProperty , boolean invalidMAP , boolean preExistingSOAPAction ) throws Exception { message . put ( mapProperty , maps ) ; mimeHeaders = new HashMap < String , List < String > > ( ) ; message . put ( MIME_HEADERS , mimeHeaders ) ; if ( preExistingSOAPAction ) { List < String > soapAction = new ArrayList < String > ( ) ; soapAction . add ( ""\""foobar\"""" ) ; mimeHeaders . put ( SoapBindingConstants . SOAP_ACTION , soapAction ) ; } if ( invalidMAP ) { message . put ( ""org.apache.cxf.ws.addressing.map.fault.name"" , Names . DUPLICATE_MESSAGE_ID_NAME ) ; message . put ( ""org.apache.cxf.ws.addressing.map.fault.reason"" , ""Duplicate Message ID urn:uuid:12345"" ) ; } } private void setUpDecode ( SoapMessage message , List < Header > headers , AddressingPropertiesImpl maps , String mapProperty , boolean requestor ) throws Exception { Unmarshaller unmarshaller = control . createMock ( Unmarshaller . class ) ; ContextUtils . getJAXBContext ( ) . createUnmarshaller ( ) ; EasyMock . expectLastCall ( ) . andReturn ( unmarshaller ) ; String uri = maps . getNamespaceURI ( ) ; boolean exposedAsNative = Names . WSA_NAMESPACE_NAME . equals ( uri ) ; boolean exposedAs200408 = VersionTransformer . Names200408 . WSA_NAMESPACE_NAME . equals ( uri ) ; boolean exposedAs200403 = VersionTransformer . Names200403 . WSA_NAMESPACE_NAME . equals ( uri ) ; assertTrue ( ""unexpected namescape URI: "" + uri , exposedAsNative || exposedAs200408 || exposedAs200403 ) ; setUpHeaderDecode ( headers , uri , Names . WSA_ACTION_NAME , exposedAsNative ? AttributedURIType . class : exposedAs200408 ? AttributedURI . class : exposedAs200403 ? org . apache . cxf . ws . addressing . v200403 . AttributedURI . class : null , 0 , unmarshaller ) ; setUpHeaderDecode ( headers , uri , Names . WSA_MESSAGEID_NAME , exposedAsNative ? AttributedURIType . class : exposedAs200408 ? AttributedURI . class : exposedAs200403 ? org . apache . cxf . ws . addressing . v200403 . AttributedURI . class : null , 1 , unmarshaller ) ; setUpHeaderDecode ( headers , uri , Names . WSA_TO_NAME , exposedAsNative ? AttributedURIType . class : exposedAs200408 ? AttributedURI . class : exposedAs200403 ? org . apache . cxf . ws . addressing . v200403 . AttributedURI . class : null , 2 , unmarshaller ) ; setUpHeaderDecode ( headers , uri , Names . WSA_REPLYTO_NAME , exposedAsNative ? EndpointReferenceType . class : exposedAs200408 ? VersionTransformer . Names200408 . EPR_TYPE : exposedAs200403 ? VersionTransformer . Names200403 . EPR_TYPE : null , 3 , unmarshaller ) ; setUpHeaderDecode ( headers , uri , Names . WSA_RELATESTO_NAME , exposedAsNative ? RelatesToType . class : exposedAs200408 ? Relationship . class : exposedAs200403 ? org . apache . cxf . ws . addressing . v200403 . Relationship . class : null , 4 , unmarshaller ) ; setUpHeaderDecode ( headers , uri , Names . WSA_FAULTTO_NAME , exposedAsNative ? EndpointReferenceType . class : exposedAs200408 ? VersionTransformer . Names200408 . EPR_TYPE : exposedAs200403 ? VersionTransformer . Names200403 . EPR_TYPE : null , 5 , unmarshaller ) ; setUpHeaderDecode ( headers , uri , Names . WSA_FROM_NAME , exposedAsNative ? EndpointReferenceType . class : exposedAs200408 ? VersionTransformer . Names200408 . EPR_TYPE : exposedAs200403 ? VersionTransformer . Names200403 . EPR_TYPE : null , 6 , unmarshaller ) ; } private < T > void setUpHeaderDecode ( List < Header > headers , String uri , String name , Class < T > clz , int index , Unmarshaller unmarshaller ) throws Exception { Element headerElement = control . createMock ( Element . class ) ; headers . add ( new Header ( new QName ( uri , name ) , headerElement ) ) ; headerElement . getNamespaceURI ( ) ; EasyMock . expectLastCall ( ) . andReturn ( uri ) ; headerElement . getLocalName ( ) ; EasyMock . expectLastCall ( ) . andReturn ( name ) ; Object v = expectedValues [ index ] ; JAXBElement < ? > jaxbElement = new JAXBElement < T > ( new QName ( uri , name ) , clz , clz . cast ( v ) ) ; unmarshaller . unmarshal ( headerElement , clz ) ; EasyMock . expectLastCall ( ) . andReturn ( jaxbElement ) ; } private void setUpOutbound ( Message message , boolean outbound ) { Exchange exchange = new ExchangeImpl ( ) ; exchange . setOutMessage ( outbound ? message : new MessageImpl ( ) ) ; message . setExchange ( exchange ) ; } private String getMAPProperty ( boolean requestor , boolean outbound ) { return requestor ? outbound ? CLIENT_ADDRESSING_PROPERTIES_OUTBOUND : CLIENT_ADDRESSING_PROPERTIES_INBOUND : outbound ? SERVER_ADDRESSING_PROPERTIES_OUTBOUND : SERVER_ADDRESSING_PROPERTIES_INBOUND ; } private AddressingPropertiesImpl getMAPs ( boolean requestor , boolean outbound , String uri ) { AddressingPropertiesImpl maps = new AddressingPropertiesImpl ( ) ; boolean exposeAsNative = Names . WSA_NAMESPACE_NAME . equals ( uri ) ; boolean exposeAs200408 = VersionTransformer . Names200408 . WSA_NAMESPACE_NAME . equals ( uri ) ; boolean exposeAs200403 = VersionTransformer . Names200403 . WSA_NAMESPACE_NAME . equals ( uri ) ; AttributedURIType id = ContextUtils . getAttributedURI ( ""urn:uuid:12345"" ) ; maps . setMessageID ( id ) ; AttributedURIType to = ContextUtils . getAttributedURI ( ""foobar"" ) ; EndpointReferenceType toEpr = EndpointReferenceUtils . getEndpointReference ( to ) ; maps . setTo ( toEpr ) ; EndpointReferenceType replyTo = new EndpointReferenceType ( ) ; String anonymous = exposeAsNative ? Names . WSA_ANONYMOUS_ADDRESS : exposeAs200408 ? VersionTransformer . Names200408 . WSA_ANONYMOUS_ADDRESS : VersionTransformer . Names200403 . WSA_ANONYMOUS_ADDRESS ; replyTo . setAddress ( ContextUtils . getAttributedURI ( anonymous ) ) ; maps . setReplyTo ( replyTo ) ; EndpointReferenceType from = EndpointReferenceUtils . getEndpointReference ( ""snafu"" ) ; maps . setFrom ( from ) ; EndpointReferenceType faultTo = new EndpointReferenceType ( ) ; anonymous = exposeAsNative ? Names . WSA_ANONYMOUS_ADDRESS : exposeAs200408 ? VersionTransformer . Names200408 . WSA_ANONYMOUS_ADDRESS : VersionTransformer . Names200403 . WSA_ANONYMOUS_ADDRESS ; faultTo . setAddress ( ContextUtils . getAttributedURI ( anonymous ) ) ; maps . setFaultTo ( faultTo ) ; RelatesToType relatesTo = null ; if ( expectRelatesTo ) { String correlationID = ""urn:uuid:67890"" ; relatesTo = new RelatesToType ( ) ; relatesTo . setValue ( correlationID ) ; maps . setRelatesTo ( relatesTo ) ; if ( nonReplyRelationship == null ) { correlatedExchange = new ExchangeImpl ( ) ; codec . uncorrelatedExchanges . put ( correlationID , correlatedExchange ) ; } else { relatesTo . setRelationshipType ( nonReplyRelationship ) ; } } AttributedURIType action = ContextUtils . getAttributedURI ( ""http://foo/bar/SEI/opRequest"" ) ; maps . setAction ( action ) ; maps . exposeAs ( uri ) ; expectedNamespaceURI = uri ; expectedNames = new QName [ ] { new QName ( uri , Names . WSA_ACTION_NAME ) , new QName ( uri , Names . WSA_MESSAGEID_NAME ) , new QName ( uri , Names . WSA_TO_NAME ) , new QName ( uri , Names . WSA_REPLYTO_NAME ) , new QName ( uri , Names . WSA_RELATESTO_NAME ) , new QName ( uri , Names . WSA_FROM_NAME ) , new QName ( uri , Names . WSA_FAULTTO_NAME ) , } ; if ( exposeAsNative ) { expectedValues = new Object [ ] { action , id , to , replyTo , relatesTo , from , faultTo } ; } else if ( exposeAs200408 ) { expectedValues = new Object [ ] { VersionTransformer . convert ( action ) , VersionTransformer . convert ( id ) , VersionTransformer . convert ( to ) , VersionTransformer . convert ( replyTo ) , VersionTransformer . convert ( relatesTo ) , VersionTransformer . convert ( from ) , VersionTransformer . convert ( faultTo ) , } ; if ( ! outbound ) { VersionTransformer . Names200408 . EPR_TYPE . cast ( expectedValues [ 3 ] ) . getAddress ( ) . setValue ( Names . WSA_ANONYMOUS_ADDRESS ) ; VersionTransformer . Names200408 . EPR_TYPE . cast ( expectedValues [ 5 ] ) . getAddress ( ) . setValue ( Names . WSA_ANONYMOUS_ADDRESS ) ; } } else if ( exposeAs200403 ) { expectedValues = new Object [ ] { VersionTransformer . convertTo200403 ( action ) , VersionTransformer . convertTo200403 ( id ) , VersionTransformer . convertTo200403 ( to ) , VersionTransformer . convertTo200403 ( replyTo ) , VersionTransformer . convertTo200403 ( relatesTo ) , VersionTransformer . convertTo200403 ( from ) , VersionTransformer . convertTo200403 ( faultTo ) , } ; if ( ! outbound ) { VersionTransformer . Names200403 . EPR_TYPE . cast ( expectedValues [ 3 ] ) . getAddress ( ) . setValue ( Names . WSA_ANONYMOUS_ADDRESS ) ; VersionTransformer . Names200403 . EPR_TYPE . cast ( expectedValues [ 5 ] ) . getAddress ( ) . setValue ( Names . WSA_ANONYMOUS_ADDRESS ) ; } } else { fail ( ""unexpected namespace URI: "" + uri ) ; } return maps ; } private boolean verifyMAPs ( Object obj ) { if ( obj instanceof AddressingPropertiesImpl ) { AddressingPropertiesImpl other = ( AddressingPropertiesImpl ) obj ; return compareExpected ( other ) ; } return false ; } private boolean compareExpected ( AddressingPropertiesImpl other ) { boolean ret = false ; String uri = other . getNamespaceURI ( ) ; boolean exposedAsNative = Names . WSA_NAMESPACE_NAME . equals ( uri ) ; boolean exposedAs200408 = VersionTransformer . Names200408 . WSA_NAMESPACE_NAME . equals ( uri ) ; boolean exposedAs200403 = VersionTransformer . Names200403 . WSA_NAMESPACE_NAME . equals ( uri ) ; if ( exposedAsNative || exposedAs200408 || exposedAs200403 ) { String expectedMessageID = exposedAsNative ? ( ( AttributedURIType ) expectedValues [ 1 ] ) . getValue ( ) : exposedAs200408 ? ( ( AttributedURI ) expectedValues [ 1 ] ) . getValue ( ) : ( ( org . apache . cxf . ws . addressing . v200403 . AttributedURI ) expectedValues [ 1 ] ) . getValue ( ) ; String expectedTo = exposedAsNative ? ( ( AttributedURIType ) expectedValues [ 2 ] ) . getValue ( ) : exposedAs200408 ? ( ( AttributedURI ) expectedValues [ 2 ] ) . getValue ( ) : ( ( org . apache . cxf . ws . addressing . v200403 . AttributedURI ) expectedValues [ 2 ] ) . getValue ( ) ; String expectedReplyTo = exposedAsNative ? ( ( EndpointReferenceType ) expectedValues [ 3 ] ) . getAddress ( ) . getValue ( ) : exposedAs200408 ? ( VersionTransformer . Names200408 . EPR_TYPE . cast ( expectedValues [ 3 ] ) ) . getAddress ( ) . getValue ( ) : ( VersionTransformer . Names200403 . EPR_TYPE . cast ( expectedValues [ 3 ] ) ) . getAddress ( ) . getValue ( ) ; String expectedAction = exposedAsNative ? ( ( AttributedURIType ) expectedValues [ 0 ] ) . getValue ( ) : exposedAs200408 ? ( ( AttributedURI ) expectedValues [ 0 ] ) . getValue ( ) : ( ( org . apache . cxf . ws . addressing . v200403 . AttributedURI ) expectedValues [ 0 ] ) . getValue ( ) ; ret = expectedMessageID . equals ( other . getMessageID ( ) . getValue ( ) ) && expectedTo . equals ( other . getTo ( ) . getValue ( ) ) && expectedReplyTo . equals ( other . getReplyTo ( ) . getAddress ( ) . getValue ( ) ) && expectedAction . equals ( other . getAction ( ) . getValue ( ) ) && expectedNamespaceURI . equals ( other . getNamespaceURI ( ) ) ; if ( expectRelatesTo ) { String expectedRelatesTo = exposedAsNative ? ( ( RelatesToType ) expectedValues [ 4 ] ) . getValue ( ) : exposedAs200408 ? ( ( Relationship ) expectedValues [ 4 ] ) . getValue ( ) : ( ( org . apache . cxf . ws . addressing . v200403 . Relationship ) expectedValues [ 4 ] ) . getValue ( ) ; ret = ret && expectedRelatesTo . equals ( other . getRelatesTo ( ) . getValue ( ) ) ; } } return ret ; } private void verifyAction ( ) { List < ? > soapAction = mimeHeaders . get ( ""SOAPAction"" ) ; assertNotNull ( ""expected propogated action"" , soapAction ) ; assertEquals ( ""expected single action"" , 1 , soapAction . size ( ) ) ; String expectedAction = ""\"""" + ( ( AttributedURIType ) expectedValues [ 0 ] ) . getValue ( ) + ""\"""" ; assertEquals ( ""expected propogated action"" , expectedAction , soapAction . get ( 0 ) ) ; } private void verifyMessage ( SoapMessage message , boolean requestor , boolean outbound , boolean exposedAsNative ) { if ( requestor ) { if ( outbound ) { String id = expectedValues [ 1 ] instanceof AttributedURIType ? ( ( AttributedURIType ) expectedValues [ 1 ] ) . getValue ( ) : expectedValues [ 0 ] instanceof AttributedURI ? ( ( AttributedURI ) expectedValues [ 1 ] ) . getValue ( ) : ( ( org . apache . cxf . ws . addressing . v200403 . AttributedURI ) expectedValues [ 1 ] ) . getValue ( ) ; assertSame ( ""unexpected correlated exchange"" , codec . uncorrelatedExchanges . get ( id ) , message . getExchange ( ) ) ; } else { if ( isReply ( exposedAsNative ) ) { assertSame ( ""unexpected correlated exchange"" , correlatedExchange , message . getExchange ( ) ) ; } else { assertNotSame ( ""unexpected correlated exchange"" , correlatedExchange , message . getExchange ( ) ) ; } assertEquals ( ""expected empty uncorrelated exchange cache"" , 0 , codec . uncorrelatedExchanges . size ( ) ) ; } } if ( outbound ) { int expectedMarshals = requestor ? expectedValues . length - 1 : expectedValues . length ; if ( ! expectFaultTo ) { -- expectedMarshals ; } List < Header > headers = message . getHeaders ( ) ; assertTrue ( ""expected holders added to header list"" , headers . size ( ) >= expectedMarshals ) ; for ( int i = 0 ; i < ( expectFaultTo ? expectedValues . length : expectedValues . length - 1 ) ; i ++ ) { if ( i == 4 && ! expectRelatesTo ) { i ++ ; } assertTrue ( ""expected "" + expectedNames [ i ] + "" added to headers"" , message . hasHeader ( expectedNames [ i ] ) ) ; } } assertTrue ( ""unexpected MAPs"" , verifyMAPs ( message . get ( getMAPProperty ( requestor , outbound ) ) ) ) ; } private boolean isReply ( boolean exposedAsNative ) { boolean isReply = false ; if ( exposedAsNative ) { isReply = Names . WSA_RELATIONSHIP_REPLY . equals ( ( ( RelatesToType ) expectedValues [ 4 ] ) . getRelationshipType ( ) ) ; } else { QName relationship = expectedValues [ 4 ] instanceof Relationship ? ( ( Relationship ) expectedValues [ 4 ] ) . getRelationshipType ( ) : ( ( org . apache . cxf . ws . addressing . v200403 . Relationship ) expectedValues [ 4 ] ) . getRelationshipType ( ) ; isReply = relationship == null || Names . WSA_REPLY_NAME . equalsIgnoreCase ( relationship . getLocalPart ( ) ) ; } return isReply ; } }",Smelly
"public class DOM2Model extends SAX2Model { static Logger logger = LoggerFactory . getLogger ( DOM2Model . class ) ; static public DOM2Model createD2M ( String base , Model m ) throws SAXParseException { return new DOM2Model ( base , m , """" , true ) ; } static public DOM2Model createD2M ( String base , Model m , String lang ) throws SAXParseException { return new DOM2Model ( base , m , lang , true ) ; } DOM2Model ( String base , Model m , String lang , boolean dummy ) throws SAXParseException { super ( base , m , lang ) ; } public void load ( Node document ) { Source input = new DOMSource ( document ) ; SAXResult output = new SAXResult ( this ) ; output . setLexicalHandler ( this ) ; TransformerFactory xformFactory = TransformerFactory . newInstance ( ) ; try { Transformer idTransform = xformFactory . newTransformer ( ) ; idTransform . transform ( input , output ) ; } catch ( FatalParsingErrorException e ) { logger . error ( ""Unexpected exception in DOM2Model"" , e ) ; } catch ( RuntimeException rte ) { throw rte ; } catch ( Exception nrte ) { throw new JenaException ( nrte ) ; } finally { close ( ) ; } } }",No
"public class H2PersistenceManager extends BundleDbPersistenceManager { private long lockTimeout = 10000 ; public String getLockTimeout ( ) { return String . valueOf ( lockTimeout ) ; } public void setLockTimeout ( String lockTimeout ) { this . lockTimeout = Long . parseLong ( lockTimeout ) ; } public void init ( PMContext context ) throws Exception { if ( getDriver ( ) == null ) { setDriver ( ""org.h2.Driver"" ) ; } if ( getUrl ( ) == null ) { setUrl ( ""jdbc:h2:file:"" + context . getHomeDir ( ) . getPath ( ) + ""/db/itemState"" ) ; } if ( getDatabaseType ( ) == null ) { setDatabaseType ( ""h2"" ) ; } if ( getSchemaObjectPrefix ( ) == null ) { setSchemaObjectPrefix ( """" ) ; } super . init ( context ) ; conHelper . exec ( ""SET LOCK_TIMEOUT "" + lockTimeout ) ; } }",No
"public abstract class AbstractXMLRenderer extends PrintRenderer { public AbstractXMLRenderer ( FOUserAgent userAgent ) { super ( userAgent ) ; } public static final String NS = """" ; public static final String CDATA = ""CDATA"" ; public static final Attributes EMPTY_ATTS = new AttributesImpl ( ) ; protected AttributesImpl atts = new AttributesImpl ( ) ; protected ContentHandler handler ; protected OutputStream out ; protected RendererContext context ; protected List extensionAttachments ; protected void handleSAXException ( SAXException saxe ) { throw new RuntimeException ( saxe . getMessage ( ) ) ; } protected void handlePageExtensionAttachments ( PageViewport page ) { handleExtensionAttachments ( page . getExtensionAttachments ( ) ) ; } protected void comment ( String comment ) { if ( handler instanceof LexicalHandler ) { try { ( ( LexicalHandler ) handler ) . comment ( comment . toCharArray ( ) , 0 , comment . length ( ) ) ; } catch ( SAXException saxe ) { handleSAXException ( saxe ) ; } } } protected void startElement ( String tagName ) { startElement ( tagName , EMPTY_ATTS ) ; } protected void startElement ( String tagName , Attributes atts ) { try { handler . startElement ( NS , tagName , tagName , atts ) ; } catch ( SAXException saxe ) { handleSAXException ( saxe ) ; } } protected void endElement ( String tagName ) { try { handler . endElement ( NS , tagName , tagName ) ; } catch ( SAXException saxe ) { handleSAXException ( saxe ) ; } } protected void characters ( String text ) { try { char [ ] ca = text . toCharArray ( ) ; handler . characters ( ca , 0 , ca . length ) ; } catch ( SAXException saxe ) { handleSAXException ( saxe ) ; } } protected void addAttribute ( String name , String value ) { atts . addAttribute ( NS , name , name , CDATA , value ) ; } protected void addAttribute ( QName name , String value ) { atts . addAttribute ( name . getNamespaceURI ( ) , name . getLocalName ( ) , name . getQName ( ) , CDATA , value ) ; } protected void addAttribute ( String name , int value ) { addAttribute ( name , Integer . toString ( value ) ) ; } private String createString ( Rectangle2D rect ) { return """" + ( int ) rect . getX ( ) + "" "" + ( int ) rect . getY ( ) + "" "" + ( int ) rect . getWidth ( ) + "" "" + ( int ) rect . getHeight ( ) ; } protected void addAttribute ( String name , Rectangle2D rect ) { addAttribute ( name , createString ( rect ) ) ; } public void startRenderer ( OutputStream outputStream ) throws IOException { if ( this . handler == null ) { SAXTransformerFactory factory = ( SAXTransformerFactory ) SAXTransformerFactory . newInstance ( ) ; try { TransformerHandler transformerHandler = factory . newTransformerHandler ( ) ; setContentHandler ( transformerHandler ) ; StreamResult res = new StreamResult ( outputStream ) ; transformerHandler . setResult ( res ) ; } catch ( TransformerConfigurationException tce ) { throw new RuntimeException ( tce . getMessage ( ) ) ; } this . out = outputStream ; } try { handler . startDocument ( ) ; } catch ( SAXException saxe ) { handleSAXException ( saxe ) ; } } public void stopRenderer ( ) throws IOException { try { handler . endDocument ( ) ; } catch ( SAXException saxe ) { handleSAXException ( saxe ) ; } if ( this . out != null ) { this . out . flush ( ) ; } } public void processOffDocumentItem ( OffDocumentItem oDI ) { if ( oDI instanceof BookmarkData ) { renderBookmarkTree ( ( BookmarkData ) oDI ) ; } else if ( oDI instanceof OffDocumentExtensionAttachment ) { ExtensionAttachment attachment = ( ( OffDocumentExtensionAttachment ) oDI ) . getAttachment ( ) ; if ( extensionAttachments == null ) { extensionAttachments = new java . util . ArrayList ( ) ; } extensionAttachments . add ( attachment ) ; } else { String warn = ""Ignoring OffDocumentItem: "" + oDI ; log . warn ( warn ) ; } } protected void handleDocumentExtensionAttachments ( ) { if ( extensionAttachments != null && extensionAttachments . size ( ) > 0 ) { handleExtensionAttachments ( extensionAttachments ) ; extensionAttachments . clear ( ) ; } } public void setContentHandler ( ContentHandler handler ) { this . handler = handler ; } protected abstract void handleExtensionAttachments ( List attachments ) ; protected abstract void renderBookmarkTree ( BookmarkData odi ) ; }",No
"public class InvalidPartition extends StreamingException { public InvalidPartition ( String partitionName , String partitionValue ) { super ( ""Invalid partition: Name="" + partitionName + "", Value="" + partitionValue ) ; } }",No
"public abstract class AbstractBundlePersistenceManager implements PersistenceManager , CachingPersistenceManager , IterablePersistenceManager { private static Logger log = LoggerFactory . getLogger ( AbstractBundlePersistenceManager . class ) ; protected static final String NODEFILENAME = ""n"" ; protected static final String NODEREFSFILENAME = ""r"" ; protected static final String RES_NAME_INDEX = ""/names.properties"" ; protected static final String RES_NS_INDEX = ""/namespaces.properties"" ; private StringIndex nsIndex ; private StringIndex nameIndex ; private BundleCache bundles ; private LRUNodeIdCache missing ; protected PMContext context ; private long bundleCacheSize = 8 * 1024 * 1024 ; public String getBundleCacheSize ( ) { return String . valueOf ( bundleCacheSize / ( 1024 * 1024 ) ) ; } public void setBundleCacheSize ( String bundleCacheSize ) { this . bundleCacheSize = Long . parseLong ( bundleCacheSize ) * 1024 * 1024 ; } protected StringBuffer buildNodeFolderPath ( StringBuffer buf , NodeId id ) { if ( buf == null ) { buf = new StringBuffer ( ) ; } char [ ] chars = id . toString ( ) . toCharArray ( ) ; int cnt = 0 ; for ( int i = 0 ; i < chars . length ; i ++ ) { if ( chars [ i ] == '-' ) { continue ; } if ( cnt == 2 || cnt == 4 ) { buf . append ( FileSystem . SEPARATOR_CHAR ) ; } buf . append ( chars [ i ] ) ; cnt ++ ; } return buf ; } protected StringBuffer buildPropFilePath ( StringBuffer buf , PropertyId id ) { if ( buf == null ) { buf = new StringBuffer ( ) ; } buildNodeFolderPath ( buf , id . getParentId ( ) ) ; buf . append ( FileSystem . SEPARATOR ) ; buf . append ( getNsIndex ( ) . stringToIndex ( id . getName ( ) . getNamespaceURI ( ) ) ) ; buf . append ( '.' ) ; buf . append ( getNameIndex ( ) . stringToIndex ( id . getName ( ) . getLocalName ( ) ) ) ; return buf ; } protected StringBuffer buildBlobFilePath ( StringBuffer buf , PropertyId id , int i ) { if ( buf == null ) { buf = new StringBuffer ( ) ; } buildPropFilePath ( buf , id ) ; buf . append ( '.' ) ; buf . append ( i ) ; return buf ; } protected StringBuffer buildNodeFilePath ( StringBuffer buf , NodeId id ) { if ( buf == null ) { buf = new StringBuffer ( ) ; } buildNodeFolderPath ( buf , id ) ; buf . append ( FileSystem . SEPARATOR ) ; buf . append ( NODEFILENAME ) ; return buf ; } protected StringBuffer buildNodeReferencesFilePath ( StringBuffer buf , NodeId id ) { if ( buf == null ) { buf = new StringBuffer ( ) ; } buildNodeFolderPath ( buf , id ) ; buf . append ( FileSystem . SEPARATOR ) ; buf . append ( NODEREFSFILENAME ) ; return buf ; } public StringIndex getNsIndex ( ) { try { if ( nsIndex == null ) { FileSystemResource nsFile = new FileSystemResource ( context . getFileSystem ( ) , RES_NS_INDEX ) ; if ( nsFile . exists ( ) ) { nsIndex = new HashMapIndex ( nsFile ) ; } else { nsIndex = ( StringIndex ) context . getNamespaceRegistry ( ) ; } } return nsIndex ; } catch ( Exception e ) { IllegalStateException e2 = new IllegalStateException ( ""Unable to create nsIndex."" ) ; e2 . initCause ( e ) ; throw e2 ; } } public StringIndex getNameIndex ( ) { try { if ( nameIndex == null ) { nameIndex = new HashMapIndex ( new FileSystemResource ( context . getFileSystem ( ) , RES_NAME_INDEX ) ) ; } return nameIndex ; } catch ( Exception e ) { IllegalStateException e2 = new IllegalStateException ( ""Unable to create nameIndex."" ) ; e2 . initCause ( e ) ; throw e2 ; } } public synchronized void onExternalUpdate ( ChangeLog changes ) { for ( ItemState state : changes . modifiedStates ( ) ) { if ( state . isNode ( ) ) { bundles . remove ( ( NodeId ) state . getId ( ) ) ; } else { bundles . remove ( state . getParentId ( ) ) ; } } for ( ItemState state : changes . deletedStates ( ) ) { if ( state . isNode ( ) ) { bundles . remove ( ( NodeId ) state . getId ( ) ) ; } else { bundles . remove ( state . getParentId ( ) ) ; } } for ( ItemState state : changes . addedStates ( ) ) { if ( state . isNode ( ) ) { missing . remove ( ( NodeId ) state . getId ( ) ) ; } else { missing . remove ( state . getParentId ( ) ) ; } } } protected abstract NodePropBundle loadBundle ( NodeId id ) throws ItemStateException ; protected abstract boolean existsBundle ( NodeId id ) throws ItemStateException ; protected abstract void storeBundle ( NodePropBundle bundle ) throws ItemStateException ; protected abstract void destroyBundle ( NodePropBundle bundle ) throws ItemStateException ; protected abstract void destroy ( NodeReferences refs ) throws ItemStateException ; protected abstract void store ( NodeReferences refs ) throws ItemStateException ; protected abstract BundleBinding getBinding ( ) ; public void init ( PMContext context ) throws Exception { this . context = context ; bundles = new BundleCache ( bundleCacheSize ) ; missing = new LRUNodeIdCache ( ) ; } public void close ( ) throws Exception { bundles . clear ( ) ; missing . clear ( ) ; } public synchronized NodeState load ( NodeId id ) throws NoSuchItemStateException , ItemStateException { NodePropBundle bundle = getBundle ( id ) ; if ( bundle == null ) { throw new NoSuchItemStateException ( id . toString ( ) ) ; } return bundle . createNodeState ( this ) ; } public synchronized PropertyState load ( PropertyId id ) throws NoSuchItemStateException , ItemStateException { NodePropBundle bundle = getBundle ( id . getParentId ( ) ) ; if ( bundle == null ) { throw new NoSuchItemStateException ( id . toString ( ) ) ; } PropertyState state = bundle . createPropertyState ( this , id . getName ( ) ) ; if ( state == null ) { if ( id . getName ( ) . equals ( NameConstants . JCR_UUID ) ) { state = createNew ( id ) ; state . setType ( PropertyType . STRING ) ; state . setMultiValued ( false ) ; state . setValues ( new InternalValue [ ] { InternalValue . create ( id . getParentId ( ) . toString ( ) ) } ) ; } else if ( id . getName ( ) . equals ( NameConstants . JCR_PRIMARYTYPE ) ) { state = createNew ( id ) ; state . setType ( PropertyType . NAME ) ; state . setMultiValued ( false ) ; state . setValues ( new InternalValue [ ] { InternalValue . create ( bundle . getNodeTypeName ( ) ) } ) ; } else if ( id . getName ( ) . equals ( NameConstants . JCR_MIXINTYPES ) ) { Set < Name > mixins = bundle . getMixinTypeNames ( ) ; state = createNew ( id ) ; state . setType ( PropertyType . NAME ) ; state . setMultiValued ( true ) ; state . setValues ( InternalValue . create ( mixins . toArray ( new Name [ mixins . size ( ) ] ) ) ) ; } else { throw new NoSuchItemStateException ( id . toString ( ) ) ; } bundle . addProperty ( state ) ; } return state ; } public synchronized boolean exists ( PropertyId id ) throws ItemStateException { NodePropBundle bundle = getBundle ( id . getParentId ( ) ) ; return bundle != null && bundle . hasProperty ( id . getName ( ) ) ; } public synchronized boolean exists ( NodeId id ) throws ItemStateException { return getBundle ( id ) != null ; } public NodeState createNew ( NodeId id ) { return new NodeState ( id , null , null , NodeState . STATUS_NEW , false ) ; } public PropertyState createNew ( PropertyId id ) { return new PropertyState ( id , PropertyState . STATUS_NEW , false ) ; } public synchronized void store ( ChangeLog changeLog ) throws ItemStateException { boolean success = false ; try { storeInternal ( changeLog ) ; success = true ; } finally { if ( ! success ) { bundles . clear ( ) ; missing . clear ( ) ; } } } private void storeInternal ( ChangeLog changeLog ) throws ItemStateException { HashSet < ItemId > deleted = new HashSet < ItemId > ( ) ; for ( ItemState state : changeLog . deletedStates ( ) ) { if ( state . isNode ( ) ) { NodePropBundle bundle = getBundle ( ( NodeId ) state . getId ( ) ) ; if ( bundle == null ) { throw new NoSuchItemStateException ( state . getId ( ) . toString ( ) ) ; } deleteBundle ( bundle ) ; deleted . add ( state . getId ( ) ) ; } } HashMap < ItemId , NodePropBundle > modified = new HashMap < ItemId , NodePropBundle > ( ) ; for ( ItemState state : changeLog . addedStates ( ) ) { if ( state . isNode ( ) ) { NodePropBundle bundle = new NodePropBundle ( getBinding ( ) , ( NodeState ) state ) ; modified . put ( state . getId ( ) , bundle ) ; } } for ( ItemState state : changeLog . modifiedStates ( ) ) { if ( state . isNode ( ) ) { NodeId nodeId = ( NodeId ) state . getId ( ) ; NodePropBundle bundle = modified . get ( nodeId ) ; if ( bundle == null ) { bundle = getBundle ( nodeId ) ; if ( bundle == null ) { throw new NoSuchItemStateException ( nodeId . toString ( ) ) ; } modified . put ( nodeId , bundle ) ; } bundle . update ( ( NodeState ) state ) ; } else { PropertyId id = ( PropertyId ) state . getId ( ) ; if ( id . getName ( ) . equals ( NameConstants . JCR_PRIMARYTYPE ) || id . getName ( ) . equals ( NameConstants . JCR_MIXINTYPES ) || id . getName ( ) . equals ( NameConstants . JCR_UUID ) ) { continue ; } NodeId nodeId = id . getParentId ( ) ; NodePropBundle bundle = modified . get ( nodeId ) ; if ( bundle == null ) { bundle = getBundle ( nodeId ) ; if ( bundle == null ) { throw new NoSuchItemStateException ( nodeId . toString ( ) ) ; } modified . put ( nodeId , bundle ) ; } bundle . addProperty ( ( PropertyState ) state ) ; } } for ( ItemState state : changeLog . deletedStates ( ) ) { if ( state . isNode ( ) ) { NodeId parentId = state . getParentId ( ) ; if ( ! modified . containsKey ( parentId ) && ! deleted . contains ( parentId ) ) { log . warn ( ""Deleted node state's parent is not modified or deleted: "" + parentId + ""/"" + state . getId ( ) ) ; } } else { PropertyId id = ( PropertyId ) state . getId ( ) ; NodeId nodeId = id . getParentId ( ) ; if ( ! deleted . contains ( nodeId ) ) { NodePropBundle bundle = modified . get ( nodeId ) ; if ( bundle == null ) { log . warn ( ""deleted property state's parent not modified!"" ) ; bundle = getBundle ( nodeId ) ; if ( bundle == null ) { throw new NoSuchItemStateException ( nodeId . toString ( ) ) ; } modified . put ( nodeId , bundle ) ; } bundle . removeProperty ( id . getName ( ) ) ; } } } for ( ItemState state : changeLog . addedStates ( ) ) { if ( ! state . isNode ( ) ) { PropertyId id = ( PropertyId ) state . getId ( ) ; if ( id . getName ( ) . equals ( NameConstants . JCR_PRIMARYTYPE ) || id . getName ( ) . equals ( NameConstants . JCR_MIXINTYPES ) || id . getName ( ) . equals ( NameConstants . JCR_UUID ) ) { continue ; } NodeId nodeId = id . getParentId ( ) ; NodePropBundle bundle = modified . get ( nodeId ) ; if ( bundle == null ) { log . warn ( ""added property state's parent not modified!"" ) ; bundle = getBundle ( nodeId ) ; if ( bundle == null ) { throw new NoSuchItemStateException ( nodeId . toString ( ) ) ; } modified . put ( nodeId , bundle ) ; } bundle . addProperty ( ( PropertyState ) state ) ; } } for ( NodePropBundle bundle : modified . values ( ) ) { putBundle ( bundle ) ; } for ( NodeReferences refs : changeLog . modifiedRefs ( ) ) { if ( refs . hasReferences ( ) ) { store ( refs ) ; } else { destroy ( refs ) ; } } } private NodePropBundle getBundle ( NodeId id ) throws ItemStateException { if ( missing . contains ( id ) ) { return null ; } NodePropBundle bundle = bundles . get ( id ) ; if ( bundle == null ) { bundle = loadBundle ( id ) ; if ( bundle != null ) { bundle . markOld ( ) ; bundles . put ( bundle ) ; } else { missing . put ( id ) ; } } return bundle ; } private void deleteBundle ( NodePropBundle bundle ) throws ItemStateException { destroyBundle ( bundle ) ; bundle . removeAllProperties ( ) ; bundles . remove ( bundle . getId ( ) ) ; missing . put ( bundle . getId ( ) ) ; } private void putBundle ( NodePropBundle bundle ) throws ItemStateException { storeBundle ( bundle ) ; bundle . markOld ( ) ; log . debug ( ""stored bundle {}"" , bundle . getId ( ) ) ; missing . remove ( bundle . getId ( ) ) ; if ( bundles . contains ( bundle . getId ( ) ) ) { bundles . put ( bundle ) ; } } public void checkConsistency ( String [ ] uuids , boolean recursive , boolean fix ) { } protected void evictBundle ( NodeId id ) { bundles . remove ( id ) ; } }",Smelly
" private class AuthParams { private String userId ; private String password ; public AuthParams ( AuthenticationDataSource authData ) throws AuthenticationException { String authParams ; if ( authData . hasDataFromCommand ( ) ) { authParams = authData . getCommandData ( ) ; } else if ( authData . hasDataFromHttp ( ) ) { String rawAuthToken = authData . getHttpHeader ( HTTP_HEADER_NAME ) ; if ( StringUtils . isBlank ( rawAuthToken ) || ! rawAuthToken . toUpperCase ( ) . startsWith ( ""BASIC "" ) ) { throw new AuthenticationException ( ""Authentication token has to be started with \""Basic \"""" ) ; } String [ ] splitRawAuthToken = rawAuthToken . split ( "" "" ) ; if ( splitRawAuthToken . length != 2 ) { throw new AuthenticationException ( ""Base64 encoded token is not found"" ) ; } try { authParams = new String ( Base64 . getDecoder ( ) . decode ( splitRawAuthToken [ 1 ] ) ) ; } catch ( Exception e ) { throw new AuthenticationException ( ""Base64 decoding is failure: "" + e . getMessage ( ) ) ; } } else { throw new AuthenticationException ( ""Authentication data source does not have data"" ) ; } String [ ] parsedAuthParams = authParams . split ( "":"" ) ; if ( parsedAuthParams . length != 2 ) { throw new AuthenticationException ( ""Base64 decoded params are invalid"" ) ; } userId = parsedAuthParams [ 0 ] ; password = parsedAuthParams [ 1 ] ; } public String getUserId ( ) { return userId ; } public String getPassword ( ) { return password ; } } ",No
"public class BooleanNumberExpression extends AbstractBooleanExpression { private final INumberExpression e1 ; private final String op ; private final INumberExpression e2 ; public BooleanNumberExpression ( INumberExpression e1 , String op , INumberExpression e2 ) { super ( ) ; this . e1 = e1 ; this . op = op ; this . e2 = e2 ; } @ Override public boolean getBooleanValue ( MatchContext context , RutaStream stream ) { double doubleValue1 = getFristExpression ( ) . getDoubleValue ( context , stream ) ; double doubleValue2 = getSecondExpression ( ) . getDoubleValue ( context , stream ) ; return eval ( doubleValue1 , getOperator ( ) , doubleValue2 ) ; } private boolean eval ( double t1 , String op , double t2 ) { if ( ""=="" . equals ( op ) ) { return t1 == t2 ; } else if ( ""!="" . equals ( op ) ) { return t1 != t2 ; } else if ( ""<"" . equals ( op ) ) { return t1 < t2 ; } else if ( ""<="" . equals ( op ) ) { return t1 <= t2 ; } else if ( "">"" . equals ( op ) ) { return t1 > t2 ; } else if ( "">="" . equals ( op ) ) { return t1 >= t2 ; } return false ; } public INumberExpression getFristExpression ( ) { return e1 ; } public String getOperator ( ) { return op ; } public INumberExpression getSecondExpression ( ) { return e2 ; } @ Override public String getStringValue ( MatchContext context , RutaStream stream ) { return e1 . getStringValue ( context , stream ) + "" "" + op + "" "" + e2 . getStringValue ( context , stream ) ; } }",No
"public class DefaultCamelContext extends ServiceSupport implements CamelContext , Service { private static final transient Log LOG = LogFactory . getLog ( DefaultCamelContext . class ) ; private static final String NAME_PREFIX = ""camel-"" ; private static int nameSuffix ; private String name ; private final Map < String , Endpoint > endpoints = new HashMap < String , Endpoint > ( ) ; private final Map < String , Component > components = new HashMap < String , Component > ( ) ; private List < Route > routes ; private List < Service > servicesToClose = new ArrayList < Service > ( ) ; private TypeConverter typeConverter ; private ExchangeConverter exchangeConverter ; private Injector injector ; private ComponentResolver componentResolver ; private boolean autoCreateComponents = true ; private LanguageResolver languageResolver = new DefaultLanguageResolver ( ) ; private Registry registry ; private LifecycleStrategy lifecycleStrategy ; private List < RouteType > routeDefinitions = new ArrayList < RouteType > ( ) ; private List < InterceptStrategy > interceptStrategies = new ArrayList < InterceptStrategy > ( ) ; private Boolean trace ; private Long delay ; private ErrorHandlerBuilder errorHandlerBuilder ; private Map < String , DataFormatType > dataFormats = new HashMap < String , DataFormatType > ( ) ; private Class < ? extends FactoryFinder > factoryFinderClass = FactoryFinder . class ; public DefaultCamelContext ( ) { name = NAME_PREFIX + ++ nameSuffix ; if ( Boolean . getBoolean ( JmxSystemPropertyKeys . DISABLED ) ) { LOG . info ( ""JMX is disabled. Using DefaultLifecycleStrategy."" ) ; lifecycleStrategy = new DefaultLifecycleStrategy ( ) ; } else { try { LOG . info ( ""JMX enabled. Using InstrumentationLifecycleStrategy."" ) ; lifecycleStrategy = new InstrumentationLifecycleStrategy ( ) ; } catch ( NoClassDefFoundError e ) { LOG . warn ( ""Could not find needed classes for JMX lifecycle strategy."" + "" Needed class is in spring-context.jar using Spring 2.5 or newer ("" + "" spring-jmx.jar using Spring 2.0.x)."" + "" NoClassDefFoundError: "" + e . getMessage ( ) ) ; } catch ( Exception e ) { LOG . warn ( ""Could not create JMX lifecycle strategy, caused by: "" + e . getMessage ( ) ) ; } if ( lifecycleStrategy == null ) { LOG . warn ( ""Not possible to use JMX lifecycle strategy. Using DefaultLifecycleStrategy instead."" ) ; lifecycleStrategy = new DefaultLifecycleStrategy ( ) ; } } } public DefaultCamelContext ( Context jndiContext ) { this ( ) ; setJndiContext ( jndiContext ) ; } public DefaultCamelContext ( Registry registry ) { this ( ) ; this . registry = registry ; } public String getName ( ) { return name ; } public void setName ( String name ) { this . name = name ; } public void addComponent ( String componentName , final Component component ) { if ( component == null ) { throw new IllegalArgumentException ( ""Component cannot be null"" ) ; } synchronized ( components ) { if ( components . containsKey ( componentName ) ) { throw new IllegalArgumentException ( ""Component previously added: "" + componentName ) ; } component . setCamelContext ( this ) ; components . put ( componentName , component ) ; } } public Component getComponent ( String name ) { synchronized ( components ) { Component component = components . get ( name ) ; if ( component == null && autoCreateComponents ) { try { component = getComponentResolver ( ) . resolveComponent ( name , this ) ; if ( component != null ) { addComponent ( name , component ) ; if ( isStarted ( ) ) { startServices ( component ) ; } } } catch ( Exception e ) { throw new RuntimeCamelException ( ""Could not auto create component: "" + name , e ) ; } } return component ; } } public < T extends Component > T getComponent ( String name , Class < T > componentType ) { Component component = getComponent ( name ) ; if ( componentType . isInstance ( component ) ) { return componentType . cast ( component ) ; } else { throw new IllegalArgumentException ( ""The component is not of type: "" + componentType + "" but is: "" + component ) ; } } public Component removeComponent ( String componentName ) { synchronized ( components ) { return components . remove ( componentName ) ; } } public Component getOrCreateComponent ( String componentName , Callable < Component > factory ) { synchronized ( components ) { Component component = components . get ( componentName ) ; if ( component == null ) { try { component = factory . call ( ) ; if ( component == null ) { throw new RuntimeCamelException ( ""Factory failed to create the "" + componentName + "" component, it returned null."" ) ; } components . put ( componentName , component ) ; component . setCamelContext ( this ) ; } catch ( Exception e ) { throw new RuntimeCamelException ( ""Factory failed to create the "" + componentName + "" component"" , e ) ; } } return component ; } } public Collection < Endpoint > getEndpoints ( ) { synchronized ( endpoints ) { return new ArrayList < Endpoint > ( endpoints . values ( ) ) ; } } public Collection < Endpoint > getEndpoints ( String uri ) { Collection < Endpoint > answer = new ArrayList < Endpoint > ( ) ; Collection < Endpoint > coll ; synchronized ( endpoints ) { Endpoint ep = endpoints . get ( uri ) ; if ( ep != null ) { answer . add ( ep ) ; return answer ; } coll = new ArrayList < Endpoint > ( endpoints . values ( ) ) ; } for ( Endpoint ep : coll ) { if ( ! ep . isSingleton ( ) && uri . equals ( ep . getEndpointUri ( ) ) ) { answer . add ( ep ) ; } } return answer ; } public Collection < Endpoint > getSingletonEndpoints ( ) { Collection < Endpoint > answer = new ArrayList < Endpoint > ( ) ; Collection < Endpoint > coll = getEndpoints ( ) ; for ( Endpoint ep : coll ) { if ( ep . isSingleton ( ) ) { answer . add ( ep ) ; } } return answer ; } public Endpoint addEndpoint ( String uri , Endpoint endpoint ) throws Exception { Endpoint oldEndpoint ; synchronized ( endpoints ) { startServices ( endpoint ) ; oldEndpoint = endpoints . remove ( uri ) ; endpoints . put ( CamelContextHelper . getEndpointKey ( uri , endpoint ) , endpoint ) ; if ( oldEndpoint != null ) { stopServices ( oldEndpoint ) ; } } return oldEndpoint ; } public Collection < Endpoint > removeEndpoints ( String uri ) throws Exception { Collection < Endpoint > answer = new ArrayList < Endpoint > ( ) ; synchronized ( endpoints ) { Endpoint oldEndpoint = endpoints . remove ( uri ) ; if ( oldEndpoint != null ) { answer . add ( oldEndpoint ) ; stopServices ( oldEndpoint ) ; } else { for ( Map . Entry entry : endpoints . entrySet ( ) ) { oldEndpoint = ( Endpoint ) entry . getValue ( ) ; if ( ! oldEndpoint . isSingleton ( ) && uri . equals ( oldEndpoint . getEndpointUri ( ) ) ) { answer . add ( oldEndpoint ) ; stopServices ( oldEndpoint ) ; endpoints . remove ( entry . getKey ( ) ) ; } } } } return answer ; } public Endpoint addSingletonEndpoint ( String uri , Endpoint endpoint ) throws Exception { return addEndpoint ( uri , endpoint ) ; } public Endpoint removeSingletonEndpoint ( String uri ) throws Exception { Collection < Endpoint > answer = removeEndpoints ( uri ) ; return ( Endpoint ) ( answer . size ( ) > 0 ? answer . toArray ( ) [ 0 ] : null ) ; } public Endpoint getEndpoint ( String uri ) { Endpoint < ? > answer ; synchronized ( endpoints ) { answer = endpoints . get ( uri ) ; if ( answer == null ) { try { String splitURI [ ] = ObjectHelper . splitOnCharacter ( uri , "":"" , 2 ) ; if ( splitURI [ 1 ] != null ) { String scheme = splitURI [ 0 ] ; Component < ? > component = getComponent ( scheme ) ; if ( component != null ) { answer = component . createEndpoint ( uri ) ; if ( answer != null && LOG . isDebugEnabled ( ) ) { LOG . debug ( uri + "" converted to endpoint: "" + answer + "" by component: "" + component ) ; } } } if ( answer == null ) { answer = createEndpoint ( uri ) ; } if ( answer != null ) { addService ( answer ) ; endpoints . put ( CamelContextHelper . getEndpointKey ( uri , answer ) , answer ) ; lifecycleStrategy . onEndpointAdd ( answer ) ; } } catch ( Exception e ) { LOG . debug ( ""Failed to resolve endpoint "" + uri + "". Reason: "" + e , e ) ; throw new ResolveEndpointFailedException ( uri , e ) ; } } } return answer ; } public < T extends Endpoint > T getEndpoint ( String name , Class < T > endpointType ) { Endpoint endpoint = getEndpoint ( name ) ; if ( endpointType . isInstance ( endpoint ) ) { return endpointType . cast ( endpoint ) ; } else { throw new IllegalArgumentException ( ""The endpoint is not of type: "" + endpointType + "" but is: "" + endpoint ) ; } } public List < Route > getRoutes ( ) { if ( routes == null ) { routes = new ArrayList < Route > ( ) ; } return routes ; } public void setRoutes ( List < Route > routes ) { this . routes = routes ; throw new UnsupportedOperationException ( ""overriding existing routes is not supported yet, use addRoutes instead"" ) ; } public void addRoutes ( Collection < Route > routes ) throws Exception { if ( this . routes == null ) { this . routes = new ArrayList < Route > ( ) ; } if ( routes != null ) { this . routes . addAll ( routes ) ; lifecycleStrategy . onRoutesAdd ( routes ) ; if ( shouldStartRoutes ( ) ) { startRoutes ( routes ) ; } } } public void addRoutes ( Routes builder ) throws Exception { builder . setContext ( this ) ; List < Route > routeList = builder . getRouteList ( ) ; if ( LOG . isDebugEnabled ( ) ) { LOG . debug ( ""Adding routes from: "" + builder + "" routes: "" + routeList ) ; } addRoutes ( routeList ) ; } public void addRouteDefinitions ( Collection < RouteType > routeDefinitions ) throws Exception { this . routeDefinitions . addAll ( routeDefinitions ) ; if ( shouldStartRoutes ( ) ) { startRouteDefinitions ( routeDefinitions ) ; } } public void addService ( Object object ) throws Exception { if ( object instanceof Service ) { Service service = ( Service ) object ; getLifecycleStrategy ( ) . onServiceAdd ( this , service ) ; service . start ( ) ; servicesToClose . add ( service ) ; } } public Language resolveLanguage ( String language ) { return getLanguageResolver ( ) . resolveLanguage ( language , this ) ; } public ExchangeConverter getExchangeConverter ( ) { if ( exchangeConverter == null ) { exchangeConverter = createExchangeConverter ( ) ; } return exchangeConverter ; } public void setExchangeConverter ( ExchangeConverter exchangeConverter ) { this . exchangeConverter = exchangeConverter ; } public TypeConverter getTypeConverter ( ) { if ( typeConverter == null ) { typeConverter = createTypeConverter ( ) ; } return typeConverter ; } public void setTypeConverter ( TypeConverter typeConverter ) { this . typeConverter = typeConverter ; } public Injector getInjector ( ) { if ( injector == null ) { injector = createInjector ( ) ; } return injector ; } public void setInjector ( Injector injector ) { this . injector = injector ; } public ComponentResolver getComponentResolver ( ) { if ( componentResolver == null ) { componentResolver = createComponentResolver ( ) ; } return componentResolver ; } public void setComponentResolver ( ComponentResolver componentResolver ) { this . componentResolver = componentResolver ; } public LanguageResolver getLanguageResolver ( ) { return languageResolver ; } public void setLanguageResolver ( LanguageResolver languageResolver ) { this . languageResolver = languageResolver ; } public boolean isAutoCreateComponents ( ) { return autoCreateComponents ; } public void setAutoCreateComponents ( boolean autoCreateComponents ) { this . autoCreateComponents = autoCreateComponents ; } public Registry getRegistry ( ) { if ( registry == null ) { registry = createRegistry ( ) ; } return registry ; } public void setJndiContext ( Context jndiContext ) { setRegistry ( new JndiRegistry ( jndiContext ) ) ; } public void setRegistry ( Registry registry ) { this . registry = registry ; } public LifecycleStrategy getLifecycleStrategy ( ) { return lifecycleStrategy ; } public void setLifecycleStrategy ( LifecycleStrategy lifecycleStrategy ) { this . lifecycleStrategy = lifecycleStrategy ; } public List < RouteType > getRouteDefinitions ( ) { return routeDefinitions ; } public List < InterceptStrategy > getInterceptStrategies ( ) { return interceptStrategies ; } public void setInterceptStrategies ( List < InterceptStrategy > interceptStrategies ) { this . interceptStrategies = interceptStrategies ; } public void addInterceptStrategy ( InterceptStrategy interceptStrategy ) { getInterceptStrategies ( ) . add ( interceptStrategy ) ; } public boolean getTrace ( ) { final Boolean value = getTracing ( ) ; if ( value != null ) { return value ; } else { return SystemHelper . isSystemProperty ( ""camel.trace"" ) ; } } public Boolean getTracing ( ) { return trace ; } public void setTrace ( Boolean trace ) { this . trace = trace ; } public long getDelay ( ) { final Long value = getDelaying ( ) ; if ( value != null ) { return value ; } else { String prop = SystemHelper . getSystemProperty ( ""camel.delay"" ) ; return prop != null ? Long . getLong ( prop ) : 0 ; } } public Long getDelaying ( ) { return delay ; } public void setDelay ( Long delay ) { this . delay = delay ; } public < E extends Exchange > ProducerTemplate < E > createProducerTemplate ( ) { return new DefaultProducerTemplate < E > ( this ) ; } public ErrorHandlerBuilder getErrorHandlerBuilder ( ) { return errorHandlerBuilder ; } public void setErrorHandlerBuilder ( ErrorHandlerBuilder errorHandlerBuilder ) { this . errorHandlerBuilder = errorHandlerBuilder ; } protected void doStart ( ) throws Exception { LOG . info ( ""Apache Camel "" + getVersion ( ) + "" (CamelContext:"" + getName ( ) + "") is starting"" ) ; if ( getTrace ( ) ) { if ( Tracer . getTracer ( this ) == null ) { Tracer tracer = new Tracer ( ) ; TraceFormatter formatter = this . getRegistry ( ) . lookup ( ""traceFormatter"" , TraceFormatter . class ) ; if ( formatter != null ) { tracer . setFormatter ( formatter ) ; } addInterceptStrategy ( tracer ) ; } } if ( getDelay ( ) > 0 ) { if ( Delayer . getDelayer ( this ) == null ) { addInterceptStrategy ( new Delayer ( getDelay ( ) ) ) ; } } lifecycleStrategy . onContextStart ( this ) ; forceLazyInitialization ( ) ; if ( components != null ) { for ( Component component : components . values ( ) ) { startServices ( component ) ; } } startRouteDefinitions ( routeDefinitions ) ; startRoutes ( routes ) ; LOG . info ( ""Apache Camel "" + getVersion ( ) + "" (CamelContext:"" + getName ( ) + "") started"" ) ; } protected void startRouteDefinitions ( Collection < RouteType > list ) throws Exception { if ( list != null ) { Collection < Route > routes = new ArrayList < Route > ( ) ; for ( RouteType route : list ) { route . addRoutes ( this , routes ) ; } addRoutes ( routes ) ; } } protected void doStop ( ) throws Exception { stopServices ( servicesToClose ) ; if ( components != null ) { for ( Component component : components . values ( ) ) { stopServices ( component ) ; } } } protected void startRoutes ( Collection < Route > routeList ) throws Exception { if ( routeList != null ) { for ( Route < Exchange > route : routeList ) { List < Service > services = route . getServicesForRoute ( ) ; for ( Service service : services ) { addService ( service ) ; } } } } protected void forceLazyInitialization ( ) { getExchangeConverter ( ) ; getInjector ( ) ; getLanguageResolver ( ) ; getTypeConverter ( ) ; } protected ExchangeConverter createExchangeConverter ( ) { return new DefaultExchangeConverter ( ) ; } protected TypeConverter createTypeConverter ( ) { return new DefaultTypeConverter ( getInjector ( ) ) ; } protected Injector createInjector ( ) { FactoryFinder finder = createFactoryFinder ( ) ; try { return ( Injector ) finder . newInstance ( ""Injector"" ) ; } catch ( NoFactoryAvailableException e ) { return new ReflectionInjector ( ) ; } catch ( IllegalAccessException e ) { throw new RuntimeCamelException ( e ) ; } catch ( InstantiationException e ) { throw new RuntimeCamelException ( e ) ; } catch ( IOException e ) { throw new RuntimeCamelException ( e ) ; } catch ( ClassNotFoundException e ) { throw new RuntimeCamelException ( e ) ; } } protected ComponentResolver createComponentResolver ( ) { return new DefaultComponentResolver ( ) ; } protected Registry createRegistry ( ) { return new JndiRegistry ( ) ; } protected Endpoint createEndpoint ( String uri ) { Object value = getRegistry ( ) . lookup ( uri ) ; if ( value instanceof Endpoint ) { return ( Endpoint ) value ; } else if ( value instanceof Processor ) { return new ProcessorEndpoint ( uri , this , ( Processor ) value ) ; } else if ( value != null ) { return convertBeanToEndpoint ( uri , value ) ; } return null ; } protected Endpoint convertBeanToEndpoint ( String uri , Object bean ) { throw new IllegalArgumentException ( ""uri: "" + uri + "" bean: "" + bean + "" could not be converted to an Endpoint"" ) ; } protected boolean shouldStartRoutes ( ) { return isStarted ( ) && ! isStarting ( ) ; } public void setDataFormats ( Map < String , DataFormatType > dataFormats ) { this . dataFormats = dataFormats ; } public Map < String , DataFormatType > getDataFormats ( ) { return dataFormats ; } public void setFactoryFinderClass ( Class < ? extends FactoryFinder > finderClass ) { factoryFinderClass = finderClass ; } public FactoryFinder createFactoryFinder ( ) { try { return factoryFinderClass . newInstance ( ) ; } catch ( Exception e ) { throw new RuntimeCamelException ( e ) ; } } public FactoryFinder createFactoryFinder ( String path ) { try { Constructor < ? extends FactoryFinder > constructor ; constructor = factoryFinderClass . getConstructor ( String . class ) ; return constructor . newInstance ( path ) ; } catch ( Exception e ) { throw new RuntimeCamelException ( e ) ; } } }",Smelly
"public class ActiveInstanceElectorServiceTest { @ Mock private Configuration configuration ; @ Mock private CuratorFactory curatorFactory ; @ Mock private ActiveInstanceState activeInstanceState ; @ Mock private ServiceState serviceState ; @ BeforeMethod public void setup ( ) { System . setProperty ( AtlasConstants . SYSTEM_PROPERTY_APP_PORT , ""21000"" ) ; MockitoAnnotations . initMocks ( this ) ; } @ Test public void testLeaderElectionIsJoinedOnStart ( ) throws Exception { when ( configuration . containsKey ( HAConfiguration . ATLAS_SERVER_HA_ENABLED_KEY ) ) . thenReturn ( true ) ; when ( configuration . getBoolean ( HAConfiguration . ATLAS_SERVER_HA_ENABLED_KEY ) ) . thenReturn ( true ) ; when ( configuration . getStringArray ( HAConfiguration . ATLAS_SERVER_IDS ) ) . thenReturn ( new String [ ] { ""id1"" } ) ; when ( configuration . getString ( HAConfiguration . ATLAS_SERVER_ADDRESS_PREFIX + ""id1"" ) ) . thenReturn ( ""127.0.0.1:21000"" ) ; when ( configuration . getString ( HAConfiguration . ATLAS_SERVER_HA_ZK_ROOT_KEY , HAConfiguration . ATLAS_SERVER_ZK_ROOT_DEFAULT ) ) . thenReturn ( HAConfiguration . ATLAS_SERVER_ZK_ROOT_DEFAULT ) ; LeaderLatch leaderLatch = mock ( LeaderLatch . class ) ; when ( curatorFactory . leaderLatchInstance ( ""id1"" , HAConfiguration . ATLAS_SERVER_ZK_ROOT_DEFAULT ) ) . thenReturn ( leaderLatch ) ; ActiveInstanceElectorService activeInstanceElectorService = new ActiveInstanceElectorService ( configuration , new HashSet < ActiveStateChangeHandler > ( ) , curatorFactory , activeInstanceState , serviceState ) ; activeInstanceElectorService . start ( ) ; verify ( leaderLatch ) . start ( ) ; } @ Test public void testListenerIsAddedForActiveInstanceCallbacks ( ) throws Exception { when ( configuration . containsKey ( HAConfiguration . ATLAS_SERVER_HA_ENABLED_KEY ) ) . thenReturn ( true ) ; when ( configuration . getBoolean ( HAConfiguration . ATLAS_SERVER_HA_ENABLED_KEY ) ) . thenReturn ( true ) ; when ( configuration . getStringArray ( HAConfiguration . ATLAS_SERVER_IDS ) ) . thenReturn ( new String [ ] { ""id1"" } ) ; when ( configuration . getString ( HAConfiguration . ATLAS_SERVER_ADDRESS_PREFIX + ""id1"" ) ) . thenReturn ( ""127.0.0.1:21000"" ) ; when ( configuration . getString ( HAConfiguration . ATLAS_SERVER_HA_ZK_ROOT_KEY , HAConfiguration . ATLAS_SERVER_ZK_ROOT_DEFAULT ) ) . thenReturn ( HAConfiguration . ATLAS_SERVER_ZK_ROOT_DEFAULT ) ; LeaderLatch leaderLatch = mock ( LeaderLatch . class ) ; when ( curatorFactory . leaderLatchInstance ( ""id1"" , HAConfiguration . ATLAS_SERVER_ZK_ROOT_DEFAULT ) ) . thenReturn ( leaderLatch ) ; ActiveInstanceElectorService activeInstanceElectorService = new ActiveInstanceElectorService ( configuration , new HashSet < ActiveStateChangeHandler > ( ) , curatorFactory , activeInstanceState , serviceState ) ; activeInstanceElectorService . start ( ) ; verify ( leaderLatch ) . addListener ( activeInstanceElectorService ) ; } @ Test public void testLeaderElectionIsNotStartedIfNotInHAMode ( ) throws AtlasException { when ( configuration . getBoolean ( HAConfiguration . ATLAS_SERVER_HA_ENABLED_KEY , false ) ) . thenReturn ( false ) ; ActiveInstanceElectorService activeInstanceElectorService = new ActiveInstanceElectorService ( configuration , new HashSet < ActiveStateChangeHandler > ( ) , curatorFactory , activeInstanceState , serviceState ) ; activeInstanceElectorService . start ( ) ; verifyZeroInteractions ( curatorFactory ) ; } @ Test public void testLeaderElectionIsLeftOnStop ( ) throws IOException , AtlasException { when ( configuration . containsKey ( HAConfiguration . ATLAS_SERVER_HA_ENABLED_KEY ) ) . thenReturn ( true ) ; when ( configuration . getBoolean ( HAConfiguration . ATLAS_SERVER_HA_ENABLED_KEY ) ) . thenReturn ( true ) ; when ( configuration . getStringArray ( HAConfiguration . ATLAS_SERVER_IDS ) ) . thenReturn ( new String [ ] { ""id1"" } ) ; when ( configuration . getString ( HAConfiguration . ATLAS_SERVER_ADDRESS_PREFIX + ""id1"" ) ) . thenReturn ( ""127.0.0.1:21000"" ) ; when ( configuration . getString ( HAConfiguration . ATLAS_SERVER_HA_ZK_ROOT_KEY , HAConfiguration . ATLAS_SERVER_ZK_ROOT_DEFAULT ) ) . thenReturn ( HAConfiguration . ATLAS_SERVER_ZK_ROOT_DEFAULT ) ; LeaderLatch leaderLatch = mock ( LeaderLatch . class ) ; when ( curatorFactory . leaderLatchInstance ( ""id1"" , HAConfiguration . ATLAS_SERVER_ZK_ROOT_DEFAULT ) ) . thenReturn ( leaderLatch ) ; ActiveInstanceElectorService activeInstanceElectorService = new ActiveInstanceElectorService ( configuration , new HashSet < ActiveStateChangeHandler > ( ) , curatorFactory , activeInstanceState , serviceState ) ; activeInstanceElectorService . start ( ) ; activeInstanceElectorService . stop ( ) ; verify ( leaderLatch ) . close ( ) ; } @ Test public void testCuratorFactoryIsClosedOnStop ( ) throws AtlasException { when ( configuration . containsKey ( HAConfiguration . ATLAS_SERVER_HA_ENABLED_KEY ) ) . thenReturn ( true ) ; when ( configuration . getBoolean ( HAConfiguration . ATLAS_SERVER_HA_ENABLED_KEY ) ) . thenReturn ( true ) ; when ( configuration . getStringArray ( HAConfiguration . ATLAS_SERVER_IDS ) ) . thenReturn ( new String [ ] { ""id1"" } ) ; when ( configuration . getString ( HAConfiguration . ATLAS_SERVER_ADDRESS_PREFIX + ""id1"" ) ) . thenReturn ( ""127.0.0.1:21000"" ) ; when ( configuration . getString ( HAConfiguration . ATLAS_SERVER_HA_ZK_ROOT_KEY , HAConfiguration . ATLAS_SERVER_ZK_ROOT_DEFAULT ) ) . thenReturn ( HAConfiguration . ATLAS_SERVER_ZK_ROOT_DEFAULT ) ; LeaderLatch leaderLatch = mock ( LeaderLatch . class ) ; when ( curatorFactory . leaderLatchInstance ( ""id1"" , HAConfiguration . ATLAS_SERVER_ZK_ROOT_DEFAULT ) ) . thenReturn ( leaderLatch ) ; ActiveInstanceElectorService activeInstanceElectorService = new ActiveInstanceElectorService ( configuration , new HashSet < ActiveStateChangeHandler > ( ) , curatorFactory , activeInstanceState , serviceState ) ; activeInstanceElectorService . start ( ) ; activeInstanceElectorService . stop ( ) ; verify ( curatorFactory ) . close ( ) ; } @ Test public void testNoActionOnStopIfHAModeIsDisabled ( ) { when ( configuration . getBoolean ( HAConfiguration . ATLAS_SERVER_HA_ENABLED_KEY , false ) ) . thenReturn ( false ) ; ActiveInstanceElectorService activeInstanceElectorService = new ActiveInstanceElectorService ( configuration , new HashSet < ActiveStateChangeHandler > ( ) , curatorFactory , activeInstanceState , serviceState ) ; activeInstanceElectorService . stop ( ) ; verifyZeroInteractions ( curatorFactory ) ; } @ Test public void testRegisteredHandlersAreNotifiedWhenInstanceIsActive ( ) throws AtlasException { when ( configuration . containsKey ( HAConfiguration . ATLAS_SERVER_HA_ENABLED_KEY ) ) . thenReturn ( true ) ; when ( configuration . getBoolean ( HAConfiguration . ATLAS_SERVER_HA_ENABLED_KEY ) ) . thenReturn ( true ) ; when ( configuration . getStringArray ( HAConfiguration . ATLAS_SERVER_IDS ) ) . thenReturn ( new String [ ] { ""id1"" } ) ; when ( configuration . getString ( HAConfiguration . ATLAS_SERVER_ADDRESS_PREFIX + ""id1"" ) ) . thenReturn ( ""127.0.0.1:21000"" ) ; when ( configuration . getString ( HAConfiguration . ATLAS_SERVER_HA_ZK_ROOT_KEY , HAConfiguration . ATLAS_SERVER_ZK_ROOT_DEFAULT ) ) . thenReturn ( HAConfiguration . ATLAS_SERVER_ZK_ROOT_DEFAULT ) ; LeaderLatch leaderLatch = mock ( LeaderLatch . class ) ; when ( curatorFactory . leaderLatchInstance ( ""id1"" , HAConfiguration . ATLAS_SERVER_ZK_ROOT_DEFAULT ) ) . thenReturn ( leaderLatch ) ; Set < ActiveStateChangeHandler > changeHandlers = new HashSet < > ( ) ; final ActiveStateChangeHandler handler1 = mock ( ActiveStateChangeHandler . class ) ; final ActiveStateChangeHandler handler2 = mock ( ActiveStateChangeHandler . class ) ; changeHandlers . add ( handler1 ) ; changeHandlers . add ( handler2 ) ; ActiveInstanceElectorService activeInstanceElectorService = new ActiveInstanceElectorService ( configuration , changeHandlers , curatorFactory , activeInstanceState , serviceState ) ; activeInstanceElectorService . start ( ) ; activeInstanceElectorService . isLeader ( ) ; verify ( handler1 ) . instanceIsActive ( ) ; verify ( handler2 ) . instanceIsActive ( ) ; } @ Test public void testSharedStateIsUpdatedWhenInstanceIsActive ( ) throws Exception { when ( configuration . containsKey ( HAConfiguration . ATLAS_SERVER_HA_ENABLED_KEY ) ) . thenReturn ( true ) ; when ( configuration . getBoolean ( HAConfiguration . ATLAS_SERVER_HA_ENABLED_KEY ) ) . thenReturn ( true ) ; when ( configuration . getStringArray ( HAConfiguration . ATLAS_SERVER_IDS ) ) . thenReturn ( new String [ ] { ""id1"" } ) ; when ( configuration . getString ( HAConfiguration . ATLAS_SERVER_ADDRESS_PREFIX + ""id1"" ) ) . thenReturn ( ""127.0.0.1:21000"" ) ; when ( configuration . getString ( HAConfiguration . ATLAS_SERVER_HA_ZK_ROOT_KEY , HAConfiguration . ATLAS_SERVER_ZK_ROOT_DEFAULT ) ) . thenReturn ( HAConfiguration . ATLAS_SERVER_ZK_ROOT_DEFAULT ) ; LeaderLatch leaderLatch = mock ( LeaderLatch . class ) ; when ( curatorFactory . leaderLatchInstance ( ""id1"" , HAConfiguration . ATLAS_SERVER_ZK_ROOT_DEFAULT ) ) . thenReturn ( leaderLatch ) ; ActiveInstanceElectorService activeInstanceElectorService = new ActiveInstanceElectorService ( configuration , new HashSet < ActiveStateChangeHandler > ( ) , curatorFactory , activeInstanceState , serviceState ) ; activeInstanceElectorService . start ( ) ; activeInstanceElectorService . isLeader ( ) ; verify ( activeInstanceState ) . update ( ""id1"" ) ; } @ Test public void testRegisteredHandlersAreNotifiedOfPassiveWhenStateUpdateFails ( ) throws Exception { when ( configuration . containsKey ( HAConfiguration . ATLAS_SERVER_HA_ENABLED_KEY ) ) . thenReturn ( true ) ; when ( configuration . getBoolean ( HAConfiguration . ATLAS_SERVER_HA_ENABLED_KEY ) ) . thenReturn ( true ) ; when ( configuration . getStringArray ( HAConfiguration . ATLAS_SERVER_IDS ) ) . thenReturn ( new String [ ] { ""id1"" } ) ; when ( configuration . getString ( HAConfiguration . ATLAS_SERVER_ADDRESS_PREFIX + ""id1"" ) ) . thenReturn ( ""127.0.0.1:21000"" ) ; when ( configuration . getString ( HAConfiguration . ATLAS_SERVER_HA_ZK_ROOT_KEY , HAConfiguration . ATLAS_SERVER_ZK_ROOT_DEFAULT ) ) . thenReturn ( HAConfiguration . ATLAS_SERVER_ZK_ROOT_DEFAULT ) ; LeaderLatch leaderLatch = mock ( LeaderLatch . class ) ; when ( curatorFactory . leaderLatchInstance ( ""id1"" , HAConfiguration . ATLAS_SERVER_ZK_ROOT_DEFAULT ) ) . thenReturn ( leaderLatch ) ; Set < ActiveStateChangeHandler > changeHandlers = new HashSet < > ( ) ; final ActiveStateChangeHandler handler1 = mock ( ActiveStateChangeHandler . class ) ; final ActiveStateChangeHandler handler2 = mock ( ActiveStateChangeHandler . class ) ; changeHandlers . add ( handler1 ) ; changeHandlers . add ( handler2 ) ; doThrow ( new AtlasBaseException ( ) ) . when ( activeInstanceState ) . update ( ""id1"" ) ; ActiveInstanceElectorService activeInstanceElectorService = new ActiveInstanceElectorService ( configuration , changeHandlers , curatorFactory , activeInstanceState , serviceState ) ; activeInstanceElectorService . start ( ) ; activeInstanceElectorService . isLeader ( ) ; verify ( handler1 ) . instanceIsPassive ( ) ; verify ( handler2 ) . instanceIsPassive ( ) ; } @ Test public void testElectionIsRejoinedWhenStateUpdateFails ( ) throws Exception { when ( configuration . containsKey ( HAConfiguration . ATLAS_SERVER_HA_ENABLED_KEY ) ) . thenReturn ( true ) ; when ( configuration . getBoolean ( HAConfiguration . ATLAS_SERVER_HA_ENABLED_KEY ) ) . thenReturn ( true ) ; when ( configuration . getStringArray ( HAConfiguration . ATLAS_SERVER_IDS ) ) . thenReturn ( new String [ ] { ""id1"" } ) ; when ( configuration . getString ( HAConfiguration . ATLAS_SERVER_ADDRESS_PREFIX + ""id1"" ) ) . thenReturn ( ""127.0.0.1:21000"" ) ; when ( configuration . getString ( HAConfiguration . ATLAS_SERVER_HA_ZK_ROOT_KEY , HAConfiguration . ATLAS_SERVER_ZK_ROOT_DEFAULT ) ) . thenReturn ( HAConfiguration . ATLAS_SERVER_ZK_ROOT_DEFAULT ) ; LeaderLatch leaderLatch = mock ( LeaderLatch . class ) ; when ( curatorFactory . leaderLatchInstance ( ""id1"" , HAConfiguration . ATLAS_SERVER_ZK_ROOT_DEFAULT ) ) . thenReturn ( leaderLatch ) ; doThrow ( new AtlasBaseException ( ) ) . when ( activeInstanceState ) . update ( ""id1"" ) ; ActiveInstanceElectorService activeInstanceElectorService = new ActiveInstanceElectorService ( configuration , new HashSet < ActiveStateChangeHandler > ( ) , curatorFactory , activeInstanceState , serviceState ) ; activeInstanceElectorService . start ( ) ; activeInstanceElectorService . isLeader ( ) ; InOrder inOrder = inOrder ( leaderLatch , curatorFactory ) ; inOrder . verify ( leaderLatch ) . close ( ) ; inOrder . verify ( curatorFactory ) . leaderLatchInstance ( ""id1"" , HAConfiguration . ATLAS_SERVER_ZK_ROOT_DEFAULT ) ; inOrder . verify ( leaderLatch ) . addListener ( activeInstanceElectorService ) ; inOrder . verify ( leaderLatch ) . start ( ) ; } @ Test public void testRegisteredHandlersAreNotifiedOfPassiveWhenInstanceIsPassive ( ) throws AtlasException { when ( configuration . containsKey ( HAConfiguration . ATLAS_SERVER_HA_ENABLED_KEY ) ) . thenReturn ( true ) ; when ( configuration . getBoolean ( HAConfiguration . ATLAS_SERVER_HA_ENABLED_KEY ) ) . thenReturn ( true ) ; when ( configuration . getStringArray ( HAConfiguration . ATLAS_SERVER_IDS ) ) . thenReturn ( new String [ ] { ""id1"" } ) ; when ( configuration . getString ( HAConfiguration . ATLAS_SERVER_ADDRESS_PREFIX + ""id1"" ) ) . thenReturn ( ""127.0.0.1:21000"" ) ; when ( configuration . getString ( HAConfiguration . ATLAS_SERVER_HA_ZK_ROOT_KEY , HAConfiguration . ATLAS_SERVER_ZK_ROOT_DEFAULT ) ) . thenReturn ( HAConfiguration . ATLAS_SERVER_ZK_ROOT_DEFAULT ) ; LeaderLatch leaderLatch = mock ( LeaderLatch . class ) ; when ( curatorFactory . leaderLatchInstance ( ""id1"" , HAConfiguration . ATLAS_SERVER_ZK_ROOT_DEFAULT ) ) . thenReturn ( leaderLatch ) ; Set < ActiveStateChangeHandler > changeHandlers = new HashSet < > ( ) ; final ActiveStateChangeHandler handler1 = mock ( ActiveStateChangeHandler . class ) ; final ActiveStateChangeHandler handler2 = mock ( ActiveStateChangeHandler . class ) ; changeHandlers . add ( handler1 ) ; changeHandlers . add ( handler2 ) ; ActiveInstanceElectorService activeInstanceElectorService = new ActiveInstanceElectorService ( configuration , changeHandlers , curatorFactory , activeInstanceState , serviceState ) ; activeInstanceElectorService . start ( ) ; activeInstanceElectorService . notLeader ( ) ; verify ( handler1 ) . instanceIsPassive ( ) ; verify ( handler2 ) . instanceIsPassive ( ) ; } @ Test public void testActiveStateSetOnBecomingLeader ( ) { ActiveInstanceElectorService activeInstanceElectorService = new ActiveInstanceElectorService ( configuration , new HashSet < ActiveStateChangeHandler > ( ) , curatorFactory , activeInstanceState , serviceState ) ; activeInstanceElectorService . isLeader ( ) ; InOrder inOrder = inOrder ( serviceState ) ; inOrder . verify ( serviceState ) . becomingActive ( ) ; inOrder . verify ( serviceState ) . setActive ( ) ; } @ Test public void testPassiveStateSetOnLoosingLeadership ( ) { ActiveInstanceElectorService activeInstanceElectorService = new ActiveInstanceElectorService ( configuration , new HashSet < ActiveStateChangeHandler > ( ) , curatorFactory , activeInstanceState , serviceState ) ; activeInstanceElectorService . notLeader ( ) ; InOrder inOrder = inOrder ( serviceState ) ; inOrder . verify ( serviceState ) . becomingPassive ( ) ; inOrder . verify ( serviceState ) . setPassive ( ) ; } @ Test public void testPassiveStateSetIfActivationFails ( ) throws Exception { when ( configuration . containsKey ( HAConfiguration . ATLAS_SERVER_HA_ENABLED_KEY ) ) . thenReturn ( true ) ; when ( configuration . getBoolean ( HAConfiguration . ATLAS_SERVER_HA_ENABLED_KEY ) ) . thenReturn ( true ) ; when ( configuration . getStringArray ( HAConfiguration . ATLAS_SERVER_IDS ) ) . thenReturn ( new String [ ] { ""id1"" } ) ; when ( configuration . getString ( HAConfiguration . ATLAS_SERVER_ADDRESS_PREFIX + ""id1"" ) ) . thenReturn ( ""127.0.0.1:21000"" ) ; when ( configuration . getString ( HAConfiguration . ATLAS_SERVER_HA_ZK_ROOT_KEY , HAConfiguration . ATLAS_SERVER_ZK_ROOT_DEFAULT ) ) . thenReturn ( HAConfiguration . ATLAS_SERVER_ZK_ROOT_DEFAULT ) ; LeaderLatch leaderLatch = mock ( LeaderLatch . class ) ; when ( curatorFactory . leaderLatchInstance ( ""id1"" , HAConfiguration . ATLAS_SERVER_ZK_ROOT_DEFAULT ) ) . thenReturn ( leaderLatch ) ; doThrow ( new AtlasBaseException ( ) ) . when ( activeInstanceState ) . update ( ""id1"" ) ; ActiveInstanceElectorService activeInstanceElectorService = new ActiveInstanceElectorService ( configuration , new HashSet < ActiveStateChangeHandler > ( ) , curatorFactory , activeInstanceState , serviceState ) ; activeInstanceElectorService . start ( ) ; activeInstanceElectorService . isLeader ( ) ; InOrder inOrder = inOrder ( serviceState ) ; inOrder . verify ( serviceState ) . becomingActive ( ) ; inOrder . verify ( serviceState ) . becomingPassive ( ) ; inOrder . verify ( serviceState ) . setPassive ( ) ; } }",Smelly
"public class TomcatCSS { public static final String TOMCAT_CSS = ""H1 {font-family:Tahoma,Arial,sans-serif;color:white;background-color:#525D76;font-size:22px;} "" + ""H2 {font-family:Tahoma,Arial,sans-serif;color:white;background-color:#525D76;font-size:16px;} "" + ""H3 {font-family:Tahoma,Arial,sans-serif;color:white;background-color:#525D76;font-size:14px;} "" + ""BODY {font-family:Tahoma,Arial,sans-serif;color:black;background-color:white;} "" + ""B {font-family:Tahoma,Arial,sans-serif;color:white;background-color:#525D76;} "" + ""P {font-family:Tahoma,Arial,sans-serif;background:white;color:black;font-size:12px;}"" + ""A {color : black;}"" + ""A.name {color : black;}"" + ""HR {color : #525D76;}"" ; }",No
"public class StoreParams implements IndexParams , StoreParamsDynamic { final Item < FileMode > fileMode ; final Item < Integer > blockSize ; final Item < Integer > blockReadCacheSize ; final Item < Integer > blockWriteCacheSize ; final Item < Integer > Node2NodeIdCacheSize ; final Item < Integer > NodeId2NodeCacheSize ; final Item < Integer > NodeMissCacheSize ; final Item < String > nodeTableBaseName ; final Item < String > primaryIndexTriples ; final Item < String [ ] > tripleIndexes ; final Item < String > primaryIndexQuads ; final Item < String [ ] > quadIndexes ; final Item < String > prefixTableBaseName ; final Item < String > primaryIndexPrefix ; final Item < String [ ] > prefixIndexes ; public static StoreParamsBuilder builder ( ) { return StoreParamsBuilder . create ( ) ; } public static StoreParamsBuilder builder ( StoreParams params ) { return StoreParamsBuilder . create ( params ) ; } StoreParams ( Item < FileMode > fileMode , Item < Integer > blockSize , Item < Integer > blockReadCacheSize , Item < Integer > blockWriteCacheSize , Item < Integer > node2NodeIdCacheSize , Item < Integer > nodeId2NodeCacheSize , Item < Integer > nodeMissCacheSize , Item < String > nodeTableBaseName , Item < String > primaryIndexTriples , Item < String [ ] > tripleIndexes , Item < String > primaryIndexQuads , Item < String [ ] > quadIndexes , Item < String > prefixTableBasename , Item < String > primaryIndexPrefix , Item < String [ ] > prefixIndexes ) { this . fileMode = fileMode ; this . blockSize = blockSize ; this . blockReadCacheSize = blockReadCacheSize ; this . blockWriteCacheSize = blockWriteCacheSize ; this . Node2NodeIdCacheSize = node2NodeIdCacheSize ; this . NodeId2NodeCacheSize = nodeId2NodeCacheSize ; this . NodeMissCacheSize = nodeMissCacheSize ; this . nodeTableBaseName = nodeTableBaseName ; this . primaryIndexTriples = primaryIndexTriples ; this . tripleIndexes = tripleIndexes ; this . primaryIndexQuads = primaryIndexQuads ; this . quadIndexes = quadIndexes ; this . primaryIndexPrefix = primaryIndexPrefix ; this . prefixIndexes = prefixIndexes ; this . prefixTableBaseName = prefixTableBasename ; } public static StoreParams getDftStoreParams ( ) { return StoreParamsConst . dftStoreParams ; } public static StoreParams getSmallStoreParams ( ) { return StoreParamsConst . smallStoreParams ; } @ Override public FileMode getFileMode ( ) { return fileMode . value ; } @ Override public boolean isSetFileMode ( ) { return fileMode . isSet ; } @ Override public Integer getBlockSize ( ) { return blockSize . value ; } @ Override public Integer getBlockReadCacheSize ( ) { return blockReadCacheSize . value ; } @ Override public boolean isSetBlockReadCacheSize ( ) { return blockReadCacheSize . isSet ; } @ Override public Integer getBlockWriteCacheSize ( ) { return blockWriteCacheSize . value ; } @ Override public boolean isSetBlockWriteCacheSize ( ) { return blockWriteCacheSize . isSet ; } @ Override public Integer getNode2NodeIdCacheSize ( ) { return Node2NodeIdCacheSize . value ; } @ Override public boolean isSetNodeId2NodeCacheSize ( ) { return NodeId2NodeCacheSize . isSet ; } @ Override public boolean isSetNode2NodeIdCacheSize ( ) { return Node2NodeIdCacheSize . isSet ; } @ Override public Integer getNodeId2NodeCacheSize ( ) { return NodeId2NodeCacheSize . value ; } @ Override public Integer getNodeMissCacheSize ( ) { return NodeMissCacheSize . value ; } @ Override public boolean isSetNodeMissCacheSize ( ) { return NodeMissCacheSize . isSet ; } public String getNodeTableBaseName ( ) { return nodeTableBaseName . value ; } public boolean isSetNodeTableBaseName ( ) { return nodeTableBaseName . isSet ; } public String getPrimaryIndexTriples ( ) { return primaryIndexTriples . value ; } public String [ ] getTripleIndexes ( ) { return tripleIndexes . value ; } public String getPrimaryIndexQuads ( ) { return primaryIndexQuads . value ; } public String [ ] getQuadIndexes ( ) { return quadIndexes . value ; } public String getPrefixTableBaseName ( ) { return prefixTableBaseName . value ; } public boolean isSetPrefixBaseName ( ) { return prefixTableBaseName . isSet ; } public String getPrimaryIndexPrefix ( ) { return primaryIndexPrefix . value ; } public String [ ] getPrefixIndexes ( ) { return prefixIndexes . value ; } @ Override public String toString ( ) { StringBuilder buff = new StringBuilder ( ) ; fmt ( buff , ""fileMode"" , getFileMode ( ) . toString ( ) , fileMode . isSet ) ; fmt ( buff , ""blockSize"" , getBlockSize ( ) , blockSize . isSet ) ; fmt ( buff , ""readCacheSize"" , getBlockReadCacheSize ( ) , blockReadCacheSize . isSet ) ; fmt ( buff , ""writeCacheSize"" , getBlockWriteCacheSize ( ) , blockWriteCacheSize . isSet ) ; fmt ( buff , ""Node2NodeIdCacheSize"" , getNode2NodeIdCacheSize ( ) , Node2NodeIdCacheSize . isSet ) ; fmt ( buff , ""NodeId2NodeCacheSize"" , getNodeId2NodeCacheSize ( ) , NodeId2NodeCacheSize . isSet ) ; fmt ( buff , ""NodeMissCacheSize"" , getNodeMissCacheSize ( ) , NodeMissCacheSize . isSet ) ; fmt ( buff , ""nodeTableBaseName"" , getNodeTableBaseName ( ) , nodeTableBaseName . isSet ) ; fmt ( buff , ""primaryIndexTriples"" , getPrimaryIndexTriples ( ) , primaryIndexTriples . isSet ) ; fmt ( buff , ""tripleIndexes"" , getTripleIndexes ( ) , tripleIndexes . isSet ) ; fmt ( buff , ""primaryIndexQuads"" , getPrimaryIndexQuads ( ) , primaryIndexQuads . isSet ) ; fmt ( buff , ""quadIndexes"" , getQuadIndexes ( ) , quadIndexes . isSet ) ; fmt ( buff , ""prefixTableBaseName"" , getPrefixTableBaseName ( ) , prefixTableBaseName . isSet ) ; fmt ( buff , ""primaryIndexPrefix"" , getPrimaryIndexPrefix ( ) , primaryIndexPrefix . isSet ) ; fmt ( buff , ""prefixIndexes"" , getPrefixIndexes ( ) , prefixIndexes . isSet ) ; return buff . toString ( ) ; } private void fmt ( StringBuilder buff , String name , String [ ] strings , boolean isSet ) { String dftStr = """" ; if ( ! isSet ) dftStr = ""dft:"" ; buff . append ( String . format ( ""%-20s   %s[%s]\n"" , name , dftStr , String . join ( "", "" , strings ) ) ) ; } private void fmt ( StringBuilder buff , String name , String value , boolean isSet ) { String dftStr = """" ; if ( ! isSet ) dftStr = ""dft:"" ; buff . append ( String . format ( ""%-20s   %s%s\n"" , name , dftStr , value ) ) ; } private void fmt ( StringBuilder buff , String name , int value , boolean isSet ) { String dftStr = """" ; if ( ! isSet ) dftStr = ""dft:"" ; buff . append ( String . format ( ""%-20s   %s%s\n"" , name , dftStr , value ) ) ; } public static boolean sameValues ( StoreParams params1 , StoreParams params2 ) { if ( params1 == null && params2 == null ) return true ; if ( params1 == null ) return false ; if ( params2 == null ) return false ; if ( ! sameValues ( params1 . fileMode , params2 . fileMode ) ) return false ; if ( ! sameValues ( params1 . blockSize , params2 . blockSize ) ) return false ; if ( ! sameValues ( params1 . blockReadCacheSize , params2 . blockReadCacheSize ) ) return false ; if ( ! sameValues ( params1 . blockWriteCacheSize , params2 . blockWriteCacheSize ) ) return false ; if ( ! sameValues ( params1 . Node2NodeIdCacheSize , params2 . Node2NodeIdCacheSize ) ) return false ; if ( ! sameValues ( params1 . NodeId2NodeCacheSize , params2 . NodeId2NodeCacheSize ) ) return false ; if ( ! sameValues ( params1 . NodeMissCacheSize , params2 . NodeMissCacheSize ) ) return false ; if ( ! sameValues ( params1 . nodeTableBaseName , params2 . nodeTableBaseName ) ) return false ; if ( ! sameValues ( params1 . primaryIndexTriples , params2 . primaryIndexTriples ) ) return false ; if ( ! sameValues ( params1 . tripleIndexes , params2 . tripleIndexes ) ) return false ; if ( ! sameValues ( params1 . primaryIndexQuads , params2 . primaryIndexQuads ) ) return false ; if ( ! sameValues ( params1 . quadIndexes , params2 . quadIndexes ) ) return false ; if ( ! sameValues ( params1 . prefixTableBaseName , params2 . prefixTableBaseName ) ) return false ; if ( ! sameValues ( params1 . primaryIndexPrefix , params2 . primaryIndexPrefix ) ) return false ; if ( ! sameValues ( params1 . prefixIndexes , params2 . prefixIndexes ) ) return false ; return true ; } private static < X > boolean sameValues ( Item < X > item1 , Item < X > item2 ) { return Objects . deepEquals ( item1 . value , item2 . value ) ; } @ Override public int hashCode ( ) { final int prime = 31 ; int result = 1 ; result = prime * result + ( ( Node2NodeIdCacheSize == null ) ? 0 : Node2NodeIdCacheSize . hashCode ( ) ) ; result = prime * result + ( ( NodeId2NodeCacheSize == null ) ? 0 : NodeId2NodeCacheSize . hashCode ( ) ) ; result = prime * result + ( ( NodeMissCacheSize == null ) ? 0 : NodeMissCacheSize . hashCode ( ) ) ; result = prime * result + ( ( blockReadCacheSize == null ) ? 0 : blockReadCacheSize . hashCode ( ) ) ; result = prime * result + ( ( blockSize == null ) ? 0 : blockSize . hashCode ( ) ) ; result = prime * result + ( ( blockWriteCacheSize == null ) ? 0 : blockWriteCacheSize . hashCode ( ) ) ; result = prime * result + ( ( fileMode == null ) ? 0 : fileMode . hashCode ( ) ) ; result = prime * result + ( ( nodeTableBaseName == null ) ? 0 : nodeTableBaseName . hashCode ( ) ) ; result = prime * result + ( ( prefixTableBaseName == null ) ? 0 : prefixTableBaseName . hashCode ( ) ) ; result = prime * result + ( ( prefixIndexes == null ) ? 0 : prefixIndexes . hashCode ( ) ) ; result = prime * result + ( ( primaryIndexPrefix == null ) ? 0 : primaryIndexPrefix . hashCode ( ) ) ; result = prime * result + ( ( primaryIndexQuads == null ) ? 0 : primaryIndexQuads . hashCode ( ) ) ; result = prime * result + ( ( primaryIndexTriples == null ) ? 0 : primaryIndexTriples . hashCode ( ) ) ; result = prime * result + ( ( quadIndexes == null ) ? 0 : quadIndexes . hashCode ( ) ) ; result = prime * result + ( ( tripleIndexes == null ) ? 0 : tripleIndexes . hashCode ( ) ) ; return result ; } @ Override public boolean equals ( Object obj ) { if ( this == obj ) return true ; if ( obj == null ) return false ; if ( getClass ( ) != obj . getClass ( ) ) return false ; StoreParams other = ( StoreParams ) obj ; if ( Node2NodeIdCacheSize == null ) { if ( other . Node2NodeIdCacheSize != null ) return false ; } else if ( ! Node2NodeIdCacheSize . equals ( other . Node2NodeIdCacheSize ) ) return false ; if ( NodeId2NodeCacheSize == null ) { if ( other . NodeId2NodeCacheSize != null ) return false ; } else if ( ! NodeId2NodeCacheSize . equals ( other . NodeId2NodeCacheSize ) ) return false ; if ( NodeMissCacheSize == null ) { if ( other . NodeMissCacheSize != null ) return false ; } else if ( ! NodeMissCacheSize . equals ( other . NodeMissCacheSize ) ) return false ; if ( blockReadCacheSize == null ) { if ( other . blockReadCacheSize != null ) return false ; } else if ( ! blockReadCacheSize . equals ( other . blockReadCacheSize ) ) return false ; if ( blockSize == null ) { if ( other . blockSize != null ) return false ; } else if ( ! blockSize . equals ( other . blockSize ) ) return false ; if ( blockWriteCacheSize == null ) { if ( other . blockWriteCacheSize != null ) return false ; } else if ( ! blockWriteCacheSize . equals ( other . blockWriteCacheSize ) ) return false ; if ( fileMode == null ) { if ( other . fileMode != null ) return false ; } else if ( ! fileMode . equals ( other . fileMode ) ) return false ; if ( nodeTableBaseName == null ) { if ( other . nodeTableBaseName != null ) return false ; } else if ( ! nodeTableBaseName . equals ( other . nodeTableBaseName ) ) return false ; if ( prefixTableBaseName == null ) { if ( other . prefixTableBaseName != null ) return false ; } else if ( ! prefixTableBaseName . equals ( other . prefixTableBaseName ) ) return false ; if ( prefixIndexes == null ) { if ( other . prefixIndexes != null ) return false ; } else if ( ! prefixIndexes . equals ( other . prefixIndexes ) ) return false ; if ( primaryIndexPrefix == null ) { if ( other . primaryIndexPrefix != null ) return false ; } else if ( ! primaryIndexPrefix . equals ( other . primaryIndexPrefix ) ) return false ; if ( primaryIndexQuads == null ) { if ( other . primaryIndexQuads != null ) return false ; } else if ( ! primaryIndexQuads . equals ( other . primaryIndexQuads ) ) return false ; if ( primaryIndexTriples == null ) { if ( other . primaryIndexTriples != null ) return false ; } else if ( ! primaryIndexTriples . equals ( other . primaryIndexTriples ) ) return false ; if ( quadIndexes == null ) { if ( other . quadIndexes != null ) return false ; } else if ( ! quadIndexes . equals ( other . quadIndexes ) ) return false ; if ( tripleIndexes == null ) { if ( other . tripleIndexes != null ) return false ; } else if ( ! tripleIndexes . equals ( other . tripleIndexes ) ) return false ; return true ; } }",Smelly
"public class Cayenne { final static String PROPERTY_COLLECTION_SIZE = ""@size"" ; public static ObjEntity getObjEntity ( Persistent p ) { return ( p . getObjectContext ( ) != null ) ? p . getObjectContext ( ) . getEntityResolver ( ) . getObjEntity ( p ) : null ; } public static ClassDescriptor getClassDescriptor ( Persistent object ) { ObjectContext context = object . getObjectContext ( ) ; if ( context == null ) { return null ; } return context . getEntityResolver ( ) . getClassDescriptor ( object . getObjectId ( ) . getEntityName ( ) ) ; } public static PropertyDescriptor getProperty ( Persistent object , String properyName ) { ClassDescriptor descriptor = getClassDescriptor ( object ) ; if ( descriptor == null ) { return null ; } return descriptor . getProperty ( properyName ) ; } public static Object readNestedProperty ( Object o , String path ) { if ( o == null ) { return null ; } else if ( o instanceof DataObject ) { return ( ( DataObject ) o ) . readNestedProperty ( path ) ; } else if ( o instanceof Collection < ? > ) { Collection < ? > collection = ( Collection < ? > ) o ; if ( path . equals ( PROPERTY_COLLECTION_SIZE ) ) { return collection . size ( ) ; } Collection < Object > result = o instanceof List < ? > ? new ArrayList < > ( ) : new HashSet < > ( ) ; for ( Object item : collection ) { if ( item instanceof DataObject ) { DataObject cdo = ( DataObject ) item ; Object rest = cdo . readNestedProperty ( path ) ; if ( rest instanceof Collection < ? > ) { result . addAll ( ( Collection < ? > ) rest ) ; } else { result . add ( rest ) ; } } } return result ; } if ( ( null == path ) || ( 0 == path . length ( ) ) ) { throw new IllegalArgumentException ( ""the path must be supplied in order to lookup a nested property"" ) ; } int dotIndex = path . indexOf ( '.' ) ; if ( 0 == dotIndex ) { throw new IllegalArgumentException ( ""the path is invalid because it starts with a period character"" ) ; } if ( dotIndex == path . length ( ) - 1 ) { throw new IllegalArgumentException ( ""the path is invalid because it ends with a period character"" ) ; } if ( - 1 == dotIndex ) { return readSimpleProperty ( o , path ) ; } String path0 = path . substring ( 0 , dotIndex ) ; String pathRemainder = path . substring ( dotIndex + 1 ) ; if ( '+' == path0 . charAt ( path0 . length ( ) - 1 ) ) { path0 = path0 . substring ( 0 , path0 . length ( ) - 1 ) ; } Object property = readSimpleProperty ( o , path0 ) ; return readNestedProperty ( property , pathRemainder ) ; } private static final Object readSimpleProperty ( Object o , String propertyName ) { if ( o instanceof Persistent ) { PropertyDescriptor property = getProperty ( ( Persistent ) o , propertyName ) ; if ( property != null ) { return property . readProperty ( o ) ; } } return PropertyUtils . getProperty ( o , propertyName ) ; } public static String makePath ( String ... pathParts ) { StringBuilder builder = new StringBuilder ( ) ; String separator = """" ; for ( String path : pathParts ) { builder . append ( separator ) . append ( path ) ; separator = ""."" ; } return builder . toString ( ) ; } public static long longPKForObject ( Persistent dataObject ) { Object value = pkForObject ( dataObject ) ; if ( ! ( value instanceof Number ) ) { throw new CayenneRuntimeException ( ""PK is not a number: %s"" , dataObject . getObjectId ( ) ) ; } return ( ( Number ) value ) . longValue ( ) ; } public static int intPKForObject ( Persistent dataObject ) { Object value = pkForObject ( dataObject ) ; if ( ! ( value instanceof Number ) ) { throw new CayenneRuntimeException ( ""PK is not a number: %s"" , dataObject . getObjectId ( ) ) ; } return ( ( Number ) value ) . intValue ( ) ; } public static Object pkForObject ( Persistent dataObject ) { Map < String , Object > pk = extractObjectId ( dataObject ) ; if ( pk . size ( ) != 1 ) { throw new CayenneRuntimeException ( ""Expected single column PK, got %d columns, ID: %s"" , pk . size ( ) , pk ) ; } return pk . entrySet ( ) . iterator ( ) . next ( ) . getValue ( ) ; } public static Map < String , Object > compoundPKForObject ( Persistent dataObject ) { return Collections . unmodifiableMap ( extractObjectId ( dataObject ) ) ; } static Map < String , Object > extractObjectId ( Persistent dataObject ) { if ( dataObject == null ) { throw new IllegalArgumentException ( ""Null DataObject"" ) ; } ObjectId id = dataObject . getObjectId ( ) ; if ( ! id . isTemporary ( ) ) { return id . getIdSnapshot ( ) ; } if ( id . isReplacementIdAttached ( ) ) { ObjEntity objEntity = dataObject . getObjectContext ( ) . getEntityResolver ( ) . getObjEntity ( dataObject ) ; if ( objEntity != null ) { DbEntity entity = objEntity . getDbEntity ( ) ; if ( entity != null && entity . isFullReplacementIdAttached ( id ) ) { return id . getReplacementIdMap ( ) ; } } } throw new CayenneRuntimeException ( ""Can't get primary key from temporary id."" ) ; } @ SuppressWarnings ( ""unchecked"" ) public static < T > T objectForPK ( ObjectContext context , Class < T > dataObjectClass , int pk ) { return ( T ) objectForPK ( context , buildId ( context , dataObjectClass , Integer . valueOf ( pk ) ) ) ; } @ SuppressWarnings ( ""unchecked"" ) public static < T > T objectForPK ( ObjectContext context , Class < T > dataObjectClass , Object pk ) { return ( T ) objectForPK ( context , buildId ( context , dataObjectClass , pk ) ) ; } @ SuppressWarnings ( ""unchecked"" ) public static < T > T objectForPK ( ObjectContext context , Class < T > dataObjectClass , Map < String , ? > pk ) { ObjEntity entity = context . getEntityResolver ( ) . getObjEntity ( dataObjectClass ) ; if ( entity == null ) { throw new CayenneRuntimeException ( ""Non-existent ObjEntity for class: %s"" , dataObjectClass ) ; } return ( T ) objectForPK ( context , new ObjectId ( entity . getName ( ) , pk ) ) ; } public static Object objectForPK ( ObjectContext context , String objEntityName , int pk ) { return objectForPK ( context , buildId ( context , objEntityName , pk ) ) ; } public static Object objectForPK ( ObjectContext context , String objEntityName , Object pk ) { return objectForPK ( context , buildId ( context , objEntityName , pk ) ) ; } public static Object objectForPK ( ObjectContext context , String objEntityName , Map < String , ? > pk ) { if ( objEntityName == null ) { throw new IllegalArgumentException ( ""Null ObjEntity name."" ) ; } return objectForPK ( context , new ObjectId ( objEntityName , pk ) ) ; } public static Object objectForPK ( ObjectContext context , ObjectId id ) { return objectForQuery ( context , new ObjectIdQuery ( id , false , ObjectIdQuery . CACHE ) ) ; } public static Object objectForQuery ( ObjectContext context , Query query ) { List < ? > objects = context . performQuery ( query ) ; if ( objects . size ( ) == 0 ) { return null ; } else if ( objects . size ( ) > 1 ) { throw new CayenneRuntimeException ( ""Expected zero or one object, instead query matched: %d"" , objects . size ( ) ) ; } return objects . get ( 0 ) ; } static ObjectId buildId ( ObjectContext context , String objEntityName , Object pk ) { if ( pk == null ) { throw new IllegalArgumentException ( ""Null PK"" ) ; } if ( objEntityName == null ) { throw new IllegalArgumentException ( ""Null ObjEntity name."" ) ; } ObjEntity entity = context . getEntityResolver ( ) . getObjEntity ( objEntityName ) ; if ( entity == null ) { throw new CayenneRuntimeException ( ""Non-existent ObjEntity: %s"" , objEntityName ) ; } Collection < String > pkAttributes = entity . getPrimaryKeyNames ( ) ; if ( pkAttributes . size ( ) != 1 ) { throw new CayenneRuntimeException ( ""PK contains %d columns, expected 1."" , pkAttributes . size ( ) ) ; } String attr = pkAttributes . iterator ( ) . next ( ) ; return new ObjectId ( objEntityName , attr , pk ) ; } static ObjectId buildId ( ObjectContext context , Class < ? > dataObjectClass , Object pk ) { if ( pk == null ) { throw new IllegalArgumentException ( ""Null PK"" ) ; } if ( dataObjectClass == null ) { throw new IllegalArgumentException ( ""Null DataObject class."" ) ; } ObjEntity entity = context . getEntityResolver ( ) . getObjEntity ( dataObjectClass ) ; if ( entity == null ) { throw new CayenneRuntimeException ( ""Unmapped DataObject Class: %s"" , dataObjectClass . getName ( ) ) ; } Collection < String > pkAttributes = entity . getPrimaryKeyNames ( ) ; if ( pkAttributes . size ( ) != 1 ) { throw new CayenneRuntimeException ( ""PK contains %d columns, expected 1."" , pkAttributes . size ( ) ) ; } String attr = pkAttributes . iterator ( ) . next ( ) ; return new ObjectId ( entity . getName ( ) , attr , pk ) ; } protected Cayenne ( ) { } }",Smelly
"class JobNodeConfigurationGenerator { private static final Logger LOG = LoggerFactory . getLogger ( JobNodeConfigurationGenerator . class ) ; static final String CONFIG_INTERNAL_EXECUTION_PLAN = ""samza.internal.execution.plan"" ; static Config mergeConfig ( Map < String , String > originalConfig , Map < String , String > generatedConfig ) { validateJobConfigs ( originalConfig , generatedConfig ) ; Map < String , String > mergedConfig = new HashMap < > ( generatedConfig ) ; originalConfig . forEach ( ( k , v ) -> { if ( generatedConfig . containsKey ( k ) && ! Objects . equals ( generatedConfig . get ( k ) , v ) ) { LOG . info ( ""Replacing generated config for key: {} value: {} with original config value: {}"" , k , generatedConfig . get ( k ) , v ) ; } mergedConfig . put ( k , v ) ; } ) ; return Util . rewriteConfig ( new MapConfig ( mergedConfig ) ) ; } static void validateJobConfigs ( Map < String , String > originalConfig , Map < String , String > generatedConfig ) { String userConfiguredJobId = originalConfig . get ( JobConfig . JOB_ID ( ) ) ; String userConfiguredJobName = originalConfig . get ( JobConfig . JOB_NAME ( ) ) ; String generatedJobId = generatedConfig . get ( JobConfig . JOB_ID ( ) ) ; String generatedJobName = generatedConfig . get ( JobConfig . JOB_NAME ( ) ) ; if ( generatedJobName != null && userConfiguredJobName != null && ! StringUtils . equals ( generatedJobName , userConfiguredJobName ) ) { throw new SamzaException ( String . format ( ""Generated job.name = %s from app.name = %s does not match user configured job.name = %s, please configure job.name same as app.name"" , generatedJobName , originalConfig . get ( ApplicationConfig . APP_NAME ) , userConfiguredJobName ) ) ; } if ( generatedJobId != null && userConfiguredJobId != null && ! StringUtils . equals ( generatedJobId , userConfiguredJobId ) ) { throw new SamzaException ( String . format ( ""Generated job.id = %s from app.id = %s does not match user configured job.id = %s, please configure job.id same as app.id"" , generatedJobId , originalConfig . get ( ApplicationConfig . APP_ID ) , userConfiguredJobId ) ) ; } } JobConfig generateJobConfig ( JobNode jobNode , String executionPlanJson ) { if ( jobNode . isLegacyTaskApplication ( ) ) { return new JobConfig ( jobNode . getConfig ( ) ) ; } Map < String , String > generatedConfig = new HashMap < > ( ) ; generatedConfig . put ( JobConfig . JOB_NAME ( ) , jobNode . getJobName ( ) ) ; generatedConfig . put ( JobConfig . JOB_ID ( ) , jobNode . getJobId ( ) ) ; Map < String , StreamEdge > inEdges = jobNode . getInEdges ( ) ; Map < String , StreamEdge > outEdges = jobNode . getOutEdges ( ) ; Collection < OperatorSpec > reachableOperators = jobNode . getReachableOperators ( ) ; List < StoreDescriptor > stores = getStoreDescriptors ( reachableOperators ) ; Map < String , TableDescriptor > reachableTables = getReachableTables ( reachableOperators , jobNode ) ; Config originalConfig = jobNode . getConfig ( ) ; final Set < String > inputs = new HashSet < > ( ) ; final Set < String > broadcastInputs = new HashSet < > ( ) ; for ( StreamEdge inEdge : inEdges . values ( ) ) { String formattedSystemStream = inEdge . getName ( ) ; if ( inEdge . isBroadcast ( ) ) { if ( inEdge . getPartitionCount ( ) > 1 ) { broadcastInputs . add ( formattedSystemStream + ""#[0-"" + ( inEdge . getPartitionCount ( ) - 1 ) + ""]"" ) ; } else { broadcastInputs . add ( formattedSystemStream + ""#0"" ) ; } } else { inputs . add ( formattedSystemStream ) ; } } configureBroadcastInputs ( generatedConfig , originalConfig , broadcastInputs ) ; configureWindowInterval ( generatedConfig , originalConfig , reachableOperators ) ; stores . forEach ( sd -> generatedConfig . putAll ( sd . getStorageConfigs ( ) ) ) ; generatedConfig . put ( CONFIG_INTERNAL_EXECUTION_PLAN , executionPlanJson ) ; inEdges . values ( ) . stream ( ) . filter ( StreamEdge :: isIntermediate ) . forEach ( intermediateEdge -> generatedConfig . putAll ( intermediateEdge . generateConfig ( ) ) ) ; configureSerdes ( generatedConfig , inEdges , outEdges , stores , reachableTables . keySet ( ) , jobNode ) ; configureTables ( generatedConfig , originalConfig , reachableTables , inputs ) ; generatedConfig . put ( TaskConfig . INPUT_STREAMS ( ) , Joiner . on ( ',' ) . join ( inputs ) ) ; LOG . info ( ""Job {} has generated configs {}"" , jobNode . getJobNameAndId ( ) , generatedConfig ) ; return new JobConfig ( mergeConfig ( originalConfig , generatedConfig ) ) ; } private Map < String , TableDescriptor > getReachableTables ( Collection < OperatorSpec > reachableOperators , JobNode jobNode ) { return jobNode . getTables ( ) ; } private void configureBroadcastInputs ( Map < String , String > configs , Config config , Set < String > broadcastStreams ) { if ( broadcastStreams . isEmpty ( ) ) { return ; } String broadcastInputs = config . get ( TaskConfigJava . BROADCAST_INPUT_STREAMS ) ; if ( StringUtils . isNotBlank ( broadcastInputs ) ) { broadcastStreams . add ( broadcastInputs ) ; } configs . put ( TaskConfigJava . BROADCAST_INPUT_STREAMS , Joiner . on ( ',' ) . join ( broadcastStreams ) ) ; } private void configureWindowInterval ( Map < String , String > configs , Config config , Collection < OperatorSpec > reachableOperators ) { if ( ! reachableOperators . stream ( ) . anyMatch ( op -> op . getOpCode ( ) == OperatorSpec . OpCode . WINDOW || op . getOpCode ( ) == OperatorSpec . OpCode . JOIN ) ) { return ; } long triggerInterval = computeTriggerInterval ( reachableOperators ) ; LOG . info ( ""Using triggering interval: {}"" , triggerInterval ) ; configs . put ( TaskConfig . WINDOW_MS ( ) , String . valueOf ( triggerInterval ) ) ; } private long computeTriggerInterval ( Collection < OperatorSpec > reachableOperators ) { List < Long > windowTimerIntervals = reachableOperators . stream ( ) . filter ( spec -> spec . getOpCode ( ) == OperatorSpec . OpCode . WINDOW ) . map ( spec -> ( ( WindowOperatorSpec ) spec ) . getDefaultTriggerMs ( ) ) . collect ( Collectors . toList ( ) ) ; List < Long > joinTtlIntervals = reachableOperators . stream ( ) . filter ( spec -> spec instanceof JoinOperatorSpec ) . map ( spec -> ( ( JoinOperatorSpec ) spec ) . getTtlMs ( ) ) . collect ( Collectors . toList ( ) ) ; List < Long > candidateTimerIntervals = new ArrayList < > ( joinTtlIntervals ) ; candidateTimerIntervals . addAll ( windowTimerIntervals ) ; if ( candidateTimerIntervals . isEmpty ( ) ) { return - 1 ; } return MathUtil . gcd ( candidateTimerIntervals ) ; } private List < StoreDescriptor > getStoreDescriptors ( Collection < OperatorSpec > reachableOperators ) { return reachableOperators . stream ( ) . filter ( operatorSpec -> operatorSpec instanceof StatefulOperatorSpec ) . map ( operatorSpec -> ( ( StatefulOperatorSpec ) operatorSpec ) . getStoreDescriptors ( ) ) . flatMap ( Collection :: stream ) . collect ( Collectors . toList ( ) ) ; } private void configureTables ( Map < String , String > generatedConfig , Config originalConfig , Map < String , TableDescriptor > tables , Set < String > inputs ) { generatedConfig . putAll ( TableConfigGenerator . generate ( new MapConfig ( generatedConfig ) , new ArrayList < > ( tables . values ( ) ) ) ) ; tables . values ( ) . forEach ( tableDescriptor -> { if ( tableDescriptor instanceof LocalTableDescriptor ) { LocalTableDescriptor localTableDescriptor = ( LocalTableDescriptor ) tableDescriptor ; List < String > sideInputs = localTableDescriptor . getSideInputs ( ) ; if ( sideInputs != null && ! sideInputs . isEmpty ( ) ) { sideInputs . stream ( ) . map ( sideInput -> StreamUtil . getSystemStreamFromNameOrId ( originalConfig , sideInput ) ) . forEach ( systemStream -> { inputs . add ( StreamUtil . getNameFromSystemStream ( systemStream ) ) ; generatedConfig . put ( String . format ( StreamConfig . STREAM_PREFIX ( ) + StreamConfig . BOOTSTRAP ( ) , systemStream . getSystem ( ) , systemStream . getStream ( ) ) , ""true"" ) ; } ) ; } } } ) ; } private void configureSerdes ( Map < String , String > configs , Map < String , StreamEdge > inEdges , Map < String , StreamEdge > outEdges , List < StoreDescriptor > stores , Collection < String > tables , JobNode jobNode ) { Map < String , Serde > streamKeySerdes = new HashMap < > ( ) ; Map < String , Serde > streamMsgSerdes = new HashMap < > ( ) ; inEdges . keySet ( ) . forEach ( streamId -> addSerdes ( jobNode . getInputSerdes ( streamId ) , streamId , streamKeySerdes , streamMsgSerdes ) ) ; outEdges . keySet ( ) . forEach ( streamId -> addSerdes ( jobNode . getOutputSerde ( streamId ) , streamId , streamKeySerdes , streamMsgSerdes ) ) ; Map < String , Serde > storeKeySerdes = new HashMap < > ( ) ; Map < String , Serde > storeMsgSerdes = new HashMap < > ( ) ; stores . forEach ( storeDescriptor -> { storeKeySerdes . put ( storeDescriptor . getStoreName ( ) , storeDescriptor . getKeySerde ( ) ) ; storeMsgSerdes . put ( storeDescriptor . getStoreName ( ) , storeDescriptor . getMsgSerde ( ) ) ; } ) ; Map < String , Serde > tableKeySerdes = new HashMap < > ( ) ; Map < String , Serde > tableMsgSerdes = new HashMap < > ( ) ; tables . forEach ( tableId -> { addSerdes ( jobNode . getTableSerdes ( tableId ) , tableId , tableKeySerdes , tableMsgSerdes ) ; } ) ; HashSet < Serde > serdes = new HashSet < > ( streamKeySerdes . values ( ) ) ; serdes . addAll ( streamMsgSerdes . values ( ) ) ; serdes . addAll ( storeKeySerdes . values ( ) ) ; serdes . addAll ( storeMsgSerdes . values ( ) ) ; serdes . addAll ( tableKeySerdes . values ( ) ) ; serdes . addAll ( tableMsgSerdes . values ( ) ) ; SerializableSerde < Serde > serializableSerde = new SerializableSerde < > ( ) ; Base64 . Encoder base64Encoder = Base64 . getEncoder ( ) ; Map < Serde , String > serdeUUIDs = new HashMap < > ( ) ; serdes . forEach ( serde -> { String serdeName = serdeUUIDs . computeIfAbsent ( serde , s -> serde . getClass ( ) . getSimpleName ( ) + ""-"" + UUID . randomUUID ( ) . toString ( ) ) ; configs . putIfAbsent ( String . format ( SerializerConfig . SERDE_SERIALIZED_INSTANCE ( ) , serdeName ) , base64Encoder . encodeToString ( serializableSerde . toBytes ( serde ) ) ) ; } ) ; streamKeySerdes . forEach ( ( streamId , serde ) -> { String streamIdPrefix = String . format ( StreamConfig . STREAM_ID_PREFIX ( ) , streamId ) ; String keySerdeConfigKey = streamIdPrefix + StreamConfig . KEY_SERDE ( ) ; configs . put ( keySerdeConfigKey , serdeUUIDs . get ( serde ) ) ; } ) ; streamMsgSerdes . forEach ( ( streamId , serde ) -> { String streamIdPrefix = String . format ( StreamConfig . STREAM_ID_PREFIX ( ) , streamId ) ; String valueSerdeConfigKey = streamIdPrefix + StreamConfig . MSG_SERDE ( ) ; configs . put ( valueSerdeConfigKey , serdeUUIDs . get ( serde ) ) ; } ) ; storeKeySerdes . forEach ( ( storeName , serde ) -> { String keySerdeConfigKey = String . format ( StorageConfig . KEY_SERDE , storeName ) ; configs . put ( keySerdeConfigKey , serdeUUIDs . get ( serde ) ) ; } ) ; storeMsgSerdes . forEach ( ( storeName , serde ) -> { String msgSerdeConfigKey = String . format ( StorageConfig . MSG_SERDE , storeName ) ; configs . put ( msgSerdeConfigKey , serdeUUIDs . get ( serde ) ) ; } ) ; tableKeySerdes . forEach ( ( tableId , serde ) -> { String keySerdeConfigKey = String . format ( JavaTableConfig . STORE_KEY_SERDE , tableId ) ; configs . put ( keySerdeConfigKey , serdeUUIDs . get ( serde ) ) ; } ) ; tableMsgSerdes . forEach ( ( tableId , serde ) -> { String valueSerdeConfigKey = String . format ( JavaTableConfig . STORE_MSG_SERDE , tableId ) ; configs . put ( valueSerdeConfigKey , serdeUUIDs . get ( serde ) ) ; } ) ; } private void addSerdes ( KV < Serde , Serde > serdes , String streamId , Map < String , Serde > keySerdeMap , Map < String , Serde > msgSerdeMap ) { if ( serdes != null ) { if ( serdes . getKey ( ) != null && ! ( serdes . getKey ( ) instanceof NoOpSerde ) ) { keySerdeMap . put ( streamId , serdes . getKey ( ) ) ; } if ( serdes . getValue ( ) != null && ! ( serdes . getValue ( ) instanceof NoOpSerde ) ) { msgSerdeMap . put ( streamId , serdes . getValue ( ) ) ; } } } }",Smelly
"public class AnnotationCheckComposite extends Composite implements ISelectionChangedListener , ISelectionListener { private CheckAnnotationDocumentListener annotationListener ; private AnnotationCheckTreeNodeComparator comparator = new AnnotationCheckTreeNodeComparator ( ) ; private AnnotationCheckLabelProvider lableProvider ; private TreeViewer treeView ; private Text documentSource ; private ViewPart viewPart ; private Text pathToTypeSystem ; private HashMap < String , Image > images ; private Text documentSink ; private Map < String , Set < String > > typesToCheck ; private Set < String > typesToTransferUnchecked ; private CheckDocument currentDocument = null ; private String annotationMode ; private AnnotationEditor casEditor ; private List < CheckDocument > oldDocs ; private TypeSystemDescription tsd ; public AnnotationCheckComposite ( Composite parent , int style , ViewPart viewPart ) { super ( parent , style ) ; this . viewPart = viewPart ; typesToCheck = new HashMap < String , Set < String > > ( ) ; typesToTransferUnchecked = new HashSet < String > ( ) ; initGui ( ) ; annotationListener = new CheckAnnotationDocumentListener ( this ) ; } private void initGui ( ) { this . setLayout ( new FormLayout ( ) ) ; this . setSize ( 400 , 800 ) ; initDocumentSourceTextField ( ) ; initDocumentSinkTextField ( ) ; initTypeSystemPathTextField ( ) ; initTreeViewer ( ) ; viewPart . getSite ( ) . getPage ( ) . addSelectionListener ( this ) ; viewPart . getSite ( ) . setSelectionProvider ( treeView ) ; } private void initTreeViewer ( ) { FormData fdata3 = new FormData ( ) ; fdata3 . left = new FormAttachment ( 0 , 1000 , 3 ) ; fdata3 . top = new FormAttachment ( 0 , 1000 , 81 ) ; fdata3 . right = new FormAttachment ( 1000 , 1000 , - 3 ) ; fdata3 . bottom = new FormAttachment ( 1000 , 1000 , - 3 ) ; Composite comp = new Composite ( this , SWT . CENTER ) ; comp . setLayoutData ( fdata3 ) ; comp . setLayout ( new FillLayout ( ) ) ; treeView = new TreeViewer ( comp , SWT . MULTI | SWT . H_SCROLL | SWT . V_SCROLL ) ; AnnotationCheckContentProvider provider = new AnnotationCheckContentProvider ( ) ; treeView . setContentProvider ( provider ) ; treeView . getControl ( ) . addKeyListener ( new KeyAdapter ( ) { @ Override public void keyPressed ( KeyEvent e ) { char c = e . character ; if ( c == '4' || c == '5' ) { if ( c == '4' ) { accept ( ) ; } else if ( c == '5' ) { reject ( true ) ; } } } } ) ; treeView . setComparator ( new FeatureCheckTreeNodeComparator ( ) ) ; treeView . getTree ( ) . addMouseListener ( new MouseAdapter ( ) { @ Override public void mouseDown ( MouseEvent e ) { Object source = e . getSource ( ) ; if ( source instanceof Tree && e . button == 3 ) { Tree tree = ( Tree ) source ; Composite composite = tree . getParent ( ) . getParent ( ) ; TreeSelection teeSelection = ( TreeSelection ) treeView . getSelection ( ) ; Object node = teeSelection . getFirstElement ( ) ; Display display = Display . getDefault ( ) ; Shell shell = new Shell ( display , SWT . RESIZE | SWT . APPLICATION_MODAL | SWT . DIALOG_TRIM ) ; if ( node instanceof AnnotationCheckTreeNode && ! ( node instanceof FeatureCheckTreeNode ) ) { changeType ( shell , composite , node ) ; } if ( node instanceof AnnotationCheckTreeNode && node instanceof FeatureCheckTreeNode ) { changeFeature ( shell , node ) ; } } } } ) ; lableProvider = new AnnotationCheckLabelProvider ( this ) ; treeView . setLabelProvider ( lableProvider ) ; } private void initTypeSystemPathTextField ( ) { pathToTypeSystem = new Text ( this , SWT . SINGLE | SWT . BORDER ) ; FormData fdata2 = new FormData ( ) ; fdata2 . width = 200 ; fdata2 . left = new FormAttachment ( 0 , 1000 , 5 ) ; fdata2 . top = new FormAttachment ( 0 , 1000 , 55 ) ; fdata2 . right = new FormAttachment ( 1000 , 1000 , - 5 ) ; pathToTypeSystem . setLayoutData ( fdata2 ) ; pathToTypeSystem . setToolTipText ( ""Type System..."" ) ; pathToTypeSystem . setMessage ( ""Type System..."" ) ; DropTarget dt1 = new DropTarget ( pathToTypeSystem , DND . DROP_DEFAULT | DND . DROP_MOVE ) ; dt1 . setTransfer ( new Transfer [ ] { FileTransfer . getInstance ( ) } ) ; dt1 . addDropListener ( new DropTargetAdapter ( ) { @ Override public void drop ( DropTargetEvent event ) { String fileList [ ] = null ; FileTransfer ft = FileTransfer . getInstance ( ) ; if ( ft . isSupportedType ( event . currentDataType ) ) { fileList = ( String [ ] ) event . data ; } if ( fileList != null && fileList . length > 0 ) { String fileString = fileList [ 0 ] ; pathToTypeSystem . setText ( fileString ) ; } } } ) ; } private void initDocumentSinkTextField ( ) { documentSink = new Text ( this , SWT . SINGLE | SWT . BORDER ) ; FormData fdatag = new FormData ( ) ; fdatag . width = 200 ; fdatag . left = new FormAttachment ( 0 , 1000 , 5 ) ; fdatag . top = new FormAttachment ( 0 , 1000 , 30 ) ; fdatag . right = new FormAttachment ( 1000 , 1000 , - 5 ) ; documentSink . setLayoutData ( fdatag ) ; documentSink . setToolTipText ( ""Document gold output folder..."" ) ; documentSink . setMessage ( ""Document gold output folder..."" ) ; DropTarget dtg = new DropTarget ( documentSink , DND . DROP_DEFAULT | DND . DROP_MOVE ) ; dtg . setTransfer ( new Transfer [ ] { FileTransfer . getInstance ( ) } ) ; dtg . addDropListener ( new DropTargetAdapter ( ) { @ Override public void drop ( DropTargetEvent event ) { String fileList [ ] = null ; FileTransfer ft = FileTransfer . getInstance ( ) ; if ( ft . isSupportedType ( event . currentDataType ) ) { fileList = ( String [ ] ) event . data ; } if ( fileList != null && fileList . length > 0 ) { String fileString = fileList [ 0 ] ; documentSink . setText ( fileString ) ; } } } ) ; } private void initDocumentSourceTextField ( ) { documentSource = new Text ( this , SWT . SINGLE | SWT . BORDER ) ; FormData fdata1 = new FormData ( ) ; fdata1 . width = 200 ; fdata1 . left = new FormAttachment ( 0 , 1000 , 5 ) ; fdata1 . top = new FormAttachment ( 0 , 1000 , 5 ) ; fdata1 . right = new FormAttachment ( 1000 , 1000 , - 5 ) ; documentSource . setLayoutData ( fdata1 ) ; documentSource . setToolTipText ( ""Document source folder..."" ) ; documentSource . setMessage ( ""Document source folder..."" ) ; DropTarget dt = new DropTarget ( documentSource , DND . DROP_DEFAULT | DND . DROP_MOVE ) ; dt . setTransfer ( new Transfer [ ] { FileTransfer . getInstance ( ) } ) ; dt . addDropListener ( new DropTargetAdapter ( ) { @ Override public void drop ( DropTargetEvent event ) { String fileList [ ] = null ; FileTransfer ft = FileTransfer . getInstance ( ) ; if ( ft . isSupportedType ( event . currentDataType ) ) { fileList = ( String [ ] ) event . data ; } if ( fileList != null && fileList . length > 0 ) { String fileString = fileList [ 0 ] ; documentSource . setText ( fileString ) ; } } } ) ; } private void changeType ( Shell shell , Composite composite , Object node ) { AnnotationCheckComposite annotCheckCompo = null ; if ( ! ( composite instanceof AnnotationCheckComposite ) ) { return ; } annotCheckCompo = ( AnnotationCheckComposite ) composite ; shell . setText ( ""Change annotation type"" ) ; TypeSystemDescription tsd = annotCheckCompo . getTypeSystemDescription ( ) ; SelectTypesDialogCheck dialog = new SelectTypesDialogCheck ( shell , tsd , null , false , SWT . SINGLE , false ) ; String newTypeName = null ; if ( dialog . open ( ) == Window . OK ) { newTypeName = dialog . getChoosenType ( ) ; } if ( newTypeName != null ) { AnnotationCheckTreeNode annotCheckTreeNode = ( AnnotationCheckTreeNode ) node ; CheckAnnotation checkAnnot = ( CheckAnnotation ) annotCheckTreeNode . getElement ( ) ; checkAnnot . setTypeName ( newTypeName ) ; String [ ] split = newTypeName . split ( ""\\."" ) ; String shortTypeName = split [ split . length - 1 ] ; checkAnnot . setShortType ( shortTypeName ) ; treeView . refresh ( ) ; return ; } } private void changeFeature ( Shell shell , Object node ) { FeatureCheckTreeNode featTreeNode = ( FeatureCheckTreeNode ) node ; shell . setText ( ""Change value of feature"" ) ; Type range = featTreeNode . getFeature ( ) . getRange ( ) ; IInputValidator validator = new ChangeFeatureValidator ( range ) ; InputDialog dialog = new InputDialog ( getShell ( ) , ""Define new feature value"" , ""New feature value:"" , """" , validator ) ; if ( dialog . open ( ) == Window . OK ) { featTreeNode . setValue ( dialog . getValue ( ) ) ; treeView . refresh ( ) ; return ; } } @ Override public void dispose ( ) { super . dispose ( ) ; viewPart . getSite ( ) . getPage ( ) . removeSelectionListener ( this ) ; Collection < Image > values = images . values ( ) ; for ( Image image : values ) { image . dispose ( ) ; } } public Image getImage ( String name ) { if ( images == null ) { initImages ( ) ; } return images . get ( name ) ; } private void initImages ( ) { images = new HashMap < String , Image > ( ) ; ImageDescriptor desc ; Image image ; String name ; desc = RutaAddonsPlugin . getImageDescriptor ( ""/icons/accept.png"" ) ; image = desc . createImage ( ) ; name = ""accept"" ; images . put ( name , image ) ; desc = RutaAddonsPlugin . getImageDescriptor ( ""/icons/delete.png"" ) ; image = desc . createImage ( ) ; name = ""delete"" ; images . put ( name , image ) ; desc = RutaAddonsPlugin . getImageDescriptor ( ""/icons/help.png"" ) ; image = desc . createImage ( ) ; name = ""help"" ; images . put ( name , image ) ; desc = RutaAddonsPlugin . getImageDescriptor ( ""/icons/bullet_blue.png"" ) ; image = desc . createImage ( ) ; name = ""feature"" ; images . put ( name , image ) ; desc = RutaAddonsPlugin . getImageDescriptor ( ""/icons/folder_page.png"" ) ; image = desc . createImage ( ) ; name = ""folder"" ; images . put ( name , image ) ; } @ Override public void selectionChanged ( IWorkbenchPart part , ISelection selection ) { if ( part instanceof AnnotationCheckView ) { if ( selection instanceof TreeSelection ) { TreeSelection ts = ( TreeSelection ) selection ; if ( ts . getFirstElement ( ) instanceof FeatureCheckTreeNode ) { return ; } if ( ts . getFirstElement ( ) instanceof AnnotationCheckTreeNode ) { AnnotationCheckTreeNode firstElement = ( AnnotationCheckTreeNode ) ts . getFirstElement ( ) ; CheckElement element = firstElement . getElement ( ) ; int begin = 0 ; int end = 0 ; CheckDocument newDoc = null ; if ( element instanceof CheckAnnotation ) { begin = ( ( CheckAnnotation ) element ) . getBegin ( ) ; end = ( ( CheckAnnotation ) element ) . getEnd ( ) ; newDoc = ( ( CheckDocument ) firstElement . getParent ( ) . getElement ( ) ) ; } else if ( element instanceof CheckDocument ) { newDoc = ( ( CheckDocument ) element ) ; } else { return ; } if ( casEditor != null && casEditor . getDocumentProvider ( ) != null && casEditor . getDocument ( ) != null ) { IFile file = ( ( FileEditorInput ) casEditor . getEditorInput ( ) ) . getFile ( ) ; if ( ! newDoc . source . equals ( file . getLocation ( ) . toOSString ( ) ) ) { casEditor . getDocument ( ) . removeChangeListener ( annotationListener ) ; casEditor = CheckAnnotationUtils . openInCasEditor ( new File ( newDoc . source ) , begin , end ) ; casEditor . getDocument ( ) . addChangeListener ( annotationListener ) ; } else { casEditor . selectAndReveal ( begin , end - begin ) ; } } else { casEditor = CheckAnnotationUtils . openInCasEditor ( new File ( newDoc . source ) , begin , end ) ; casEditor . getDocument ( ) . addChangeListener ( annotationListener ) ; } setAnnotationMode ( annotationMode ) ; Iterator < Type > typeIterator = casEditor . getDocument ( ) . getCAS ( ) . getTypeSystem ( ) . getTypeIterator ( ) ; while ( typeIterator . hasNext ( ) ) { Type type = typeIterator . next ( ) ; boolean contains = typesToCheck . containsKey ( type . getName ( ) ) ; casEditor . setShownAnnotationType ( type , contains ) ; } currentDocument = newDoc ; treeView . getControl ( ) . setFocus ( ) ; } } } } @ Override public void selectionChanged ( SelectionChangedEvent arg0 ) { } public void restoreState ( IMemento memento ) { if ( memento == null ) return ; IMemento dir = memento . getChild ( ""documentSource"" ) ; if ( dir != null ) { String id = dir . getID ( ) ; documentSource . setText ( id ) ; } IMemento dir2 = memento . getChild ( ""documentSink"" ) ; if ( dir2 != null ) { String id = dir2 . getID ( ) ; documentSink . setText ( id ) ; } IMemento tsName = memento . getChild ( ""typeSystem"" ) ; if ( tsName != null ) { String id = tsName . getID ( ) ; pathToTypeSystem . setText ( id ) ; } IMemento selectedTypes = memento . getChild ( ""typesToCheck"" ) ; if ( selectedTypes != null ) { typesToCheck = new HashMap < String , Set < String > > ( ) ; for ( IMemento mementoTypesToCheck : selectedTypes . getChildren ( selectedTypes . getID ( ) ) ) { String typeName = mementoTypesToCheck . getID ( ) ; Set < String > features = new HashSet < String > ( ) ; for ( IMemento mementoFeature : mementoTypesToCheck . getChildren ( ""feature"" ) ) { features . add ( mementoFeature . getID ( ) ) ; } typesToCheck . put ( typeName , features ) ; } } IMemento uncheckedTypes = memento . getChild ( ""typesToTransferUnchecked"" ) ; if ( uncheckedTypes != null ) { typesToTransferUnchecked = new HashSet < String > ( ) ; for ( IMemento mementoUnchecked : uncheckedTypes . getChildren ( uncheckedTypes . getID ( ) ) ) { String typeName = mementoUnchecked . getID ( ) ; typesToTransferUnchecked . add ( typeName ) ; } } } public void saveState ( IMemento memento ) { memento . createChild ( ""documentSource"" , documentSource . getText ( ) ) ; memento . createChild ( ""documentSink"" , documentSink . getText ( ) ) ; memento . createChild ( ""typeSystem"" , pathToTypeSystem . getText ( ) ) ; IMemento selectedTypesMemento = memento . createChild ( ""typesToCheck"" , ""type"" ) ; for ( Entry < String , Set < String > > checkedTypeEntry : typesToCheck . entrySet ( ) ) { IMemento selectedTypeMemento = selectedTypesMemento . createChild ( ""type"" , checkedTypeEntry . getKey ( ) ) ; for ( String feature : checkedTypeEntry . getValue ( ) ) { selectedTypeMemento . createChild ( ""feature"" , feature ) ; } } IMemento uncheckTypesMemento = memento . createChild ( ""typesToTransferUnchecked"" , ""unchecked"" ) ; for ( String uncheckedTypeName : typesToTransferUnchecked ) { uncheckTypesMemento . createChild ( ""unchecked"" , uncheckedTypeName ) ; } } public TreeViewer getTreeViewer ( ) { return treeView ; } public String getDocumentSource ( ) { return documentSource . getText ( ) ; } public String getDocumentSink ( ) { return documentSink . getText ( ) ; } public String getPathToTypeSystem ( ) { return pathToTypeSystem . getText ( ) ; } public Map < String , Set < String > > getCheckedTypes ( ) { return typesToCheck ; } public void setTypesToCheck ( Map < String , Set < String > > typesToCheck ) { this . typesToCheck = typesToCheck ; } public void reject ( boolean doMove ) { TreeSelection selection = ( TreeSelection ) treeView . getSelection ( ) ; AnnotationCheckTreeNode firstElement = ( AnnotationCheckTreeNode ) selection . getFirstElement ( ) ; if ( firstElement == null ) { return ; } firstElement . getElement ( ) . checked = true ; firstElement . getElement ( ) . keep = false ; if ( doMove ) { moveToNext ( ) ; } treeView . refresh ( ) ; } public void accept ( ) { TreeSelection selection = ( TreeSelection ) treeView . getSelection ( ) ; AnnotationCheckTreeNode firstElement = ( AnnotationCheckTreeNode ) selection . getFirstElement ( ) ; if ( firstElement == null ) { return ; } firstElement . getElement ( ) . checked = true ; firstElement . getElement ( ) . keep = true ; List < AnnotationCheckTreeNode > siblings = Arrays . asList ( firstElement . getParent ( ) . getChildren ( ) ) ; int indexOfFirstElement = siblings . indexOf ( firstElement ) ; CheckAnnotation firstElementAnnotation = ( CheckAnnotation ) firstElement . getElement ( ) ; moveToNext ( ) ; for ( int i = indexOfFirstElement + 1 ; i < siblings . size ( ) ; i ++ ) { CheckElement nextSiblingCE = siblings . get ( i ) . getElement ( ) ; if ( nextSiblingCE instanceof CheckAnnotation ) { CheckAnnotation nextSibling = ( CheckAnnotation ) nextSiblingCE ; if ( nextSibling . getBegin ( ) == firstElementAnnotation . getBegin ( ) && nextSibling . getEnd ( ) == firstElementAnnotation . getEnd ( ) ) { reject ( true ) ; } else { break ; } if ( i == siblings . size ( ) - 1 ) { IAnnotationCheckTreeNode parent = siblings . get ( 0 ) . getParent ( ) ; parent . getElement ( ) . checked = true ; parent . getElement ( ) . keep = true ; } } } treeView . refresh ( ) ; } public void moveToNext ( ) { TreeSelection selection = ( TreeSelection ) treeView . getSelection ( ) ; IAnnotationCheckTreeNode parent = null ; AnnotationCheckTreeNode firstElement = null ; if ( selection . getFirstElement ( ) instanceof FeatureCheckTreeNode ) { return ; } firstElement = ( AnnotationCheckTreeNode ) selection . getFirstElement ( ) ; parent = firstElement . getParent ( ) ; IAnnotationCheckTreeNode [ ] children = parent . getChildren ( ) ; List < IAnnotationCheckTreeNode > list = Arrays . asList ( children ) ; int indexOf = list . indexOf ( firstElement ) ; IAnnotationCheckTreeNode brother = null ; IAnnotationCheckTreeNode uncle = parent ; if ( list == null || list . isEmpty ( ) ) { } else if ( indexOf == - 1 ) { brother = list . get ( 0 ) ; } else if ( firstElement . getElement ( ) instanceof CheckDocument && indexOf < list . size ( ) - 1 ) { uncle = list . get ( indexOf + 1 ) ; if ( uncle . getChildren ( ) . length > 0 ) { brother = uncle . getChildren ( ) [ 0 ] ; } } else if ( indexOf < list . size ( ) - 1 ) { brother = list . get ( indexOf + 1 ) ; } else if ( firstElement . getElement ( ) instanceof CheckAnnotation ) { brother = null ; IAnnotationCheckTreeNode [ ] children2 = parent . getParent ( ) . getChildren ( ) ; List < IAnnotationCheckTreeNode > list2 = Arrays . asList ( children2 ) ; int indexOf2 = list2 . indexOf ( parent ) ; if ( list2 == null || list2 . isEmpty ( ) ) { } else if ( indexOf2 == - 1 ) { uncle = list2 . get ( 0 ) ; } else if ( indexOf2 < list2 . size ( ) - 1 ) { uncle = list2 . get ( indexOf2 + 1 ) ; if ( uncle . getChildren ( ) . length != 0 ) { brother = uncle . getChildren ( ) [ 0 ] ; } } } TreePath treePath = null ; if ( brother == null ) { treePath = new TreePath ( new Object [ ] { treeView . getInput ( ) , uncle } ) ; } else { treePath = new TreePath ( new Object [ ] { treeView . getInput ( ) , uncle , brother } ) ; } final TreeSelection newSelection = new TreeSelection ( treePath ) ; treeView . setSelection ( newSelection , true ) ; treeView . expandToLevel ( ( ( AnnotationCheckTreeNode ) newSelection . getFirstElement ( ) ) . getParent ( ) , TreeViewer . ALL_LEVELS ) ; if ( firstElement . getElement ( ) instanceof CheckAnnotation ) { boolean allChecked = true ; boolean oneKeep = false ; for ( IAnnotationCheckTreeNode each : list ) { CheckElement element = each . getElement ( ) ; allChecked &= element . checked ; oneKeep |= element . keep ; } parent . getElement ( ) . checked = allChecked ; parent . getElement ( ) . keep = oneKeep ; } } public void save ( ) { AnnotationCheckTreeNode root = ( AnnotationCheckTreeNode ) treeView . getInput ( ) ; AnnotationCheckTreeNode [ ] children = root . getChildren ( ) ; List < CheckDocument > docs = new ArrayList < CheckDocument > ( oldDocs ) ; TypeSystemDescription tsd = getTypeSystemDescription ( ) ; CAS casSource = null ; CAS cas = null ; try { cas = CasCreationUtils . createCas ( tsd , null , new FsIndexDescription [ 0 ] ) ; casSource = CasCreationUtils . createCas ( tsd , null , new FsIndexDescription [ 0 ] ) ; } catch ( ResourceInitializationException e ) { RutaAddonsPlugin . error ( e ) ; } String goldFolderLocation = documentSink . getText ( ) ; for ( AnnotationCheckTreeNode each : children ) { CheckDocument cd = ( CheckDocument ) each . getElement ( ) ; if ( cd . checked && cd . keep ) { cas . reset ( ) ; casSource . reset ( ) ; File oldFile = new File ( cd . source ) ; File goldFile = new File ( goldFolderLocation , oldFile . getName ( ) ) ; try { XmiCasDeserializer . deserialize ( new FileInputStream ( oldFile ) , casSource , true ) ; } catch ( FileNotFoundException e ) { RutaAddonsPlugin . error ( e ) ; } catch ( SAXException e ) { RutaAddonsPlugin . error ( e ) ; } catch ( IOException e ) { RutaAddonsPlugin . error ( e ) ; } try { if ( goldFile . exists ( ) ) { XmiCasDeserializer . deserialize ( new FileInputStream ( goldFile ) , cas , false ) ; } else { String documentText = casSource . getDocumentText ( ) ; cas . setDocumentText ( documentText ) ; } } catch ( FileNotFoundException e ) { RutaAddonsPlugin . error ( e ) ; } catch ( SAXException e ) { RutaAddonsPlugin . error ( e ) ; } catch ( IOException e ) { RutaAddonsPlugin . error ( e ) ; } CasCopier cc = new CasCopier ( casSource , cas ) ; for ( String uncheckedTypeName : typesToTransferUnchecked ) { Type type = cas . getTypeSystem ( ) . getType ( uncheckedTypeName ) ; if ( type != null ) { for ( AnnotationFS annot : casSource . getAnnotationIndex ( type ) ) { FeatureStructure copyFs = cc . copyFs ( annot ) ; cas . addFsToIndexes ( copyFs ) ; } } } AnnotationCheckTreeNode [ ] annotationNodes = each . getChildren ( ) ; for ( AnnotationCheckTreeNode eachAN : annotationNodes ) { CheckAnnotation ca = ( CheckAnnotation ) eachAN . getElement ( ) ; if ( ca . checked && ca . keep ) { TypeSystem ts = casEditor . getDocument ( ) . getCAS ( ) . getTypeSystem ( ) ; Type type = ts . getType ( ca . getTypeName ( ) ) ; if ( type != null ) { AnnotationFS annotFS = ca . toAnnotationFS ( cas , type ) ; if ( eachAN . hasChildren ( ) ) { FeatureCheckTreeNode [ ] featureNodes = ( FeatureCheckTreeNode [ ] ) eachAN . getChildren ( ) ; for ( FeatureCheckTreeNode featureNode : featureNodes ) { Feature feature = featureNode . getFeature ( ) ; try { annotFS . setFeatureValueFromString ( feature , featureNode . getValue ( ) ) ; } catch ( Exception e ) { continue ; } } } cas . addFsToIndexes ( annotFS ) ; } } } try { CheckAnnotationUtils . writeXmi ( cas , goldFile ) ; } catch ( Exception e ) { RutaAddonsPlugin . error ( e ) ; } cd . checkedTypes . addAll ( typesToCheck . keySet ( ) ) ; if ( ! docs . contains ( cd ) ) { docs . add ( cd ) ; } } File dataFile = new File ( goldFolderLocation , ""data.xml"" ) ; try { CheckDocumentXMLUtils . write ( docs , dataFile ) ; } catch ( IOException e ) { RutaAddonsPlugin . error ( e ) ; } } IPath goldPath = Path . fromOSString ( goldFolderLocation ) ; IContainer containerForLocation = ResourcesPlugin . getWorkspace ( ) . getRoot ( ) . getContainerForLocation ( goldPath ) ; try { containerForLocation . refreshLocal ( IResource . DEPTH_ONE , new NullProgressMonitor ( ) ) ; } catch ( CoreException e ) { RutaAddonsPlugin . error ( e ) ; } } public void setAnnotationMode ( String typeString ) { this . annotationMode = typeString ; if ( casEditor != null && casEditor . getDocument ( ) != null && typeString != null ) { Type type = casEditor . getDocument ( ) . getCAS ( ) . getTypeSystem ( ) . getType ( typeString ) ; casEditor . setAnnotationMode ( type ) ; } } public void addAnnotations ( Collection < AnnotationFS > annotations ) { AnnotationCheckRootNode root = ( AnnotationCheckRootNode ) treeView . getInput ( ) ; AnnotationCheckTreeNode [ ] children = root . getChildren ( ) ; for ( AnnotationCheckTreeNode docNode : children ) { if ( docNode . getElement ( ) . equals ( currentDocument ) ) { List < AnnotationCheckTreeNode > annotationList = new ArrayList < AnnotationCheckTreeNode > ( Arrays . asList ( docNode . getChildren ( ) ) ) ; for ( AnnotationFS eachAnnotation : annotations ) { CheckElement ac = new CheckAnnotation ( eachAnnotation ) ; ac . checked = true ; ac . keep = true ; AnnotationCheckTreeNode anode = new AnnotationCheckTreeNode ( docNode , ac ) ; annotationList . add ( anode ) ; } Collections . sort ( annotationList , comparator ) ; docNode . setChildren ( annotationList ) ; treeView . refresh ( docNode ) ; break ; } } } public void removeAnnotations ( Collection < AnnotationFS > annotations ) { AnnotationCheckRootNode root = ( AnnotationCheckRootNode ) treeView . getInput ( ) ; AnnotationCheckTreeNode [ ] children = root . getChildren ( ) ; for ( AnnotationCheckTreeNode docNode : children ) { if ( docNode . getElement ( ) . equals ( currentDocument ) ) { AnnotationCheckTreeNode [ ] achildren = docNode . getChildren ( ) ; for ( AnnotationCheckTreeNode anode : achildren ) { CheckAnnotation checkAnnotation = ( CheckAnnotation ) anode . getElement ( ) ; for ( AnnotationFS eachAnnotation : annotations ) { if ( eachAnnotation . getBegin ( ) == checkAnnotation . getBegin ( ) && eachAnnotation . getEnd ( ) == checkAnnotation . getBegin ( ) && eachAnnotation . getType ( ) . getName ( ) . equals ( checkAnnotation . getTypeName ( ) ) ) { checkAnnotation . checked = true ; checkAnnotation . keep = false ; } } } treeView . refresh ( docNode ) ; break ; } } } public void updateAnnotations ( Collection < AnnotationFS > annotations ) { } public void setOldDocs ( List < CheckDocument > docs ) { this . oldDocs = docs ; } public TypeSystemDescription getTypeSystemDescription ( ) { refreshTypeSystem ( ) ; return tsd ; } public void refreshTypeSystem ( ) { try { String typeSystem = getPathToTypeSystem ( ) ; TypeSystemDescription tsd = UIMAFramework . getXMLParser ( ) . parseTypeSystemDescription ( new XMLInputSource ( new File ( typeSystem ) ) ) ; tsd . resolveImports ( ) ; this . tsd = tsd ; } catch ( InvalidXMLException e ) { e . printStackTrace ( ) ; } catch ( IOException e ) { e . printStackTrace ( ) ; } } public Map < String , Set < String > > getUncheckedTypes ( ) { Map < String , Set < String > > map = new HashMap < String , Set < String > > ( ) ; for ( String entry : typesToTransferUnchecked ) { map . put ( entry , null ) ; } return map ; } public void setUncheckedTypes ( Set < String > typesToTransferUnchecked ) { this . typesToTransferUnchecked = typesToTransferUnchecked ; } }",Smelly
"public class FragmentWritableBatch { static final org . slf4j . Logger logger = org . slf4j . LoggerFactory . getLogger ( FragmentWritableBatch . class ) ; private static RecordBatchDef EMPTY_DEF = RecordBatchDef . newBuilder ( ) . setRecordCount ( 0 ) . build ( ) ; private final ByteBuf [ ] buffers ; private final FragmentRecordBatch header ; public FragmentWritableBatch ( final boolean isLast , final QueryId queryId , final int sendMajorFragmentId , final int sendMinorFragmentId , final int receiveMajorFragmentId , final int receiveMinorFragmentId , final WritableBatch batch ) { this ( isLast , queryId , sendMajorFragmentId , sendMinorFragmentId , receiveMajorFragmentId , new int [ ] { receiveMinorFragmentId } , batch . getDef ( ) , batch . getBuffers ( ) ) ; } public FragmentWritableBatch ( final boolean isLast , final QueryId queryId , final int sendMajorFragmentId , final int sendMinorFragmentId , final int receiveMajorFragmentId , final int [ ] receiveMinorFragmentIds , final WritableBatch batch ) { this ( isLast , queryId , sendMajorFragmentId , sendMinorFragmentId , receiveMajorFragmentId , receiveMinorFragmentIds , batch . getDef ( ) , batch . getBuffers ( ) ) ; } private FragmentWritableBatch ( final boolean isLast , final QueryId queryId , final int sendMajorFragmentId , final int sendMinorFragmentId , final int receiveMajorFragmentId , final int [ ] receiveMinorFragmentId , final RecordBatchDef def , final ByteBuf ... buffers ) { this . buffers = buffers ; final FragmentRecordBatch . Builder builder = FragmentRecordBatch . newBuilder ( ) . setIsLastBatch ( isLast ) . setDef ( def ) . setQueryId ( queryId ) . setReceivingMajorFragmentId ( receiveMajorFragmentId ) . setSendingMajorFragmentId ( sendMajorFragmentId ) . setSendingMinorFragmentId ( sendMinorFragmentId ) ; for ( final int i : receiveMinorFragmentId ) { builder . addReceivingMinorFragmentId ( i ) ; } this . header = builder . build ( ) ; } public static FragmentWritableBatch getEmptyLast ( final QueryId queryId , final int sendMajorFragmentId , final int sendMinorFragmentId , final int receiveMajorFragmentId , final int receiveMinorFragmentId ) { return getEmptyLast ( queryId , sendMajorFragmentId , sendMinorFragmentId , receiveMajorFragmentId , new int [ ] { receiveMinorFragmentId } ) ; } public static FragmentWritableBatch getEmptyLast ( final QueryId queryId , final int sendMajorFragmentId , final int sendMinorFragmentId , final int receiveMajorFragmentId , final int [ ] receiveMinorFragmentIds ) { return new FragmentWritableBatch ( true , queryId , sendMajorFragmentId , sendMinorFragmentId , receiveMajorFragmentId , receiveMinorFragmentIds , EMPTY_DEF ) ; } public static FragmentWritableBatch getEmptyLastWithSchema ( final QueryId queryId , final int sendMajorFragmentId , final int sendMinorFragmentId , final int receiveMajorFragmentId , final int receiveMinorFragmentId , final BatchSchema schema ) { return getEmptyBatchWithSchema ( true , queryId , sendMajorFragmentId , sendMinorFragmentId , receiveMajorFragmentId , receiveMinorFragmentId , schema ) ; } public static FragmentWritableBatch getEmptyBatchWithSchema ( final boolean isLast , final QueryId queryId , final int sendMajorFragmentId , final int sendMinorFragmentId , final int receiveMajorFragmentId , final int receiveMinorFragmentId , final BatchSchema schema ) { final RecordBatchDef . Builder def = RecordBatchDef . newBuilder ( ) ; if ( schema != null ) { for ( final MaterializedField field : schema ) { def . addField ( field . getSerializedField ( ) ) ; } } return new FragmentWritableBatch ( isLast , queryId , sendMajorFragmentId , sendMinorFragmentId , receiveMajorFragmentId , new int [ ] { receiveMinorFragmentId } , def . build ( ) ) ; } public ByteBuf [ ] getBuffers ( ) { return buffers ; } public long getByteCount ( ) { long n = 0 ; for ( final ByteBuf buf : buffers ) { n += buf . readableBytes ( ) ; } return n ; } public FragmentRecordBatch getHeader ( ) { return header ; } }",No
" public static class JdbcFilterRule extends JdbcConverterRule { @ Deprecated public JdbcFilterRule ( JdbcConvention out ) { this ( out , RelFactories . LOGICAL_BUILDER ) ; } public JdbcFilterRule ( JdbcConvention out , RelBuilderFactory relBuilderFactory ) { super ( Filter . class , ( Predicate < Filter > ) r -> ! userDefinedFunctionInFilter ( r ) , Convention . NONE , out , relBuilderFactory , ""JdbcFilterRule"" ) ; } private static boolean userDefinedFunctionInFilter ( Filter filter ) { CheckingUserDefinedFunctionVisitor visitor = new CheckingUserDefinedFunctionVisitor ( ) ; filter . getCondition ( ) . accept ( visitor ) ; return visitor . containsUserDefinedFunction ( ) ; } public RelNode convert ( RelNode rel ) { final Filter filter = ( Filter ) rel ; return new JdbcFilter ( rel . getCluster ( ) , rel . getTraitSet ( ) . replace ( out ) , convert ( filter . getInput ( ) , filter . getInput ( ) . getTraitSet ( ) . replace ( out ) ) , filter . getCondition ( ) ) ; } ",No
"public final class ValidationError implements IValidationError { private static final long serialVersionUID = 1L ; private static final Map < String , Object > EMPTY_VARS = Collections . emptyMap ( ) ; private List < String > keys ; private Map < String , Object > vars ; private String message ; public ValidationError ( ) { } public ValidationError ( IValidator < ? > validator ) { addKey ( validator ) ; } public ValidationError ( IValidator < ? > validator , String variation ) { addKey ( validator , variation ) ; } public ValidationError ( String message ) { setMessage ( message ) ; } @ Deprecated public ValidationError addMessageKey ( String key ) { return addKey ( key ) ; } public ValidationError addKey ( String key ) { Args . notEmpty ( key , ""key"" ) ; if ( keys == null ) { keys = new ArrayList < String > ( 1 ) ; } keys . add ( key ) ; return this ; } public ValidationError addKey ( IValidator < ? > validator ) { Args . notNull ( validator , ""validator"" ) ; addKey ( Classes . simpleName ( validator . getClass ( ) ) ) ; return this ; } public ValidationError addKey ( IValidator < ? > validator , String variation ) { Args . notNull ( validator , ""validator"" ) ; String key = Classes . simpleName ( validator . getClass ( ) ) ; if ( ! Strings . isEmpty ( variation ) ) { key = key + ""."" + variation . trim ( ) ; } addKey ( key ) ; return this ; } public ValidationError setVariable ( String name , Object value ) { Args . notEmpty ( name , ""name"" ) ; getVariables ( ) . put ( name , value ) ; return this ; } public final Map < String , Object > getVariables ( ) { if ( vars == null ) { vars = new HashMap < String , Object > ( 2 ) ; } return vars ; } public final ValidationError setVariables ( Map < String , Object > vars ) { Args . notNull ( vars , ""vars"" ) ; this . vars = vars ; return this ; } @ Override public final Serializable getErrorMessage ( IErrorMessageSource messageSource ) { String errorMessage = null ; if ( keys != null ) { for ( String key : keys ) { errorMessage = messageSource . getMessage ( key , vars ) ; if ( errorMessage != null ) { break ; } } } if ( errorMessage == null && message != null ) { errorMessage = message ; } return new ValidationErrorFeedback ( this , errorMessage ) ; } public final String getMessage ( ) { return message ; } public final ValidationError setMessage ( String message ) { Args . notNull ( message , ""message"" ) ; this . message = message ; return this ; } public List < String > getKeys ( ) { if ( keys == null ) { keys = new ArrayList < String > ( ) ; } return keys ; } public void setKeys ( List < String > keys ) { this . keys = keys ; } @ Override public String toString ( ) { StringBuilder tostring = new StringBuilder ( ) ; tostring . append ( '[' ) . append ( Classes . simpleName ( getClass ( ) ) ) ; tostring . append ( "" message=["" ) . append ( message ) ; tostring . append ( ""], keys=["" ) ; if ( keys != null ) { Iterator < String > i = keys . iterator ( ) ; while ( i . hasNext ( ) ) { tostring . append ( i . next ( ) ) ; if ( i . hasNext ( ) ) { tostring . append ( "", "" ) ; } } } else { tostring . append ( ""null"" ) ; } tostring . append ( ""], variables=["" ) ; if ( vars != null ) { Iterator < Entry < String , Object > > i = vars . entrySet ( ) . iterator ( ) ; while ( i . hasNext ( ) ) { final Entry < String , Object > e = i . next ( ) ; tostring . append ( ""["" ) . append ( e . getKey ( ) ) . append ( ""="" ) . append ( e . getValue ( ) ) . append ( ""]"" ) ; if ( i . hasNext ( ) ) { tostring . append ( "","" ) ; } } } else { tostring . append ( ""null"" ) ; } tostring . append ( ""]"" ) ; tostring . append ( ""]"" ) ; return tostring . toString ( ) ; } }",No
 private class SrcFileInfo { private Path path ; private TezIndexRecord [ ] indexedRecords ; ,No
"public class WritingModeTraits implements WritingModeTraitsSetter { private Direction inlineProgressionDirection ; private Direction blockProgressionDirection ; private Direction columnProgressionDirection ; private Direction rowProgressionDirection ; private Direction shiftDirection ; private WritingMode writingMode ; private boolean explicit ; public WritingModeTraits ( ) { this ( WritingMode . LR_TB , false ) ; } public WritingModeTraits ( WritingMode writingMode , boolean explicit ) { assignWritingModeTraits ( writingMode , explicit ) ; } public Direction getInlineProgressionDirection ( ) { return inlineProgressionDirection ; } public void setInlineProgressionDirection ( Direction direction ) { this . inlineProgressionDirection = direction ; } public Direction getBlockProgressionDirection ( ) { return blockProgressionDirection ; } public void setBlockProgressionDirection ( Direction direction ) { this . blockProgressionDirection = direction ; } public Direction getColumnProgressionDirection ( ) { return columnProgressionDirection ; } public void setColumnProgressionDirection ( Direction direction ) { this . columnProgressionDirection = direction ; } public Direction getRowProgressionDirection ( ) { return rowProgressionDirection ; } public void setRowProgressionDirection ( Direction direction ) { this . rowProgressionDirection = direction ; } public Direction getShiftDirection ( ) { return shiftDirection ; } public void setShiftDirection ( Direction direction ) { this . shiftDirection = direction ; } public WritingMode getWritingMode ( ) { return writingMode ; } public boolean getExplicitWritingMode ( ) { return explicit ; } public void setWritingMode ( WritingMode writingMode , boolean explicit ) { this . writingMode = writingMode ; this . explicit = explicit ; } public void assignWritingModeTraits ( WritingMode writingMode , boolean explicit ) { writingMode . assignWritingModeTraits ( this , explicit ) ; } public static WritingModeTraitsGetter getWritingModeTraitsGetter ( org . apache . fop . fo . FONode fn ) { for ( org . apache . fop . fo . FONode n = fn ; n != null ; n = n . getParent ( ) ) { if ( n instanceof WritingModeTraitsGetter ) { return ( WritingModeTraitsGetter ) n ; } } return null ; } }",No
"public class ConnectorRestClient extends BaseRestClient { private static final long serialVersionUID = - 6870366819966266617L ; public List < ConnInstanceTO > getAllConnectors ( ) { List < ConnInstanceTO > connectors = Collections . < ConnInstanceTO > emptyList ( ) ; try { connectors = getService ( ConnectorService . class ) . list ( SyncopeConsoleSession . get ( ) . getLocale ( ) . toString ( ) ) ; } catch ( Exception e ) { LOG . error ( ""While reading connectors"" , e ) ; } return connectors ; } public ConnInstanceTO create ( final ConnInstanceTO connectorTO ) { Set < ConnConfProperty > filteredConf = filterProperties ( connectorTO . getConf ( ) ) ; connectorTO . getConf ( ) . clear ( ) ; connectorTO . getConf ( ) . addAll ( filteredConf ) ; ConnectorService service = getService ( ConnectorService . class ) ; Response response = service . create ( connectorTO ) ; return getObject ( service , response . getLocation ( ) , ConnInstanceTO . class ) ; } public List < String > getObjectClasses ( final String connectorKey ) { List < String > result = new ArrayList < > ( ) ; ConnectorService service = getService ( ConnectorService . class ) ; ConnInstanceTO connInstance = service . read ( connectorKey , SyncopeConsoleSession . get ( ) . getLocale ( ) . getLanguage ( ) ) ; if ( connInstance != null ) { CollectionUtils . collect ( service . buildObjectClassInfo ( connInstance , true ) , new Transformer < ConnIdObjectClassTO , String > ( ) { @ Override public String transform ( final ConnIdObjectClassTO input ) { return input . getType ( ) ; } } , result ) ; } return result ; } public List < String > getExtAttrNames ( final String objectClass , final String connectorKey , final Set < ConnConfProperty > conf ) { ConnInstanceTO connInstanceTO = new ConnInstanceTO ( ) ; connInstanceTO . setKey ( connectorKey ) ; connInstanceTO . getConf ( ) . addAll ( conf ) ; ConnIdObjectClassTO connIdObjectClass = IterableUtils . find ( buildObjectClassInfo ( connInstanceTO , false ) , new Predicate < ConnIdObjectClassTO > ( ) { @ Override public boolean evaluate ( final ConnIdObjectClassTO object ) { return object . getType ( ) . equalsIgnoreCase ( objectClass ) ; } } ) ; return connIdObjectClass == null ? new ArrayList < String > ( ) : connIdObjectClass . getAttributes ( ) ; } public ConnInstanceTO read ( final String key ) { ConnInstanceTO connectorTO = null ; try { connectorTO = getService ( ConnectorService . class ) . read ( key , SyncopeConsoleSession . get ( ) . getLocale ( ) . toString ( ) ) ; } catch ( SyncopeClientException e ) { LOG . error ( ""While reading a connector"" , e ) ; } return connectorTO ; } public void update ( final ConnInstanceTO connectorTO ) { Set < ConnConfProperty > filteredConf = filterProperties ( connectorTO . getConf ( ) ) ; connectorTO . getConf ( ) . clear ( ) ; connectorTO . getConf ( ) . addAll ( filteredConf ) ; getService ( ConnectorService . class ) . update ( connectorTO ) ; } public ConnInstanceTO delete ( final String key ) { ConnInstanceTO connectorTO = getService ( ConnectorService . class ) . read ( key , SyncopeConsoleSession . get ( ) . getLocale ( ) . toString ( ) ) ; getService ( ConnectorService . class ) . delete ( key ) ; return connectorTO ; } public List < ConnBundleTO > getAllBundles ( ) { List < ConnBundleTO > bundles = Collections . < ConnBundleTO > emptyList ( ) ; try { bundles = getService ( ConnectorService . class ) . getBundles ( SyncopeConsoleSession . get ( ) . getLocale ( ) . toString ( ) ) ; } catch ( SyncopeClientException e ) { LOG . error ( ""While getting connector bundles"" , e ) ; } return bundles ; } private Set < ConnConfProperty > filterProperties ( final Set < ConnConfProperty > properties ) { Set < ConnConfProperty > newProperties = new HashSet < > ( ) ; for ( ConnConfProperty property : properties ) { ConnConfProperty prop = new ConnConfProperty ( ) ; prop . setSchema ( property . getSchema ( ) ) ; prop . setOverridable ( property . isOverridable ( ) ) ; final List < Object > parsed = new ArrayList < > ( ) ; if ( property . getValues ( ) != null ) { for ( Object obj : property . getValues ( ) ) { if ( obj != null && ! obj . toString ( ) . isEmpty ( ) ) { parsed . add ( obj ) ; } } } prop . getValues ( ) . addAll ( parsed ) ; newProperties . add ( prop ) ; } return newProperties ; } public Pair < Boolean , String > check ( final ConnInstanceTO connectorTO ) { ConnInstanceTO toBeChecked = new ConnInstanceTO ( ) ; BeanUtils . copyProperties ( connectorTO , toBeChecked , new String [ ] { ""configuration"" , ""configurationMap"" } ) ; toBeChecked . getConf ( ) . addAll ( filterProperties ( connectorTO . getConf ( ) ) ) ; boolean check = false ; String errorMessage = null ; try { getService ( ConnectorService . class ) . check ( toBeChecked ) ; check = true ; } catch ( Exception e ) { LOG . error ( ""While checking {}"" , toBeChecked , e ) ; errorMessage = e . getMessage ( ) ; } return Pair . of ( check , errorMessage ) ; } public List < ConnIdObjectClassTO > buildObjectClassInfo ( final ConnInstanceTO connInstanceTO , final boolean includeSpecial ) { List < ConnIdObjectClassTO > result = Collections . emptyList ( ) ; try { result = getService ( ConnectorService . class ) . buildObjectClassInfo ( connInstanceTO , includeSpecial ) ; } catch ( Exception e ) { LOG . error ( ""While getting supported object classes"" , e ) ; } return result ; } public void reload ( ) { getService ( ConnectorService . class ) . reload ( ) ; } }",No
 static class MaxFileDescriptorResourceAnalyzer extends ResourceChecker . ResourceAnalyzer { @ Override public int getVal ( Phase phase ) { if ( ! JVM . isUnix ( ) ) { return 0 ; } JVM jvm = new JVM ( ) ; return ( int ) jvm . getMaxFileDescriptorCount ( ) ; } ,No
"public class ApproximateEvaluator < T > extends LeafEvaluator < T > { public ApproximateEvaluator ( ApproximateNode < T > node , Store db , SchemaManager schemaManager ) throws Exception { super ( node , db , schemaManager ) ; if ( db . hasIndexOn ( attributeType ) ) { idx = ( Index < T , String > ) db . getIndex ( attributeType ) ; normalizer = null ; ldapComparator = null ; } else { idx = null ; MatchingRule mr = attributeType . getEquality ( ) ; if ( mr == null ) { throw new IllegalStateException ( I18n . err ( I18n . ERR_709 , node ) ) ; } normalizer = mr . getNormalizer ( ) ; ldapComparator = mr . getLdapComparator ( ) ; } } public ApproximateNode < T > getExpression ( ) { return ( ApproximateNode < T > ) node ; } public boolean evaluate ( Entry entry ) throws LdapException { Attribute attr = entry . get ( attributeType ) ; if ( ( attr != null ) && evaluate ( attr ) ) { return true ; } if ( schemaManager . getAttributeTypeRegistry ( ) . hasDescendants ( attributeType ) ) { Iterator < AttributeType > descendants = schemaManager . getAttributeTypeRegistry ( ) . descendants ( attributeType ) ; while ( descendants . hasNext ( ) ) { AttributeType descendant = descendants . next ( ) ; attr = entry . get ( descendant ) ; if ( attr != null && evaluate ( attr ) ) { return true ; } } } return false ; } public boolean evaluate ( IndexEntry < ? , String > indexEntry ) throws LdapException { Entry entry = indexEntry . getEntry ( ) ; if ( null == entry ) { entry = db . fetch ( indexEntry . getId ( ) ) ; if ( null == entry ) { return false ; } indexEntry . setEntry ( entry ) ; } return evaluate ( entry ) ; } private boolean evaluate ( Attribute attribute ) throws LdapException { for ( Value < ? > value : attribute ) { if ( ldapComparator . compare ( value . getNormValue ( ) , node . getValue ( ) . getNormValue ( ) ) == 0 ) { return true ; } } return false ; } public String toString ( String tabs ) { StringBuilder sb = new StringBuilder ( ) ; sb . append ( tabs ) . append ( ""ApproximateEvaluator : "" ) . append ( super . toString ( ) ) . append ( ""\n"" ) ; return sb . toString ( ) ; } public String toString ( ) { return toString ( """" ) ; } }",No
"public class XATransactionIdTest extends TransactionIdTestSupport { public static XATransactionIdTest SINGLETON = new XATransactionIdTest ( ) ; public Object createObject ( ) throws Exception { XATransactionId info = new XATransactionId ( ) ; populateObject ( info ) ; return info ; } protected void populateObject ( Object object ) throws Exception { super . populateObject ( object ) ; XATransactionId info = ( XATransactionId ) object ; info . setFormatId ( 1 ) ; info . setGlobalTransactionId ( ""GlobalTransactionId:1"" . getBytes ( ) ) ; info . setBranchQualifier ( ""BranchQualifier:2"" . getBytes ( ) ) ; } }",No
"public class TikaInputStream extends TaggedInputStream { public static boolean isTikaInputStream ( InputStream stream ) { return stream instanceof TikaInputStream ; } public static TikaInputStream get ( InputStream stream , TemporaryResources tmp ) { if ( stream == null ) { throw new NullPointerException ( ""The Stream must not be null"" ) ; } if ( stream instanceof TikaInputStream ) { return ( TikaInputStream ) stream ; } else { if ( ! ( stream instanceof BufferedInputStream ) && ! ( stream instanceof ByteArrayInputStream ) ) { stream = new BufferedInputStream ( stream ) ; } return new TikaInputStream ( stream , tmp , - 1 ) ; } } public static TikaInputStream get ( InputStream stream ) { return get ( stream , new TemporaryResources ( ) ) ; } public static TikaInputStream cast ( InputStream stream ) { if ( stream instanceof TikaInputStream ) { return ( TikaInputStream ) stream ; } else { return null ; } } public static TikaInputStream get ( byte [ ] data ) { return get ( data , new Metadata ( ) ) ; } public static TikaInputStream get ( byte [ ] data , Metadata metadata ) { metadata . set ( Metadata . CONTENT_LENGTH , Integer . toString ( data . length ) ) ; return new TikaInputStream ( new ByteArrayInputStream ( data ) , new TemporaryResources ( ) , data . length ) ; } public static TikaInputStream get ( Path path ) throws IOException { return get ( path , new Metadata ( ) ) ; } public static TikaInputStream get ( Path path , Metadata metadata ) throws IOException { metadata . set ( Metadata . RESOURCE_NAME_KEY , path . getFileName ( ) . toString ( ) ) ; metadata . set ( Metadata . CONTENT_LENGTH , Long . toString ( Files . size ( path ) ) ) ; return new TikaInputStream ( path ) ; } @ Deprecated public static TikaInputStream get ( File file ) throws FileNotFoundException { return get ( file , new Metadata ( ) ) ; } @ Deprecated public static TikaInputStream get ( File file , Metadata metadata ) throws FileNotFoundException { metadata . set ( Metadata . RESOURCE_NAME_KEY , file . getName ( ) ) ; metadata . set ( Metadata . CONTENT_LENGTH , Long . toString ( file . length ( ) ) ) ; return new TikaInputStream ( file ) ; } public static TikaInputStream get ( Blob blob ) throws SQLException { return get ( blob , new Metadata ( ) ) ; } private static final int BLOB_SIZE_THRESHOLD = 1024 * 1024 ; public static TikaInputStream get ( Blob blob , Metadata metadata ) throws SQLException { long length = - 1 ; try { length = blob . length ( ) ; metadata . set ( Metadata . CONTENT_LENGTH , Long . toString ( length ) ) ; } catch ( SQLException ignore ) { } if ( 0 <= length && length <= BLOB_SIZE_THRESHOLD ) { return get ( blob . getBytes ( 1 , ( int ) length ) , metadata ) ; } else { return new TikaInputStream ( new BufferedInputStream ( blob . getBinaryStream ( ) ) , new TemporaryResources ( ) , length ) ; } } public static TikaInputStream get ( URI uri ) throws IOException { return get ( uri , new Metadata ( ) ) ; } public static TikaInputStream get ( URI uri , Metadata metadata ) throws IOException { if ( ""file"" . equalsIgnoreCase ( uri . getScheme ( ) ) ) { Path path = Paths . get ( uri ) ; if ( Files . isRegularFile ( path ) ) { return get ( path , metadata ) ; } } return get ( uri . toURL ( ) , metadata ) ; } public static TikaInputStream get ( URL url ) throws IOException { return get ( url , new Metadata ( ) ) ; } public static TikaInputStream get ( URL url , Metadata metadata ) throws IOException { if ( ""file"" . equalsIgnoreCase ( url . getProtocol ( ) ) ) { try { Path path = Paths . get ( url . toURI ( ) ) ; if ( Files . isRegularFile ( path ) ) { return get ( path , metadata ) ; } } catch ( URISyntaxException e ) { } } URLConnection connection = url . openConnection ( ) ; String path = url . getPath ( ) ; int slash = path . lastIndexOf ( '/' ) ; if ( slash + 1 < path . length ( ) ) { metadata . set ( Metadata . RESOURCE_NAME_KEY , path . substring ( slash + 1 ) ) ; } String type = connection . getContentType ( ) ; if ( type != null ) { metadata . set ( Metadata . CONTENT_TYPE , type ) ; } String encoding = connection . getContentEncoding ( ) ; if ( encoding != null ) { metadata . set ( Metadata . CONTENT_ENCODING , encoding ) ; } int length = connection . getContentLength ( ) ; if ( length >= 0 ) { metadata . set ( Metadata . CONTENT_LENGTH , Integer . toString ( length ) ) ; } return new TikaInputStream ( new BufferedInputStream ( connection . getInputStream ( ) ) , new TemporaryResources ( ) , length ) ; } private Path path ; private final TemporaryResources tmp ; private long length ; private long position = 0 ; private long mark = - 1 ; private Object openContainer ; private TikaInputStream ( Path path ) throws IOException { super ( new BufferedInputStream ( Files . newInputStream ( path ) ) ) ; this . path = path ; this . tmp = new TemporaryResources ( ) ; this . length = Files . size ( path ) ; } @ Deprecated private TikaInputStream ( File file ) throws FileNotFoundException { super ( new BufferedInputStream ( new FileInputStream ( file ) ) ) ; this . path = file . toPath ( ) ; this . tmp = new TemporaryResources ( ) ; this . length = file . length ( ) ; } private TikaInputStream ( InputStream stream , TemporaryResources tmp , long length ) { super ( stream ) ; this . path = null ; this . tmp = tmp ; this . length = length ; } public int peek ( byte [ ] buffer ) throws IOException { int n = 0 ; mark ( buffer . length ) ; int m = read ( buffer ) ; while ( m != - 1 ) { n += m ; if ( n < buffer . length ) { m = read ( buffer , n , buffer . length - n ) ; } else { m = - 1 ; } } reset ( ) ; return n ; } public Object getOpenContainer ( ) { return openContainer ; } public void setOpenContainer ( Object container ) { openContainer = container ; if ( container instanceof Closeable ) { tmp . addResource ( ( Closeable ) container ) ; } } public boolean hasFile ( ) { return path != null ; } public Path getPath ( ) throws IOException { if ( path == null ) { if ( position > 0 ) { throw new IOException ( ""Stream is already being read"" ) ; } else { path = tmp . createTempFile ( ) ; Files . copy ( in , path , REPLACE_EXISTING ) ; InputStream newStream = Files . newInputStream ( path ) ; tmp . addResource ( newStream ) ; final InputStream oldStream = in ; in = new BufferedInputStream ( newStream ) { @ Override public void close ( ) throws IOException { oldStream . close ( ) ; } } ; length = Files . size ( path ) ; } } return path ; } public File getFile ( ) throws IOException { return getPath ( ) . toFile ( ) ; } public FileChannel getFileChannel ( ) throws IOException { FileChannel channel = FileChannel . open ( getPath ( ) ) ; tmp . addResource ( channel ) ; return channel ; } public boolean hasLength ( ) { return length != - 1 ; } public long getLength ( ) throws IOException { if ( length == - 1 ) { getPath ( ) ; } return length ; } public long getPosition ( ) { return position ; } @ Override public long skip ( long ln ) throws IOException { long n = super . skip ( ln ) ; position += n ; return n ; } @ Override public void mark ( int readlimit ) { super . mark ( readlimit ) ; mark = position ; } @ Override public boolean markSupported ( ) { return true ; } @ Override public void reset ( ) throws IOException { super . reset ( ) ; position = mark ; mark = - 1 ; } @ Override public void close ( ) throws IOException { path = null ; mark = - 1 ; tmp . addResource ( in ) ; tmp . close ( ) ; } @ Override protected void afterRead ( int n ) { if ( n != - 1 ) { position += n ; } } public String toString ( ) { String str = ""TikaInputStream of "" ; if ( hasFile ( ) ) { str += path . toString ( ) ; } else { str += in . toString ( ) ; } if ( openContainer != null ) { str += "" (in "" + openContainer + "")"" ; } return str ; } }",Smelly
"public class CuratorFrameworkImpl implements CuratorFramework { private final Logger log = LoggerFactory . getLogger ( getClass ( ) ) ; private final CuratorZookeeperClient client ; private final ListenerContainer < CuratorListener > listeners ; private final ListenerContainer < UnhandledErrorListener > unhandledErrorListeners ; private final ThreadFactory threadFactory ; private final int maxCloseWaitMs ; private final BlockingQueue < OperationAndData < ? > > backgroundOperations ; private final BlockingQueue < OperationAndData < ? > > forcedSleepOperations ; private final NamespaceImpl namespace ; private final ConnectionStateManager connectionStateManager ; private final List < AuthInfo > authInfos ; private final byte [ ] defaultData ; private final FailedDeleteManager failedDeleteManager ; private final FailedRemoveWatchManager failedRemoveWatcherManager ; private final CompressionProvider compressionProvider ; private final ACLProvider aclProvider ; private final NamespaceFacadeCache namespaceFacadeCache ; private final boolean useContainerParentsIfAvailable ; private final ConnectionStateErrorPolicy connectionStateErrorPolicy ; private final AtomicLong currentInstanceIndex = new AtomicLong ( - 1 ) ; private final InternalConnectionHandler internalConnectionHandler ; private final EnsembleTracker ensembleTracker ; private final SchemaSet schemaSet ; private final boolean zk34CompatibilityMode ; private final Executor runSafeService ; private volatile ExecutorService executorService ; private final AtomicBoolean logAsErrorConnectionErrors = new AtomicBoolean ( false ) ; private static final boolean LOG_ALL_CONNECTION_ISSUES_AS_ERROR_LEVEL = ! Boolean . getBoolean ( DebugUtils . PROPERTY_LOG_ONLY_FIRST_CONNECTION_ISSUE_AS_ERROR_LEVEL ) ; interface DebugBackgroundListener { void listen ( OperationAndData < ? > data ) ; } volatile DebugBackgroundListener debugListener = null ; @ VisibleForTesting public volatile UnhandledErrorListener debugUnhandledErrorListener = null ; private final AtomicReference < CuratorFrameworkState > state ; public CuratorFrameworkImpl ( CuratorFrameworkFactory . Builder builder ) { ZookeeperFactory localZookeeperFactory = makeZookeeperFactory ( builder . getZookeeperFactory ( ) ) ; this . client = new CuratorZookeeperClient ( localZookeeperFactory , builder . getEnsembleProvider ( ) , builder . getSessionTimeoutMs ( ) , builder . getConnectionTimeoutMs ( ) , builder . getWaitForShutdownTimeoutMs ( ) , new Watcher ( ) { @ Override public void process ( WatchedEvent watchedEvent ) { CuratorEvent event = new CuratorEventImpl ( CuratorFrameworkImpl . this , CuratorEventType . WATCHED , watchedEvent . getState ( ) . getIntValue ( ) , unfixForNamespace ( watchedEvent . getPath ( ) ) , null , null , null , null , null , watchedEvent , null , null ) ; processEvent ( event ) ; } } , builder . getRetryPolicy ( ) , builder . canBeReadOnly ( ) , builder . getConnectionHandlingPolicy ( ) ) ; internalConnectionHandler = new StandardInternalConnectionHandler ( ) ; listeners = new ListenerContainer < CuratorListener > ( ) ; unhandledErrorListeners = new ListenerContainer < UnhandledErrorListener > ( ) ; backgroundOperations = new DelayQueue < OperationAndData < ? > > ( ) ; forcedSleepOperations = new LinkedBlockingQueue < > ( ) ; namespace = new NamespaceImpl ( this , builder . getNamespace ( ) ) ; threadFactory = getThreadFactory ( builder ) ; maxCloseWaitMs = builder . getMaxCloseWaitMs ( ) ; connectionStateManager = new ConnectionStateManager ( this , builder . getThreadFactory ( ) , builder . getSessionTimeoutMs ( ) , builder . getConnectionHandlingPolicy ( ) . getSimulatedSessionExpirationPercent ( ) , builder . getConnectionStateListenerManagerFactory ( ) ) ; compressionProvider = builder . getCompressionProvider ( ) ; aclProvider = builder . getAclProvider ( ) ; state = new AtomicReference < CuratorFrameworkState > ( CuratorFrameworkState . LATENT ) ; useContainerParentsIfAvailable = builder . useContainerParentsIfAvailable ( ) ; connectionStateErrorPolicy = Preconditions . checkNotNull ( builder . getConnectionStateErrorPolicy ( ) , ""errorPolicy cannot be null"" ) ; schemaSet = Preconditions . checkNotNull ( builder . getSchemaSet ( ) , ""schemaSet cannot be null"" ) ; zk34CompatibilityMode = builder . isZk34CompatibilityMode ( ) ; byte [ ] builderDefaultData = builder . getDefaultData ( ) ; defaultData = ( builderDefaultData != null ) ? Arrays . copyOf ( builderDefaultData , builderDefaultData . length ) : new byte [ 0 ] ; authInfos = buildAuths ( builder ) ; failedDeleteManager = new FailedDeleteManager ( this ) ; failedRemoveWatcherManager = new FailedRemoveWatchManager ( this ) ; namespaceFacadeCache = new NamespaceFacadeCache ( this ) ; ensembleTracker = zk34CompatibilityMode ? null : new EnsembleTracker ( this , builder . getEnsembleProvider ( ) ) ; runSafeService = makeRunSafeService ( builder ) ; } private Executor makeRunSafeService ( CuratorFrameworkFactory . Builder builder ) { if ( builder . getRunSafeService ( ) != null ) { return builder . getRunSafeService ( ) ; } ThreadFactory threadFactory = builder . getThreadFactory ( ) ; if ( threadFactory == null ) { threadFactory = ThreadUtils . newThreadFactory ( ""SafeNotifyService"" ) ; } return Executors . newSingleThreadExecutor ( threadFactory ) ; } private List < AuthInfo > buildAuths ( CuratorFrameworkFactory . Builder builder ) { ImmutableList . Builder < AuthInfo > builder1 = ImmutableList . builder ( ) ; if ( builder . getAuthInfos ( ) != null ) { builder1 . addAll ( builder . getAuthInfos ( ) ) ; } return builder1 . build ( ) ; } @ Override public CompletableFuture < Void > runSafe ( Runnable runnable ) { return CompletableFuture . runAsync ( runnable , runSafeService ) ; } @ Override public WatcherRemoveCuratorFramework newWatcherRemoveCuratorFramework ( ) { return new WatcherRemovalFacade ( this ) ; } @ Override public QuorumVerifier getCurrentConfig ( ) { return ( ensembleTracker != null ) ? ensembleTracker . getCurrentConfig ( ) : null ; } private ZookeeperFactory makeZookeeperFactory ( final ZookeeperFactory actualZookeeperFactory ) { return new ZookeeperFactory ( ) { @ Override public ZooKeeper newZooKeeper ( String connectString , int sessionTimeout , Watcher watcher , boolean canBeReadOnly ) throws Exception { ZooKeeper zooKeeper = actualZookeeperFactory . newZooKeeper ( connectString , sessionTimeout , watcher , canBeReadOnly ) ; for ( AuthInfo auth : authInfos ) { zooKeeper . addAuthInfo ( auth . getScheme ( ) , auth . getAuth ( ) ) ; } return zooKeeper ; } } ; } private ThreadFactory getThreadFactory ( CuratorFrameworkFactory . Builder builder ) { ThreadFactory threadFactory = builder . getThreadFactory ( ) ; if ( threadFactory == null ) { threadFactory = ThreadUtils . newThreadFactory ( ""Framework"" ) ; } return threadFactory ; } protected CuratorFrameworkImpl ( CuratorFrameworkImpl parent ) { client = parent . client ; listeners = parent . listeners ; unhandledErrorListeners = parent . unhandledErrorListeners ; threadFactory = parent . threadFactory ; maxCloseWaitMs = parent . maxCloseWaitMs ; backgroundOperations = parent . backgroundOperations ; forcedSleepOperations = parent . forcedSleepOperations ; connectionStateManager = parent . connectionStateManager ; defaultData = parent . defaultData ; failedDeleteManager = parent . failedDeleteManager ; failedRemoveWatcherManager = parent . failedRemoveWatcherManager ; compressionProvider = parent . compressionProvider ; aclProvider = parent . aclProvider ; namespaceFacadeCache = parent . namespaceFacadeCache ; namespace = new NamespaceImpl ( this , null ) ; state = parent . state ; authInfos = parent . authInfos ; useContainerParentsIfAvailable = parent . useContainerParentsIfAvailable ; connectionStateErrorPolicy = parent . connectionStateErrorPolicy ; internalConnectionHandler = parent . internalConnectionHandler ; schemaSet = parent . schemaSet ; zk34CompatibilityMode = parent . zk34CompatibilityMode ; ensembleTracker = null ; runSafeService = parent . runSafeService ; } @ Override public void createContainers ( String path ) throws Exception { checkExists ( ) . creatingParentContainersIfNeeded ( ) . forPath ( ZKPaths . makePath ( path , ""foo"" ) ) ; } @ Override public void clearWatcherReferences ( Watcher watcher ) { } @ Override public CuratorFrameworkState getState ( ) { return state . get ( ) ; } @ Override @ Deprecated public boolean isStarted ( ) { return state . get ( ) == CuratorFrameworkState . STARTED ; } @ Override public boolean blockUntilConnected ( int maxWaitTime , TimeUnit units ) throws InterruptedException { return connectionStateManager . blockUntilConnected ( maxWaitTime , units ) ; } @ Override public void blockUntilConnected ( ) throws InterruptedException { blockUntilConnected ( 0 , null ) ; } @ Override public ConnectionStateErrorPolicy getConnectionStateErrorPolicy ( ) { return connectionStateErrorPolicy ; } @ Override public void start ( ) { log . info ( ""Starting"" ) ; if ( ! state . compareAndSet ( CuratorFrameworkState . LATENT , CuratorFrameworkState . STARTED ) ) { throw new IllegalStateException ( ""Cannot be started more than once"" ) ; } try { connectionStateManager . start ( ) ; final ConnectionStateListener listener = new ConnectionStateListener ( ) { @ Override public void stateChanged ( CuratorFramework client , ConnectionState newState ) { if ( ConnectionState . CONNECTED == newState || ConnectionState . RECONNECTED == newState ) { logAsErrorConnectionErrors . set ( true ) ; } } @ Override public boolean doNotProxy ( ) { return true ; } } ; this . getConnectionStateListenable ( ) . addListener ( listener ) ; client . start ( ) ; executorService = Executors . newSingleThreadScheduledExecutor ( threadFactory ) ; executorService . submit ( new Callable < Object > ( ) { @ Override public Object call ( ) throws Exception { backgroundOperationsLoop ( ) ; return null ; } } ) ; if ( ensembleTracker != null ) { ensembleTracker . start ( ) ; } log . info ( schemaSet . toDocumentation ( ) ) ; } catch ( Exception e ) { ThreadUtils . checkInterrupted ( e ) ; handleBackgroundOperationException ( null , e ) ; } } @ Override public void close ( ) { log . debug ( ""Closing"" ) ; if ( state . compareAndSet ( CuratorFrameworkState . STARTED , CuratorFrameworkState . STOPPED ) ) { listeners . forEach ( new Function < CuratorListener , Void > ( ) { @ Override public Void apply ( CuratorListener listener ) { CuratorEvent event = new CuratorEventImpl ( CuratorFrameworkImpl . this , CuratorEventType . CLOSING , 0 , null , null , null , null , null , null , null , null , null ) ; try { listener . eventReceived ( CuratorFrameworkImpl . this , event ) ; } catch ( Exception e ) { ThreadUtils . checkInterrupted ( e ) ; log . error ( ""Exception while sending Closing event"" , e ) ; } return null ; } } ) ; if ( executorService != null ) { executorService . shutdownNow ( ) ; try { executorService . awaitTermination ( maxCloseWaitMs , TimeUnit . MILLISECONDS ) ; } catch ( InterruptedException e ) { Thread . currentThread ( ) . interrupt ( ) ; } } if ( ensembleTracker != null ) { ensembleTracker . close ( ) ; } listeners . clear ( ) ; unhandledErrorListeners . clear ( ) ; connectionStateManager . close ( ) ; client . close ( ) ; } } @ Override @ Deprecated public CuratorFramework nonNamespaceView ( ) { return usingNamespace ( null ) ; } @ Override public String getNamespace ( ) { String str = namespace . getNamespace ( ) ; return ( str != null ) ? str : """" ; } private void checkState ( ) { CuratorFrameworkState state = getState ( ) ; Preconditions . checkState ( state == CuratorFrameworkState . STARTED , ""Expected state [%s] was [%s]"" , CuratorFrameworkState . STARTED , state ) ; } @ Override public CuratorFramework usingNamespace ( String newNamespace ) { checkState ( ) ; return namespaceFacadeCache . get ( newNamespace ) ; } @ Override public CreateBuilder create ( ) { checkState ( ) ; return new CreateBuilderImpl ( this ) ; } @ Override public DeleteBuilder delete ( ) { checkState ( ) ; return new DeleteBuilderImpl ( this ) ; } @ Override public ExistsBuilder checkExists ( ) { checkState ( ) ; return new ExistsBuilderImpl ( this ) ; } @ Override public GetDataBuilder getData ( ) { checkState ( ) ; return new GetDataBuilderImpl ( this ) ; } @ Override public SetDataBuilder setData ( ) { checkState ( ) ; return new SetDataBuilderImpl ( this ) ; } @ Override public GetChildrenBuilder getChildren ( ) { checkState ( ) ; return new GetChildrenBuilderImpl ( this ) ; } @ Override public GetACLBuilder getACL ( ) { checkState ( ) ; return new GetACLBuilderImpl ( this ) ; } @ Override public SetACLBuilder setACL ( ) { checkState ( ) ; return new SetACLBuilderImpl ( this ) ; } @ Override public ReconfigBuilder reconfig ( ) { Preconditions . checkState ( ! isZk34CompatibilityMode ( ) , ""reconfig/config APIs are not support when running in ZooKeeper 3.4 compatibility mode"" ) ; return new ReconfigBuilderImpl ( this ) ; } @ Override public GetConfigBuilder getConfig ( ) { Preconditions . checkState ( ! isZk34CompatibilityMode ( ) , ""reconfig/config APIs are not support when running in ZooKeeper 3.4 compatibility mode"" ) ; return new GetConfigBuilderImpl ( this ) ; } @ Override public CuratorTransaction inTransaction ( ) { checkState ( ) ; return new CuratorTransactionImpl ( this ) ; } @ Override public CuratorMultiTransaction transaction ( ) { checkState ( ) ; return new CuratorMultiTransactionImpl ( this ) ; } @ Override public TransactionOp transactionOp ( ) { checkState ( ) ; return new TransactionOpImpl ( this ) ; } @ Override public Listenable < ConnectionStateListener > getConnectionStateListenable ( ) { return connectionStateManager . getListenable ( ) ; } @ Override public Listenable < CuratorListener > getCuratorListenable ( ) { return listeners ; } @ Override public Listenable < UnhandledErrorListener > getUnhandledErrorListenable ( ) { return unhandledErrorListeners ; } @ Override public void sync ( String path , Object context ) { checkState ( ) ; path = fixForNamespace ( path ) ; internalSync ( this , path , context ) ; } @ Override public SyncBuilder sync ( ) { return new SyncBuilderImpl ( this ) ; } @ Override public RemoveWatchesBuilder watches ( ) { Preconditions . checkState ( ! isZk34CompatibilityMode ( ) , ""Remove watches APIs are not support when running in ZooKeeper 3.4 compatibility mode"" ) ; return new RemoveWatchesBuilderImpl ( this ) ; } protected void internalSync ( CuratorFrameworkImpl impl , String path , Object context ) { BackgroundOperation < String > operation = new BackgroundSyncImpl ( impl , context ) ; performBackgroundOperation ( new OperationAndData < String > ( operation , path , null , null , context , null ) ) ; } @ Override public CuratorZookeeperClient getZookeeperClient ( ) { return client ; } @ Override public EnsurePath newNamespaceAwareEnsurePath ( String path ) { return namespace . newNamespaceAwareEnsurePath ( path ) ; } @ Override public SchemaSet getSchemaSet ( ) { return schemaSet ; } ACLProvider getAclProvider ( ) { return aclProvider ; } FailedDeleteManager getFailedDeleteManager ( ) { return failedDeleteManager ; } FailedRemoveWatchManager getFailedRemoveWatcherManager ( ) { return failedRemoveWatcherManager ; } RetryLoop newRetryLoop ( ) { return client . newRetryLoop ( ) ; } ZooKeeper getZooKeeper ( ) throws Exception { return client . getZooKeeper ( ) ; } CompressionProvider getCompressionProvider ( ) { return compressionProvider ; } boolean useContainerParentsIfAvailable ( ) { return useContainerParentsIfAvailable ; } < DATA_TYPE > void processBackgroundOperation ( OperationAndData < DATA_TYPE > operationAndData , CuratorEvent event ) { boolean isInitialExecution = ( event == null ) ; if ( isInitialExecution ) { performBackgroundOperation ( operationAndData ) ; return ; } boolean doQueueOperation = false ; do { if ( RetryLoop . shouldRetry ( event . getResultCode ( ) ) ) { doQueueOperation = checkBackgroundRetry ( operationAndData , event ) ; break ; } if ( operationAndData . getCallback ( ) != null ) { sendToBackgroundCallback ( operationAndData , event ) ; break ; } processEvent ( event ) ; } while ( false ) ; if ( doQueueOperation ) { queueOperation ( operationAndData ) ; } } < DATA_TYPE > boolean queueOperation ( OperationAndData < DATA_TYPE > operationAndData ) { if ( getState ( ) == CuratorFrameworkState . STARTED ) { backgroundOperations . offer ( operationAndData ) ; return true ; } return false ; } void logError ( String reason , final Throwable e ) { if ( ( reason == null ) || ( reason . length ( ) == 0 ) ) { reason = ""n/a"" ; } if ( ! Boolean . getBoolean ( DebugUtils . PROPERTY_DONT_LOG_CONNECTION_ISSUES ) || ! ( e instanceof KeeperException ) ) { if ( e instanceof KeeperException . ConnectionLossException ) { if ( LOG_ALL_CONNECTION_ISSUES_AS_ERROR_LEVEL || logAsErrorConnectionErrors . compareAndSet ( true , false ) ) { log . error ( reason , e ) ; } else { log . debug ( reason , e ) ; } } else { log . error ( reason , e ) ; } } final String localReason = reason ; unhandledErrorListeners . forEach ( new Function < UnhandledErrorListener , Void > ( ) { @ Override public Void apply ( UnhandledErrorListener listener ) { listener . unhandledError ( localReason , e ) ; return null ; } } ) ; if ( debugUnhandledErrorListener != null ) { debugUnhandledErrorListener . unhandledError ( reason , e ) ; } } String unfixForNamespace ( String path ) { return namespace . unfixForNamespace ( path ) ; } String fixForNamespace ( String path ) { return namespace . fixForNamespace ( path , false ) ; } String fixForNamespace ( String path , boolean isSequential ) { return namespace . fixForNamespace ( path , isSequential ) ; } byte [ ] getDefaultData ( ) { return defaultData ; } NamespaceFacadeCache getNamespaceFacadeCache ( ) { return namespaceFacadeCache ; } void validateConnection ( Watcher . Event . KeeperState state ) { if ( state == Watcher . Event . KeeperState . Disconnected ) { internalConnectionHandler . suspendConnection ( this ) ; } else if ( state == Watcher . Event . KeeperState . Expired ) { connectionStateManager . addStateChange ( ConnectionState . LOST ) ; } else if ( state == Watcher . Event . KeeperState . SyncConnected ) { internalConnectionHandler . checkNewConnection ( this ) ; connectionStateManager . addStateChange ( ConnectionState . RECONNECTED ) ; unSleepBackgroundOperations ( ) ; } else if ( state == Watcher . Event . KeeperState . ConnectedReadOnly ) { internalConnectionHandler . checkNewConnection ( this ) ; connectionStateManager . addStateChange ( ConnectionState . READ_ONLY ) ; } } void checkInstanceIndex ( ) { long instanceIndex = client . getInstanceIndex ( ) ; long newInstanceIndex = currentInstanceIndex . getAndSet ( instanceIndex ) ; if ( ( newInstanceIndex >= 0 ) && ( instanceIndex != newInstanceIndex ) ) { connectionStateManager . addStateChange ( ConnectionState . LOST ) ; } } Watcher . Event . KeeperState codeToState ( KeeperException . Code code ) { switch ( code ) { case AUTHFAILED : case NOAUTH : { return Watcher . Event . KeeperState . AuthFailed ; } case CONNECTIONLOSS : case OPERATIONTIMEOUT : { return Watcher . Event . KeeperState . Disconnected ; } case SESSIONEXPIRED : { return Watcher . Event . KeeperState . Expired ; } case OK : case SESSIONMOVED : { return Watcher . Event . KeeperState . SyncConnected ; } } return Watcher . Event . KeeperState . fromInt ( - 1 ) ; } WatcherRemovalManager getWatcherRemovalManager ( ) { return null ; } boolean setToSuspended ( ) { return connectionStateManager . setToSuspended ( ) ; } void addStateChange ( ConnectionState newConnectionState ) { connectionStateManager . addStateChange ( newConnectionState ) ; } @ Override public boolean isZk34CompatibilityMode ( ) { return zk34CompatibilityMode ; } EnsembleTracker getEnsembleTracker ( ) { return ensembleTracker ; } @ SuppressWarnings ( { ""ThrowableResultOfMethodCallIgnored"" } ) private < DATA_TYPE > boolean checkBackgroundRetry ( OperationAndData < DATA_TYPE > operationAndData , CuratorEvent event ) { boolean doRetry = false ; if ( client . getRetryPolicy ( ) . allowRetry ( operationAndData . getThenIncrementRetryCount ( ) , operationAndData . getElapsedTimeMs ( ) , operationAndData ) ) { doRetry = true ; } else { if ( operationAndData . getErrorCallback ( ) != null ) { operationAndData . getErrorCallback ( ) . retriesExhausted ( operationAndData ) ; } if ( operationAndData . getCallback ( ) != null ) { sendToBackgroundCallback ( operationAndData , event ) ; } KeeperException . Code code = KeeperException . Code . get ( event . getResultCode ( ) ) ; Exception e = null ; try { e = ( code != null ) ? KeeperException . create ( code ) : null ; } catch ( Throwable t ) { ThreadUtils . checkInterrupted ( t ) ; } if ( e == null ) { e = new Exception ( ""Unknown result codegetResultCode()"" ) ; } validateConnection ( codeToState ( code ) ) ; logError ( ""Background operation retry gave up"" , e ) ; } return doRetry ; } private < DATA_TYPE > void sendToBackgroundCallback ( OperationAndData < DATA_TYPE > operationAndData , CuratorEvent event ) { try { operationAndData . getCallback ( ) . processResult ( this , event ) ; } catch ( Exception e ) { ThreadUtils . checkInterrupted ( e ) ; handleBackgroundOperationException ( operationAndData , e ) ; } } private < DATA_TYPE > void handleBackgroundOperationException ( OperationAndData < DATA_TYPE > operationAndData , Throwable e ) { do { if ( ( operationAndData != null ) && RetryLoop . isRetryException ( e ) ) { if ( ! Boolean . getBoolean ( DebugUtils . PROPERTY_DONT_LOG_CONNECTION_ISSUES ) ) { log . debug ( ""Retry-able exception received"" , e ) ; } if ( client . getRetryPolicy ( ) . allowRetry ( operationAndData . getThenIncrementRetryCount ( ) , operationAndData . getElapsedTimeMs ( ) , operationAndData ) ) { if ( ! Boolean . getBoolean ( DebugUtils . PROPERTY_DONT_LOG_CONNECTION_ISSUES ) ) { log . debug ( ""Retrying operation"" ) ; } backgroundOperations . offer ( operationAndData ) ; break ; } else { if ( ! Boolean . getBoolean ( DebugUtils . PROPERTY_DONT_LOG_CONNECTION_ISSUES ) ) { log . debug ( ""Retry policy did not allow retry"" ) ; } if ( operationAndData . getErrorCallback ( ) != null ) { operationAndData . getErrorCallback ( ) . retriesExhausted ( operationAndData ) ; } } } logError ( ""Background exception was not retry-able or retry gave up"" , e ) ; } while ( false ) ; } private void backgroundOperationsLoop ( ) { try { while ( state . get ( ) == CuratorFrameworkState . STARTED ) { OperationAndData < ? > operationAndData ; try { operationAndData = backgroundOperations . take ( ) ; if ( debugListener != null ) { debugListener . listen ( operationAndData ) ; } performBackgroundOperation ( operationAndData ) ; } catch ( InterruptedException e ) { } } } finally { log . info ( ""backgroundOperationsLoop exiting"" ) ; } } void performBackgroundOperation ( OperationAndData < ? > operationAndData ) { try { if ( ! operationAndData . isConnectionRequired ( ) || client . isConnected ( ) ) { operationAndData . callPerformBackgroundOperation ( ) ; } else { client . getZooKeeper ( ) ; if ( operationAndData . getElapsedTimeMs ( ) >= client . getConnectionTimeoutMs ( ) ) { throw new CuratorConnectionLossException ( ) ; } sleepAndQueueOperation ( operationAndData ) ; } } catch ( Throwable e ) { ThreadUtils . checkInterrupted ( e ) ; if ( e instanceof CuratorConnectionLossException ) { WatchedEvent watchedEvent = new WatchedEvent ( Watcher . Event . EventType . None , Watcher . Event . KeeperState . Disconnected , null ) ; CuratorEvent event = new CuratorEventImpl ( this , CuratorEventType . WATCHED , KeeperException . Code . CONNECTIONLOSS . intValue ( ) , null , null , operationAndData . getContext ( ) , null , null , null , watchedEvent , null , null ) ; if ( checkBackgroundRetry ( operationAndData , event ) ) { queueOperation ( operationAndData ) ; } else { logError ( ""Background retry gave up"" , e ) ; } } else { handleBackgroundOperationException ( operationAndData , e ) ; } } } @ VisibleForTesting volatile long sleepAndQueueOperationSeconds = 1 ; private void sleepAndQueueOperation ( OperationAndData < ? > operationAndData ) throws InterruptedException { operationAndData . sleepFor ( sleepAndQueueOperationSeconds , TimeUnit . SECONDS ) ; if ( queueOperation ( operationAndData ) ) { forcedSleepOperations . add ( operationAndData ) ; } } private void unSleepBackgroundOperations ( ) { Collection < OperationAndData < ? > > drain = new ArrayList < > ( forcedSleepOperations . size ( ) ) ; forcedSleepOperations . drainTo ( drain ) ; log . debug ( ""Clearing sleep for {} operations"" , drain . size ( ) ) ; for ( OperationAndData < ? > operation : drain ) { operation . clearSleep ( ) ; if ( backgroundOperations . remove ( operation ) ) { backgroundOperations . offer ( operation ) ; } } } private void processEvent ( final CuratorEvent curatorEvent ) { if ( curatorEvent . getType ( ) == CuratorEventType . WATCHED ) { validateConnection ( curatorEvent . getWatchedEvent ( ) . getState ( ) ) ; } listeners . forEach ( new Function < CuratorListener , Void > ( ) { @ Override public Void apply ( CuratorListener listener ) { try { OperationTrace trace = client . startAdvancedTracer ( ""EventListener"" ) ; listener . eventReceived ( CuratorFrameworkImpl . this , curatorEvent ) ; trace . commit ( ) ; } catch ( Exception e ) { ThreadUtils . checkInterrupted ( e ) ; logError ( ""Event listener threw exception"" , e ) ; } return null ; } } ) ; } }",Smelly
"public class ZkHelixConnection implements HelixConnection , IZkStateListener { private static Logger LOG = Logger . getLogger ( ZkHelixConnection . class ) ; private final String _zkAddr ; private final int _sessionTimeout ; private SessionId _sessionId ; ZkClient _zkclient ; private BaseDataAccessor < ZNRecord > _baseAccessor ; private ConfigAccessor _configAccessor ; private final Set < HelixConnectionStateListener > _connectionListener ; final Map < HelixRole , List < ZkCallbackHandler > > _handlers ; private final HelixManagerProperties _properties ; private final List < Long > _disconnectTimeHistory = new ArrayList < Long > ( ) ; private final int _flappingTimeWindowMs ; private final int _maxDisconnectThreshold ; private final String _version ; public ZkHelixConnection ( String zkAddr ) { _zkAddr = zkAddr ; _handlers = new HashMap < HelixRole , List < ZkCallbackHandler > > ( ) ; _connectionListener = new CopyOnWriteArraySet < HelixConnectionStateListener > ( ) ; _flappingTimeWindowMs = getSystemPropertyAsInt ( ""helixmanager.flappingTimeWindow"" , ZKHelixManager . FLAPPING_TIME_WINDIOW ) ; _maxDisconnectThreshold = getSystemPropertyAsInt ( ""helixmanager.maxDisconnectThreshold"" , ZKHelixManager . MAX_DISCONNECT_THRESHOLD ) ; _sessionTimeout = getSystemPropertyAsInt ( ""zk.session.timeout"" , ZkClient . DEFAULT_SESSION_TIMEOUT ) ; _properties = new HelixManagerProperties ( ""cluster-manager-version.properties"" ) ; _version = _properties . getVersion ( ) ; } private int getSystemPropertyAsInt ( String propertyKey , int propertyDefaultValue ) { String valueString = System . getProperty ( propertyKey , """" + propertyDefaultValue ) ; try { int value = Integer . parseInt ( valueString ) ; if ( value > 0 ) { return value ; } } catch ( NumberFormatException e ) { LOG . warn ( ""Exception while parsing property: "" + propertyKey + "", string: "" + valueString + "", using default value: "" + propertyDefaultValue ) ; } return propertyDefaultValue ; } @ Override public synchronized void connect ( ) { if ( isConnected ( ) ) { return ; } boolean isStarted = false ; try { _zkclient = new ZkClient ( _zkAddr , ZkClient . DEFAULT_SESSION_TIMEOUT , ZkClient . DEFAULT_CONNECTION_TIMEOUT , new ZNRecordSerializer ( ) ) ; _baseAccessor = new ZkBaseDataAccessor < ZNRecord > ( _zkclient ) ; _configAccessor = new ConfigAccessor ( _zkclient ) ; _zkclient . subscribeStateChanges ( this ) ; handleNewSession ( ) ; isStarted = true ; } catch ( Exception e ) { LOG . error ( ""Exception connect"" , e ) ; } finally { if ( ! isStarted ) { disconnect ( ) ; } } } @ Override public synchronized void disconnect ( ) { try { if ( ! isConnected ( ) ) { return ; } if ( LOG . isInfoEnabled ( ) ) { LOG . info ( ""Disconnecting connection: "" + this ) ; } for ( final HelixConnectionStateListener listener : _connectionListener ) { try { listener . onDisconnecting ( ) ; } catch ( Exception e ) { LOG . error ( ""Exception in calling disconnect on listener: "" + listener , e ) ; } } _zkclient . close ( ) ; _zkclient = null ; if ( LOG . isInfoEnabled ( ) ) { LOG . info ( ""Disconnected connection: "" + this ) ; } } catch ( Exception e ) { LOG . error ( ""Exception disconnect"" , e ) ; } } @ Override public synchronized boolean isConnected ( ) { return _zkclient != null ; } @ Override public HelixParticipant createParticipant ( ClusterId clusterId , ParticipantId participantId ) { return new ZkHelixParticipant ( this , clusterId , participantId ) ; } @ Override public HelixController createController ( ClusterId clusterId , ControllerId controllerId ) { return new ZkHelixController ( this , clusterId , controllerId ) ; } @ Override public HelixMultiClusterController createMultiClusterController ( ClusterId clusterId , ControllerId controllerId ) { return new ZkHelixMultiClusterController ( this , clusterId , controllerId ) ; } @ Override public ClusterAccessor createClusterAccessor ( ClusterId clusterId ) { return new ClusterAccessor ( clusterId , createDataAccessor ( clusterId ) ) ; } @ Override public HelixAdmin createClusterManagementTool ( ) { return new ZKHelixAdmin ( _zkclient ) ; } @ Override public HelixPropertyStore < ZNRecord > createPropertyStore ( ClusterId clusterId ) { PropertyKey key = new PropertyKey . Builder ( clusterId . stringify ( ) ) . propertyStore ( ) ; String fallbackPath = String . format ( ""/%s/%s"" , clusterId . toString ( ) , ""HELIX_PROPERTYSTORE"" ) ; return new AutoFallbackPropertyStore < ZNRecord > ( new ZkBaseDataAccessor < ZNRecord > ( _zkclient ) , key . getPath ( ) , fallbackPath ) ; } private void checkConnected ( ) { if ( ! isConnected ( ) ) { throw new IllegalStateException ( ""Connection not connected. Please call #connect()"" ) ; } } @ Override public HelixDataAccessor createDataAccessor ( ClusterId clusterId ) { checkConnected ( ) ; return new ZKHelixDataAccessor ( clusterId . stringify ( ) , _baseAccessor ) ; } @ Override public ConfigAccessor getConfigAccessor ( ) { return _configAccessor ; } @ Override public void addControllerListener ( HelixRole role , ControllerChangeListener listener , ClusterId clusterId ) { addListener ( role , listener , new PropertyKey . Builder ( clusterId . stringify ( ) ) . controller ( ) , ChangeType . CONTROLLER , new EventType [ ] { EventType . NodeChildrenChanged , EventType . NodeDeleted , EventType . NodeCreated } ) ; } @ Override public void addMessageListener ( HelixRole role , MessageListener listener , ClusterId clusterId , ParticipantId participantId ) { addListener ( role , listener , new PropertyKey . Builder ( clusterId . stringify ( ) ) . messages ( participantId . stringify ( ) ) , ChangeType . MESSAGE , new EventType [ ] { EventType . NodeChildrenChanged , EventType . NodeDeleted , EventType . NodeCreated } ) ; } @ Override public void addControllerMessageListener ( HelixRole role , MessageListener listener , ClusterId clusterId ) { addListener ( role , listener , new PropertyKey . Builder ( clusterId . stringify ( ) ) . controllerMessages ( ) , ChangeType . MESSAGES_CONTROLLER , new EventType [ ] { EventType . NodeChildrenChanged , EventType . NodeDeleted , EventType . NodeCreated } ) ; } @ Override public void addIdealStateChangeListener ( HelixRole role , IdealStateChangeListener listener , ClusterId clusterId ) { addListener ( role , listener , new PropertyKey . Builder ( clusterId . stringify ( ) ) . idealStates ( ) , ChangeType . IDEAL_STATE , new EventType [ ] { EventType . NodeDataChanged , EventType . NodeDeleted , EventType . NodeCreated } ) ; } @ Override public void addLiveInstanceChangeListener ( HelixRole role , LiveInstanceChangeListener listener , ClusterId clusterId ) { addListener ( role , listener , new PropertyKey . Builder ( clusterId . stringify ( ) ) . liveInstances ( ) , ChangeType . LIVE_INSTANCE , new EventType [ ] { EventType . NodeDataChanged , EventType . NodeChildrenChanged , EventType . NodeDeleted , EventType . NodeCreated } ) ; } @ Override public void addInstanceConfigChangeListener ( HelixRole role , InstanceConfigChangeListener listener , ClusterId clusterId ) { addListener ( role , listener , new PropertyKey . Builder ( clusterId . stringify ( ) ) . instanceConfigs ( ) , ChangeType . INSTANCE_CONFIG , new EventType [ ] { EventType . NodeChildrenChanged } ) ; } @ Override public void addConfigChangeListener ( HelixRole role , ScopedConfigChangeListener listener , ClusterId clusterId , ConfigScopeProperty scope ) { PropertyKey . Builder keyBuilder = new PropertyKey . Builder ( clusterId . stringify ( ) ) ; PropertyKey propertyKey = null ; switch ( scope ) { case CLUSTER : propertyKey = keyBuilder . clusterConfigs ( ) ; break ; case PARTICIPANT : propertyKey = keyBuilder . instanceConfigs ( ) ; break ; case RESOURCE : propertyKey = keyBuilder . resourceConfigs ( ) ; break ; case CONSTRAINT : propertyKey = keyBuilder . constraints ( ) ; default : break ; } if ( propertyKey == null ) { LOG . error ( ""Failed to add listener: "" + listener + "", unrecognized config scope: "" + scope ) ; return ; } addListener ( role , listener , propertyKey , ChangeType . CONFIG , new EventType [ ] { EventType . NodeChildrenChanged } ) ; } @ Override public void addCurrentStateChangeListener ( HelixRole role , CurrentStateChangeListener listener , ClusterId clusterId , ParticipantId participantId , SessionId sessionId ) { addListener ( role , listener , new PropertyKey . Builder ( clusterId . stringify ( ) ) . currentStates ( participantId . stringify ( ) , sessionId . stringify ( ) ) , ChangeType . CURRENT_STATE , new EventType [ ] { EventType . NodeChildrenChanged , EventType . NodeDeleted , EventType . NodeCreated } ) ; } @ Override public void addExternalViewChangeListener ( HelixRole role , ExternalViewChangeListener listener , ClusterId clusterId ) { addListener ( role , listener , new PropertyKey . Builder ( clusterId . stringify ( ) ) . externalViews ( ) , ChangeType . EXTERNAL_VIEW , new EventType [ ] { EventType . NodeChildrenChanged , EventType . NodeDeleted , EventType . NodeCreated } ) ; } @ Override public boolean removeListener ( HelixRole role , Object listener , PropertyKey key ) { LOG . info ( ""role: "" + role + "" removing listener: "" + listener + "" on path: "" + key . getPath ( ) + "" from connection: "" + this ) ; List < ZkCallbackHandler > toRemove = new ArrayList < ZkCallbackHandler > ( ) ; List < ZkCallbackHandler > handlerList = _handlers . get ( role ) ; if ( handlerList == null ) { return true ; } synchronized ( this ) { for ( ZkCallbackHandler handler : handlerList ) { if ( handler . getPath ( ) . equals ( key . getPath ( ) ) && handler . getListener ( ) . equals ( listener ) ) { toRemove . add ( handler ) ; } } handlerList . removeAll ( toRemove ) ; if ( handlerList . isEmpty ( ) ) { _handlers . remove ( role ) ; } } for ( ZkCallbackHandler handler : toRemove ) { handler . reset ( ) ; } return true ; } @ Override public void addConnectionStateListener ( HelixConnectionStateListener listener ) { synchronized ( _connectionListener ) { _connectionListener . add ( listener ) ; } } @ Override public void removeConnectionStateListener ( HelixConnectionStateListener listener ) { synchronized ( _connectionListener ) { _connectionListener . remove ( listener ) ; } } @ Override public synchronized void handleStateChanged ( KeeperState state ) throws Exception { switch ( state ) { case SyncConnected : ZkConnection zkConnection = ( ZkConnection ) _zkclient . getConnection ( ) ; LOG . info ( ""KeeperState: "" + state + "", zookeeper:"" + zkConnection . getZookeeper ( ) ) ; break ; case Disconnected : LOG . info ( ""KeeperState:"" + state + "", disconnectedSessionId: "" + _sessionId ) ; _disconnectTimeHistory . add ( System . currentTimeMillis ( ) ) ; if ( isFlapping ( ) ) { LOG . error ( ""helix-connection: "" + this + "", sessionId: "" + _sessionId + "" is flapping. diconnect it. "" + "" maxDisconnectThreshold: "" + _maxDisconnectThreshold + "" disconnects in "" + _flappingTimeWindowMs + ""ms"" ) ; disconnect ( ) ; } break ; case Expired : LOG . info ( ""KeeperState:"" + state + "", expiredSessionId: "" + _sessionId ) ; break ; default : break ; } } @ Override public synchronized void handleNewSession ( ) throws Exception { waitUntilConnected ( ) ; for ( final HelixConnectionStateListener listener : _connectionListener ) { try { listener . onConnected ( ) ; } catch ( Exception e ) { LOG . error ( ""Exception invoking connect on listener: "" + listener , e ) ; } } } @ Override public SessionId getSessionId ( ) { return _sessionId ; } @ Override public String getHelixVersion ( ) { return _version ; } @ Override public HelixManagerProperties getHelixProperties ( ) { return _properties ; } private void waitUntilConnected ( ) { boolean isConnected ; do { isConnected = _zkclient . waitUntilConnected ( ZkClient . DEFAULT_CONNECTION_TIMEOUT , TimeUnit . MILLISECONDS ) ; if ( ! isConnected ) { LOG . error ( ""fail to connect zkserver: "" + _zkAddr + "" in "" + ZkClient . DEFAULT_CONNECTION_TIMEOUT + ""ms. expiredSessionId: "" + _sessionId ) ; continue ; } ZkConnection zkConnection = ( ( ZkConnection ) _zkclient . getConnection ( ) ) ; _sessionId = SessionId . from ( Long . toHexString ( zkConnection . getZookeeper ( ) . getSessionId ( ) ) ) ; } while ( ! isConnected || ""0"" . equals ( _sessionId ) ) ; LOG . info ( ""Handling new session, session id: "" + _sessionId + "", zkconnection: "" + ( ( ZkConnection ) _zkclient . getConnection ( ) ) . getZookeeper ( ) ) ; } @ Override public int getSessionTimeout ( ) { return _sessionTimeout ; } @ Override public ClusterMessagingService createMessagingService ( HelixRole role ) { HelixManager manager = new ZKHelixManager ( role ) ; return new DefaultMessagingService ( manager ) ; } void addListener ( HelixRole role , Object listener , PropertyKey propertyKey , ChangeType changeType , EventType [ ] eventType ) { PropertyType type = propertyKey . getType ( ) ; synchronized ( this ) { if ( ! _handlers . containsKey ( role ) ) { _handlers . put ( role , new CopyOnWriteArrayList < ZkCallbackHandler > ( ) ) ; } List < ZkCallbackHandler > handlerList = _handlers . get ( role ) ; for ( ZkCallbackHandler handler : handlerList ) { if ( handler . getPath ( ) . equals ( propertyKey . getPath ( ) ) && handler . getListener ( ) . equals ( listener ) ) { LOG . info ( ""role: "" + role + "", listener: "" + listener + "" on path: "" + propertyKey . getPath ( ) + "" already exists. skip add"" ) ; return ; } } ZkCallbackHandler newHandler = new ZkCallbackHandler ( role , _zkclient , propertyKey , listener , eventType , changeType ) ; handlerList . add ( newHandler ) ; LOG . info ( ""role: "" + role + "" added listener: "" + listener + "" for type: "" + type + "" to path: "" + newHandler . getPath ( ) ) ; } } void initHandlers ( HelixRole role ) { synchronized ( this ) { List < ZkCallbackHandler > handlerList = _handlers . get ( role ) ; if ( handlerList != null ) { for ( ZkCallbackHandler handler : handlerList ) { handler . init ( ) ; LOG . info ( ""role: "" + role + "", init handler: "" + handler . getPath ( ) + "", "" + handler . getListener ( ) ) ; } } } } void resetHandlers ( HelixRole role ) { synchronized ( this ) { List < ZkCallbackHandler > handlerList = _handlers . get ( role ) ; if ( handlerList != null ) { for ( ZkCallbackHandler handler : handlerList ) { handler . reset ( ) ; LOG . info ( ""role: "" + role + "", reset handler: "" + handler . getPath ( ) + "", "" + handler . getListener ( ) ) ; } } } } private boolean isFlapping ( ) { if ( _disconnectTimeHistory . size ( ) == 0 ) { return false ; } long mostRecentTimestamp = _disconnectTimeHistory . get ( _disconnectTimeHistory . size ( ) - 1 ) ; while ( ( _disconnectTimeHistory . get ( 0 ) + _flappingTimeWindowMs ) < mostRecentTimestamp ) { _disconnectTimeHistory . remove ( 0 ) ; } return _disconnectTimeHistory . size ( ) > _maxDisconnectThreshold ; } }",Smelly
"@ Deprecated public abstract class AbstractFactoryAndRepository extends AbstractService { @ Deprecated protected < T > T newPersistentInstance ( final Class < T > ofClass ) { return getContainer ( ) . newPersistentInstance ( ofClass ) ; } @ Deprecated protected < T > T newInstance ( final Class < T > ofClass , final Object object ) { return getContainer ( ) . newInstance ( ofClass , object ) ; } }",No
"public class DimensionPropertyMaker extends CorrespondingPropertyMaker { private int [ ] [ ] extraCorresponding ; public DimensionPropertyMaker ( PropertyMaker baseMaker ) { super ( baseMaker ) ; } public void setExtraCorresponding ( int [ ] [ ] extraCorresponding ) { if ( extraCorresponding == null ) { throw new NullPointerException ( ) ; } for ( int i = 0 ; i < extraCorresponding . length ; i ++ ) { int [ ] eca = extraCorresponding [ i ] ; if ( ( eca == null ) || ( eca . length != 4 ) ) { throw new IllegalArgumentException ( ""bad sub-array @ ["" + i + ""]"" ) ; } } this . extraCorresponding = extraCorresponding ; } public boolean isCorrespondingForced ( PropertyList propertyList ) { if ( super . isCorrespondingForced ( propertyList ) ) { return true ; } for ( int [ ] anExtraCorresponding : extraCorresponding ) { int wmcorr = anExtraCorresponding [ 0 ] ; if ( propertyList . getExplicit ( wmcorr ) != null ) { return true ; } } return false ; } public Property compute ( PropertyList propertyList ) throws PropertyException { Property p = super . compute ( propertyList ) ; if ( p == null ) { p = baseMaker . make ( propertyList ) ; } int wmcorr = propertyList . selectFromWritingMode ( extraCorresponding [ 0 ] [ 0 ] , extraCorresponding [ 0 ] [ 1 ] , extraCorresponding [ 0 ] [ 2 ] , extraCorresponding [ 0 ] [ 3 ] ) ; Property subprop = propertyList . getExplicitOrShorthand ( wmcorr ) ; if ( subprop != null ) { baseMaker . setSubprop ( p , Constants . CP_MINIMUM , subprop ) ; } wmcorr = propertyList . selectFromWritingMode ( extraCorresponding [ 1 ] [ 0 ] , extraCorresponding [ 1 ] [ 1 ] , extraCorresponding [ 1 ] [ 2 ] , extraCorresponding [ 1 ] [ 3 ] ) ; subprop = propertyList . getExplicitOrShorthand ( wmcorr ) ; if ( subprop != null ) { baseMaker . setSubprop ( p , Constants . CP_MAXIMUM , subprop ) ; } return p ; } }",No
"public abstract class ObjectActionParameterAbstract implements ObjectActionParameter { private final FeatureType featureType ; private final int number ; private final ObjectActionDefault parentAction ; private final TypedHolder peer ; protected ObjectActionParameterAbstract ( final FeatureType featureType , final int number , final ObjectActionDefault objectAction , final TypedHolder peer ) { this . featureType = featureType ; this . number = number ; this . parentAction = objectAction ; this . peer = peer ; } @ Override public FeatureType getFeatureType ( ) { return featureType ; } @ Override public ObjectAdapter get ( final ObjectAdapter owner , final InteractionInitiatedBy interactionInitiatedBy ) { final MutableProposedHolder proposedHolder = getProposedHolder ( owner ) ; final Object proposed = proposedHolder . getProposed ( ) ; return getAdapterMap ( ) . adapterFor ( proposed ) ; } protected MutableProposedHolder getProposedHolder ( final ObjectAdapter owner ) { if ( ! ( owner instanceof MutableProposedHolder ) ) { throw new IllegalArgumentException ( ""Instance should implement MutableProposedHolder"" ) ; } return ( MutableProposedHolder ) owner ; } @ Override public int getNumber ( ) { return number ; } @ Override public ObjectAction getAction ( ) { return parentAction ; } TypedHolder getPeer ( ) { return peer ; } @ Override public ObjectSpecification getSpecification ( ) { return ObjectMemberAbstract . getSpecification ( getSpecificationLoader ( ) , peer . getType ( ) ) ; } @ Override public Identifier getIdentifier ( ) { return parentAction . getIdentifier ( ) ; } @ Override public String getId ( ) { final NamedFacet facet = getFacet ( NamedFacet . class ) ; if ( facet != null && facet . value ( ) != null ) { return StringExtensions . asCamelLowerFirst ( facet . value ( ) ) ; } final String name = getSpecification ( ) . getSingularName ( ) ; final List < ObjectActionParameter > parameters = this . getAction ( ) . getParameters ( new Filter < ObjectActionParameter > ( ) { @ Override public boolean accept ( final ObjectActionParameter t ) { return equalsShortIdentifier ( t . getSpecification ( ) , getSpecification ( ) ) ; } protected boolean equalsShortIdentifier ( final ObjectSpecification spec1 , final ObjectSpecification spec2 ) { return spec1 . getShortIdentifier ( ) . toLowerCase ( ) . equals ( spec2 . getShortIdentifier ( ) . toLowerCase ( ) ) ; } } ) ; if ( parameters . size ( ) == 1 ) { return StringExtensions . asCamelLowerFirst ( name ) ; } final int indexOf = parameters . indexOf ( this ) ; return StringExtensions . asCamelLowerFirst ( name + ( indexOf + 1 ) ) ; } @ Override public String getName ( ) { final NamedFacet facet = getFacet ( NamedFacet . class ) ; if ( facet != null && facet . value ( ) != null ) { return facet . value ( ) ; } final String name = getSpecification ( ) . getSingularName ( ) ; final List < ObjectActionParameter > parameters = getAction ( ) . getParameters ( new Filter < ObjectActionParameter > ( ) { @ Override public boolean accept ( final ObjectActionParameter t ) { return equalsShortIdentifier ( t . getSpecification ( ) , getSpecification ( ) ) ; } protected boolean equalsShortIdentifier ( final ObjectSpecification spec1 , final ObjectSpecification spec2 ) { return spec1 . getShortIdentifier ( ) . toLowerCase ( ) . equals ( spec2 . getShortIdentifier ( ) . toLowerCase ( ) ) ; } } ) ; if ( parameters . size ( ) == 1 ) { return name ; } final int indexOf = parameters . indexOf ( this ) ; return name + "" "" + ( indexOf + 1 ) ; } @ Override public String getDescription ( ) { final DescribedAsFacet facet = getFacet ( DescribedAsFacet . class ) ; final String description = facet . value ( ) ; return description == null ? """" : description ; } @ Override public boolean isOptional ( ) { final MandatoryFacet facet = getFacet ( MandatoryFacet . class ) ; return facet . isInvertedSemantics ( ) ; } public Consent isUsable ( ) { return Allow . DEFAULT ; } protected FacetHolder getFacetHolder ( ) { return peer ; } @ Override public boolean containsFacet ( final Class < ? extends Facet > facetType ) { final FacetHolder facetHolder = getFacetHolder ( ) ; return facetHolder != null && facetHolder . containsFacet ( facetType ) ; } @ Override public boolean containsDoOpFacet ( final Class < ? extends Facet > facetType ) { final FacetHolder facetHolder = getFacetHolder ( ) ; return facetHolder != null && facetHolder . containsDoOpFacet ( facetType ) ; } @ Override public boolean containsDoOpNotDerivedFacet ( final Class < ? extends Facet > facetType ) { final FacetHolder facetHolder = getFacetHolder ( ) ; return facetHolder != null && facetHolder . containsDoOpNotDerivedFacet ( facetType ) ; } @ Override public < T extends Facet > T getFacet ( final Class < T > cls ) { final FacetHolder facetHolder = getFacetHolder ( ) ; return facetHolder != null ? facetHolder . getFacet ( cls ) : null ; } @ SuppressWarnings ( ""unchecked"" ) @ Override public Class < ? extends Facet > [ ] getFacetTypes ( ) { final FacetHolder facetHolder = getFacetHolder ( ) ; return facetHolder != null ? facetHolder . getFacetTypes ( ) : new Class [ ] { } ; } @ Override public List < Facet > getFacets ( final Filter < Facet > filter ) { final FacetHolder facetHolder = getFacetHolder ( ) ; return facetHolder != null ? facetHolder . getFacets ( filter ) : Lists . < Facet > newArrayList ( ) ; } @ Override public void addFacet ( final Facet facet ) { final FacetHolder facetHolder = getFacetHolder ( ) ; if ( facetHolder != null ) { facetHolder . addFacet ( facet ) ; } } @ Override public void addFacet ( final MultiTypedFacet facet ) { final FacetHolder facetHolder = getFacetHolder ( ) ; if ( facetHolder != null ) { facetHolder . addFacet ( facet ) ; } } @ Override public void removeFacet ( final Facet facet ) { final FacetHolder facetHolder = getFacetHolder ( ) ; if ( facetHolder != null ) { facetHolder . removeFacet ( facet ) ; } } @ Override public void removeFacet ( final Class < ? extends Facet > facetType ) { final FacetHolder facetHolder = getFacetHolder ( ) ; if ( facetHolder != null ) { facetHolder . removeFacet ( facetType ) ; } } @ Override public boolean hasAutoComplete ( ) { final ActionParameterAutoCompleteFacet facet = getFacet ( ActionParameterAutoCompleteFacet . class ) ; return facet != null ; } @ Override public ObjectAdapter [ ] getAutoComplete ( final ObjectAdapter adapter , final String searchArg , final InteractionInitiatedBy interactionInitiatedBy ) { final List < ObjectAdapter > adapters = Lists . newArrayList ( ) ; final ActionParameterAutoCompleteFacet facet = getFacet ( ActionParameterAutoCompleteFacet . class ) ; if ( facet != null ) { final Object [ ] choices = facet . autoComplete ( adapter , searchArg , interactionInitiatedBy ) ; checkChoicesOrAutoCompleteType ( getSpecificationLoader ( ) , choices , getSpecification ( ) ) ; for ( final Object choice : choices ) { adapters . add ( getAdapterMap ( ) . adapterFor ( choice ) ) ; } } return adapters . toArray ( new ObjectAdapter [ 0 ] ) ; } @ Override public int getAutoCompleteMinLength ( ) { final ActionParameterAutoCompleteFacet facet = getFacet ( ActionParameterAutoCompleteFacet . class ) ; return facet != null ? facet . getMinLength ( ) : MinLengthUtil . MIN_LENGTH_DEFAULT ; } @ Override public boolean hasChoices ( ) { final ActionParameterChoicesFacet choicesFacet = getFacet ( ActionParameterChoicesFacet . class ) ; return choicesFacet != null ; } @ Override public ObjectAdapter [ ] getChoices ( final ObjectAdapter adapter , final ObjectAdapter [ ] argumentsIfAvailable , final InteractionInitiatedBy interactionInitiatedBy ) { final List < ObjectAdapter > argListIfAvailable = ListExtensions . mutableCopy ( argumentsIfAvailable ) ; final ObjectAdapter target = targetForDefaultOrChoices ( adapter ) ; final List < ObjectAdapter > args = argsForDefaultOrChoices ( adapter , argListIfAvailable ) ; return findChoices ( target , args , interactionInitiatedBy ) ; } private ObjectAdapter [ ] findChoices ( final ObjectAdapter target , final List < ObjectAdapter > args , final InteractionInitiatedBy interactionInitiatedBy ) { final List < ObjectAdapter > adapters = Lists . newArrayList ( ) ; final ActionParameterChoicesFacet facet = getFacet ( ActionParameterChoicesFacet . class ) ; if ( facet != null ) { final Object [ ] choices = facet . getChoices ( target , args , interactionInitiatedBy ) ; checkChoicesOrAutoCompleteType ( getSpecificationLoader ( ) , choices , getSpecification ( ) ) ; for ( final Object choice : choices ) { ObjectAdapter adapter = choice != null ? getAdapterMap ( ) . adapterFor ( choice ) : null ; adapters . add ( adapter ) ; } } return adapters . toArray ( new ObjectAdapter [ adapters . size ( ) ] ) ; } @ Override public ObjectAdapter getDefault ( final ObjectAdapter adapter ) { final ObjectAdapter target = targetForDefaultOrChoices ( adapter ) ; final List < ObjectAdapter > args = argsForDefaultOrChoices ( adapter , null ) ; return findDefault ( target , args ) ; } private ObjectAdapter findDefault ( final ObjectAdapter target , final List < ObjectAdapter > args ) { final ActionParameterDefaultsFacet defaultsFacet = getFacet ( ActionParameterDefaultsFacet . class ) ; if ( defaultsFacet != null ) { final Object dflt = defaultsFacet . getDefault ( target , args ) ; if ( dflt == null ) { return null ; } return getAdapterMap ( ) . adapterFor ( dflt ) ; } return null ; } protected ObjectAdapter targetForDefaultOrChoices ( final ObjectAdapter adapter ) { return adapter ; } protected List < ObjectAdapter > argsForDefaultOrChoices ( final ObjectAdapter adapter , final List < ObjectAdapter > argumentsIfAvailable ) { return argumentsIfAvailable ; } static void checkChoicesOrAutoCompleteType ( final SpecificationLoader specificationLookup , final Object [ ] objects , final ObjectSpecification paramSpec ) { for ( final Object object : objects ) { if ( object == null ) { continue ; } final Class < ? extends Object > choiceClass = object . getClass ( ) ; final Class < ? > paramClass = paramSpec . getCorrespondingClass ( ) ; final Class < ? extends Object > choiceWrappedClass = ClassExtensions . asWrappedIfNecessary ( choiceClass ) ; final Class < ? extends Object > paramWrappedClass = ClassExtensions . asWrappedIfNecessary ( paramClass ) ; final ObjectSpecification choiceWrappedSpec = specificationLookup . loadSpecification ( choiceWrappedClass ) ; final ObjectSpecification paramWrappedSpec = specificationLookup . loadSpecification ( paramWrappedClass ) ; if ( ! choiceWrappedSpec . isOfType ( paramWrappedSpec ) ) { throw new DomainModelException ( String . format ( ""Type incompatible with parameter type; expected %s, but was %s"" , paramSpec . getFullIdentifier ( ) , choiceClass . getName ( ) ) ) ; } } } @ SuppressWarnings ( ""unused"" ) private < T > void addAllInstancesForType ( final List < ObjectAdapter > adapters ) { final Query < T > query = new QueryFindAllInstances < T > ( getSpecification ( ) . getFullIdentifier ( ) ) ; final List < ObjectAdapter > allInstancesAdapter = getObjectPersistor ( ) . allMatchingQuery ( query ) ; for ( final ObjectAdapter choiceAdapter : allInstancesAdapter ) { adapters . add ( choiceAdapter ) ; } } @ Override public ActionArgValidityContext createProposedArgumentInteractionContext ( final ObjectAdapter objectAdapter , final ObjectAdapter [ ] proposedArguments , final int position , final InteractionInitiatedBy interactionInitiatedBy ) { return new ActionArgValidityContext ( objectAdapter , parentAction , getIdentifier ( ) , proposedArguments , position , interactionInitiatedBy ) ; } @ Override public String isValid ( final ObjectAdapter objectAdapter , final Object proposedValue , final InteractionInitiatedBy interactionInitiatedBy ) { ObjectAdapter proposedValueAdapter = null ; ObjectSpecification proposedValueSpec ; if ( proposedValue != null ) { proposedValueAdapter = getAdapterMap ( ) . adapterFor ( proposedValue ) ; if ( proposedValueAdapter == null ) { return null ; } proposedValueSpec = proposedValueAdapter . getSpecification ( ) ; if ( ! proposedValueSpec . isOfType ( proposedValueSpec ) ) { return null ; } } final ObjectAdapter [ ] argumentAdapters = arguments ( proposedValueAdapter ) ; final ValidityContext < ? > ic = createProposedArgumentInteractionContext ( objectAdapter , argumentAdapters , getNumber ( ) , interactionInitiatedBy ) ; final InteractionResultSet buf = new InteractionResultSet ( ) ; InteractionUtils . isValidResultSet ( this , ic , buf ) ; if ( buf . isVetoed ( ) ) { return buf . getInteractionResult ( ) . getReason ( ) ; } return null ; } private ObjectAdapter [ ] arguments ( final ObjectAdapter proposedValue ) { final int parameterCount = getAction ( ) . getParameterCount ( ) ; final ObjectAdapter [ ] arguments = new ObjectAdapter [ parameterCount ] ; arguments [ getNumber ( ) ] = proposedValue ; return arguments ; } protected SpecificationLoader getSpecificationLoader ( ) { return parentAction . getSpecificationLoader ( ) ; } protected AdapterManager getAdapterMap ( ) { return parentAction . getPersistenceSessionService ( ) ; } protected PersistenceSessionServiceInternal getObjectPersistor ( ) { return parentAction . getPersistenceSessionService ( ) ; } }",Smelly
"public class KahaTopicMessageStore extends KahaMessageStore implements TopicMessageStore { protected ListContainer < TopicSubAck > ackContainer ; protected Map < Object , TopicSubContainer > subscriberMessages = new ConcurrentHashMap < Object , TopicSubContainer > ( ) ; private Map < String , SubscriptionInfo > subscriberContainer ; private Store store ; public KahaTopicMessageStore ( Store store , MapContainer < MessageId , Message > messageContainer , ListContainer < TopicSubAck > ackContainer , MapContainer < String , SubscriptionInfo > subsContainer , ActiveMQDestination destination ) throws IOException { super ( messageContainer , destination ) ; this . store = store ; this . ackContainer = ackContainer ; subscriberContainer = subsContainer ; for ( Iterator < String > i = subscriberContainer . keySet ( ) . iterator ( ) ; i . hasNext ( ) ; ) { Object key = i . next ( ) ; addSubscriberMessageContainer ( key ) ; } } @ Override public synchronized void addMessage ( ConnectionContext context , Message message ) throws IOException { int subscriberCount = subscriberMessages . size ( ) ; if ( subscriberCount > 0 ) { MessageId id = message . getMessageId ( ) ; StoreEntry messageEntry = messageContainer . place ( id , message ) ; TopicSubAck tsa = new TopicSubAck ( ) ; tsa . setCount ( subscriberCount ) ; tsa . setMessageEntry ( messageEntry ) ; StoreEntry ackEntry = ackContainer . placeLast ( tsa ) ; for ( Iterator < TopicSubContainer > i = subscriberMessages . values ( ) . iterator ( ) ; i . hasNext ( ) ; ) { TopicSubContainer container = i . next ( ) ; ConsumerMessageRef ref = new ConsumerMessageRef ( ) ; ref . setAckEntry ( ackEntry ) ; ref . setMessageEntry ( messageEntry ) ; ref . setMessageId ( id ) ; container . add ( ref ) ; } } } public synchronized void acknowledge ( ConnectionContext context , String clientId , String subscriptionName , MessageId messageId , MessageAck ack ) throws IOException { String subcriberId = getSubscriptionKey ( clientId , subscriptionName ) ; TopicSubContainer container = subscriberMessages . get ( subcriberId ) ; if ( container != null ) { ConsumerMessageRef ref = container . remove ( messageId ) ; if ( container . isEmpty ( ) ) { container . reset ( ) ; } if ( ref != null ) { TopicSubAck tsa = ackContainer . get ( ref . getAckEntry ( ) ) ; if ( tsa != null ) { if ( tsa . decrementCount ( ) <= 0 ) { StoreEntry entry = ref . getAckEntry ( ) ; entry = ackContainer . refresh ( entry ) ; ackContainer . remove ( entry ) ; entry = tsa . getMessageEntry ( ) ; entry = messageContainer . refresh ( entry ) ; messageContainer . remove ( entry ) ; } else { ackContainer . update ( ref . getAckEntry ( ) , tsa ) ; } } } } } public synchronized SubscriptionInfo lookupSubscription ( String clientId , String subscriptionName ) throws IOException { return subscriberContainer . get ( getSubscriptionKey ( clientId , subscriptionName ) ) ; } public synchronized void addSubsciption ( SubscriptionInfo info , boolean retroactive ) throws IOException { String key = getSubscriptionKey ( info . getClientId ( ) , info . getSubscriptionName ( ) ) ; if ( ! subscriberContainer . containsKey ( key ) ) { subscriberContainer . put ( key , info ) ; } addSubscriberMessageContainer ( key ) ; } public synchronized void deleteSubscription ( String clientId , String subscriptionName ) throws IOException { String key = getSubscriptionKey ( clientId , subscriptionName ) ; removeSubscriberMessageContainer ( key ) ; } public synchronized void recoverSubscription ( String clientId , String subscriptionName , MessageRecoveryListener listener ) throws Exception { String key = getSubscriptionKey ( clientId , subscriptionName ) ; TopicSubContainer container = subscriberMessages . get ( key ) ; if ( container != null ) { for ( Iterator i = container . iterator ( ) ; i . hasNext ( ) ; ) { ConsumerMessageRef ref = ( ConsumerMessageRef ) i . next ( ) ; Message msg = messageContainer . get ( ref . getMessageEntry ( ) ) ; if ( msg != null ) { if ( ! recoverMessage ( listener , msg ) ) { break ; } } } } } public synchronized void recoverNextMessages ( String clientId , String subscriptionName , int maxReturned , MessageRecoveryListener listener ) throws Exception { String key = getSubscriptionKey ( clientId , subscriptionName ) ; TopicSubContainer container = subscriberMessages . get ( key ) ; if ( container != null ) { int count = 0 ; StoreEntry entry = container . getBatchEntry ( ) ; if ( entry == null ) { entry = container . getEntry ( ) ; } else { entry = container . refreshEntry ( entry ) ; if ( entry != null ) { entry = container . getNextEntry ( entry ) ; } } if ( entry != null ) { do { ConsumerMessageRef consumerRef = container . get ( entry ) ; Message msg = messageContainer . getValue ( consumerRef . getMessageEntry ( ) ) ; if ( msg != null ) { recoverMessage ( listener , msg ) ; count ++ ; container . setBatchEntry ( msg . getMessageId ( ) . toString ( ) , entry ) ; } else { container . reset ( ) ; } entry = container . getNextEntry ( entry ) ; } while ( entry != null && count < maxReturned && listener . hasSpace ( ) ) ; } } } public synchronized void delete ( ) { super . delete ( ) ; ackContainer . clear ( ) ; subscriberContainer . clear ( ) ; } public SubscriptionInfo [ ] getAllSubscriptions ( ) throws IOException { return subscriberContainer . values ( ) . toArray ( new SubscriptionInfo [ subscriberContainer . size ( ) ] ) ; } protected String getSubscriptionKey ( String clientId , String subscriberName ) { String result = clientId + "":"" ; result += subscriberName != null ? subscriberName : ""NOT_SET"" ; return result ; } protected MapContainer addSubscriberMessageContainer ( Object key ) throws IOException { MapContainer container = store . getMapContainer ( key , ""topic-subs"" ) ; container . setKeyMarshaller ( Store . MESSAGEID_MARSHALLER ) ; Marshaller marshaller = new ConsumerMessageRefMarshaller ( ) ; container . setValueMarshaller ( marshaller ) ; TopicSubContainer tsc = new TopicSubContainer ( container ) ; subscriberMessages . put ( key , tsc ) ; return container ; } protected synchronized void removeSubscriberMessageContainer ( Object key ) throws IOException { subscriberContainer . remove ( key ) ; TopicSubContainer container = subscriberMessages . remove ( key ) ; if ( container != null ) { for ( Iterator i = container . iterator ( ) ; i . hasNext ( ) ; ) { ConsumerMessageRef ref = ( ConsumerMessageRef ) i . next ( ) ; if ( ref != null ) { TopicSubAck tsa = ackContainer . get ( ref . getAckEntry ( ) ) ; if ( tsa != null ) { if ( tsa . decrementCount ( ) <= 0 ) { ackContainer . remove ( ref . getAckEntry ( ) ) ; messageContainer . remove ( tsa . getMessageEntry ( ) ) ; } else { ackContainer . update ( ref . getAckEntry ( ) , tsa ) ; } } } } container . clear ( ) ; } store . deleteListContainer ( key , ""topic-subs"" ) ; } public synchronized int getMessageCount ( String clientId , String subscriberName ) throws IOException { String key = getSubscriptionKey ( clientId , subscriberName ) ; TopicSubContainer container = subscriberMessages . get ( key ) ; return container != null ? container . size ( ) : 0 ; } public synchronized void removeAllMessages ( ConnectionContext context ) throws IOException { messageContainer . clear ( ) ; ackContainer . clear ( ) ; for ( Iterator < TopicSubContainer > i = subscriberMessages . values ( ) . iterator ( ) ; i . hasNext ( ) ; ) { TopicSubContainer container = i . next ( ) ; container . clear ( ) ; } } public synchronized void resetBatching ( String clientId , String subscriptionName ) { String key = getSubscriptionKey ( clientId , subscriptionName ) ; TopicSubContainer topicSubContainer = subscriberMessages . get ( key ) ; if ( topicSubContainer != null ) { topicSubContainer . reset ( ) ; } } }",No
"@ InterfaceAudience . Private public class ScanDeleteTracker implements DeleteTracker { protected boolean hasFamilyStamp = false ; protected long familyStamp = 0L ; protected SortedSet < Long > familyVersionStamps = new TreeSet < Long > ( ) ; protected Cell deleteCell = null ; protected byte [ ] deleteBuffer = null ; protected int deleteOffset = 0 ; protected int deleteLength = 0 ; protected byte deleteType = 0 ; protected long deleteTimestamp = 0L ; protected final CellComparator comparator ; public ScanDeleteTracker ( CellComparator comparator ) { this . comparator = comparator ; } @ Override public void add ( Cell cell ) { long timestamp = cell . getTimestamp ( ) ; byte type = cell . getTypeByte ( ) ; if ( ! hasFamilyStamp || timestamp > familyStamp ) { if ( type == KeyValue . Type . DeleteFamily . getCode ( ) ) { hasFamilyStamp = true ; familyStamp = timestamp ; return ; } else if ( type == KeyValue . Type . DeleteFamilyVersion . getCode ( ) ) { familyVersionStamps . add ( timestamp ) ; return ; } if ( deleteCell != null && type < deleteType ) { if ( CellUtil . matchingQualifier ( cell , deleteCell ) ) { return ; } } deleteCell = cell ; deleteType = type ; deleteTimestamp = timestamp ; } } @ Override public DeleteResult isDeleted ( Cell cell ) { long timestamp = cell . getTimestamp ( ) ; if ( hasFamilyStamp && timestamp <= familyStamp ) { return DeleteResult . FAMILY_DELETED ; } if ( familyVersionStamps . contains ( Long . valueOf ( timestamp ) ) ) { return DeleteResult . FAMILY_VERSION_DELETED ; } if ( deleteCell != null ) { int ret = - ( this . comparator . compareQualifiers ( cell , deleteCell ) ) ; if ( ret == 0 ) { if ( deleteType == KeyValue . Type . DeleteColumn . getCode ( ) ) { return DeleteResult . COLUMN_DELETED ; } if ( timestamp == deleteTimestamp ) { return DeleteResult . VERSION_DELETED ; } assert timestamp < deleteTimestamp ; deleteCell = null ; } else if ( ret < 0 ) { deleteCell = null ; } else { throw new IllegalStateException ( ""isDelete failed: deleteBuffer="" + Bytes . toStringBinary ( deleteCell . getQualifierArray ( ) , deleteCell . getQualifierOffset ( ) , deleteCell . getQualifierLength ( ) ) + "", qualifier="" + Bytes . toStringBinary ( cell . getQualifierArray ( ) , cell . getQualifierOffset ( ) , cell . getQualifierLength ( ) ) + "", timestamp="" + timestamp + "", comparison result: "" + ret ) ; } } return DeleteResult . NOT_DELETED ; } @ Override public boolean isEmpty ( ) { return deleteCell == null && ! hasFamilyStamp && familyVersionStamps . isEmpty ( ) ; } @ Override public void reset ( ) { hasFamilyStamp = false ; familyStamp = 0L ; familyVersionStamps . clear ( ) ; deleteCell = null ; } @ Override public void update ( ) { this . reset ( ) ; } @ Override public void beforeShipped ( ) throws IOException { if ( deleteCell != null ) { deleteCell = KeyValueUtil . toNewKeyCell ( deleteCell ) ; } } @ Override public CellComparator getCellComparator ( ) { return this . comparator ; } }",No
public class MyType < F extends Cow > { public TypeLiteral < Animal < F > > ANIMAL = new TypeLiteral < Animal < F > > ( ) { } ; public Type getType ( ) { return ANIMAL . getType ( ) ; } },No
"public class PojoAdapter extends InstanceAbstract implements ObjectAdapter { private final static Logger LOG = LoggerFactory . getLogger ( PojoAdapter . class ) ; private final AuthenticationSession authenticationSession ; private final SpecificationLoader specificationLoader ; private final PersistenceSession persistenceSession ; private Object pojo ; private Oid oid ; private ElementSpecificationProvider elementSpecificationProvider ; public PojoAdapter ( final Object pojo , final Oid oid , final AuthenticationSession authenticationSession , final SpecificationLoader specificationLoader , final PersistenceSession persistenceSession ) { this . persistenceSession = persistenceSession ; this . specificationLoader = specificationLoader ; this . authenticationSession = authenticationSession ; if ( pojo instanceof ObjectAdapter ) { throw new IsisException ( ""Adapter can't be used to adapt an adapter: "" + pojo ) ; } this . pojo = pojo ; this . oid = oid ; } @ Override public ObjectSpecification getSpecification ( ) { return ( ObjectSpecification ) super . getSpecification ( ) ; } @ Override protected ObjectSpecification loadSpecification ( ) { final Class < ? > aClass = getObject ( ) . getClass ( ) ; final ObjectSpecification specification = specificationLoader . loadSpecification ( aClass ) ; return specification ; } @ Override public Object getObject ( ) { return pojo ; } @ Override public void replacePojo ( final Object pojo ) { this . pojo = pojo ; } @ Override public Oid getOid ( ) { return oid ; } @ Override public void replaceOid ( Oid persistedOid ) { Ensure . ensureThatArg ( oid , is ( notNullValue ( ) ) ) ; this . oid = persistedOid ; } @ Override public boolean isParentedCollection ( ) { return oid instanceof ParentedCollectionOid ; } @ Override public boolean isValue ( ) { return oid == null ; } @ Override public boolean isTransient ( ) { if ( getSpecification ( ) . isService ( ) || getSpecification ( ) . isViewModel ( ) ) { return false ; } if ( pojo instanceof Persistable ) { final Persistable pojo = ( Persistable ) this . pojo ; final boolean isPersistent = pojo . dnIsPersistent ( ) ; final boolean isDeleted = pojo . dnIsDeleted ( ) ; if ( ! isPersistent && ! isDeleted ) { return true ; } } return false ; } @ Override public boolean representsPersistent ( ) { if ( getSpecification ( ) . isService ( ) || getSpecification ( ) . isViewModel ( ) ) { return true ; } if ( pojo instanceof Persistable ) { final Persistable pojo = ( Persistable ) this . pojo ; final boolean isPersistent = pojo . dnIsPersistent ( ) ; final boolean isDeleted = pojo . dnIsDeleted ( ) ; if ( isPersistent ) { return true ; } } return false ; } @ Override public boolean isDestroyed ( ) { if ( getSpecification ( ) . isService ( ) || getSpecification ( ) . isViewModel ( ) ) { return false ; } if ( pojo instanceof Persistable ) { final Persistable pojo = ( Persistable ) this . pojo ; final boolean isDeleted = pojo . dnIsDeleted ( ) ; if ( isDeleted ) { return true ; } } return false ; } @ Override public ObjectAdapter getAggregateRoot ( ) { if ( ! isParentedCollection ( ) ) { return this ; } ParentedCollectionOid collectionOid = ( ParentedCollectionOid ) oid ; return persistenceSession . getAggregateRoot ( collectionOid ) ; } @ Override public Version getVersion ( ) { if ( isParentedCollection ( ) ) { return getAggregateRoot ( ) . getVersion ( ) ; } else { return getOid ( ) . getVersion ( ) ; } } @ Override public void checkLock ( final Version otherVersion ) { if ( isParentedCollection ( ) ) { getAggregateRoot ( ) . checkLock ( otherVersion ) ; return ; } Oid thisOid = getOid ( ) ; final Version thisVersion = thisOid . getVersion ( ) ; if ( thisVersion != null && otherVersion != null && thisVersion . different ( otherVersion ) ) { if ( AdapterManager . ConcurrencyChecking . isCurrentlyEnabled ( ) ) { LOG . info ( ""concurrency conflict detected on {} ({})"" , thisOid , otherVersion ) ; final String currentUser = authenticationSession . getUserName ( ) ; throw new ConcurrencyException ( currentUser , thisOid , thisVersion , otherVersion ) ; } else { LOG . info ( ""concurrency conflict detected but suppressed, on {} ({})"" , thisOid , otherVersion ) ; } } } @ Override public void setVersion ( final Version version ) { if ( isParentedCollection ( ) ) { return ; } if ( shouldSetVersion ( version ) ) { RootOid rootOid = ( RootOid ) getOid ( ) ; rootOid . setVersion ( version ) ; } } private boolean shouldSetVersion ( final Version otherVersion ) { final Version version = getOid ( ) . getVersion ( ) ; return version == null || otherVersion == null || otherVersion . different ( version ) ; } @ Override public String titleString ( ) { return titleString ( null ) ; } @ Override public String titleString ( ObjectAdapter contextAdapterIfAny ) { if ( getSpecification ( ) . isParentedOrFreeCollection ( ) ) { final CollectionFacet facet = getSpecification ( ) . getFacet ( CollectionFacet . class ) ; return collectionTitleString ( facet ) ; } else { return objectTitleString ( contextAdapterIfAny ) ; } } private String objectTitleString ( ObjectAdapter contextAdapterIfAny ) { if ( getObject ( ) instanceof String ) { return ( String ) getObject ( ) ; } final ObjectSpecification specification = getSpecification ( ) ; String title = specification . getTitle ( contextAdapterIfAny , this ) ; if ( title == null ) { title = getDefaultTitle ( ) ; } return title ; } private String collectionTitleString ( final CollectionFacet facet ) { final int size = facet . size ( this ) ; final ObjectSpecification elementSpecification = getElementSpecification ( ) ; if ( elementSpecification == null || elementSpecification . getFullIdentifier ( ) . equals ( Object . class . getName ( ) ) ) { switch ( size ) { case - 1 : return ""Objects"" ; case 0 : return ""No objects"" ; case 1 : return ""1 object"" ; default : return size + "" objects"" ; } } else { switch ( size ) { case - 1 : return elementSpecification . getPluralName ( ) ; case 0 : return ""No "" + elementSpecification . getPluralName ( ) ; case 1 : return ""1 "" + elementSpecification . getSingularName ( ) ; default : return size + "" "" + elementSpecification . getPluralName ( ) ; } } } @ Override public String toString ( ) { final ToString str = new ToString ( this ) ; toString ( str ) ; str . append ( ""pojo-toString"" , pojo . toString ( ) ) ; str . appendAsHex ( ""pojo-hash"" , pojo . hashCode ( ) ) ; return str . toString ( ) ; } protected String getDefaultTitle ( ) { return ""A"" + ( "" "" + getSpecification ( ) . getSingularName ( ) ) . toLowerCase ( ) ; } protected void toString ( final ToString str ) { str . append ( aggregateResolveStateCode ( ) ) ; final Oid oid = getOid ( ) ; if ( oid != null ) { str . append ( "":"" ) ; str . append ( oid . toString ( ) ) ; } else { str . append ( "":-"" ) ; } str . setAddComma ( ) ; if ( getSpecificationNoLoad ( ) == null ) { str . append ( ""class"" , getObject ( ) . getClass ( ) . getName ( ) ) ; } else { str . append ( ""specification"" , getSpecification ( ) . getShortIdentifier ( ) ) ; } if ( getOid ( ) != null ) { final Version version = getOid ( ) . getVersion ( ) ; str . append ( ""version"" , version != null ? version . sequence ( ) : null ) ; } } private String aggregateResolveStateCode ( ) { final Oid oid = getOid ( ) ; if ( oid != null ) { if ( oid . isPersistent ( ) ) return ""P"" ; if ( oid . isTransient ( ) ) return ""T"" ; if ( oid . isViewModel ( ) ) return ""V"" ; } return ""S"" ; } @ Override public String getIconName ( ) { return getSpecification ( ) . getIconName ( this ) ; } @ Override public ObjectSpecification getElementSpecification ( ) { if ( elementSpecificationProvider == null ) { return null ; } return elementSpecificationProvider . getElementType ( ) ; } @ Override public void setElementSpecificationProvider ( final ElementSpecificationProvider elementSpecificationProvider ) { this . elementSpecificationProvider = elementSpecificationProvider ; } @ Override public Instance getInstance ( final Specification specification ) { throw new UnsupportedOperationException ( ) ; } }",Smelly
"public class CalendarValidatorTest extends AbstractCalendarValidatorTest { private static final int DATE_2005_11_23 = 20051123 ; private static final int TIME_12_03_45 = 120345 ; private CalendarValidator calValidator ; public CalendarValidatorTest ( String name ) { super ( name ) ; } @ Override protected void setUp ( ) throws Exception { super . setUp ( ) ; calValidator = new CalendarValidator ( ) ; validator = calValidator ; } public void testCalendarValidatorMethods ( ) { Locale . setDefault ( Locale . US ) ; Locale locale = Locale . GERMAN ; String pattern = ""yyyy-MM-dd"" ; String patternVal = ""2005-12-31"" ; String germanVal = ""31 Dez 2005"" ; String germanPattern = ""dd MMM yyyy"" ; String localeVal = ""31.12.2005"" ; String defaultVal = ""12/31/05"" ; String XXXX = ""XXXX"" ; Date expected = createCalendar ( null , 20051231 , 0 ) . getTime ( ) ; assertEquals ( ""validate(A) default"" , expected , CalendarValidator . getInstance ( ) . validate ( defaultVal ) . getTime ( ) ) ; assertEquals ( ""validate(A) locale "" , expected , CalendarValidator . getInstance ( ) . validate ( localeVal , locale ) . getTime ( ) ) ; assertEquals ( ""validate(A) pattern"" , expected , CalendarValidator . getInstance ( ) . validate ( patternVal , pattern ) . getTime ( ) ) ; assertEquals ( ""validate(A) both"" , expected , CalendarValidator . getInstance ( ) . validate ( germanVal , germanPattern , Locale . GERMAN ) . getTime ( ) ) ; assertTrue ( ""isValid(A) default"" , CalendarValidator . getInstance ( ) . isValid ( defaultVal ) ) ; assertTrue ( ""isValid(A) locale "" , CalendarValidator . getInstance ( ) . isValid ( localeVal , locale ) ) ; assertTrue ( ""isValid(A) pattern"" , CalendarValidator . getInstance ( ) . isValid ( patternVal , pattern ) ) ; assertTrue ( ""isValid(A) both"" , CalendarValidator . getInstance ( ) . isValid ( germanVal , germanPattern , Locale . GERMAN ) ) ; assertNull ( ""validate(B) default"" , CalendarValidator . getInstance ( ) . validate ( XXXX ) ) ; assertNull ( ""validate(B) locale "" , CalendarValidator . getInstance ( ) . validate ( XXXX , locale ) ) ; assertNull ( ""validate(B) pattern"" , CalendarValidator . getInstance ( ) . validate ( XXXX , pattern ) ) ; assertNull ( ""validate(B) both"" , CalendarValidator . getInstance ( ) . validate ( ""31 Dec 2005"" , germanPattern , Locale . GERMAN ) ) ; assertFalse ( ""isValid(B) default"" , CalendarValidator . getInstance ( ) . isValid ( XXXX ) ) ; assertFalse ( ""isValid(B) locale "" , CalendarValidator . getInstance ( ) . isValid ( XXXX , locale ) ) ; assertFalse ( ""isValid(B) pattern"" , CalendarValidator . getInstance ( ) . isValid ( XXXX , pattern ) ) ; assertFalse ( ""isValid(B) both"" , CalendarValidator . getInstance ( ) . isValid ( ""31 Dec 2005"" , germanPattern , Locale . GERMAN ) ) ; TimeZone zone = ( TimeZone . getDefault ( ) . getRawOffset ( ) == EET . getRawOffset ( ) ? EST : EET ) ; Date expectedZone = createCalendar ( zone , 20051231 , 0 ) . getTime ( ) ; assertFalse ( ""default/EET same "" , expected . getTime ( ) == expectedZone . getTime ( ) ) ; assertEquals ( ""validate(C) default"" , expectedZone , CalendarValidator . getInstance ( ) . validate ( defaultVal , zone ) . getTime ( ) ) ; assertEquals ( ""validate(C) locale "" , expectedZone , CalendarValidator . getInstance ( ) . validate ( localeVal , locale , zone ) . getTime ( ) ) ; assertEquals ( ""validate(C) pattern"" , expectedZone , CalendarValidator . getInstance ( ) . validate ( patternVal , pattern , zone ) . getTime ( ) ) ; assertEquals ( ""validate(C) both"" , expectedZone , CalendarValidator . getInstance ( ) . validate ( germanVal , germanPattern , Locale . GERMAN , zone ) . getTime ( ) ) ; } public void testCompare ( ) { int sameTime = 124522 ; int testDate = 20050823 ; Calendar diffHour = createCalendar ( GMT , testDate , 115922 ) ; Calendar diffMin = createCalendar ( GMT , testDate , 124422 ) ; Calendar diffSec = createCalendar ( GMT , testDate , 124521 ) ; Calendar value = createCalendar ( GMT , testDate , sameTime ) ; Calendar cal20050824 = createCalendar ( GMT , 20050824 , sameTime ) ; Calendar cal20050822 = createCalendar ( GMT , 20050822 , sameTime ) ; Calendar cal20050830 = createCalendar ( GMT , 20050830 , sameTime ) ; Calendar cal20050816 = createCalendar ( GMT , 20050816 , sameTime ) ; Calendar cal20050901 = createCalendar ( GMT , 20050901 , sameTime ) ; Calendar cal20050801 = createCalendar ( GMT , 20050801 , sameTime ) ; Calendar cal20050731 = createCalendar ( GMT , 20050731 , sameTime ) ; Calendar cal20051101 = createCalendar ( GMT , 20051101 , sameTime ) ; Calendar cal20051001 = createCalendar ( GMT , 20051001 , sameTime ) ; Calendar cal20050701 = createCalendar ( GMT , 20050701 , sameTime ) ; Calendar cal20050630 = createCalendar ( GMT , 20050630 , sameTime ) ; Calendar cal20060101 = createCalendar ( GMT , 20060101 , sameTime ) ; Calendar cal20050101 = createCalendar ( GMT , 20050101 , sameTime ) ; Calendar cal20041231 = createCalendar ( GMT , 20041231 , sameTime ) ; assertEquals ( ""hour GT"" , 1 , calValidator . compare ( value , diffHour , Calendar . HOUR_OF_DAY ) ) ; assertEquals ( ""hour EQ"" , 0 , calValidator . compare ( value , diffMin , Calendar . HOUR_OF_DAY ) ) ; assertEquals ( ""mins GT"" , 1 , calValidator . compare ( value , diffMin , Calendar . MINUTE ) ) ; assertEquals ( ""mins EQ"" , 0 , calValidator . compare ( value , diffSec , Calendar . MINUTE ) ) ; assertEquals ( ""secs GT"" , 1 , calValidator . compare ( value , diffSec , Calendar . SECOND ) ) ; assertEquals ( ""date LT"" , - 1 , calValidator . compareDates ( value , cal20050824 ) ) ; assertEquals ( ""date EQ"" , 0 , calValidator . compareDates ( value , diffHour ) ) ; assertEquals ( ""date(B)"" , 0 , calValidator . compare ( value , diffHour , Calendar . DAY_OF_YEAR ) ) ; assertEquals ( ""date GT"" , 1 , calValidator . compareDates ( value , cal20050822 ) ) ; assertEquals ( ""week LT"" , - 1 , calValidator . compareWeeks ( value , cal20050830 ) ) ; assertEquals ( ""week =1"" , 0 , calValidator . compareWeeks ( value , cal20050824 ) ) ; assertEquals ( ""week =2"" , 0 , calValidator . compareWeeks ( value , cal20050822 ) ) ; assertEquals ( ""week =3"" , 0 , calValidator . compare ( value , cal20050822 , Calendar . WEEK_OF_MONTH ) ) ; assertEquals ( ""week =4"" , 0 , calValidator . compareWeeks ( value , cal20050822 ) ) ; assertEquals ( ""week GT"" , 1 , calValidator . compareWeeks ( value , cal20050816 ) ) ; assertEquals ( ""mnth LT"" , - 1 , calValidator . compareMonths ( value , cal20050901 ) ) ; assertEquals ( ""mnth =1"" , 0 , calValidator . compareMonths ( value , cal20050830 ) ) ; assertEquals ( ""mnth =2"" , 0 , calValidator . compareMonths ( value , cal20050801 ) ) ; assertEquals ( ""mnth =3"" , 0 , calValidator . compareMonths ( value , cal20050816 ) ) ; assertEquals ( ""mnth GT"" , 1 , calValidator . compareMonths ( value , cal20050731 ) ) ; assertEquals ( ""qtrA <1"" , - 1 , calValidator . compareQuarters ( value , cal20051101 ) ) ; assertEquals ( ""qtrA <2"" , - 1 , calValidator . compareQuarters ( value , cal20051001 ) ) ; assertEquals ( ""qtrA =1"" , 0 , calValidator . compareQuarters ( value , cal20050901 ) ) ; assertEquals ( ""qtrA =2"" , 0 , calValidator . compareQuarters ( value , cal20050701 ) ) ; assertEquals ( ""qtrA =3"" , 0 , calValidator . compareQuarters ( value , cal20050731 ) ) ; assertEquals ( ""qtrA GT"" , 1 , calValidator . compareQuarters ( value , cal20050630 ) ) ; assertEquals ( ""qtrB LT"" , - 1 , calValidator . compareQuarters ( value , cal20051101 , 2 ) ) ; assertEquals ( ""qtrB =1"" , 0 , calValidator . compareQuarters ( value , cal20051001 , 2 ) ) ; assertEquals ( ""qtrB =2"" , 0 , calValidator . compareQuarters ( value , cal20050901 , 2 ) ) ; assertEquals ( ""qtrB =3"" , 1 , calValidator . compareQuarters ( value , cal20050701 , 2 ) ) ; assertEquals ( ""qtrB =4"" , 1 , calValidator . compareQuarters ( value , cal20050731 , 2 ) ) ; assertEquals ( ""qtrB GT"" , 1 , calValidator . compareQuarters ( value , cal20050630 , 2 ) ) ; assertEquals ( ""year LT"" , - 1 , calValidator . compareYears ( value , cal20060101 ) ) ; assertEquals ( ""year EQ"" , 0 , calValidator . compareYears ( value , cal20050101 ) ) ; assertEquals ( ""year GT"" , 1 , calValidator . compareYears ( value , cal20041231 ) ) ; try { calValidator . compare ( value , value , - 1 ) ; fail ( ""Invalid Compare field - expected IllegalArgumentException to be thrown"" ) ; } catch ( IllegalArgumentException e ) { assertEquals ( ""check message"" , ""Invalid field: -1"" , e . getMessage ( ) ) ; } } public void testDateTimeStyle ( ) { Locale origDefault = Locale . getDefault ( ) ; Locale . setDefault ( Locale . UK ) ; AbstractCalendarValidator dateTimeValidator = new AbstractCalendarValidator ( true , DateFormat . SHORT , DateFormat . SHORT ) { private static final long serialVersionUID = 1L ; @ Override protected Object processParsedValue ( Object value , Format formatter ) { return value ; } } ; assertTrue ( ""validate(A) default"" , dateTimeValidator . isValid ( ""31/12/05 14:23"" ) ) ; assertTrue ( ""validate(A) locale "" , dateTimeValidator . isValid ( ""12/31/05 2:23 PM"" , Locale . US ) ) ; Locale . setDefault ( origDefault ) ; } @ Override public void testFormat ( ) { Locale origDefault = Locale . getDefault ( ) ; Locale . setDefault ( Locale . UK ) ; Calendar cal20050101 = createCalendar ( GMT , 20051231 , 11500 ) ; assertNull ( ""null"" , calValidator . format ( null ) ) ; assertEquals ( ""default"" , ""31/12/05"" , calValidator . format ( cal20050101 ) ) ; assertEquals ( ""locale"" , ""12/31/05"" , calValidator . format ( cal20050101 , Locale . US ) ) ; assertEquals ( ""patternA"" , ""2005-12-31 01:15"" , calValidator . format ( cal20050101 , ""yyyy-MM-dd HH:mm"" ) ) ; assertEquals ( ""patternB"" , ""2005-12-31 GMT"" , calValidator . format ( cal20050101 , ""yyyy-MM-dd z"" ) ) ; assertEquals ( ""both"" , ""31 Dez 2005"" , calValidator . format ( cal20050101 , ""dd MMM yyyy"" , Locale . GERMAN ) ) ; assertEquals ( ""EST default"" , ""30/12/05"" , calValidator . format ( cal20050101 , EST ) ) ; assertEquals ( ""EST locale"" , ""12/30/05"" , calValidator . format ( cal20050101 , Locale . US , EST ) ) ; assertEquals ( ""EST patternA"" , ""2005-12-30 20:15"" , calValidator . format ( cal20050101 , ""yyyy-MM-dd HH:mm"" , EST ) ) ; assertEquals ( ""EST patternB"" , ""2005-12-30 EST"" , calValidator . format ( cal20050101 , ""yyyy-MM-dd z"" , EST ) ) ; assertEquals ( ""EST both"" , ""30 Dez 2005"" , calValidator . format ( cal20050101 , ""dd MMM yyyy"" , Locale . GERMAN , EST ) ) ; Locale . setDefault ( origDefault ) ; } public void testAdjustToTimeZone ( ) { Calendar calEST = createCalendar ( EST , DATE_2005_11_23 , TIME_12_03_45 ) ; Date dateEST = calEST . getTime ( ) ; Calendar calGMT = createCalendar ( GMT , DATE_2005_11_23 , TIME_12_03_45 ) ; Date dateGMT = calGMT . getTime ( ) ; Calendar calCET = createCalendar ( EET , DATE_2005_11_23 , TIME_12_03_45 ) ; Date dateCET = calCET . getTime ( ) ; assertFalse ( ""Check GMT != CET"" , dateGMT . getTime ( ) == dateCET . getTime ( ) ) ; assertFalse ( ""Check GMT != EST"" , dateGMT . getTime ( ) == dateEST . getTime ( ) ) ; assertFalse ( ""Check CET != EST"" , dateCET . getTime ( ) == dateEST . getTime ( ) ) ; CalendarValidator . adjustToTimeZone ( calEST , GMT ) ; assertEquals ( ""EST to GMT"" , dateGMT , calEST . getTime ( ) ) ; assertFalse ( ""Check EST = GMT"" , dateEST == calEST . getTime ( ) ) ; CalendarValidator . adjustToTimeZone ( calEST , EST ) ; assertEquals ( ""back to EST"" , dateEST , calEST . getTime ( ) ) ; assertFalse ( ""Check EST != GMT"" , dateGMT == calEST . getTime ( ) ) ; CalendarValidator . adjustToTimeZone ( calCET , GMT ) ; assertEquals ( ""CET to GMT"" , dateGMT , calCET . getTime ( ) ) ; assertFalse ( ""Check CET = GMT"" , dateCET == calCET . getTime ( ) ) ; CalendarValidator . adjustToTimeZone ( calCET , EET ) ; assertEquals ( ""back to CET"" , dateCET , calCET . getTime ( ) ) ; assertFalse ( ""Check CET != GMT"" , dateGMT == calCET . getTime ( ) ) ; Calendar calUTC = createCalendar ( UTC , DATE_2005_11_23 , TIME_12_03_45 ) ; assertTrue ( ""SAME: UTC = GMT"" , UTC . hasSameRules ( GMT ) ) ; assertEquals ( ""SAME: Check time (A)"" , calUTC . getTime ( ) , calGMT . getTime ( ) ) ; assertFalse ( ""SAME: Check GMT(A)"" , GMT . equals ( calUTC . getTimeZone ( ) ) ) ; assertTrue ( ""SAME: Check UTC(A)"" , UTC . equals ( calUTC . getTimeZone ( ) ) ) ; CalendarValidator . adjustToTimeZone ( calUTC , GMT ) ; assertEquals ( ""SAME: Check time (B)"" , calUTC . getTime ( ) , calGMT . getTime ( ) ) ; assertTrue ( ""SAME: Check GMT(B)"" , GMT . equals ( calUTC . getTimeZone ( ) ) ) ; assertFalse ( ""SAME: Check UTC(B)"" , UTC . equals ( calUTC . getTimeZone ( ) ) ) ; } }",Smelly
"public class DefaultContextsService extends AbstractContextsService { private static ThreadLocal < RequestContext > requestContext = null ; private static ThreadLocal < SessionContext > sessionContext = null ; private ApplicationContext applicationContext = null ; private static ThreadLocal < ConversationContext > conversationContext = null ; private static ThreadLocal < SingletonContext > singletonContext = null ; private static ThreadLocal < DependentContext > dependentContext = null ; static { requestContext = new ThreadLocal < RequestContext > ( ) ; sessionContext = new ThreadLocal < SessionContext > ( ) ; conversationContext = new ThreadLocal < ConversationContext > ( ) ; dependentContext = new ThreadLocal < DependentContext > ( ) ; singletonContext = new ThreadLocal < SingletonContext > ( ) ; } @ Override public void endContext ( Class < ? extends Annotation > scopeType , Object endParameters ) { if ( supportsContext ( scopeType ) ) { if ( scopeType . equals ( RequestScoped . class ) ) { stopRequestContext ( endParameters ) ; } else if ( scopeType . equals ( SessionScoped . class ) ) { stopSessionContext ( endParameters ) ; } else if ( scopeType . equals ( ApplicationScoped . class ) ) { stopApplicationContext ( endParameters ) ; } else if ( scopeType . equals ( ConversationScoped . class ) ) { stopConversationContext ( endParameters ) ; } else if ( scopeType . equals ( Dependent . class ) ) { } else { stopSingletonContext ( endParameters ) ; } } } @ Override public Context getCurrentContext ( Class < ? extends Annotation > scopeType ) { if ( scopeType . equals ( RequestScoped . class ) ) { return getCurrentRequestContext ( ) ; } else if ( scopeType . equals ( SessionScoped . class ) ) { return getCurrentSessionContext ( ) ; } else if ( scopeType . equals ( ApplicationScoped . class ) ) { return getCurrentApplicationContext ( ) ; } else if ( scopeType . equals ( ConversationScoped . class ) ) { return getCurrentConversationContext ( ) ; } else if ( scopeType . equals ( Dependent . class ) ) { return getCurrentDependentContext ( ) ; } else if ( scopeType . equals ( Singleton . class ) ) { return getCurrentSingletonContext ( ) ; } return null ; } @ Override public void startContext ( Class < ? extends Annotation > scopeType , Object startParameter ) throws ContextException { try { if ( scopeType . equals ( RequestScoped . class ) ) { startRequestContext ( startParameter ) ; } else if ( scopeType . equals ( SessionScoped . class ) ) { startSessionContext ( startParameter ) ; } else if ( scopeType . equals ( ApplicationScoped . class ) ) { startApplicationContext ( startParameter ) ; } else if ( scopeType . equals ( ConversationScoped . class ) ) { startConversationContext ( ( ConversationContext ) startParameter ) ; } else if ( scopeType . equals ( Dependent . class ) ) { } else if ( scopeType . equals ( Singleton . class ) ) { startSingletonContext ( startParameter ) ; } } catch ( Exception e ) { if ( e instanceof ContextException ) { throw ( ContextException ) e ; } throw new ContextException ( e ) ; } } @ Override public boolean supportsContext ( Class < ? extends Annotation > scopeType ) { if ( scopeType . equals ( RequestScoped . class ) || scopeType . equals ( SessionScoped . class ) || scopeType . equals ( ApplicationScoped . class ) || scopeType . equals ( ConversationScoped . class ) || scopeType . equals ( Dependent . class ) || scopeType . equals ( Singleton . class ) ) { return true ; } return false ; } @ Override public void destroy ( Object destroyObject ) { requestContext . set ( null ) ; sessionContext . set ( null ) ; conversationContext . set ( null ) ; dependentContext . set ( null ) ; singletonContext . set ( null ) ; requestContext . remove ( ) ; sessionContext . remove ( ) ; conversationContext . remove ( ) ; dependentContext . remove ( ) ; singletonContext . remove ( ) ; } private Context getCurrentApplicationContext ( ) { return applicationContext ; } private Context getCurrentConversationContext ( ) { return conversationContext . get ( ) ; } private Context getCurrentDependentContext ( ) { if ( dependentContext . get ( ) == null ) { dependentContext . set ( new DependentContext ( ) ) ; } return dependentContext . get ( ) ; } private Context getCurrentRequestContext ( ) { return requestContext . get ( ) ; } private Context getCurrentSessionContext ( ) { return sessionContext . get ( ) ; } private Context getCurrentSingletonContext ( ) { return singletonContext . get ( ) ; } private void startApplicationContext ( Object instance ) { ApplicationContext ctx = new ApplicationContext ( ) ; ctx . setActive ( true ) ; applicationContext = ctx ; } private void startConversationContext ( Object object ) { ConversationContext ctx = new ConversationContext ( ) ; ctx . setActive ( true ) ; conversationContext . set ( ctx ) ; } private void startRequestContext ( Object instance ) { RequestContext ctx = new RequestContext ( ) ; ctx . setActive ( true ) ; requestContext . set ( ctx ) ; } private void startSessionContext ( Object instance ) { SessionContext ctx = new SessionContext ( ) ; ctx . setActive ( true ) ; sessionContext . set ( ctx ) ; } private void startSingletonContext ( Object object ) { SingletonContext ctx = new SingletonContext ( ) ; ctx . setActive ( true ) ; singletonContext . set ( ctx ) ; } private void stopApplicationContext ( Object object ) { if ( applicationContext != null ) { applicationContext . destroy ( ) ; applicationContext = null ; WebBeansContext . currentInstance ( ) . getBeanManagerImpl ( ) . clearCacheProxies ( ) ; } } private void stopConversationContext ( Object object ) { if ( conversationContext . get ( ) != null ) { conversationContext . get ( ) . destroy ( ) ; } conversationContext . set ( null ) ; conversationContext . remove ( ) ; } private void stopRequestContext ( Object instance ) { if ( requestContext . get ( ) != null ) { requestContext . get ( ) . destroy ( ) ; } requestContext . set ( null ) ; requestContext . remove ( ) ; } private void stopSessionContext ( Object instance ) { if ( sessionContext . get ( ) != null ) { sessionContext . get ( ) . destroy ( ) ; } sessionContext . set ( null ) ; sessionContext . remove ( ) ; } private void stopSingletonContext ( Object object ) { if ( singletonContext . get ( ) != null ) { singletonContext . get ( ) . destroy ( ) ; } singletonContext . set ( null ) ; singletonContext . remove ( ) ; } }",Smelly
"public class WebRuleSet extends RuleSetBase { protected static final StringManager sm = StringManager . getManager ( Constants . Package ) ; protected String prefix = null ; protected String fullPrefix = null ; protected boolean fragment = false ; protected SetSessionConfig sessionConfig = new SetSessionConfig ( ) ; protected SetLoginConfig loginConfig = new SetLoginConfig ( ) ; protected SetJspConfig jspConfig = new SetJspConfig ( ) ; protected NameRule name = new NameRule ( ) ; protected AbsoluteOrderingRule absoluteOrdering ; protected RelativeOrderingRule relativeOrdering ; public WebRuleSet ( ) { this ( """" , false ) ; } public WebRuleSet ( boolean fragment ) { this ( """" , fragment ) ; } public WebRuleSet ( String prefix , boolean fragment ) { super ( ) ; this . namespaceURI = null ; this . prefix = prefix ; this . fragment = fragment ; if ( fragment ) { fullPrefix = prefix + ""web-fragment"" ; } else { fullPrefix = prefix + ""web-app"" ; } absoluteOrdering = new AbsoluteOrderingRule ( fragment ) ; relativeOrdering = new RelativeOrderingRule ( fragment ) ; } @ Override public void addRuleInstances ( Digester digester ) { digester . addRule ( fullPrefix , new SetPublicIdRule ( ""setPublicId"" ) ) ; digester . addRule ( fullPrefix , new IgnoreAnnotationsRule ( ) ) ; digester . addRule ( fullPrefix , new VersionRule ( ) ) ; digester . addRule ( fullPrefix + ""/absolute-ordering"" , absoluteOrdering ) ; digester . addRule ( fullPrefix + ""/ordering"" , relativeOrdering ) ; if ( fragment ) { digester . addRule ( fullPrefix + ""/name"" , name ) ; digester . addCallMethod ( fullPrefix + ""/ordering/after/name"" , ""addAfterOrdering"" , 0 ) ; digester . addCallMethod ( fullPrefix + ""/ordering/after/others"" , ""addAfterOrderingOthers"" ) ; digester . addCallMethod ( fullPrefix + ""/ordering/before/name"" , ""addBeforeOrdering"" , 0 ) ; digester . addCallMethod ( fullPrefix + ""/ordering/before/others"" , ""addBeforeOrderingOthers"" ) ; } else { digester . addCallMethod ( fullPrefix + ""/absolute-ordering/name"" , ""addAbsoluteOrdering"" , 0 ) ; digester . addCallMethod ( fullPrefix + ""/absolute-ordering/others"" , ""addAbsoluteOrderingOthers"" ) ; } digester . addCallMethod ( fullPrefix + ""/context-param"" , ""addContextParam"" , 2 ) ; digester . addCallParam ( fullPrefix + ""/context-param/param-name"" , 0 ) ; digester . addCallParam ( fullPrefix + ""/context-param/param-value"" , 1 ) ; digester . addCallMethod ( fullPrefix + ""/display-name"" , ""setDisplayName"" , 0 ) ; digester . addRule ( fullPrefix + ""/distributable"" , new SetDistributableRule ( ) ) ; configureNamingRules ( digester ) ; digester . addObjectCreate ( fullPrefix + ""/error-page"" , ""org.apache.catalina.deploy.ErrorPage"" ) ; digester . addSetNext ( fullPrefix + ""/error-page"" , ""addErrorPage"" , ""org.apache.catalina.deploy.ErrorPage"" ) ; digester . addCallMethod ( fullPrefix + ""/error-page/error-code"" , ""setErrorCode"" , 0 ) ; digester . addCallMethod ( fullPrefix + ""/error-page/exception-type"" , ""setExceptionType"" , 0 ) ; digester . addCallMethod ( fullPrefix + ""/error-page/location"" , ""setLocation"" , 0 ) ; digester . addObjectCreate ( fullPrefix + ""/filter"" , ""org.apache.catalina.deploy.FilterDef"" ) ; digester . addSetNext ( fullPrefix + ""/filter"" , ""addFilter"" , ""org.apache.catalina.deploy.FilterDef"" ) ; digester . addCallMethod ( fullPrefix + ""/filter/description"" , ""setDescription"" , 0 ) ; digester . addCallMethod ( fullPrefix + ""/filter/display-name"" , ""setDisplayName"" , 0 ) ; digester . addCallMethod ( fullPrefix + ""/filter/filter-class"" , ""setFilterClass"" , 0 ) ; digester . addCallMethod ( fullPrefix + ""/filter/filter-name"" , ""setFilterName"" , 0 ) ; digester . addCallMethod ( fullPrefix + ""/filter/icon/large-icon"" , ""setLargeIcon"" , 0 ) ; digester . addCallMethod ( fullPrefix + ""/filter/icon/small-icon"" , ""setSmallIcon"" , 0 ) ; digester . addCallMethod ( fullPrefix + ""/filter/async-supported"" , ""setAsyncSupported"" , 0 ) ; digester . addCallMethod ( fullPrefix + ""/filter/init-param"" , ""addInitParameter"" , 2 ) ; digester . addCallParam ( fullPrefix + ""/filter/init-param/param-name"" , 0 ) ; digester . addCallParam ( fullPrefix + ""/filter/init-param/param-value"" , 1 ) ; digester . addObjectCreate ( fullPrefix + ""/filter-mapping"" , ""org.apache.catalina.deploy.FilterMap"" ) ; digester . addSetNext ( fullPrefix + ""/filter-mapping"" , ""addFilterMapping"" , ""org.apache.catalina.deploy.FilterMap"" ) ; digester . addCallMethod ( fullPrefix + ""/filter-mapping/filter-name"" , ""setFilterName"" , 0 ) ; digester . addCallMethod ( fullPrefix + ""/filter-mapping/servlet-name"" , ""addServletName"" , 0 ) ; digester . addCallMethod ( fullPrefix + ""/filter-mapping/url-pattern"" , ""addURLPattern"" , 0 ) ; digester . addCallMethod ( fullPrefix + ""/filter-mapping/dispatcher"" , ""setDispatcher"" , 0 ) ; digester . addCallMethod ( fullPrefix + ""/listener/listener-class"" , ""addListener"" , 0 ) ; digester . addRule ( fullPrefix + ""/jsp-config"" , jspConfig ) ; digester . addObjectCreate ( fullPrefix + ""/jsp-config/jsp-property-group"" , ""org.apache.catalina.deploy.JspPropertyGroup"" ) ; digester . addSetNext ( fullPrefix + ""/jsp-config/jsp-property-group"" , ""addJspPropertyGroup"" , ""org.apache.catalina.deploy.JspPropertyGroup"" ) ; digester . addCallMethod ( fullPrefix + ""/jsp-config/jsp-property-group/deferred-syntax-allowed-as-literal"" , ""setDeferredSyntax"" , 0 ) ; digester . addCallMethod ( fullPrefix + ""/jsp-config/jsp-property-group/el-ignored"" , ""setElIgnored"" , 0 ) ; digester . addCallMethod ( fullPrefix + ""/jsp-config/jsp-property-group/include-coda"" , ""addIncludeCoda"" , 0 ) ; digester . addCallMethod ( fullPrefix + ""/jsp-config/jsp-property-group/include-prelude"" , ""addIncludePrelude"" , 0 ) ; digester . addCallMethod ( fullPrefix + ""/jsp-config/jsp-property-group/is-xml"" , ""setIsXml"" , 0 ) ; digester . addCallMethod ( fullPrefix + ""/jsp-config/jsp-property-group/page-encoding"" , ""setPageEncoding"" , 0 ) ; digester . addCallMethod ( fullPrefix + ""/jsp-config/jsp-property-group/scripting-invalid"" , ""setScriptingInvalid"" , 0 ) ; digester . addCallMethod ( fullPrefix + ""/jsp-config/jsp-property-group/trim-directive-whitespaces"" , ""setTrimWhitespace"" , 0 ) ; digester . addCallMethod ( fullPrefix + ""/jsp-config/jsp-property-group/url-pattern"" , ""addUrlPattern"" , 0 ) ; digester . addCallMethod ( fullPrefix + ""/jsp-config/jsp-property-group/default-content-type"" , ""setDefaultContentType"" , 0 ) ; digester . addCallMethod ( fullPrefix + ""/jsp-config/jsp-property-group/buffer"" , ""setBuffer"" , 0 ) ; digester . addCallMethod ( fullPrefix + ""/jsp-config/jsp-property-group/error-on-undeclared-namespace"" , ""setErrorOnUndeclaredNamespace"" , 0 ) ; digester . addRule ( fullPrefix + ""/login-config"" , loginConfig ) ; digester . addObjectCreate ( fullPrefix + ""/login-config"" , ""org.apache.catalina.deploy.LoginConfig"" ) ; digester . addSetNext ( fullPrefix + ""/login-config"" , ""setLoginConfig"" , ""org.apache.catalina.deploy.LoginConfig"" ) ; digester . addCallMethod ( fullPrefix + ""/login-config/auth-method"" , ""setAuthMethod"" , 0 ) ; digester . addCallMethod ( fullPrefix + ""/login-config/realm-name"" , ""setRealmName"" , 0 ) ; digester . addCallMethod ( fullPrefix + ""/login-config/form-login-config/form-error-page"" , ""setErrorPage"" , 0 ) ; digester . addCallMethod ( fullPrefix + ""/login-config/form-login-config/form-login-page"" , ""setLoginPage"" , 0 ) ; digester . addCallMethod ( fullPrefix + ""/mime-mapping"" , ""addMimeMapping"" , 2 ) ; digester . addCallParam ( fullPrefix + ""/mime-mapping/extension"" , 0 ) ; digester . addCallParam ( fullPrefix + ""/mime-mapping/mime-type"" , 1 ) ; digester . addObjectCreate ( fullPrefix + ""/security-constraint"" , ""org.apache.catalina.deploy.SecurityConstraint"" ) ; digester . addSetNext ( fullPrefix + ""/security-constraint"" , ""addSecurityConstraint"" , ""org.apache.catalina.deploy.SecurityConstraint"" ) ; digester . addRule ( fullPrefix + ""/security-constraint/auth-constraint"" , new SetAuthConstraintRule ( ) ) ; digester . addCallMethod ( fullPrefix + ""/security-constraint/auth-constraint/role-name"" , ""addAuthRole"" , 0 ) ; digester . addCallMethod ( fullPrefix + ""/security-constraint/display-name"" , ""setDisplayName"" , 0 ) ; digester . addCallMethod ( fullPrefix + ""/security-constraint/user-data-constraint/transport-guarantee"" , ""setUserConstraint"" , 0 ) ; digester . addObjectCreate ( fullPrefix + ""/security-constraint/web-resource-collection"" , ""org.apache.catalina.deploy.SecurityCollection"" ) ; digester . addSetNext ( fullPrefix + ""/security-constraint/web-resource-collection"" , ""addCollection"" , ""org.apache.catalina.deploy.SecurityCollection"" ) ; digester . addCallMethod ( fullPrefix + ""/security-constraint/web-resource-collection/http-method"" , ""addMethod"" , 0 ) ; digester . addCallMethod ( fullPrefix + ""/security-constraint/web-resource-collection/http-method-omission"" , ""addOmittedMethod"" , 0 ) ; digester . addCallMethod ( fullPrefix + ""/security-constraint/web-resource-collection/url-pattern"" , ""addPattern"" , 0 ) ; digester . addCallMethod ( fullPrefix + ""/security-constraint/web-resource-collection/web-resource-name"" , ""setName"" , 0 ) ; digester . addCallMethod ( fullPrefix + ""/security-role/role-name"" , ""addSecurityRole"" , 0 ) ; digester . addRule ( fullPrefix + ""/servlet"" , new ServletDefCreateRule ( ) ) ; digester . addSetNext ( fullPrefix + ""/servlet"" , ""addServlet"" , ""org.apache.catalina.deploy.ServletDef"" ) ; digester . addCallMethod ( fullPrefix + ""/servlet/init-param"" , ""addInitParameter"" , 2 ) ; digester . addCallParam ( fullPrefix + ""/servlet/init-param/param-name"" , 0 ) ; digester . addCallParam ( fullPrefix + ""/servlet/init-param/param-value"" , 1 ) ; digester . addCallMethod ( fullPrefix + ""/servlet/jsp-file"" , ""setJspFile"" , 0 ) ; digester . addCallMethod ( fullPrefix + ""/servlet/load-on-startup"" , ""setLoadOnStartup"" , 0 ) ; digester . addCallMethod ( fullPrefix + ""/servlet/run-as/role-name"" , ""setRunAs"" , 0 ) ; digester . addObjectCreate ( fullPrefix + ""/servlet/security-role-ref"" , ""org.apache.catalina.deploy.SecurityRoleRef"" ) ; digester . addSetNext ( fullPrefix + ""/servlet/security-role-ref"" , ""addSecurityRoleRef"" , ""org.apache.catalina.deploy.SecurityRoleRef"" ) ; digester . addCallMethod ( fullPrefix + ""/servlet/security-role-ref/role-link"" , ""setLink"" , 0 ) ; digester . addCallMethod ( fullPrefix + ""/servlet/security-role-ref/role-name"" , ""setName"" , 0 ) ; digester . addCallMethod ( fullPrefix + ""/servlet/servlet-class"" , ""setServletClass"" , 0 ) ; digester . addCallMethod ( fullPrefix + ""/servlet/servlet-name"" , ""setServletName"" , 0 ) ; digester . addObjectCreate ( fullPrefix + ""/servlet/multipart-config"" , ""org.apache.catalina.deploy.MultipartDef"" ) ; digester . addSetNext ( fullPrefix + ""/servlet/multipart-config"" , ""setMultipartDef"" , ""org.apache.catalina.deploy.MultipartDef"" ) ; digester . addCallMethod ( fullPrefix + ""/servlet/multipart-config/location"" , ""setLocation"" , 0 ) ; digester . addCallMethod ( fullPrefix + ""/servlet/multipart-config/max-file-size"" , ""setMaxFileSize"" , 0 ) ; digester . addCallMethod ( fullPrefix + ""/servlet/multipart-config/max-request-size"" , ""setMaxRequestSize"" , 0 ) ; digester . addCallMethod ( fullPrefix + ""/servlet/multipart-config/file-size-threshold"" , ""setFileSizeThreshold"" , 0 ) ; digester . addCallMethod ( fullPrefix + ""/servlet/async-supported"" , ""setAsyncSupported"" , 0 ) ; digester . addCallMethod ( fullPrefix + ""/servlet/enabled"" , ""setEnabled"" , 0 ) ; digester . addRule ( fullPrefix + ""/servlet-mapping"" , new CallMethodMultiRule ( ""addServletMapping"" , 2 , 0 ) ) ; digester . addCallParam ( fullPrefix + ""/servlet-mapping/servlet-name"" , 1 ) ; digester . addRule ( fullPrefix + ""/servlet-mapping/url-pattern"" , new CallParamMultiRule ( 0 ) ) ; digester . addRule ( fullPrefix + ""/session-config"" , sessionConfig ) ; digester . addObjectCreate ( fullPrefix + ""/session-config"" , ""org.apache.catalina.deploy.SessionConfig"" ) ; digester . addSetNext ( fullPrefix + ""/session-config"" , ""setSessionConfig"" , ""org.apache.catalina.deploy.SessionConfig"" ) ; digester . addCallMethod ( fullPrefix + ""/session-config/session-timeout"" , ""setSessionTimeout"" , 0 ) ; digester . addCallMethod ( fullPrefix + ""/session-config/cookie-config/name"" , ""setCookieName"" , 0 ) ; digester . addCallMethod ( fullPrefix + ""/session-config/cookie-config/domain"" , ""setCookieDomain"" , 0 ) ; digester . addCallMethod ( fullPrefix + ""/session-config/cookie-config/path"" , ""setCookiePath"" , 0 ) ; digester . addCallMethod ( fullPrefix + ""/session-config/cookie-config/comment"" , ""setCookieComment"" , 0 ) ; digester . addCallMethod ( fullPrefix + ""/session-config/cookie-config/http-only"" , ""setCookieHttpOnly"" , 0 ) ; digester . addCallMethod ( fullPrefix + ""/session-config/cookie-config/secure"" , ""setCookieSecure"" , 0 ) ; digester . addCallMethod ( fullPrefix + ""/session-config/cookie-config/max-age"" , ""setCookieMaxAge"" , 0 ) ; digester . addCallMethod ( fullPrefix + ""/session-config/tracking-mode"" , ""addSessionTrackingMode"" , 0 ) ; digester . addRule ( fullPrefix + ""/taglib"" , new TaglibLocationRule ( false ) ) ; digester . addCallMethod ( fullPrefix + ""/taglib"" , ""addTaglib"" , 2 ) ; digester . addCallParam ( fullPrefix + ""/taglib/taglib-location"" , 1 ) ; digester . addCallParam ( fullPrefix + ""/taglib/taglib-uri"" , 0 ) ; digester . addRule ( fullPrefix + ""/jsp-config/taglib"" , new TaglibLocationRule ( true ) ) ; digester . addCallMethod ( fullPrefix + ""/jsp-config/taglib"" , ""addTaglib"" , 2 ) ; digester . addCallParam ( fullPrefix + ""/jsp-config/taglib/taglib-location"" , 1 ) ; digester . addCallParam ( fullPrefix + ""/jsp-config/taglib/taglib-uri"" , 0 ) ; digester . addCallMethod ( fullPrefix + ""/welcome-file-list/welcome-file"" , ""addWelcomeFile"" , 0 ) ; digester . addCallMethod ( fullPrefix + ""/locale-encoding-mapping-list/locale-encoding-mapping"" , ""addLocaleEncodingMapping"" , 2 ) ; digester . addCallParam ( fullPrefix + ""/locale-encoding-mapping-list/locale-encoding-mapping/locale"" , 0 ) ; digester . addCallParam ( fullPrefix + ""/locale-encoding-mapping-list/locale-encoding-mapping/encoding"" , 1 ) ; digester . addRule ( fullPrefix + ""/post-construct"" , new LifecycleCallbackRule ( ""addPostConstructMethods"" , 2 , true ) ) ; digester . addCallParam ( fullPrefix + ""/post-construct/lifecycle-callback-class"" , 0 ) ; digester . addCallParam ( fullPrefix + ""/post-construct/lifecycle-callback-method"" , 1 ) ; digester . addRule ( fullPrefix + ""/pre-destroy"" , new LifecycleCallbackRule ( ""addPreDestroyMethods"" , 2 , false ) ) ; digester . addCallParam ( fullPrefix + ""/pre-destroy/lifecycle-callback-class"" , 0 ) ; digester . addCallParam ( fullPrefix + ""/pre-destroy/lifecycle-callback-method"" , 1 ) ; } protected void configureNamingRules ( Digester digester ) { digester . addObjectCreate ( fullPrefix + ""/ejb-local-ref"" , ""org.apache.catalina.deploy.ContextLocalEjb"" ) ; digester . addSetNext ( fullPrefix + ""/ejb-local-ref"" , ""addEjbLocalRef"" , ""org.apache.catalina.deploy.ContextLocalEjb"" ) ; digester . addCallMethod ( fullPrefix + ""/ejb-local-ref/description"" , ""setDescription"" , 0 ) ; digester . addCallMethod ( fullPrefix + ""/ejb-local-ref/ejb-link"" , ""setLink"" , 0 ) ; digester . addCallMethod ( fullPrefix + ""/ejb-local-ref/ejb-ref-name"" , ""setName"" , 0 ) ; digester . addCallMethod ( fullPrefix + ""/ejb-local-ref/ejb-ref-type"" , ""setType"" , 0 ) ; digester . addCallMethod ( fullPrefix + ""/ejb-local-ref/local"" , ""setLocal"" , 0 ) ; digester . addCallMethod ( fullPrefix + ""/ejb-local-ref/local-home"" , ""setHome"" , 0 ) ; digester . addRule ( fullPrefix + ""/ejb-local-ref/mapped-name"" , new MappedNameRule ( ) ) ; configureInjectionRules ( digester , ""web-app/ejb-local-ref/"" ) ; digester . addObjectCreate ( fullPrefix + ""/ejb-ref"" , ""org.apache.catalina.deploy.ContextEjb"" ) ; digester . addSetNext ( fullPrefix + ""/ejb-ref"" , ""addEjbRef"" , ""org.apache.catalina.deploy.ContextEjb"" ) ; digester . addCallMethod ( fullPrefix + ""/ejb-ref/description"" , ""setDescription"" , 0 ) ; digester . addCallMethod ( fullPrefix + ""/ejb-ref/ejb-link"" , ""setLink"" , 0 ) ; digester . addCallMethod ( fullPrefix + ""/ejb-ref/ejb-ref-name"" , ""setName"" , 0 ) ; digester . addCallMethod ( fullPrefix + ""/ejb-ref/ejb-ref-type"" , ""setType"" , 0 ) ; digester . addCallMethod ( fullPrefix + ""/ejb-ref/home"" , ""setHome"" , 0 ) ; digester . addCallMethod ( fullPrefix + ""/ejb-ref/remote"" , ""setRemote"" , 0 ) ; digester . addRule ( fullPrefix + ""/ejb-ref/mapped-name"" , new MappedNameRule ( ) ) ; configureInjectionRules ( digester , ""web-app/ejb-ref/"" ) ; digester . addObjectCreate ( fullPrefix + ""/env-entry"" , ""org.apache.catalina.deploy.ContextEnvironment"" ) ; digester . addSetNext ( fullPrefix + ""/env-entry"" , ""addEnvEntry"" , ""org.apache.catalina.deploy.ContextEnvironment"" ) ; digester . addRule ( fullPrefix + ""/env-entry"" , new SetOverrideRule ( ) ) ; digester . addCallMethod ( fullPrefix + ""/env-entry/description"" , ""setDescription"" , 0 ) ; digester . addCallMethod ( fullPrefix + ""/env-entry/env-entry-name"" , ""setName"" , 0 ) ; digester . addCallMethod ( fullPrefix + ""/env-entry/env-entry-type"" , ""setType"" , 0 ) ; digester . addCallMethod ( fullPrefix + ""/env-entry/env-entry-value"" , ""setValue"" , 0 ) ; digester . addRule ( fullPrefix + ""/env-entry/mapped-name"" , new MappedNameRule ( ) ) ; configureInjectionRules ( digester , ""web-app/env-entry/"" ) ; digester . addObjectCreate ( fullPrefix + ""/resource-env-ref"" , ""org.apache.catalina.deploy.ContextResourceEnvRef"" ) ; digester . addSetNext ( fullPrefix + ""/resource-env-ref"" , ""addResourceEnvRef"" , ""org.apache.catalina.deploy.ContextResourceEnvRef"" ) ; digester . addCallMethod ( fullPrefix + ""/resource-env-ref/resource-env-ref-name"" , ""setName"" , 0 ) ; digester . addCallMethod ( fullPrefix + ""/resource-env-ref/resource-env-ref-type"" , ""setType"" , 0 ) ; digester . addRule ( fullPrefix + ""/resource-env-ref/mapped-name"" , new MappedNameRule ( ) ) ; configureInjectionRules ( digester , ""web-app/resource-env-ref/"" ) ; digester . addObjectCreate ( fullPrefix + ""/message-destination"" , ""org.apache.catalina.deploy.MessageDestination"" ) ; digester . addSetNext ( fullPrefix + ""/message-destination"" , ""addMessageDestination"" , ""org.apache.catalina.deploy.MessageDestination"" ) ; digester . addCallMethod ( fullPrefix + ""/message-destination/description"" , ""setDescription"" , 0 ) ; digester . addCallMethod ( fullPrefix + ""/message-destination/display-name"" , ""setDisplayName"" , 0 ) ; digester . addCallMethod ( fullPrefix + ""/message-destination/icon/large-icon"" , ""setLargeIcon"" , 0 ) ; digester . addCallMethod ( fullPrefix + ""/message-destination/icon/small-icon"" , ""setSmallIcon"" , 0 ) ; digester . addCallMethod ( fullPrefix + ""/message-destination/message-destination-name"" , ""setName"" , 0 ) ; digester . addRule ( fullPrefix + ""/message-destination/mapped-name"" , new MappedNameRule ( ) ) ; digester . addObjectCreate ( fullPrefix + ""/message-destination-ref"" , ""org.apache.catalina.deploy.MessageDestinationRef"" ) ; digester . addSetNext ( fullPrefix + ""/message-destination-ref"" , ""addMessageDestinationRef"" , ""org.apache.catalina.deploy.MessageDestinationRef"" ) ; digester . addCallMethod ( fullPrefix + ""/message-destination-ref/description"" , ""setDescription"" , 0 ) ; digester . addCallMethod ( fullPrefix + ""/message-destination-ref/message-destination-link"" , ""setLink"" , 0 ) ; digester . addCallMethod ( fullPrefix + ""/message-destination-ref/message-destination-ref-name"" , ""setName"" , 0 ) ; digester . addCallMethod ( fullPrefix + ""/message-destination-ref/message-destination-type"" , ""setType"" , 0 ) ; digester . addCallMethod ( fullPrefix + ""/message-destination-ref/message-destination-usage"" , ""setUsage"" , 0 ) ; digester . addRule ( fullPrefix + ""/message-destination-ref/mapped-name"" , new MappedNameRule ( ) ) ; configureInjectionRules ( digester , ""web-app/message-destination-ref/"" ) ; digester . addObjectCreate ( fullPrefix + ""/resource-ref"" , ""org.apache.catalina.deploy.ContextResource"" ) ; digester . addSetNext ( fullPrefix + ""/resource-ref"" , ""addResourceRef"" , ""org.apache.catalina.deploy.ContextResource"" ) ; digester . addCallMethod ( fullPrefix + ""/resource-ref/description"" , ""setDescription"" , 0 ) ; digester . addCallMethod ( fullPrefix + ""/resource-ref/res-auth"" , ""setAuth"" , 0 ) ; digester . addCallMethod ( fullPrefix + ""/resource-ref/res-ref-name"" , ""setName"" , 0 ) ; digester . addCallMethod ( fullPrefix + ""/resource-ref/res-sharing-scope"" , ""setScope"" , 0 ) ; digester . addCallMethod ( fullPrefix + ""/resource-ref/res-type"" , ""setType"" , 0 ) ; digester . addRule ( fullPrefix + ""/resource-ref/mapped-name"" , new MappedNameRule ( ) ) ; configureInjectionRules ( digester , ""web-app/resource-ref/"" ) ; digester . addObjectCreate ( fullPrefix + ""/service-ref"" , ""org.apache.catalina.deploy.ContextService"" ) ; digester . addSetNext ( fullPrefix + ""/service-ref"" , ""addServiceRef"" , ""org.apache.catalina.deploy.ContextService"" ) ; digester . addCallMethod ( fullPrefix + ""/service-ref/description"" , ""setDescription"" , 0 ) ; digester . addCallMethod ( fullPrefix + ""/service-ref/display-name"" , ""setDisplayname"" , 0 ) ; digester . addCallMethod ( fullPrefix + ""/service-ref/icon/large-icon"" , ""setLargeIcon"" , 0 ) ; digester . addCallMethod ( fullPrefix + ""/service-ref/icon/small-icon"" , ""setSmallIcon"" , 0 ) ; digester . addCallMethod ( fullPrefix + ""/service-ref/service-ref-name"" , ""setName"" , 0 ) ; digester . addCallMethod ( fullPrefix + ""/service-ref/service-interface"" , ""setInterface"" , 0 ) ; digester . addCallMethod ( fullPrefix + ""/service-ref/service-ref-type"" , ""setType"" , 0 ) ; digester . addCallMethod ( fullPrefix + ""/service-ref/wsdl-file"" , ""setWsdlfile"" , 0 ) ; digester . addCallMethod ( fullPrefix + ""/service-ref/jaxrpc-mapping-file"" , ""setJaxrpcmappingfile"" , 0 ) ; digester . addRule ( fullPrefix + ""/service-ref/service-qname"" , new ServiceQnameRule ( ) ) ; digester . addRule ( fullPrefix + ""/service-ref/port-component-ref"" , new CallMethodMultiRule ( ""addPortcomponent"" , 2 , 1 ) ) ; digester . addCallParam ( fullPrefix + ""/service-ref/port-component-ref/service-endpoint-interface"" , 0 ) ; digester . addRule ( fullPrefix + ""/service-ref/port-component-ref/port-component-link"" , new CallParamMultiRule ( 1 ) ) ; digester . addObjectCreate ( fullPrefix + ""/service-ref/handler"" , ""org.apache.catalina.deploy.ContextHandler"" ) ; digester . addRule ( fullPrefix + ""/service-ref/handler"" , new SetNextRule ( ""addHandler"" , ""org.apache.catalina.deploy.ContextHandler"" ) ) ; digester . addCallMethod ( fullPrefix + ""/service-ref/handler/handler-name"" , ""setName"" , 0 ) ; digester . addCallMethod ( fullPrefix + ""/service-ref/handler/handler-class"" , ""setHandlerclass"" , 0 ) ; digester . addCallMethod ( fullPrefix + ""/service-ref/handler/init-param"" , ""setProperty"" , 2 ) ; digester . addCallParam ( fullPrefix + ""/service-ref/handler/init-param/param-name"" , 0 ) ; digester . addCallParam ( fullPrefix + ""/service-ref/handler/init-param/param-value"" , 1 ) ; digester . addRule ( fullPrefix + ""/service-ref/handler/soap-header"" , new SoapHeaderRule ( ) ) ; digester . addCallMethod ( fullPrefix + ""/service-ref/handler/soap-role"" , ""addSoapRole"" , 0 ) ; digester . addCallMethod ( fullPrefix + ""/service-ref/handler/port-name"" , ""addPortName"" , 0 ) ; digester . addRule ( fullPrefix + ""/service-ref/mapped-name"" , new MappedNameRule ( ) ) ; configureInjectionRules ( digester , ""web-app/service-ref/"" ) ; } protected void configureInjectionRules ( Digester digester , String base ) { digester . addCallMethod ( prefix + base + ""injection-target"" , ""addInjectionTarget"" , 2 ) ; digester . addCallParam ( prefix + base + ""injection-target/injection-target-class"" , 0 ) ; digester . addCallParam ( prefix + base + ""injection-target/injection-target-name"" , 1 ) ; } public void recycle ( ) { jspConfig . isJspConfigSet = false ; sessionConfig . isSessionConfigSet = false ; loginConfig . isLoginConfigSet = false ; name . isNameSet = false ; absoluteOrdering . isAbsoluteOrderingSet = false ; relativeOrdering . isRelativeOrderingSet = false ; } }",Smelly
"@ Entity @ Table ( name = ""DC_ACCOUNT"" ) public class Account implements IAccount { public Account ( ) { } public Account ( String name , IUserIdentity uid ) { setName ( name ) ; setUserIdent ( uid ) ; } @ Id @ GeneratedValue @ Column ( name = ""ACCT_ID"" ) private int id ; @ ManyToOne ( fetch = FetchType . LAZY ) @ JoinColumn ( name = ""UID_ID"" ) private UserIdentity userIdent ; private String name ; public void setId ( int id ) { this . id = id ; } public int getId ( ) { return id ; } public void setName ( String name ) { this . name = name ; } public String getName ( ) { return name ; } public void setUserIdent ( IUserIdentity userIdent ) { this . userIdent = ( UserIdentity ) userIdent ; } public IUserIdentity getUserIdent ( ) { return userIdent ; } }",No
"public class InternalValue extends AbstractQValue { public static final InternalValue [ ] EMPTY_ARRAY = new InternalValue [ 0 ] ; private static final InternalValue BOOLEAN_TRUE = new InternalValue ( true ) ; private static final InternalValue BOOLEAN_FALSE = new InternalValue ( false ) ; private static final int MIN_BLOB_FILE_SIZE = 1024 ; public static InternalValue create ( Value value , NamePathResolver resolver ) throws ValueFormatException , RepositoryException { return create ( value , resolver , null ) ; } public static InternalValue create ( Value value , NamePathResolver resolver , DataStore store ) throws ValueFormatException , RepositoryException { switch ( value . getType ( ) ) { case PropertyType . BINARY : BLOBFileValue blob = null ; if ( value instanceof BinaryValueImpl ) { BinaryValueImpl bin = ( BinaryValueImpl ) value ; DataIdentifier identifier = bin . getDataIdentifier ( ) ; if ( identifier != null ) { if ( store . getRecordIfStored ( identifier ) != null ) { blob = BLOBInDataStore . getInstance ( store , identifier ) ; } } } if ( blob == null ) { Binary b = value . getBinary ( ) ; boolean dispose = false ; try { if ( b instanceof BLOBFileValue ) { blob = ( BLOBFileValue ) b ; } else { dispose = true ; blob = getBLOBFileValue ( store , b . getStream ( ) , true ) ; } } finally { if ( dispose ) { b . dispose ( ) ; } } } return new InternalValue ( blob ) ; case PropertyType . BOOLEAN : return create ( value . getBoolean ( ) ) ; case PropertyType . DATE : return create ( value . getDate ( ) ) ; case PropertyType . DOUBLE : return create ( value . getDouble ( ) ) ; case PropertyType . DECIMAL : return create ( value . getDecimal ( ) ) ; case PropertyType . LONG : return create ( value . getLong ( ) ) ; case PropertyType . REFERENCE : return create ( new NodeId ( value . getString ( ) ) ) ; case PropertyType . WEAKREFERENCE : return create ( new NodeId ( value . getString ( ) ) , true ) ; case PropertyType . URI : try { return create ( new URI ( value . getString ( ) ) ) ; } catch ( URISyntaxException e ) { throw new ValueFormatException ( e . getMessage ( ) ) ; } case PropertyType . NAME : try { if ( value instanceof QValueValue ) { QValue qv = ( ( QValueValue ) value ) . getQValue ( ) ; if ( qv instanceof InternalValue ) { return ( InternalValue ) qv ; } else { return create ( qv . getName ( ) ) ; } } else { return create ( resolver . getQName ( value . getString ( ) ) ) ; } } catch ( NameException e ) { throw new ValueFormatException ( e . getMessage ( ) ) ; } case PropertyType . PATH : try { if ( value instanceof QValueValue ) { QValue qv = ( ( QValueValue ) value ) . getQValue ( ) ; if ( qv instanceof InternalValue ) { return ( InternalValue ) qv ; } else { return create ( qv . getPath ( ) ) ; } } else { return create ( resolver . getQPath ( value . getString ( ) , false ) ) ; } } catch ( MalformedPathException mpe ) { throw new ValueFormatException ( mpe . getMessage ( ) ) ; } case PropertyType . STRING : return create ( value . getString ( ) ) ; default : throw new IllegalArgumentException ( ""illegal value"" ) ; } } public static InternalValue create ( QValue value ) throws RepositoryException { switch ( value . getType ( ) ) { case PropertyType . BINARY : try { return create ( value . getString ( ) . getBytes ( AbstractQValueFactory . DEFAULT_ENCODING ) ) ; } catch ( UnsupportedEncodingException e ) { throw new InternalError ( AbstractQValueFactory . DEFAULT_ENCODING + "" not supported"" ) ; } case PropertyType . BOOLEAN : return new InternalValue ( value . getBoolean ( ) ) ; case PropertyType . DATE : return new InternalValue ( value . getCalendar ( ) ) ; case PropertyType . DOUBLE : return new InternalValue ( value . getDouble ( ) ) ; case PropertyType . DECIMAL : return new InternalValue ( value . getDecimal ( ) ) ; case PropertyType . LONG : return new InternalValue ( value . getLong ( ) ) ; case PropertyType . REFERENCE : return create ( new NodeId ( value . getString ( ) ) ) ; case PropertyType . WEAKREFERENCE : return create ( new NodeId ( value . getString ( ) ) , true ) ; case PropertyType . URI : return new InternalValue ( value . getURI ( ) ) ; case PropertyType . NAME : return new InternalValue ( value . getName ( ) ) ; case PropertyType . PATH : return new InternalValue ( value . getPath ( ) ) ; case PropertyType . STRING : return new InternalValue ( value . getString ( ) ) ; default : throw new IllegalArgumentException ( ""illegal value"" ) ; } } public static InternalValue [ ] create ( QValue [ ] values ) throws RepositoryException { if ( values == null ) { return null ; } InternalValue [ ] tmp = new InternalValue [ values . length ] ; for ( int i = 0 ; i < values . length ; i ++ ) { tmp [ i ] = InternalValue . create ( values [ i ] ) ; } return tmp ; } static InternalValue getInternalValue ( DataIdentifier identifier , DataStore store ) throws DataStoreException { if ( store . getRecordIfStored ( identifier ) != null ) { BLOBFileValue blob = BLOBInDataStore . getInstance ( store , identifier ) ; return new InternalValue ( blob ) ; } return null ; } public static InternalValue create ( String value ) { return new InternalValue ( value ) ; } public static InternalValue create ( long value ) { return new InternalValue ( value ) ; } public static InternalValue create ( double value ) { return new InternalValue ( value ) ; } public static InternalValue create ( Calendar value ) { return new InternalValue ( value ) ; } public static InternalValue create ( BigDecimal value ) { return new InternalValue ( value ) ; } static InternalValue create ( URI value ) { return new InternalValue ( value ) ; } public static InternalValue create ( boolean value ) { return value ? BOOLEAN_TRUE : BOOLEAN_FALSE ; } public static InternalValue create ( byte [ ] value ) { return new InternalValue ( BLOBInMemory . getInstance ( value ) ) ; } public static InternalValue createTemporary ( InputStream value ) throws RepositoryException { return new InternalValue ( getBLOBFileValue ( null , value , true ) ) ; } public static InternalValue create ( InputStream value , DataStore store ) throws RepositoryException { return new InternalValue ( getBLOBFileValue ( store , value , false ) ) ; } public static InternalValue create ( InputStream value ) throws RepositoryException { return create ( value , null ) ; } public static InternalValue create ( FileSystemResource value ) throws IOException { return new InternalValue ( BLOBInResource . getInstance ( value ) ) ; } public static InternalValue create ( DataStore store , String id ) { return new InternalValue ( getBLOBFileValue ( store , id ) ) ; } public static InternalValue create ( Name value ) { return new InternalValue ( value ) ; } public static InternalValue [ ] create ( Name [ ] values ) { InternalValue [ ] ret = new InternalValue [ values . length ] ; for ( int i = 0 ; i < values . length ; i ++ ) { ret [ i ] = new InternalValue ( values [ i ] ) ; } return ret ; } public static InternalValue create ( Path value ) { return new InternalValue ( value ) ; } public static InternalValue create ( NodeId value ) { return create ( value , false ) ; } public static InternalValue create ( NodeId value , boolean weak ) { return new InternalValue ( value , weak ) ; } BLOBFileValue getBLOBFileValue ( ) { assert val != null && type == PropertyType . BINARY ; return ( BLOBFileValue ) val ; } public NodeId getNodeId ( ) { assert val != null && ( type == PropertyType . REFERENCE || type == PropertyType . WEAKREFERENCE ) ; return ( NodeId ) val ; } public Calendar getDate ( ) { assert val != null && type == PropertyType . DATE ; return ( Calendar ) val ; } public InternalValue createCopy ( ) throws RepositoryException { if ( type != PropertyType . BINARY ) { return this ; } return new InternalValue ( ( ( BLOBFileValue ) val ) . copy ( ) ) ; } public static InternalValue valueOf ( String s , int type ) { switch ( type ) { case PropertyType . BOOLEAN : return create ( Boolean . valueOf ( s ) ) ; case PropertyType . DATE : return create ( ISO8601 . parse ( s ) ) ; case PropertyType . DOUBLE : return create ( Double . parseDouble ( s ) ) ; case PropertyType . LONG : return create ( Long . parseLong ( s ) ) ; case PropertyType . DECIMAL : return create ( new BigDecimal ( s ) ) ; case PropertyType . REFERENCE : return create ( new NodeId ( s ) ) ; case PropertyType . WEAKREFERENCE : return create ( new NodeId ( s ) , true ) ; case PropertyType . PATH : return create ( PathFactoryImpl . getInstance ( ) . create ( s ) ) ; case PropertyType . NAME : return create ( NameFactoryImpl . getInstance ( ) . create ( s ) ) ; case PropertyType . URI : return create ( URI . create ( s ) ) ; case PropertyType . STRING : return create ( s ) ; case PropertyType . BINARY : throw new IllegalArgumentException ( ""this method does not support the type PropertyType.BINARY"" ) ; default : throw new IllegalArgumentException ( ""illegal type: "" + type ) ; } } public String toString ( ) { if ( type == PropertyType . DATE ) { return ISO8601 . format ( ( Calendar ) val ) ; } else { return val . toString ( ) ; } } private InternalValue ( String value ) { super ( value , PropertyType . STRING ) ; } private InternalValue ( Name value ) { super ( value ) ; } private InternalValue ( long value ) { super ( value ) ; } private InternalValue ( double value ) { super ( value ) ; } private InternalValue ( Calendar value ) { super ( value , PropertyType . DATE ) ; } private InternalValue ( boolean value ) { super ( value ) ; } private InternalValue ( URI value ) { super ( value ) ; } private InternalValue ( BigDecimal value ) { super ( value ) ; } private InternalValue ( BLOBFileValue value ) { super ( value , PropertyType . BINARY ) ; } private InternalValue ( Path value ) { super ( value ) ; } private InternalValue ( NodeId value , boolean weak ) { super ( value , weak ? PropertyType . WEAKREFERENCE : PropertyType . REFERENCE ) ; } private static BLOBFileValue getBLOBFileValue ( DataStore store , InputStream in , boolean temporary ) throws RepositoryException { int maxMemorySize ; if ( store != null ) { maxMemorySize = store . getMinRecordLength ( ) - 1 ; } else { maxMemorySize = MIN_BLOB_FILE_SIZE ; } maxMemorySize = Math . max ( 0 , maxMemorySize ) ; byte [ ] buffer = new byte [ maxMemorySize ] ; int pos = 0 , len = maxMemorySize ; try { while ( pos < maxMemorySize ) { int l = in . read ( buffer , pos , len ) ; if ( l < 0 ) { break ; } pos += l ; len -= l ; } } catch ( IOException e ) { throw new RepositoryException ( ""Could not read from stream"" , e ) ; } if ( pos < maxMemorySize ) { byte [ ] data = new byte [ pos ] ; System . arraycopy ( buffer , 0 , data , 0 , pos ) ; return BLOBInMemory . getInstance ( data ) ; } else { in = new SequenceInputStream ( new ByteArrayInputStream ( buffer , 0 , pos ) , in ) ; if ( store != null ) { return BLOBInDataStore . getInstance ( store , in ) ; } else { return BLOBInTempFile . getInstance ( in , temporary ) ; } } } private static BLOBFileValue getBLOBFileValue ( DataStore store , String id ) { if ( BLOBInMemory . isInstance ( id ) ) { return BLOBInMemory . getInstance ( id ) ; } else if ( BLOBInDataStore . isInstance ( id ) ) { return BLOBInDataStore . getInstance ( store , id ) ; } else { throw new IllegalArgumentException ( ""illegal binary id: "" + id ) ; } } public void store ( DataStore dataStore ) throws RepositoryException { assert dataStore != null ; assert type == PropertyType . BINARY ; BLOBFileValue v = ( BLOBFileValue ) val ; if ( v instanceof BLOBInDataStore ) { return ; } val = BLOBInDataStore . getInstance ( dataStore , getStream ( ) ) ; } public long getLength ( ) throws RepositoryException { if ( PropertyType . BINARY == type ) { return ( ( Binary ) val ) . getSize ( ) ; } else { return super . getLength ( ) ; } } public String getString ( ) throws RepositoryException { if ( type == PropertyType . BINARY ) { InputStream stream = getStream ( ) ; try { return IOUtils . toString ( stream , ""UTF-8"" ) ; } catch ( IOException e ) { throw new RepositoryException ( ""conversion from stream to string failed"" , e ) ; } finally { IOUtils . closeQuietly ( stream ) ; } } else if ( type == PropertyType . DATE ) { return ISO8601 . format ( ( ( Calendar ) val ) ) ; } else { return toString ( ) ; } } public InputStream getStream ( ) throws RepositoryException { if ( type == PropertyType . BINARY ) { return ( ( Binary ) val ) . getStream ( ) ; } else { try { return new ByteArrayInputStream ( getString ( ) . getBytes ( InternalValueFactory . DEFAULT_ENCODING ) ) ; } catch ( UnsupportedEncodingException e ) { throw new RepositoryException ( InternalValueFactory . DEFAULT_ENCODING + "" is not supported encoding on this platform"" , e ) ; } } } public Binary getBinary ( ) throws RepositoryException { if ( type == PropertyType . BINARY ) { return ( ( BLOBFileValue ) val ) . copy ( ) ; } else { try { byte [ ] data = getString ( ) . getBytes ( InternalValueFactory . DEFAULT_ENCODING ) ; return BLOBInMemory . getInstance ( data ) ; } catch ( UnsupportedEncodingException e ) { throw new RepositoryException ( InternalValueFactory . DEFAULT_ENCODING + "" is not supported encoding on this platform"" , e ) ; } } } public void discard ( ) { if ( type == PropertyType . BINARY ) { BLOBFileValue bfv = ( BLOBFileValue ) val ; bfv . dispose ( ) ; } else { super . discard ( ) ; } } public void deleteBinaryResource ( ) { if ( type == PropertyType . BINARY ) { BLOBFileValue bfv = ( BLOBFileValue ) val ; bfv . delete ( true ) ; } } }",Smelly
"public abstract class AbstractTypeTestClient2 extends AbstractTypeTestClient { protected < T > boolean equalsNilable ( T x , T y ) { if ( x == null ) { return y == null ; } else if ( y == null ) { return false ; } else { return x . equals ( y ) ; } } protected < T > boolean notNull ( T x , T y ) { return x != null && y != null ; } @ Test public void testEmptyStruct ( ) throws Exception { if ( ! shouldRunTest ( ""EmptyStruct"" ) ) { return ; } EmptyStruct x = new EmptyStruct ( ) ; EmptyStruct yOrig = new EmptyStruct ( ) ; Holder < EmptyStruct > y = new Holder < EmptyStruct > ( yOrig ) ; Holder < EmptyStruct > z = new Holder < EmptyStruct > ( ) ; EmptyStruct ret ; if ( testDocLiteral ) { ret = docClient . testEmptyStruct ( x , y , z ) ; } else if ( testXMLBinding ) { ret = xmlClient . testEmptyStruct ( x , y , z ) ; } else { ret = rpcClient . testEmptyStruct ( x , y , z ) ; } if ( ! perfTestOnly ) { assertTrue ( ""testEmptyStruct(): Null value for inout param"" , notNull ( x , y . value ) ) ; assertTrue ( ""testEmptyStruct(): Null value for out param"" , notNull ( yOrig , z . value ) ) ; assertTrue ( ""testEmptyStruct(): Null return value"" , notNull ( x , ret ) ) ; } DerivedStructBaseEmpty derivedX = new DerivedStructBaseEmpty ( ) ; derivedX . setVarFloatExt ( - 3.14f ) ; derivedX . setVarStringExt ( ""DerivedStruct-x"" ) ; derivedX . setAttrString ( ""DerivedAttr-x"" ) ; DerivedStructBaseEmpty derivedY = new DerivedStructBaseEmpty ( ) ; derivedY . setVarFloatExt ( 1.414f ) ; derivedY . setVarStringExt ( ""DerivedStruct-y"" ) ; derivedY . setAttrString ( ""DerivedAttr-y"" ) ; y = new Holder < EmptyStruct > ( derivedY ) ; z = new Holder < EmptyStruct > ( ) ; if ( testDocLiteral ) { ret = docClient . testEmptyStruct ( derivedX , y , z ) ; } else if ( testXMLBinding ) { ret = xmlClient . testEmptyStruct ( derivedX , y , z ) ; } else { ret = rpcClient . testEmptyStruct ( derivedX , y , z ) ; } if ( ! perfTestOnly ) { assertTrue ( ""testEmptyStruct(): Null value for inout param"" , notNull ( derivedX , y . value ) ) ; assertTrue ( ""testEmptyStruct(): Null value for out param"" , notNull ( derivedY , z . value ) ) ; assertTrue ( ""testEmptyStruct(): Null return value"" , notNull ( derivedX , ret ) ) ; } } protected boolean equals ( SimpleStruct x , SimpleStruct y ) { return ( Double . compare ( x . getVarFloat ( ) , y . getVarFloat ( ) ) == 0 ) && ( x . getVarInt ( ) . compareTo ( y . getVarInt ( ) ) == 0 ) && ( x . getVarString ( ) . equals ( y . getVarString ( ) ) ) && ( equalsNilable ( x . getVarAttrString ( ) , y . getVarAttrString ( ) ) ) ; } @ Test public void testSimpleStruct ( ) throws Exception { if ( ! shouldRunTest ( ""SimpleStruct"" ) ) { return ; } SimpleStruct x = new SimpleStruct ( ) ; x . setVarFloat ( 3.14f ) ; x . setVarInt ( new BigInteger ( ""42"" ) ) ; x . setVarString ( ""Hello There"" ) ; SimpleStruct yOrig = new SimpleStruct ( ) ; yOrig . setVarFloat ( 1.414f ) ; yOrig . setVarInt ( new BigInteger ( ""13"" ) ) ; yOrig . setVarString ( ""Cheerio"" ) ; Holder < SimpleStruct > y = new Holder < SimpleStruct > ( yOrig ) ; Holder < SimpleStruct > z = new Holder < SimpleStruct > ( ) ; SimpleStruct ret ; if ( testDocLiteral ) { ret = docClient . testSimpleStruct ( x , y , z ) ; } else if ( testXMLBinding ) { ret = xmlClient . testSimpleStruct ( x , y , z ) ; } else { ret = rpcClient . testSimpleStruct ( x , y , z ) ; } if ( ! perfTestOnly ) { assertTrue ( ""testSimpleStruct(): Incorrect value for inout param"" , equals ( x , y . value ) ) ; assertTrue ( ""testSimpleStruct(): Incorrect value for out param"" , equals ( yOrig , z . value ) ) ; assertTrue ( ""testSimpleStruct(): Incorrect return value"" , equals ( x , ret ) ) ; } } protected boolean equals ( StructWithNillables x , StructWithNillables y ) { return equalsNilable ( x . getVarFloat ( ) , y . getVarFloat ( ) ) && equalsNilable ( x . getVarInt ( ) , x . getVarInt ( ) ) && equalsNilable ( x . getVarString ( ) , y . getVarString ( ) ) && equalsNilable ( x . getVarStruct ( ) , y . getVarStruct ( ) ) ; } @ Test public void testStructWithNillables ( ) throws Exception { if ( ! shouldRunTest ( ""StructWithNillables"" ) ) { return ; } StructWithNillables x = new StructWithNillables ( ) ; StructWithNillables yOrig = new StructWithNillables ( ) ; yOrig . setVarFloat ( new Float ( 1.414f ) ) ; yOrig . setVarInt ( new Integer ( 13 ) ) ; yOrig . setVarString ( ""Cheerio"" ) ; Holder < StructWithNillables > y = new Holder < StructWithNillables > ( yOrig ) ; Holder < StructWithNillables > z = new Holder < StructWithNillables > ( ) ; StructWithNillables ret ; if ( testDocLiteral ) { ret = docClient . testStructWithNillables ( x , y , z ) ; } else if ( testXMLBinding ) { ret = xmlClient . testStructWithNillables ( x , y , z ) ; } else { ret = rpcClient . testStructWithNillables ( x , y , z ) ; } if ( ! perfTestOnly ) { assertTrue ( ""testStructWithNillables(): Incorrect value for inout param"" , equals ( x , y . value ) ) ; assertTrue ( ""testStructWithNillables(): Incorrect value for out param"" , equals ( yOrig , z . value ) ) ; assertTrue ( ""testStructWithNillables(): Incorrect return value"" , equals ( x , ret ) ) ; } } protected boolean equals ( AnonymousStruct x , AnonymousStruct y ) { return ( x . getVarFloat ( ) == y . getVarFloat ( ) ) && ( x . getVarInt ( ) == y . getVarInt ( ) ) && ( x . getVarString ( ) . equals ( y . getVarString ( ) ) ) ; } @ Test public void testAnonymousStruct ( ) throws Exception { if ( ! shouldRunTest ( ""AnonymousStruct"" ) ) { return ; } AnonymousStruct x = new AnonymousStruct ( ) ; x . setVarInt ( 100 ) ; x . setVarString ( ""hello"" ) ; x . setVarFloat ( 1.1f ) ; AnonymousStruct yOrig = new AnonymousStruct ( ) ; yOrig . setVarInt ( 11 ) ; yOrig . setVarString ( ""world"" ) ; yOrig . setVarFloat ( 10.1f ) ; Holder < AnonymousStruct > y = new Holder < AnonymousStruct > ( yOrig ) ; Holder < AnonymousStruct > z = new Holder < AnonymousStruct > ( ) ; AnonymousStruct ret ; if ( testDocLiteral ) { ret = docClient . testAnonymousStruct ( x , y , z ) ; } else if ( testXMLBinding ) { ret = xmlClient . testAnonymousStruct ( x , y , z ) ; } else { ret = rpcClient . testAnonymousStruct ( x , y , z ) ; } if ( ! perfTestOnly ) { assertTrue ( ""testAnonymousStruct(): Incorrect value for inout param"" , equals ( x , y . value ) ) ; assertTrue ( ""testAnonymousStruct(): Incorrect value for out param"" , equals ( yOrig , z . value ) ) ; assertTrue ( ""testAnonymousStruct(): Incorrect return value"" , equals ( x , ret ) ) ; } } protected boolean equals ( NestedStruct x , NestedStruct y ) { return ( x . getVarInt ( ) == y . getVarInt ( ) ) && ( x . getVarFloat ( ) . compareTo ( y . getVarFloat ( ) ) == 0 ) && ( x . getVarString ( ) . equals ( y . getVarString ( ) ) ) && equalsNilable ( x . getVarEmptyStruct ( ) , y . getVarEmptyStruct ( ) ) && equalsNilableStruct ( x . getVarStruct ( ) , y . getVarStruct ( ) ) ; } protected boolean equalsNilable ( EmptyStruct x , EmptyStruct y ) { if ( x == null ) { return y == null ; } return y != null ; } protected boolean equalsNilableStruct ( SimpleStruct x , SimpleStruct y ) { if ( x == null ) { return y == null ; } else if ( y == null ) { return false ; } else { return equals ( x , y ) ; } } @ Test public void testNestedStruct ( ) throws Exception { if ( ! shouldRunTest ( ""NestedStruct"" ) ) { return ; } SimpleStruct xs = new SimpleStruct ( ) ; xs . setVarFloat ( 30.14 ) ; xs . setVarInt ( new BigInteger ( ""420"" ) ) ; xs . setVarString ( ""NESTED Hello There"" ) ; NestedStruct x = new NestedStruct ( ) ; x . setVarFloat ( new BigDecimal ( ""3.14"" ) ) ; x . setVarInt ( 42 ) ; x . setVarString ( ""Hello There"" ) ; x . setVarEmptyStruct ( new EmptyStruct ( ) ) ; x . setVarStruct ( xs ) ; SimpleStruct ys = new SimpleStruct ( ) ; ys . setVarFloat ( 10.414 ) ; ys . setVarInt ( new BigInteger ( ""130"" ) ) ; ys . setVarString ( ""NESTED Cheerio"" ) ; NestedStruct yOrig = new NestedStruct ( ) ; yOrig . setVarFloat ( new BigDecimal ( ""1.414"" ) ) ; yOrig . setVarInt ( 13 ) ; yOrig . setVarString ( ""Cheerio"" ) ; yOrig . setVarEmptyStruct ( new EmptyStruct ( ) ) ; yOrig . setVarStruct ( ys ) ; Holder < NestedStruct > y = new Holder < NestedStruct > ( yOrig ) ; Holder < NestedStruct > z = new Holder < NestedStruct > ( ) ; NestedStruct ret ; if ( testDocLiteral ) { ret = docClient . testNestedStruct ( x , y , z ) ; } else if ( testXMLBinding ) { ret = xmlClient . testNestedStruct ( x , y , z ) ; } else { ret = rpcClient . testNestedStruct ( x , y , z ) ; } if ( ! perfTestOnly ) { assertTrue ( ""testNestedStruct(): Incorrect value for inout param"" , equals ( x , y . value ) ) ; assertTrue ( ""testNestedStruct(): Incorrect value for out param"" , equals ( yOrig , z . value ) ) ; assertTrue ( ""testNestedStruct(): Incorrect return value"" , equals ( x , ret ) ) ; } } @ Test public void testFixedArray ( ) throws Exception { if ( ! shouldRunTest ( ""FixedArray"" ) ) { return ; } FixedArray x = new FixedArray ( ) ; x . getItem ( ) . addAll ( Arrays . asList ( Integer . MIN_VALUE , 0 , Integer . MAX_VALUE ) ) ; FixedArray yOrig = new FixedArray ( ) ; yOrig . getItem ( ) . addAll ( Arrays . asList ( - 1 , 0 , 1 ) ) ; Holder < FixedArray > y = new Holder < FixedArray > ( yOrig ) ; Holder < FixedArray > z = new Holder < FixedArray > ( ) ; FixedArray ret ; if ( testDocLiteral ) { ret = docClient . testFixedArray ( x , y , z ) ; } else if ( testXMLBinding ) { ret = xmlClient . testFixedArray ( x , y , z ) ; } else { ret = rpcClient . testFixedArray ( x , y , z ) ; } if ( ! perfTestOnly ) { for ( int i = 0 ; i < 3 ; i ++ ) { assertEquals ( ""testFixedArray(): Incorrect value for inout param"" , x . getItem ( ) . get ( i ) , y . value . getItem ( ) . get ( i ) ) ; assertEquals ( ""testFixedArray(): Incorrect value for out param"" , yOrig . getItem ( ) . get ( i ) , z . value . getItem ( ) . get ( i ) ) ; assertEquals ( ""testFixedArray(): Incorrect return value"" , x . getItem ( ) . get ( i ) , ret . getItem ( ) . get ( i ) ) ; } } } @ Test public void testBoundedArray ( ) throws Exception { if ( ! shouldRunTest ( ""BoundedArray"" ) ) { return ; } BoundedArray x = new BoundedArray ( ) ; x . getItem ( ) . addAll ( Arrays . asList ( - 100.00f , 0f , 100.00f ) ) ; BoundedArray yOrig = new BoundedArray ( ) ; yOrig . getItem ( ) . addAll ( Arrays . asList ( - 1f , 0f , 1f ) ) ; Holder < BoundedArray > y = new Holder < BoundedArray > ( yOrig ) ; Holder < BoundedArray > z = new Holder < BoundedArray > ( ) ; BoundedArray ret ; if ( testDocLiteral ) { ret = docClient . testBoundedArray ( x , y , z ) ; } else if ( testXMLBinding ) { ret = xmlClient . testBoundedArray ( x , y , z ) ; } else { ret = rpcClient . testBoundedArray ( x , y , z ) ; } if ( ! perfTestOnly ) { float delta = 0.0f ; int xSize = x . getItem ( ) . size ( ) ; int ySize = y . value . getItem ( ) . size ( ) ; int zSize = z . value . getItem ( ) . size ( ) ; int retSize = ret . getItem ( ) . size ( ) ; assertTrue ( ""testBoundedArray() array size incorrect"" , xSize == ySize && ySize == zSize && zSize == retSize && xSize == 3 ) ; for ( int i = 0 ; i < xSize ; i ++ ) { assertEquals ( ""testBoundedArray(): Incorrect value for inout param"" , x . getItem ( ) . get ( i ) , y . value . getItem ( ) . get ( i ) , delta ) ; assertEquals ( ""testBoundedArray(): Incorrect value for out param"" , yOrig . getItem ( ) . get ( i ) , z . value . getItem ( ) . get ( i ) , delta ) ; assertEquals ( ""testBoundedArray(): Incorrect return value"" , x . getItem ( ) . get ( i ) , ret . getItem ( ) . get ( i ) , delta ) ; } } } protected boolean equals ( UnboundedArray x , UnboundedArray y ) { List < String > xx = x . getItem ( ) ; List < String > yy = y . getItem ( ) ; if ( xx . size ( ) != yy . size ( ) ) { return false ; } for ( int i = 0 ; i < xx . size ( ) ; i ++ ) { if ( ! xx . get ( i ) . equals ( yy . get ( i ) ) ) { return false ; } } return true ; } @ Test public void testUnboundedArray ( ) throws Exception { if ( ! shouldRunTest ( ""UnboundedArray"" ) ) { return ; } UnboundedArray x = new UnboundedArray ( ) ; x . getItem ( ) . addAll ( Arrays . asList ( ""AAA"" , ""BBB"" , ""CCC"" ) ) ; UnboundedArray yOrig = new UnboundedArray ( ) ; yOrig . getItem ( ) . addAll ( Arrays . asList ( ""XXX"" , ""YYY"" , ""ZZZ"" ) ) ; Holder < UnboundedArray > y = new Holder < UnboundedArray > ( yOrig ) ; Holder < UnboundedArray > z = new Holder < UnboundedArray > ( ) ; UnboundedArray ret ; if ( testDocLiteral ) { ret = docClient . testUnboundedArray ( x , y , z ) ; } else if ( testXMLBinding ) { ret = xmlClient . testUnboundedArray ( x , y , z ) ; } else { ret = rpcClient . testUnboundedArray ( x , y , z ) ; } if ( ! perfTestOnly ) { for ( int i = 0 ; i < 3 ; i ++ ) { assertTrue ( ""testUnboundedArray(): Incorrect value for inout param"" , equals ( x , y . value ) ) ; assertTrue ( ""testUnboundedArray(): Incorrect value for out param"" , equals ( yOrig , z . value ) ) ; assertTrue ( ""testUnboundedArray(): Incorrect return value"" , equals ( x , ret ) ) ; } } } protected boolean equals ( CompoundArray x , CompoundArray y ) { return x . getArray1 ( ) . equals ( y . getArray1 ( ) ) && x . getArray2 ( ) . equals ( y . getArray2 ( ) ) ; } @ Test public void testCompoundArray ( ) throws Exception { if ( ! shouldRunTest ( ""CompoundArray"" ) ) { return ; } CompoundArray x = new CompoundArray ( ) ; x . getArray1 ( ) . addAll ( Arrays . asList ( ""AAA"" , ""BBB"" , ""CCC"" ) ) ; x . getArray2 ( ) . addAll ( Arrays . asList ( ""aaa"" , ""bbb"" , ""ccc"" ) ) ; CompoundArray yOrig = new CompoundArray ( ) ; yOrig . getArray1 ( ) . addAll ( Arrays . asList ( ""XXX"" , ""YYY"" , ""ZZZ"" ) ) ; yOrig . getArray2 ( ) . addAll ( Arrays . asList ( ""xxx"" , ""yyy"" , ""zzz"" ) ) ; Holder < CompoundArray > y = new Holder < CompoundArray > ( yOrig ) ; Holder < CompoundArray > z = new Holder < CompoundArray > ( ) ; CompoundArray ret ; if ( testDocLiteral ) { ret = docClient . testCompoundArray ( x , y , z ) ; } else if ( testXMLBinding ) { ret = xmlClient . testCompoundArray ( x , y , z ) ; } else { ret = rpcClient . testCompoundArray ( x , y , z ) ; } if ( ! perfTestOnly ) { assertTrue ( ""testCompoundArray(): Incorrect value for inout param"" , equals ( x , y . value ) ) ; assertTrue ( ""testCompoundArray(): Incorrect value for out param"" , equals ( yOrig , z . value ) ) ; assertTrue ( ""testCompoundArray(): Incorrect return value"" , equals ( x , ret ) ) ; } } @ Test public void testNestedArray ( ) throws Exception { if ( ! shouldRunTest ( ""NestedArray"" ) ) { return ; } String [ ] [ ] xs = { { ""AAA"" , ""BBB"" , ""CCC"" } , { ""aaa"" , ""bbb"" , ""ccc"" } , { ""a_a_a"" , ""b_b_b"" , ""c_c_c"" } } ; String [ ] [ ] ys = { { ""XXX"" , ""YYY"" , ""ZZZ"" } , { ""xxx"" , ""yyy"" , ""zzz"" } , { ""x_x_x"" , ""y_y_y"" , ""z_z_z"" } } ; NestedArray x = new NestedArray ( ) ; NestedArray yOrig = new NestedArray ( ) ; List < UnboundedArray > xList = x . getSubarray ( ) ; List < UnboundedArray > yList = yOrig . getSubarray ( ) ; for ( int i = 0 ; i < 3 ; i ++ ) { UnboundedArray xx = new UnboundedArray ( ) ; xx . getItem ( ) . addAll ( Arrays . asList ( xs [ i ] ) ) ; xList . add ( xx ) ; UnboundedArray yy = new UnboundedArray ( ) ; yy . getItem ( ) . addAll ( Arrays . asList ( ys [ i ] ) ) ; yList . add ( yy ) ; } Holder < NestedArray > y = new Holder < NestedArray > ( yOrig ) ; Holder < NestedArray > z = new Holder < NestedArray > ( ) ; NestedArray ret ; if ( testDocLiteral ) { ret = docClient . testNestedArray ( x , y , z ) ; } else if ( testXMLBinding ) { ret = xmlClient . testNestedArray ( x , y , z ) ; } else { ret = rpcClient . testNestedArray ( x , y , z ) ; } if ( ! perfTestOnly ) { for ( int i = 0 ; i < 3 ; i ++ ) { for ( int j = 0 ; j < 3 ; j ++ ) { assertEquals ( ""testNestedArray(): Incorrect value for inout param"" , x . getSubarray ( ) . get ( i ) . getItem ( ) . get ( j ) , y . value . getSubarray ( ) . get ( i ) . getItem ( ) . get ( j ) ) ; assertEquals ( ""testNestedArray(): Incorrect value for out param"" , yOrig . getSubarray ( ) . get ( i ) . getItem ( ) . get ( j ) , z . value . getSubarray ( ) . get ( i ) . getItem ( ) . get ( j ) ) ; assertEquals ( ""testNestedArray(): Incorrect return value"" , x . getSubarray ( ) . get ( i ) . getItem ( ) . get ( j ) , ret . getSubarray ( ) . get ( i ) . getItem ( ) . get ( j ) ) ; } } } } protected void assertEquals ( String msg , StructWithList x , StructWithList y ) throws Exception { assertTrue ( msg , x != null ) ; assertTrue ( msg , y != null ) ; List < String > xVar = x . getVarList ( ) ; List < String > yVar = y . getVarList ( ) ; assertTrue ( xVar . size ( ) == yVar . size ( ) ) ; for ( int i = 0 ; i < xVar . size ( ) ; ++ i ) { assertEquals ( msg , xVar . get ( i ) , yVar . get ( i ) ) ; } List < Integer > xAttr = x . getAttribList ( ) ; List < Integer > yAttr = y . getAttribList ( ) ; if ( xAttr == null ) { assertTrue ( msg , yAttr == null ) ; } else { assertTrue ( xAttr . size ( ) == yAttr . size ( ) ) ; for ( int i = 0 ; i < xAttr . size ( ) ; ++ i ) { assertEquals ( msg , xAttr . get ( i ) , yAttr . get ( i ) ) ; } } } @ Test public void testStructWithList ( ) throws Exception { if ( ! shouldRunTest ( ""StructWithList"" ) ) { return ; } StructWithList x = new StructWithList ( ) ; x . getVarList ( ) . add ( ""I"" ) ; x . getVarList ( ) . add ( ""am"" ) ; x . getVarList ( ) . add ( ""StructWithList"" ) ; StructWithList yOrig = new StructWithList ( ) ; yOrig . getVarList ( ) . add ( ""Does"" ) ; yOrig . getVarList ( ) . add ( ""StructWithList"" ) ; yOrig . getVarList ( ) . add ( ""work"" ) ; Holder < StructWithList > y = new Holder < StructWithList > ( yOrig ) ; Holder < StructWithList > z = new Holder < StructWithList > ( ) ; StructWithList ret ; if ( testDocLiteral ) { ret = docClient . testStructWithList ( x , y , z ) ; } else if ( testXMLBinding ) { ret = xmlClient . testStructWithList ( x , y , z ) ; } else { ret = rpcClient . testStructWithList ( x , y , z ) ; } if ( ! perfTestOnly ) { assertEquals ( ""testStructWithList(): Incorrect value for inout param"" , x , y . value ) ; assertEquals ( ""testStructWithList(): Incorrect value for out param"" , yOrig , z . value ) ; assertEquals ( ""testStructWithList(): Incorrect return value"" , x , ret ) ; } x . getAttribList ( ) . add ( 1 ) ; x . getAttribList ( ) . add ( 2 ) ; x . getAttribList ( ) . add ( 3 ) ; y . value = yOrig ; if ( testDocLiteral ) { ret = docClient . testStructWithList ( x , y , z ) ; } else if ( testXMLBinding ) { ret = xmlClient . testStructWithList ( x , y , z ) ; } else { ret = rpcClient . testStructWithList ( x , y , z ) ; } if ( ! perfTestOnly ) { assertEquals ( ""testStructWithList(): Incorrect value for inout param"" , x , y . value ) ; assertEquals ( ""testStructWithList(): Incorrect value for out param"" , yOrig , z . value ) ; assertEquals ( ""testStructWithList(): Incorrect return value"" , x , ret ) ; } yOrig . getAttribList ( ) . add ( 4 ) ; yOrig . getAttribList ( ) . add ( 5 ) ; yOrig . getAttribList ( ) . add ( 6 ) ; y . value = yOrig ; if ( testDocLiteral ) { ret = docClient . testStructWithList ( x , y , z ) ; } else if ( testXMLBinding ) { ret = xmlClient . testStructWithList ( x , y , z ) ; } else { ret = rpcClient . testStructWithList ( x , y , z ) ; } if ( ! perfTestOnly ) { assertEquals ( ""testStructWithList(): Incorrect value for inout param"" , x , y . value ) ; assertEquals ( ""testStructWithList(): Incorrect value for out param"" , yOrig , z . value ) ; assertEquals ( ""testStructWithList(): Incorrect return value"" , x , ret ) ; } } protected void assertEquals ( String msg , StructWithUnion x , StructWithUnion y ) throws Exception { assertTrue ( msg , x != null ) ; assertTrue ( msg , y != null ) ; assertEquals ( msg , x . getVarUnion ( ) , y . getVarUnion ( ) ) ; assertEquals ( msg , x . getAttribUnion ( ) , y . getAttribUnion ( ) ) ; } @ Test public void testStructWithUnion ( ) throws Exception { if ( ! shouldRunTest ( ""StructWithUnion"" ) ) { return ; } StructWithUnion x = new StructWithUnion ( ) ; x . setVarUnion ( ""999"" ) ; StructWithUnion yOrig = new StructWithUnion ( ) ; yOrig . setVarUnion ( ""-999"" ) ; Holder < StructWithUnion > y = new Holder < StructWithUnion > ( yOrig ) ; Holder < StructWithUnion > z = new Holder < StructWithUnion > ( ) ; StructWithUnion ret ; if ( testDocLiteral ) { ret = docClient . testStructWithUnion ( x , y , z ) ; } else if ( testXMLBinding ) { ret = xmlClient . testStructWithUnion ( x , y , z ) ; } else { ret = rpcClient . testStructWithUnion ( x , y , z ) ; } if ( ! perfTestOnly ) { assertEquals ( ""testStructWithUnion(): Incorrect value for inout param"" , x , y . value ) ; assertEquals ( ""testStructWithUnion(): Incorrect value for out param"" , yOrig , z . value ) ; assertEquals ( ""testStructWithUnion(): Incorrect return value"" , x , ret ) ; } x . setAttribUnion ( ""99"" ) ; y . value = yOrig ; if ( testDocLiteral ) { ret = docClient . testStructWithUnion ( x , y , z ) ; } else if ( testXMLBinding ) { ret = xmlClient . testStructWithUnion ( x , y , z ) ; } else { ret = rpcClient . testStructWithUnion ( x , y , z ) ; } if ( ! perfTestOnly ) { assertEquals ( ""testStructWithUnion(): Incorrect value for inout param"" , x , y . value ) ; assertEquals ( ""testStructWithUnion(): Incorrect value for out param"" , yOrig , z . value ) ; assertEquals ( ""testStructWithUnion(): Incorrect return value"" , x , ret ) ; } yOrig . setAttribUnion ( ""-99"" ) ; y . value = yOrig ; if ( testDocLiteral ) { ret = docClient . testStructWithUnion ( x , y , z ) ; } else if ( testXMLBinding ) { ret = xmlClient . testStructWithUnion ( x , y , z ) ; } else { ret = rpcClient . testStructWithUnion ( x , y , z ) ; } if ( ! perfTestOnly ) { assertEquals ( ""testStructWithUnion(): Incorrect value for inout param"" , x , y . value ) ; assertEquals ( ""testStructWithUnion(): Incorrect value for out param"" , yOrig , z . value ) ; assertEquals ( ""testStructWithUnion(): Incorrect return value"" , x , ret ) ; } } @ Test public void testEmptyChoice ( ) throws Exception { if ( ! shouldRunTest ( ""EmptyChoice"" ) ) { return ; } EmptyChoice x = new EmptyChoice ( ) ; EmptyChoice yOrig = new EmptyChoice ( ) ; Holder < EmptyChoice > y = new Holder < EmptyChoice > ( yOrig ) ; Holder < EmptyChoice > z = new Holder < EmptyChoice > ( ) ; EmptyChoice ret ; if ( testDocLiteral ) { ret = docClient . testEmptyChoice ( x , y , z ) ; } else if ( testXMLBinding ) { ret = xmlClient . testEmptyChoice ( x , y , z ) ; } else { ret = rpcClient . testEmptyChoice ( x , y , z ) ; } if ( ! perfTestOnly ) { assertTrue ( ""testEmptyChoice(): Null value for inout param"" , notNull ( x , y . value ) ) ; assertTrue ( ""testEmptyChoice(): Null value for out param"" , notNull ( yOrig , z . value ) ) ; assertTrue ( ""testEmptyChoice(): Null return value"" , notNull ( x , ret ) ) ; } } protected boolean equals ( SimpleChoice x , SimpleChoice y ) { if ( x . getVarFloat ( ) != null && y . getVarFloat ( ) != null ) { return x . getVarFloat ( ) . compareTo ( y . getVarFloat ( ) ) == 0 ; } else if ( x . getVarInt ( ) != null && y . getVarInt ( ) != null ) { return x . getVarInt ( ) . compareTo ( y . getVarInt ( ) ) == 0 ; } else if ( x . getVarString ( ) != null && y . getVarString ( ) != null ) { return x . getVarString ( ) . equals ( y . getVarString ( ) ) ; } else { return false ; } } @ Test public void testSimpleChoice ( ) throws Exception { if ( ! shouldRunTest ( ""SimpleChoice"" ) ) { return ; } SimpleChoice x = new SimpleChoice ( ) ; x . setVarFloat ( - 3.14f ) ; SimpleChoice yOrig = new SimpleChoice ( ) ; yOrig . setVarString ( ""Cheerio"" ) ; Holder < SimpleChoice > y = new Holder < SimpleChoice > ( yOrig ) ; Holder < SimpleChoice > z = new Holder < SimpleChoice > ( ) ; SimpleChoice ret ; if ( testDocLiteral ) { ret = docClient . testSimpleChoice ( x , y , z ) ; } else if ( testXMLBinding ) { ret = xmlClient . testSimpleChoice ( x , y , z ) ; } else { ret = rpcClient . testSimpleChoice ( x , y , z ) ; } if ( ! perfTestOnly ) { assertTrue ( ""testSimpleChoice(): Incorrect value for inout param"" , equals ( x , y . value ) ) ; assertTrue ( ""testSimpleChoice(): Incorrect value for out param"" , equals ( yOrig , z . value ) ) ; assertTrue ( ""testSimpleChoice(): Incorrect return value"" , equals ( x , ret ) ) ; } } @ Test public void testEmptyAll ( ) throws Exception { if ( ! shouldRunTest ( ""EmptyAll"" ) ) { return ; } EmptyAll x = new EmptyAll ( ) ; EmptyAll yOrig = new EmptyAll ( ) ; Holder < EmptyAll > y = new Holder < EmptyAll > ( yOrig ) ; Holder < EmptyAll > z = new Holder < EmptyAll > ( ) ; EmptyAll ret ; if ( testDocLiteral ) { ret = docClient . testEmptyAll ( x , y , z ) ; } else if ( testXMLBinding ) { ret = xmlClient . testEmptyAll ( x , y , z ) ; } else { ret = rpcClient . testEmptyAll ( x , y , z ) ; } if ( ! perfTestOnly ) { assertTrue ( ""testEmptyAll(): Null value for inout param"" , notNull ( x , y . value ) ) ; assertTrue ( ""testEmptyAll(): Null value for out param"" , notNull ( yOrig , z . value ) ) ; assertTrue ( ""testEmptyAll(): Null return value"" , notNull ( x , ret ) ) ; } } protected boolean equals ( SimpleAll x , SimpleAll y ) { return ( x . getVarFloat ( ) == y . getVarFloat ( ) ) && ( x . getVarInt ( ) == y . getVarInt ( ) ) && ( x . getVarString ( ) . equals ( y . getVarString ( ) ) ) && ( x . getVarAttrString ( ) . equals ( y . getVarAttrString ( ) ) ) ; } @ Test public void testSimpleAll ( ) throws Exception { if ( ! shouldRunTest ( ""SimpleAll"" ) ) { return ; } SimpleAll x = new SimpleAll ( ) ; x . setVarFloat ( 3.14f ) ; x . setVarInt ( 42 ) ; x . setVarString ( ""Hello There"" ) ; x . setVarAttrString ( ""Attr-x"" ) ; SimpleAll yOrig = new SimpleAll ( ) ; yOrig . setVarFloat ( - 9.14f ) ; yOrig . setVarInt ( 10 ) ; yOrig . setVarString ( ""Cheerio"" ) ; yOrig . setVarAttrString ( ""Attr-y"" ) ; Holder < SimpleAll > y = new Holder < SimpleAll > ( yOrig ) ; Holder < SimpleAll > z = new Holder < SimpleAll > ( ) ; SimpleAll ret ; if ( testDocLiteral ) { ret = docClient . testSimpleAll ( x , y , z ) ; } else if ( testXMLBinding ) { ret = xmlClient . testSimpleAll ( x , y , z ) ; } else { ret = rpcClient . testSimpleAll ( x , y , z ) ; } if ( ! perfTestOnly ) { assertTrue ( ""testSimpleAll(): Incorrect value for inout param"" , equals ( x , y . value ) ) ; assertTrue ( ""testSimpleAll(): Incorrect value for out param"" , equals ( yOrig , z . value ) ) ; assertTrue ( ""testSimpleAll(): Incorrect return value"" , equals ( x , ret ) ) ; } } protected boolean equals ( StructWithOptionals x , StructWithOptionals y ) { return equalsNilable ( x . getVarFloat ( ) , y . getVarFloat ( ) ) && equalsNilable ( x . getVarInt ( ) , x . getVarInt ( ) ) && equalsNilable ( x . getVarString ( ) , y . getVarString ( ) ) && equalsNilable ( x . getVarStruct ( ) , y . getVarStruct ( ) ) ; } @ Test public void testStructWithOptionals ( ) throws Exception { if ( ! shouldRunTest ( ""StructWithOptionals"" ) ) { return ; } StructWithOptionals x = new StructWithOptionals ( ) ; StructWithOptionals yOrig = new StructWithOptionals ( ) ; yOrig . setVarFloat ( new Float ( 1.414f ) ) ; yOrig . setVarInt ( new Integer ( 13 ) ) ; yOrig . setVarString ( ""Cheerio"" ) ; Holder < StructWithOptionals > y = new Holder < StructWithOptionals > ( yOrig ) ; Holder < StructWithOptionals > z = new Holder < StructWithOptionals > ( ) ; StructWithOptionals ret ; if ( testDocLiteral ) { ret = docClient . testStructWithOptionals ( x , y , z ) ; } else if ( testXMLBinding ) { ret = xmlClient . testStructWithOptionals ( x , y , z ) ; } else { ret = rpcClient . testStructWithOptionals ( x , y , z ) ; } if ( ! perfTestOnly ) { assertTrue ( ""testStructWithOptionals(): Incorrect value for inout param"" , equals ( x , y . value ) ) ; assertTrue ( ""testStructWithOptionals(): Incorrect value for out param"" , equals ( yOrig , z . value ) ) ; assertTrue ( ""testStructWithOptionals(): Incorrect return value"" , equals ( x , ret ) ) ; } } protected boolean equals ( RecursiveStruct x , RecursiveStruct y ) { return ( x . getVarFloat ( ) == y . getVarFloat ( ) ) && ( x . getVarInt ( ) == y . getVarInt ( ) ) && ( x . getVarString ( ) . equals ( y . getVarString ( ) ) ) && equals ( x . getVarStructArray ( ) , y . getVarStructArray ( ) ) ; } @ Test public void testRecursiveStruct ( ) throws Exception { if ( ! shouldRunTest ( ""RecursiveStruct"" ) ) { return ; } RecursiveStruct xtmp = new RecursiveStruct ( ) ; xtmp . setVarFloat ( 0.14f ) ; xtmp . setVarInt ( 4 ) ; xtmp . setVarString ( ""tmp-x"" ) ; xtmp . setVarStructArray ( new RecursiveStructArray ( ) ) ; RecursiveStruct ytmp = new RecursiveStruct ( ) ; ytmp . setVarFloat ( 0.414f ) ; ytmp . setVarInt ( 1 ) ; ytmp . setVarString ( ""tmp-y"" ) ; ytmp . setVarStructArray ( new RecursiveStructArray ( ) ) ; RecursiveStructArray arr = new RecursiveStructArray ( ) ; arr . getItem ( ) . add ( xtmp ) ; arr . getItem ( ) . add ( ytmp ) ; RecursiveStruct x = new RecursiveStruct ( ) ; x . setVarFloat ( 3.14f ) ; x . setVarInt ( 42 ) ; x . setVarString ( ""RecStruct-x"" ) ; x . setVarStructArray ( arr ) ; RecursiveStruct yOrig = new RecursiveStruct ( ) ; yOrig . setVarFloat ( 1.414f ) ; yOrig . setVarInt ( 13 ) ; yOrig . setVarString ( ""RecStruct-y"" ) ; yOrig . setVarStructArray ( arr ) ; Holder < RecursiveStruct > y = new Holder < RecursiveStruct > ( yOrig ) ; Holder < RecursiveStruct > z = new Holder < RecursiveStruct > ( ) ; RecursiveStruct ret ; if ( testDocLiteral ) { ret = docClient . testRecursiveStruct ( x , y , z ) ; } else if ( testXMLBinding ) { ret = xmlClient . testRecursiveStruct ( x , y , z ) ; } else { ret = rpcClient . testRecursiveStruct ( x , y , z ) ; } if ( ! perfTestOnly ) { assertTrue ( ""testRecursiveStruct(): Incorrect value for inout param"" , equals ( x , y . value ) ) ; assertTrue ( ""testRecursiveStruct(): Incorrect value for out param"" , equals ( yOrig , z . value ) ) ; assertTrue ( ""testRecursiveStruct(): Incorrect return value"" , equals ( ret , x ) ) ; } } protected boolean equals ( RecursiveStructArray x , RecursiveStructArray y ) { List < RecursiveStruct > xx = x . getItem ( ) ; List < RecursiveStruct > yy = y . getItem ( ) ; if ( xx . isEmpty ( ) && yy . isEmpty ( ) ) { return true ; } if ( xx . size ( ) != yy . size ( ) ) { return false ; } for ( int i = 0 ; i < xx . size ( ) ; i ++ ) { if ( ! equals ( xx . get ( i ) , yy . get ( i ) ) ) { return false ; } } return true ; } @ Test public void testRecursiveStructArray ( ) throws Exception { if ( ! shouldRunTest ( ""RecursiveStructArray"" ) ) { return ; } RecursiveStruct xtmp = new RecursiveStruct ( ) ; xtmp . setVarFloat ( 0.14f ) ; xtmp . setVarInt ( 4 ) ; xtmp . setVarString ( ""tmp-x"" ) ; xtmp . setVarStructArray ( new RecursiveStructArray ( ) ) ; RecursiveStruct ytmp = new RecursiveStruct ( ) ; ytmp . setVarFloat ( 0.414f ) ; ytmp . setVarInt ( 1 ) ; ytmp . setVarString ( ""tmp-y"" ) ; ytmp . setVarStructArray ( new RecursiveStructArray ( ) ) ; RecursiveStructArray x = new RecursiveStructArray ( ) ; x . getItem ( ) . add ( xtmp ) ; x . getItem ( ) . add ( ytmp ) ; RecursiveStructArray yOrig = new RecursiveStructArray ( ) ; yOrig . getItem ( ) . add ( ytmp ) ; yOrig . getItem ( ) . add ( xtmp ) ; Holder < RecursiveStructArray > y = new Holder < RecursiveStructArray > ( yOrig ) ; Holder < RecursiveStructArray > z = new Holder < RecursiveStructArray > ( ) ; RecursiveStructArray ret ; if ( testDocLiteral ) { ret = docClient . testRecursiveStructArray ( x , y , z ) ; } else if ( testXMLBinding ) { ret = xmlClient . testRecursiveStructArray ( x , y , z ) ; } else { ret = rpcClient . testRecursiveStructArray ( x , y , z ) ; } if ( ! perfTestOnly ) { assertTrue ( ""testRecursiveStructArray(): Incorrect value for inout param"" , equals ( x , y . value ) ) ; assertTrue ( ""testRecursiveStructArray(): Incorrect value for out param"" , equals ( yOrig , z . value ) ) ; assertTrue ( ""testRecursiveStructArray(): Incorrect return value"" , equals ( ret , x ) ) ; } } protected boolean equals ( RecursiveUnion x , RecursiveUnion y ) { if ( x . getVarString ( ) != null && y . getVarString ( ) != null ) { return x . getVarString ( ) . equals ( y . getVarString ( ) ) ; } if ( x . getVarChoice ( ) != null && y . getVarChoice ( ) != null ) { return equals ( x . getVarChoice ( ) , y . getVarChoice ( ) ) ; } return false ; } @ Test public void testRecursiveUnion ( ) throws Exception { if ( ! shouldRunTest ( ""RecursiveUnion"" ) ) { return ; } RecursiveUnion tmp1 = new RecursiveUnion ( ) ; tmp1 . setVarString ( ""RecusiveUnion-1"" ) ; RecursiveUnion tmp2 = new RecursiveUnion ( ) ; tmp2 . setVarString ( ""RecusiveUnion-2"" ) ; RecursiveUnionData xData = new RecursiveUnionData ( ) ; ChoiceArray xChoice = new ChoiceArray ( ) ; xChoice . getItem ( ) . add ( tmp1 ) ; xChoice . getItem ( ) . add ( tmp2 ) ; xData . setVarInt ( 5 ) ; xData . setVarChoiceArray ( xChoice ) ; RecursiveUnion x = new RecursiveUnion ( ) ; x . setVarChoice ( xData ) ; RecursiveUnionData yData = new RecursiveUnionData ( ) ; ChoiceArray yChoice = new ChoiceArray ( ) ; yChoice . getItem ( ) . add ( tmp1 ) ; yChoice . getItem ( ) . add ( tmp2 ) ; yData . setVarInt ( - 5 ) ; yData . setVarChoiceArray ( yChoice ) ; RecursiveUnion yOrig = new RecursiveUnion ( ) ; yOrig . setVarChoice ( yData ) ; Holder < RecursiveUnion > y = new Holder < RecursiveUnion > ( yOrig ) ; Holder < RecursiveUnion > z = new Holder < RecursiveUnion > ( ) ; RecursiveUnion ret ; if ( testDocLiteral ) { ret = docClient . testRecursiveUnion ( x , y , z ) ; } else if ( testXMLBinding ) { ret = xmlClient . testRecursiveUnion ( x , y , z ) ; } else { ret = rpcClient . testRecursiveUnion ( x , y , z ) ; } if ( ! perfTestOnly ) { assertTrue ( ""testRecursiveUnion(): Incorrect value for inout param"" , equals ( x , y . value ) ) ; assertTrue ( ""testRecursiveUnion(): Incorrect value for out param"" , equals ( yOrig , z . value ) ) ; assertTrue ( ""testRecursiveUnion(): Incorrect return value"" , equals ( ret , x ) ) ; } } protected boolean equals ( RecursiveUnionData x , RecursiveUnionData y ) { return x . getVarInt ( ) == y . getVarInt ( ) && equals ( x . getVarChoiceArray ( ) , y . getVarChoiceArray ( ) ) ; } @ Test public void testRecursiveUnionData ( ) throws Exception { if ( ! shouldRunTest ( ""RecursiveUnionData"" ) ) { return ; } RecursiveUnion tmp1 = new RecursiveUnion ( ) ; tmp1 . setVarString ( ""RecusiveUnion-1"" ) ; RecursiveUnion tmp2 = new RecursiveUnion ( ) ; tmp2 . setVarString ( ""RecusiveUnion-2"" ) ; RecursiveUnionData x = new RecursiveUnionData ( ) ; ChoiceArray xChoice = new ChoiceArray ( ) ; xChoice . getItem ( ) . add ( tmp1 ) ; xChoice . getItem ( ) . add ( tmp2 ) ; x . setVarInt ( 5 ) ; x . setVarChoiceArray ( xChoice ) ; RecursiveUnionData yOrig = new RecursiveUnionData ( ) ; ChoiceArray yOrigchoice = new ChoiceArray ( ) ; xChoice . getItem ( ) . add ( tmp1 ) ; xChoice . getItem ( ) . add ( tmp2 ) ; yOrig . setVarInt ( - 5 ) ; yOrig . setVarChoiceArray ( yOrigchoice ) ; Holder < RecursiveUnionData > y = new Holder < RecursiveUnionData > ( yOrig ) ; Holder < RecursiveUnionData > z = new Holder < RecursiveUnionData > ( ) ; RecursiveUnionData ret ; if ( testDocLiteral ) { ret = docClient . testRecursiveUnionData ( x , y , z ) ; } else if ( testXMLBinding ) { ret = xmlClient . testRecursiveUnionData ( x , y , z ) ; } else { ret = rpcClient . testRecursiveUnionData ( x , y , z ) ; } if ( ! perfTestOnly ) { assertTrue ( ""testRecursiveUnionData(): Incorrect value for inout param"" , equals ( x , y . value ) ) ; assertTrue ( ""testRecursiveUnionData(): Incorrect value for out param"" , equals ( yOrig , z . value ) ) ; assertTrue ( ""testRecursiveUnionData(): Incorrect return value"" , equals ( ret , x ) ) ; } } protected boolean equals ( ChoiceArray x , ChoiceArray y ) { List < RecursiveUnion > xx = x . getItem ( ) ; List < RecursiveUnion > yy = y . getItem ( ) ; if ( xx . isEmpty ( ) && yy . isEmpty ( ) ) { return true ; } if ( xx . size ( ) != yy . size ( ) ) { return false ; } for ( int i = 0 ; i < xx . size ( ) ; i ++ ) { if ( ! equals ( xx . get ( i ) , yy . get ( i ) ) ) { return false ; } } return true ; } @ Test public void testChoiceArray ( ) throws Exception { if ( ! shouldRunTest ( ""ChoiceArray"" ) ) { return ; } RecursiveUnion tmp1 = new RecursiveUnion ( ) ; tmp1 . setVarString ( ""RecusiveUnion-1"" ) ; RecursiveUnion tmp2 = new RecursiveUnion ( ) ; tmp2 . setVarString ( ""RecusiveUnion-2"" ) ; ChoiceArray x = new ChoiceArray ( ) ; x . getItem ( ) . add ( tmp1 ) ; x . getItem ( ) . add ( tmp2 ) ; ChoiceArray yOrig = new ChoiceArray ( ) ; yOrig . getItem ( ) . add ( tmp2 ) ; yOrig . getItem ( ) . add ( tmp1 ) ; Holder < ChoiceArray > y = new Holder < ChoiceArray > ( yOrig ) ; Holder < ChoiceArray > z = new Holder < ChoiceArray > ( ) ; ChoiceArray ret ; if ( testDocLiteral ) { ret = docClient . testChoiceArray ( x , y , z ) ; } else if ( testXMLBinding ) { ret = xmlClient . testChoiceArray ( x , y , z ) ; } else { ret = rpcClient . testChoiceArray ( x , y , z ) ; } if ( ! perfTestOnly ) { assertTrue ( ""testChoiceArray(): Incorrect value for inout param"" , equals ( x , y . value ) ) ; assertTrue ( ""testChoiceArray(): Incorrect value for out param"" , equals ( yOrig , z . value ) ) ; assertTrue ( ""testChoiceArray(): Incorrect return value"" , equals ( ret , x ) ) ; } } @ Test public void testExtendsSimpleType ( ) throws Exception { if ( ! shouldRunTest ( ""ExtendsSimpleType"" ) ) { return ; } ExtendsSimpleType x = new ExtendsSimpleType ( ) ; x . setValue ( ""foo"" ) ; ExtendsSimpleType yOriginal = new ExtendsSimpleType ( ) ; yOriginal . setValue ( ""bar"" ) ; Holder < ExtendsSimpleType > y = new Holder < ExtendsSimpleType > ( yOriginal ) ; Holder < ExtendsSimpleType > z = new Holder < ExtendsSimpleType > ( ) ; ExtendsSimpleType ret ; if ( testDocLiteral ) { ret = docClient . testExtendsSimpleType ( x , y , z ) ; } else if ( testXMLBinding ) { ret = xmlClient . testExtendsSimpleType ( x , y , z ) ; } else { ret = rpcClient . testExtendsSimpleType ( x , y , z ) ; } if ( ! perfTestOnly ) { assertEquals ( x . getValue ( ) , y . value . getValue ( ) ) ; assertEquals ( yOriginal . getValue ( ) , z . value . getValue ( ) ) ; assertEquals ( x . getValue ( ) , ret . getValue ( ) ) ; } } @ Test public void testExtendsSimpleContent ( ) throws Exception { if ( ! shouldRunTest ( ""ExtendsSimpleContent"" ) ) { return ; } ExtendsSimpleContent x = new ExtendsSimpleContent ( ) ; x . setValue ( ""foo"" ) ; ExtendsSimpleContent yOriginal = new ExtendsSimpleContent ( ) ; yOriginal . setValue ( ""bar"" ) ; Holder < ExtendsSimpleContent > y = new Holder < ExtendsSimpleContent > ( yOriginal ) ; Holder < ExtendsSimpleContent > z = new Holder < ExtendsSimpleContent > ( ) ; ExtendsSimpleContent ret ; if ( testDocLiteral ) { ret = docClient . testExtendsSimpleContent ( x , y , z ) ; } else if ( testXMLBinding ) { ret = xmlClient . testExtendsSimpleContent ( x , y , z ) ; } else { ret = rpcClient . testExtendsSimpleContent ( x , y , z ) ; } if ( ! perfTestOnly ) { assertEquals ( x . getValue ( ) , y . value . getValue ( ) ) ; assertEquals ( yOriginal . getValue ( ) , z . value . getValue ( ) ) ; assertEquals ( x . getValue ( ) , ret . getValue ( ) ) ; } } protected void equals ( String msg , Document x , Document y ) throws Exception { assertEquals ( msg , x . getValue ( ) , y . getValue ( ) ) ; assertEquals ( msg , x . getID ( ) , y . getID ( ) ) ; } @ Test public void testDocument ( ) throws Exception { if ( ! shouldRunTest ( ""Document"" ) ) { return ; } Document x = new Document ( ) ; x . setValue ( ""content-x"" ) ; x . setID ( ""Hello There"" ) ; Document yOrig = new Document ( ) ; yOrig . setID ( ""Cheerio"" ) ; yOrig . setValue ( ""content-y"" ) ; Holder < Document > y = new Holder < Document > ( yOrig ) ; Holder < Document > z = new Holder < Document > ( ) ; Document ret ; if ( testDocLiteral ) { ret = docClient . testDocument ( x , y , z ) ; } else if ( testXMLBinding ) { ret = xmlClient . testDocument ( x , y , z ) ; } else { ret = rpcClient . testDocument ( x , y , z ) ; } if ( ! perfTestOnly ) { equals ( ""testDocument(): Incorrect value for inout param"" , x , y . value ) ; equals ( ""testDocument(): Incorrect value for out param"" , yOrig , z . value ) ; equals ( ""testDocument(): Incorrect return value"" , x , ret ) ; } x = new Document ( ) ; yOrig = new Document ( ) ; x . setValue ( ""content-x"" ) ; yOrig . setValue ( ""content-y"" ) ; x . setID ( null ) ; yOrig . setID ( null ) ; y = new Holder < Document > ( yOrig ) ; z = new Holder < Document > ( ) ; if ( testDocLiteral ) { ret = docClient . testDocument ( x , y , z ) ; } else if ( testXMLBinding ) { ret = xmlClient . testDocument ( x , y , z ) ; } else { ret = rpcClient . testDocument ( x , y , z ) ; } if ( ! perfTestOnly ) { equals ( ""testDocument(): Incorrect value for inout param"" , x , y . value ) ; equals ( ""testDocument(): Incorrect value for out param"" , yOrig , z . value ) ; equals ( ""testDocument(): Incorrect return value"" , x , ret ) ; assertNull ( y . value . getID ( ) ) ; assertNull ( ret . getID ( ) ) ; } } protected boolean equals ( ExtColourEnum x , ExtColourEnum y ) { return ( x . getAttrib1 ( ) . equals ( y . getAttrib1 ( ) ) ) && ( x . getAttrib2 ( ) . equals ( y . getAttrib2 ( ) ) ) && ( x . getValue ( ) . equals ( y . getValue ( ) ) ) ; } @ Test public void testExtColourEnum ( ) throws Exception { if ( ! shouldRunTest ( ""ExtColourEnum"" ) ) { return ; } ExtColourEnum x = new ExtColourEnum ( ) ; x . setAttrib1 ( new Integer ( 1 ) ) ; x . setAttrib2 ( ""Ax"" ) ; x . setValue ( ColourEnum . fromValue ( ""RED"" ) ) ; ExtColourEnum yOrig = new ExtColourEnum ( ) ; yOrig . setAttrib1 ( new Integer ( 10 ) ) ; yOrig . setAttrib2 ( ""Ay"" ) ; yOrig . setValue ( ColourEnum . fromValue ( ""GREEN"" ) ) ; Holder < ExtColourEnum > y = new Holder < ExtColourEnum > ( yOrig ) ; Holder < ExtColourEnum > z = new Holder < ExtColourEnum > ( ) ; ExtColourEnum ret ; if ( testDocLiteral ) { ret = docClient . testExtColourEnum ( x , y , z ) ; } else if ( testXMLBinding ) { ret = xmlClient . testExtColourEnum ( x , y , z ) ; } else { ret = rpcClient . testExtColourEnum ( x , y , z ) ; } if ( ! perfTestOnly ) { assertTrue ( ""testExtColourEnum(): Incorrect value for inout param"" , equals ( x , y . value ) ) ; assertTrue ( ""testExtColourEnum(): Incorrect value for out param"" , equals ( yOrig , z . value ) ) ; assertTrue ( ""testExtColourEnum(): Incorrect return value"" , equals ( x , ret ) ) ; } } protected boolean equals ( ExtBase64Binary x , ExtBase64Binary y ) { return x . getId ( ) == y . getId ( ) && Arrays . equals ( x . getValue ( ) , y . getValue ( ) ) ; } @ Test public void testExtBase64Binary ( ) throws Exception { if ( ! shouldRunTest ( ""ExtBase64Binary"" ) ) { return ; } ExtBase64Binary x1 = new ExtBase64Binary ( ) ; x1 . setValue ( ""base64a"" . getBytes ( ) ) ; x1 . setId ( 1 ) ; ExtBase64Binary y1 = new ExtBase64Binary ( ) ; y1 . setValue ( ""base64b"" . getBytes ( ) ) ; y1 . setId ( 2 ) ; Holder < ExtBase64Binary > y1Holder = new Holder < ExtBase64Binary > ( y1 ) ; Holder < ExtBase64Binary > z1 = new Holder < ExtBase64Binary > ( ) ; ExtBase64Binary ret ; if ( testDocLiteral ) { ret = docClient . testExtBase64Binary ( x1 , y1Holder , z1 ) ; } else if ( testXMLBinding ) { ret = xmlClient . testExtBase64Binary ( x1 , y1Holder , z1 ) ; } else { ret = rpcClient . testExtBase64Binary ( x1 , y1Holder , z1 ) ; } if ( ! perfTestOnly ) { assertTrue ( ""testExtBase64Binary(): Incorrect value for inout param"" , equals ( x1 , y1Holder . value ) ) ; assertTrue ( ""testExtBase64Binary(): Incorrect value for out param"" , equals ( y1 , z1 . value ) ) ; assertTrue ( ""testExtBase64Binary(): Incorrect return value"" , equals ( x1 , ret ) ) ; } } protected boolean equals ( StructWithSubstitutionGroup x , StructWithSubstitutionGroup y ) { if ( ! x . getSg01BaseElementA ( ) . isNil ( ) && ! y . getSg01BaseElementA ( ) . isNil ( ) ) { SgBaseTypeA xTypeA = x . getSg01BaseElementA ( ) . getValue ( ) ; SgBaseTypeA yTypeA = y . getSg01BaseElementA ( ) . getValue ( ) ; return equals ( xTypeA , yTypeA ) ; } return false ; } @ Test public void testStructWithSubstitutionGroup ( ) throws Exception { if ( ! shouldRunTest ( ""StructWithSubstitutionGroup"" ) ) { return ; } SgBaseTypeA baseA = new SgBaseTypeA ( ) ; baseA . setVarInt ( new BigInteger ( ""1"" ) ) ; SgDerivedTypeB derivedB = new SgDerivedTypeB ( ) ; derivedB . setVarInt ( new BigInteger ( ""32"" ) ) ; derivedB . setVarString ( ""foo"" ) ; ObjectFactory objectFactory = new ObjectFactory ( ) ; StructWithSubstitutionGroup x = new StructWithSubstitutionGroup ( ) ; JAXBElement < ? extends SgBaseTypeA > elementA = objectFactory . createSg01BaseElementA ( baseA ) ; x . setSg01BaseElementA ( elementA ) ; StructWithSubstitutionGroup yOrig = new StructWithSubstitutionGroup ( ) ; JAXBElement < ? extends SgBaseTypeA > elementB = objectFactory . createSg01DerivedElementB ( derivedB ) ; yOrig . setSg01BaseElementA ( elementB ) ; Holder < StructWithSubstitutionGroup > y = new Holder < StructWithSubstitutionGroup > ( yOrig ) ; Holder < StructWithSubstitutionGroup > z = new Holder < StructWithSubstitutionGroup > ( ) ; StructWithSubstitutionGroup ret ; if ( testDocLiteral ) { ret = docClient . testStructWithSubstitutionGroup ( x , y , z ) ; } else if ( testXMLBinding ) { ret = xmlClient . testStructWithSubstitutionGroup ( x , y , z ) ; } else { ret = rpcClient . testStructWithSubstitutionGroup ( x , y , z ) ; } if ( ! perfTestOnly ) { assertTrue ( ""testStructWithSubstitutionGroup(): Incorrect value for inout param"" , equals ( x , y . value ) ) ; assertTrue ( ""testStructWithSubstitutionGroup(): Incorrect value for out param"" , equals ( yOrig , z . value ) ) ; assertTrue ( ""testStructWithSubstitutionGroup(): Incorrect return value"" , equals ( x , ret ) ) ; } } protected boolean equals ( StructWithSubstitutionGroupAbstract x , StructWithSubstitutionGroupAbstract y ) { if ( x . getSg03AbstractBaseElementA ( ) != null && y . getSg03AbstractBaseElementA ( ) != null ) { SgBaseTypeA xTypeA = x . getSg03AbstractBaseElementA ( ) . getValue ( ) ; SgBaseTypeA yTypeA = y . getSg03AbstractBaseElementA ( ) . getValue ( ) ; return equals ( xTypeA , yTypeA ) ; } return false ; } @ Test public void testStructWithSubstitutionGroupAbstract ( ) throws Exception { if ( ! shouldRunTest ( ""StructWithSubstitutionGroupAbstract"" ) ) { return ; } SgDerivedTypeB derivedB = new SgDerivedTypeB ( ) ; derivedB . setVarInt ( new BigInteger ( ""32"" ) ) ; derivedB . setVarString ( ""foo"" ) ; ObjectFactory objectFactory = new ObjectFactory ( ) ; JAXBElement < SgDerivedTypeB > elementB = objectFactory . createSg03DerivedElementB ( derivedB ) ; SgDerivedTypeC derivedC = new SgDerivedTypeC ( ) ; derivedC . setVarInt ( new BigInteger ( ""32"" ) ) ; derivedC . setVarFloat ( 3.14f ) ; JAXBElement < SgDerivedTypeC > elementC = objectFactory . createSg03DerivedElementC ( derivedC ) ; StructWithSubstitutionGroupAbstract x = new StructWithSubstitutionGroupAbstract ( ) ; x . setSg03AbstractBaseElementA ( elementC ) ; StructWithSubstitutionGroupAbstract yOrig = new StructWithSubstitutionGroupAbstract ( ) ; yOrig . setSg03AbstractBaseElementA ( elementB ) ; Holder < StructWithSubstitutionGroupAbstract > y = new Holder < StructWithSubstitutionGroupAbstract > ( yOrig ) ; Holder < StructWithSubstitutionGroupAbstract > z = new Holder < StructWithSubstitutionGroupAbstract > ( ) ; StructWithSubstitutionGroupAbstract ret ; if ( testDocLiteral ) { ret = docClient . testStructWithSubstitutionGroupAbstract ( x , y , z ) ; } else if ( testXMLBinding ) { ret = xmlClient . testStructWithSubstitutionGroupAbstract ( x , y , z ) ; } else { ret = rpcClient . testStructWithSubstitutionGroupAbstract ( x , y , z ) ; } if ( ! perfTestOnly ) { assertTrue ( ""testStructWithSubstitutionGroupAbstract(): Incorrect value for inout param"" , equals ( x , y . value ) ) ; assertTrue ( ""testStructWithSubstitutionGroupAbstract(): Incorrect value for out param"" , equals ( yOrig , z . value ) ) ; assertTrue ( ""testStructWithSubstitutionGroupAbstract(): Incorrect return value"" , equals ( x , ret ) ) ; } } protected boolean equals ( StructWithSubstitutionGroupNil x , StructWithSubstitutionGroupNil y ) { if ( x . getSg04NillableBaseElementA ( ) . isNil ( ) ) { return y . getSg04NillableBaseElementA ( ) . isNil ( ) ; } else if ( y . getSg04NillableBaseElementA ( ) . isNil ( ) ) { return false ; } else { SgBaseTypeA xTypeA = x . getSg04NillableBaseElementA ( ) . getValue ( ) ; SgBaseTypeA yTypeA = y . getSg04NillableBaseElementA ( ) . getValue ( ) ; return equals ( xTypeA , yTypeA ) ; } } @ Test public void testStructWithSubstitutionGroupNil ( ) throws Exception { if ( ! shouldRunTest ( ""StructWithSubstitutionGroupNil"" ) ) { return ; } StructWithSubstitutionGroupNil x = new StructWithSubstitutionGroupNil ( ) ; ObjectFactory objectFactory = new ObjectFactory ( ) ; JAXBElement < ? extends SgBaseTypeA > element = objectFactory . createSg04NillableBaseElementA ( null ) ; x . setSg04NillableBaseElementA ( element ) ; StructWithSubstitutionGroupNil yOrig = new StructWithSubstitutionGroupNil ( ) ; element = objectFactory . createSg04NillableBaseElementA ( null ) ; yOrig . setSg04NillableBaseElementA ( element ) ; Holder < StructWithSubstitutionGroupNil > y = new Holder < StructWithSubstitutionGroupNil > ( yOrig ) ; Holder < StructWithSubstitutionGroupNil > z = new Holder < StructWithSubstitutionGroupNil > ( ) ; StructWithSubstitutionGroupNil ret ; if ( testDocLiteral ) { ret = docClient . testStructWithSubstitutionGroupNil ( x , y , z ) ; } else if ( testXMLBinding ) { ret = xmlClient . testStructWithSubstitutionGroupNil ( x , y , z ) ; } else { ret = rpcClient . testStructWithSubstitutionGroupNil ( x , y , z ) ; } if ( ! perfTestOnly ) { assertTrue ( ""testStructWithSubstitutionGroupNil(): Incorrect value for inout param"" , equals ( x , y . value ) ) ; assertTrue ( ""testStructWithSubstitutionGroupNil(): Incorrect value for out param"" , equals ( yOrig , z . value ) ) ; assertTrue ( ""testStructWithSubstitutionGroupNil(): Incorrect return value"" , equals ( x , ret ) ) ; } } protected boolean equals ( StructWithMultipleSubstitutionGroups x , StructWithMultipleSubstitutionGroups y ) { if ( Double . compare ( x . getVarFloat ( ) , y . getVarFloat ( ) ) != 0 ) { return false ; } if ( x . getVarInt ( ) . compareTo ( y . getVarInt ( ) ) != 0 ) { return false ; } if ( ! x . getVarString ( ) . equals ( y . getVarString ( ) ) ) { return false ; } if ( x . getSg01BaseElementA ( ) . isNil ( ) ) { if ( ! y . getSg01BaseElementA ( ) . isNil ( ) ) { return false ; } } else if ( y . getSg01BaseElementA ( ) . isNil ( ) ) { return false ; } else { SgBaseTypeA xTypeA = x . getSg01BaseElementA ( ) . getValue ( ) ; SgBaseTypeA yTypeA = y . getSg01BaseElementA ( ) . getValue ( ) ; if ( ! equals ( xTypeA , yTypeA ) ) { return false ; } } if ( x . getSg02BaseElementA ( ) . isNil ( ) ) { if ( ! y . getSg02BaseElementA ( ) . isNil ( ) ) { return false ; } } else if ( y . getSg02BaseElementA ( ) . isNil ( ) ) { return false ; } else { SgBaseTypeA xTypeA = x . getSg02BaseElementA ( ) . getValue ( ) ; SgBaseTypeA yTypeA = y . getSg02BaseElementA ( ) . getValue ( ) ; return equals ( xTypeA , yTypeA ) ; } return true ; } @ Test public void testStructWithMultipleSubstitutionGroups ( ) throws Exception { if ( ! shouldRunTest ( ""StructWithMultipleSubstitutionGroups"" ) ) { return ; } SgBaseTypeA baseA = new SgBaseTypeA ( ) ; baseA . setVarInt ( new BigInteger ( ""1"" ) ) ; SgDerivedTypeB derivedB = new SgDerivedTypeB ( ) ; derivedB . setVarInt ( new BigInteger ( ""32"" ) ) ; derivedB . setVarString ( ""y-SgDerivedTypeB"" ) ; SgDerivedTypeC derivedC = new SgDerivedTypeC ( ) ; derivedC . setVarInt ( new BigInteger ( ""1"" ) ) ; derivedC . setVarFloat ( 3.14f ) ; ObjectFactory objectFactory = new ObjectFactory ( ) ; JAXBElement < ? extends SgBaseTypeA > x1 = objectFactory . createSg01DerivedElementB ( derivedB ) ; JAXBElement < ? extends SgBaseTypeA > x2 = objectFactory . createSg02BaseElementA ( baseA ) ; JAXBElement < ? extends SgBaseTypeA > y1 = objectFactory . createSg01DerivedElementB ( derivedB ) ; JAXBElement < ? extends SgBaseTypeA > y2 = objectFactory . createSg02DerivedElementC ( derivedC ) ; StructWithMultipleSubstitutionGroups x = new StructWithMultipleSubstitutionGroups ( ) ; x . setVarFloat ( 111.1f ) ; x . setVarInt ( new BigInteger ( ""100"" ) ) ; x . setVarString ( ""x-varString"" ) ; x . setSg01BaseElementA ( x1 ) ; x . setSg02BaseElementA ( x2 ) ; StructWithMultipleSubstitutionGroups yOrig = new StructWithMultipleSubstitutionGroups ( ) ; yOrig . setVarFloat ( 1.1f ) ; yOrig . setVarInt ( new BigInteger ( ""10"" ) ) ; yOrig . setVarString ( ""y-varString"" ) ; yOrig . setSg01BaseElementA ( y1 ) ; yOrig . setSg02BaseElementA ( y2 ) ; Holder < StructWithMultipleSubstitutionGroups > y = new Holder < StructWithMultipleSubstitutionGroups > ( yOrig ) ; Holder < StructWithMultipleSubstitutionGroups > z = new Holder < StructWithMultipleSubstitutionGroups > ( ) ; StructWithMultipleSubstitutionGroups ret ; if ( testDocLiteral ) { ret = docClient . testStructWithMultipleSubstitutionGroups ( x , y , z ) ; } else if ( testXMLBinding ) { ret = xmlClient . testStructWithMultipleSubstitutionGroups ( x , y , z ) ; } else { ret = rpcClient . testStructWithMultipleSubstitutionGroups ( x , y , z ) ; } if ( ! perfTestOnly ) { assertTrue ( ""testStructWithMultipleSubstitutionGroups(): Incorrect value for inout param"" , equals ( x , y . value ) ) ; assertTrue ( ""testStructWithMultipleSubstitutionGroups(): Incorrect value for out param"" , equals ( yOrig , z . value ) ) ; assertTrue ( ""testStructWithMultipleSubstitutionGroups(): Incorrect return value"" , equals ( x , ret ) ) ; } } protected boolean equals ( ChoiceWithSubstitutionGroupAbstract x , ChoiceWithSubstitutionGroupAbstract y ) { if ( x . getVarInt ( ) != null && y . getVarInt ( ) != null && x . getVarInt ( ) . equals ( y . getVarInt ( ) ) ) { return true ; } if ( ! x . getSg03AbstractBaseElementA ( ) . isNil ( ) && ! y . getSg03AbstractBaseElementA ( ) . isNil ( ) ) { SgBaseTypeA xTypeA = x . getSg03AbstractBaseElementA ( ) . getValue ( ) ; SgBaseTypeA yTypeA = y . getSg03AbstractBaseElementA ( ) . getValue ( ) ; return equals ( xTypeA , yTypeA ) ; } return false ; } @ Test public void testChoiceWithSubstitutionGroupAbstract ( ) throws Exception { if ( ! shouldRunTest ( ""ChoiceWithSubstitutionGroupAbstract"" ) ) { return ; } SgDerivedTypeB derivedB = new SgDerivedTypeB ( ) ; derivedB . setVarInt ( new BigInteger ( ""32"" ) ) ; derivedB . setVarString ( ""foo"" ) ; SgDerivedTypeC derivedC = new SgDerivedTypeC ( ) ; derivedC . setVarInt ( new BigInteger ( ""32"" ) ) ; derivedC . setVarFloat ( 3.14f ) ; ObjectFactory objectFactory = new ObjectFactory ( ) ; JAXBElement < ? extends SgBaseTypeA > elementB = objectFactory . createSg03DerivedElementB ( derivedB ) ; JAXBElement < ? extends SgBaseTypeA > elementC = objectFactory . createSg03DerivedElementC ( derivedC ) ; ChoiceWithSubstitutionGroupAbstract x = new ChoiceWithSubstitutionGroupAbstract ( ) ; x . setSg03AbstractBaseElementA ( elementC ) ; ChoiceWithSubstitutionGroupAbstract yOrig = new ChoiceWithSubstitutionGroupAbstract ( ) ; yOrig . setSg03AbstractBaseElementA ( elementB ) ; Holder < ChoiceWithSubstitutionGroupAbstract > y = new Holder < ChoiceWithSubstitutionGroupAbstract > ( yOrig ) ; Holder < ChoiceWithSubstitutionGroupAbstract > z = new Holder < ChoiceWithSubstitutionGroupAbstract > ( ) ; ChoiceWithSubstitutionGroupAbstract ret ; if ( testDocLiteral ) { ret = docClient . testChoiceWithSubstitutionGroupAbstract ( x , y , z ) ; } else if ( testXMLBinding ) { ret = xmlClient . testChoiceWithSubstitutionGroupAbstract ( x , y , z ) ; } else { ret = rpcClient . testChoiceWithSubstitutionGroupAbstract ( x , y , z ) ; } if ( ! perfTestOnly ) { assertTrue ( ""testChoiceWithSubstitutionGroupAbstract(): Incorrect value for inout param"" , equals ( x , y . value ) ) ; assertTrue ( ""testChoiceWithSubstitutionGroupAbstract(): Incorrect value for out param"" , equals ( yOrig , z . value ) ) ; assertTrue ( ""testChoiceWithSubstitutionGroupAbstract(): Incorrect return value"" , equals ( x , ret ) ) ; } } protected boolean equals ( ChoiceWithSubstitutionGroupNil x , ChoiceWithSubstitutionGroupNil y ) { if ( x . getVarInt ( ) != null ) { if ( y . getVarInt ( ) == null ) { return false ; } else if ( x . getVarInt ( ) . isNil ( ) ) { return y . getVarInt ( ) . isNil ( ) ; } else { if ( y . getVarInt ( ) . isNil ( ) ) { return false ; } return x . getVarInt ( ) . getValue ( ) . equals ( y . getVarInt ( ) . getValue ( ) ) ; } } else if ( y . getVarInt ( ) != null ) { return false ; } if ( x . getSg04NillableBaseElementA ( ) != null ) { if ( y . getSg04NillableBaseElementA ( ) == null ) { return false ; } else if ( x . getSg04NillableBaseElementA ( ) . isNil ( ) ) { return y . getSg04NillableBaseElementA ( ) . isNil ( ) ; } else { if ( y . getSg04NillableBaseElementA ( ) . isNil ( ) ) { return false ; } SgBaseTypeA xTypeA = x . getSg04NillableBaseElementA ( ) . getValue ( ) ; SgBaseTypeA yTypeA = y . getSg04NillableBaseElementA ( ) . getValue ( ) ; return equals ( xTypeA , yTypeA ) ; } } else { return y . getSg04NillableBaseElementA ( ) == null ; } } @ Test public void testChoiceWithSubstitutionGroupNil ( ) throws Exception { if ( ! shouldRunTest ( ""ChoiceWithSubstitutionGroupNil"" ) ) { return ; } ObjectFactory objectFactory = new ObjectFactory ( ) ; ChoiceWithSubstitutionGroupNil x = new ChoiceWithSubstitutionGroupNil ( ) ; JAXBElement < BigInteger > varInt = objectFactory . createChoiceWithSubstitutionGroupNilVarInt ( null ) ; x . setVarInt ( varInt ) ; ChoiceWithSubstitutionGroupNil yOrig = new ChoiceWithSubstitutionGroupNil ( ) ; JAXBElement < ? extends SgBaseTypeA > elementA = objectFactory . createSg04NillableBaseElementA ( null ) ; yOrig . setSg04NillableBaseElementA ( elementA ) ; Holder < ChoiceWithSubstitutionGroupNil > y = new Holder < ChoiceWithSubstitutionGroupNil > ( yOrig ) ; Holder < ChoiceWithSubstitutionGroupNil > z = new Holder < ChoiceWithSubstitutionGroupNil > ( ) ; ChoiceWithSubstitutionGroupNil ret ; if ( testDocLiteral ) { ret = docClient . testChoiceWithSubstitutionGroupNil ( x , y , z ) ; } else if ( testXMLBinding ) { ret = xmlClient . testChoiceWithSubstitutionGroupNil ( x , y , z ) ; } else { ret = rpcClient . testChoiceWithSubstitutionGroupNil ( x , y , z ) ; } if ( ! perfTestOnly ) { assertTrue ( ""testChoiceWithSubstitutionGroupNil(): Incorrect value for inout param"" , equals ( x , y . value ) ) ; assertTrue ( ""testChoiceWithSubstitutionGroupNil(): Incorrect value for out param"" , equals ( yOrig , z . value ) ) ; assertTrue ( ""testChoiceWithSubstitutionGroupNil(): Incorrect return value"" , equals ( x , ret ) ) ; } } protected boolean equals ( SgBaseTypeA x , SgBaseTypeA y ) { if ( x == null ) { return y == null ; } else if ( y == null ) { return false ; } if ( x . getVarInt ( ) . compareTo ( y . getVarInt ( ) ) != 0 ) { return false ; } if ( x instanceof SgDerivedTypeC ) { if ( y instanceof SgDerivedTypeC ) { SgDerivedTypeC xTypeC = ( SgDerivedTypeC ) x ; SgDerivedTypeC yTypeC = ( SgDerivedTypeC ) y ; return equals ( xTypeC , yTypeC ) ; } else { return false ; } } else if ( x instanceof SgDerivedTypeB ) { if ( y instanceof SgDerivedTypeB ) { SgDerivedTypeB xTypeB = ( SgDerivedTypeB ) x ; SgDerivedTypeB yTypeB = ( SgDerivedTypeB ) y ; return equals ( xTypeB , yTypeB ) ; } else { return false ; } } return true ; } protected boolean equals ( SgDerivedTypeB x , SgDerivedTypeB y ) { return x . getVarString ( ) . equals ( y . getVarString ( ) ) ; } protected boolean equals ( SgDerivedTypeC x , SgDerivedTypeC y ) { return Double . compare ( x . getVarFloat ( ) , y . getVarFloat ( ) ) == 0 ; } protected boolean equals ( ChoiceWithSubstitutionGroup x , ChoiceWithSubstitutionGroup y ) { if ( x . getVarInt ( ) != null && y . getVarInt ( ) != null && x . getVarInt ( ) . compareTo ( y . getVarInt ( ) ) == 0 ) { return true ; } if ( ! x . getSg01BaseElementA ( ) . isNil ( ) && ! y . getSg01BaseElementA ( ) . isNil ( ) ) { SgBaseTypeA xTypeA = x . getSg01BaseElementA ( ) . getValue ( ) ; SgBaseTypeA yTypeA = y . getSg01BaseElementA ( ) . getValue ( ) ; return equals ( xTypeA , yTypeA ) ; } return false ; } @ Test public void testChoiceWithSubstitutionGroup ( ) throws Exception { if ( ! shouldRunTest ( ""ChoiceWithSubstitutionGroup"" ) ) { return ; } SgBaseTypeA baseA = new SgBaseTypeA ( ) ; baseA . setVarInt ( new BigInteger ( ""1"" ) ) ; ObjectFactory objectFactory = new ObjectFactory ( ) ; JAXBElement < ? extends SgBaseTypeA > elementA = objectFactory . createSg01BaseElementA ( baseA ) ; SgDerivedTypeB derivedB = new SgDerivedTypeB ( ) ; derivedB . setVarInt ( new BigInteger ( ""32"" ) ) ; derivedB . setVarString ( ""SgDerivedTypeB"" ) ; JAXBElement < ? extends SgBaseTypeA > elementB = objectFactory . createSg01DerivedElementB ( derivedB ) ; ChoiceWithSubstitutionGroup x = new ChoiceWithSubstitutionGroup ( ) ; x . setSg01BaseElementA ( elementA ) ; ChoiceWithSubstitutionGroup yOrig = new ChoiceWithSubstitutionGroup ( ) ; yOrig . setSg01BaseElementA ( elementB ) ; Holder < ChoiceWithSubstitutionGroup > y = new Holder < ChoiceWithSubstitutionGroup > ( yOrig ) ; Holder < ChoiceWithSubstitutionGroup > z = new Holder < ChoiceWithSubstitutionGroup > ( ) ; assertTrue ( ""yoo: "" , equals ( y . value , y . value ) ) ; ChoiceWithSubstitutionGroup ret ; if ( testDocLiteral ) { ret = docClient . testChoiceWithSubstitutionGroup ( x , y , z ) ; } else if ( testXMLBinding ) { ret = xmlClient . testChoiceWithSubstitutionGroup ( x , y , z ) ; } else { ret = rpcClient . testChoiceWithSubstitutionGroup ( x , y , z ) ; } if ( ! perfTestOnly ) { assertTrue ( ""testChoiceWithSubstitutionGroup(): Incorrect value for inout param"" , equals ( x , y . value ) ) ; assertTrue ( ""testChoiceWithSubstitutionGroup(): Incorrect value for out param"" , equals ( yOrig , z . value ) ) ; assertTrue ( ""testChoiceWithSubstitutionGroup(): Incorrect return value"" , equals ( x , ret ) ) ; } } protected boolean equals ( RecElNextType x , RecElNextType y ) { List < RecElType > xx = x . getRecEl ( ) ; List < RecElType > yy = y . getRecEl ( ) ; if ( xx . size ( ) != yy . size ( ) ) { return false ; } for ( int i = 0 ; i < xx . size ( ) ; i ++ ) { if ( ! equals ( xx . get ( i ) , yy . get ( i ) ) ) { return false ; } } return true ; } protected boolean equals ( RecElType x , RecElType y ) { return x . getVarInt ( ) == y . getVarInt ( ) && equals ( x . getRecElNext ( ) , y . getRecElNext ( ) ) ; } @ Test public void testRecElType ( ) throws Exception { if ( ! shouldRunTest ( ""RecElType"" ) ) { return ; } RecElType x = new RecElType ( ) ; RecElType y = new RecElType ( ) ; RecElNextType xn = new RecElNextType ( ) ; RecElNextType yn = new RecElNextType ( ) ; y . setVarInt ( 123 ) ; y . setRecElNext ( yn ) ; xn . getRecEl ( ) . add ( y ) ; x . setVarInt ( 456 ) ; x . setRecElNext ( xn ) ; Holder < RecElType > yh = new Holder < RecElType > ( y ) ; Holder < RecElType > zh = new Holder < RecElType > ( ) ; RecElType ret ; if ( testDocLiteral ) { ret = docClient . testRecElType ( x , yh , zh ) ; } else if ( testXMLBinding ) { ret = xmlClient . testRecElType ( x , yh , zh ) ; } else { ret = rpcClient . testRecElType ( x , yh , zh ) ; } if ( ! perfTestOnly ) { assertTrue ( ""testRecElType(): Incorrect value for inout param"" , equals ( x , yh . value ) ) ; assertTrue ( ""testRecElType(): Incorrect value for inout param"" , equals ( y , zh . value ) ) ; assertTrue ( ""testRecElType(): Incorrect value for inout param"" , equals ( ret , x ) ) ; } } protected boolean equals ( RecMostInnerType x , RecMostInnerType y ) { return x . getVarInt ( ) == y . getVarInt ( ) && equals ( x . getRecMostInnerNext ( ) , y . getRecMostInnerNext ( ) ) ; } protected boolean equals ( RecMostInnerNextType x , RecMostInnerNextType y ) { List < RecMostInnerType > xx = x . getRecMostInner ( ) ; List < RecMostInnerType > yy = y . getRecMostInner ( ) ; if ( xx . size ( ) != yy . size ( ) ) { return false ; } for ( int i = 0 ; i < xx . size ( ) ; i ++ ) { if ( ! equals ( xx . get ( i ) , yy . get ( i ) ) ) { return false ; } } return true ; } protected boolean equals ( RecInnerType x , RecInnerType y ) { List < RecMostInnerType > mitx = x . getRecMostInner ( ) ; List < RecMostInnerType > mity = y . getRecMostInner ( ) ; if ( mitx . size ( ) != mity . size ( ) ) { return false ; } for ( int i = 0 ; i < mitx . size ( ) ; i ++ ) { if ( ! equals ( mitx . get ( i ) , mity . get ( i ) ) ) { return false ; } } return x . getVarInt ( ) == y . getVarInt ( ) && equals ( x . getRecInnerNext ( ) , y . getRecInnerNext ( ) ) ; } protected boolean equals ( RecInnerNextType x , RecInnerNextType y ) { List < RecInnerType > xx = x . getRecInner ( ) ; List < RecInnerType > yy = y . getRecInner ( ) ; if ( xx . size ( ) != yy . size ( ) ) { return false ; } for ( int i = 0 ; i < xx . size ( ) ; i ++ ) { if ( ! equals ( xx . get ( i ) , yy . get ( i ) ) ) { return false ; } } return true ; } protected boolean equals ( RecOuterNextType x , RecOuterNextType y ) { List < RecOuterType > xx = x . getRecOuter ( ) ; List < RecOuterType > yy = y . getRecOuter ( ) ; if ( xx . size ( ) != yy . size ( ) ) { return false ; } for ( int i = 0 ; i < xx . size ( ) ; i ++ ) { if ( ! equals ( xx . get ( i ) , yy . get ( i ) ) ) { return false ; } } return true ; } protected boolean equals ( RecOuterType x , RecOuterType y ) { List < RecMostInnerType > mitx = x . getRecMostInner ( ) ; List < RecMostInnerType > mity = y . getRecMostInner ( ) ; List < RecInnerType > itx = x . getRecInner ( ) ; List < RecInnerType > ity = y . getRecInner ( ) ; if ( mitx . size ( ) != mity . size ( ) || itx . size ( ) != ity . size ( ) ) { return false ; } for ( int i = 0 ; i < mitx . size ( ) ; i ++ ) { if ( ! equals ( mitx . get ( i ) , mity . get ( i ) ) ) { return false ; } } for ( int i = 0 ; i < itx . size ( ) ; i ++ ) { if ( ! equals ( itx . get ( i ) , ity . get ( i ) ) ) { return false ; } } return x . getVarInt ( ) == y . getVarInt ( ) && equals ( x . getRecOuterNext ( ) , y . getRecOuterNext ( ) ) ; } @ Test public void testRecOuterType ( ) throws Exception { if ( ! shouldRunTest ( ""RecOuterType"" ) ) { return ; } RecMostInnerType mitx = new RecMostInnerType ( ) ; RecMostInnerType mity = new RecMostInnerType ( ) ; RecMostInnerNextType mitxNext = new RecMostInnerNextType ( ) ; RecMostInnerNextType mityNext = new RecMostInnerNextType ( ) ; mitx . setRecMostInnerNext ( mitxNext ) ; mity . setRecMostInnerNext ( mityNext ) ; RecInnerType itx = new RecInnerType ( ) ; RecInnerType ity = new RecInnerType ( ) ; RecInnerNextType itxNext = new RecInnerNextType ( ) ; RecInnerNextType ityNext = new RecInnerNextType ( ) ; itx . setRecInnerNext ( itxNext ) ; ity . setRecInnerNext ( ityNext ) ; RecOuterType otx = new RecOuterType ( ) ; RecOuterType oty = new RecOuterType ( ) ; RecOuterNextType otxNext = new RecOuterNextType ( ) ; RecOuterNextType otyNext = new RecOuterNextType ( ) ; otx . setRecOuterNext ( otxNext ) ; oty . setRecOuterNext ( otyNext ) ; mitx . setVarInt ( 11 ) ; mity . setVarInt ( 12 ) ; mitxNext . getRecMostInner ( ) . add ( mity ) ; itx . setVarInt ( 21 ) ; ity . setVarInt ( 22 ) ; itxNext . getRecInner ( ) . add ( ity ) ; itx . getRecMostInner ( ) . add ( mitx ) ; otx . setVarInt ( 31 ) ; oty . setVarInt ( 32 ) ; otxNext . getRecOuter ( ) . add ( oty ) ; otx . getRecInner ( ) . add ( itx ) ; otx . getRecMostInner ( ) . add ( mitx ) ; Holder < RecOuterType > yh = new Holder < RecOuterType > ( oty ) ; Holder < RecOuterType > zh = new Holder < RecOuterType > ( ) ; RecOuterType ret ; if ( testDocLiteral ) { ret = docClient . testRecOuterType ( otx , yh , zh ) ; } else if ( testXMLBinding ) { ret = xmlClient . testRecOuterType ( otx , yh , zh ) ; } else { ret = rpcClient . testRecOuterType ( otx , yh , zh ) ; } if ( ! perfTestOnly ) { assertTrue ( ""testRecOuterType(): Incorrect value for inout param"" , equals ( otx , yh . value ) ) ; assertTrue ( ""testRecOuterType(): Incorrect value for inout param"" , equals ( oty , zh . value ) ) ; assertTrue ( ""testRecOuterType(): Incorrect value for inout param"" , equals ( ret , otx ) ) ; } } protected void equals ( String msg , SimpleContent1 x , SimpleContent1 y ) throws Exception { assertEquals ( msg , x . getAttrib1A ( ) , y . getAttrib1A ( ) ) ; assertEquals ( msg , x . getAttrib1B ( ) , y . getAttrib1B ( ) ) ; assertEquals ( msg , x . getValue ( ) , y . getValue ( ) ) ; } @ Test public void testSimpleContent1 ( ) throws Exception { if ( ! shouldRunTest ( ""SimpleContent1"" ) ) { return ; } SimpleContent1 x1 = new SimpleContent1 ( ) ; x1 . setValue ( ""foo"" ) ; x1 . setAttrib1A ( new Byte ( ( byte ) 1 ) ) ; x1 . setAttrib1B ( new Short ( ( short ) 2 ) ) ; SimpleContent1 y1 = new SimpleContent1 ( ) ; y1 . setValue ( ""bar"" ) ; y1 . setAttrib1A ( new Byte ( ( byte ) 3 ) ) ; y1 . setAttrib1B ( new Short ( ( short ) 4 ) ) ; Holder < SimpleContent1 > y1Holder = new Holder < SimpleContent1 > ( y1 ) ; Holder < SimpleContent1 > z1 = new Holder < SimpleContent1 > ( ) ; SimpleContent1 ret ; if ( testDocLiteral ) { ret = docClient . testSimpleContent1 ( x1 , y1Holder , z1 ) ; } else if ( testXMLBinding ) { ret = xmlClient . testSimpleContent1 ( x1 , y1Holder , z1 ) ; } else { ret = rpcClient . testSimpleContent1 ( x1 , y1Holder , z1 ) ; } if ( ! perfTestOnly ) { equals ( ""testSimpleContent1(): Incorrect value for inout param"" , x1 , y1Holder . value ) ; equals ( ""testSimpleContent1(): Incorrect value for out param"" , y1 , z1 . value ) ; equals ( ""testSimpleContent1(): Incorrect return value"" , x1 , ret ) ; } } protected void equals ( String msg , SimpleContent2 x , SimpleContent2 y ) throws Exception { assertEquals ( msg , x . getAttrib2A ( ) , y . getAttrib2A ( ) ) ; assertEquals ( msg , x . getAttrib2B ( ) , y . getAttrib2B ( ) ) ; equals ( msg , ( SimpleContent1 ) x , ( SimpleContent1 ) y ) ; } @ Test public void testSimpleContent2 ( ) throws Exception { if ( ! shouldRunTest ( ""SimpleContent2"" ) ) { return ; } SimpleContent2 x2 = new SimpleContent2 ( ) ; x2 . setValue ( ""foo"" ) ; x2 . setAttrib1A ( new Byte ( ( byte ) 1 ) ) ; x2 . setAttrib1B ( new Short ( ( short ) 2 ) ) ; x2 . setAttrib2A ( new Integer ( 5 ) ) ; x2 . setAttrib2B ( new Long ( 6 ) ) ; SimpleContent2 y2 = new SimpleContent2 ( ) ; y2 . setValue ( ""bar"" ) ; y2 . setAttrib1A ( new Byte ( ( byte ) 3 ) ) ; y2 . setAttrib1B ( new Short ( ( short ) 4 ) ) ; y2 . setAttrib2A ( new Integer ( 7 ) ) ; y2 . setAttrib2B ( new Long ( 8 ) ) ; Holder < SimpleContent2 > y2Holder = new Holder < SimpleContent2 > ( y2 ) ; Holder < SimpleContent2 > z2 = new Holder < SimpleContent2 > ( ) ; SimpleContent2 ret ; if ( testDocLiteral ) { ret = docClient . testSimpleContent2 ( x2 , y2Holder , z2 ) ; } else if ( testXMLBinding ) { ret = xmlClient . testSimpleContent2 ( x2 , y2Holder , z2 ) ; } else { ret = rpcClient . testSimpleContent2 ( x2 , y2Holder , z2 ) ; } if ( ! perfTestOnly ) { equals ( ""testSimpleContent2(): Incorrect value for inout param"" , x2 , y2Holder . value ) ; equals ( ""testSimpleContent2(): Incorrect value for out param"" , y2 , z2 . value ) ; equals ( ""testSimpleContent2(): Incorrect return value"" , x2 , ret ) ; } } protected void equals ( String msg , SimpleContent3 x , SimpleContent3 y ) throws Exception { assertEquals ( msg , x . getAttrib3A ( ) , y . getAttrib3A ( ) ) ; assertEquals ( msg , x . isAttrib3B ( ) , y . isAttrib3B ( ) ) ; equals ( msg , ( SimpleContent2 ) x , ( SimpleContent2 ) y ) ; } @ Test public void testSimpleContent3 ( ) throws Exception { if ( ! shouldRunTest ( ""SimpleContent3"" ) ) { return ; } SimpleContent3 x3 = new SimpleContent3 ( ) ; x3 . setValue ( ""foo"" ) ; x3 . setAttrib1A ( new Byte ( ( byte ) 1 ) ) ; x3 . setAttrib1B ( new Short ( ( short ) 2 ) ) ; x3 . setAttrib2A ( new Integer ( 5 ) ) ; x3 . setAttrib2B ( new Long ( 6 ) ) ; x3 . setAttrib3A ( ""xxx"" ) ; x3 . setAttrib3B ( Boolean . TRUE ) ; SimpleContent3 y3 = new SimpleContent3 ( ) ; y3 . setValue ( ""bar"" ) ; y3 . setAttrib1A ( new Byte ( ( byte ) 3 ) ) ; y3 . setAttrib1B ( new Short ( ( short ) 4 ) ) ; y3 . setAttrib2A ( new Integer ( 7 ) ) ; y3 . setAttrib2B ( new Long ( 8 ) ) ; y3 . setAttrib3A ( ""yyy"" ) ; y3 . setAttrib3B ( Boolean . FALSE ) ; Holder < SimpleContent3 > y3Holder = new Holder < SimpleContent3 > ( y3 ) ; Holder < SimpleContent3 > z3 = new Holder < SimpleContent3 > ( ) ; SimpleContent3 ret ; if ( testDocLiteral ) { ret = docClient . testSimpleContent3 ( x3 , y3Holder , z3 ) ; } else if ( testXMLBinding ) { ret = xmlClient . testSimpleContent3 ( x3 , y3Holder , z3 ) ; } else { ret = rpcClient . testSimpleContent3 ( x3 , y3Holder , z3 ) ; } if ( ! perfTestOnly ) { equals ( ""testSimpleContent3(): Incorrect value for inout param"" , x3 , y3Holder . value ) ; equals ( ""testSimpleContent3(): Incorrect value for out param"" , y3 , z3 . value ) ; equals ( ""testSimpleContent3(): Incorrect return value"" , x3 , ret ) ; } } protected void assertEquals ( String msg , UnionSimpleContent x , UnionSimpleContent y ) throws Exception { assertTrue ( msg , x != null ) ; assertTrue ( msg , y != null ) ; assertEquals ( msg , x . getValue ( ) , y . getValue ( ) ) ; } @ Test public void testUnionSimpleContent ( ) throws Exception { if ( ! shouldRunTest ( ""UnionSimpleContent"" ) ) { return ; } UnionSimpleContent x = new UnionSimpleContent ( ) ; x . setValue ( ""5"" ) ; UnionSimpleContent yOrig = new UnionSimpleContent ( ) ; yOrig . setValue ( ""-7"" ) ; Holder < UnionSimpleContent > y = new Holder < UnionSimpleContent > ( yOrig ) ; Holder < UnionSimpleContent > z = new Holder < UnionSimpleContent > ( ) ; UnionSimpleContent ret ; if ( testDocLiteral ) { ret = docClient . testUnionSimpleContent ( x , y , z ) ; } else if ( testXMLBinding ) { ret = xmlClient . testUnionSimpleContent ( x , y , z ) ; } else { ret = rpcClient . testUnionSimpleContent ( x , y , z ) ; } if ( ! perfTestOnly ) { assertEquals ( ""testUnionSimpleContent(): Incorrect value for inout param"" , x , y . value ) ; assertEquals ( ""testUnionSimpleContent(): Incorrect value for out param"" , yOrig , z . value ) ; assertEquals ( ""testUnionSimpleContent(): Incorrect return value"" , x , ret ) ; } } }",Smelly
"public class EditProxyConnectorActionTest extends AbstractWebworkTestCase { private static final String TEST_TARGET_ID = ""central"" ; private static final String TEST_SOURCE_ID = ""corporate"" ; private EditProxyConnectorAction action ; private MockControl archivaConfigurationControl ; private ArchivaConfiguration archivaConfiguration ; @ Override @ Before public void setUp ( ) throws Exception { super . setUp ( ) ; action = ( EditProxyConnectorAction ) getActionProxy ( ""/admin/editProxyConnector.action"" ) . getAction ( ) ; archivaConfigurationControl = MockControl . createControl ( ArchivaConfiguration . class ) ; archivaConfiguration = ( ArchivaConfiguration ) archivaConfigurationControl . getMock ( ) ; ( ( DefaultManagedRepositoryAdmin ) action . getManagedRepositoryAdmin ( ) ) . setArchivaConfiguration ( archivaConfiguration ) ; ( ( DefaultRemoteRepositoryAdmin ) action . getRemoteRepositoryAdmin ( ) ) . setArchivaConfiguration ( archivaConfiguration ) ; ( ( DefaultProxyConnectorAdmin ) action . getProxyConnectorAdmin ( ) ) . setArchivaConfiguration ( archivaConfiguration ) ; } private void expectConfigurationRequests ( int requestConfigCount ) throws org . apache . archiva . redback . components . registry . RegistryException , IndeterminateConfigurationException { expectConfigurationRequests ( requestConfigCount , 1 ) ; } private void expectConfigurationRequests ( int requestConfigCount , int saveRequestCount ) throws RegistryException , IndeterminateConfigurationException { Configuration config = createInitialConfiguration ( ) ; archivaConfigurationControl . expectAndReturn ( archivaConfiguration . getConfiguration ( ) , config , requestConfigCount , 20 ) ; for ( int i = 0 ; i <= saveRequestCount ; i ++ ) { archivaConfiguration . save ( config ) ; } ( ( DefaultManagedRepositoryAdmin ) action . getManagedRepositoryAdmin ( ) ) . setArchivaConfiguration ( archivaConfiguration ) ; ( ( DefaultRemoteRepositoryAdmin ) action . getRemoteRepositoryAdmin ( ) ) . setArchivaConfiguration ( archivaConfiguration ) ; ( ( DefaultProxyConnectorAdmin ) action . getProxyConnectorAdmin ( ) ) . setArchivaConfiguration ( archivaConfiguration ) ; } @ Test public void testAddBlackListPattern ( ) throws Exception { expectConfigurationRequests ( 7 ) ; archivaConfigurationControl . replay ( ) ; action . setSource ( TEST_SOURCE_ID ) ; action . setTarget ( TEST_TARGET_ID ) ; action . prepare ( ) ; ProxyConnector connector = action . getConnector ( ) ; assertInitialProxyConnector ( connector ) ; preRequest ( action ) ; String status = action . addBlackListPattern ( ) ; assertEquals ( Action . INPUT , status ) ; assertHasErrors ( action ) ; assertEquals ( 0 , connector . getBlackListPatterns ( ) . size ( ) ) ; action . setBlackListPattern ( ""**/*-javadoc.jar"" ) ; preRequest ( action ) ; status = action . addBlackListPattern ( ) ; assertEquals ( Action . INPUT , status ) ; assertNoErrors ( action ) ; assertEquals ( 1 , connector . getBlackListPatterns ( ) . size ( ) ) ; } @ Test public void testAddProperty ( ) throws Exception { expectConfigurationRequests ( 7 ) ; archivaConfigurationControl . replay ( ) ; action . setSource ( TEST_SOURCE_ID ) ; action . setTarget ( TEST_TARGET_ID ) ; action . prepare ( ) ; ProxyConnector connector = action . getConnector ( ) ; assertInitialProxyConnector ( connector ) ; preRequest ( action ) ; String status = action . addProperty ( ) ; assertEquals ( Action . INPUT , status ) ; assertHasErrors ( action ) ; assertEquals ( 0 , connector . getProperties ( ) . size ( ) ) ; action . setPropertyKey ( ""eat-a"" ) ; action . setPropertyValue ( ""gramov-a-bits"" ) ; preRequest ( action ) ; status = action . addProperty ( ) ; assertEquals ( Action . INPUT , status ) ; assertNoErrors ( action ) ; assertEquals ( 1 , connector . getProperties ( ) . size ( ) ) ; assertEquals ( ""gramov-a-bits"" , connector . getProperties ( ) . get ( ""eat-a"" ) ) ; } @ Test public void testAddWhiteListPattern ( ) throws Exception { expectConfigurationRequests ( 7 ) ; archivaConfigurationControl . replay ( ) ; action . setSource ( TEST_SOURCE_ID ) ; action . setTarget ( TEST_TARGET_ID ) ; action . prepare ( ) ; ProxyConnector connector = action . getConnector ( ) ; assertInitialProxyConnector ( connector ) ; preRequest ( action ) ; String status = action . addWhiteListPattern ( ) ; assertEquals ( Action . INPUT , status ) ; assertHasErrors ( action ) ; assertEquals ( 0 , connector . getWhiteListPatterns ( ) . size ( ) ) ; action . setWhiteListPattern ( ""**/*.jar"" ) ; preRequest ( action ) ; status = action . addWhiteListPattern ( ) ; assertEquals ( Action . INPUT , status ) ; assertNoErrors ( action ) ; assertEquals ( 1 , connector . getWhiteListPatterns ( ) . size ( ) ) ; } @ SuppressWarnings ( ""unchecked"" ) @ Test public void testEditProxyConnectorCommit ( ) throws Exception { expectConfigurationRequests ( 9 , 2 ) ; archivaConfigurationControl . replay ( ) ; action . setSource ( TEST_SOURCE_ID ) ; action . setTarget ( TEST_TARGET_ID ) ; action . prepare ( ) ; ProxyConnector connector = action . getConnector ( ) ; assertInitialProxyConnector ( connector ) ; connector . getProperties ( ) . put ( ""eat-a"" , ""gramov-a-bits"" ) ; assertRequestStatus ( action , Action . SUCCESS , ""commit"" ) ; assertNoErrors ( action ) ; List < ProxyConnectorConfiguration > proxyConfigs = archivaConfiguration . getConfiguration ( ) . getProxyConnectors ( ) ; assertNotNull ( proxyConfigs ) ; assertEquals ( 1 , proxyConfigs . size ( ) ) ; ProxyConnectorConfiguration actualConnector = proxyConfigs . get ( 0 ) ; assertNotNull ( actualConnector ) ; assertNull ( actualConnector . getProxyId ( ) ) ; assertEquals ( ""corporate"" , actualConnector . getSourceRepoId ( ) ) ; assertEquals ( ""central"" , actualConnector . getTargetRepoId ( ) ) ; } @ Test public void testEditProxyConnectorInitialPage ( ) throws Exception { expectConfigurationRequests ( 3 ) ; archivaConfigurationControl . replay ( ) ; action . setSource ( TEST_SOURCE_ID ) ; action . setTarget ( TEST_TARGET_ID ) ; action . prepare ( ) ; ProxyConnector connector = action . getConnector ( ) ; assertInitialProxyConnector ( connector ) ; String status = action . input ( ) ; assertEquals ( Action . INPUT , status ) ; } @ Test public void testRemoveBlackListPattern ( ) throws Exception { expectConfigurationRequests ( 7 ) ; archivaConfigurationControl . replay ( ) ; action . setSource ( TEST_SOURCE_ID ) ; action . setTarget ( TEST_TARGET_ID ) ; action . prepare ( ) ; ProxyConnector connector = action . getConnector ( ) ; assertInitialProxyConnector ( connector ) ; connector . addBlackListPattern ( ""**/*-javadoc.jar"" ) ; connector . addBlackListPattern ( ""**/*.war"" ) ; preRequest ( action ) ; String status = action . removeBlackListPattern ( ) ; assertEquals ( Action . INPUT , status ) ; assertHasErrors ( action ) ; assertEquals ( 2 , connector . getBlackListPatterns ( ) . size ( ) ) ; preRequest ( action ) ; action . setPattern ( ""**/*oops*"" ) ; status = action . removeBlackListPattern ( ) ; assertEquals ( Action . INPUT , status ) ; assertHasErrors ( action ) ; assertEquals ( 2 , connector . getBlackListPatterns ( ) . size ( ) ) ; action . setPattern ( ""**/*-javadoc.jar"" ) ; preRequest ( action ) ; status = action . removeBlackListPattern ( ) ; assertEquals ( Action . INPUT , status ) ; assertNoErrors ( action ) ; assertEquals ( 1 , connector . getBlackListPatterns ( ) . size ( ) ) ; assertEquals ( ""Should have left 1 blacklist pattern"" , ""**/*.war"" , connector . getBlackListPatterns ( ) . get ( 0 ) ) ; } @ Test public void testRemoveProperty ( ) throws Exception { expectConfigurationRequests ( 7 ) ; archivaConfigurationControl . replay ( ) ; action . setSource ( TEST_SOURCE_ID ) ; action . setTarget ( TEST_TARGET_ID ) ; action . prepare ( ) ; ProxyConnector connector = action . getConnector ( ) ; assertInitialProxyConnector ( connector ) ; connector . addProperty ( ""username"" , ""general-tso"" ) ; connector . addProperty ( ""password"" , ""chicken"" ) ; preRequest ( action ) ; String status = action . removeProperty ( ) ; assertEquals ( Action . INPUT , status ) ; assertHasErrors ( action ) ; assertEquals ( 2 , connector . getProperties ( ) . size ( ) ) ; preRequest ( action ) ; action . setPropertyKey ( ""slurm"" ) ; status = action . removeProperty ( ) ; assertEquals ( Action . INPUT , status ) ; assertHasErrors ( action ) ; assertEquals ( 2 , connector . getProperties ( ) . size ( ) ) ; preRequest ( action ) ; action . setPropertyKey ( ""password"" ) ; status = action . removeProperty ( ) ; assertEquals ( Action . INPUT , status ) ; assertNoErrors ( action ) ; assertEquals ( 1 , connector . getProperties ( ) . size ( ) ) ; assertEquals ( ""Should have left 1 property"" , ""general-tso"" , connector . getProperties ( ) . get ( ""username"" ) ) ; } @ Test public void testRemoveWhiteListPattern ( ) throws Exception { expectConfigurationRequests ( 7 ) ; archivaConfigurationControl . replay ( ) ; action . setSource ( TEST_SOURCE_ID ) ; action . setTarget ( TEST_TARGET_ID ) ; action . prepare ( ) ; ProxyConnector connector = action . getConnector ( ) ; assertInitialProxyConnector ( connector ) ; connector . addWhiteListPattern ( ""javax/**/*"" ) ; connector . addWhiteListPattern ( ""com/sun/**/*"" ) ; preRequest ( action ) ; String status = action . removeWhiteListPattern ( ) ; assertEquals ( Action . INPUT , status ) ; assertHasErrors ( action ) ; assertEquals ( 2 , connector . getWhiteListPatterns ( ) . size ( ) ) ; preRequest ( action ) ; action . setPattern ( ""**/*oops*"" ) ; status = action . removeWhiteListPattern ( ) ; assertEquals ( Action . INPUT , status ) ; assertHasErrors ( action ) ; assertEquals ( 2 , connector . getWhiteListPatterns ( ) . size ( ) ) ; action . setPattern ( ""com/sun/**/*"" ) ; preRequest ( action ) ; status = action . removeWhiteListPattern ( ) ; assertEquals ( Action . INPUT , status ) ; assertNoErrors ( action ) ; assertEquals ( 1 , connector . getWhiteListPatterns ( ) . size ( ) ) ; assertEquals ( ""Should have left 1 whitelist pattern"" , ""javax/**/*"" , connector . getWhiteListPatterns ( ) . get ( 0 ) ) ; } @ Test public void testSecureActionBundle ( ) throws Exception { archivaConfiguration . getConfiguration ( ) ; archivaConfigurationControl . setReturnValue ( new Configuration ( ) , 3 ) ; archivaConfigurationControl . replay ( ) ; action . prepare ( ) ; SecureActionBundle bundle = action . getSecureActionBundle ( ) ; assertTrue ( bundle . requiresAuthentication ( ) ) ; assertEquals ( 1 , bundle . getAuthorizationTuples ( ) . size ( ) ) ; } private void assertInitialProxyConnector ( ProxyConnector connector ) { assertNotNull ( connector ) ; assertNotNull ( connector . getBlackListPatterns ( ) ) ; assertNotNull ( connector . getWhiteListPatterns ( ) ) ; assertNotNull ( connector . getProperties ( ) ) ; assertEquals ( TEST_SOURCE_ID , connector . getSourceRepoId ( ) ) ; assertEquals ( TEST_TARGET_ID , connector . getTargetRepoId ( ) ) ; } @ SuppressWarnings ( ""unchecked"" ) private Configuration createInitialConfiguration ( ) { Configuration config = new Configuration ( ) ; ManagedRepositoryConfiguration managedRepo = new ManagedRepositoryConfiguration ( ) ; managedRepo . setId ( TEST_SOURCE_ID ) ; managedRepo . setLayout ( ""${java.io.tmpdir}/archiva-test/managed-repo"" ) ; managedRepo . setReleases ( true ) ; config . addManagedRepository ( managedRepo ) ; RemoteRepositoryConfiguration remoteRepo = new RemoteRepositoryConfiguration ( ) ; remoteRepo . setId ( TEST_TARGET_ID ) ; remoteRepo . setUrl ( ""http://repo1.maven.org/maven2/"" ) ; config . addRemoteRepository ( remoteRepo ) ; ProxyConnectorConfiguration connector = new ProxyConnectorConfiguration ( ) ; connector . setSourceRepoId ( TEST_SOURCE_ID ) ; connector . setTargetRepoId ( TEST_TARGET_ID ) ; Map < String , String > policies = connector . getPolicies ( ) ; policies . put ( ""releases"" , new ReleasesPolicy ( ) . getDefaultOption ( ) ) ; policies . put ( ""snapshots"" , new SnapshotsPolicy ( ) . getDefaultOption ( ) ) ; policies . put ( ""checksum"" , new ChecksumPolicy ( ) . getDefaultOption ( ) ) ; policies . put ( ""cache-failures"" , new CachedFailuresPolicy ( ) . getDefaultOption ( ) ) ; policies . put ( ""propagate-errors"" , new PropagateErrorsDownloadPolicy ( ) . getDefaultOption ( ) ) ; policies . put ( ""propagate-errors-on-update"" , new PropagateErrorsOnUpdateDownloadPolicy ( ) . getDefaultOption ( ) ) ; config . addProxyConnector ( connector ) ; return config ; } }",Smelly
"public class StructInstance implements ITypedStruct { public final String dataTypeName ; public final FieldMapping fieldMapping ; public final boolean nullFlags [ ] ; public final boolean explicitSets [ ] ; public final boolean [ ] bools ; public final byte [ ] bytes ; public final short [ ] shorts ; public final int [ ] ints ; public final long [ ] longs ; public final float [ ] floats ; public final double [ ] doubles ; public final BigDecimal [ ] bigDecimals ; public final BigInteger [ ] bigIntegers ; public final Date [ ] dates ; public final String [ ] strings ; public final ImmutableList < Object > [ ] arrays ; public final ImmutableMap < Object , Object > [ ] maps ; public final StructInstance [ ] structs ; public final ReferenceableInstance [ ] referenceables ; public final Id [ ] ids ; public StructInstance ( String dataTypeName , FieldMapping fieldMapping , boolean [ ] nullFlags , boolean [ ] explicitSets , boolean [ ] bools , byte [ ] bytes , short [ ] shorts , int [ ] ints , long [ ] longs , float [ ] floats , double [ ] doubles , BigDecimal [ ] bigDecimals , BigInteger [ ] bigIntegers , Date [ ] dates , String [ ] strings , ImmutableList < Object > [ ] arrays , ImmutableMap < Object , Object > [ ] maps , StructInstance [ ] structs , ReferenceableInstance [ ] referenceables , Id [ ] ids ) { assert dataTypeName != null ; this . dataTypeName = dataTypeName ; this . fieldMapping = fieldMapping ; this . nullFlags = nullFlags ; this . explicitSets = explicitSets ; this . bools = bools ; this . bytes = bytes ; this . shorts = shorts ; this . ints = ints ; this . longs = longs ; this . floats = floats ; this . doubles = doubles ; this . bigDecimals = bigDecimals ; this . bigIntegers = bigIntegers ; this . dates = dates ; this . strings = strings ; this . arrays = arrays ; this . maps = maps ; this . structs = structs ; this . referenceables = referenceables ; this . ids = ids ; for ( int i = 0 ; i < nullFlags . length ; i ++ ) { nullFlags [ i ] = true ; } for ( int i = 0 ; i < explicitSets . length ; i ++ ) { explicitSets [ i ] = false ; } } @ Override public String getTypeName ( ) { return dataTypeName ; } @ Override public FieldMapping fieldMapping ( ) { return fieldMapping ; } public void set ( String attrName , Object val ) throws AtlasException { AttributeInfo i = fieldMapping . fields . get ( attrName ) ; if ( i == null ) { throw new ValueConversionException ( getTypeName ( ) , val , ""Unknown field "" + attrName ) ; } int pos = fieldMapping . fieldPos . get ( attrName ) ; int nullPos = fieldMapping . fieldNullPos . get ( attrName ) ; Object cVal = null ; explicitSets [ nullPos ] = true ; if ( val != null && val instanceof Id ) { ClassType clsType = TypeSystem . getInstance ( ) . getDataType ( ClassType . class , i . dataType ( ) . getName ( ) ) ; clsType . validateId ( ( Id ) val ) ; cVal = val ; } else { try { cVal = i . dataType ( ) . convert ( val , i . multiplicity ) ; } catch ( ValueConversionException . NullConversionException e ) { throw new ValueConversionException . NullConversionException ( ""For field '"" + attrName + ""'"" , e ) ; } } if ( cVal == null ) { nullFlags [ nullPos ] = true ; return ; } nullFlags [ nullPos ] = false ; if ( i . dataType ( ) == DataTypes . BOOLEAN_TYPE ) { bools [ pos ] = ( Boolean ) cVal ; } else if ( i . dataType ( ) == DataTypes . BYTE_TYPE ) { bytes [ pos ] = ( Byte ) cVal ; } else if ( i . dataType ( ) == DataTypes . SHORT_TYPE ) { shorts [ pos ] = ( Short ) cVal ; } else if ( i . dataType ( ) == DataTypes . INT_TYPE ) { ints [ pos ] = ( Integer ) cVal ; } else if ( i . dataType ( ) == DataTypes . LONG_TYPE ) { longs [ pos ] = ( Long ) cVal ; } else if ( i . dataType ( ) == DataTypes . FLOAT_TYPE ) { floats [ pos ] = ( Float ) cVal ; } else if ( i . dataType ( ) == DataTypes . DOUBLE_TYPE ) { doubles [ pos ] = ( Double ) cVal ; } else if ( i . dataType ( ) == DataTypes . BIGINTEGER_TYPE ) { bigIntegers [ pos ] = ( BigInteger ) cVal ; } else if ( i . dataType ( ) == DataTypes . BIGDECIMAL_TYPE ) { bigDecimals [ pos ] = ( BigDecimal ) cVal ; } else if ( i . dataType ( ) == DataTypes . DATE_TYPE ) { dates [ pos ] = ( Date ) cVal ; } else if ( i . dataType ( ) == DataTypes . STRING_TYPE ) { strings [ pos ] = ( String ) cVal ; } else if ( i . dataType ( ) . getTypeCategory ( ) == DataTypes . TypeCategory . ENUM ) { ints [ pos ] = ( ( EnumValue ) cVal ) . ordinal ; } else if ( i . dataType ( ) . getTypeCategory ( ) == DataTypes . TypeCategory . ARRAY ) { arrays [ pos ] = ( ImmutableList ) cVal ; } else if ( i . dataType ( ) . getTypeCategory ( ) == DataTypes . TypeCategory . MAP ) { maps [ pos ] = ( ImmutableMap ) cVal ; } else if ( i . dataType ( ) . getTypeCategory ( ) == DataTypes . TypeCategory . STRUCT || i . dataType ( ) . getTypeCategory ( ) == DataTypes . TypeCategory . TRAIT ) { structs [ pos ] = ( StructInstance ) cVal ; } else if ( i . dataType ( ) . getTypeCategory ( ) == DataTypes . TypeCategory . CLASS ) { if ( cVal instanceof Id ) { ids [ pos ] = ( Id ) cVal ; } else { referenceables [ pos ] = ( ReferenceableInstance ) cVal ; } } else { throw new AtlasException ( String . format ( ""Unknown datatype %s"" , i . dataType ( ) ) ) ; } } public Object get ( String attrName ) throws AtlasException { AttributeInfo i = fieldMapping . fields . get ( attrName ) ; if ( i == null ) { throw new AtlasException ( String . format ( ""Unknown field %s for Struct %s"" , attrName , getTypeName ( ) ) ) ; } int pos = fieldMapping . fieldPos . get ( attrName ) ; int nullPos = fieldMapping . fieldNullPos . get ( attrName ) ; if ( nullFlags [ nullPos ] ) { if ( i . dataType ( ) . getTypeCategory ( ) == DataTypes . TypeCategory . PRIMITIVE ) { return ( ( DataTypes . PrimitiveType ) i . dataType ( ) ) . nullValue ( ) ; } else { return null ; } } if ( i . dataType ( ) == DataTypes . BOOLEAN_TYPE ) { return bools [ pos ] ; } else if ( i . dataType ( ) == DataTypes . BYTE_TYPE ) { return bytes [ pos ] ; } else if ( i . dataType ( ) == DataTypes . SHORT_TYPE ) { return shorts [ pos ] ; } else if ( i . dataType ( ) == DataTypes . INT_TYPE ) { return ints [ pos ] ; } else if ( i . dataType ( ) == DataTypes . LONG_TYPE ) { return longs [ pos ] ; } else if ( i . dataType ( ) == DataTypes . FLOAT_TYPE ) { return floats [ pos ] ; } else if ( i . dataType ( ) == DataTypes . DOUBLE_TYPE ) { return doubles [ pos ] ; } else if ( i . dataType ( ) == DataTypes . BIGINTEGER_TYPE ) { return bigIntegers [ pos ] ; } else if ( i . dataType ( ) == DataTypes . BIGDECIMAL_TYPE ) { return bigDecimals [ pos ] ; } else if ( i . dataType ( ) == DataTypes . DATE_TYPE ) { return dates [ pos ] ; } else if ( i . dataType ( ) == DataTypes . STRING_TYPE ) { return strings [ pos ] ; } else if ( i . dataType ( ) . getTypeCategory ( ) == DataTypes . TypeCategory . ENUM ) { return ( ( EnumType ) i . dataType ( ) ) . fromOrdinal ( ints [ pos ] ) ; } else if ( i . dataType ( ) . getTypeCategory ( ) == DataTypes . TypeCategory . ARRAY ) { return arrays [ pos ] ; } else if ( i . dataType ( ) . getTypeCategory ( ) == DataTypes . TypeCategory . MAP ) { return maps [ pos ] ; } else if ( i . dataType ( ) . getTypeCategory ( ) == DataTypes . TypeCategory . STRUCT || i . dataType ( ) . getTypeCategory ( ) == DataTypes . TypeCategory . TRAIT ) { return structs [ pos ] ; } else if ( i . dataType ( ) . getTypeCategory ( ) == DataTypes . TypeCategory . CLASS ) { if ( ids [ pos ] != null ) { return ids [ pos ] ; } else { return referenceables [ pos ] ; } } else { throw new AtlasException ( String . format ( ""Unknown datatype %s"" , i . dataType ( ) ) ) ; } } public void setNull ( String attrName ) throws AtlasException { AttributeInfo i = fieldMapping . fields . get ( attrName ) ; if ( i == null ) { throw new AtlasException ( String . format ( ""Unknown field %s for Struct %s"" , attrName , getTypeName ( ) ) ) ; } int nullPos = fieldMapping . fieldNullPos . get ( attrName ) ; nullFlags [ nullPos ] = true ; explicitSets [ nullPos ] = true ; int pos = fieldMapping . fieldPos . get ( attrName ) ; if ( i . dataType ( ) == DataTypes . BIGINTEGER_TYPE ) { bigIntegers [ pos ] = null ; } else if ( i . dataType ( ) == DataTypes . BIGDECIMAL_TYPE ) { bigDecimals [ pos ] = null ; } else if ( i . dataType ( ) == DataTypes . DATE_TYPE ) { dates [ pos ] = null ; } else if ( i . dataType ( ) == DataTypes . INT_TYPE ) { ints [ pos ] = 0 ; } else if ( i . dataType ( ) == DataTypes . BOOLEAN_TYPE ) { bools [ pos ] = false ; } else if ( i . dataType ( ) == DataTypes . STRING_TYPE ) { strings [ pos ] = null ; } else if ( i . dataType ( ) . getTypeCategory ( ) == DataTypes . TypeCategory . ARRAY ) { arrays [ pos ] = null ; } else if ( i . dataType ( ) . getTypeCategory ( ) == DataTypes . TypeCategory . MAP ) { maps [ pos ] = null ; } else if ( i . dataType ( ) . getTypeCategory ( ) == DataTypes . TypeCategory . STRUCT || i . dataType ( ) . getTypeCategory ( ) == DataTypes . TypeCategory . TRAIT ) { structs [ pos ] = null ; } else if ( i . dataType ( ) . getTypeCategory ( ) == DataTypes . TypeCategory . CLASS ) { ids [ pos ] = null ; referenceables [ pos ] = null ; } else { throw new AtlasException ( String . format ( ""Unknown datatype %s"" , i . dataType ( ) ) ) ; } } @ Override public Map < String , Object > getValuesMap ( ) throws AtlasException { Map < String , Object > m = new HashMap < > ( ) ; for ( String attr : fieldMapping . fields . keySet ( ) ) { m . put ( attr , get ( attr ) ) ; } return m ; } public boolean getBoolean ( String attrName ) throws AtlasException { AttributeInfo i = fieldMapping . fields . get ( attrName ) ; if ( i == null ) { throw new AtlasException ( String . format ( ""Unknown field %s for Struct %s"" , attrName , getTypeName ( ) ) ) ; } if ( i . dataType ( ) != DataTypes . BOOLEAN_TYPE ) { throw new AtlasException ( String . format ( ""Field %s for Struct %s is not a %s, call generic get method"" , attrName , getTypeName ( ) , DataTypes . BOOLEAN_TYPE . getName ( ) ) ) ; } int pos = fieldMapping . fieldPos . get ( attrName ) ; int nullPos = fieldMapping . fieldNullPos . get ( attrName ) ; if ( nullFlags [ nullPos ] ) { return DataTypes . BOOLEAN_TYPE . nullValue ( ) ; } return bools [ pos ] ; } public byte getByte ( String attrName ) throws AtlasException { AttributeInfo i = fieldMapping . fields . get ( attrName ) ; if ( i == null ) { throw new AtlasException ( String . format ( ""Unknown field %s for Struct %s"" , attrName , getTypeName ( ) ) ) ; } if ( i . dataType ( ) != DataTypes . BYTE_TYPE ) { throw new AtlasException ( String . format ( ""Field %s for Struct %s is not a %s, call generic get method"" , attrName , getTypeName ( ) , DataTypes . BYTE_TYPE . getName ( ) ) ) ; } int pos = fieldMapping . fieldPos . get ( attrName ) ; int nullPos = fieldMapping . fieldNullPos . get ( attrName ) ; if ( nullFlags [ nullPos ] ) { return DataTypes . BYTE_TYPE . nullValue ( ) ; } return bytes [ pos ] ; } public short getShort ( String attrName ) throws AtlasException { AttributeInfo i = fieldMapping . fields . get ( attrName ) ; if ( i == null ) { throw new AtlasException ( String . format ( ""Unknown field %s for Struct %s"" , attrName , getTypeName ( ) ) ) ; } if ( i . dataType ( ) != DataTypes . SHORT_TYPE ) { throw new AtlasException ( String . format ( ""Field %s for Struct %s is not a %s, call generic get method"" , attrName , getTypeName ( ) , DataTypes . SHORT_TYPE . getName ( ) ) ) ; } int pos = fieldMapping . fieldPos . get ( attrName ) ; int nullPos = fieldMapping . fieldNullPos . get ( attrName ) ; if ( nullFlags [ nullPos ] ) { return DataTypes . SHORT_TYPE . nullValue ( ) ; } return shorts [ pos ] ; } public int getInt ( String attrName ) throws AtlasException { AttributeInfo i = fieldMapping . fields . get ( attrName ) ; if ( i == null ) { throw new AtlasException ( String . format ( ""Unknown field %s for Struct %s"" , attrName , getTypeName ( ) ) ) ; } if ( i . dataType ( ) != DataTypes . INT_TYPE && ! ( i . dataType ( ) instanceof EnumType ) ) { throw new AtlasException ( String . format ( ""Field %s for Struct %s is not a %s, call generic get method"" , attrName , getTypeName ( ) , DataTypes . INT_TYPE . getName ( ) ) ) ; } int pos = fieldMapping . fieldPos . get ( attrName ) ; int nullPos = fieldMapping . fieldNullPos . get ( attrName ) ; if ( nullFlags [ nullPos ] ) { return DataTypes . INT_TYPE . nullValue ( ) ; } return ints [ pos ] ; } public long getLong ( String attrName ) throws AtlasException { AttributeInfo i = fieldMapping . fields . get ( attrName ) ; if ( i == null ) { throw new AtlasException ( String . format ( ""Unknown field %s for Struct %s"" , attrName , getTypeName ( ) ) ) ; } if ( i . dataType ( ) != DataTypes . LONG_TYPE ) { throw new AtlasException ( String . format ( ""Field %s for Struct %s is not a %s, call generic get method"" , attrName , getTypeName ( ) , DataTypes . LONG_TYPE . getName ( ) ) ) ; } int pos = fieldMapping . fieldPos . get ( attrName ) ; int nullPos = fieldMapping . fieldNullPos . get ( attrName ) ; if ( nullFlags [ nullPos ] ) { return DataTypes . LONG_TYPE . nullValue ( ) ; } return longs [ pos ] ; } public float getFloat ( String attrName ) throws AtlasException { AttributeInfo i = fieldMapping . fields . get ( attrName ) ; if ( i == null ) { throw new AtlasException ( String . format ( ""Unknown field %s for Struct %s"" , attrName , getTypeName ( ) ) ) ; } if ( i . dataType ( ) != DataTypes . FLOAT_TYPE ) { throw new AtlasException ( String . format ( ""Field %s for Struct %s is not a %s, call generic get method"" , attrName , getTypeName ( ) , DataTypes . FLOAT_TYPE . getName ( ) ) ) ; } int pos = fieldMapping . fieldPos . get ( attrName ) ; int nullPos = fieldMapping . fieldNullPos . get ( attrName ) ; if ( nullFlags [ nullPos ] ) { return DataTypes . FLOAT_TYPE . nullValue ( ) ; } return floats [ pos ] ; } public double getDouble ( String attrName ) throws AtlasException { AttributeInfo i = fieldMapping . fields . get ( attrName ) ; if ( i == null ) { throw new AtlasException ( String . format ( ""Unknown field %s for Struct %s"" , attrName , getTypeName ( ) ) ) ; } if ( i . dataType ( ) != DataTypes . DOUBLE_TYPE ) { throw new AtlasException ( String . format ( ""Field %s for Struct %s is not a %s, call generic get method"" , attrName , getTypeName ( ) , DataTypes . DOUBLE_TYPE . getName ( ) ) ) ; } int pos = fieldMapping . fieldPos . get ( attrName ) ; int nullPos = fieldMapping . fieldNullPos . get ( attrName ) ; if ( nullFlags [ nullPos ] ) { return DataTypes . DOUBLE_TYPE . nullValue ( ) ; } return doubles [ pos ] ; } public BigInteger getBigInt ( String attrName ) throws AtlasException { AttributeInfo i = fieldMapping . fields . get ( attrName ) ; if ( i == null ) { throw new AtlasException ( String . format ( ""Unknown field %s for Struct %s"" , attrName , getTypeName ( ) ) ) ; } if ( i . dataType ( ) != DataTypes . BIGINTEGER_TYPE ) { throw new AtlasException ( String . format ( ""Field %s for Struct %s is not a %s, call generic get method"" , attrName , getTypeName ( ) , DataTypes . BIGINTEGER_TYPE . getName ( ) ) ) ; } int pos = fieldMapping . fieldPos . get ( attrName ) ; int nullPos = fieldMapping . fieldNullPos . get ( attrName ) ; if ( nullFlags [ nullPos ] ) { return DataTypes . BIGINTEGER_TYPE . nullValue ( ) ; } return bigIntegers [ pos ] ; } public BigDecimal getBigDecimal ( String attrName ) throws AtlasException { AttributeInfo i = fieldMapping . fields . get ( attrName ) ; if ( i == null ) { throw new AtlasException ( String . format ( ""Unknown field %s for Struct %s"" , attrName , getTypeName ( ) ) ) ; } if ( i . dataType ( ) != DataTypes . BIGDECIMAL_TYPE ) { throw new AtlasException ( String . format ( ""Field %s for Struct %s is not a %s, call generic get method"" , attrName , getTypeName ( ) , DataTypes . BIGDECIMAL_TYPE . getName ( ) ) ) ; } int pos = fieldMapping . fieldPos . get ( attrName ) ; int nullPos = fieldMapping . fieldNullPos . get ( attrName ) ; if ( nullFlags [ nullPos ] ) { return DataTypes . BIGDECIMAL_TYPE . nullValue ( ) ; } return bigDecimals [ pos ] ; } public Date getDate ( String attrName ) throws AtlasException { AttributeInfo i = fieldMapping . fields . get ( attrName ) ; if ( i == null ) { throw new AtlasException ( String . format ( ""Unknown field %s for Struct %s"" , attrName , getTypeName ( ) ) ) ; } if ( i . dataType ( ) != DataTypes . DATE_TYPE ) { throw new AtlasException ( String . format ( ""Field %s for Struct %s is not a %s, call generic get method"" , attrName , getTypeName ( ) , DataTypes . DATE_TYPE . getName ( ) ) ) ; } int pos = fieldMapping . fieldPos . get ( attrName ) ; int nullPos = fieldMapping . fieldNullPos . get ( attrName ) ; if ( nullFlags [ nullPos ] ) { return DataTypes . DATE_TYPE . nullValue ( ) ; } return dates [ pos ] ; } public String getString ( String attrName ) throws AtlasException { AttributeInfo i = fieldMapping . fields . get ( attrName ) ; if ( i == null ) { throw new AtlasException ( String . format ( ""Unknown field %s for Struct %s"" , attrName , getTypeName ( ) ) ) ; } if ( i . dataType ( ) != DataTypes . STRING_TYPE ) { throw new AtlasException ( String . format ( ""Field %s for Struct %s is not a %s, call generic get method"" , attrName , getTypeName ( ) , DataTypes . STRING_TYPE . getName ( ) ) ) ; } int pos = fieldMapping . fieldPos . get ( attrName ) ; int nullPos = fieldMapping . fieldNullPos . get ( attrName ) ; if ( nullFlags [ nullPos ] ) { return DataTypes . STRING_TYPE . nullValue ( ) ; } return strings [ pos ] ; } public void setBoolean ( String attrName , boolean val ) throws AtlasException { AttributeInfo i = fieldMapping . fields . get ( attrName ) ; if ( i == null ) { throw new AtlasException ( String . format ( ""Unknown field %s for Struct %s"" , attrName , getTypeName ( ) ) ) ; } if ( i . dataType ( ) != DataTypes . BOOLEAN_TYPE ) { throw new AtlasException ( String . format ( ""Field %s for Struct %s is not a %s, call generic set method"" , attrName , getTypeName ( ) , DataTypes . BOOLEAN_TYPE . getName ( ) ) ) ; } int pos = fieldMapping . fieldPos . get ( attrName ) ; int nullPos = fieldMapping . fieldNullPos . get ( attrName ) ; nullFlags [ nullPos ] = false ; bools [ pos ] = val ; explicitSets [ nullPos ] = true ; } public void setByte ( String attrName , byte val ) throws AtlasException { AttributeInfo i = fieldMapping . fields . get ( attrName ) ; if ( i == null ) { throw new AtlasException ( String . format ( ""Unknown field %s for Struct %s"" , attrName , getTypeName ( ) ) ) ; } if ( i . dataType ( ) != DataTypes . BYTE_TYPE ) { throw new AtlasException ( String . format ( ""Field %s for Struct %s is not a %s, call generic set method"" , attrName , getTypeName ( ) , DataTypes . BYTE_TYPE . getName ( ) ) ) ; } int pos = fieldMapping . fieldPos . get ( attrName ) ; int nullPos = fieldMapping . fieldNullPos . get ( attrName ) ; nullFlags [ nullPos ] = false ; bytes [ pos ] = val ; explicitSets [ nullPos ] = true ; } public void setShort ( String attrName , short val ) throws AtlasException { AttributeInfo i = fieldMapping . fields . get ( attrName ) ; if ( i == null ) { throw new AtlasException ( String . format ( ""Unknown field %s for Struct %s"" , attrName , getTypeName ( ) ) ) ; } if ( i . dataType ( ) != DataTypes . SHORT_TYPE ) { throw new AtlasException ( String . format ( ""Field %s for Struct %s is not a %s, call generic set method"" , attrName , getTypeName ( ) , DataTypes . SHORT_TYPE . getName ( ) ) ) ; } int pos = fieldMapping . fieldPos . get ( attrName ) ; int nullPos = fieldMapping . fieldNullPos . get ( attrName ) ; nullFlags [ nullPos ] = false ; shorts [ pos ] = val ; explicitSets [ nullPos ] = true ; } public void setInt ( String attrName , int val ) throws AtlasException { AttributeInfo i = fieldMapping . fields . get ( attrName ) ; if ( i == null ) { throw new AtlasException ( String . format ( ""Unknown field %s for Struct %s"" , attrName , getTypeName ( ) ) ) ; } if ( i . dataType ( ) != DataTypes . INT_TYPE && ! ( i . dataType ( ) instanceof EnumType ) ) { throw new AtlasException ( String . format ( ""Field %s for Struct %s is not a %s, call generic set method"" , attrName , getTypeName ( ) , DataTypes . INT_TYPE . getName ( ) ) ) ; } int pos = fieldMapping . fieldPos . get ( attrName ) ; int nullPos = fieldMapping . fieldNullPos . get ( attrName ) ; nullFlags [ nullPos ] = false ; ints [ pos ] = val ; explicitSets [ nullPos ] = true ; } public void setLong ( String attrName , long val ) throws AtlasException { AttributeInfo i = fieldMapping . fields . get ( attrName ) ; if ( i == null ) { throw new AtlasException ( String . format ( ""Unknown field %s for Struct %s"" , attrName , getTypeName ( ) ) ) ; } if ( i . dataType ( ) != DataTypes . LONG_TYPE ) { throw new AtlasException ( String . format ( ""Field %s for Struct %s is not a %s, call generic set method"" , attrName , getTypeName ( ) , DataTypes . LONG_TYPE . getName ( ) ) ) ; } int pos = fieldMapping . fieldPos . get ( attrName ) ; int nullPos = fieldMapping . fieldNullPos . get ( attrName ) ; nullFlags [ nullPos ] = false ; longs [ pos ] = val ; explicitSets [ nullPos ] = true ; } public void setFloat ( String attrName , float val ) throws AtlasException { AttributeInfo i = fieldMapping . fields . get ( attrName ) ; if ( i == null ) { throw new AtlasException ( String . format ( ""Unknown field %s for Struct %s"" , attrName , getTypeName ( ) ) ) ; } if ( i . dataType ( ) != DataTypes . FLOAT_TYPE ) { throw new AtlasException ( String . format ( ""Field %s for Struct %s is not a %s, call generic set method"" , attrName , getTypeName ( ) , DataTypes . FLOAT_TYPE . getName ( ) ) ) ; } int pos = fieldMapping . fieldPos . get ( attrName ) ; int nullPos = fieldMapping . fieldNullPos . get ( attrName ) ; nullFlags [ nullPos ] = false ; floats [ pos ] = val ; explicitSets [ nullPos ] = true ; } public void setDouble ( String attrName , double val ) throws AtlasException { AttributeInfo i = fieldMapping . fields . get ( attrName ) ; if ( i == null ) { throw new AtlasException ( String . format ( ""Unknown field %s for Struct %s"" , attrName , getTypeName ( ) ) ) ; } if ( i . dataType ( ) != DataTypes . DOUBLE_TYPE ) { throw new AtlasException ( String . format ( ""Field %s for Struct %s is not a %s, call generic set method"" , attrName , getTypeName ( ) , DataTypes . DOUBLE_TYPE . getName ( ) ) ) ; } int pos = fieldMapping . fieldPos . get ( attrName ) ; int nullPos = fieldMapping . fieldNullPos . get ( attrName ) ; nullFlags [ nullPos ] = false ; doubles [ pos ] = val ; explicitSets [ nullPos ] = true ; } public void setBigInt ( String attrName , BigInteger val ) throws AtlasException { AttributeInfo i = fieldMapping . fields . get ( attrName ) ; if ( i == null ) { throw new AtlasException ( String . format ( ""Unknown field %s for Struct %s"" , attrName , getTypeName ( ) ) ) ; } if ( i . dataType ( ) != DataTypes . BIGINTEGER_TYPE ) { throw new AtlasException ( String . format ( ""Field %s for Struct %s is not a %s, call generic set method"" , attrName , getTypeName ( ) , DataTypes . BIGINTEGER_TYPE . getName ( ) ) ) ; } int pos = fieldMapping . fieldPos . get ( attrName ) ; int nullPos = fieldMapping . fieldNullPos . get ( attrName ) ; nullFlags [ nullPos ] = val == null ; bigIntegers [ pos ] = val ; explicitSets [ nullPos ] = true ; } public void setBigDecimal ( String attrName , BigDecimal val ) throws AtlasException { AttributeInfo i = fieldMapping . fields . get ( attrName ) ; if ( i == null ) { throw new AtlasException ( String . format ( ""Unknown field %s for Struct %s"" , attrName , getTypeName ( ) ) ) ; } if ( i . dataType ( ) != DataTypes . BIGDECIMAL_TYPE ) { throw new AtlasException ( String . format ( ""Field %s for Struct %s is not a %s, call generic set method"" , attrName , getTypeName ( ) , DataTypes . BIGDECIMAL_TYPE . getName ( ) ) ) ; } int pos = fieldMapping . fieldPos . get ( attrName ) ; int nullPos = fieldMapping . fieldNullPos . get ( attrName ) ; nullFlags [ nullPos ] = val == null ; bigDecimals [ pos ] = val ; explicitSets [ nullPos ] = true ; } public void setDate ( String attrName , Date val ) throws AtlasException { AttributeInfo i = fieldMapping . fields . get ( attrName ) ; if ( i == null ) { throw new AtlasException ( String . format ( ""Unknown field %s for Struct %s"" , attrName , getTypeName ( ) ) ) ; } if ( i . dataType ( ) != DataTypes . DATE_TYPE ) { throw new AtlasException ( String . format ( ""Field %s for Struct %s is not a %s, call generic set method"" , attrName , getTypeName ( ) , DataTypes . DATE_TYPE . getName ( ) ) ) ; } int pos = fieldMapping . fieldPos . get ( attrName ) ; int nullPos = fieldMapping . fieldNullPos . get ( attrName ) ; nullFlags [ nullPos ] = val == null ; dates [ pos ] = val ; explicitSets [ nullPos ] = true ; } public void setString ( String attrName , String val ) throws AtlasException { AttributeInfo i = fieldMapping . fields . get ( attrName ) ; if ( i == null ) { throw new AtlasException ( String . format ( ""Unknown field %s for Struct %s"" , attrName , getTypeName ( ) ) ) ; } if ( i . dataType ( ) != DataTypes . STRING_TYPE ) { throw new AtlasException ( String . format ( ""Field %s for Struct %s is not a %s, call generic set method"" , attrName , getTypeName ( ) , DataTypes . STRING_TYPE . getName ( ) ) ) ; } int pos = fieldMapping . fieldPos . get ( attrName ) ; int nullPos = fieldMapping . fieldNullPos . get ( attrName ) ; nullFlags [ nullPos ] = val == null ; strings [ pos ] = val ; explicitSets [ nullPos ] = true ; } @ Override public String toString ( ) { try { StringBuilder buf = new StringBuilder ( ) ; String prefix = """" ; fieldMapping . output ( this , buf , prefix , null ) ; return buf . toString ( ) ; } catch ( AtlasException me ) { throw new RuntimeException ( me ) ; } } @ Override public String getSignatureHash ( MessageDigest digester ) throws AtlasException { StructType structType = TypeSystem . getInstance ( ) . getDataType ( StructType . class , getTypeName ( ) ) ; structType . updateSignatureHash ( digester , this ) ; byte [ ] digest = digester . digest ( ) ; return SHA256Utils . toString ( digest ) ; } @ Override public boolean isValueSet ( final String attrName ) throws AtlasException { int nullPos = fieldMapping . fieldNullPos . get ( attrName ) ; return explicitSets [ nullPos ] ; } @ Override public String toShortString ( ) { return String . format ( ""struct[type=%s]"" , dataTypeName ) ; } }",Smelly
"public abstract class RegExFacetAbstract extends MultipleValueFacetAbstract implements RegExFacet { public static Class < ? extends Facet > type ( ) { return RegExFacet . class ; } private final String validation ; private final String format ; private final boolean caseSensitive ; private final String replacement ; public RegExFacetAbstract ( final String validation , final String format , final boolean caseSensitive , final FacetHolder holder , final String replacement ) { super ( type ( ) , holder ) ; this . validation = validation ; this . format = format ; this . caseSensitive = caseSensitive ; this . replacement = replacement ; } @ Override public String validation ( ) { return validation ; } @ Override public String format ( ) { return format ; } @ Override public boolean caseSensitive ( ) { return caseSensitive ; } @ Override public String replacement ( ) { return replacement ; } @ Override public String invalidates ( final ValidityContext < ? extends ValidityEvent > context ) { if ( ! ( context instanceof ProposedHolder ) ) { return null ; } final ProposedHolder proposedHolder = ( ProposedHolder ) context ; final ObjectAdapter proposedArgument = proposedHolder . getProposed ( ) ; if ( proposedArgument == null ) { return null ; } final String titleString = proposedArgument . titleString ( ) ; if ( ! doesNotMatch ( titleString ) ) { return null ; } return replacement ( ) ; } }",No
" public final static class BytecodeSerializer implements SerializerShim < Bytecode > { @ Override public < O extends OutputShim > void write ( final KryoShim < ? , O > kryo , final O output , final Bytecode bytecode ) { writeInstructions ( kryo , output , bytecode . getSourceInstructions ( ) ) ; writeInstructions ( kryo , output , bytecode . getStepInstructions ( ) ) ; } @ Override public < I extends InputShim > Bytecode read ( final KryoShim < I , ? > kryo , final I input , final Class < Bytecode > clazz ) { final Bytecode bytecode = new Bytecode ( ) ; final int sourceInstructionCount = input . readInt ( ) ; for ( int ix = 0 ; ix < sourceInstructionCount ; ix ++ ) { final String operator = input . readString ( ) ; final Object [ ] args = operator . equals ( TraversalSource . Symbols . withoutStrategies ) ? kryo . readObject ( input , Class [ ] . class ) : kryo . readObject ( input , Object [ ] . class ) ; bytecode . addSource ( operator , args ) ; } final int stepInstructionCount = input . readInt ( ) ; for ( int ix = 0 ; ix < stepInstructionCount ; ix ++ ) { final String operator = input . readString ( ) ; final Object [ ] args = kryo . readObject ( input , Object [ ] . class ) ; bytecode . addStep ( operator , args ) ; } return bytecode ; } private static < O extends OutputShim > void writeInstructions ( final KryoShim < ? , O > kryo , final O output , final List < Bytecode . Instruction > instructions ) { output . writeInt ( instructions . size ( ) ) ; for ( Bytecode . Instruction inst : instructions ) { output . writeString ( inst . getOperator ( ) ) ; kryo . writeObject ( output , inst . getArguments ( ) ) ; } } ",No
"abstract class AbstractPersistenceManager implements PersistenceManager { protected static final Logger LOG = LoggerFactory . getLogger ( AbstractPersistenceManager . class ) ; private static final long serialVersionUID = 2065240290461241515L ; protected final AbstractService < ? > service ; AbstractPersistenceManager ( final AbstractService < ? > factory ) { this . service = factory ; } @ Override public Future < Void > flushAsync ( ) { return service . getClient ( ) . getConfiguration ( ) . getExecutor ( ) . submit ( new Callable < Void > ( ) { @ Override public Void call ( ) throws Exception { flush ( ) ; return ClassUtils . returnVoid ( ) ; } } ) ; } protected abstract void doFlush ( PersistenceChanges changes , TransactionItems items ) ; @ Override public void flush ( ) { final PersistenceChanges changes = new PersistenceChanges ( ) ; final TransactionItems items = new TransactionItems ( ) ; int pos = 0 ; final List < EntityLinkDesc > delayedUpdates = new ArrayList < EntityLinkDesc > ( ) ; for ( AttachedEntity attachedEntity : service . getContext ( ) . entityContext ( ) ) { final AttachedEntityStatus status = attachedEntity . getStatus ( ) ; if ( ( ( status != AttachedEntityStatus . ATTACHED && status != AttachedEntityStatus . LINKED ) || attachedEntity . getEntity ( ) . isChanged ( ) ) && ! items . contains ( attachedEntity . getEntity ( ) ) ) { pos ++ ; pos = processEntityContext ( attachedEntity . getEntity ( ) , pos , items , delayedUpdates , changes ) ; } } processDelayedUpdates ( delayedUpdates , pos , items , changes ) ; items . normalize ( ) ; for ( URI uri : service . getContext ( ) . entityContext ( ) . getFurtherDeletes ( ) ) { pos ++ ; queueDelete ( uri , null , changes ) ; items . put ( null , pos ) ; } if ( ! items . isEmpty ( ) ) { doFlush ( changes , items ) ; } service . getContext ( ) . detachAll ( ) ; } private ClientLink buildNavigationLink ( final String name , final URI uri , final ClientLinkType type ) { ClientLink result ; switch ( type ) { case ENTITY_NAVIGATION : result = service . getClient ( ) . getObjectFactory ( ) . newEntityNavigationLink ( name , uri ) ; break ; case ENTITY_SET_NAVIGATION : result = service . getClient ( ) . getObjectFactory ( ) . newEntitySetNavigationLink ( name , uri ) ; break ; default : throw new IllegalArgumentException ( ""Invalid link type "" + type . name ( ) ) ; } return result ; } protected int processEntityContext ( final EntityInvocationHandler handler , int pos , final TransactionItems items , final List < EntityLinkDesc > delayedUpdates , final PersistenceChanges changeset ) { int posNumber = pos ; items . put ( handler , null ) ; final ClientEntity entity = handler . getEntity ( ) ; entity . getNavigationLinks ( ) . clear ( ) ; final AttachedEntityStatus currentStatus = service . getContext ( ) . entityContext ( ) . getStatus ( handler ) ; LOG . debug ( ""Process '{}({})'"" , handler , currentStatus ) ; if ( AttachedEntityStatus . DELETED != currentStatus ) { entity . getProperties ( ) . clear ( ) ; CoreUtils . addProperties ( service . getClient ( ) , handler . getPropertyChanges ( ) , entity ) ; entity . getAnnotations ( ) . clear ( ) ; CoreUtils . addAnnotations ( service . getClient ( ) , handler . getAnnotations ( ) , entity ) ; for ( Map . Entry < String , AnnotatableInvocationHandler > entry : handler . getPropAnnotatableHandlers ( ) . entrySet ( ) ) { CoreUtils . addAnnotations ( service . getClient ( ) , entry . getValue ( ) . getAnnotations ( ) , entity . getProperty ( entry . getKey ( ) ) ) ; } } for ( Map . Entry < NavigationProperty , Object > property : handler . getLinkChanges ( ) . entrySet ( ) ) { final ClientLinkType type = Collection . class . isAssignableFrom ( property . getValue ( ) . getClass ( ) ) ? ClientLinkType . ENTITY_SET_NAVIGATION : ClientLinkType . ENTITY_NAVIGATION ; final Set < EntityInvocationHandler > toBeLinked = new HashSet < EntityInvocationHandler > ( ) ; for ( Object proxy : type == ClientLinkType . ENTITY_SET_NAVIGATION ? ( Collection < ? > ) property . getValue ( ) : Collections . singleton ( property . getValue ( ) ) ) { final EntityInvocationHandler target = ( EntityInvocationHandler ) Proxy . getInvocationHandler ( proxy ) ; final AttachedEntityStatus status ; if ( ! service . getContext ( ) . entityContext ( ) . isAttached ( target ) ) { status = resolveNavigationLink ( property . getKey ( ) , target ) ; } else { status = service . getContext ( ) . entityContext ( ) . getStatus ( target ) ; } LOG . debug ( ""Found link to '{}({})'"" , target , status ) ; final URI editLink = target . getEntity ( ) . getEditLink ( ) ; if ( ( status == AttachedEntityStatus . ATTACHED || status == AttachedEntityStatus . LINKED ) && ! target . isChanged ( ) ) { LOG . debug ( ""Add link to '{}'"" , target ) ; entity . addLink ( buildNavigationLink ( property . getKey ( ) . name ( ) , URIUtils . getURI ( service . getClient ( ) . getServiceRoot ( ) , editLink . toASCIIString ( ) ) , type ) ) ; } else { if ( ! items . contains ( target ) ) { posNumber = processEntityContext ( target , posNumber , items , delayedUpdates , changeset ) ; posNumber ++ ; } final Integer targetPos = items . get ( target ) ; if ( targetPos == null ) { LOG . debug ( ""Schedule '{}' from '{}' to '{}'"" , type . name ( ) , handler , target ) ; toBeLinked . add ( target ) ; } else if ( status == AttachedEntityStatus . CHANGED ) { LOG . debug ( ""Changed: '{}' from '{}' to (${}) '{}'"" , type . name ( ) , handler , targetPos , target ) ; entity . addLink ( buildNavigationLink ( property . getKey ( ) . name ( ) , URIUtils . getURI ( service . getClient ( ) . getServiceRoot ( ) , editLink . toASCIIString ( ) ) , type ) ) ; } else { LOG . debug ( ""'{}' from '{}' to (${}) '{}'"" , type . name ( ) , handler , targetPos , target ) ; entity . addLink ( buildNavigationLink ( property . getKey ( ) . name ( ) , URI . create ( ""$"" + targetPos ) , type ) ) ; } } } if ( ! toBeLinked . isEmpty ( ) ) { delayedUpdates . add ( new EntityLinkDesc ( property . getKey ( ) . name ( ) , handler , toBeLinked , type ) ) ; } if ( property . getValue ( ) instanceof Proxy ) { final InvocationHandler target = Proxy . getInvocationHandler ( property . getValue ( ) ) ; if ( target instanceof EntityCollectionInvocationHandler ) { for ( String ref : ( ( EntityCollectionInvocationHandler < ? > ) target ) . referenceItems ) { delayedUpdates . add ( new EntityLinkDesc ( property . getKey ( ) . name ( ) , handler , ref ) ) ; } } } } for ( Map . Entry < String , AnnotatableInvocationHandler > entry : handler . getNavPropAnnotatableHandlers ( ) . entrySet ( ) ) { CoreUtils . addAnnotations ( service . getClient ( ) , entry . getValue ( ) . getAnnotations ( ) , entity . getNavigationLink ( entry . getKey ( ) ) ) ; } final AttachedEntityStatus processedStatus = queue ( handler , entity , changeset ) ; if ( processedStatus != null ) { LOG . debug ( ""{}: Insert '{}' into the process queue"" , posNumber , handler ) ; items . put ( handler , posNumber ) ; } else { posNumber -- ; } if ( processedStatus != AttachedEntityStatus . DELETED ) { int startingPos = posNumber ; if ( handler . getEntity ( ) . isMediaEntity ( ) && handler . isChanged ( ) ) { if ( ! handler . getPropertyChanges ( ) . isEmpty ( ) ) { final URI targetURI = currentStatus == AttachedEntityStatus . NEW ? URI . create ( ""$"" + startingPos ) : URIUtils . getURI ( service . getClient ( ) . getServiceRoot ( ) , handler . getEntity ( ) . getEditLink ( ) . toASCIIString ( ) ) ; queueUpdate ( handler , targetURI , entity , changeset ) ; posNumber ++ ; items . put ( handler , posNumber ) ; LOG . debug ( ""{}: Update media properties for '{}' into the process queue"" , posNumber , handler ) ; } if ( handler . getStreamChanges ( ) != null ) { final URI targetURI = currentStatus == AttachedEntityStatus . NEW ? URI . create ( ""$"" + startingPos + ""/$value"" ) : URIUtils . getURI ( service . getClient ( ) . getServiceRoot ( ) , handler . getEntity ( ) . getEditLink ( ) . toASCIIString ( ) + ""/$value"" ) ; queueUpdateMediaEntity ( handler , targetURI , handler . getStreamChanges ( ) , changeset ) ; posNumber ++ ; items . put ( null , posNumber ) ; LOG . debug ( ""{}: Update media info for '{}' into the process queue"" , posNumber , handler ) ; } } for ( Map . Entry < String , EdmStreamValue > streamedChanges : handler . getStreamedPropertyChanges ( ) . entrySet ( ) ) { final URI targetURI = currentStatus == AttachedEntityStatus . NEW ? URI . create ( ""$"" + startingPos ) : URIUtils . getURI ( service . getClient ( ) . getServiceRoot ( ) , CoreUtils . getMediaEditLink ( streamedChanges . getKey ( ) , entity ) . toASCIIString ( ) ) ; queueUpdateMediaResource ( handler , targetURI , streamedChanges . getValue ( ) , changeset ) ; posNumber ++ ; items . put ( handler , posNumber ) ; LOG . debug ( ""{}: Update media info (null key) for '{}' into the process queue"" , posNumber , handler ) ; } } return posNumber ; } protected void processDelayedUpdates ( final List < EntityLinkDesc > delayedUpdates , int pos , final TransactionItems items , final PersistenceChanges changeset ) { int posNumber = pos ; for ( EntityLinkDesc delayedUpdate : delayedUpdates ) { if ( StringUtils . isBlank ( delayedUpdate . getReference ( ) ) ) { posNumber ++ ; items . put ( delayedUpdate . getSource ( ) , posNumber ) ; final ClientEntity changes = service . getClient ( ) . getObjectFactory ( ) . newEntity ( delayedUpdate . getSource ( ) . getEntity ( ) . getTypeName ( ) ) ; AttachedEntityStatus status = service . getContext ( ) . entityContext ( ) . getStatus ( delayedUpdate . getSource ( ) ) ; final URI sourceURI ; if ( status == AttachedEntityStatus . CHANGED ) { sourceURI = URIUtils . getURI ( service . getClient ( ) . getServiceRoot ( ) , delayedUpdate . getSource ( ) . getEntity ( ) . getEditLink ( ) . toASCIIString ( ) ) ; } else { int sourcePos = items . get ( delayedUpdate . getSource ( ) ) ; sourceURI = URI . create ( ""$"" + sourcePos ) ; } for ( EntityInvocationHandler target : delayedUpdate . getTargets ( ) ) { status = service . getContext ( ) . entityContext ( ) . getStatus ( target ) ; final URI targetURI ; if ( status == AttachedEntityStatus . CHANGED ) { targetURI = URIUtils . getURI ( service . getClient ( ) . getServiceRoot ( ) , target . getEntity ( ) . getEditLink ( ) . toASCIIString ( ) ) ; } else { int targetPos = items . get ( target ) ; targetURI = URI . create ( ""$"" + targetPos ) ; } changes . addLink ( delayedUpdate . getType ( ) == ClientLinkType . ENTITY_NAVIGATION ? service . getClient ( ) . getObjectFactory ( ) . newEntityNavigationLink ( delayedUpdate . getSourceName ( ) , targetURI ) : service . getClient ( ) . getObjectFactory ( ) . newEntitySetNavigationLink ( delayedUpdate . getSourceName ( ) , targetURI ) ) ; LOG . debug ( ""'{}' from {} to {}"" , delayedUpdate . getType ( ) . name ( ) , sourceURI , targetURI ) ; } queueUpdate ( delayedUpdate . getSource ( ) , sourceURI , changes , changeset ) ; } else { URI sourceURI = URIUtils . getURI ( service . getClient ( ) . getServiceRoot ( ) , delayedUpdate . getSource ( ) . getEntity ( ) . getEditLink ( ) . toASCIIString ( ) + ""/"" + delayedUpdate . getSourceName ( ) + ""/$ref"" ) ; if ( queueUpdateLinkViaRef ( delayedUpdate . getSource ( ) , sourceURI , URI . create ( delayedUpdate . getReference ( ) ) , changeset ) ) { posNumber ++ ; items . put ( delayedUpdate . getSource ( ) , posNumber ) ; } } } } private AttachedEntityStatus queue ( final EntityInvocationHandler handler , final ClientEntity entity , final PersistenceChanges changeset ) { switch ( service . getContext ( ) . entityContext ( ) . getStatus ( handler ) ) { case NEW : queueCreate ( handler , entity , changeset ) ; return AttachedEntityStatus . NEW ; case DELETED : queueDelete ( handler , entity , changeset ) ; return AttachedEntityStatus . DELETED ; default : if ( handler . isChanged ( false ) ) { queueUpdate ( handler , entity , changeset ) ; return AttachedEntityStatus . CHANGED ; } else { return null ; } } } private void queueCreate ( final EntityInvocationHandler handler , final ClientEntity entity , final PersistenceChanges changeset ) { LOG . debug ( ""Create '{}'"" , handler ) ; changeset . addChange ( service . getClient ( ) . getCUDRequestFactory ( ) . getEntityCreateRequest ( handler . getEntitySetURI ( ) , entity ) , handler ) ; } private void queueUpdateMediaEntity ( final EntityInvocationHandler handler , final URI uri , final EdmStreamValue input , final PersistenceChanges changeset ) { LOG . debug ( ""Update media entity '{}'"" , uri ) ; final ODataMediaEntityUpdateRequest < ? > req = service . getClient ( ) . getCUDRequestFactory ( ) . getMediaEntityUpdateRequest ( uri , input . getStream ( ) ) ; if ( StringUtils . isNotBlank ( input . getContentType ( ) ) ) { req . setContentType ( input . getContentType ( ) ) ; } if ( StringUtils . isNotBlank ( handler . getETag ( ) ) ) { req . setIfMatch ( handler . getETag ( ) ) ; } changeset . addChange ( req , handler ) ; } private void queueUpdateMediaResource ( final EntityInvocationHandler handler , final URI uri , final EdmStreamValue input , final PersistenceChanges changeset ) { LOG . debug ( ""Update media entity '{}'"" , uri ) ; final ODataStreamUpdateRequest req = service . getClient ( ) . getCUDRequestFactory ( ) . getStreamUpdateRequest ( uri , input . getStream ( ) ) ; if ( StringUtils . isNotBlank ( input . getContentType ( ) ) ) { req . setContentType ( input . getContentType ( ) ) ; } if ( StringUtils . isNotBlank ( handler . getETag ( ) ) ) { req . setIfMatch ( handler . getETag ( ) ) ; } changeset . addChange ( req , handler ) ; } private void queueUpdate ( final EntityInvocationHandler handler , final ClientEntity changes , final PersistenceChanges changeset ) { LOG . debug ( ""Update '{}'"" , handler . getEntityURI ( ) ) ; final ODataEntityUpdateRequest < ClientEntity > req = ( ( EdmEnabledODataClient ) service . getClient ( ) ) . getCUDRequestFactory ( ) . getEntityUpdateRequest ( handler . getEntityURI ( ) , org . apache . olingo . client . api . communication . request . cud . UpdateType . PATCH , changes ) ; req . setPrefer ( new ODataPreferences ( ) . returnContent ( ) ) ; if ( StringUtils . isNotBlank ( handler . getETag ( ) ) ) { req . setIfMatch ( handler . getETag ( ) ) ; } changeset . addChange ( req , handler ) ; } private boolean queueUpdateLinkViaRef ( final EntityInvocationHandler handler , final URI source , final URI targetRef , final PersistenceChanges changeset ) { LOG . debug ( ""Update '{}'"" , targetRef ) ; URI sericeRoot = handler . getClient ( ) . newURIBuilder ( handler . getClient ( ) . getServiceRoot ( ) ) . build ( ) ; final ODataReferenceAddingRequest req = ( ( org . apache . olingo . client . api . EdmEnabledODataClient ) service . getClient ( ) ) . getCUDRequestFactory ( ) . getReferenceAddingRequest ( sericeRoot , source , targetRef ) ; req . setPrefer ( new ODataPreferences ( ) . returnContent ( ) ) ; if ( StringUtils . isNotBlank ( handler . getETag ( ) ) ) { req . setIfMatch ( handler . getETag ( ) ) ; } changeset . addChange ( req , handler ) ; return true ; } private void queueUpdate ( final EntityInvocationHandler handler , final URI uri , final ClientEntity changes , final PersistenceChanges changeset ) { LOG . debug ( ""Update '{}'"" , uri ) ; final ODataEntityUpdateRequest < ClientEntity > req = ( ( EdmEnabledODataClient ) service . getClient ( ) ) . getCUDRequestFactory ( ) . getEntityUpdateRequest ( uri , org . apache . olingo . client . api . communication . request . cud . UpdateType . PATCH , changes ) ; req . setPrefer ( new ODataPreferences ( ) . returnContent ( ) ) ; if ( StringUtils . isNotBlank ( handler . getETag ( ) ) ) { req . setIfMatch ( handler . getETag ( ) ) ; } changeset . addChange ( req , handler ) ; } private void queueDelete ( final EntityInvocationHandler handler , final ClientEntity entity , final PersistenceChanges changeset ) { final URI deleteURI = entity . getEditLink ( ) == null ? handler . getEntityURI ( ) : entity . getEditLink ( ) ; changeset . addChange ( buildDeleteRequest ( deleteURI , handler . getETag ( ) ) , handler ) ; } private void queueDelete ( final URI deleteURI , final String etag , final PersistenceChanges changeset ) { changeset . addChange ( buildDeleteRequest ( deleteURI , etag ) , null ) ; } private ODataDeleteRequest buildDeleteRequest ( final URI deleteURI , final String etag ) { LOG . debug ( ""Delete '{}'"" , deleteURI ) ; final ODataDeleteRequest req = service . getClient ( ) . getCUDRequestFactory ( ) . getDeleteRequest ( deleteURI ) ; if ( StringUtils . isNotBlank ( etag ) ) { req . setIfMatch ( etag ) ; } return req ; } private AttachedEntityStatus resolveNavigationLink ( final NavigationProperty property , final EntityInvocationHandler handler ) { if ( handler . getUUID ( ) . getEntitySetURI ( ) == null ) { CoreUtils . getKey ( service . getClient ( ) , handler , handler . getTypeRef ( ) , handler . getEntity ( ) ) ; handler . updateUUID ( CoreUtils . getTargetEntitySetURI ( service . getClient ( ) , property ) , handler . getTypeRef ( ) , null ) ; service . getContext ( ) . entityContext ( ) . attach ( handler , AttachedEntityStatus . NEW ) ; return AttachedEntityStatus . NEW ; } else { service . getContext ( ) . entityContext ( ) . attach ( handler , AttachedEntityStatus . LINKED ) ; return AttachedEntityStatus . LINKED ; } } }",Smelly
"public class TicketGrantingEncryptionTypeTest extends AbstractTicketGrantingServiceTest { private KerberosConfig config ; private KdcServer kdcServer ; private PrincipalStore store ; private KerberosProtocolHandler handler ; private KrbDummySession session ; @ Before public void setUp ( ) { kdcServer = new KdcServer ( ) ; config = kdcServer . getConfig ( ) ; config . setBodyChecksumVerified ( false ) ; store = new MapPrincipalStoreImpl ( ) ; handler = new KerberosProtocolHandler ( kdcServer , store ) ; session = new KrbDummySession ( ) ; lockBox = new CipherTextHandler ( ) ; } @ After public void shutDown ( ) { kdcServer . stop ( ) ; } @ Test @ Ignore ( ""uses DES but the encryption key is generated in AbstractAuthenticationServiceTest always uses AES"" ) public void testRequestDesCbcMd5 ( ) throws Exception { KerberosPrincipal clientPrincipal = new KerberosPrincipal ( ""hnelson@EXAMPLE.COM"" ) ; EncTicketPart encTicketPart = getTicketArchetype ( clientPrincipal ) ; KerberosPrincipal serverPrincipal = new KerberosPrincipal ( ""krbtgt/EXAMPLE.COM@EXAMPLE.COM"" ) ; String passPhrase = ""randomKey"" ; EncryptionKey serverKey = getEncryptionKey ( serverPrincipal , passPhrase ) ; Ticket tgt = getTicket ( encTicketPart , serverPrincipal , serverKey ) ; KdcReqBody kdcReqBody = new KdcReqBody ( ) ; kdcReqBody . setSName ( new PrincipalName ( new KerberosPrincipal ( ""ldap/ldap.example.com@EXAMPLE.COM"" ) ) ) ; kdcReqBody . setRealm ( ""EXAMPLE.COM"" ) ; Set < EncryptionType > encryptionTypes = new HashSet < EncryptionType > ( ) ; encryptionTypes . add ( EncryptionType . DES_CBC_MD5 ) ; kdcReqBody . setEType ( encryptionTypes ) ; kdcReqBody . setNonce ( random . nextInt ( ) ) ; KdcOptions kdcOptions = new KdcOptions ( ) ; kdcReqBody . setKdcOptions ( kdcOptions ) ; long now = System . currentTimeMillis ( ) ; KerberosTime requestedEndTime = new KerberosTime ( now + 1 * KerberosTime . DAY ) ; kdcReqBody . setTill ( requestedEndTime ) ; KdcReq message = getKdcRequest ( tgt , kdcReqBody ) ; handler . messageReceived ( session , message ) ; Object msg = session . getMessage ( ) ; assertEquals ( ""session.getMessage() instanceOf"" , TgsRep . class , msg . getClass ( ) ) ; TgsRep reply = ( TgsRep ) msg ; assertEquals ( ""Encryption type"" , EncryptionType . DES_CBC_MD5 , reply . getEncPart ( ) . getEType ( ) ) ; } @ Test public void testRequestAes128 ( ) throws Exception { EncryptionType [ ] configuredEncryptionTypes = { EncryptionType . AES128_CTS_HMAC_SHA1_96 } ; config . setEncryptionTypes ( configuredEncryptionTypes ) ; KerberosPrincipal clientPrincipal = new KerberosPrincipal ( ""hnelson@EXAMPLE.COM"" ) ; EncTicketPart encTicketPart = getTicketArchetype ( clientPrincipal ) ; KerberosPrincipal serverPrincipal = new KerberosPrincipal ( ""krbtgt/EXAMPLE.COM@EXAMPLE.COM"" ) ; String passPhrase = ""randomKey"" ; EncryptionKey serverKey = getEncryptionKey ( serverPrincipal , passPhrase ) ; Ticket tgt = getTicket ( encTicketPart , serverPrincipal , serverKey ) ; KdcReqBody kdcReqBody = new KdcReqBody ( ) ; kdcReqBody . setSName ( getPrincipalName ( ""ldap/ldap.example.com@EXAMPLE.COM"" ) ) ; kdcReqBody . setRealm ( ""EXAMPLE.COM"" ) ; Set < EncryptionType > encryptionTypes = new HashSet < EncryptionType > ( ) ; encryptionTypes . add ( EncryptionType . AES128_CTS_HMAC_SHA1_96 ) ; kdcReqBody . setEType ( encryptionTypes ) ; kdcReqBody . setNonce ( random . nextInt ( ) ) ; KdcOptions kdcOptions = new KdcOptions ( ) ; kdcReqBody . setKdcOptions ( kdcOptions ) ; long now = System . currentTimeMillis ( ) ; KerberosTime requestedEndTime = new KerberosTime ( now + 1 * KerberosTime . DAY ) ; kdcReqBody . setTill ( requestedEndTime ) ; KdcReq message = getKdcRequest ( tgt , kdcReqBody ) ; handler . messageReceived ( session , message ) ; Object msg = session . getMessage ( ) ; assertEquals ( ""session.getMessage() instanceOf"" , TgsRep . class , msg . getClass ( ) ) ; TgsRep reply = ( TgsRep ) msg ; assertEquals ( ""Encryption type"" , EncryptionType . AES128_CTS_HMAC_SHA1_96 , reply . getEncPart ( ) . getEType ( ) ) ; assertEquals ( ""Encryption type"" , EncryptionType . AES128_CTS_HMAC_SHA1_96 , reply . getTicket ( ) . getEncPart ( ) . getEType ( ) ) ; } @ Test public void testRequestAes128TgtAndRequested ( ) throws Exception { EncryptionType [ ] configuredEncryptionTypes = { EncryptionType . AES128_CTS_HMAC_SHA1_96 } ; config . setEncryptionTypes ( configuredEncryptionTypes ) ; KerberosPrincipal clientPrincipal = new KerberosPrincipal ( ""hnelson@EXAMPLE.COM"" ) ; EncTicketPart encTicketPart = getTicketArchetype ( clientPrincipal ) ; sessionKey = RandomKeyFactory . getRandomKey ( EncryptionType . AES128_CTS_HMAC_SHA1_96 ) ; encTicketPart . setKey ( sessionKey ) ; String principalName = ""krbtgt/EXAMPLE.COM@EXAMPLE.COM"" ; KerberosPrincipal serverPrincipal = new KerberosPrincipal ( principalName ) ; String passPhrase = ""randomKey"" ; Set < EncryptionType > preAuthEncryptionTypes = new HashSet < EncryptionType > ( ) ; preAuthEncryptionTypes . add ( EncryptionType . AES128_CTS_HMAC_SHA1_96 ) ; Map < EncryptionType , EncryptionKey > keyMap = KerberosKeyFactory . getKerberosKeys ( principalName , passPhrase , preAuthEncryptionTypes ) ; EncryptionKey serverKey = keyMap . get ( EncryptionType . AES128_CTS_HMAC_SHA1_96 ) ; Ticket tgt = getTicket ( encTicketPart , serverPrincipal , serverKey ) ; KdcReqBody kdcReqBody = new KdcReqBody ( ) ; kdcReqBody . setSName ( getPrincipalName ( ""ldap/ldap.example.com@EXAMPLE.COM"" ) ) ; kdcReqBody . setRealm ( ""EXAMPLE.COM"" ) ; Set < EncryptionType > encryptionTypes = new HashSet < EncryptionType > ( ) ; encryptionTypes . add ( EncryptionType . AES128_CTS_HMAC_SHA1_96 ) ; kdcReqBody . setEType ( encryptionTypes ) ; kdcReqBody . setNonce ( random . nextInt ( ) ) ; KdcOptions kdcOptions = new KdcOptions ( ) ; kdcReqBody . setKdcOptions ( kdcOptions ) ; long now = System . currentTimeMillis ( ) ; KerberosTime requestedEndTime = new KerberosTime ( now + 1 * KerberosTime . DAY ) ; kdcReqBody . setTill ( requestedEndTime ) ; KdcReq message = getKdcRequest ( tgt , kdcReqBody ) ; handler . messageReceived ( session , message ) ; Object msg = session . getMessage ( ) ; assertEquals ( ""session.getMessage() instanceOf"" , TgsRep . class , msg . getClass ( ) ) ; TgsRep reply = ( TgsRep ) msg ; assertEquals ( ""Encryption type"" , EncryptionType . AES128_CTS_HMAC_SHA1_96 , reply . getEncPart ( ) . getEType ( ) ) ; assertEquals ( ""Encryption type"" , EncryptionType . AES128_CTS_HMAC_SHA1_96 , reply . getTicket ( ) . getEncPart ( ) . getEType ( ) ) ; } @ Test public void testNonce ( ) throws Exception { EncryptionType [ ] configuredEncryptionTypes = { EncryptionType . AES128_CTS_HMAC_SHA1_96 } ; config . setEncryptionTypes ( configuredEncryptionTypes ) ; KerberosPrincipal clientPrincipal = new KerberosPrincipal ( ""hnelson@EXAMPLE.COM"" ) ; EncTicketPart encTicketPart = getTicketArchetype ( clientPrincipal ) ; sessionKey = RandomKeyFactory . getRandomKey ( EncryptionType . AES128_CTS_HMAC_SHA1_96 ) ; encTicketPart . setKey ( sessionKey ) ; String principalName = ""krbtgt/EXAMPLE.COM@EXAMPLE.COM"" ; KerberosPrincipal serverPrincipal = new KerberosPrincipal ( principalName ) ; String passPhrase = ""randomKey"" ; Set < EncryptionType > preAuthEncryptionTypes = new HashSet < EncryptionType > ( ) ; preAuthEncryptionTypes . add ( EncryptionType . AES128_CTS_HMAC_SHA1_96 ) ; Map < EncryptionType , EncryptionKey > keyMap = KerberosKeyFactory . getKerberosKeys ( principalName , passPhrase , preAuthEncryptionTypes ) ; EncryptionKey serverKey = keyMap . get ( EncryptionType . AES128_CTS_HMAC_SHA1_96 ) ; Ticket tgt = getTicket ( encTicketPart , serverPrincipal , serverKey ) ; KdcReqBody kdcReqBody = new KdcReqBody ( ) ; kdcReqBody . setSName ( getPrincipalName ( ""ldap/ldap.example.com@EXAMPLE.COM"" ) ) ; kdcReqBody . setRealm ( ""EXAMPLE.COM"" ) ; Set < EncryptionType > encryptionTypes = new HashSet < EncryptionType > ( ) ; encryptionTypes . add ( EncryptionType . AES128_CTS_HMAC_SHA1_96 ) ; kdcReqBody . setEType ( encryptionTypes ) ; int nonce = random . nextInt ( ) ; kdcReqBody . setNonce ( nonce ) ; KdcOptions kdcOptions = new KdcOptions ( ) ; kdcReqBody . setKdcOptions ( kdcOptions ) ; long now = System . currentTimeMillis ( ) ; KerberosTime requestedEndTime = new KerberosTime ( now + 1 * KerberosTime . DAY ) ; kdcReqBody . setTill ( requestedEndTime ) ; KdcReq message = getKdcRequest ( tgt , kdcReqBody ) ; handler . messageReceived ( session , message ) ; Object msg = session . getMessage ( ) ; assertEquals ( ""session.getMessage() instanceOf"" , TgsRep . class , msg . getClass ( ) ) ; TgsRep reply = ( TgsRep ) msg ; assertEquals ( ""Encryption type"" , EncryptionType . AES128_CTS_HMAC_SHA1_96 , reply . getEncPart ( ) . getEType ( ) ) ; assertEquals ( ""Encryption type"" , EncryptionType . AES128_CTS_HMAC_SHA1_96 , reply . getTicket ( ) . getEncPart ( ) . getEType ( ) ) ; assertEquals ( ""Nonce"" , nonce , reply . getNonce ( ) ) ; } @ Test public void testDecryptWithSessionKey ( ) throws Exception { EncryptionType [ ] configuredEncryptionTypes = { EncryptionType . AES128_CTS_HMAC_SHA1_96 } ; config . setEncryptionTypes ( configuredEncryptionTypes ) ; KerberosPrincipal clientPrincipal = new KerberosPrincipal ( ""hnelson@EXAMPLE.COM"" ) ; EncTicketPart encTicketPart = getTicketArchetype ( clientPrincipal ) ; sessionKey = RandomKeyFactory . getRandomKey ( EncryptionType . AES128_CTS_HMAC_SHA1_96 ) ; encTicketPart . setKey ( sessionKey ) ; String principalName = ""krbtgt/EXAMPLE.COM@EXAMPLE.COM"" ; KerberosPrincipal serverPrincipal = new KerberosPrincipal ( principalName ) ; String passPhrase = ""randomKey"" ; Set < EncryptionType > preAuthEncryptionTypes = new HashSet < EncryptionType > ( ) ; preAuthEncryptionTypes . add ( EncryptionType . AES128_CTS_HMAC_SHA1_96 ) ; Map < EncryptionType , EncryptionKey > keyMap = KerberosKeyFactory . getKerberosKeys ( principalName , passPhrase , preAuthEncryptionTypes ) ; EncryptionKey serverKey = keyMap . get ( EncryptionType . AES128_CTS_HMAC_SHA1_96 ) ; Ticket tgt = getTicket ( encTicketPart , serverPrincipal , serverKey ) ; KdcReqBody kdcReqBody = new KdcReqBody ( ) ; kdcReqBody . setSName ( getPrincipalName ( ""ldap/ldap.example.com@EXAMPLE.COM"" ) ) ; kdcReqBody . setRealm ( ""EXAMPLE.COM"" ) ; Set < EncryptionType > encryptionTypes = new HashSet < EncryptionType > ( ) ; encryptionTypes . add ( EncryptionType . AES128_CTS_HMAC_SHA1_96 ) ; kdcReqBody . setEType ( encryptionTypes ) ; kdcReqBody . setNonce ( random . nextInt ( ) ) ; KdcOptions kdcOptions = new KdcOptions ( ) ; kdcReqBody . setKdcOptions ( kdcOptions ) ; long now = System . currentTimeMillis ( ) ; KerberosTime requestedEndTime = new KerberosTime ( now + 1 * KerberosTime . DAY ) ; kdcReqBody . setTill ( requestedEndTime ) ; KdcReq message = getKdcRequest ( tgt , kdcReqBody ) ; handler . messageReceived ( session , message ) ; Object msg = session . getMessage ( ) ; assertEquals ( ""session.getMessage() instanceOf"" , TgsRep . class , msg . getClass ( ) ) ; TgsRep reply = ( TgsRep ) msg ; assertEquals ( ""Encryption type"" , EncryptionType . AES128_CTS_HMAC_SHA1_96 , reply . getEncPart ( ) . getEType ( ) ) ; assertEquals ( ""Encryption type"" , EncryptionType . AES128_CTS_HMAC_SHA1_96 , reply . getTicket ( ) . getEncPart ( ) . getEType ( ) ) ; } @ Test public void testDecryptWithSubSessionKey ( ) throws Exception { EncryptionType [ ] configuredEncryptionTypes = { EncryptionType . AES128_CTS_HMAC_SHA1_96 } ; config . setEncryptionTypes ( configuredEncryptionTypes ) ; KerberosPrincipal clientPrincipal = new KerberosPrincipal ( ""hnelson@EXAMPLE.COM"" ) ; EncTicketPart encTicketPart = getTicketArchetype ( clientPrincipal ) ; sessionKey = RandomKeyFactory . getRandomKey ( EncryptionType . AES128_CTS_HMAC_SHA1_96 ) ; encTicketPart . setKey ( sessionKey ) ; String principalName = ""krbtgt/EXAMPLE.COM@EXAMPLE.COM"" ; KerberosPrincipal serverPrincipal = new KerberosPrincipal ( principalName ) ; String passPhrase = ""randomKey"" ; Set < EncryptionType > preAuthEncryptionTypes = new HashSet < EncryptionType > ( ) ; preAuthEncryptionTypes . add ( EncryptionType . AES128_CTS_HMAC_SHA1_96 ) ; Map < EncryptionType , EncryptionKey > keyMap = KerberosKeyFactory . getKerberosKeys ( principalName , passPhrase , preAuthEncryptionTypes ) ; EncryptionKey serverKey = keyMap . get ( EncryptionType . AES128_CTS_HMAC_SHA1_96 ) ; Ticket tgt = getTicket ( encTicketPart , serverPrincipal , serverKey ) ; KdcReqBody kdcReqBody = new KdcReqBody ( ) ; kdcReqBody . setSName ( getPrincipalName ( ""ldap/ldap.example.com@EXAMPLE.COM"" ) ) ; kdcReqBody . setRealm ( ""EXAMPLE.COM"" ) ; Set < EncryptionType > encryptionTypes = new HashSet < EncryptionType > ( ) ; encryptionTypes . add ( EncryptionType . AES128_CTS_HMAC_SHA1_96 ) ; kdcReqBody . setEType ( encryptionTypes ) ; kdcReqBody . setNonce ( random . nextInt ( ) ) ; KdcOptions kdcOptions = new KdcOptions ( ) ; kdcReqBody . setKdcOptions ( kdcOptions ) ; long now = System . currentTimeMillis ( ) ; KerberosTime requestedEndTime = new KerberosTime ( now + 1 * KerberosTime . DAY ) ; kdcReqBody . setTill ( requestedEndTime ) ; subSessionKey = RandomKeyFactory . getRandomKey ( EncryptionType . DES_CBC_MD5 ) ; KdcReq message = getKdcRequest ( tgt , kdcReqBody ) ; handler . messageReceived ( session , message ) ; Object msg = session . getMessage ( ) ; assertEquals ( ""session.getMessage() instanceOf"" , TgsRep . class , msg . getClass ( ) ) ; TgsRep reply = ( TgsRep ) msg ; assertEquals ( ""Encryption type"" , EncryptionType . DES_CBC_MD5 , reply . getEncPart ( ) . getEType ( ) ) ; assertEquals ( ""Encryption type"" , EncryptionType . AES128_CTS_HMAC_SHA1_96 , reply . getTicket ( ) . getEncPart ( ) . getEType ( ) ) ; } }",Smelly
"@ InterfaceAudience . Private class FSWALEntry extends Entry { private final transient long txid ; private final transient boolean inMemstore ; private final transient boolean closeRegion ; private final transient RegionInfo regionInfo ; private final transient Set < byte [ ] > familyNames ; private final transient ServerCall < ? > rpcCall ; FSWALEntry ( final long txid , final WALKeyImpl key , final WALEdit edit , final RegionInfo regionInfo , final boolean inMemstore , ServerCall < ? > rpcCall ) { super ( key , edit ) ; this . inMemstore = inMemstore ; this . closeRegion = ! inMemstore && edit . isRegionCloseMarker ( ) ; this . regionInfo = regionInfo ; this . txid = txid ; if ( inMemstore ) { Set < byte [ ] > families = edit . getFamilies ( ) ; this . familyNames = families != null ? families : collectFamilies ( edit . getCells ( ) ) ; } else { this . familyNames = Collections . emptySet ( ) ; } this . rpcCall = rpcCall ; if ( rpcCall != null ) { rpcCall . retainByWAL ( ) ; } } @ VisibleForTesting static Set < byte [ ] > collectFamilies ( List < Cell > cells ) { if ( CollectionUtils . isEmpty ( cells ) ) { return Collections . emptySet ( ) ; } else { Set < byte [ ] > set = new TreeSet < > ( Bytes . BYTES_COMPARATOR ) ; for ( Cell cell : cells ) { if ( ! WALEdit . isMetaEditFamily ( cell ) ) { set . add ( CellUtil . cloneFamily ( cell ) ) ; } } return set ; } } @ Override public String toString ( ) { return ""sequence="" + this . txid + "", "" + super . toString ( ) ; } boolean isInMemStore ( ) { return this . inMemstore ; } boolean isCloseRegion ( ) { return closeRegion ; } RegionInfo getRegionInfo ( ) { return this . regionInfo ; } long getTxid ( ) { return this . txid ; } long stampRegionSequenceId ( MultiVersionConcurrencyControl . WriteEntry we ) throws IOException { long regionSequenceId = we . getWriteNumber ( ) ; if ( ! this . getEdit ( ) . isReplay ( ) && inMemstore ) { for ( Cell c : getEdit ( ) . getCells ( ) ) { PrivateCellUtil . setSequenceId ( c , regionSequenceId ) ; } } getKey ( ) . setWriteEntry ( we ) ; return regionSequenceId ; } Set < byte [ ] > getFamilyNames ( ) { return familyNames ; } void release ( ) { if ( rpcCall != null ) { rpcCall . releaseByWAL ( ) ; } } }",No
"public class ConfigImpl implements Config { private String resource ; private Map < String , ConfigObject > properties ; private List < Config > configs ; protected ConfigImpl ( String resource ) { this . resource = resource ; this . properties = new HashMap < String , ConfigObject > ( ) ; this . configs = new ArrayList < Config > ( 0 ) ; } protected void reset ( ) { this . properties . clear ( ) ; this . configs . clear ( ) ; } @ Override public String getResource ( ) { return resource ; } @ Override public Set < String > getNames ( ) { Set < String > propNames = new HashSet < String > ( properties . keySet ( ) ) ; for ( Config config : configs ) { propNames . addAll ( config . getNames ( ) ) ; } return propNames ; } @ Override public String getString ( String name ) { String result = null ; ConfigObject co = properties . get ( name ) ; if ( co != null ) { result = co . getPropertyValue ( ) ; } else { for ( Config config : configs ) { result = config . getString ( name ) ; if ( result != null ) { break ; } } } return result ; } @ Override public String getString ( ConfigKey name , boolean useDefault ) { if ( useDefault ) { return getString ( name . getPropertyKey ( ) , ( String ) name . getDefaultValue ( ) ) ; } return getString ( name . getPropertyKey ( ) ) ; } @ Override public String getString ( String name , String defaultValue ) { String result = getString ( name ) ; if ( result == null ) { result = defaultValue ; } return result ; } @ Override public String getTrimmed ( String name ) { String result = getString ( name ) ; if ( null != result ) { result = result . trim ( ) ; } return result ; } @ Override public String getTrimmed ( ConfigKey name ) { return getTrimmed ( name . getPropertyKey ( ) ) ; } @ Override public Integer getInt ( String name ) { Integer result = null ; String value = getTrimmed ( name ) ; if ( value != null ) { result = Integer . valueOf ( value ) ; } return result ; } @ Override public Integer getInt ( ConfigKey name , boolean useDefault ) { if ( useDefault ) { return getInt ( name . getPropertyKey ( ) , getDefaultValueAs ( name , Integer . class ) ) ; } return getInt ( name . getPropertyKey ( ) ) ; } private < T > T getDefaultValueAs ( ConfigKey confKey , Class < T > cls ) { Object defValue = confKey . getDefaultValue ( ) ; if ( defValue != null && cls != null ) { return ( T ) defValue ; } return null ; } @ Override public Integer getInt ( String name , Integer defaultValue ) { Integer result = getInt ( name ) ; if ( result == null ) { result = defaultValue ; } return result ; } @ Override public void setInt ( String name , Integer value ) { set ( name , String . valueOf ( value ) ) ; } @ Override public void setInt ( ConfigKey name , Integer value ) { set ( name . getPropertyKey ( ) , String . valueOf ( value ) ) ; } @ Override public Long getLong ( String name ) { Long result = null ; String value = getTrimmed ( name ) ; if ( value != null ) { result = Long . valueOf ( value ) ; } return result ; } @ Override public Long getLong ( ConfigKey name , boolean useDefault ) { if ( useDefault ) { return getLong ( name . getPropertyKey ( ) , getDefaultValueAs ( name , Long . class ) ) ; } return getLong ( name . getPropertyKey ( ) ) ; } @ Override public Long getLong ( String name , Long defaultValue ) { Long result = getLong ( name ) ; if ( result == null ) { result = defaultValue ; } return result ; } @ Override public void setLong ( String name , Long value ) { set ( name , String . valueOf ( value ) ) ; } @ Override public void setLong ( ConfigKey name , Long value ) { set ( name . getPropertyKey ( ) , String . valueOf ( value ) ) ; } @ Override public Float getFloat ( String name ) { Float result = null ; String value = getTrimmed ( name ) ; if ( value != null ) { result = Float . valueOf ( value ) ; } return result ; } @ Override public Float getFloat ( ConfigKey name , boolean useDefault ) { if ( useDefault ) { return getFloat ( name . getPropertyKey ( ) , getDefaultValueAs ( name , Float . class ) ) ; } return getFloat ( name . getPropertyKey ( ) ) ; } @ Override public Float getFloat ( String name , Float defaultValue ) { Float result = getFloat ( name ) ; if ( result == null ) { result = defaultValue ; } return result ; } @ Override public void setFloat ( String name , Float value ) { set ( name , String . valueOf ( value ) ) ; } @ Override public void setFloat ( ConfigKey name , Float value ) { set ( name . getPropertyKey ( ) , String . valueOf ( value ) ) ; } @ Override public Boolean getBoolean ( String name ) { Boolean result = null ; String value = getTrimmed ( name ) ; if ( value != null ) { result = Boolean . valueOf ( value ) ; } return result ; } @ Override public Boolean getBoolean ( ConfigKey name , boolean useDefault ) { if ( useDefault ) { return getBoolean ( name . getPropertyKey ( ) , ( Boolean ) name . getDefaultValue ( ) ) ; } return getBoolean ( name . getPropertyKey ( ) ) ; } @ Override public Boolean getBoolean ( String name , Boolean defaultValue ) { Boolean result = getBoolean ( name ) ; if ( result == null ) { result = defaultValue ; } return result ; } @ Override public void setBoolean ( String name , Boolean value ) { set ( name , String . valueOf ( value ) ) ; } @ Override public void setBoolean ( ConfigKey name , Boolean value ) { set ( name . getPropertyKey ( ) , String . valueOf ( value ) ) ; } @ Override public List < String > getList ( String name ) { List < String > results = null ; ConfigObject co = properties . get ( name ) ; if ( co != null ) { results = co . getListValues ( ) ; } else { for ( Config config : configs ) { results = config . getList ( name ) ; if ( results != null ) { break ; } } } return results ; } @ Override public List < String > getList ( String name , String [ ] defaultValue ) { List < String > results = getList ( name ) ; if ( results == null ) { results = Arrays . asList ( defaultValue ) ; } return results ; } @ Override public List < String > getList ( ConfigKey name ) { if ( name . getDefaultValue ( ) != null ) { return getList ( name . getPropertyKey ( ) , ( String [ ] ) name . getDefaultValue ( ) ) ; } return getList ( name . getPropertyKey ( ) ) ; } @ Override public Config getConfig ( String name ) { Config result = null ; ConfigObject co = properties . get ( name ) ; if ( co != null ) { result = co . getConfigValue ( ) ; } else { for ( Config config : configs ) { result = config . getConfig ( name ) ; if ( result != null ) { break ; } } } return result ; } @ Override public Config getConfig ( ConfigKey name ) { return getConfig ( name . getPropertyKey ( ) ) ; } @ Override public Class < ? > getClass ( String name ) throws ClassNotFoundException { Class < ? > result = null ; String valueString = getString ( name ) ; if ( valueString != null ) { Class < ? > cls = Class . forName ( name ) ; result = cls ; } return result ; } @ Override public Class < ? > getClass ( String name , Class < ? > defaultValue ) throws ClassNotFoundException { Class < ? > result = getClass ( name ) ; if ( result == null ) { result = defaultValue ; } return result ; } @ Override public Class < ? > getClass ( ConfigKey name , boolean useDefault ) throws ClassNotFoundException { if ( useDefault ) { return getClass ( name . getPropertyKey ( ) , ( Class < ? > ) name . getDefaultValue ( ) ) ; } return getClass ( name . getPropertyKey ( ) ) ; } @ Override public < T > T getInstance ( String name ) throws ClassNotFoundException { return getInstance ( name , null ) ; } @ Override public < T > T getInstance ( ConfigKey name ) throws ClassNotFoundException { return getInstance ( name . getPropertyKey ( ) ) ; } @ Override public < T > T getInstance ( String name , Class < T > xface ) throws ClassNotFoundException { T result = null ; Class < ? > cls = getClass ( name , null ) ; if ( xface != null && ! xface . isAssignableFrom ( cls ) ) { throw new RuntimeException ( cls + "" does not implement "" + xface ) ; } try { result = ( T ) cls . newInstance ( ) ; } catch ( Exception e ) { throw new RuntimeException ( ""Failed to create instance with class "" + cls . getName ( ) ) ; } return result ; } @ Override public void setString ( String name , String value ) { set ( name , value ) ; } @ Override public void setString ( ConfigKey name , String value ) { set ( name . getPropertyKey ( ) , value ) ; } protected void set ( String name , String value ) { ConfigObject co = new ConfigObject ( value ) ; set ( name , co ) ; } protected void set ( String name , Config value ) { ConfigObject co = new ConfigObject ( value ) ; set ( name , co ) ; } protected void set ( String name , ConfigObject value ) { this . properties . put ( name , value ) ; } protected void add ( Config config ) { if ( config != null ) { if ( this == config ) { throw new IllegalArgumentException ( ""You can not add a config to itself"" ) ; } this . configs . add ( config ) ; } } }",Smelly
"public class Query extends Segment { private String queryName ; public Query ( String queryName , String paramName , String valuePattern , boolean literal ) { super ( new Token ( paramName , valuePattern , literal ) ) ; this . queryName = queryName ; } public Query ( Query that ) { super ( that . getToken ( ) ) ; this . queryName = that . queryName ; } Query ( String queryName , Token token ) { super ( token ) ; this . queryName = queryName ; } public String getQueryName ( ) { return queryName ; } @ Override public boolean matches ( Segment that ) { boolean matches = super . matches ( that ) ; if ( matches ) { Query thatQuery = ( Query ) that ; matches = this . queryName . equals ( thatQuery . queryName ) ; } return matches ; } @ Override public boolean equals ( Object obj ) { if ( obj instanceof Query ) { Query that = ( Query ) obj ; return super . equals ( that ) && that . getQueryName ( ) . equals ( getQueryName ( ) ) ; } return false ; } @ Override public int hashCode ( ) { int result = super . hashCode ( ) ; return 31 * result + getQueryName ( ) . hashCode ( ) ; } }",No
"@ NamedQueries ( { @ NamedQuery ( name = ""getRecordingMetaDeltaByMetaDataId"" , query = ""SELECT c FROM RecordingMetaDelta c WHERE c.metaDataId = :metaDataId"" ) } ) @ Entity @ Table ( name = ""recording_meta_delta"" ) public class RecordingMetaDelta implements IDataProviderEntity { private static final long serialVersionUID = 1L ; @ Id @ GeneratedValue ( strategy = GenerationType . IDENTITY ) @ Column ( name = ""id"" ) private Long id ; @ Column ( name = ""metadata_id"" ) private Long metaDataId ; @ Column ( name = ""time_stamp"" ) private Integer timeStamp ; @ Column ( name = ""delta_time"" ) private Long deltaTime ; @ Column ( name = ""last_time_stamp"" ) private Long lastTimeStamp ; @ Column ( name = ""start_time"" ) private Date startTime ; @ Column ( name = ""current_event_time"" ) private Date currentTime ; @ Column ( name = ""delta_time_stamp"" ) private Long deltaTimeStamp ; @ Column ( name = ""missing_time"" ) private Long missingTime ; @ Column ( name = ""duration"" ) private Integer duration ; @ Column ( name = ""start_time_stamp"" ) private Integer startTimeStamp ; @ Column ( name = ""packet_time_stamp"" ) private Integer packetTimeStamp ; @ Column ( name = ""wave_out_put_name"" ) private String waveOutPutName ; @ Column ( name = ""data_length_packet"" ) private Integer dataLengthPacket ; @ Column ( name = ""received_audio_data_length"" ) private Long receivedAudioDataLength ; @ Column ( name = ""is_end_padding"" , nullable = false ) private boolean endPadding ; @ Column ( name = ""is_start_padding"" , nullable = false ) private boolean startPadding ; @ Column ( name = ""debug_status"" ) private String debugStatus ; @ Override public Long getId ( ) { return id ; } @ Override public void setId ( Long id ) { this . id = id ; } public Long getMetaDataId ( ) { return metaDataId ; } public void setMetaDataId ( Long metaDataId ) { this . metaDataId = metaDataId ; } public Integer getTimeStamp ( ) { return timeStamp ; } public void setTimeStamp ( Integer timeStamp ) { this . timeStamp = timeStamp ; } public Long getDeltaTime ( ) { return deltaTime ; } public void setDeltaTime ( Long deltaTime ) { this . deltaTime = deltaTime ; } public Long getLastTimeStamp ( ) { return lastTimeStamp ; } public void setLastTimeStamp ( Long lastTimeStamp ) { this . lastTimeStamp = lastTimeStamp ; } public Long getDeltaTimeStamp ( ) { return deltaTimeStamp ; } public void setDeltaTimeStamp ( Long deltaTimeStamp ) { this . deltaTimeStamp = deltaTimeStamp ; } public Integer getPacketTimeStamp ( ) { return packetTimeStamp ; } public void setPacketTimeStamp ( Integer packetTimeStamp ) { this . packetTimeStamp = packetTimeStamp ; } public Integer getStartTimeStamp ( ) { return startTimeStamp ; } public void setStartTimeStamp ( Integer startTimeStamp ) { this . startTimeStamp = startTimeStamp ; } public Long getMissingTime ( ) { return missingTime ; } public void setMissingTime ( Long missingTime ) { this . missingTime = missingTime ; } public Integer getDuration ( ) { return duration ; } public void setDuration ( Integer duration ) { this . duration = duration ; } public Date getStartTime ( ) { return startTime ; } public void setStartTime ( Date startTime ) { this . startTime = startTime ; } public Date getCurrentTime ( ) { return currentTime ; } public void setCurrentTime ( Date currentTime ) { this . currentTime = currentTime ; } public boolean isEndPadding ( ) { return endPadding ; } public void setEndPadding ( boolean endPadding ) { this . endPadding = endPadding ; } public boolean isStartPadding ( ) { return startPadding ; } public void setStartPadding ( boolean startPadding ) { this . startPadding = startPadding ; } public String getDebugStatus ( ) { return debugStatus ; } public void setDebugStatus ( String debugStatus ) { this . debugStatus = debugStatus ; } public String getWaveOutPutName ( ) { return waveOutPutName ; } public void setWaveOutPutName ( String waveOutPutName ) { this . waveOutPutName = waveOutPutName ; } public Integer getDataLengthPacket ( ) { return dataLengthPacket ; } public void setDataLengthPacket ( Integer dataLengthPacket ) { this . dataLengthPacket = dataLengthPacket ; } public Long getReceivedAudioDataLength ( ) { return receivedAudioDataLength ; } public void setReceivedAudioDataLength ( Long receivedAudioDataLength ) { this . receivedAudioDataLength = receivedAudioDataLength ; } }",No
"public class TestAMRMClient { static Configuration conf = null ; static MiniYARNCluster yarnCluster = null ; static YarnClient yarnClient = null ; static List < NodeReport > nodeReports = null ; static ApplicationAttemptId attemptId = null ; static int nodeCount = 3 ; static Resource capability ; static Priority priority ; static Priority priority2 ; static String node ; static String rack ; static String [ ] nodes ; static String [ ] racks ; private final static int DEFAULT_ITERATION = 3 ; @ BeforeClass public static void setup ( ) throws Exception { conf = new YarnConfiguration ( ) ; conf . setInt ( YarnConfiguration . RM_NM_HEARTBEAT_INTERVAL_MS , 100 ) ; conf . setLong ( YarnConfiguration . NM_LOG_RETAIN_SECONDS , 1 ) ; yarnCluster = new MiniYARNCluster ( TestAMRMClient . class . getName ( ) , nodeCount , 1 , 1 ) ; yarnCluster . init ( conf ) ; yarnCluster . start ( ) ; yarnClient = YarnClient . createYarnClient ( ) ; yarnClient . init ( conf ) ; yarnClient . start ( ) ; nodeReports = yarnClient . getNodeReports ( NodeState . RUNNING ) ; priority = Priority . newInstance ( 1 ) ; priority2 = Priority . newInstance ( 2 ) ; capability = Resource . newInstance ( 1024 , 1 ) ; node = nodeReports . get ( 0 ) . getNodeId ( ) . getHost ( ) ; rack = nodeReports . get ( 0 ) . getRackName ( ) ; nodes = new String [ ] { node } ; racks = new String [ ] { rack } ; } @ Before public void startApp ( ) throws Exception { ApplicationSubmissionContext appContext = yarnClient . createApplication ( ) . getApplicationSubmissionContext ( ) ; ApplicationId appId = appContext . getApplicationId ( ) ; appContext . setApplicationName ( ""Test"" ) ; Priority pri = Records . newRecord ( Priority . class ) ; pri . setPriority ( 0 ) ; appContext . setPriority ( pri ) ; appContext . setQueue ( ""default"" ) ; ContainerLaunchContext amContainer = BuilderUtils . newContainerLaunchContext ( Collections . < String , LocalResource > emptyMap ( ) , new HashMap < String , String > ( ) , Arrays . asList ( ""sleep"" , ""100"" ) , new HashMap < String , ByteBuffer > ( ) , null , new HashMap < ApplicationAccessType , String > ( ) ) ; appContext . setAMContainerSpec ( amContainer ) ; appContext . setResource ( Resource . newInstance ( 1024 , 1 ) ) ; SubmitApplicationRequest appRequest = Records . newRecord ( SubmitApplicationRequest . class ) ; appRequest . setApplicationSubmissionContext ( appContext ) ; yarnClient . submitApplication ( appContext ) ; RMAppAttempt appAttempt = null ; while ( true ) { ApplicationReport appReport = yarnClient . getApplicationReport ( appId ) ; if ( appReport . getYarnApplicationState ( ) == YarnApplicationState . ACCEPTED ) { attemptId = appReport . getCurrentApplicationAttemptId ( ) ; appAttempt = yarnCluster . getResourceManager ( ) . getRMContext ( ) . getRMApps ( ) . get ( attemptId . getApplicationId ( ) ) . getCurrentAppAttempt ( ) ; while ( true ) { if ( appAttempt . getAppAttemptState ( ) == RMAppAttemptState . LAUNCHED ) { break ; } } break ; } } UserGroupInformation . setLoginUser ( UserGroupInformation . createRemoteUser ( UserGroupInformation . getCurrentUser ( ) . getUserName ( ) ) ) ; UserGroupInformation . getCurrentUser ( ) . addToken ( appAttempt . getAMRMToken ( ) ) ; } @ After public void cancelApp ( ) throws YarnException , IOException { yarnClient . killApplication ( attemptId . getApplicationId ( ) ) ; attemptId = null ; } @ AfterClass public static void tearDown ( ) { if ( yarnClient != null && yarnClient . getServiceState ( ) == STATE . STARTED ) { yarnClient . stop ( ) ; } if ( yarnCluster != null && yarnCluster . getServiceState ( ) == STATE . STARTED ) { yarnCluster . stop ( ) ; } } @ Test ( timeout = 60000 ) public void testAMRMClientMatchingFit ( ) throws YarnException , IOException { AMRMClient < ContainerRequest > amClient = null ; try { amClient = AMRMClient . < ContainerRequest > createAMRMClient ( ) ; amClient . init ( conf ) ; amClient . start ( ) ; amClient . registerApplicationMaster ( ""Host"" , 10000 , """" ) ; Resource capability1 = Resource . newInstance ( 1024 , 2 ) ; Resource capability2 = Resource . newInstance ( 1024 , 1 ) ; Resource capability3 = Resource . newInstance ( 1000 , 2 ) ; Resource capability4 = Resource . newInstance ( 2000 , 1 ) ; Resource capability5 = Resource . newInstance ( 1000 , 3 ) ; Resource capability6 = Resource . newInstance ( 2000 , 1 ) ; Resource capability7 = Resource . newInstance ( 2000 , 1 ) ; ContainerRequest storedContainer1 = new ContainerRequest ( capability1 , nodes , racks , priority ) ; ContainerRequest storedContainer2 = new ContainerRequest ( capability2 , nodes , racks , priority ) ; ContainerRequest storedContainer3 = new ContainerRequest ( capability3 , nodes , racks , priority ) ; ContainerRequest storedContainer4 = new ContainerRequest ( capability4 , nodes , racks , priority ) ; ContainerRequest storedContainer5 = new ContainerRequest ( capability5 , nodes , racks , priority ) ; ContainerRequest storedContainer6 = new ContainerRequest ( capability6 , nodes , racks , priority ) ; ContainerRequest storedContainer7 = new ContainerRequest ( capability7 , nodes , racks , priority2 , false ) ; amClient . addContainerRequest ( storedContainer1 ) ; amClient . addContainerRequest ( storedContainer2 ) ; amClient . addContainerRequest ( storedContainer3 ) ; amClient . addContainerRequest ( storedContainer4 ) ; amClient . addContainerRequest ( storedContainer5 ) ; amClient . addContainerRequest ( storedContainer6 ) ; amClient . addContainerRequest ( storedContainer7 ) ; List < ? extends Collection < ContainerRequest > > matches ; ContainerRequest storedRequest ; Resource testCapability1 = Resource . newInstance ( 1024 , 2 ) ; matches = amClient . getMatchingRequests ( priority , node , testCapability1 ) ; verifyMatches ( matches , 1 ) ; storedRequest = matches . get ( 0 ) . iterator ( ) . next ( ) ; assertTrue ( storedContainer1 == storedRequest ) ; amClient . removeContainerRequest ( storedContainer1 ) ; Resource testCapability2 = Resource . newInstance ( 2000 , 1 ) ; matches = amClient . getMatchingRequests ( priority , node , testCapability2 ) ; verifyMatches ( matches , 2 ) ; int i = 0 ; for ( ContainerRequest storedRequest1 : matches . get ( 0 ) ) { if ( i ++ == 0 ) { assertTrue ( storedContainer4 == storedRequest1 ) ; } else { assertTrue ( storedContainer6 == storedRequest1 ) ; } } amClient . removeContainerRequest ( storedContainer6 ) ; Resource testCapability3 = Resource . newInstance ( 4000 , 4 ) ; matches = amClient . getMatchingRequests ( priority , node , testCapability3 ) ; assert ( matches . size ( ) == 4 ) ; Resource testCapability4 = Resource . newInstance ( 1024 , 2 ) ; matches = amClient . getMatchingRequests ( priority , node , testCapability4 ) ; assert ( matches . size ( ) == 2 ) ; for ( Collection < ContainerRequest > testSet : matches ) { assertTrue ( testSet . size ( ) == 1 ) ; ContainerRequest testRequest = testSet . iterator ( ) . next ( ) ; assertTrue ( testRequest != storedContainer4 ) ; assertTrue ( testRequest != storedContainer5 ) ; assert ( testRequest == storedContainer2 || testRequest == storedContainer3 ) ; } Resource testCapability5 = Resource . newInstance ( 512 , 4 ) ; matches = amClient . getMatchingRequests ( priority , node , testCapability5 ) ; assert ( matches . size ( ) == 0 ) ; Resource testCapability7 = Resource . newInstance ( 2000 , 1 ) ; matches = amClient . getMatchingRequests ( priority2 , ResourceRequest . ANY , testCapability7 ) ; assert ( matches . size ( ) == 0 ) ; matches = amClient . getMatchingRequests ( priority2 , node , testCapability7 ) ; assert ( matches . size ( ) == 1 ) ; amClient . unregisterApplicationMaster ( FinalApplicationStatus . SUCCEEDED , null , null ) ; } finally { if ( amClient != null && amClient . getServiceState ( ) == STATE . STARTED ) { amClient . stop ( ) ; } } } private void verifyMatches ( List < ? extends Collection < ContainerRequest > > matches , int matchSize ) { assertTrue ( matches . size ( ) == 1 ) ; assertTrue ( matches . get ( 0 ) . size ( ) == matchSize ) ; } @ Test ( timeout = 60000 ) public void testAMRMClientMatchingFitInferredRack ( ) throws YarnException , IOException { AMRMClientImpl < ContainerRequest > amClient = null ; try { amClient = new AMRMClientImpl < ContainerRequest > ( ) ; amClient . init ( conf ) ; amClient . start ( ) ; amClient . registerApplicationMaster ( ""Host"" , 10000 , """" ) ; Resource capability = Resource . newInstance ( 1024 , 2 ) ; ContainerRequest storedContainer1 = new ContainerRequest ( capability , nodes , null , priority ) ; amClient . addContainerRequest ( storedContainer1 ) ; List < ? extends Collection < ContainerRequest > > matches ; ContainerRequest storedRequest ; matches = amClient . getMatchingRequests ( priority , node , capability ) ; verifyMatches ( matches , 1 ) ; storedRequest = matches . get ( 0 ) . iterator ( ) . next ( ) ; assertTrue ( storedContainer1 == storedRequest ) ; matches = amClient . getMatchingRequests ( priority , rack , capability ) ; verifyMatches ( matches , 1 ) ; storedRequest = matches . get ( 0 ) . iterator ( ) . next ( ) ; assertTrue ( storedContainer1 == storedRequest ) ; amClient . removeContainerRequest ( storedContainer1 ) ; matches = amClient . getMatchingRequests ( priority , rack , capability ) ; assertTrue ( matches . isEmpty ( ) ) ; amClient . unregisterApplicationMaster ( FinalApplicationStatus . SUCCEEDED , null , null ) ; } finally { if ( amClient != null && amClient . getServiceState ( ) == STATE . STARTED ) { amClient . stop ( ) ; } } } @ Test public void testAMRMClientMatchStorage ( ) throws YarnException , IOException { AMRMClientImpl < ContainerRequest > amClient = null ; try { amClient = ( AMRMClientImpl < ContainerRequest > ) AMRMClient . < ContainerRequest > createAMRMClient ( ) ; amClient . init ( conf ) ; amClient . start ( ) ; amClient . registerApplicationMaster ( ""Host"" , 10000 , """" ) ; Priority priority1 = Records . newRecord ( Priority . class ) ; priority1 . setPriority ( 2 ) ; ContainerRequest storedContainer1 = new ContainerRequest ( capability , nodes , racks , priority ) ; ContainerRequest storedContainer2 = new ContainerRequest ( capability , nodes , racks , priority ) ; ContainerRequest storedContainer3 = new ContainerRequest ( capability , null , null , priority1 ) ; amClient . addContainerRequest ( storedContainer1 ) ; amClient . addContainerRequest ( storedContainer2 ) ; amClient . addContainerRequest ( storedContainer3 ) ; int containersRequestedAny = amClient . remoteRequestsTable . get ( priority ) . get ( ResourceRequest . ANY ) . get ( capability ) . remoteRequest . getNumContainers ( ) ; assertTrue ( containersRequestedAny == 2 ) ; containersRequestedAny = amClient . remoteRequestsTable . get ( priority1 ) . get ( ResourceRequest . ANY ) . get ( capability ) . remoteRequest . getNumContainers ( ) ; assertTrue ( containersRequestedAny == 1 ) ; List < ? extends Collection < ContainerRequest > > matches = amClient . getMatchingRequests ( priority , node , capability ) ; verifyMatches ( matches , 2 ) ; matches = amClient . getMatchingRequests ( priority , rack , capability ) ; verifyMatches ( matches , 2 ) ; matches = amClient . getMatchingRequests ( priority , ResourceRequest . ANY , capability ) ; verifyMatches ( matches , 2 ) ; matches = amClient . getMatchingRequests ( priority1 , rack , capability ) ; assertTrue ( matches . isEmpty ( ) ) ; matches = amClient . getMatchingRequests ( priority1 , ResourceRequest . ANY , capability ) ; verifyMatches ( matches , 1 ) ; amClient . removeContainerRequest ( storedContainer3 ) ; matches = amClient . getMatchingRequests ( priority , node , capability ) ; verifyMatches ( matches , 2 ) ; amClient . removeContainerRequest ( storedContainer2 ) ; matches = amClient . getMatchingRequests ( priority , node , capability ) ; verifyMatches ( matches , 1 ) ; matches = amClient . getMatchingRequests ( priority , rack , capability ) ; verifyMatches ( matches , 1 ) ; ContainerRequest storedRequest = matches . get ( 0 ) . iterator ( ) . next ( ) ; assertTrue ( storedContainer1 == storedRequest ) ; amClient . removeContainerRequest ( storedContainer1 ) ; matches = amClient . getMatchingRequests ( priority , ResourceRequest . ANY , capability ) ; assertTrue ( matches . isEmpty ( ) ) ; matches = amClient . getMatchingRequests ( priority1 , ResourceRequest . ANY , capability ) ; assertTrue ( matches . isEmpty ( ) ) ; assertTrue ( amClient . remoteRequestsTable . isEmpty ( ) ) ; amClient . addContainerRequest ( storedContainer1 ) ; amClient . addContainerRequest ( storedContainer3 ) ; int allocatedContainerCount = 0 ; int iterationsLeft = 3 ; while ( allocatedContainerCount < 2 && iterationsLeft -- > 0 ) { Log . info ( "" == alloc "" + allocatedContainerCount + "" it left "" + iterationsLeft ) ; AllocateResponse allocResponse = amClient . allocate ( 0.1f ) ; assertTrue ( amClient . ask . size ( ) == 0 ) ; assertTrue ( amClient . release . size ( ) == 0 ) ; assertTrue ( nodeCount == amClient . getClusterNodeCount ( ) ) ; allocatedContainerCount += allocResponse . getAllocatedContainers ( ) . size ( ) ; for ( Container container : allocResponse . getAllocatedContainers ( ) ) { ContainerRequest expectedRequest = container . getPriority ( ) . equals ( storedContainer1 . getPriority ( ) ) ? storedContainer1 : storedContainer3 ; matches = amClient . getMatchingRequests ( container . getPriority ( ) , ResourceRequest . ANY , container . getResource ( ) ) ; verifyMatches ( matches , 1 ) ; ContainerRequest matchedRequest = matches . get ( 0 ) . iterator ( ) . next ( ) ; assertTrue ( matchedRequest == expectedRequest ) ; amClient . removeContainerRequest ( matchedRequest ) ; amClient . releaseAssignedContainer ( container . getId ( ) ) ; } if ( allocatedContainerCount < containersRequestedAny ) { sleep ( 100 ) ; } } assertTrue ( allocatedContainerCount == 2 ) ; AllocateResponse allocResponse = amClient . allocate ( 0.1f ) ; assertTrue ( amClient . release . size ( ) == 0 ) ; assertTrue ( amClient . ask . size ( ) == 0 ) ; assertTrue ( allocResponse . getAllocatedContainers ( ) . size ( ) == 0 ) ; assertTrue ( amClient . remoteRequestsTable . isEmpty ( ) ) ; amClient . unregisterApplicationMaster ( FinalApplicationStatus . SUCCEEDED , null , null ) ; } finally { if ( amClient != null && amClient . getServiceState ( ) == STATE . STARTED ) { amClient . stop ( ) ; } } } @ Test ( timeout = 60000 ) public void testAllocationWithBlacklist ( ) throws YarnException , IOException { AMRMClientImpl < ContainerRequest > amClient = null ; try { amClient = ( AMRMClientImpl < ContainerRequest > ) AMRMClient . < ContainerRequest > createAMRMClient ( ) ; amClient . init ( conf ) ; amClient . start ( ) ; amClient . registerApplicationMaster ( ""Host"" , 10000 , """" ) ; assertTrue ( amClient . ask . size ( ) == 0 ) ; assertTrue ( amClient . release . size ( ) == 0 ) ; ContainerRequest storedContainer1 = new ContainerRequest ( capability , nodes , racks , priority ) ; amClient . addContainerRequest ( storedContainer1 ) ; assertTrue ( amClient . ask . size ( ) == 3 ) ; assertTrue ( amClient . release . size ( ) == 0 ) ; List < String > localNodeBlacklist = new ArrayList < String > ( ) ; localNodeBlacklist . add ( node ) ; amClient . updateBlacklist ( localNodeBlacklist , null ) ; int allocatedContainerCount = getAllocatedContainersNumber ( amClient , DEFAULT_ITERATION ) ; assertTrue ( allocatedContainerCount == 0 ) ; amClient . updateBlacklist ( null , localNodeBlacklist ) ; ContainerRequest storedContainer2 = new ContainerRequest ( capability , nodes , racks , priority ) ; amClient . addContainerRequest ( storedContainer2 ) ; allocatedContainerCount = getAllocatedContainersNumber ( amClient , DEFAULT_ITERATION ) ; assertEquals ( allocatedContainerCount , 2 ) ; assertTrue ( amClient . blacklistAdditions . isEmpty ( ) ) ; assertTrue ( amClient . blacklistRemovals . isEmpty ( ) ) ; ContainerRequest invalidContainerRequest = new ContainerRequest ( Resource . newInstance ( - 1024 , 1 ) , nodes , racks , priority ) ; amClient . addContainerRequest ( invalidContainerRequest ) ; amClient . updateBlacklist ( localNodeBlacklist , null ) ; try { amClient . allocate ( 0.1f ) ; fail ( ""there should be an exception here."" ) ; } catch ( Exception e ) { assertEquals ( amClient . blacklistAdditions . size ( ) , 1 ) ; } } finally { if ( amClient != null && amClient . getServiceState ( ) == STATE . STARTED ) { amClient . stop ( ) ; } } } @ Test ( timeout = 60000 ) public void testAMRMClientWithBlacklist ( ) throws YarnException , IOException { AMRMClientImpl < ContainerRequest > amClient = null ; try { amClient = ( AMRMClientImpl < ContainerRequest > ) AMRMClient . < ContainerRequest > createAMRMClient ( ) ; amClient . init ( conf ) ; amClient . start ( ) ; amClient . registerApplicationMaster ( ""Host"" , 10000 , """" ) ; String [ ] nodes = { ""node1"" , ""node2"" , ""node3"" } ; List < String > nodeList01 = new ArrayList < String > ( ) ; nodeList01 . add ( nodes [ 0 ] ) ; nodeList01 . add ( nodes [ 1 ] ) ; amClient . updateBlacklist ( nodeList01 , null ) ; assertEquals ( amClient . blacklistAdditions . size ( ) , 2 ) ; assertEquals ( amClient . blacklistRemovals . size ( ) , 0 ) ; List < String > nodeList02 = new ArrayList < String > ( ) ; nodeList02 . add ( nodes [ 0 ] ) ; nodeList02 . add ( nodes [ 2 ] ) ; amClient . updateBlacklist ( nodeList02 , null ) ; assertEquals ( amClient . blacklistAdditions . size ( ) , 3 ) ; assertEquals ( amClient . blacklistRemovals . size ( ) , 0 ) ; List < String > nodeList12 = new ArrayList < String > ( ) ; nodeList12 . add ( nodes [ 1 ] ) ; nodeList12 . add ( nodes [ 2 ] ) ; amClient . updateBlacklist ( null , nodeList12 ) ; assertEquals ( amClient . blacklistAdditions . size ( ) , 1 ) ; assertEquals ( amClient . blacklistRemovals . size ( ) , 2 ) ; List < String > nodeList1 = new ArrayList < String > ( ) ; nodeList1 . add ( nodes [ 1 ] ) ; amClient . updateBlacklist ( nodeList1 , null ) ; assertEquals ( amClient . blacklistAdditions . size ( ) , 2 ) ; assertEquals ( amClient . blacklistRemovals . size ( ) , 1 ) ; } finally { if ( amClient != null && amClient . getServiceState ( ) == STATE . STARTED ) { amClient . stop ( ) ; } } } private int getAllocatedContainersNumber ( AMRMClientImpl < ContainerRequest > amClient , int iterationsLeft ) throws YarnException , IOException { int allocatedContainerCount = 0 ; while ( iterationsLeft -- > 0 ) { Log . info ( "" == alloc "" + allocatedContainerCount + "" it left "" + iterationsLeft ) ; AllocateResponse allocResponse = amClient . allocate ( 0.1f ) ; assertTrue ( amClient . ask . size ( ) == 0 ) ; assertTrue ( amClient . release . size ( ) == 0 ) ; assertTrue ( nodeCount == amClient . getClusterNodeCount ( ) ) ; allocatedContainerCount += allocResponse . getAllocatedContainers ( ) . size ( ) ; if ( allocatedContainerCount == 0 ) { sleep ( 100 ) ; } } return allocatedContainerCount ; } @ Test ( timeout = 60000 ) public void testAMRMClient ( ) throws YarnException , IOException { AMRMClient < ContainerRequest > amClient = null ; try { amClient = AMRMClient . < ContainerRequest > createAMRMClient ( ) ; amClient . init ( conf ) ; amClient . start ( ) ; amClient . registerApplicationMaster ( ""Host"" , 10000 , """" ) ; testAllocation ( ( AMRMClientImpl < ContainerRequest > ) amClient ) ; amClient . unregisterApplicationMaster ( FinalApplicationStatus . SUCCEEDED , null , null ) ; } finally { if ( amClient != null && amClient . getServiceState ( ) == STATE . STARTED ) { amClient . stop ( ) ; } } } private void testAllocation ( final AMRMClientImpl < ContainerRequest > amClient ) throws YarnException , IOException { assertTrue ( amClient . ask . size ( ) == 0 ) ; assertTrue ( amClient . release . size ( ) == 0 ) ; amClient . addContainerRequest ( new ContainerRequest ( capability , nodes , racks , priority ) ) ; amClient . addContainerRequest ( new ContainerRequest ( capability , nodes , racks , priority ) ) ; amClient . addContainerRequest ( new ContainerRequest ( capability , nodes , racks , priority ) ) ; amClient . addContainerRequest ( new ContainerRequest ( capability , nodes , racks , priority ) ) ; amClient . removeContainerRequest ( new ContainerRequest ( capability , nodes , racks , priority ) ) ; amClient . removeContainerRequest ( new ContainerRequest ( capability , nodes , racks , priority ) ) ; int containersRequestedNode = amClient . remoteRequestsTable . get ( priority ) . get ( node ) . get ( capability ) . remoteRequest . getNumContainers ( ) ; int containersRequestedRack = amClient . remoteRequestsTable . get ( priority ) . get ( rack ) . get ( capability ) . remoteRequest . getNumContainers ( ) ; int containersRequestedAny = amClient . remoteRequestsTable . get ( priority ) . get ( ResourceRequest . ANY ) . get ( capability ) . remoteRequest . getNumContainers ( ) ; assertTrue ( containersRequestedNode == 2 ) ; assertTrue ( containersRequestedRack == 2 ) ; assertTrue ( containersRequestedAny == 2 ) ; assertTrue ( amClient . ask . size ( ) == 3 ) ; assertTrue ( amClient . release . size ( ) == 0 ) ; int allocatedContainerCount = 0 ; int iterationsLeft = 3 ; Set < ContainerId > releases = new TreeSet < ContainerId > ( ) ; NMTokenCache . clearCache ( ) ; Assert . assertEquals ( 0 , NMTokenCache . numberOfNMTokensInCache ( ) ) ; HashMap < String , Token > receivedNMTokens = new HashMap < String , Token > ( ) ; while ( allocatedContainerCount < containersRequestedAny && iterationsLeft -- > 0 ) { AllocateResponse allocResponse = amClient . allocate ( 0.1f ) ; assertTrue ( amClient . ask . size ( ) == 0 ) ; assertTrue ( amClient . release . size ( ) == 0 ) ; assertTrue ( nodeCount == amClient . getClusterNodeCount ( ) ) ; allocatedContainerCount += allocResponse . getAllocatedContainers ( ) . size ( ) ; for ( Container container : allocResponse . getAllocatedContainers ( ) ) { ContainerId rejectContainerId = container . getId ( ) ; releases . add ( rejectContainerId ) ; amClient . releaseAssignedContainer ( rejectContainerId ) ; } for ( NMToken token : allocResponse . getNMTokens ( ) ) { String nodeID = token . getNodeId ( ) . toString ( ) ; if ( receivedNMTokens . containsKey ( nodeID ) ) { Assert . fail ( ""Received token again for : "" + nodeID ) ; } receivedNMTokens . put ( nodeID , token . getToken ( ) ) ; } if ( allocatedContainerCount < containersRequestedAny ) { sleep ( 100 ) ; } } Assert . assertTrue ( receivedNMTokens . size ( ) > 0 && receivedNMTokens . size ( ) <= nodeCount ) ; assertTrue ( allocatedContainerCount == containersRequestedAny ) ; assertTrue ( amClient . release . size ( ) == 2 ) ; assertTrue ( amClient . ask . size ( ) == 0 ) ; amClient . removeContainerRequest ( new ContainerRequest ( capability , nodes , racks , priority ) ) ; amClient . removeContainerRequest ( new ContainerRequest ( capability , nodes , racks , priority ) ) ; assertTrue ( amClient . ask . size ( ) == 3 ) ; ResourceRequest snoopRequest = amClient . ask . iterator ( ) . next ( ) ; assertTrue ( snoopRequest . getNumContainers ( ) == 0 ) ; amClient . addContainerRequest ( new ContainerRequest ( capability , nodes , racks , priority ) ) ; amClient . addContainerRequest ( new ContainerRequest ( capability , nodes , racks , priority ) ) ; snoopRequest = amClient . ask . iterator ( ) . next ( ) ; assertTrue ( snoopRequest . getNumContainers ( ) == 2 ) ; ApplicationMasterProtocol realRM = amClient . rmClient ; try { ApplicationMasterProtocol mockRM = mock ( ApplicationMasterProtocol . class ) ; when ( mockRM . allocate ( any ( AllocateRequest . class ) ) ) . thenAnswer ( new Answer < AllocateResponse > ( ) { public AllocateResponse answer ( InvocationOnMock invocation ) throws Exception { amClient . removeContainerRequest ( new ContainerRequest ( capability , nodes , racks , priority ) ) ; amClient . removeContainerRequest ( new ContainerRequest ( capability , nodes , racks , priority ) ) ; throw new Exception ( ) ; } } ) ; amClient . rmClient = mockRM ; amClient . allocate ( 0.1f ) ; } catch ( Exception ioe ) { } finally { amClient . rmClient = realRM ; } assertTrue ( amClient . release . size ( ) == 2 ) ; assertTrue ( amClient . ask . size ( ) == 3 ) ; snoopRequest = amClient . ask . iterator ( ) . next ( ) ; assertTrue ( snoopRequest . getNumContainers ( ) == 0 ) ; iterationsLeft = 3 ; while ( ! releases . isEmpty ( ) || iterationsLeft -- > 0 ) { AllocateResponse allocResponse = amClient . allocate ( 0.1f ) ; assertTrue ( allocResponse . getAllocatedContainers ( ) . size ( ) == 0 ) ; if ( allocResponse . getCompletedContainersStatuses ( ) . size ( ) > 0 ) { for ( ContainerStatus cStatus : allocResponse . getCompletedContainersStatuses ( ) ) { if ( releases . contains ( cStatus . getContainerId ( ) ) ) { assertTrue ( cStatus . getState ( ) == ContainerState . COMPLETE ) ; assertTrue ( cStatus . getExitStatus ( ) == - 100 ) ; releases . remove ( cStatus . getContainerId ( ) ) ; } } } if ( iterationsLeft > 0 ) { sleep ( 100 ) ; } } assertTrue ( amClient . ask . size ( ) == 0 ) ; assertTrue ( amClient . release . size ( ) == 0 ) ; } private void sleep ( int sleepTime ) { try { Thread . sleep ( sleepTime ) ; } catch ( InterruptedException e ) { e . printStackTrace ( ) ; } } }",Smelly
"public class TestAll extends AbstractJCRTest { private static final String TEST_NAMESPACE = ""http://www.apache.org/jackrabbit/test"" ; private static final String TEST_NODETYPES = ""org/apache/jackrabbit/core/nodetype/xml/test_nodetypes.xml"" ; private static final String TEST_NS_XML_NODETYPES = ""test_ns_xml_nodetypes.xml"" ; private static final String TEST_NS_CND_NODETYPES = ""test_ns_cnd_nodetypes.cnd"" ; private static final String TEST_SAME_NT_NAME_XML_NODETYPES = ""test_same_nt_name_xml_nodetypes.xml"" ; private static final String TEST_SAME_NT_NAME_CND_NODETYPES = ""test_same_nt_name_cnd_nodetypes.cnd"" ; private static final NameFactory FACTORY = NameFactoryImpl . getInstance ( ) ; private QNodeTypeDefinition [ ] types ; private NamespaceRegistry registry ; protected void setUp ( ) throws Exception { super . setUp ( ) ; InputStream xml = getClass ( ) . getClassLoader ( ) . getResourceAsStream ( TEST_NODETYPES ) ; types = NodeTypeReader . read ( xml ) ; registry = new SimpleNamespaceRegistry ( ) ; registry . registerNamespace ( ""test"" , TEST_NAMESPACE ) ; } private QNodeTypeDefinition getNodeType ( String name ) { Name qname = FACTORY . create ( TEST_NAMESPACE , name ) ; for ( int i = 0 ; i < types . length ; i ++ ) { if ( qname . equals ( types [ i ] . getName ( ) ) ) { return types [ i ] ; } } throw new AssertionFailedError ( ""Node type "" + name + "" does not exist"" ) ; } private QPropertyDefinition getPropDef ( String typeName , String propertyName ) { Name name ; if ( propertyName != null ) { name = FACTORY . create ( TEST_NAMESPACE , propertyName ) ; } else { name = NameConstants . ANY_NAME ; } QNodeTypeDefinition def = getNodeType ( typeName ) ; QPropertyDefinition [ ] defs = def . getPropertyDefs ( ) ; for ( int i = 0 ; i < defs . length ; i ++ ) { if ( name . equals ( defs [ i ] . getName ( ) ) ) { return defs [ i ] ; } } throw new AssertionFailedError ( ""Property "" + propertyName + "" does not exist"" ) ; } private String getDefaultValue ( QPropertyDefinition def , int index ) { try { QValue [ ] values = def . getDefaultValues ( ) ; NamespaceResolver nsResolver = new AdditionalNamespaceResolver ( registry ) ; NamePathResolver resolver = new DefaultNamePathResolver ( nsResolver ) ; ValueFactoryQImpl factory = new ValueFactoryQImpl ( InternalValueFactory . getInstance ( ) , resolver ) ; return factory . createValue ( values [ index ] ) . getString ( ) ; } catch ( RepositoryException e ) { throw new AssertionFailedError ( e . getMessage ( ) ) ; } } private QNodeDefinition getChildNode ( String typeName , String nodeName ) { Name name = FACTORY . create ( TEST_NAMESPACE , nodeName ) ; QNodeTypeDefinition def = getNodeType ( typeName ) ; QNodeDefinition [ ] defs = def . getChildNodeDefs ( ) ; for ( int i = 0 ; i < defs . length ; i ++ ) { if ( name . equals ( defs [ i ] . getName ( ) ) ) { return defs [ i ] ; } } throw new AssertionFailedError ( ""Child node "" + nodeName + "" does not exist"" ) ; } public void testRead ( ) { assertEquals ( ""number of node types"" , 6 , types . length ) ; } public void testEmptyNodeType ( ) { QNodeTypeDefinition def = getNodeType ( ""emptyNodeType"" ) ; assertNotNull ( ""emptyNodeType exists"" , def ) ; assertEquals ( ""emptyNodeType mixin"" , false , def . isMixin ( ) ) ; assertEquals ( ""emptyNodeType hasOrderableChildNodes"" , false , def . hasOrderableChildNodes ( ) ) ; assertEquals ( ""emptyNodeType primaryItemName"" , null , def . getPrimaryItemName ( ) ) ; assertEquals ( ""emptyNodeType childNodeDefs"" , 0 , def . getChildNodeDefs ( ) . length ) ; assertEquals ( ""emptyNodeType propertyDefs"" , 0 , def . getPropertyDefs ( ) . length ) ; } public void testMixinNodeType ( ) { QNodeTypeDefinition def = getNodeType ( ""mixinNodeType"" ) ; assertEquals ( ""mixinNodeType mixin"" , true , def . isMixin ( ) ) ; } public void testOrderedNodeType ( ) { QNodeTypeDefinition def = getNodeType ( ""orderedNodeType"" ) ; assertEquals ( ""orderedNodeType hasOrderableChildNodes"" , true , def . hasOrderableChildNodes ( ) ) ; } public void testItemNodeType ( ) { QNodeTypeDefinition def = getNodeType ( ""itemNodeType"" ) ; assertEquals ( ""itemNodeType primaryItemName"" , FACTORY . create ( TEST_NAMESPACE , ""emptyItem"" ) , def . getPrimaryItemName ( ) ) ; assertEquals ( ""itemNodeType propertyDefs"" , 10 , def . getPropertyDefs ( ) . length ) ; QPropertyDefinition pdef = getPropDef ( ""itemNodeType"" , null ) ; assertTrue ( ""itemNodeType wildcard property"" , pdef . definesResidual ( ) ) ; } public void testImportXMLNodeTypes ( ) throws Exception { try { superuser . getNamespacePrefix ( ""test-namespace2"" ) ; } catch ( NamespaceException e1 ) { JackrabbitNodeTypeManager ntm = ( JackrabbitNodeTypeManager ) superuser . getWorkspace ( ) . getNodeTypeManager ( ) ; ntm . registerNodeTypes ( TestAll . class . getResourceAsStream ( TEST_NS_XML_NODETYPES ) , JackrabbitNodeTypeManager . TEXT_XML ) ; try { superuser . getNamespacePrefix ( ""test-namespace2"" ) ; } catch ( NamespaceException e2 ) { fail ( ""xml test2 namespace not registered"" ) ; } } } public void testInvalidXMLNodeTypes ( ) throws Exception { JackrabbitNodeTypeManager ntm = ( JackrabbitNodeTypeManager ) superuser . getWorkspace ( ) . getNodeTypeManager ( ) ; try { ntm . registerNodeTypes ( TestAll . class . getResourceAsStream ( TEST_SAME_NT_NAME_XML_NODETYPES ) , JackrabbitNodeTypeManager . TEXT_XML ) ; fail ( ""Importing multiple node types with the same name must fail"" ) ; } catch ( RepositoryException e ) { if ( e . getCause ( ) instanceof InvalidNodeTypeDefException ) { } else { throw e ; } } } public void testImportCNDNodeTypes ( ) throws Exception { try { superuser . getNamespacePrefix ( ""test-namespace3"" ) ; } catch ( NamespaceException e1 ) { Reader cnd = new InputStreamReader ( TestAll . class . getResourceAsStream ( TEST_NS_CND_NODETYPES ) ) ; CndImporter . registerNodeTypes ( cnd , superuser ) ; cnd . close ( ) ; try { superuser . getNamespacePrefix ( ""test-namespace3"" ) ; } catch ( NamespaceException e2 ) { fail ( ""cnd test3 namespace not registered"" ) ; } } } public void testInvalidCNDNodeTypes ( ) throws Exception { JackrabbitNodeTypeManager ntm = ( JackrabbitNodeTypeManager ) superuser . getWorkspace ( ) . getNodeTypeManager ( ) ; try { ntm . registerNodeTypes ( TestAll . class . getResourceAsStream ( TEST_SAME_NT_NAME_CND_NODETYPES ) , JackrabbitNodeTypeManager . TEXT_X_JCR_CND ) ; fail ( ""Importing multiple node types with the same name must fail"" ) ; } catch ( RepositoryException e ) { if ( e . getCause ( ) instanceof InvalidNodeTypeDefException ) { } else { throw e ; } } } public void testEmptyItem ( ) { QPropertyDefinition def = getPropDef ( ""itemNodeType"" , ""emptyItem"" ) ; assertEquals ( ""emptyItem autoCreate"" , false , def . isAutoCreated ( ) ) ; assertEquals ( ""emptyItem mandatory"" , false , def . isMandatory ( ) ) ; assertEquals ( ""emptyItem onParentVersion"" , OnParentVersionAction . IGNORE , def . getOnParentVersion ( ) ) ; assertEquals ( ""emptyItem protected"" , false , def . isProtected ( ) ) ; } public void testAutoCreateItem ( ) { QPropertyDefinition def = getPropDef ( ""itemNodeType"" , ""autoCreatedItem"" ) ; assertEquals ( ""autoCreatedItem autoCreated"" , true , def . isAutoCreated ( ) ) ; } public void testMandatoryItem ( ) { QPropertyDefinition def = getPropDef ( ""itemNodeType"" , ""mandatoryItem"" ) ; assertEquals ( ""mandatoryItem mandatory"" , true , def . isMandatory ( ) ) ; } public void testCopyItem ( ) { QPropertyDefinition def = getPropDef ( ""itemNodeType"" , ""copyItem"" ) ; assertEquals ( ""copyItem onParentVersion"" , OnParentVersionAction . COPY , def . getOnParentVersion ( ) ) ; } public void testVersionItem ( ) { QPropertyDefinition def = getPropDef ( ""itemNodeType"" , ""versionItem"" ) ; assertEquals ( ""versionItem onParentVersion"" , OnParentVersionAction . VERSION , def . getOnParentVersion ( ) ) ; } public void testInitializeItem ( ) { QPropertyDefinition def = getPropDef ( ""itemNodeType"" , ""initializeItem"" ) ; assertEquals ( ""initializeItem onParentVersion"" , OnParentVersionAction . INITIALIZE , def . getOnParentVersion ( ) ) ; } public void testComputeItem ( ) { QPropertyDefinition def = getPropDef ( ""itemNodeType"" , ""computeItem"" ) ; assertEquals ( ""computeItem onParentVersion"" , OnParentVersionAction . COMPUTE , def . getOnParentVersion ( ) ) ; } public void testAbortItem ( ) { QPropertyDefinition def = getPropDef ( ""itemNodeType"" , ""abortItem"" ) ; assertEquals ( ""abortItem onParentVersion"" , OnParentVersionAction . ABORT , def . getOnParentVersion ( ) ) ; } public void testProtectedItem ( ) { QPropertyDefinition def = getPropDef ( ""itemNodeType"" , ""protectedItem"" ) ; assertEquals ( ""protectedItem protected"" , true , def . isProtected ( ) ) ; } public void testPropertyNodeType ( ) { QNodeTypeDefinition def = getNodeType ( ""propertyNodeType"" ) ; assertEquals ( ""propertyNodeType propertyDefs"" , 13 , def . getPropertyDefs ( ) . length ) ; } public void testEmptyProperty ( ) { QPropertyDefinition def = getPropDef ( ""propertyNodeType"" , ""emptyProperty"" ) ; assertEquals ( ""emptyProperty requiredType"" , PropertyType . UNDEFINED , def . getRequiredType ( ) ) ; assertEquals ( ""emptyProperty multiple"" , false , def . isMultiple ( ) ) ; assertNull ( ""emptyProperty defaultValues"" , def . getDefaultValues ( ) ) ; assertEquals ( ""emptyProperty valueConstraints"" , 0 , def . getValueConstraints ( ) . length ) ; } public void testBinaryProperty ( ) { QPropertyDefinition def = getPropDef ( ""propertyNodeType"" , ""binaryProperty"" ) ; assertEquals ( ""binaryProperty requiredType"" , PropertyType . BINARY , def . getRequiredType ( ) ) ; assertEquals ( ""binaryProperty valueConstraints"" , 1 , def . getValueConstraints ( ) . length ) ; assertEquals ( ""binaryProperty valueConstraints[0]"" , ""[0,)"" , ( def . getValueConstraints ( ) ) [ 0 ] . getString ( ) ) ; assertNull ( ""binaryProperty defaultValues"" , def . getDefaultValues ( ) ) ; } public void testBooleanProperty ( ) { QPropertyDefinition def = getPropDef ( ""propertyNodeType"" , ""booleanProperty"" ) ; assertEquals ( ""booleanProperty requiredType"" , PropertyType . BOOLEAN , def . getRequiredType ( ) ) ; assertEquals ( ""booleanProperty valueConstraints"" , 2 , def . getValueConstraints ( ) . length ) ; assertEquals ( ""booleanProperty valueConstraints[0]"" , ""true"" , ( def . getValueConstraints ( ) ) [ 0 ] . getString ( ) ) ; assertEquals ( ""booleanProperty valueConstraints[1]"" , ""false"" , ( def . getValueConstraints ( ) ) [ 1 ] . getString ( ) ) ; assertEquals ( ""booleanProperty defaultValues"" , 1 , def . getDefaultValues ( ) . length ) ; assertEquals ( ""booleanProperty defaultValues[0]"" , ""true"" , getDefaultValue ( def , 0 ) ) ; } public void testDateProperty ( ) { QPropertyDefinition def = getPropDef ( ""propertyNodeType"" , ""dateProperty"" ) ; assertEquals ( ""dateProperty requiredType"" , PropertyType . DATE , def . getRequiredType ( ) ) ; assertEquals ( ""dateProperty valueConstraints"" , 1 , def . getValueConstraints ( ) . length ) ; assertEquals ( ""dateProperty valueConstraints[0]"" , ""[2005-01-01T00:00:00.000Z,2006-01-01T00:00:00.000Z)"" , ( def . getValueConstraints ( ) ) [ 0 ] . getString ( ) ) ; assertEquals ( ""dateProperty defaultValues"" , 1 , def . getDefaultValues ( ) . length ) ; assertEquals ( ""dateProperty defaultValues[0]"" , ""2005-01-01T00:00:00.000Z"" , getDefaultValue ( def , 0 ) ) ; } public void testDoubleProperty ( ) { QPropertyDefinition def = getPropDef ( ""propertyNodeType"" , ""doubleProperty"" ) ; assertEquals ( ""doubleProperty requiredType"" , PropertyType . DOUBLE , def . getRequiredType ( ) ) ; assertEquals ( ""doubleProperty valueConstraints"" , 3 , def . getValueConstraints ( ) . length ) ; assertEquals ( ""doubleProperty valueConstraints[0]"" , ""[,0.0)"" , ( def . getValueConstraints ( ) ) [ 0 ] . getString ( ) ) ; assertEquals ( ""doubleProperty valueConstraints[1]"" , ""(1.0,2.0)"" , ( def . getValueConstraints ( ) ) [ 1 ] . getString ( ) ) ; assertEquals ( ""doubleProperty valueConstraints[2]"" , ""(3.0,]"" , ( def . getValueConstraints ( ) ) [ 2 ] . getString ( ) ) ; assertEquals ( ""doubleProperty defaultValues"" , 1 , def . getDefaultValues ( ) . length ) ; assertEquals ( ""doubleProperty defaultValues[0]"" , ""1.5"" , getDefaultValue ( def , 0 ) ) ; } public void testLongProperty ( ) { QPropertyDefinition def = getPropDef ( ""propertyNodeType"" , ""longProperty"" ) ; assertEquals ( ""longProperty requiredType"" , PropertyType . LONG , def . getRequiredType ( ) ) ; assertEquals ( ""longProperty valueConstraints"" , 3 , def . getValueConstraints ( ) . length ) ; assertEquals ( ""longProperty valueConstraints[0]"" , ""(-10,0]"" , ( def . getValueConstraints ( ) ) [ 0 ] . getString ( ) ) ; assertEquals ( ""longProperty valueConstraints[1]"" , ""[1,2]"" , ( def . getValueConstraints ( ) ) [ 1 ] . getString ( ) ) ; assertEquals ( ""longProperty valueConstraints[2]"" , ""[10,100)"" , ( def . getValueConstraints ( ) ) [ 2 ] . getString ( ) ) ; assertEquals ( ""longProperty defaultValues"" , 1 , def . getDefaultValues ( ) . length ) ; assertEquals ( ""longProperty defaultValues[0]"" , ""25"" , getDefaultValue ( def , 0 ) ) ; } public void testNameProperty ( ) { QPropertyDefinition def = getPropDef ( ""propertyNodeType"" , ""nameProperty"" ) ; assertEquals ( ""nameProperty requiredType"" , PropertyType . NAME , def . getRequiredType ( ) ) ; assertEquals ( ""nameProperty valueConstraints"" , 1 , def . getValueConstraints ( ) . length ) ; assertEquals ( ""nameProperty valueConstraints[0]"" , ""{http://www.apache.org/jackrabbit/test}testName"" , ( def . getValueConstraints ( ) ) [ 0 ] . getString ( ) ) ; assertEquals ( ""nameProperty defaultValues"" , 1 , def . getDefaultValues ( ) . length ) ; assertEquals ( ""nameProperty defaultValues[0]"" , ""test:testName"" , getDefaultValue ( def , 0 ) ) ; } public void testPathProperty ( ) { QPropertyDefinition def = getPropDef ( ""propertyNodeType"" , ""pathProperty"" ) ; assertEquals ( ""pathProperty requiredType"" , PropertyType . PATH , def . getRequiredType ( ) ) ; assertEquals ( ""pathProperty valueConstraints"" , 1 , def . getValueConstraints ( ) . length ) ; assertEquals ( ""pathProperty valueConstraints[0]"" , ""{}\t{http://www.apache.org/jackrabbit/test}testPath"" , ( def . getValueConstraints ( ) ) [ 0 ] . getString ( ) ) ; assertNull ( ""pathProperty defaultValues"" , def . getDefaultValues ( ) ) ; } public void testPathProperty1 ( ) { QPropertyDefinition def = getPropDef ( ""propertyNodeType"" , ""pathProperty1"" ) ; assertEquals ( ""pathProperty requiredType"" , PropertyType . PATH , def . getRequiredType ( ) ) ; assertEquals ( ""pathProperty valueConstraints"" , 1 , def . getValueConstraints ( ) . length ) ; assertEquals ( ""pathProperty valueConstraints[0]"" , ""{}\t{http://www.apache.org/jackrabbit/test}testPath\t{}*"" , ( def . getValueConstraints ( ) ) [ 0 ] . getString ( ) ) ; assertNull ( ""pathProperty defaultValues"" , def . getDefaultValues ( ) ) ; } public void testPathProperty2 ( ) { QPropertyDefinition def = getPropDef ( ""propertyNodeType"" , ""pathProperty2"" ) ; assertEquals ( ""pathProperty requiredType"" , PropertyType . PATH , def . getRequiredType ( ) ) ; assertEquals ( ""pathProperty valueConstraints"" , 1 , def . getValueConstraints ( ) . length ) ; assertEquals ( ""pathProperty valueConstraints[0]"" , ""{http://www.apache.org/jackrabbit/test}testPath\t{}*"" , ( def . getValueConstraints ( ) ) [ 0 ] . getString ( ) ) ; assertNull ( ""pathProperty defaultValues"" , def . getDefaultValues ( ) ) ; } public void testReferenceProperty ( ) { QPropertyDefinition def = getPropDef ( ""propertyNodeType"" , ""referenceProperty"" ) ; assertEquals ( ""referenceProperty requiredType"" , PropertyType . REFERENCE , def . getRequiredType ( ) ) ; assertEquals ( ""referenceProperty valueConstraints"" , 1 , def . getValueConstraints ( ) . length ) ; assertEquals ( ""referenceProperty valueConstraints[0]"" , ""{http://www.jcp.org/jcr/nt/1.0}base"" , ( def . getValueConstraints ( ) ) [ 0 ] . getString ( ) ) ; assertNull ( ""referenceProperty defaultValues"" , def . getDefaultValues ( ) ) ; } public void testStringProperty ( ) { QPropertyDefinition def = getPropDef ( ""propertyNodeType"" , ""stringProperty"" ) ; assertEquals ( ""stringProperty requiredType"" , PropertyType . STRING , def . getRequiredType ( ) ) ; assertEquals ( ""stringProperty valueConstraints"" , 1 , def . getValueConstraints ( ) . length ) ; assertEquals ( ""stringProperty valueConstraints[0]"" , ""bananas?"" , ( def . getValueConstraints ( ) ) [ 0 ] . getString ( ) ) ; assertEquals ( ""stringProperty defaultValues"" , 2 , def . getDefaultValues ( ) . length ) ; assertEquals ( ""stringProperty defaultValues[0]"" , ""banana"" , getDefaultValue ( def , 0 ) ) ; assertEquals ( ""stringProperty defaultValues[1]"" , ""bananas"" , getDefaultValue ( def , 1 ) ) ; } public void testMultipleProperty ( ) { QPropertyDefinition def = getPropDef ( ""propertyNodeType"" , ""multipleProperty"" ) ; assertEquals ( ""multipleProperty multiple"" , true , def . isMultiple ( ) ) ; } public void testChildNodeType ( ) { QNodeTypeDefinition def = getNodeType ( ""childNodeType"" ) ; assertEquals ( ""childNodeType childNodeDefs"" , 4 , def . getChildNodeDefs ( ) . length ) ; } public void testEmptyNode ( ) { QNodeDefinition def = getChildNode ( ""childNodeType"" , ""emptyNode"" ) ; assertEquals ( ""emptyNode allowsSameNameSiblings"" , false , def . allowsSameNameSiblings ( ) ) ; assertEquals ( ""emptyNode defaultPrimaryType"" , null , def . getDefaultPrimaryType ( ) ) ; } public void testSiblingNode ( ) { QNodeDefinition def = getChildNode ( ""childNodeType"" , ""siblingNode"" ) ; assertEquals ( ""siblingNode allowsSameNameSiblings"" , true , def . allowsSameNameSiblings ( ) ) ; } public void testDefaultTypeNode ( ) { QNodeDefinition def = getChildNode ( ""childNodeType"" , ""defaultTypeNode"" ) ; assertEquals ( ""defaultTypeNode defaultPrimaryType"" , FACTORY . create ( Name . NS_NT_URI , ""base"" ) , def . getDefaultPrimaryType ( ) ) ; } public void testRequiredTypeNode ( ) { QNodeDefinition def = getChildNode ( ""childNodeType"" , ""requiredTypeNode"" ) ; assertEquals ( ""requiredTypeNode requiredPrimaryTypes"" , 2 , def . getRequiredPrimaryTypes ( ) . length ) ; Name [ ] types = def . getRequiredPrimaryTypes ( ) ; Arrays . sort ( types ) ; assertEquals ( ""requiredTypeNode requiredPrimaryTypes[0]"" , FACTORY . create ( Name . NS_NT_URI , ""base"" ) , types [ 0 ] ) ; assertEquals ( ""requiredTypeNode requiredPrimaryTypes[1]"" , FACTORY . create ( Name . NS_NT_URI , ""unstructured"" ) , types [ 1 ] ) ; } public void testWrite ( ) throws IOException , RepositoryException { try { ByteArrayOutputStream xml = new ByteArrayOutputStream ( ) ; NodeTypeWriter . write ( xml , types , registry ) ; byte [ ] bytes = xml . toByteArray ( ) ; QNodeTypeDefinition [ ] output = NodeTypeReader . read ( new ByteArrayInputStream ( bytes ) ) ; assertTrue ( ""write output"" , Arrays . equals ( types , output ) ) ; } catch ( InvalidNodeTypeDefException e ) { fail ( e . getMessage ( ) ) ; } } }",Smelly
"public class Banner { private static final String eol = System . getProperty ( ""line.separator"" ) ; public static String encode ( String raw ) { raw = raw . replace ( ""\r\n"" , ""\n"" ) . replace ( ""\r"" , ""\n"" ) ; StringBuilder encoded = new StringBuilder ( ) ; int rawlen = raw . length ( ) ; for ( int i = 0 ; i < rawlen ; i ++ ) { char c = raw . charAt ( i ) ; if ( c == '\\' ) { encoded . append ( ""$."" ) ; } else if ( c == '$' ) { encoded . append ( ""$$"" ) ; } else if ( c == '\n' ) { encoded . append ( ""$n"" ) ; } else if ( Character . isDigit ( c ) ) { encoded . append ( c ) ; } else if ( Character . isLetter ( c ) ) { encoded . append ( rot13 ( c ) ) ; } else if ( i < raw . length ( ) - 1 ) { char nc ; boolean done = false ; int count = 0 ; for ( int n = i ; ! done ; n ++ ) { if ( n >= rawlen ) { break ; } nc = raw . charAt ( n ) ; if ( nc != c ) { done = true ; } else { count ++ ; } } if ( count < 3 ) { encoded . append ( c ) ; } else { encoded . append ( ""$"" ) . append ( String . valueOf ( count ) ) . append ( c ) ; i += count - 1 ; } } else { encoded . append ( c ) ; } } return encoded . toString ( ) ; } public static String decode ( String encoded ) { StringBuilder decoded = new StringBuilder ( ) ; int enlen = encoded . length ( ) ; for ( int i = 0 ; i < enlen ; i ++ ) { char c = encoded . charAt ( i ) ; if ( c == '$' ) { char nc = encoded . charAt ( i + 1 ) ; if ( nc == '$' ) { decoded . append ( '$' ) ; i ++ ; } else if ( nc == '.' ) { decoded . append ( '\\' ) ; i ++ ; } else if ( nc == 'n' ) { decoded . append ( eol ) ; i ++ ; } else if ( Character . isDigit ( nc ) ) { int count = 0 ; int nn = i + 1 ; while ( Character . isDigit ( nc ) ) { count = ( count * 10 ) ; count += ( nc - '0' ) ; nc = encoded . charAt ( ++ nn ) ; } for ( int d = 0 ; d < count ; d ++ ) { decoded . append ( nc ) ; } i = nn ; } } else if ( Character . isLetter ( c ) ) { decoded . append ( rot13 ( c ) ) ; } else { decoded . append ( c ) ; } } return decoded . toString ( ) ; } private static char rot13 ( char c ) { if ( ( c >= 'a' ) && ( c <= 'z' ) ) { char dc = c += 13 ; if ( dc > 'z' ) { dc -= 26 ; } return dc ; } else if ( ( c >= 'A' ) && ( c <= 'Z' ) ) { char dc = c += 13 ; if ( dc > 'Z' ) { dc -= 26 ; } return dc ; } else { return c ; } } public static String injectVersion ( String text , String version ) { Pattern pat = Pattern . compile ( ""#{2,}"" ) ; Matcher mat = pat . matcher ( text ) ; StringBuilder ret = new StringBuilder ( ) ; int off = 0 ; while ( mat . find ( off ) ) { ret . append ( text . substring ( off , mat . start ( ) ) ) ; String repl = mat . group ( ) ; ret . append ( StringUtils . center ( version , repl . length ( ) ) ) ; off = mat . end ( ) ; } ret . append ( text . substring ( off ) ) ; return ret . toString ( ) ; } public static String getBanner ( String version ) { String encodedBanner = ""$26 $34_$n$15 /$._$7 /$34 $.$n$14 /`/@),$4 |  Ba"" + "" orunys bs nyy bs gur nycnpnf   |$n$14 |  (~'  __| gbvyvat njnl ba "" + ""gur Ncnpur Nepuvin |$n$6 _,--.$3_/  |$4 $.$5  cebwrpg grnz, V jbhyq y"" + ""vxr gb$3 |$n$4 ,' ,$5 ($3 |$5 $.$5     jrypbzr lbh gb Nepuvin$6 |$"" + ""n$4 |  ($6 $.  /$6 |  $32#  |$n$5 $.  )$._/  ,_/$7 |$36 |$n$5 / /$3 "" + ""( |/$9 |     uggc://nepuvin.ncnpur.bet/     |$n$4 ( |$4 ( |$10 |     hf"" + ""ref@nepuvin.ncnpur.bet$7 |$n$5 $.|$5 $.|$11 $.$34_/$n$n"" ; return injectVersion ( decode ( encodedBanner ) , version ) ; } public static void display ( String version ) { String banner = getBanner ( version ) ; LoggerFactory . getLogger ( Banner . class ) . info ( StringUtils . repeat ( ""_"" , 25 ) + eol + banner ) ; } }",No
"public class HttpsRouteTest extends ContextTestSupport { private static final String NULL_VALUE_MARKER = ContextTestSupport . class . getCanonicalName ( ) ; protected String expectedBody = ""<hello>world!</hello>"" ; protected String pwd = ""changeit"" ; protected Properties originalValues = new Properties ( ) ; @ Override protected void setUp ( ) throws Exception { super . setUp ( ) ; URL trustStoreUrl = this . getClass ( ) . getClassLoader ( ) . getResource ( ""jsse/localhost.ks"" ) ; setSystemProp ( ""javax.net.ssl.trustStore"" , trustStoreUrl . getPath ( ) ) ; } @ Override protected void tearDown ( ) throws Exception { restoreSystemProperties ( ) ; super . tearDown ( ) ; } private void setSystemProp ( String key , String value ) { String originalValue = System . setProperty ( key , value ) ; originalValues . put ( key , originalValue != null ? originalValue : NULL_VALUE_MARKER ) ; } private void restoreSystemProperties ( ) { for ( Object key : originalValues . keySet ( ) ) { Object value = ( String ) originalValues . get ( key ) ; if ( NULL_VALUE_MARKER . equals ( value ) ) { System . getProperties ( ) . remove ( key ) ; } else { System . setProperty ( ( String ) key , ( String ) value ) ; } } } public void testEndpoint ( ) throws Exception { MockEndpoint mockEndpoint = resolveMandatoryEndpoint ( ""mock:a"" , MockEndpoint . class ) ; mockEndpoint . expectedBodiesReceived ( expectedBody ) ; invokeHttpEndpoint ( ) ; mockEndpoint . assertIsSatisfied ( ) ; List < Exchange > list = mockEndpoint . getReceivedExchanges ( ) ; Exchange exchange = list . get ( 0 ) ; assertNotNull ( ""exchange"" , exchange ) ; Message in = exchange . getIn ( ) ; assertNotNull ( ""in"" , in ) ; Map < String , Object > headers = in . getHeaders ( ) ; log . info ( ""Headers: "" + headers ) ; assertTrue ( ""Should be more than one header but was: "" + headers , headers . size ( ) > 0 ) ; } public void testEndpointWithoutHttps ( ) { MockEndpoint mockEndpoint = resolveMandatoryEndpoint ( ""mock:a"" , MockEndpoint . class ) ; try { template . sendBodyAndHeader ( ""jetty:http://localhost:8080/test"" , expectedBody , ""Content-Type"" , ""application/xml"" ) ; fail ( ""expect exception on access to https endpoint via http"" ) ; } catch ( RuntimeCamelException expected ) { } assertTrue ( ""mock endpoint was not called"" , mockEndpoint . getExchanges ( ) . isEmpty ( ) ) ; } public void testHelloEndpoint ( ) throws Exception { ByteArrayOutputStream os = new ByteArrayOutputStream ( ) ; InputStream is = new URL ( ""https://localhost:8080/hello"" ) . openStream ( ) ; int c ; while ( ( c = is . read ( ) ) >= 0 ) { os . write ( c ) ; } String data = new String ( os . toByteArray ( ) ) ; assertEquals ( ""<b>Hello World</b>"" , data ) ; } public void testHelloEndpointWithoutHttps ( ) throws Exception { try { new URL ( ""http://localhost:8080/hello"" ) . openStream ( ) ; fail ( ""expected SocketException on use ot http"" ) ; } catch ( SocketException expected ) { } } protected void invokeHttpEndpoint ( ) throws IOException { template . sendBodyAndHeader ( ""jetty:https://localhost:8080/test"" , expectedBody , ""Content-Type"" , ""application/xml"" ) ; } @ Override protected RouteBuilder createRouteBuilder ( ) throws Exception { return new RouteBuilder ( ) { public void configure ( ) { JettyHttpComponent componentJetty = ( JettyHttpComponent ) context . getComponent ( ""jetty"" ) ; componentJetty . setSslPassword ( pwd ) ; componentJetty . setSslKeyPassword ( pwd ) ; URL keyStoreUrl = this . getClass ( ) . getClassLoader ( ) . getResource ( ""jsse/localhost.ks"" ) ; componentJetty . setKeystore ( keyStoreUrl . getPath ( ) ) ; from ( ""jetty:https://localhost:8080/test"" ) . to ( ""mock:a"" ) ; Processor proc = new Processor ( ) { public void process ( Exchange exchange ) throws Exception { exchange . getOut ( true ) . setBody ( ""<b>Hello World</b>"" ) ; } } ; from ( ""jetty:https://localhost:8080/hello"" ) . process ( proc ) ; } } ; } }",Smelly
"@ SuppressWarnings ( ""serial"" ) public class ActiveMQPrefetchPolicy extends Object implements Serializable { public static final int MAX_PREFETCH_SIZE = Short . MAX_VALUE ; public static final int DEFAULT_QUEUE_PREFETCH = 1000 ; public static final int DEFAULT_QUEUE_BROWSER_PREFETCH = 500 ; public static final int DEFAULT_DURABLE_TOPIC_PREFETCH = 100 ; public static final int DEFAULT_OPTIMIZE_DURABLE_TOPIC_PREFETCH = 1000 ; public static final int DEFAULT_INPUT_STREAM_PREFETCH = 100 ; public static final int DEFAULT_TOPIC_PREFETCH = MAX_PREFETCH_SIZE ; private static final Logger LOG = LoggerFactory . getLogger ( ActiveMQPrefetchPolicy . class ) ; private int queuePrefetch ; private int queueBrowserPrefetch ; private int topicPrefetch ; private int durableTopicPrefetch ; private int optimizeDurableTopicPrefetch ; private int inputStreamPrefetch ; private int maximumPendingMessageLimit ; public ActiveMQPrefetchPolicy ( ) { this . queuePrefetch = DEFAULT_QUEUE_PREFETCH ; this . queueBrowserPrefetch = DEFAULT_QUEUE_BROWSER_PREFETCH ; this . topicPrefetch = DEFAULT_TOPIC_PREFETCH ; this . durableTopicPrefetch = DEFAULT_DURABLE_TOPIC_PREFETCH ; this . optimizeDurableTopicPrefetch = DEFAULT_OPTIMIZE_DURABLE_TOPIC_PREFETCH ; this . inputStreamPrefetch = DEFAULT_INPUT_STREAM_PREFETCH ; } public int getDurableTopicPrefetch ( ) { return durableTopicPrefetch ; } public void setDurableTopicPrefetch ( int durableTopicPrefetch ) { this . durableTopicPrefetch = getMaxPrefetchLimit ( durableTopicPrefetch ) ; } public int getQueuePrefetch ( ) { return queuePrefetch ; } public void setQueuePrefetch ( int queuePrefetch ) { this . queuePrefetch = getMaxPrefetchLimit ( queuePrefetch ) ; } public int getQueueBrowserPrefetch ( ) { return queueBrowserPrefetch ; } public void setQueueBrowserPrefetch ( int queueBrowserPrefetch ) { this . queueBrowserPrefetch = getMaxPrefetchLimit ( queueBrowserPrefetch ) ; } public int getTopicPrefetch ( ) { return topicPrefetch ; } public void setTopicPrefetch ( int topicPrefetch ) { this . topicPrefetch = getMaxPrefetchLimit ( topicPrefetch ) ; } public int getOptimizeDurableTopicPrefetch ( ) { return optimizeDurableTopicPrefetch ; } public void setOptimizeDurableTopicPrefetch ( int optimizeAcknowledgePrefetch ) { this . optimizeDurableTopicPrefetch = optimizeAcknowledgePrefetch ; } public int getMaximumPendingMessageLimit ( ) { return maximumPendingMessageLimit ; } public void setMaximumPendingMessageLimit ( int maximumPendingMessageLimit ) { this . maximumPendingMessageLimit = maximumPendingMessageLimit ; } private int getMaxPrefetchLimit ( int value ) { int result = Math . min ( value , MAX_PREFETCH_SIZE ) ; if ( result < value ) { LOG . warn ( ""maximum prefetch limit has been reset from "" + value + "" to "" + MAX_PREFETCH_SIZE ) ; } return result ; } public void setAll ( int i ) { this . durableTopicPrefetch = i ; this . queueBrowserPrefetch = i ; this . queuePrefetch = i ; this . topicPrefetch = i ; this . inputStreamPrefetch = 1 ; this . optimizeDurableTopicPrefetch = i ; } public int getInputStreamPrefetch ( ) { return inputStreamPrefetch ; } public void setInputStreamPrefetch ( int inputStreamPrefetch ) { this . inputStreamPrefetch = getMaxPrefetchLimit ( inputStreamPrefetch ) ; } public boolean equals ( Object object ) { if ( object instanceof ActiveMQPrefetchPolicy ) { ActiveMQPrefetchPolicy other = ( ActiveMQPrefetchPolicy ) object ; return this . queuePrefetch == other . queuePrefetch && this . queueBrowserPrefetch == other . queueBrowserPrefetch && this . topicPrefetch == other . topicPrefetch && this . durableTopicPrefetch == other . durableTopicPrefetch && this . optimizeDurableTopicPrefetch == other . optimizeDurableTopicPrefetch && this . inputStreamPrefetch == other . inputStreamPrefetch ; } return false ; } }",No
"public class ProxyTransformer extends AbstractTransformer implements Serviceable , Parameterizable { public static String ENVELOPE_TAG_PARAMETER = ""envelope-tag"" ; public static final String PORTALNAME = ""cocoon-portal-portalname"" ; public static final String COPLETID = ""cocoon-portal-copletid"" ; public static final String PROXY_PREFIX = ""proxy-"" ; public static final String COPLET_ID_PARAM = ""copletId"" ; public static final String PORTAL_NAME_PARAM = ""portalName"" ; public static final String SESSIONTOKEN = ""sessiontoken"" ; public static final String COOKIE = ""cookie"" ; public static final String START_URI = ""start-uri"" ; public static final String LINK = ""link"" ; public static final String CONFIG = ""config"" ; public static final String DOCUMENT_BASE = ""documentbase"" ; public static String PROTOCOL_HANDLER_PARAMETER = ""protocol-handler"" ; protected String documentBase ; protected String link ; protected String envelopeTag ; protected ServiceManager manager ; protected CopletInstanceData copletInstanceData ; protected Request request ; protected int configuredEncoding ; protected String userAgent = null ; public void service ( ServiceManager manager ) throws ServiceException { this . manager = manager ; } public void parameterize ( Parameters parameters ) { if ( parameters != null ) { envelopeTag = parameters . getParameter ( ENVELOPE_TAG_PARAMETER , null ) ; String protocolHandler = parameters . getParameter ( PROTOCOL_HANDLER_PARAMETER , null ) ; if ( protocolHandler != null ) { if ( System . getProperty ( ""java.protocol.handler.pkgs"" ) == null ) { System . setProperty ( ""java.protocol.handler.pkgs"" , protocolHandler ) ; } } } } public void setup ( SourceResolver resolver , Map objectModel , String src , Parameters parameters ) throws ProcessingException , SAXException , IOException { request = ObjectModelHelper . getRequest ( objectModel ) ; copletInstanceData = getInstanceData ( this . manager , objectModel , parameters ) ; PortalApplicationConfig pac = ( PortalApplicationConfig ) copletInstanceData . getAttribute ( CONFIG ) ; String startURI = pac . getAttribute ( START_URI ) ; link = ( String ) copletInstanceData . getAttribute ( LINK ) ; documentBase = ( String ) copletInstanceData . getAttribute ( DOCUMENT_BASE ) ; if ( link == null ) { link = startURI ; } if ( documentBase == null ) { documentBase = link . substring ( 0 , link . lastIndexOf ( '/' ) + 1 ) ; copletInstanceData . setAttribute ( DOCUMENT_BASE , documentBase ) ; } String encodingString = pac . getAttribute ( ""encoding"" ) ; configuredEncoding = encodingConstantFromString ( encodingString ) ; userAgent = pac . getAttribute ( ""user-agent"" ) ; envelopeTag = parameters . getParameter ( ""envelope-tag"" , envelopeTag ) ; if ( envelopeTag == null ) { throw new ProcessingException ( ""Can not initialize RSFHtmlTransformer - sitemap parameter envelope-tag missing"" ) ; } String protocolHandler = parameters . getParameter ( PROTOCOL_HANDLER_PARAMETER , null ) ; if ( protocolHandler != null ) { System . setProperty ( ""java.protocol.handler.pkgs"" , protocolHandler ) ; } } public void startElement ( String uri , String name , String raw , Attributes attributes ) throws SAXException { super . startElement ( uri , name , raw , attributes ) ; if ( name . equalsIgnoreCase ( this . envelopeTag ) ) { processRequest ( ) ; } } protected void processRequest ( ) throws SAXException { try { String remoteURI = null ; try { remoteURI = resolveURI ( link , documentBase ) ; } catch ( MalformedURLException ex ) { throw new SAXException ( ex ) ; } StringBuffer query = new StringBuffer ( ) ; boolean firstparameter = true ; Enumeration enumeration = request . getParameterNames ( ) ; boolean post = ( ""POST"" . equals ( request . getMethod ( ) ) ) ; while ( enumeration . hasMoreElements ( ) ) { String paramName = ( String ) enumeration . nextElement ( ) ; if ( ! paramName . startsWith ( ""cocoon-portal-"" ) ) { String [ ] paramValues = request . getParameterValues ( paramName ) ; for ( int i = 0 ; i < paramValues . length ; i ++ ) { if ( firstparameter ) { if ( ! post ) { query . append ( '?' ) ; } firstparameter = false ; } else { query . append ( '&' ) ; } query . append ( NetUtils . encode ( paramName , ""utf-8"" ) ) ; query . append ( '=' ) ; query . append ( NetUtils . encode ( paramValues [ i ] , ""utf-8"" ) ) ; } } } Document result = null ; try { do { HttpURLConnection connection = connect ( request , remoteURI , query . toString ( ) , post ) ; remoteURI = checkForRedirect ( connection , documentBase ) ; if ( remoteURI == null ) { result = readXML ( connection ) ; remoteURI = checkForRedirect ( result , documentBase ) ; } } while ( remoteURI != null ) ; } catch ( IOException ex ) { throw new SAXException ( ""Failed to retrieve remoteURI "" + remoteURI , ex ) ; } XMLUtils . stripDuplicateAttributes ( result , null ) ; DOMStreamer streamer = new DOMStreamer ( ) ; streamer . setContentHandler ( contentHandler ) ; streamer . stream ( result . getDocumentElement ( ) ) ; } catch ( SAXException se ) { throw se ; } catch ( Exception ex ) { throw new SAXException ( ex ) ; } } protected String checkForRedirect ( HttpURLConnection connection , String documentBase ) throws IOException { if ( connection . getResponseCode ( ) == HttpURLConnection . HTTP_MOVED_PERM || connection . getResponseCode ( ) == HttpURLConnection . HTTP_MOVED_TEMP ) { String newURI = ( connection . getHeaderField ( ""location"" ) ) ; int index_semikolon = newURI . indexOf ( "";"" ) ; int index_question = newURI . indexOf ( ""?"" ) ; if ( ( index_semikolon > - 1 ) ) { String sessionToken = newURI . substring ( index_semikolon + 1 , ( index_question == - 1 ? newURI . length ( ) : index_question ) ) ; this . copletInstanceData . getPersistentAspectData ( ) . put ( SESSIONTOKEN , sessionToken ) ; } if ( newURI != null ) { newURI = resolveURI ( newURI , documentBase ) ; } return newURI ; } return null ; } protected String checkForRedirect ( Document doc , String documentBase ) throws MalformedURLException { Element htmlElement = doc . getDocumentElement ( ) ; NodeList headList = htmlElement . getElementsByTagName ( ""head"" ) ; if ( headList . getLength ( ) <= 0 ) { return null ; } Element headElement = ( Element ) headList . item ( 0 ) ; NodeList metaList = headElement . getElementsByTagName ( ""meta"" ) ; for ( int i = 0 ; i < metaList . getLength ( ) ; i ++ ) { Element metaElement = ( Element ) metaList . item ( i ) ; String httpEquiv = metaElement . getAttribute ( ""http-equiv"" ) ; if ( ""refresh"" . equalsIgnoreCase ( httpEquiv ) ) { String content = metaElement . getAttribute ( ""content"" ) ; if ( content != null ) { String time = content . substring ( 0 , content . indexOf ( ';' ) ) ; try { if ( Integer . parseInt ( time ) > 10 ) { getLogger ( ) . warn ( ""Redirects with refresh time longer than 10 seconds ("" + time + "" seconds) will be ignored!"" ) ; return null ; } } catch ( NumberFormatException ex ) { getLogger ( ) . warn ( ""Failed to convert refresh time from redirect to integer: "" + time ) ; return null ; } String newURI = content . substring ( content . indexOf ( '=' ) + 1 ) ; int index_semikolon = newURI . indexOf ( "";"" ) ; int index_question = newURI . indexOf ( ""?"" ) ; if ( ( index_semikolon > - 1 ) ) { String sessionToken = newURI . substring ( index_semikolon + 1 , ( index_question == - 1 ? newURI . length ( ) : index_question ) ) ; this . copletInstanceData . getPersistentAspectData ( ) . put ( SESSIONTOKEN , sessionToken ) ; } if ( newURI != null ) { newURI = resolveURI ( newURI , documentBase ) ; } return newURI ; } } } return null ; } protected Document readXML ( HttpURLConnection connection ) throws SAXException { try { int charEncoding = configuredEncoding ; String contentType = connection . getHeaderField ( ""Content-Type"" ) ; int begin = contentType . indexOf ( ""charset="" ) ; int end = - 1 ; if ( begin > - 1 ) { begin += ""charset="" . length ( ) ; end = contentType . indexOf ( ';' , begin ) ; if ( end == - 1 ) { end = contentType . length ( ) ; } String charset = contentType . substring ( begin , end ) ; charEncoding = encodingConstantFromString ( charset ) ; } InputStream stream = connection . getInputStream ( ) ; Tidy tidy = new Tidy ( ) ; tidy . setXmlOut ( true ) ; tidy . setCharEncoding ( charEncoding ) ; tidy . setXHTML ( true ) ; tidy . setShowWarnings ( this . getLogger ( ) . isWarnEnabled ( ) ) ; tidy . setQuiet ( ! this . getLogger ( ) . isInfoEnabled ( ) ) ; StringWriter stringWriter = new StringWriter ( ) ; PrintWriter errorWriter = new PrintWriter ( stringWriter ) ; tidy . setErrout ( errorWriter ) ; Document doc = tidy . parseDOM ( new BufferedInputStream ( stream ) , null ) ; errorWriter . flush ( ) ; errorWriter . close ( ) ; return doc ; } catch ( Exception ex ) { throw new SAXException ( ex ) ; } } private int encodingConstantFromString ( String encoding ) { if ( ""ISO8859_1"" . equalsIgnoreCase ( encoding ) ) { return Configuration . LATIN1 ; } else if ( ""UTF-8"" . equalsIgnoreCase ( encoding ) ) { return Configuration . UTF8 ; } else { return Configuration . LATIN1 ; } } protected HttpURLConnection connect ( Request request , String uri , String query , boolean post ) throws IOException { String cookie = ( String ) copletInstanceData . getAttribute ( COOKIE ) ; if ( ! post ) { uri = uri + query ; } URL url = new URL ( uri ) ; HttpURLConnection connection = ( HttpURLConnection ) url . openConnection ( ) ; connection . setInstanceFollowRedirects ( false ) ; connection . setRequestMethod ( request . getMethod ( ) ) ; connection . setRequestProperty ( ""User-Agent"" , ( userAgent != null ) ? userAgent : request . getHeader ( ""User-Agent"" ) ) ; connection . setRequestProperty ( ""Accept-Language"" , request . getHeader ( ""Accept-Language"" ) ) ; if ( cookie != null ) { connection . setRequestProperty ( COOKIE , cookie ) ; } if ( post ) { connection . setDoOutput ( true ) ; connection . setRequestProperty ( ""Content-Type"" , ""application/x-www-form-urlencoded"" ) ; connection . setRequestProperty ( ""Content-Length"" , String . valueOf ( query . length ( ) ) ) ; } connection . connect ( ) ; if ( post ) { PrintWriter out = new PrintWriter ( connection . getOutputStream ( ) ) ; out . print ( query ) ; out . close ( ) ; } copletInstanceData . setAttribute ( COOKIE , connection . getHeaderField ( COOKIE ) ) ; documentBase = uri . substring ( 0 , uri . lastIndexOf ( '/' ) + 1 ) ; copletInstanceData . setAttribute ( DOCUMENT_BASE , documentBase ) ; return connection ; } public static String resolveURI ( String uri , String documentBase ) throws MalformedURLException { if ( uri . indexOf ( ""://"" ) > - 1 ) { return uri ; } if ( uri == null ) { throw new IllegalArgumentException ( ""URI to be resolved must not be null!"" ) ; } if ( documentBase == null ) { throw new IllegalArgumentException ( ""Documentbase String must not be null!"" ) ; } if ( uri . startsWith ( ""./"" ) ) { uri = uri . substring ( 2 ) ; } URL documentBaseURL = new URL ( documentBase ) ; if ( uri . startsWith ( ""/"" ) ) { return documentBaseURL . getProtocol ( ) + ""://"" + documentBaseURL . getAuthority ( ) + uri ; } else { return documentBaseURL . toExternalForm ( ) + uri ; } } public static CopletInstanceData getInstanceData ( ServiceManager manager , String copletID , String portalName ) throws ProcessingException { PortalService portalService = null ; try { portalService = ( PortalService ) manager . lookup ( PortalService . ROLE ) ; portalService . setPortalName ( portalName ) ; ProfileManager profileManager = portalService . getComponentManager ( ) . getProfileManager ( ) ; CopletInstanceData data = profileManager . getCopletInstanceData ( copletID ) ; return data ; } catch ( ServiceException e ) { throw new ProcessingException ( ""Error getting portal service."" , e ) ; } finally { manager . release ( portalService ) ; } } public static CopletInstanceData getInstanceData ( ServiceManager manager , Map objectModel , Parameters parameters ) throws ProcessingException { PortalService portalService = null ; try { portalService = ( PortalService ) manager . lookup ( PortalService . ROLE ) ; String copletId = null ; Map context = ( Map ) objectModel . get ( ObjectModelHelper . PARENT_CONTEXT ) ; if ( context != null ) { copletId = ( String ) context . get ( Constants . COPLET_ID_KEY ) ; if ( copletId == null ) { throw new ProcessingException ( ""copletId must be passed as parameter or in the object model within the parent context."" ) ; } } else { try { copletId = parameters . getParameter ( COPLET_ID_PARAM ) ; portalService . setPortalName ( parameters . getParameter ( PORTAL_NAME_PARAM ) ) ; } catch ( ParameterException e ) { throw new ProcessingException ( ""copletId and portalName must be passed as parameter or in the object model within the parent context."" ) ; } } return portalService . getComponentManager ( ) . getProfileManager ( ) . getCopletInstanceData ( copletId ) ; } catch ( ServiceException e ) { throw new ProcessingException ( ""Error getting portal service."" , e ) ; } finally { manager . release ( portalService ) ; } } }",Smelly
"public class AmqpNioTest extends AmqpTestSupport { protected void addAMQPConnector ( BrokerService brokerService ) throws Exception { brokerService . addConnector ( ""amqp+nio://localhost:1883?maxInactivityDuration=-1"" ) ; } }",No
 private static class ConstGetObjectIdExpState extends ConstExpState { public final ExpState constantState ; public Object sqlValue = null ; public int otherLength = 0 ; public ConstGetObjectIdExpState ( ExpState constantState ) { this . constantState = constantState ; } } ,No
"public class ProcessGroupEndpointMerger extends AbstractSingleEntityEndpoint < ProcessGroupEntity > implements EndpointResponseMerger { public static final Pattern PROCESS_GROUP_URI_PATTERN = Pattern . compile ( ""/nifi-api/process-groups/(?:(?:root)|(?:[a-f0-9\\-]{36}))"" ) ; public static final Pattern CONTROLLER_ARCHIVE_URI_PATTERN = Pattern . compile ( ""/nifi-api/controller/archive"" ) ; private ProcessGroupEntityMerger processGroupEntityMerger = new ProcessGroupEntityMerger ( ) ; @ Override public boolean canHandle ( final URI uri , final String method ) { if ( ""GET"" . equalsIgnoreCase ( method ) && ( PROCESS_GROUP_URI_PATTERN . matcher ( uri . getPath ( ) ) . matches ( ) || CONTROLLER_ARCHIVE_URI_PATTERN . matcher ( uri . getPath ( ) ) . matches ( ) ) ) { return true ; } else if ( ""PUT"" . equalsIgnoreCase ( method ) && PROCESS_GROUP_URI_PATTERN . matcher ( uri . getPath ( ) ) . matches ( ) ) { return true ; } return false ; } @ Override protected Class < ProcessGroupEntity > getEntityClass ( ) { return ProcessGroupEntity . class ; } @ Override protected void mergeResponses ( ProcessGroupEntity clientEntity , Map < NodeIdentifier , ProcessGroupEntity > entityMap , Set < NodeResponse > successfulResponses , Set < NodeResponse > problematicResponses ) { processGroupEntityMerger . merge ( clientEntity , entityMap ) ; } }",No
"public class ReverseEngineeringConfigPanel extends JPanel { private static final String DATA_FIELDS_LAYOUT = ""right:pref, 3dlu, fill:235dlu"" ; private JComboBox < String > strategyCombo ; private TextAdapter meaningfulPk ; private TextAdapter stripFromTableNames ; private JCheckBox skipRelationshipsLoading ; private JCheckBox skipPrimaryKeyLoading ; private JCheckBox forceDataMapCatalog ; private JCheckBox forceDataMapSchema ; private JCheckBox usePrimitives ; private JCheckBox useJava7Types ; private ProjectController projectController ; ReverseEngineeringConfigPanel ( ProjectController projectController ) { this . projectController = projectController ; initFormElements ( ) ; initListeners ( ) ; buildView ( ) ; } private void buildView ( ) { FormLayout panelLayout = new FormLayout ( DATA_FIELDS_LAYOUT ) ; DefaultFormBuilder panelBuilder = new DefaultFormBuilder ( panelLayout ) ; panelBuilder . setDefaultDialogBorder ( ) ; panelBuilder . append ( ""Tables with Meaningful PK Pattern:"" , meaningfulPk . getComponent ( ) ) ; panelBuilder . append ( ""Strip from table names:"" , stripFromTableNames . getComponent ( ) ) ; panelBuilder . append ( ""Skip relationships loading:"" , skipRelationshipsLoading ) ; panelBuilder . append ( ""Skip primary key loading:"" , skipPrimaryKeyLoading ) ; panelBuilder . append ( ""Force datamap catalog:"" , forceDataMapCatalog ) ; panelBuilder . append ( ""Force datamap schema:"" , forceDataMapSchema ) ; panelBuilder . append ( ""Use Java primitive types:"" , usePrimitives ) ; panelBuilder . append ( ""Use java.util.Date type:"" , useJava7Types ) ; panelBuilder . append ( ""Naming strategy:"" , strategyCombo ) ; add ( panelBuilder . getPanel ( ) ) ; } void fillCheckboxes ( ReverseEngineering reverseEngineering ) { skipRelationshipsLoading . setSelected ( reverseEngineering . getSkipRelationshipsLoading ( ) ) ; skipPrimaryKeyLoading . setSelected ( reverseEngineering . getSkipPrimaryKeyLoading ( ) ) ; forceDataMapCatalog . setSelected ( reverseEngineering . isForceDataMapCatalog ( ) ) ; forceDataMapSchema . setSelected ( reverseEngineering . isForceDataMapSchema ( ) ) ; usePrimitives . setSelected ( reverseEngineering . isUsePrimitives ( ) ) ; useJava7Types . setSelected ( reverseEngineering . isUseJava7Types ( ) ) ; } void initializeTextFields ( ReverseEngineering reverseEngineering ) { meaningfulPk . setText ( reverseEngineering . getMeaningfulPkTables ( ) ) ; stripFromTableNames . setText ( reverseEngineering . getStripFromTableNames ( ) ) ; } private ReverseEngineering getReverseEngineeringBySelectedMap ( ) { DataMap dataMap = projectController . getCurrentDataMap ( ) ; return projectController . getApplication ( ) . getMetaData ( ) . get ( dataMap , ReverseEngineering . class ) ; } void initStrategy ( ReverseEngineering reverseEngineering ) { Vector < String > arr = NameGeneratorPreferences . getInstance ( ) . getLastUsedStrategies ( ) ; strategyCombo . setModel ( new DefaultComboBoxModel < > ( arr ) ) ; strategyCombo . setSelectedItem ( reverseEngineering . getNamingStrategy ( ) ) ; } private void initFormElements ( ) { strategyCombo = Application . getWidgetFactory ( ) . createComboBox ( ) ; AutoCompletion . enable ( strategyCombo , false , true ) ; strategyCombo . setToolTipText ( ""Naming strategy to use"" ) ; JTextField meaningfulPkField = new JTextField ( ) ; meaningfulPkField . setToolTipText ( ""<html>Regular expression to filter tables with meaningful primary keys.<br>"" + ""Multiple expressions divided by comma can be used.<br>"" + ""Example: <b>^table1|^table2|^prefix.*|table_name</b></html>"" ) ; meaningfulPk = new TextAdapter ( meaningfulPkField ) { protected void updateModel ( String text ) { getReverseEngineeringBySelectedMap ( ) . setMeaningfulPkTables ( text ) ; projectController . setDirty ( true ) ; } } ; JTextField stripFromTableNamesField = new JTextField ( ) ; stripFromTableNamesField . setToolTipText ( ""<html>Regex that matches the part of the table name that needs to be stripped off "" + ""when generating ObjEntity name</html>"" ) ; stripFromTableNames = new TextAdapter ( stripFromTableNamesField ) { protected void updateModel ( String text ) { getReverseEngineeringBySelectedMap ( ) . setStripFromTableNames ( text ) ; projectController . setDirty ( true ) ; } } ; skipRelationshipsLoading = new JCheckBox ( ) ; skipRelationshipsLoading . setToolTipText ( ""<html>Whether to load relationships.</html>"" ) ; skipPrimaryKeyLoading = new JCheckBox ( ) ; skipPrimaryKeyLoading . setToolTipText ( ""<html>Whether to load primary keys.</html>"" ) ; forceDataMapCatalog = new JCheckBox ( ) ; forceDataMapCatalog . setToolTipText ( ""<html>Automatically tagging each DbEntity with the actual DB catalog/schema"" + ""(default behavior) may sometimes be undesirable.<br>  If this is the case then setting <b>forceDataMapCatalog</b> "" + ""to <b>true</b> will set DbEntity catalog to one in the DataMap.</html>"" ) ; forceDataMapSchema = new JCheckBox ( ) ; forceDataMapSchema . setToolTipText ( ""<html>Automatically tagging each DbEntity with the actual DB catalog/schema "" + ""(default behavior) may sometimes be undesirable.<br> If this is the case then setting <b>forceDataMapSchema</b> "" + ""to <b>true</b> will set DbEntity schema to one in the DataMap.</html>"" ) ; useJava7Types = new JCheckBox ( ) ; useJava7Types . setToolTipText ( ""<html>Use <b>java.util.Date</b> for all columns with <i>DATE/TIME/TIMESTAMP</i> types.<br>"" + ""By default <b>java.time.*</b> types will be used.</html>"" ) ; usePrimitives = new JCheckBox ( ) ; usePrimitives . setToolTipText ( ""<html>Use primitive types (e.g. int) or Object types (e.g. java.lang.Integer)</html>"" ) ; } private void initListeners ( ) { skipRelationshipsLoading . addActionListener ( e -> { getReverseEngineeringBySelectedMap ( ) . setSkipRelationshipsLoading ( skipRelationshipsLoading . isSelected ( ) ) ; projectController . setDirty ( true ) ; } ) ; skipPrimaryKeyLoading . addActionListener ( e -> { getReverseEngineeringBySelectedMap ( ) . setSkipPrimaryKeyLoading ( skipPrimaryKeyLoading . isSelected ( ) ) ; projectController . setDirty ( true ) ; } ) ; forceDataMapCatalog . addActionListener ( e -> { getReverseEngineeringBySelectedMap ( ) . setForceDataMapCatalog ( forceDataMapCatalog . isSelected ( ) ) ; projectController . setDirty ( true ) ; } ) ; forceDataMapSchema . addActionListener ( e -> { getReverseEngineeringBySelectedMap ( ) . setForceDataMapSchema ( forceDataMapSchema . isSelected ( ) ) ; projectController . setDirty ( true ) ; } ) ; usePrimitives . addActionListener ( e -> { getReverseEngineeringBySelectedMap ( ) . setUsePrimitives ( usePrimitives . isSelected ( ) ) ; projectController . setDirty ( true ) ; } ) ; useJava7Types . addActionListener ( e -> { getReverseEngineeringBySelectedMap ( ) . setUseJava7Types ( useJava7Types . isSelected ( ) ) ; projectController . setDirty ( true ) ; } ) ; strategyCombo . addActionListener ( e -> { String strategy = ( String ) ReverseEngineeringConfigPanel . this . getStrategyCombo ( ) . getSelectedItem ( ) ; checkStrategy ( strategy ) ; getReverseEngineeringBySelectedMap ( ) . setNamingStrategy ( strategy ) ; NameGeneratorPreferences . getInstance ( ) . addToLastUsedStrategies ( strategy ) ; projectController . setDirty ( true ) ; } ) ; } private void checkStrategy ( String strategy ) { try { Thread . currentThread ( ) . getContextClassLoader ( ) . loadClass ( strategy ) ; } catch ( Exception ex ) { JOptionPane . showMessageDialog ( this , strategy + "" not found. Please, add naming strategy to classpath."" , ""Error"" , JOptionPane . WARNING_MESSAGE ) ; } } JComboBox < String > getStrategyCombo ( ) { return strategyCombo ; } TextAdapter getMeaningfulPk ( ) { return meaningfulPk ; } TextAdapter getStripFromTableNames ( ) { return stripFromTableNames ; } JCheckBox getSkipRelationshipsLoading ( ) { return skipRelationshipsLoading ; } JCheckBox getSkipPrimaryKeyLoading ( ) { return skipPrimaryKeyLoading ; } JCheckBox getForceDataMapCatalog ( ) { return forceDataMapCatalog ; } JCheckBox getForceDataMapSchema ( ) { return forceDataMapSchema ; } JCheckBox getUsePrimitives ( ) { return usePrimitives ; } JCheckBox getUseJava7Types ( ) { return useJava7Types ; } }",No
"public class Parser implements Constants , ContentHandler { private static final String XSL = ""xsl"" ; private static final String TRANSLET = ""translet"" ; private Locator _locator = null ; private XSLTC _xsltc ; private XPathParser _xpathParser ; private Vector _errors ; private Vector _warnings ; private Hashtable _instructionClasses ; private Hashtable _instructionAttrs ; ; private Hashtable _qNames ; private Hashtable _namespaces ; private QName _useAttributeSets ; private QName _excludeResultPrefixes ; private QName _extensionElementPrefixes ; private Hashtable _variableScope ; private Stylesheet _currentStylesheet ; private SymbolTable _symbolTable ; private Output _output ; private Template _template ; private boolean _rootNamespaceDef ; private SyntaxTreeNode _root ; private String _target ; private int _currentImportPrecedence ; public Parser ( XSLTC xsltc ) { _xsltc = xsltc ; } public void init ( ) { _qNames = new Hashtable ( 512 ) ; _namespaces = new Hashtable ( ) ; _instructionClasses = new Hashtable ( ) ; _instructionAttrs = new Hashtable ( ) ; _variableScope = new Hashtable ( ) ; _template = null ; _errors = new Vector ( ) ; _warnings = new Vector ( ) ; _symbolTable = new SymbolTable ( ) ; _xpathParser = new XPathParser ( this ) ; _currentStylesheet = null ; _output = null ; _root = null ; _rootNamespaceDef = false ; _currentImportPrecedence = 1 ; initStdClasses ( ) ; initInstructionAttrs ( ) ; initExtClasses ( ) ; initSymbolTable ( ) ; _useAttributeSets = getQName ( XSLT_URI , XSL , ""use-attribute-sets"" ) ; _excludeResultPrefixes = getQName ( XSLT_URI , XSL , ""exclude-result-prefixes"" ) ; _extensionElementPrefixes = getQName ( XSLT_URI , XSL , ""extension-element-prefixes"" ) ; } public void setOutput ( Output output ) { if ( _output != null ) { if ( _output . getImportPrecedence ( ) <= output . getImportPrecedence ( ) ) { String cdata = _output . getCdata ( ) ; output . mergeOutput ( _output ) ; _output . disable ( ) ; _output = output ; } else { output . disable ( ) ; } } else { _output = output ; } } public Output getOutput ( ) { return _output ; } public Properties getOutputProperties ( ) { return getTopLevelStylesheet ( ) . getOutputProperties ( ) ; } public void addVariable ( Variable var ) { addVariableOrParam ( var ) ; } public void addParameter ( Param param ) { addVariableOrParam ( param ) ; } private void addVariableOrParam ( VariableBase var ) { Object existing = _variableScope . get ( var . getName ( ) ) ; if ( existing != null ) { if ( existing instanceof Stack ) { Stack stack = ( Stack ) existing ; stack . push ( var ) ; } else if ( existing instanceof VariableBase ) { Stack stack = new Stack ( ) ; stack . push ( existing ) ; stack . push ( var ) ; _variableScope . put ( var . getName ( ) , stack ) ; } } else { _variableScope . put ( var . getName ( ) , var ) ; } } public void removeVariable ( QName name ) { Object existing = _variableScope . get ( name ) ; if ( existing instanceof Stack ) { Stack stack = ( Stack ) existing ; if ( ! stack . isEmpty ( ) ) stack . pop ( ) ; if ( ! stack . isEmpty ( ) ) return ; } _variableScope . remove ( name ) ; } public VariableBase lookupVariable ( QName name ) { Object existing = _variableScope . get ( name ) ; if ( existing instanceof VariableBase ) { return ( ( VariableBase ) existing ) ; } else if ( existing instanceof Stack ) { Stack stack = ( Stack ) existing ; return ( ( VariableBase ) stack . peek ( ) ) ; } return ( null ) ; } public void setXSLTC ( XSLTC xsltc ) { _xsltc = xsltc ; } public XSLTC getXSLTC ( ) { return _xsltc ; } public int getCurrentImportPrecedence ( ) { return _currentImportPrecedence ; } public int getNextImportPrecedence ( ) { return ++ _currentImportPrecedence ; } public void setCurrentStylesheet ( Stylesheet stylesheet ) { _currentStylesheet = stylesheet ; } public Stylesheet getCurrentStylesheet ( ) { return _currentStylesheet ; } public Stylesheet getTopLevelStylesheet ( ) { return _xsltc . getStylesheet ( ) ; } public QName getQNameSafe ( final String stringRep ) { final int colon = stringRep . lastIndexOf ( ':' ) ; if ( colon != - 1 ) { final String prefix = stringRep . substring ( 0 , colon ) ; final String localname = stringRep . substring ( colon + 1 ) ; String namespace = null ; if ( prefix . equals ( XMLNS_PREFIX ) == false ) { namespace = _symbolTable . lookupNamespace ( prefix ) ; if ( namespace == null ) namespace = EMPTYSTRING ; } return getQName ( namespace , prefix , localname ) ; } else { final String uri = stringRep . equals ( XMLNS_PREFIX ) ? null : _symbolTable . lookupNamespace ( EMPTYSTRING ) ; return getQName ( uri , null , stringRep ) ; } } public QName getQName ( final String stringRep ) { return getQName ( stringRep , true , false ) ; } public QName getQNameIgnoreDefaultNs ( final String stringRep ) { return getQName ( stringRep , true , true ) ; } public QName getQName ( final String stringRep , boolean reportError ) { return getQName ( stringRep , reportError , false ) ; } private QName getQName ( final String stringRep , boolean reportError , boolean ignoreDefaultNs ) { final int colon = stringRep . lastIndexOf ( ':' ) ; if ( colon != - 1 ) { final String prefix = stringRep . substring ( 0 , colon ) ; final String localname = stringRep . substring ( colon + 1 ) ; String namespace = null ; if ( prefix . equals ( XMLNS_PREFIX ) == false ) { namespace = _symbolTable . lookupNamespace ( prefix ) ; if ( namespace == null && reportError ) { final int line = getLineNumber ( ) ; ErrorMsg err = new ErrorMsg ( ErrorMsg . NAMESPACE_UNDEF_ERR , line , prefix ) ; reportError ( ERROR , err ) ; } } return getQName ( namespace , prefix , localname ) ; } else { if ( stringRep . equals ( XMLNS_PREFIX ) ) { ignoreDefaultNs = true ; } final String defURI = ignoreDefaultNs ? null : _symbolTable . lookupNamespace ( EMPTYSTRING ) ; return getQName ( defURI , null , stringRep ) ; } } public QName getQName ( String namespace , String prefix , String localname ) { if ( namespace == null || namespace . equals ( EMPTYSTRING ) ) { QName name = ( QName ) _qNames . get ( localname ) ; if ( name == null ) { name = new QName ( null , prefix , localname ) ; _qNames . put ( localname , name ) ; } return name ; } else { Dictionary space = ( Dictionary ) _namespaces . get ( namespace ) ; if ( space == null ) { final QName name = new QName ( namespace , prefix , localname ) ; _namespaces . put ( namespace , space = new Hashtable ( ) ) ; space . put ( localname , name ) ; return name ; } else { QName name = ( QName ) space . get ( localname ) ; if ( name == null ) { name = new QName ( namespace , prefix , localname ) ; space . put ( localname , name ) ; } return name ; } } } public QName getQName ( String scope , String name ) { return getQName ( scope + name ) ; } public QName getQName ( QName scope , QName name ) { return getQName ( scope . toString ( ) + name . toString ( ) ) ; } public QName getUseAttributeSets ( ) { return _useAttributeSets ; } public QName getExtensionElementPrefixes ( ) { return _extensionElementPrefixes ; } public QName getExcludeResultPrefixes ( ) { return _excludeResultPrefixes ; } public Stylesheet makeStylesheet ( SyntaxTreeNode element ) throws CompilerException { try { Stylesheet stylesheet ; if ( element instanceof Stylesheet ) { stylesheet = ( Stylesheet ) element ; } else { stylesheet = new Stylesheet ( ) ; stylesheet . setSimplified ( ) ; stylesheet . addElement ( element ) ; stylesheet . setAttributes ( ( AttributeList ) element . getAttributes ( ) ) ; if ( element . lookupNamespace ( EMPTYSTRING ) == null ) { element . addPrefixMapping ( EMPTYSTRING , EMPTYSTRING ) ; } } stylesheet . setParser ( this ) ; return stylesheet ; } catch ( ClassCastException e ) { ErrorMsg err = new ErrorMsg ( ErrorMsg . NOT_STYLESHEET_ERR , element ) ; throw new CompilerException ( err . toString ( ) ) ; } } public void createAST ( Stylesheet stylesheet ) { try { if ( stylesheet != null ) { stylesheet . parseContents ( this ) ; final int precedence = stylesheet . getImportPrecedence ( ) ; final Enumeration elements = stylesheet . elements ( ) ; while ( elements . hasMoreElements ( ) ) { Object child = elements . nextElement ( ) ; if ( child instanceof Text ) { final int l = getLineNumber ( ) ; ErrorMsg err = new ErrorMsg ( ErrorMsg . ILLEGAL_TEXT_NODE_ERR , l , null ) ; reportError ( ERROR , err ) ; } } if ( ! errorsFound ( ) ) { stylesheet . typeCheck ( _symbolTable ) ; } } } catch ( TypeCheckError e ) { reportError ( ERROR , new ErrorMsg ( e ) ) ; } } public SyntaxTreeNode parse ( XMLReader reader , InputSource input ) { try { reader . setContentHandler ( this ) ; reader . parse ( input ) ; return ( SyntaxTreeNode ) getStylesheet ( _root ) ; } catch ( IOException e ) { if ( _xsltc . debug ( ) ) e . printStackTrace ( ) ; reportError ( ERROR , new ErrorMsg ( e ) ) ; } catch ( SAXException e ) { Throwable ex = e . getException ( ) ; if ( _xsltc . debug ( ) ) { e . printStackTrace ( ) ; if ( ex != null ) ex . printStackTrace ( ) ; } reportError ( ERROR , new ErrorMsg ( e ) ) ; } catch ( CompilerException e ) { if ( _xsltc . debug ( ) ) e . printStackTrace ( ) ; reportError ( ERROR , new ErrorMsg ( e ) ) ; } catch ( Exception e ) { if ( _xsltc . debug ( ) ) e . printStackTrace ( ) ; reportError ( ERROR , new ErrorMsg ( e ) ) ; } return null ; } public SyntaxTreeNode parse ( InputSource input ) { try { final SAXParserFactory factory = SAXParserFactory . newInstance ( ) ; if ( _xsltc . isSecureProcessing ( ) ) { try { factory . setFeature ( XMLConstants . FEATURE_SECURE_PROCESSING , true ) ; } catch ( SAXException e ) { } } try { factory . setFeature ( Constants . NAMESPACE_FEATURE , true ) ; } catch ( Exception e ) { factory . setNamespaceAware ( true ) ; } final SAXParser parser = factory . newSAXParser ( ) ; final XMLReader reader = parser . getXMLReader ( ) ; return ( parse ( reader , input ) ) ; } catch ( ParserConfigurationException e ) { ErrorMsg err = new ErrorMsg ( ErrorMsg . SAX_PARSER_CONFIG_ERR ) ; reportError ( ERROR , err ) ; } catch ( SAXParseException e ) { reportError ( ERROR , new ErrorMsg ( e . getMessage ( ) , e . getLineNumber ( ) ) ) ; } catch ( SAXException e ) { reportError ( ERROR , new ErrorMsg ( e . getMessage ( ) ) ) ; } return null ; } public SyntaxTreeNode getDocumentRoot ( ) { return _root ; } private String _PImedia = null ; private String _PItitle = null ; private String _PIcharset = null ; protected void setPIParameters ( String media , String title , String charset ) { _PImedia = media ; _PItitle = title ; _PIcharset = charset ; } private SyntaxTreeNode getStylesheet ( SyntaxTreeNode root ) throws CompilerException { if ( _target == null ) { if ( ! _rootNamespaceDef ) { ErrorMsg msg = new ErrorMsg ( ErrorMsg . MISSING_XSLT_URI_ERR ) ; throw new CompilerException ( msg . toString ( ) ) ; } return ( root ) ; } if ( _target . charAt ( 0 ) == '#' ) { SyntaxTreeNode element = findStylesheet ( root , _target . substring ( 1 ) ) ; if ( element == null ) { ErrorMsg msg = new ErrorMsg ( ErrorMsg . MISSING_XSLT_TARGET_ERR , _target , root ) ; throw new CompilerException ( msg . toString ( ) ) ; } return ( element ) ; } else { return ( loadExternalStylesheet ( _target ) ) ; } } private SyntaxTreeNode findStylesheet ( SyntaxTreeNode root , String href ) { if ( root == null ) return null ; if ( root instanceof Stylesheet ) { String id = root . getAttribute ( ""id"" ) ; if ( id . equals ( href ) ) return root ; } Vector children = root . getContents ( ) ; if ( children != null ) { final int count = children . size ( ) ; for ( int i = 0 ; i < count ; i ++ ) { SyntaxTreeNode child = ( SyntaxTreeNode ) children . elementAt ( i ) ; SyntaxTreeNode node = findStylesheet ( child , href ) ; if ( node != null ) return node ; } } return null ; } private SyntaxTreeNode loadExternalStylesheet ( String location ) throws CompilerException { InputSource source ; if ( ( new File ( location ) ) . exists ( ) ) source = new InputSource ( ""file:"" + location ) ; else source = new InputSource ( location ) ; SyntaxTreeNode external = ( SyntaxTreeNode ) parse ( source ) ; return ( external ) ; } private void initAttrTable ( String elementName , String [ ] attrs ) { _instructionAttrs . put ( getQName ( XSLT_URI , XSL , elementName ) , attrs ) ; } private void initInstructionAttrs ( ) { initAttrTable ( ""template"" , new String [ ] { ""match"" , ""name"" , ""priority"" , ""mode"" } ) ; initAttrTable ( ""stylesheet"" , new String [ ] { ""id"" , ""version"" , ""extension-element-prefixes"" , ""exclude-result-prefixes"" } ) ; initAttrTable ( ""transform"" , new String [ ] { ""id"" , ""version"" , ""extension-element-prefixes"" , ""exclude-result-prefixes"" } ) ; initAttrTable ( ""text"" , new String [ ] { ""disable-output-escaping"" } ) ; initAttrTable ( ""if"" , new String [ ] { ""test"" } ) ; initAttrTable ( ""choose"" , new String [ ] { } ) ; initAttrTable ( ""when"" , new String [ ] { ""test"" } ) ; initAttrTable ( ""otherwise"" , new String [ ] { } ) ; initAttrTable ( ""for-each"" , new String [ ] { ""select"" } ) ; initAttrTable ( ""message"" , new String [ ] { ""terminate"" } ) ; initAttrTable ( ""number"" , new String [ ] { ""level"" , ""count"" , ""from"" , ""value"" , ""format"" , ""lang"" , ""letter-value"" , ""grouping-separator"" , ""grouping-size"" } ) ; initAttrTable ( ""comment"" , new String [ ] { } ) ; initAttrTable ( ""copy"" , new String [ ] { ""use-attribute-sets"" } ) ; initAttrTable ( ""copy-of"" , new String [ ] { ""select"" } ) ; initAttrTable ( ""param"" , new String [ ] { ""name"" , ""select"" } ) ; initAttrTable ( ""with-param"" , new String [ ] { ""name"" , ""select"" } ) ; initAttrTable ( ""variable"" , new String [ ] { ""name"" , ""select"" } ) ; initAttrTable ( ""output"" , new String [ ] { ""method"" , ""version"" , ""encoding"" , ""omit-xml-declaration"" , ""standalone"" , ""doctype-public"" , ""doctype-system"" , ""cdata-section-elements"" , ""indent"" , ""media-type"" } ) ; initAttrTable ( ""sort"" , new String [ ] { ""select"" , ""order"" , ""case-order"" , ""lang"" , ""data-type"" } ) ; initAttrTable ( ""key"" , new String [ ] { ""name"" , ""match"" , ""use"" } ) ; initAttrTable ( ""fallback"" , new String [ ] { } ) ; initAttrTable ( ""attribute"" , new String [ ] { ""name"" , ""namespace"" } ) ; initAttrTable ( ""attribute-set"" , new String [ ] { ""name"" , ""use-attribute-sets"" } ) ; initAttrTable ( ""value-of"" , new String [ ] { ""select"" , ""disable-output-escaping"" } ) ; initAttrTable ( ""element"" , new String [ ] { ""name"" , ""namespace"" , ""use-attribute-sets"" } ) ; initAttrTable ( ""call-template"" , new String [ ] { ""name"" } ) ; initAttrTable ( ""apply-templates"" , new String [ ] { ""select"" , ""mode"" } ) ; initAttrTable ( ""apply-imports"" , new String [ ] { } ) ; initAttrTable ( ""decimal-format"" , new String [ ] { ""name"" , ""decimal-separator"" , ""grouping-separator"" , ""infinity"" , ""minus-sign"" , ""NaN"" , ""percent"" , ""per-mille"" , ""zero-digit"" , ""digit"" , ""pattern-separator"" } ) ; initAttrTable ( ""import"" , new String [ ] { ""href"" } ) ; initAttrTable ( ""include"" , new String [ ] { ""href"" } ) ; initAttrTable ( ""strip-space"" , new String [ ] { ""elements"" } ) ; initAttrTable ( ""preserve-space"" , new String [ ] { ""elements"" } ) ; initAttrTable ( ""processing-instruction"" , new String [ ] { ""name"" } ) ; initAttrTable ( ""namespace-alias"" , new String [ ] { ""stylesheet-prefix"" , ""result-prefix"" } ) ; } private void initStdClasses ( ) { initStdClass ( ""template"" , ""Template"" ) ; initStdClass ( ""stylesheet"" , ""Stylesheet"" ) ; initStdClass ( ""transform"" , ""Stylesheet"" ) ; initStdClass ( ""text"" , ""Text"" ) ; initStdClass ( ""if"" , ""If"" ) ; initStdClass ( ""choose"" , ""Choose"" ) ; initStdClass ( ""when"" , ""When"" ) ; initStdClass ( ""otherwise"" , ""Otherwise"" ) ; initStdClass ( ""for-each"" , ""ForEach"" ) ; initStdClass ( ""message"" , ""Message"" ) ; initStdClass ( ""number"" , ""Number"" ) ; initStdClass ( ""comment"" , ""Comment"" ) ; initStdClass ( ""copy"" , ""Copy"" ) ; initStdClass ( ""copy-of"" , ""CopyOf"" ) ; initStdClass ( ""param"" , ""Param"" ) ; initStdClass ( ""with-param"" , ""WithParam"" ) ; initStdClass ( ""variable"" , ""Variable"" ) ; initStdClass ( ""output"" , ""Output"" ) ; initStdClass ( ""sort"" , ""Sort"" ) ; initStdClass ( ""key"" , ""Key"" ) ; initStdClass ( ""fallback"" , ""Fallback"" ) ; initStdClass ( ""attribute"" , ""XslAttribute"" ) ; initStdClass ( ""attribute-set"" , ""AttributeSet"" ) ; initStdClass ( ""value-of"" , ""ValueOf"" ) ; initStdClass ( ""element"" , ""XslElement"" ) ; initStdClass ( ""call-template"" , ""CallTemplate"" ) ; initStdClass ( ""apply-templates"" , ""ApplyTemplates"" ) ; initStdClass ( ""apply-imports"" , ""ApplyImports"" ) ; initStdClass ( ""decimal-format"" , ""DecimalFormatting"" ) ; initStdClass ( ""import"" , ""Import"" ) ; initStdClass ( ""include"" , ""Include"" ) ; initStdClass ( ""strip-space"" , ""Whitespace"" ) ; initStdClass ( ""preserve-space"" , ""Whitespace"" ) ; initStdClass ( ""processing-instruction"" , ""ProcessingInstruction"" ) ; initStdClass ( ""namespace-alias"" , ""NamespaceAlias"" ) ; } private void initStdClass ( String elementName , String className ) { _instructionClasses . put ( getQName ( XSLT_URI , XSL , elementName ) , COMPILER_PACKAGE + '.' + className ) ; } public boolean elementSupported ( String namespace , String localName ) { return ( _instructionClasses . get ( getQName ( namespace , XSL , localName ) ) != null ) ; } public boolean functionSupported ( String fname ) { return ( _symbolTable . lookupPrimop ( fname ) != null ) ; } private void initExtClasses ( ) { initExtClass ( ""output"" , ""TransletOutput"" ) ; initExtClass ( REDIRECT_URI , ""write"" , ""TransletOutput"" ) ; } private void initExtClass ( String elementName , String className ) { _instructionClasses . put ( getQName ( TRANSLET_URI , TRANSLET , elementName ) , COMPILER_PACKAGE + '.' + className ) ; } private void initExtClass ( String namespace , String elementName , String className ) { _instructionClasses . put ( getQName ( namespace , TRANSLET , elementName ) , COMPILER_PACKAGE + '.' + className ) ; } private void initSymbolTable ( ) { MethodType I_V = new MethodType ( Type . Int , Type . Void ) ; MethodType I_R = new MethodType ( Type . Int , Type . Real ) ; MethodType I_S = new MethodType ( Type . Int , Type . String ) ; MethodType I_D = new MethodType ( Type . Int , Type . NodeSet ) ; MethodType R_I = new MethodType ( Type . Real , Type . Int ) ; MethodType R_V = new MethodType ( Type . Real , Type . Void ) ; MethodType R_R = new MethodType ( Type . Real , Type . Real ) ; MethodType R_D = new MethodType ( Type . Real , Type . NodeSet ) ; MethodType R_O = new MethodType ( Type . Real , Type . Reference ) ; MethodType I_I = new MethodType ( Type . Int , Type . Int ) ; MethodType D_O = new MethodType ( Type . NodeSet , Type . Reference ) ; MethodType D_V = new MethodType ( Type . NodeSet , Type . Void ) ; MethodType D_S = new MethodType ( Type . NodeSet , Type . String ) ; MethodType D_D = new MethodType ( Type . NodeSet , Type . NodeSet ) ; MethodType A_V = new MethodType ( Type . Node , Type . Void ) ; MethodType S_V = new MethodType ( Type . String , Type . Void ) ; MethodType S_S = new MethodType ( Type . String , Type . String ) ; MethodType S_A = new MethodType ( Type . String , Type . Node ) ; MethodType S_D = new MethodType ( Type . String , Type . NodeSet ) ; MethodType S_O = new MethodType ( Type . String , Type . Reference ) ; MethodType B_O = new MethodType ( Type . Boolean , Type . Reference ) ; MethodType B_V = new MethodType ( Type . Boolean , Type . Void ) ; MethodType B_B = new MethodType ( Type . Boolean , Type . Boolean ) ; MethodType B_S = new MethodType ( Type . Boolean , Type . String ) ; MethodType D_X = new MethodType ( Type . NodeSet , Type . Object ) ; MethodType R_RR = new MethodType ( Type . Real , Type . Real , Type . Real ) ; MethodType I_II = new MethodType ( Type . Int , Type . Int , Type . Int ) ; MethodType B_RR = new MethodType ( Type . Boolean , Type . Real , Type . Real ) ; MethodType B_II = new MethodType ( Type . Boolean , Type . Int , Type . Int ) ; MethodType S_SS = new MethodType ( Type . String , Type . String , Type . String ) ; MethodType S_DS = new MethodType ( Type . String , Type . Real , Type . String ) ; MethodType S_SR = new MethodType ( Type . String , Type . String , Type . Real ) ; MethodType O_SO = new MethodType ( Type . Reference , Type . String , Type . Reference ) ; MethodType D_SS = new MethodType ( Type . NodeSet , Type . String , Type . String ) ; MethodType D_SD = new MethodType ( Type . NodeSet , Type . String , Type . NodeSet ) ; MethodType B_BB = new MethodType ( Type . Boolean , Type . Boolean , Type . Boolean ) ; MethodType B_SS = new MethodType ( Type . Boolean , Type . String , Type . String ) ; MethodType S_SD = new MethodType ( Type . String , Type . String , Type . NodeSet ) ; MethodType S_DSS = new MethodType ( Type . String , Type . Real , Type . String , Type . String ) ; MethodType S_SRR = new MethodType ( Type . String , Type . String , Type . Real , Type . Real ) ; MethodType S_SSS = new MethodType ( Type . String , Type . String , Type . String , Type . String ) ; _symbolTable . addPrimop ( ""current"" , A_V ) ; _symbolTable . addPrimop ( ""last"" , I_V ) ; _symbolTable . addPrimop ( ""position"" , I_V ) ; _symbolTable . addPrimop ( ""true"" , B_V ) ; _symbolTable . addPrimop ( ""false"" , B_V ) ; _symbolTable . addPrimop ( ""not"" , B_B ) ; _symbolTable . addPrimop ( ""name"" , S_V ) ; _symbolTable . addPrimop ( ""name"" , S_A ) ; _symbolTable . addPrimop ( ""generate-id"" , S_V ) ; _symbolTable . addPrimop ( ""generate-id"" , S_A ) ; _symbolTable . addPrimop ( ""ceiling"" , R_R ) ; _symbolTable . addPrimop ( ""floor"" , R_R ) ; _symbolTable . addPrimop ( ""round"" , R_R ) ; _symbolTable . addPrimop ( ""contains"" , B_SS ) ; _symbolTable . addPrimop ( ""number"" , R_O ) ; _symbolTable . addPrimop ( ""number"" , R_V ) ; _symbolTable . addPrimop ( ""boolean"" , B_O ) ; _symbolTable . addPrimop ( ""string"" , S_O ) ; _symbolTable . addPrimop ( ""string"" , S_V ) ; _symbolTable . addPrimop ( ""translate"" , S_SSS ) ; _symbolTable . addPrimop ( ""string-length"" , I_V ) ; _symbolTable . addPrimop ( ""string-length"" , I_S ) ; _symbolTable . addPrimop ( ""starts-with"" , B_SS ) ; _symbolTable . addPrimop ( ""format-number"" , S_DS ) ; _symbolTable . addPrimop ( ""format-number"" , S_DSS ) ; _symbolTable . addPrimop ( ""unparsed-entity-uri"" , S_S ) ; _symbolTable . addPrimop ( ""key"" , D_SS ) ; _symbolTable . addPrimop ( ""key"" , D_SD ) ; _symbolTable . addPrimop ( ""id"" , D_S ) ; _symbolTable . addPrimop ( ""id"" , D_D ) ; _symbolTable . addPrimop ( ""namespace-uri"" , S_V ) ; _symbolTable . addPrimop ( ""function-available"" , B_S ) ; _symbolTable . addPrimop ( ""element-available"" , B_S ) ; _symbolTable . addPrimop ( ""document"" , D_S ) ; _symbolTable . addPrimop ( ""document"" , D_V ) ; _symbolTable . addPrimop ( ""count"" , I_D ) ; _symbolTable . addPrimop ( ""sum"" , R_D ) ; _symbolTable . addPrimop ( ""local-name"" , S_V ) ; _symbolTable . addPrimop ( ""local-name"" , S_D ) ; _symbolTable . addPrimop ( ""namespace-uri"" , S_V ) ; _symbolTable . addPrimop ( ""namespace-uri"" , S_D ) ; _symbolTable . addPrimop ( ""substring"" , S_SR ) ; _symbolTable . addPrimop ( ""substring"" , S_SRR ) ; _symbolTable . addPrimop ( ""substring-after"" , S_SS ) ; _symbolTable . addPrimop ( ""substring-before"" , S_SS ) ; _symbolTable . addPrimop ( ""normalize-space"" , S_V ) ; _symbolTable . addPrimop ( ""normalize-space"" , S_S ) ; _symbolTable . addPrimop ( ""system-property"" , S_S ) ; _symbolTable . addPrimop ( ""nodeset"" , D_O ) ; _symbolTable . addPrimop ( ""objectType"" , S_O ) ; _symbolTable . addPrimop ( ""cast"" , O_SO ) ; _symbolTable . addPrimop ( ""+"" , R_RR ) ; _symbolTable . addPrimop ( ""-"" , R_RR ) ; _symbolTable . addPrimop ( ""*"" , R_RR ) ; _symbolTable . addPrimop ( ""/"" , R_RR ) ; _symbolTable . addPrimop ( ""%"" , R_RR ) ; _symbolTable . addPrimop ( ""+"" , I_II ) ; _symbolTable . addPrimop ( ""-"" , I_II ) ; _symbolTable . addPrimop ( ""*"" , I_II ) ; _symbolTable . addPrimop ( ""<"" , B_RR ) ; _symbolTable . addPrimop ( ""<="" , B_RR ) ; _symbolTable . addPrimop ( "">"" , B_RR ) ; _symbolTable . addPrimop ( "">="" , B_RR ) ; _symbolTable . addPrimop ( ""<"" , B_II ) ; _symbolTable . addPrimop ( ""<="" , B_II ) ; _symbolTable . addPrimop ( "">"" , B_II ) ; _symbolTable . addPrimop ( "">="" , B_II ) ; _symbolTable . addPrimop ( ""<"" , B_BB ) ; _symbolTable . addPrimop ( ""<="" , B_BB ) ; _symbolTable . addPrimop ( "">"" , B_BB ) ; _symbolTable . addPrimop ( "">="" , B_BB ) ; _symbolTable . addPrimop ( ""or"" , B_BB ) ; _symbolTable . addPrimop ( ""and"" , B_BB ) ; _symbolTable . addPrimop ( ""u-"" , R_R ) ; _symbolTable . addPrimop ( ""u-"" , I_I ) ; } public SymbolTable getSymbolTable ( ) { return _symbolTable ; } public Template getTemplate ( ) { return _template ; } public void setTemplate ( Template template ) { _template = template ; } private int _templateIndex = 0 ; public int getTemplateIndex ( ) { return ( _templateIndex ++ ) ; } private boolean versionIsOne = true ; public SyntaxTreeNode makeInstance ( String uri , String prefix , String local , Attributes attributes ) { SyntaxTreeNode node = null ; QName qname = getQName ( uri , prefix , local ) ; String className = ( String ) _instructionClasses . get ( qname ) ; if ( className != null ) { try { final Class clazz = ObjectFactory . findProviderClass ( className , ObjectFactory . findClassLoader ( ) , true ) ; node = ( SyntaxTreeNode ) clazz . newInstance ( ) ; node . setQName ( qname ) ; node . setParser ( this ) ; if ( _locator != null ) { node . setLineNumber ( getLineNumber ( ) ) ; } if ( node instanceof Stylesheet ) { _xsltc . setStylesheet ( ( Stylesheet ) node ) ; } checkForSuperfluousAttributes ( node , attributes ) ; } catch ( ClassNotFoundException e ) { ErrorMsg err = new ErrorMsg ( ErrorMsg . CLASS_NOT_FOUND_ERR , node ) ; reportError ( ERROR , err ) ; } catch ( Exception e ) { ErrorMsg err = new ErrorMsg ( ErrorMsg . INTERNAL_ERR , e . getMessage ( ) , node ) ; reportError ( FATAL , err ) ; } } else { if ( uri != null ) { if ( uri . equals ( XSLT_URI ) ) { node = new UnsupportedElement ( uri , prefix , local , false ) ; UnsupportedElement element = ( UnsupportedElement ) node ; ErrorMsg msg = new ErrorMsg ( ErrorMsg . UNSUPPORTED_XSL_ERR , getLineNumber ( ) , local ) ; element . setErrorMessage ( msg ) ; if ( versionIsOne ) { reportError ( UNSUPPORTED , msg ) ; } } else if ( uri . equals ( TRANSLET_URI ) ) { node = new UnsupportedElement ( uri , prefix , local , true ) ; UnsupportedElement element = ( UnsupportedElement ) node ; ErrorMsg msg = new ErrorMsg ( ErrorMsg . UNSUPPORTED_EXT_ERR , getLineNumber ( ) , local ) ; element . setErrorMessage ( msg ) ; } else { Stylesheet sheet = _xsltc . getStylesheet ( ) ; if ( ( sheet != null ) && ( sheet . isExtension ( uri ) ) ) { if ( sheet != ( SyntaxTreeNode ) _parentStack . peek ( ) ) { node = new UnsupportedElement ( uri , prefix , local , true ) ; UnsupportedElement elem = ( UnsupportedElement ) node ; ErrorMsg msg = new ErrorMsg ( ErrorMsg . UNSUPPORTED_EXT_ERR , getLineNumber ( ) , prefix + "":"" + local ) ; elem . setErrorMessage ( msg ) ; } } } } if ( node == null ) { node = new LiteralElement ( ) ; node . setLineNumber ( getLineNumber ( ) ) ; } } if ( ( node != null ) && ( node instanceof LiteralElement ) ) { ( ( LiteralElement ) node ) . setQName ( qname ) ; } return ( node ) ; } private void checkForSuperfluousAttributes ( SyntaxTreeNode node , Attributes attrs ) { QName qname = node . getQName ( ) ; boolean isStylesheet = ( node instanceof Stylesheet ) ; String [ ] legal = ( String [ ] ) _instructionAttrs . get ( qname ) ; if ( versionIsOne && legal != null ) { int j ; final int n = attrs . getLength ( ) ; for ( int i = 0 ; i < n ; i ++ ) { final String attrQName = attrs . getQName ( i ) ; if ( isStylesheet && attrQName . equals ( ""version"" ) ) { versionIsOne = attrs . getValue ( i ) . equals ( ""1.0"" ) ; } if ( attrQName . startsWith ( ""xml"" ) || attrQName . indexOf ( ':' ) > 0 ) continue ; for ( j = 0 ; j < legal . length ; j ++ ) { if ( attrQName . equalsIgnoreCase ( legal [ j ] ) ) { break ; } } if ( j == legal . length ) { final ErrorMsg err = new ErrorMsg ( ErrorMsg . ILLEGAL_ATTRIBUTE_ERR , attrQName , node ) ; err . setWarningError ( true ) ; reportError ( WARNING , err ) ; } } } } public Expression parseExpression ( SyntaxTreeNode parent , String exp ) { return ( Expression ) parseTopLevel ( parent , ""<EXPRESSION>"" + exp , null ) ; } public Expression parseExpression ( SyntaxTreeNode parent , String attr , String def ) { String exp = parent . getAttribute ( attr ) ; if ( ( exp . length ( ) == 0 ) && ( def != null ) ) exp = def ; return ( Expression ) parseTopLevel ( parent , ""<EXPRESSION>"" + exp , exp ) ; } public Pattern parsePattern ( SyntaxTreeNode parent , String pattern ) { return ( Pattern ) parseTopLevel ( parent , ""<PATTERN>"" + pattern , pattern ) ; } public Pattern parsePattern ( SyntaxTreeNode parent , String attr , String def ) { String pattern = parent . getAttribute ( attr ) ; if ( ( pattern . length ( ) == 0 ) && ( def != null ) ) pattern = def ; return ( Pattern ) parseTopLevel ( parent , ""<PATTERN>"" + pattern , pattern ) ; } private SyntaxTreeNode parseTopLevel ( SyntaxTreeNode parent , String text , String expression ) { int line = getLineNumber ( ) ; try { _xpathParser . setScanner ( new XPathLexer ( new StringReader ( text ) ) ) ; Symbol result = _xpathParser . parse ( expression , line ) ; if ( result != null ) { final SyntaxTreeNode node = ( SyntaxTreeNode ) result . value ; if ( node != null ) { node . setParser ( this ) ; node . setParent ( parent ) ; node . setLineNumber ( line ) ; return node ; } } reportError ( ERROR , new ErrorMsg ( ErrorMsg . XPATH_PARSER_ERR , expression , parent ) ) ; } catch ( Exception e ) { if ( _xsltc . debug ( ) ) e . printStackTrace ( ) ; reportError ( ERROR , new ErrorMsg ( ErrorMsg . XPATH_PARSER_ERR , expression , parent ) ) ; } SyntaxTreeNode . Dummy . setParser ( this ) ; return SyntaxTreeNode . Dummy ; } public boolean errorsFound ( ) { return _errors . size ( ) > 0 ; } public void printErrors ( ) { final int size = _errors . size ( ) ; if ( size > 0 ) { System . err . println ( new ErrorMsg ( ErrorMsg . COMPILER_ERROR_KEY ) ) ; for ( int i = 0 ; i < size ; i ++ ) { System . err . println ( ""  "" + _errors . elementAt ( i ) ) ; } } } public void printWarnings ( ) { final int size = _warnings . size ( ) ; if ( size > 0 ) { System . err . println ( new ErrorMsg ( ErrorMsg . COMPILER_WARNING_KEY ) ) ; for ( int i = 0 ; i < size ; i ++ ) { System . err . println ( ""  "" + _warnings . elementAt ( i ) ) ; } } } public void reportError ( final int category , final ErrorMsg error ) { switch ( category ) { case Constants . INTERNAL : _errors . addElement ( error ) ; break ; case Constants . UNSUPPORTED : _errors . addElement ( error ) ; break ; case Constants . FATAL : _errors . addElement ( error ) ; break ; case Constants . ERROR : _errors . addElement ( error ) ; break ; case Constants . WARNING : _warnings . addElement ( error ) ; break ; } } public Vector getErrors ( ) { return _errors ; } public Vector getWarnings ( ) { return _warnings ; } private Stack _parentStack = null ; private Hashtable _prefixMapping = null ; public void startDocument ( ) { _root = null ; _target = null ; _prefixMapping = null ; _parentStack = new Stack ( ) ; } public void endDocument ( ) { } public void startPrefixMapping ( String prefix , String uri ) { if ( _prefixMapping == null ) { _prefixMapping = new Hashtable ( ) ; } _prefixMapping . put ( prefix , uri ) ; } public void endPrefixMapping ( String prefix ) { } public void startElement ( String uri , String localname , String qname , Attributes attributes ) throws SAXException { final int col = qname . lastIndexOf ( ':' ) ; final String prefix = ( col == - 1 ) ? null : qname . substring ( 0 , col ) ; SyntaxTreeNode element = makeInstance ( uri , prefix , localname , attributes ) ; if ( element == null ) { ErrorMsg err = new ErrorMsg ( ErrorMsg . ELEMENT_PARSE_ERR , prefix + ':' + localname ) ; throw new SAXException ( err . toString ( ) ) ; } if ( _root == null ) { if ( ( _prefixMapping == null ) || ( _prefixMapping . containsValue ( Constants . XSLT_URI ) == false ) ) _rootNamespaceDef = false ; else _rootNamespaceDef = true ; _root = element ; } else { SyntaxTreeNode parent = ( SyntaxTreeNode ) _parentStack . peek ( ) ; parent . addElement ( element ) ; element . setParent ( parent ) ; } element . setAttributes ( new AttributeList ( attributes ) ) ; element . setPrefixMapping ( _prefixMapping ) ; if ( element instanceof Stylesheet ) { getSymbolTable ( ) . setCurrentNode ( element ) ; ( ( Stylesheet ) element ) . excludeExtensionPrefixes ( this ) ; } _prefixMapping = null ; _parentStack . push ( element ) ; } public void endElement ( String uri , String localname , String qname ) { _parentStack . pop ( ) ; } public void characters ( char [ ] ch , int start , int length ) { String string = new String ( ch , start , length ) ; SyntaxTreeNode parent = ( SyntaxTreeNode ) _parentStack . peek ( ) ; if ( string . length ( ) == 0 ) return ; if ( parent instanceof Text ) { ( ( Text ) parent ) . setText ( string ) ; return ; } if ( parent instanceof Stylesheet ) return ; SyntaxTreeNode bro = parent . lastChild ( ) ; if ( ( bro != null ) && ( bro instanceof Text ) ) { Text text = ( Text ) bro ; if ( ! text . isTextElement ( ) ) { if ( ( length > 1 ) || ( ( ( int ) ch [ 0 ] ) < 0x100 ) ) { text . setText ( string ) ; return ; } } } parent . addElement ( new Text ( string ) ) ; } private String getTokenValue ( String token ) { final int start = token . indexOf ( '""' ) ; final int stop = token . lastIndexOf ( '""' ) ; return token . substring ( start + 1 , stop ) ; } public void processingInstruction ( String name , String value ) { if ( ( _target == null ) && ( name . equals ( ""xml-stylesheet"" ) ) ) { String href = null ; String media = null ; String title = null ; String charset = null ; StringTokenizer tokens = new StringTokenizer ( value ) ; while ( tokens . hasMoreElements ( ) ) { String token = ( String ) tokens . nextElement ( ) ; if ( token . startsWith ( ""href"" ) ) href = getTokenValue ( token ) ; else if ( token . startsWith ( ""media"" ) ) media = getTokenValue ( token ) ; else if ( token . startsWith ( ""title"" ) ) title = getTokenValue ( token ) ; else if ( token . startsWith ( ""charset"" ) ) charset = getTokenValue ( token ) ; } if ( ( ( _PImedia == null ) || ( _PImedia . equals ( media ) ) ) && ( ( _PItitle == null ) || ( _PImedia . equals ( title ) ) ) && ( ( _PIcharset == null ) || ( _PImedia . equals ( charset ) ) ) ) { _target = href ; } } } public void ignorableWhitespace ( char [ ] ch , int start , int length ) { } public void skippedEntity ( String name ) { } public void setDocumentLocator ( Locator locator ) { _locator = locator ; } private int getLineNumber ( ) { int line = 0 ; if ( _locator != null ) line = _locator . getLineNumber ( ) ; return line ; } }",Smelly
"@ RunWith ( SpringJUnit4ClassRunner . class ) @ ContextConfiguration ( locations = { ""classpath:testJDBCEnv.xml"" } ) public class AuthenticationITCase extends AbstractITCase { @ Autowired private DataSource testDataSource ; private int getFailedLogins ( final UserService userService , final String userKey ) { UserTO readUserTO = userService . read ( userKey ) ; assertNotNull ( readUserTO ) ; assertNotNull ( readUserTO . getFailedLogins ( ) ) ; return readUserTO . getFailedLogins ( ) ; } @ Test public void testReadEntitlements ( ) { try { clientFactory . create ( ) . self ( ) ; fail ( ) ; } catch ( AccessControlException e ) { assertNotNull ( e ) ; } Pair < Map < String , Set < String > > , UserTO > self = clientFactory . create ( new AnonymousAuthenticationHandler ( ANONYMOUS_UNAME , ANONYMOUS_KEY ) ) . self ( ) ; assertEquals ( 1 , self . getKey ( ) . size ( ) ) ; assertTrue ( self . getKey ( ) . keySet ( ) . contains ( StandardEntitlement . ANONYMOUS ) ) ; assertEquals ( ANONYMOUS_UNAME , self . getValue ( ) . getUsername ( ) ) ; self = adminClient . self ( ) ; assertEquals ( syncopeService . platform ( ) . getEntitlements ( ) . size ( ) , self . getKey ( ) . size ( ) ) ; assertFalse ( self . getKey ( ) . keySet ( ) . contains ( StandardEntitlement . ANONYMOUS ) ) ; assertEquals ( ADMIN_UNAME , self . getValue ( ) . getUsername ( ) ) ; self = clientFactory . create ( ""bellini"" , ADMIN_PWD ) . self ( ) ; assertFalse ( self . getKey ( ) . isEmpty ( ) ) ; assertFalse ( self . getKey ( ) . keySet ( ) . contains ( StandardEntitlement . ANONYMOUS ) ) ; assertEquals ( ""bellini"" , self . getValue ( ) . getUsername ( ) ) ; } @ Test public void testUserSchemaAuthorization ( ) { String schemaName = ""authTestSchema"" + getUUIDString ( ) ; PlainSchemaTO schemaTO = new PlainSchemaTO ( ) ; schemaTO . setKey ( schemaName ) ; schemaTO . setMandatoryCondition ( ""false"" ) ; schemaTO . setType ( AttrSchemaType . String ) ; PlainSchemaTO newPlainSchemaTO = createSchema ( SchemaType . PLAIN , schemaTO ) ; assertEquals ( schemaTO , newPlainSchemaTO ) ; UserTO userTO = UserITCase . getUniqueSampleTO ( ""auth@test.org"" ) ; userTO = createUser ( userTO ) . getEntity ( ) ; assertNotNull ( userTO ) ; schemaTO = schemaService . read ( SchemaType . PLAIN , schemaName ) ; assertNotNull ( schemaTO ) ; SchemaService schemaService2 = clientFactory . create ( userTO . getUsername ( ) , ""password123"" ) . getService ( SchemaService . class ) ; schemaTO = schemaService2 . read ( SchemaType . PLAIN , schemaName ) ; assertNotNull ( schemaTO ) ; try { schemaService2 . update ( SchemaType . PLAIN , schemaTO ) ; fail ( ""Schema update as user should not work"" ) ; } catch ( ForbiddenException e ) { assertNotNull ( e ) ; } assertEquals ( 0 , getFailedLogins ( userService , userTO . getKey ( ) ) ) ; } @ Test public void testUserRead ( ) { UserTO userTO = UserITCase . getUniqueSampleTO ( ""testuserread@test.org"" ) ; userTO . getRoles ( ) . add ( ""User manager"" ) ; userTO = createUser ( userTO ) . getEntity ( ) ; assertNotNull ( userTO ) ; UserService userService2 = clientFactory . create ( userTO . getUsername ( ) , ""password123"" ) . getService ( UserService . class ) ; UserTO readUserTO = userService2 . read ( ""1417acbe-cbf6-4277-9372-e75e04f97000"" ) ; assertNotNull ( readUserTO ) ; UserService userService3 = clientFactory . create ( ""puccini"" , ADMIN_PWD ) . getService ( UserService . class ) ; try { userService3 . read ( ""b3cbc78d-32e6-4bd4-92e0-bbe07566a2ee"" ) ; fail ( ) ; } catch ( SyncopeClientException e ) { assertNotNull ( e ) ; assertEquals ( ClientExceptionType . DelegatedAdministration , e . getType ( ) ) ; } } @ Test public void testUserSearch ( ) { UserTO userTO = UserITCase . getUniqueSampleTO ( ""testusersearch@test.org"" ) ; userTO . getRoles ( ) . add ( ""User reviewer"" ) ; userTO = createUser ( userTO ) . getEntity ( ) ; assertNotNull ( userTO ) ; UserService userService2 = clientFactory . create ( userTO . getUsername ( ) , ""password123"" ) . getService ( UserService . class ) ; PagedResult < UserTO > matchingUsers = userService2 . search ( new AnyQuery . Builder ( ) . realm ( SyncopeConstants . ROOT_REALM ) . fiql ( SyncopeClient . getUserSearchConditionBuilder ( ) . isNotNull ( ""key"" ) . query ( ) ) . build ( ) ) ; assertNotNull ( matchingUsers ) ; assertFalse ( matchingUsers . getResult ( ) . isEmpty ( ) ) ; Set < String > matchingUserKeys = CollectionUtils . collect ( matchingUsers . getResult ( ) , EntityTOUtils . < UserTO > keyTransformer ( ) , new HashSet < String > ( ) ) ; assertTrue ( matchingUserKeys . contains ( ""1417acbe-cbf6-4277-9372-e75e04f97000"" ) ) ; assertFalse ( matchingUserKeys . contains ( ""74cd8ece-715a-44a4-a736-e17b46c4e7e6"" ) ) ; assertFalse ( matchingUserKeys . contains ( ""823074dc-d280-436d-a7dd-07399fae48ec"" ) ) ; UserService userService3 = clientFactory . create ( ""puccini"" , ADMIN_PWD ) . getService ( UserService . class ) ; matchingUsers = userService3 . search ( new AnyQuery . Builder ( ) . realm ( ""/even/two"" ) . fiql ( SyncopeClient . getUserSearchConditionBuilder ( ) . isNotNull ( ""loginDate"" ) . query ( ) ) . build ( ) ) ; assertNotNull ( matchingUsers ) ; assertTrue ( IterableUtils . matchesAll ( matchingUsers . getResult ( ) , new Predicate < UserTO > ( ) { @ Override public boolean evaluate ( final UserTO matched ) { return ""/even/two"" . equals ( matched . getRealm ( ) ) ; } } ) ) ; } @ Test public void delegatedUserCRUD ( ) { String roleKey = null ; String delegatedAdminKey = null ; try { RoleTO role = new RoleTO ( ) ; role . setKey ( ""Delegated user admin"" ) ; role . getEntitlements ( ) . add ( StandardEntitlement . USER_CREATE ) ; role . getEntitlements ( ) . add ( StandardEntitlement . USER_UPDATE ) ; role . getEntitlements ( ) . add ( StandardEntitlement . USER_DELETE ) ; role . getEntitlements ( ) . add ( StandardEntitlement . USER_SEARCH ) ; role . getEntitlements ( ) . add ( StandardEntitlement . USER_READ ) ; role . getRealms ( ) . add ( ""/even/two"" ) ; roleKey = roleService . create ( role ) . getHeaderString ( RESTHeaders . RESOURCE_KEY ) ; assertNotNull ( roleKey ) ; UserTO delegatedAdmin = UserITCase . getUniqueSampleTO ( ""admin@syncope.apache.org"" ) ; delegatedAdmin . getRoles ( ) . add ( roleKey ) ; delegatedAdmin = createUser ( delegatedAdmin ) . getEntity ( ) ; delegatedAdminKey = delegatedAdmin . getKey ( ) ; UserService delegatedUserService = clientFactory . create ( delegatedAdmin . getUsername ( ) , ""password123"" ) . getService ( UserService . class ) ; UserTO user = UserITCase . getUniqueSampleTO ( ""delegated@syncope.apache.org"" ) ; try { delegatedUserService . create ( user ) ; fail ( ) ; } catch ( SyncopeClientException e ) { assertEquals ( ClientExceptionType . DelegatedAdministration , e . getType ( ) ) ; } user . setRealm ( ""/even/two"" ) ; Response response = delegatedUserService . create ( user ) ; assertEquals ( Response . Status . CREATED . getStatusCode ( ) , response . getStatus ( ) ) ; user = response . readEntity ( new GenericType < ProvisioningResult < UserTO > > ( ) { } ) . getEntity ( ) ; assertEquals ( ""surname"" , user . getPlainAttr ( ""surname"" ) . getValues ( ) . get ( 0 ) ) ; UserPatch userPatch = new UserPatch ( ) ; userPatch . setKey ( user . getKey ( ) ) ; userPatch . setRealm ( new StringReplacePatchItem . Builder ( ) . value ( ""/odd"" ) . build ( ) ) ; userPatch . getPlainAttrs ( ) . add ( attrAddReplacePatch ( ""surname"" , ""surname2"" ) ) ; try { delegatedUserService . update ( userPatch ) ; fail ( ) ; } catch ( SyncopeClientException e ) { assertEquals ( ClientExceptionType . DelegatedAdministration , e . getType ( ) ) ; } userPatch . setRealm ( null ) ; response = delegatedUserService . update ( userPatch ) ; assertEquals ( Response . Status . OK . getStatusCode ( ) , response . getStatus ( ) ) ; user = response . readEntity ( new GenericType < ProvisioningResult < UserTO > > ( ) { } ) . getEntity ( ) ; assertEquals ( ""surname2"" , user . getPlainAttr ( ""surname"" ) . getValues ( ) . get ( 0 ) ) ; delegatedUserService . delete ( user . getKey ( ) ) ; try { userService . read ( user . getKey ( ) ) ; fail ( ) ; } catch ( SyncopeClientException e ) { assertEquals ( ClientExceptionType . NotFound , e . getType ( ) ) ; } } finally { if ( roleKey != null ) { roleService . delete ( roleKey ) ; } if ( delegatedAdminKey != null ) { userService . delete ( delegatedAdminKey ) ; } } } @ Test public void checkFailedLogins ( ) { UserTO userTO = UserITCase . getUniqueSampleTO ( ""checkFailedLogin@syncope.apache.org"" ) ; userTO . getRoles ( ) . add ( ""User manager"" ) ; userTO = createUser ( userTO ) . getEntity ( ) ; assertNotNull ( userTO ) ; String userKey = userTO . getKey ( ) ; UserService userService2 = clientFactory . create ( userTO . getUsername ( ) , ""password123"" ) . getService ( UserService . class ) ; assertEquals ( 0 , getFailedLogins ( userService2 , userKey ) ) ; try { clientFactory . create ( userTO . getUsername ( ) , ""wrongpwd1"" ) ; fail ( ) ; } catch ( AccessControlException e ) { assertNotNull ( e ) ; } try { clientFactory . create ( userTO . getUsername ( ) , ""wrongpwd1"" ) ; fail ( ) ; } catch ( AccessControlException e ) { assertNotNull ( e ) ; } assertEquals ( 2 , getFailedLogins ( userService , userKey ) ) ; UserService userService4 = clientFactory . create ( userTO . getUsername ( ) , ""password123"" ) . getService ( UserService . class ) ; assertEquals ( 0 , getFailedLogins ( userService4 , userKey ) ) ; } @ Test public void checkUserSuspension ( ) { UserTO userTO = UserITCase . getUniqueSampleTO ( ""checkSuspension@syncope.apache.org"" ) ; userTO . setRealm ( ""/odd"" ) ; userTO . getRoles ( ) . add ( ""User manager"" ) ; userTO = createUser ( userTO ) . getEntity ( ) ; String userKey = userTO . getKey ( ) ; assertNotNull ( userTO ) ; assertEquals ( 0 , getFailedLogins ( userService , userKey ) ) ; try { clientFactory . create ( userTO . getUsername ( ) , ""wrongpwd1"" ) ; fail ( ) ; } catch ( AccessControlException e ) { assertNotNull ( e ) ; } try { clientFactory . create ( userTO . getUsername ( ) , ""wrongpwd1"" ) ; fail ( ) ; } catch ( AccessControlException e ) { assertNotNull ( e ) ; } try { clientFactory . create ( userTO . getUsername ( ) , ""wrongpwd1"" ) ; fail ( ) ; } catch ( AccessControlException e ) { assertNotNull ( e ) ; } assertEquals ( 3 , getFailedLogins ( userService , userKey ) ) ; try { clientFactory . create ( userTO . getUsername ( ) , ""wrongpwd1"" ) ; fail ( ) ; } catch ( AccessControlException e ) { assertNotNull ( e ) ; } userTO = userService . read ( userTO . getKey ( ) ) ; assertNotNull ( userTO ) ; assertNotNull ( userTO . getFailedLogins ( ) ) ; assertEquals ( 3 , userTO . getFailedLogins ( ) , 0 ) ; assertEquals ( ""suspended"" , userTO . getStatus ( ) ) ; try { clientFactory . create ( userTO . getUsername ( ) , ""password123"" ) ; fail ( ) ; } catch ( AccessControlException e ) { assertNotNull ( e ) ; } StatusPatch reactivate = new StatusPatch ( ) ; reactivate . setKey ( userTO . getKey ( ) ) ; reactivate . setType ( StatusPatchType . REACTIVATE ) ; userTO = userService . status ( reactivate ) . readEntity ( new GenericType < ProvisioningResult < UserTO > > ( ) { } ) . getEntity ( ) ; assertNotNull ( userTO ) ; assertEquals ( ""active"" , userTO . getStatus ( ) ) ; SyncopeClient goodPwdClient = clientFactory . create ( userTO . getUsername ( ) , ""password123"" ) ; assertEquals ( 0 , goodPwdClient . self ( ) . getValue ( ) . getFailedLogins ( ) , 0 ) ; } @ Test public void anyTypeEntitlement ( ) { final String anyTypeKey = ""FOLDER "" + getUUIDString ( ) ; assertFalse ( IterableUtils . matchesAny ( syncopeService . platform ( ) . getEntitlements ( ) , new Predicate < String > ( ) { @ Override public boolean evaluate ( final String entitlement ) { return entitlement . contains ( anyTypeKey ) ; } } ) ) ; PlainSchemaTO path = new PlainSchemaTO ( ) ; path . setKey ( ""path"" + getUUIDString ( ) ) ; path . setType ( AttrSchemaType . String ) ; path = createSchema ( SchemaType . PLAIN , path ) ; AnyTypeClassTO anyTypeClass = new AnyTypeClassTO ( ) ; anyTypeClass . setKey ( ""folder"" + getUUIDString ( ) ) ; anyTypeClass . getPlainSchemas ( ) . add ( path . getKey ( ) ) ; anyTypeClassService . create ( anyTypeClass ) ; AnyTypeTO anyTypeTO = new AnyTypeTO ( ) ; anyTypeTO . setKey ( anyTypeKey ) ; anyTypeTO . setKind ( AnyTypeKind . ANY_OBJECT ) ; anyTypeTO . getClasses ( ) . add ( anyTypeClass . getKey ( ) ) ; anyTypeService . create ( anyTypeTO ) ; assertTrue ( IterableUtils . matchesAny ( syncopeService . platform ( ) . getEntitlements ( ) , new Predicate < String > ( ) { @ Override public boolean evaluate ( final String entitlement ) { return entitlement . contains ( anyTypeKey ) ; } } ) ) ; AnyObjectTO folder = new AnyObjectTO ( ) ; folder . setName ( ""home"" ) ; folder . setRealm ( SyncopeConstants . ROOT_REALM ) ; folder . setType ( anyTypeKey ) ; folder . getPlainAttrs ( ) . add ( attrTO ( path . getKey ( ) , ""/home"" ) ) ; SyncopeClient belliniClient = clientFactory . create ( ""bellini"" , ADMIN_PWD ) ; try { belliniClient . getService ( AnyObjectService . class ) . create ( folder ) ; fail ( ) ; } catch ( SyncopeClientException e ) { assertEquals ( ClientExceptionType . DelegatedAdministration , e . getType ( ) ) ; } RoleTO role = new RoleTO ( ) ; role . setKey ( ""role"" + getUUIDString ( ) ) ; role . getRealms ( ) . add ( SyncopeConstants . ROOT_REALM ) ; role . getEntitlements ( ) . add ( anyTypeKey + ""_READ"" ) ; role . getEntitlements ( ) . add ( anyTypeKey + ""_CREATE"" ) ; role = createRole ( role ) ; UserTO bellini = userService . read ( ""bellini"" ) ; UserPatch patch = new UserPatch ( ) ; patch . setKey ( bellini . getKey ( ) ) ; patch . getRoles ( ) . add ( new StringPatchItem . Builder ( ) . operation ( PatchOperation . ADD_REPLACE ) . value ( role . getKey ( ) ) . build ( ) ) ; bellini = updateUser ( patch ) . getEntity ( ) ; assertTrue ( bellini . getRoles ( ) . contains ( role . getKey ( ) ) ) ; belliniClient . logout ( ) ; belliniClient . login ( new BasicAuthenticationHandler ( ""bellini"" , ADMIN_PWD ) ) ; belliniClient . getService ( AnyObjectService . class ) . create ( folder ) ; } @ Test public void issueSYNCOPE434 ( ) { Assume . assumeTrue ( ActivitiDetector . isActivitiEnabledForUsers ( syncopeService ) ) ; UserTO userTO = UserITCase . getUniqueSampleTO ( ""createWithReject@syncope.apache.org"" ) ; userTO . getMemberships ( ) . add ( new MembershipTO . Builder ( ) . group ( ""0cbcabd2-4410-4b6b-8f05-a052b451d18f"" ) . build ( ) ) ; userTO = createUser ( userTO ) . getEntity ( ) ; assertNotNull ( userTO ) ; assertEquals ( ""createApproval"" , userTO . getStatus ( ) ) ; try { clientFactory . create ( userTO . getUsername ( ) , ""password123"" ) . self ( ) ; fail ( ) ; } catch ( AccessControlException e ) { assertNotNull ( e ) ; } WorkflowFormTO form = userWorkflowService . getFormForUser ( userTO . getKey ( ) ) ; form = userWorkflowService . claimForm ( form . getTaskId ( ) ) ; form . getProperty ( ""approve"" ) . setValue ( Boolean . TRUE . toString ( ) ) ; userTO = userWorkflowService . submitForm ( form ) ; assertNotNull ( userTO ) ; assertEquals ( ""active"" , userTO . getStatus ( ) ) ; Pair < Map < String , Set < String > > , UserTO > self = clientFactory . create ( userTO . getUsername ( ) , ""password123"" ) . self ( ) ; assertNotNull ( self ) ; assertNotNull ( self . getKey ( ) ) ; assertNotNull ( self . getValue ( ) ) ; } @ Test public void issueSYNCOPE164 ( ) throws Exception { UserTO user = UserITCase . getUniqueSampleTO ( ""syncope164@syncope.apache.org"" ) ; user . setRealm ( ""/even/two"" ) ; user . setPassword ( ""password123"" ) ; user . getResources ( ) . add ( RESOURCE_NAME_TESTDB ) ; user = createUser ( user ) . getEntity ( ) ; assertNotNull ( user ) ; DeassociationPatch deassociationPatch = new DeassociationPatch ( ) ; deassociationPatch . setKey ( user . getKey ( ) ) ; deassociationPatch . setAction ( ResourceDeassociationAction . UNLINK ) ; deassociationPatch . getResources ( ) . add ( RESOURCE_NAME_TESTDB ) ; assertNotNull ( userService . deassociate ( deassociationPatch ) . readEntity ( BulkActionResult . class ) ) ; UserPatch userPatch = new UserPatch ( ) ; userPatch . setKey ( user . getKey ( ) ) ; userPatch . setPassword ( new PasswordPatch . Builder ( ) . value ( ""password234"" ) . build ( ) ) ; user = updateUser ( userPatch ) . getEntity ( ) ; assertNotNull ( user ) ; final JdbcTemplate jdbcTemplate = new JdbcTemplate ( testDataSource ) ; String value = queryForObject ( jdbcTemplate , 50 , ""SELECT PASSWORD FROM test WHERE ID=?"" , String . class , user . getUsername ( ) ) ; assertEquals ( Encryptor . getInstance ( ) . encode ( ""password123"" , CipherAlgorithm . SHA1 ) , value . toUpperCase ( ) ) ; Pair < Map < String , Set < String > > , UserTO > self = clientFactory . create ( user . getUsername ( ) , ""password123"" ) . self ( ) ; assertNotNull ( self ) ; self = clientFactory . create ( user . getUsername ( ) , ""password234"" ) . self ( ) ; assertNotNull ( self ) ; } @ Test public void issueSYNCOPE706 ( ) { String username = getUUIDString ( ) ; try { userService . read ( username ) ; fail ( ) ; } catch ( SyncopeClientException e ) { assertEquals ( ClientExceptionType . NotFound , e . getType ( ) ) ; } try { clientFactory . create ( username , ""anypassword"" ) . self ( ) ; fail ( ) ; } catch ( AccessControlException e ) { assertNotNull ( e . getMessage ( ) ) ; } } }",Smelly
"public class TestFunctionExpansion { @ BeforeClass public static void setup ( ) { UserDefinedFunctionFactory . getFactory ( ) . clear ( ) ; UserDefinedFunctionFactory . getFactory ( ) . setPreserveDependencies ( false ) ; } @ AfterClass public static void teardown ( ) { UserDefinedFunctionFactory . getFactory ( ) . clear ( ) ; UserDefinedFunctionFactory . getFactory ( ) . setPreserveDependencies ( false ) ; } @ Test public void test_function_expansion_01 ( ) { Expr e = new ExprVar ( ""x"" ) ; UserDefinedFunctionFactory . getFactory ( ) . add ( ""http://example/simple"" , e , new ArrayList < > ( e . getVarsMentioned ( ) ) ) ; UserDefinedFunction f = ( UserDefinedFunction ) UserDefinedFunctionFactory . getFactory ( ) . create ( ""http://example/simple"" ) ; f . build ( ""http://example/simple"" , new ExprList ( new NodeValueBoolean ( true ) ) ) ; Expr actual = f . getActualExpr ( ) ; Assert . assertFalse ( e . equals ( actual ) ) ; Assert . assertEquals ( 0 , actual . getVarsMentioned ( ) . size ( ) ) ; Assert . assertEquals ( new NodeValueBoolean ( true ) , actual ) ; } @ Test public void test_function_expansion_02 ( ) { Expr e = new E_Multiply ( new ExprVar ( ""x"" ) , new ExprVar ( ""x"" ) ) ; UserDefinedFunctionFactory . getFactory ( ) . add ( ""http://example/square"" , e , new ArrayList < > ( e . getVarsMentioned ( ) ) ) ; UserDefinedFunction f = ( UserDefinedFunction ) UserDefinedFunctionFactory . getFactory ( ) . create ( ""http://example/square"" ) ; f . build ( ""http://example/square"" , new ExprList ( new NodeValueInteger ( 3 ) ) ) ; Expr actual = f . getActualExpr ( ) ; Assert . assertFalse ( e . equals ( actual ) ) ; Assert . assertEquals ( 0 , actual . getVarsMentioned ( ) . size ( ) ) ; Assert . assertEquals ( new E_Multiply ( new NodeValueInteger ( 3 ) , new NodeValueInteger ( 3 ) ) , actual ) ; } @ Test public void test_function_expansion_03 ( ) { Expr e = new E_Multiply ( new ExprVar ( ""x"" ) , new ExprVar ( ""y"" ) ) ; List < Var > defArgs = new ArrayList < > ( ) ; defArgs . add ( Var . alloc ( ""x"" ) ) ; defArgs . add ( Var . alloc ( ""y"" ) ) ; UserDefinedFunctionFactory . getFactory ( ) . add ( ""http://example/square"" , e , defArgs ) ; UserDefinedFunction f = ( UserDefinedFunction ) UserDefinedFunctionFactory . getFactory ( ) . create ( ""http://example/square"" ) ; ExprList args = new ExprList ( ) ; args . add ( new NodeValueInteger ( 3 ) ) ; args . add ( new NodeValueInteger ( 4 ) ) ; f . build ( ""http://example/square"" , args ) ; Expr actual = f . getActualExpr ( ) ; Assert . assertFalse ( e . equals ( actual ) ) ; Assert . assertEquals ( 0 , actual . getVarsMentioned ( ) . size ( ) ) ; Assert . assertEquals ( new E_Multiply ( new NodeValueInteger ( 3 ) , new NodeValueInteger ( 4 ) ) , actual ) ; } @ Test public void test_function_expansion_04 ( ) { Expr square = new E_Multiply ( new ExprVar ( ""x"" ) , new ExprVar ( ""x"" ) ) ; UserDefinedFunctionFactory . getFactory ( ) . add ( ""http://example/square"" , square , new ArrayList < > ( square . getVarsMentioned ( ) ) ) ; Expr cube = new E_Multiply ( new E_Function ( ""http://example/square"" , new ExprList ( new ExprVar ( ""x"" ) ) ) , new ExprVar ( ""x"" ) ) ; UserDefinedFunctionFactory . getFactory ( ) . add ( ""http://example/cube"" , cube , new ArrayList < > ( cube . getVarsMentioned ( ) ) ) ; UserDefinedFunctionDefinition def = UserDefinedFunctionFactory . getFactory ( ) . get ( ""http://example/cube"" ) ; Expr base = def . getBaseExpr ( ) ; Assert . assertTrue ( base instanceof E_Multiply ) ; E_Multiply m = ( E_Multiply ) base ; Assert . assertTrue ( m . getArg1 ( ) instanceof E_Multiply ) ; Assert . assertTrue ( m . getArg2 ( ) instanceof ExprVar ) ; Assert . assertEquals ( 1 , base . getVarsMentioned ( ) . size ( ) ) ; } @ Test public void test_function_expansion_05 ( ) { Expr square = new E_Multiply ( new ExprVar ( ""x"" ) , new ExprVar ( ""x"" ) ) ; UserDefinedFunctionFactory . getFactory ( ) . add ( ""http://example/square"" , square , new ArrayList < > ( square . getVarsMentioned ( ) ) ) ; Expr cube = new E_Multiply ( new E_Function ( ""http://example/square"" , new ExprList ( new ExprVar ( ""y"" ) ) ) , new ExprVar ( ""y"" ) ) ; UserDefinedFunctionFactory . getFactory ( ) . add ( ""http://example/cube"" , cube , new ArrayList < > ( cube . getVarsMentioned ( ) ) ) ; UserDefinedFunctionDefinition def = UserDefinedFunctionFactory . getFactory ( ) . get ( ""http://example/cube"" ) ; Expr base = def . getBaseExpr ( ) ; Assert . assertTrue ( base instanceof E_Multiply ) ; E_Multiply m = ( E_Multiply ) base ; Assert . assertTrue ( m . getArg1 ( ) instanceof E_Multiply ) ; Assert . assertTrue ( m . getArg2 ( ) instanceof ExprVar ) ; Assert . assertEquals ( 1 , base . getVarsMentioned ( ) . size ( ) ) ; } @ Test public void test_function_expansion_06 ( ) { Expr takeaway = new E_Subtract ( new ExprVar ( ""x"" ) , new ExprVar ( ""y"" ) ) ; List < Var > args = new ArrayList < > ( ) ; args . add ( Var . alloc ( ""x"" ) ) ; args . add ( Var . alloc ( ""y"" ) ) ; UserDefinedFunctionFactory . getFactory ( ) . add ( ""http://example/takeaway"" , takeaway , args ) ; ExprList numArgs = new ExprList ( ) ; numArgs . add ( new NodeValueInteger ( 1 ) ) ; numArgs . add ( new NodeValueDouble ( 2.3 ) ) ; Expr test = new E_Function ( ""http://example/takeaway"" , numArgs ) ; UserDefinedFunctionFactory . getFactory ( ) . add ( ""http://example/test"" , test , new ArrayList < Var > ( ) ) ; UserDefinedFunctionDefinition def = UserDefinedFunctionFactory . getFactory ( ) . get ( ""http://example/test"" ) ; Expr base = def . getBaseExpr ( ) ; Assert . assertTrue ( base instanceof E_Subtract ) ; E_Subtract subtract = ( E_Subtract ) base ; Assert . assertTrue ( subtract . getArg1 ( ) instanceof NodeValueInteger ) ; Assert . assertTrue ( subtract . getArg2 ( ) instanceof NodeValueDouble ) ; } @ Test public void test_function_expansion_07 ( ) { Expr takeaway = new E_Subtract ( new ExprVar ( ""x"" ) , new ExprVar ( ""y"" ) ) ; List < Var > args = new ArrayList < > ( ) ; args . add ( Var . alloc ( ""x"" ) ) ; args . add ( Var . alloc ( ""y"" ) ) ; UserDefinedFunctionFactory . getFactory ( ) . add ( ""http://example/takeaway"" , takeaway , args ) ; ExprList numArgs = new ExprList ( ) ; numArgs . add ( new NodeValueDouble ( 2.3 ) ) ; numArgs . add ( new NodeValueInteger ( 1 ) ) ; Expr test = new E_Function ( ""http://example/takeaway"" , numArgs ) ; UserDefinedFunctionFactory . getFactory ( ) . add ( ""http://example/test"" , test , new ArrayList < Var > ( ) ) ; UserDefinedFunctionDefinition def = UserDefinedFunctionFactory . getFactory ( ) . get ( ""http://example/test"" ) ; Expr base = def . getBaseExpr ( ) ; Assert . assertTrue ( base instanceof E_Subtract ) ; E_Subtract subtract = ( E_Subtract ) base ; Assert . assertTrue ( subtract . getArg1 ( ) instanceof NodeValueDouble ) ; Assert . assertTrue ( subtract . getArg2 ( ) instanceof NodeValueInteger ) ; } @ Test public void test_function_expansion_08 ( ) { Expr takeaway = new E_Subtract ( new ExprVar ( ""x"" ) , new ExprVar ( ""y"" ) ) ; List < Var > args = new ArrayList < > ( ) ; args . add ( Var . alloc ( ""x"" ) ) ; args . add ( Var . alloc ( ""y"" ) ) ; UserDefinedFunctionFactory . getFactory ( ) . add ( ""http://example/takeaway"" , takeaway , args ) ; ExprList altArgs = new ExprList ( ) ; altArgs . add ( new ExprVar ( ""a"" ) ) ; altArgs . add ( new ExprVar ( ""b"" ) ) ; ArrayList < Var > defArgs = new ArrayList < > ( ) ; defArgs . add ( Var . alloc ( ""a"" ) ) ; defArgs . add ( Var . alloc ( ""b"" ) ) ; Expr test = new E_Function ( ""http://example/takeaway"" , altArgs ) ; UserDefinedFunctionFactory . getFactory ( ) . add ( ""http://example/test"" , test , defArgs ) ; UserDefinedFunctionDefinition def = UserDefinedFunctionFactory . getFactory ( ) . get ( ""http://example/test"" ) ; Expr base = def . getBaseExpr ( ) ; Assert . assertTrue ( base instanceof E_Subtract ) ; E_Subtract subtract = ( E_Subtract ) base ; Assert . assertTrue ( subtract . getArg1 ( ) instanceof ExprVar ) ; Assert . assertTrue ( subtract . getArg2 ( ) instanceof ExprVar ) ; Assert . assertEquals ( subtract . getArg1 ( ) . getVarName ( ) , ""a"" ) ; Assert . assertEquals ( subtract . getArg2 ( ) . getVarName ( ) , ""b"" ) ; } @ Test public void test_function_expansion_09 ( ) { Expr takeaway = new E_Subtract ( new ExprVar ( ""x"" ) , new ExprVar ( ""y"" ) ) ; List < Var > args = new ArrayList < > ( ) ; args . add ( Var . alloc ( ""x"" ) ) ; args . add ( Var . alloc ( ""y"" ) ) ; UserDefinedFunctionFactory . getFactory ( ) . add ( ""http://example/takeaway"" , takeaway , args ) ; ExprList altArgs = new ExprList ( ) ; altArgs . add ( new ExprVar ( ""b"" ) ) ; altArgs . add ( new ExprVar ( ""a"" ) ) ; ArrayList < Var > defArgs = new ArrayList < > ( ) ; defArgs . add ( Var . alloc ( ""a"" ) ) ; defArgs . add ( Var . alloc ( ""b"" ) ) ; Expr test = new E_Function ( ""http://example/takeaway"" , altArgs ) ; UserDefinedFunctionFactory . getFactory ( ) . add ( ""http://example/test"" , test , defArgs ) ; UserDefinedFunctionDefinition def = UserDefinedFunctionFactory . getFactory ( ) . get ( ""http://example/test"" ) ; Expr base = def . getBaseExpr ( ) ; Assert . assertTrue ( base instanceof E_Subtract ) ; E_Subtract subtract = ( E_Subtract ) base ; Assert . assertTrue ( subtract . getArg1 ( ) instanceof ExprVar ) ; Assert . assertTrue ( subtract . getArg2 ( ) instanceof ExprVar ) ; Assert . assertEquals ( subtract . getArg1 ( ) . getVarName ( ) , ""b"" ) ; Assert . assertEquals ( subtract . getArg2 ( ) . getVarName ( ) , ""a"" ) ; } @ Test public void test_function_expansion_10 ( ) { Expr single = new ExprVar ( ""x"" ) ; UserDefinedFunctionFactory . getFactory ( ) . add ( ""http://example/single"" , single , new ArrayList < > ( single . getVarsMentioned ( ) ) ) ; List < Var > args = new ArrayList < > ( ) ; args . add ( Var . alloc ( ""x"" ) ) ; args . add ( Var . alloc ( ""y"" ) ) ; Expr add = new E_Add ( new E_Function ( ""http://example/single"" , new ExprList ( new ExprVar ( ""x"" ) ) ) , new ExprVar ( ""y"" ) ) ; UserDefinedFunctionFactory . getFactory ( ) . add ( ""http://example/add"" , add , args ) ; UserDefinedFunctionDefinition def = UserDefinedFunctionFactory . getFactory ( ) . get ( ""http://example/add"" ) ; Expr base = def . getBaseExpr ( ) ; Assert . assertTrue ( base instanceof E_Add ) ; E_Add actual = ( E_Add ) base ; Assert . assertTrue ( actual . getArg1 ( ) instanceof ExprVar ) ; Assert . assertTrue ( actual . getArg2 ( ) instanceof ExprVar ) ; Assert . assertEquals ( ""x"" , actual . getArg1 ( ) . getVarName ( ) ) ; Assert . assertEquals ( ""y"" , actual . getArg2 ( ) . getVarName ( ) ) ; } @ Test public void test_function_expansion_11 ( ) { Expr single = new ExprVar ( ""x"" ) ; UserDefinedFunctionFactory . getFactory ( ) . add ( ""http://example/single"" , single , new ArrayList < > ( single . getVarsMentioned ( ) ) ) ; List < Var > args = new ArrayList < > ( ) ; args . add ( Var . alloc ( ""x"" ) ) ; args . add ( Var . alloc ( ""y"" ) ) ; Expr add = new E_Add ( new E_Function ( ""http://example/single"" , new ExprList ( new ExprVar ( ""y"" ) ) ) , new ExprVar ( ""y"" ) ) ; UserDefinedFunctionFactory . getFactory ( ) . add ( ""http://example/add"" , add , args ) ; UserDefinedFunctionDefinition def = UserDefinedFunctionFactory . getFactory ( ) . get ( ""http://example/add"" ) ; Expr base = def . getBaseExpr ( ) ; Assert . assertTrue ( base instanceof E_Add ) ; E_Add actual = ( E_Add ) base ; Assert . assertTrue ( actual . getArg1 ( ) instanceof ExprVar ) ; Assert . assertTrue ( actual . getArg2 ( ) instanceof ExprVar ) ; Assert . assertEquals ( ""y"" , actual . getArg1 ( ) . getVarName ( ) ) ; Assert . assertEquals ( ""y"" , actual . getArg2 ( ) . getVarName ( ) ) ; } @ Test public void test_function_expansion_12 ( ) { Expr takeaway = new E_Subtract ( new ExprVar ( ""x"" ) , new ExprVar ( ""y"" ) ) ; List < Var > args = new ArrayList < > ( ) ; args . add ( Var . alloc ( ""x"" ) ) ; args . add ( Var . alloc ( ""y"" ) ) ; UserDefinedFunctionFactory . getFactory ( ) . add ( ""http://example/takeaway"" , takeaway , args ) ; ExprList altArgs = new ExprList ( ) ; altArgs . add ( new ExprVar ( ""a"" ) ) ; altArgs . add ( new ExprVar ( ""a"" ) ) ; ArrayList < Var > defArgs = new ArrayList < > ( ) ; defArgs . add ( Var . alloc ( ""a"" ) ) ; defArgs . add ( Var . alloc ( ""b"" ) ) ; Expr test = new E_Function ( ""http://example/takeaway"" , altArgs ) ; UserDefinedFunctionFactory . getFactory ( ) . add ( ""http://example/test"" , test , defArgs ) ; UserDefinedFunctionDefinition def = UserDefinedFunctionFactory . getFactory ( ) . get ( ""http://example/test"" ) ; Expr base = def . getBaseExpr ( ) ; Assert . assertTrue ( base instanceof E_Subtract ) ; E_Subtract subtract = ( E_Subtract ) base ; Assert . assertTrue ( subtract . getArg1 ( ) instanceof ExprVar ) ; Assert . assertTrue ( subtract . getArg2 ( ) instanceof ExprVar ) ; Assert . assertEquals ( subtract . getArg1 ( ) . getVarName ( ) , ""a"" ) ; Assert . assertEquals ( subtract . getArg2 ( ) . getVarName ( ) , ""a"" ) ; } @ Test public void test_function_expansion_13 ( ) { Expr square = new E_Multiply ( new ExprVar ( ""x"" ) , new ExprVar ( ""x"" ) ) ; UserDefinedFunctionFactory . getFactory ( ) . add ( ""http://example/square"" , square , new ArrayList < > ( square . getVarsMentioned ( ) ) ) ; Expr cube = new E_Multiply ( new E_Function ( ""http://example/square"" , new ExprList ( new ExprVar ( ""x"" ) ) ) , new ExprVar ( ""x"" ) ) ; UserDefinedFunctionFactory . getFactory ( ) . add ( ""http://example/cube"" , cube , new ArrayList < > ( cube . getVarsMentioned ( ) ) ) ; UserDefinedFunction f = ( UserDefinedFunction ) UserDefinedFunctionFactory . getFactory ( ) . create ( ""http://example/cube"" ) ; f . build ( ""http://example/cube"" , new ExprList ( new NodeValueInteger ( 2 ) ) ) ; Expr actual = f . getActualExpr ( ) ; NodeValue result = actual . eval ( BindingFactory . create ( ) , LibTestExpr . createTest ( ) ) ; Assert . assertEquals ( 8 , NodeFactoryExtra . nodeToInt ( result . asNode ( ) ) ) ; square = new ExprVar ( ""x"" ) ; UserDefinedFunctionFactory . getFactory ( ) . add ( ""http://example/square"" , square , new ArrayList < > ( square . getVarsMentioned ( ) ) ) ; f . build ( ""http://example/cube"" , new ExprList ( new NodeValueInteger ( 2 ) ) ) ; actual = f . getActualExpr ( ) ; result = actual . eval ( BindingFactory . create ( ) , LibTestExpr . createTest ( ) ) ; Assert . assertEquals ( 8 , NodeFactoryExtra . nodeToInt ( result . asNode ( ) ) ) ; } @ Test ( expected = ExprBuildException . class ) public void test_function_expansion_bad_01 ( ) { List < Var > args = new ArrayList < > ( ) ; args . add ( Var . alloc ( ""x"" ) ) ; args . add ( Var . alloc ( ""y"" ) ) ; Expr add = new E_Add ( new ExprVar ( ""x"" ) , new ExprVar ( ""y"" ) ) ; UserDefinedFunctionFactory . getFactory ( ) . add ( ""http://example/add"" , add , new ArrayList < Var > ( ) ) ; } @ Test ( expected = ExprBuildException . class ) public void test_function_expansion_bad_02 ( ) { Expr single = new ExprVar ( ""x"" ) ; UserDefinedFunctionFactory . getFactory ( ) . add ( ""http://example/single"" , single , new ArrayList < > ( single . getVarsMentioned ( ) ) ) ; Expr test = new E_Function ( ""http://example/single"" , new ExprList ( new ExprVar ( ""x"" ) ) ) ; UserDefinedFunctionFactory . getFactory ( ) . add ( ""http://example/test"" , test , new ArrayList < Var > ( ) ) ; } }",No
"public class UserManagerImpl implements UserManager { private static final Logger log = LoggerFactory . getLogger ( UserManagerImpl . class ) ; private final Root root ; private final NamePathMapper namePathMapper ; private final SecurityProvider securityProvider ; private final UserProvider userProvider ; private final MembershipProvider membershipProvider ; private final ConfigurationParameters config ; private final List < AuthorizableAction > authorizableActions ; private UserQueryManager queryManager ; private ReadOnlyNodeTypeManager ntMgr ; public UserManagerImpl ( Root root , NamePathMapper namePathMapper , SecurityProvider securityProvider ) { this . root = root ; this . namePathMapper = namePathMapper ; this . securityProvider = securityProvider ; UserConfiguration uc = securityProvider . getConfiguration ( UserConfiguration . class ) ; this . config = uc . getParameters ( ) ; this . userProvider = new UserProvider ( root , config ) ; this . membershipProvider = new MembershipProvider ( root , config ) ; this . authorizableActions = uc . getAuthorizableActionProvider ( ) . getAuthorizableActions ( ) ; } @ Override public Authorizable getAuthorizable ( String id ) throws RepositoryException { checkIsLive ( ) ; Authorizable authorizable = null ; Tree tree = userProvider . getAuthorizable ( id ) ; if ( tree != null ) { authorizable = getAuthorizable ( id , tree ) ; } return authorizable ; } @ Override public Authorizable getAuthorizable ( Principal principal ) throws RepositoryException { checkIsLive ( ) ; return getAuthorizable ( userProvider . getAuthorizableByPrincipal ( principal ) ) ; } @ Override public Authorizable getAuthorizableByPath ( String path ) throws RepositoryException { checkIsLive ( ) ; String oakPath = namePathMapper . getOakPathKeepIndex ( path ) ; if ( oakPath == null ) { throw new RepositoryException ( ""Invalid path "" + path ) ; } return getAuthorizable ( userProvider . getAuthorizableByPath ( oakPath ) ) ; } @ Override public Iterator < Authorizable > findAuthorizables ( String relPath , String value ) throws RepositoryException { return findAuthorizables ( relPath , value , SEARCH_TYPE_AUTHORIZABLE ) ; } @ Override public Iterator < Authorizable > findAuthorizables ( String relPath , String value , int searchType ) throws RepositoryException { checkIsLive ( ) ; return getQueryManager ( ) . findAuthorizables ( relPath , value , AuthorizableType . getType ( searchType ) ) ; } @ Override public Iterator < Authorizable > findAuthorizables ( Query query ) throws RepositoryException { checkIsLive ( ) ; return getQueryManager ( ) . findAuthorizables ( query ) ; } @ Override public User createUser ( final String userId , String password ) throws RepositoryException { Principal principal = new PrincipalImpl ( userId ) ; return createUser ( userId , password , principal , null ) ; } @ Override public User createUser ( String userID , String password , Principal principal , @ Nullable String intermediatePath ) throws RepositoryException { checkIsLive ( ) ; checkValidID ( userID ) ; checkValidPrincipal ( principal , false ) ; if ( intermediatePath != null ) { intermediatePath = namePathMapper . getOakPathKeepIndex ( intermediatePath ) ; } Tree userTree = userProvider . createUser ( userID , intermediatePath ) ; setPrincipal ( userTree , principal ) ; if ( password != null ) { setPassword ( userTree , password , true ) ; } User user = new UserImpl ( userID , userTree , this ) ; onCreate ( user , password ) ; log . debug ( ""User created: "" + userID ) ; return user ; } @ Override public Group createGroup ( String groupId ) throws RepositoryException { Principal principal = new PrincipalImpl ( groupId ) ; return createGroup ( groupId , principal , null ) ; } @ Override public Group createGroup ( Principal principal ) throws RepositoryException { return createGroup ( principal , null ) ; } @ Override public Group createGroup ( Principal principal , @ Nullable String intermediatePath ) throws RepositoryException { return createGroup ( principal . getName ( ) , principal , intermediatePath ) ; } @ Override public Group createGroup ( String groupID , Principal principal , @ Nullable String intermediatePath ) throws RepositoryException { checkIsLive ( ) ; checkValidID ( groupID ) ; checkValidPrincipal ( principal , true ) ; if ( intermediatePath != null ) { intermediatePath = namePathMapper . getOakPathKeepIndex ( intermediatePath ) ; } Tree groupTree = userProvider . createGroup ( groupID , intermediatePath ) ; setPrincipal ( groupTree , principal ) ; Group group = new GroupImpl ( groupID , groupTree , this ) ; onCreate ( group ) ; log . debug ( ""Group created: "" + groupID ) ; return group ; } @ Override public boolean isAutoSave ( ) { return false ; } @ Override public void autoSave ( boolean enable ) throws RepositoryException { throw new UnsupportedRepositoryOperationException ( ""Session#save() is always required."" ) ; } void onCreate ( User user , String password ) throws RepositoryException { for ( AuthorizableAction action : authorizableActions ) { action . onCreate ( user , password , root , namePathMapper ) ; } } void onCreate ( Group group ) throws RepositoryException { for ( AuthorizableAction action : authorizableActions ) { action . onCreate ( group , root , namePathMapper ) ; } } void onRemove ( Authorizable authorizable ) throws RepositoryException { for ( AuthorizableAction action : authorizableActions ) { action . onRemove ( authorizable , root , namePathMapper ) ; } } void onPasswordChange ( User user , String password ) throws RepositoryException { for ( AuthorizableAction action : authorizableActions ) { action . onPasswordChange ( user , password , root , namePathMapper ) ; } } @ CheckForNull Authorizable getAuthorizable ( Tree tree ) throws RepositoryException { if ( tree == null || ! tree . exists ( ) ) { return null ; } return getAuthorizable ( userProvider . getAuthorizableId ( tree ) , tree ) ; } @ Nonnull NamePathMapper getNamePathMapper ( ) { return namePathMapper ; } @ Nonnull ReadOnlyNodeTypeManager getNodeTypeManager ( ) { if ( ntMgr == null ) { ntMgr = ReadOnlyNodeTypeManager . getInstance ( root , NamePathMapper . DEFAULT ) ; } return ntMgr ; } @ Nonnull MembershipProvider getMembershipProvider ( ) { return membershipProvider ; } @ Nonnull PrincipalManager getPrincipalManager ( ) throws RepositoryException { return securityProvider . getConfiguration ( PrincipalConfiguration . class ) . getPrincipalManager ( root , namePathMapper ) ; } @ Nonnull SecurityProvider getSecurityProvider ( ) { return securityProvider ; } @ Nonnull ConfigurationParameters getConfig ( ) { return config ; } @ CheckForNull private Authorizable getAuthorizable ( String id , Tree tree ) throws RepositoryException { if ( id == null || tree == null ) { return null ; } if ( UserUtility . isType ( tree , AuthorizableType . USER ) ) { return new UserImpl ( userProvider . getAuthorizableId ( tree ) , tree , this ) ; } else if ( UserUtility . isType ( tree , AuthorizableType . GROUP ) ) { return new GroupImpl ( userProvider . getAuthorizableId ( tree ) , tree , this ) ; } else { throw new RepositoryException ( ""Not a user or group tree "" + tree . getPath ( ) + '.' ) ; } } private void checkValidID ( String id ) throws RepositoryException { if ( id == null || id . length ( ) == 0 ) { throw new IllegalArgumentException ( ""Invalid ID "" + id ) ; } else if ( getAuthorizable ( id ) != null ) { throw new AuthorizableExistsException ( ""Authorizable with ID "" + id + "" already exists"" ) ; } } void checkValidPrincipal ( Principal principal , boolean isGroup ) throws RepositoryException { if ( principal == null || principal . getName ( ) == null || """" . equals ( principal . getName ( ) ) ) { throw new IllegalArgumentException ( ""Principal may not be null and must have a valid name."" ) ; } if ( ! isGroup && EveryonePrincipal . NAME . equals ( principal . getName ( ) ) ) { throw new IllegalArgumentException ( ""'everyone' is a reserved group principal name."" ) ; } if ( getAuthorizable ( principal ) != null ) { throw new AuthorizableExistsException ( ""Authorizable with principal "" + principal . getName ( ) + "" already exists."" ) ; } } void setPrincipal ( Tree authorizableTree , Principal principal ) { checkNotNull ( principal ) ; authorizableTree . setProperty ( UserConstants . REP_PRINCIPAL_NAME , principal . getName ( ) ) ; } void setPassword ( Tree userTree , String password , boolean forceHash ) throws RepositoryException { String pwHash ; if ( forceHash || PasswordUtility . isPlainTextPassword ( password ) ) { try { pwHash = PasswordUtility . buildPasswordHash ( password , config ) ; } catch ( NoSuchAlgorithmException e ) { throw new RepositoryException ( e ) ; } catch ( UnsupportedEncodingException e ) { throw new RepositoryException ( e ) ; } } else { pwHash = password ; } userTree . setProperty ( UserConstants . REP_PASSWORD , pwHash ) ; } private void checkIsLive ( ) throws RepositoryException { try { root . getBlobFactory ( ) ; } catch ( IllegalStateException e ) { throw new RepositoryException ( ""User manager is no longer alive."" ) ; } } private UserQueryManager getQueryManager ( ) { if ( queryManager == null ) { queryManager = new UserQueryManager ( this , namePathMapper , config , root ) ; } return queryManager ; } }",Smelly
"@ UseServerRuntime ( CayenneProjects . TESTMAP_PROJECT ) public class DataContextSharedCacheIT extends ServerCaseContextsSync { @ Inject private DataContext context ; @ Inject private DataContext context1 ; @ Inject private SQLTemplateCustomizer sqlTemplateCustomizer ; private Artist artist ; @ Before public void setUp ( ) throws Exception { artist = ( Artist ) context . newObject ( ""Artist"" ) ; artist . setArtistName ( ""version1"" ) ; artist . setDateOfBirth ( new Date ( ) ) ; context . commitChanges ( ) ; } @ Test public void testSnapshotChangePropagationOnSelect ( ) throws Exception { String originalName = artist . getArtistName ( ) ; final String newName = ""version2"" ; SQLTemplate query = sqlTemplateCustomizer . createSQLTemplate ( Artist . class , ""UPDATE ARTIST SET ARTIST_NAME = #bind($newName) "" + ""WHERE ARTIST_NAME = #bind($oldName)"" ) ; Map < String , Object > map = new HashMap < > ( 3 ) ; map . put ( ""newName"" , newName ) ; map . put ( ""oldName"" , originalName ) ; query . setParams ( map ) ; context . performNonSelectingQuery ( query ) ; Expression qual = ExpressionFactory . matchExp ( ""artistName"" , newName ) ; List artists = context1 . performQuery ( new SelectQuery < > ( Artist . class , qual ) ) ; assertEquals ( 1 , artists . size ( ) ) ; Artist altArtist = ( Artist ) artists . get ( 0 ) ; DataRow freshSnapshot = context . getObjectStore ( ) . getDataRowCache ( ) . getCachedSnapshot ( altArtist . getObjectId ( ) ) ; assertNotNull ( freshSnapshot ) ; assertEquals ( newName , freshSnapshot . get ( ""ARTIST_NAME"" ) ) ; assertEquals ( newName , altArtist . getArtistName ( ) ) ; ParallelTestContainer helper = new ParallelTestContainer ( ) { @ Override protected void assertResult ( ) throws Exception { assertEquals ( ""Peer object state wasn't refreshed on fetch"" , newName , artist . getArtistName ( ) ) ; } } ; helper . runTest ( 3000 ) ; } @ Test public void testSnapshotChangePropagation ( ) throws Exception { String originalName = artist . getArtistName ( ) ; final String newName = ""version2"" ; final Artist altArtist = context1 . localObject ( artist ) ; assertFalse ( altArtist == artist ) ; assertEquals ( originalName , altArtist . getArtistName ( ) ) ; assertEquals ( PersistenceState . COMMITTED , altArtist . getPersistenceState ( ) ) ; artist . setArtistName ( newName ) ; assertEquals ( originalName , altArtist . getArtistName ( ) ) ; context . commitChanges ( ) ; DataRow freshSnapshot = context . getObjectStore ( ) . getDataRowCache ( ) . getCachedSnapshot ( altArtist . getObjectId ( ) ) ; assertEquals ( newName , freshSnapshot . get ( ""ARTIST_NAME"" ) ) ; ParallelTestContainer helper = new ParallelTestContainer ( ) { @ Override protected void assertResult ( ) throws Exception { assertEquals ( newName , altArtist . getArtistName ( ) ) ; } } ; helper . runTest ( 3000 ) ; } @ Test public void testSnapshotChangePropagationToModifiedObjects ( ) throws Exception { String originalName = artist . getArtistName ( ) ; Date originalDate = artist . getDateOfBirth ( ) ; String newName = ""version2"" ; final Date newDate = new Date ( originalDate . getTime ( ) - 10000 ) ; final String newAltName = ""version3"" ; final Artist altArtist = context1 . localObject ( artist ) ; assertNotNull ( altArtist ) ; assertFalse ( altArtist == artist ) ; assertEquals ( originalName , altArtist . getArtistName ( ) ) ; assertEquals ( PersistenceState . COMMITTED , altArtist . getPersistenceState ( ) ) ; artist . setArtistName ( newName ) ; artist . setDateOfBirth ( newDate ) ; altArtist . setArtistName ( newAltName ) ; context . commitChanges ( ) ; DataRow freshSnapshot = context . getObjectStore ( ) . getDataRowCache ( ) . getCachedSnapshot ( altArtist . getObjectId ( ) ) ; assertEquals ( newName , freshSnapshot . get ( ""ARTIST_NAME"" ) ) ; assertEquals ( newDate , freshSnapshot . get ( ""DATE_OF_BIRTH"" ) ) ; ParallelTestContainer helper = new ParallelTestContainer ( ) { @ Override protected void assertResult ( ) throws Exception { assertEquals ( newAltName , altArtist . getArtistName ( ) ) ; assertEquals ( newDate , altArtist . getDateOfBirth ( ) ) ; assertEquals ( PersistenceState . MODIFIED , altArtist . getPersistenceState ( ) ) ; } } ; helper . runTest ( 3000 ) ; } @ Test public void testSnapshotDeletePropagationToCommitted ( ) throws Exception { final Artist altArtist = context1 . localObject ( artist ) ; assertNotNull ( altArtist ) ; assertFalse ( altArtist == artist ) ; assertEquals ( artist . getArtistName ( ) , altArtist . getArtistName ( ) ) ; assertEquals ( PersistenceState . COMMITTED , altArtist . getPersistenceState ( ) ) ; context . deleteObjects ( artist ) ; context . commitChanges ( ) ; assertNull ( context . getObjectStore ( ) . getDataRowCache ( ) . getCachedSnapshot ( altArtist . getObjectId ( ) ) ) ; ParallelTestContainer helper = new ParallelTestContainer ( ) { @ Override protected void assertResult ( ) throws Exception { assertEquals ( PersistenceState . TRANSIENT , altArtist . getPersistenceState ( ) ) ; assertNull ( altArtist . getObjectContext ( ) ) ; } } ; helper . runTest ( 3000 ) ; } @ Test public void testSnapshotDeletePropagationToHollow ( ) throws Exception { final Artist altArtist = context1 . localObject ( artist ) ; assertNotNull ( altArtist ) ; assertFalse ( altArtist == artist ) ; assertEquals ( PersistenceState . HOLLOW , altArtist . getPersistenceState ( ) ) ; context . deleteObjects ( artist ) ; context . commitChanges ( ) ; assertNull ( context . getObjectStore ( ) . getDataRowCache ( ) . getCachedSnapshot ( altArtist . getObjectId ( ) ) ) ; ParallelTestContainer helper = new ParallelTestContainer ( ) { @ Override protected void assertResult ( ) throws Exception { assertEquals ( PersistenceState . TRANSIENT , altArtist . getPersistenceState ( ) ) ; assertNull ( altArtist . getObjectContext ( ) ) ; } } ; helper . runTest ( 3000 ) ; } @ Test public void testSnapshotDeletePropagationToModified ( ) throws Exception { final Artist altArtist = context1 . localObject ( artist ) ; altArtist . getArtistName ( ) ; assertNotNull ( altArtist ) ; assertFalse ( altArtist == artist ) ; altArtist . setArtistName ( ""version2"" ) ; assertEquals ( PersistenceState . MODIFIED , altArtist . getPersistenceState ( ) ) ; context . deleteObjects ( artist ) ; context . commitChanges ( ) ; assertNull ( context . getObjectStore ( ) . getDataRowCache ( ) . getCachedSnapshot ( altArtist . getObjectId ( ) ) ) ; ParallelTestContainer helper = new ParallelTestContainer ( ) { @ Override protected void assertResult ( ) throws Exception { assertEquals ( PersistenceState . NEW , altArtist . getPersistenceState ( ) ) ; } } ; helper . runTest ( 3000 ) ; ObjectId id = altArtist . getObjectId ( ) ; assertNotNull ( id ) ; assertNotNull ( id . getIdSnapshot ( ) . get ( Artist . ARTIST_ID_PK_COLUMN ) ) ; assertFalse ( id . isTemporary ( ) ) ; context1 . commitChanges ( ) ; assertEquals ( PersistenceState . COMMITTED , altArtist . getPersistenceState ( ) ) ; } @ Test public void testSnapshotDeletePropagationToDeleted ( ) throws Exception { final Artist altArtist = context1 . localObject ( artist ) ; altArtist . getArtistName ( ) ; assertNotNull ( altArtist ) ; assertFalse ( altArtist == artist ) ; context1 . deleteObjects ( altArtist ) ; context . deleteObjects ( artist ) ; context . commitChanges ( ) ; assertNull ( context . getObjectStore ( ) . getDataRowCache ( ) . getCachedSnapshot ( altArtist . getObjectId ( ) ) ) ; ParallelTestContainer helper = new ParallelTestContainer ( ) { @ Override protected void assertResult ( ) throws Exception { assertEquals ( PersistenceState . TRANSIENT , altArtist . getPersistenceState ( ) ) ; assertNull ( altArtist . getObjectContext ( ) ) ; } } ; helper . runTest ( 3000 ) ; assertFalse ( context1 . hasChanges ( ) ) ; } @ Test public void testSnapshotDeletePropagationToManyRefresh ( ) throws Exception { Painting painting1 = ( Painting ) context . newObject ( ""Painting"" ) ; painting1 . setPaintingTitle ( ""p1"" ) ; painting1 . setToArtist ( artist ) ; Painting painting2 = ( Painting ) context . newObject ( ""Painting"" ) ; painting2 . setPaintingTitle ( ""p2"" ) ; painting2 . setToArtist ( artist ) ; context . commitChanges ( ) ; final Artist altArtist = context1 . localObject ( artist ) ; final Painting altPainting1 = context1 . localObject ( painting1 ) ; final Painting altPainting2 = context1 . localObject ( painting2 ) ; assertEquals ( artist . getArtistName ( ) , altArtist . getArtistName ( ) ) ; assertEquals ( painting1 . getPaintingTitle ( ) , altPainting1 . getPaintingTitle ( ) ) ; assertEquals ( painting2 . getPaintingTitle ( ) , altPainting2 . getPaintingTitle ( ) ) ; assertEquals ( 2 , altArtist . getPaintingArray ( ) . size ( ) ) ; assertEquals ( PersistenceState . COMMITTED , altArtist . getPersistenceState ( ) ) ; assertEquals ( PersistenceState . COMMITTED , altPainting1 . getPersistenceState ( ) ) ; assertEquals ( PersistenceState . COMMITTED , altPainting2 . getPersistenceState ( ) ) ; altPainting1 . getToArtist ( ) ; altPainting2 . getToArtist ( ) ; assertSame ( altArtist , altPainting1 . readPropertyDirectly ( ""toArtist"" ) ) ; assertSame ( altArtist , altPainting2 . readPropertyDirectly ( ""toArtist"" ) ) ; context . deleteObjects ( painting1 ) ; context . commitChanges ( ) ; assertNull ( context . getObjectStore ( ) . getDataRowCache ( ) . getCachedSnapshot ( painting1 . getObjectId ( ) ) ) ; ParallelTestContainer helper = new ParallelTestContainer ( ) { @ Override protected void assertResult ( ) throws Exception { assertEquals ( PersistenceState . TRANSIENT , altPainting1 . getPersistenceState ( ) ) ; assertEquals ( PersistenceState . COMMITTED , altArtist . getPersistenceState ( ) ) ; Collection < Painting > list = altArtist . getPaintingArray ( ) ; assertEquals ( 1 , list . size ( ) ) ; assertFalse ( list . contains ( altPainting1 ) ) ; } } ; helper . runTest ( 3000 ) ; } @ Test public void testSnapshotInsertPropagationToManyRefresh ( ) throws Exception { Painting painting1 = ( Painting ) context . newObject ( ""Painting"" ) ; painting1 . setPaintingTitle ( ""p1"" ) ; painting1 . setToArtist ( artist ) ; context . commitChanges ( ) ; final Artist altArtist = context1 . localObject ( artist ) ; final Painting altPainting1 = context1 . localObject ( painting1 ) ; assertEquals ( artist . getArtistName ( ) , altArtist . getArtistName ( ) ) ; assertEquals ( painting1 . getPaintingTitle ( ) , altPainting1 . getPaintingTitle ( ) ) ; assertEquals ( 1 , altArtist . getPaintingArray ( ) . size ( ) ) ; assertEquals ( PersistenceState . COMMITTED , altArtist . getPersistenceState ( ) ) ; assertEquals ( PersistenceState . COMMITTED , altPainting1 . getPersistenceState ( ) ) ; Painting painting2 = ( Painting ) context . newObject ( ""Painting"" ) ; painting2 . setPaintingTitle ( ""p2"" ) ; painting2 . setToArtist ( artist ) ; context . commitChanges ( ) ; ParallelTestContainer helper = new ParallelTestContainer ( ) { @ Override protected void assertResult ( ) throws Exception { Object value = altArtist . readPropertyDirectly ( ""paintingArray"" ) ; assertTrue ( ""Unexpected: "" + value , value instanceof ToManyList ) ; assertTrue ( ( ( ToManyList ) value ) . isFault ( ) ) ; } } ; helper . runTest ( 2000 ) ; List < Painting > list = altArtist . getPaintingArray ( ) ; assertEquals ( 2 , list . size ( ) ) ; } @ Test public void testCacheRefreshingOnSelect ( ) throws Exception { String originalName = artist . getArtistName ( ) ; final String newName = ""version2"" ; DataContext context = ( DataContext ) artist . getObjectContext ( ) ; DataRow oldSnapshot = context . getObjectStore ( ) . getDataRowCache ( ) . getCachedSnapshot ( artist . getObjectId ( ) ) ; assertNotNull ( oldSnapshot ) ; assertEquals ( originalName , oldSnapshot . get ( ""ARTIST_NAME"" ) ) ; SQLTemplate update = sqlTemplateCustomizer . createSQLTemplate ( Artist . class , ""UPDATE ARTIST SET ARTIST_NAME = #bind($newName) WHERE ARTIST_NAME = #bind($oldName)"" ) ; Map < String , Object > map = new HashMap < > ( 3 ) ; map . put ( ""newName"" , newName ) ; map . put ( ""oldName"" , originalName ) ; update . setParams ( map ) ; context . performNonSelectingQuery ( update ) ; Expression qual = ExpressionFactory . matchExp ( ""artistName"" , newName ) ; SelectQuery query = new SelectQuery < > ( Artist . class , qual ) ; List artists = context . performQuery ( query ) ; assertEquals ( 1 , artists . size ( ) ) ; artist = ( Artist ) artists . get ( 0 ) ; DataRow freshSnapshot = context . getObjectStore ( ) . getDataRowCache ( ) . getCachedSnapshot ( artist . getObjectId ( ) ) ; assertNotSame ( oldSnapshot , freshSnapshot ) ; assertEquals ( newName , freshSnapshot . get ( ""ARTIST_NAME"" ) ) ; assertEquals ( newName , artist . getArtistName ( ) ) ; } @ Test public void testSnapshotEvictedForHollow ( ) throws Exception { String originalName = artist . getArtistName ( ) ; context . invalidateObjects ( artist ) ; assertEquals ( PersistenceState . HOLLOW , artist . getPersistenceState ( ) ) ; assertNull ( context . getObjectStore ( ) . getDataRowCache ( ) . getCachedSnapshot ( artist . getObjectId ( ) ) ) ; assertEquals ( originalName , artist . getArtistName ( ) ) ; DataRow freshSnapshot = context . getObjectStore ( ) . getDataRowCache ( ) . getCachedSnapshot ( artist . getObjectId ( ) ) ; assertNotNull ( freshSnapshot ) ; assertEquals ( originalName , freshSnapshot . get ( ""ARTIST_NAME"" ) ) ; } @ Test public void testSnapshotEvictedAndObjectsHollowedForInvalidate ( ) throws Exception { String originalName = artist . getArtistName ( ) ; final Artist altArtist = context1 . localObject ( artist ) ; context1 . prepareForAccess ( altArtist , null , false ) ; assertEquals ( PersistenceState . COMMITTED , altArtist . getPersistenceState ( ) ) ; context . invalidateObjects ( artist ) ; assertEquals ( PersistenceState . HOLLOW , artist . getPersistenceState ( ) ) ; assertNull ( context . getObjectStore ( ) . getDataRowCache ( ) . getCachedSnapshot ( artist . getObjectId ( ) ) ) ; new ParallelTestContainer ( ) { @ Override protected void assertResult ( ) throws Exception { assertEquals ( PersistenceState . HOLLOW , altArtist . getPersistenceState ( ) ) ; assertNull ( context1 . getObjectStore ( ) . getDataRowCache ( ) . getCachedSnapshot ( altArtist . getObjectId ( ) ) ) ; } } . runTest ( 5000 ) ; assertEquals ( originalName , altArtist . getArtistName ( ) ) ; DataRow altFreshSnapshot = context1 . getObjectStore ( ) . getDataRowCache ( ) . getCachedSnapshot ( altArtist . getObjectId ( ) ) ; assertNotNull ( altFreshSnapshot ) ; assertEquals ( originalName , altFreshSnapshot . get ( ""ARTIST_NAME"" ) ) ; } @ Test public void testSnapshotEvictedForCommitted ( ) throws Exception { String newName = ""version2"" ; assertEquals ( PersistenceState . COMMITTED , artist . getPersistenceState ( ) ) ; context . getObjectStore ( ) . getDataRowCache ( ) . forgetSnapshot ( artist . getObjectId ( ) ) ; assertNull ( context . getObjectStore ( ) . getDataRowCache ( ) . getCachedSnapshot ( artist . getObjectId ( ) ) ) ; artist . setArtistName ( newName ) ; context . commitChanges ( ) ; assertEquals ( newName , artist . getArtistName ( ) ) ; DataRow freshSnapshot = context . getObjectStore ( ) . getDataRowCache ( ) . getCachedSnapshot ( artist . getObjectId ( ) ) ; assertNotNull ( freshSnapshot ) ; assertEquals ( newName , freshSnapshot . get ( ""ARTIST_NAME"" ) ) ; } @ Test public void testSnapshotEvictedForModified ( ) throws Exception { String newName = ""version2"" ; assertEquals ( PersistenceState . COMMITTED , artist . getPersistenceState ( ) ) ; artist . setArtistName ( newName ) ; context . getObjectStore ( ) . getDataRowCache ( ) . forgetSnapshot ( artist . getObjectId ( ) ) ; assertNull ( context . getObjectStore ( ) . getDataRowCache ( ) . getCachedSnapshot ( artist . getObjectId ( ) ) ) ; context . commitChanges ( ) ; assertEquals ( newName , artist . getArtistName ( ) ) ; DataRow freshSnapshot = context . getObjectStore ( ) . getDataRowCache ( ) . getCachedSnapshot ( artist . getObjectId ( ) ) ; assertNotNull ( freshSnapshot ) ; assertEquals ( newName , freshSnapshot . get ( ""ARTIST_NAME"" ) ) ; } @ Test public void testSnapshotEvictedAndChangedForModified ( ) throws Exception { String originalName = artist . getArtistName ( ) ; String newName = ""version2"" ; String backendName = ""version3"" ; assertEquals ( PersistenceState . COMMITTED , artist . getPersistenceState ( ) ) ; artist . setArtistName ( newName ) ; context . getObjectStore ( ) . getDataRowCache ( ) . forgetSnapshot ( artist . getObjectId ( ) ) ; assertNull ( context . getObjectStore ( ) . getDataRowCache ( ) . getCachedSnapshot ( artist . getObjectId ( ) ) ) ; String template = ""UPDATE ARTIST SET ARTIST_NAME = #bind($newName) WHERE ARTIST_NAME = #bind($oldName)"" ; SQLTemplate update = new SQLTemplate ( Artist . class , template ) ; Map < String , Object > map = new HashMap < > ( 3 ) ; map . put ( ""newName"" , backendName ) ; map . put ( ""oldName"" , originalName ) ; update . setParams ( map ) ; context . performNonSelectingQuery ( update ) ; context . commitChanges ( ) ; assertEquals ( newName , artist . getArtistName ( ) ) ; DataRow freshSnapshot = context . getObjectStore ( ) . getDataRowCache ( ) . getCachedSnapshot ( artist . getObjectId ( ) ) ; assertNotNull ( freshSnapshot ) ; assertEquals ( newName , freshSnapshot . get ( ""ARTIST_NAME"" ) ) ; } @ Test public void testSnapshotEvictedForDeleted ( ) throws Exception { ObjectId id = artist . getObjectId ( ) ; assertEquals ( PersistenceState . COMMITTED , artist . getPersistenceState ( ) ) ; context . deleteObjects ( artist ) ; context . getObjectStore ( ) . getDataRowCache ( ) . forgetSnapshot ( id ) ; assertNull ( context . getObjectStore ( ) . getDataRowCache ( ) . getCachedSnapshot ( id ) ) ; context . commitChanges ( ) ; assertEquals ( PersistenceState . TRANSIENT , artist . getPersistenceState ( ) ) ; assertNull ( context . getObjectStore ( ) . getDataRowCache ( ) . getCachedSnapshot ( id ) ) ; } }",Smelly
"@ RunWith ( JUnit4 . class ) public class TopWikipediaSessionsTest { @ Rule public TestPipeline p = TestPipeline . create ( ) ; @ Test @ Category ( ValidatesRunner . class ) public void testComputeTopUsers ( ) { PCollection < String > output = p . apply ( Create . of ( Arrays . asList ( new TableRow ( ) . set ( ""timestamp"" , 0 ) . set ( ""contributor_username"" , ""user1"" ) , new TableRow ( ) . set ( ""timestamp"" , 1 ) . set ( ""contributor_username"" , ""user1"" ) , new TableRow ( ) . set ( ""timestamp"" , 2 ) . set ( ""contributor_username"" , ""user1"" ) , new TableRow ( ) . set ( ""timestamp"" , 0 ) . set ( ""contributor_username"" , ""user2"" ) , new TableRow ( ) . set ( ""timestamp"" , 1 ) . set ( ""contributor_username"" , ""user2"" ) , new TableRow ( ) . set ( ""timestamp"" , 3601 ) . set ( ""contributor_username"" , ""user2"" ) , new TableRow ( ) . set ( ""timestamp"" , 3602 ) . set ( ""contributor_username"" , ""user2"" ) , new TableRow ( ) . set ( ""timestamp"" , 35 * 24 * 3600 ) . set ( ""contributor_username"" , ""user3"" ) ) ) ) . apply ( new TopWikipediaSessions . ComputeTopSessions ( 1.0 ) ) ; PAssert . that ( output ) . containsInAnyOrder ( Arrays . asList ( ""user1 : [1970-01-01T00:00:00.000Z..1970-01-01T01:00:02.000Z)"" + "" : 3 : 1970-01-01T00:00:00.000Z"" , ""user3 : [1970-02-05T00:00:00.000Z..1970-02-05T01:00:00.000Z)"" + "" : 1 : 1970-02-01T00:00:00.000Z"" ) ) ; p . run ( ) . waitUntilFinish ( ) ; } }",No
"public class IvyResolve extends IvyTask { private File file = null ; private String conf = null ; private String organisation = null ; private String module = null ; private String revision = null ; private String pubdate = null ; private boolean inline = false ; private boolean haltOnFailure = true ; private boolean useCacheOnly = false ; private String type = null ; private boolean transitive = true ; private boolean refresh = false ; private boolean changing = false ; private Boolean keep = null ; private String failureProperty = null ; private boolean useOrigin = false ; private String resolveMode = null ; private String resolveId = null ; private String log = ResolveOptions . LOG_DEFAULT ; private boolean checkIfChanged = true ; public boolean isUseOrigin ( ) { return useOrigin ; } public void setUseOrigin ( boolean useOrigin ) { this . useOrigin = useOrigin ; } public String getDate ( ) { return pubdate ; } public void setDate ( String pubdate ) { this . pubdate = pubdate ; } public String getRevision ( ) { return revision ; } public void setRevision ( String revision ) { this . revision = revision ; } public void setCache ( File cache ) { cacheAttributeNotSupported ( ) ; } public String getConf ( ) { return conf ; } public void setConf ( String conf ) { this . conf = conf ; } public File getFile ( ) { return file ; } public void setFile ( File file ) { this . file = file ; } public boolean isHaltonfailure ( ) { return haltOnFailure ; } public void setHaltonfailure ( boolean haltOnFailure ) { this . haltOnFailure = haltOnFailure ; } public void setShowprogress ( boolean show ) { Message . setShowProgress ( show ) ; } public boolean isUseCacheOnly ( ) { return useCacheOnly ; } public void setUseCacheOnly ( boolean useCacheOnly ) { this . useCacheOnly = useCacheOnly ; } public String getType ( ) { return type ; } public void setType ( String type ) { this . type = type ; } public boolean isRefresh ( ) { return refresh ; } public void setRefresh ( boolean refresh ) { this . refresh = refresh ; } public String getLog ( ) { return log ; } public void setLog ( String log ) { this . log = log ; } public void setFailurePropery ( String failureProperty ) { log ( ""The 'failurepropery' attribute is deprecated. "" + ""Please use the 'failureproperty' attribute instead"" , Project . MSG_WARN ) ; setFailureProperty ( failureProperty ) ; } public void setFailureProperty ( String failureProperty ) { this . failureProperty = failureProperty ; } public String getFailureProperty ( ) { return failureProperty ; } public void doExecute ( ) throws BuildException { Ivy ivy = getIvyInstance ( ) ; IvySettings settings = ivy . getSettings ( ) ; try { conf = getProperty ( conf , settings , ""ivy.configurations"" ) ; type = getProperty ( type , settings , ""ivy.resolve.default.type.filter"" ) ; String [ ] confs = splitConfs ( conf ) ; ResolveReport report ; if ( isInline ( ) ) { if ( organisation == null ) { throw new BuildException ( ""'organisation' is required when using inline mode"" ) ; } if ( module == null ) { throw new BuildException ( ""'module' is required when using inline mode"" ) ; } if ( file != null ) { throw new BuildException ( ""'file' not allowed when using inline mode"" ) ; } if ( ! getAllowedLogOptions ( ) . contains ( log ) ) { throw new BuildException ( ""invalid option for 'log': "" + log + "". Available options are "" + getAllowedLogOptions ( ) ) ; } for ( int i = 0 ; i < confs . length ; i ++ ) { if ( ""*"" . equals ( confs [ i ] ) ) { confs [ i ] = ""*(public)"" ; } } if ( revision == null ) { revision = ""latest.integration"" ; } report = ivy . resolve ( ModuleRevisionId . newInstance ( organisation , module , revision ) , getResolveOptions ( ivy , confs , settings ) , changing ) ; } else { if ( organisation != null ) { throw new BuildException ( ""'organisation' not allowed when not using 'org' attribute"" ) ; } if ( module != null ) { throw new BuildException ( ""'module' not allowed when not using 'org' attribute"" ) ; } if ( file == null ) { file = getProject ( ) . resolveFile ( getProperty ( settings , ""ivy.dep.file"" ) ) ; } report = ivy . resolve ( file . toURI ( ) . toURL ( ) , getResolveOptions ( ivy , confs , settings ) ) ; } if ( report . hasError ( ) ) { if ( failureProperty != null ) { getProject ( ) . setProperty ( failureProperty , ""true"" ) ; } if ( isHaltonfailure ( ) ) { throw new BuildException ( ""resolve failed - see output for details"" ) ; } } setResolved ( report , resolveId , isKeep ( ) ) ; confs = report . getConfigurations ( ) ; if ( isKeep ( ) ) { ModuleDescriptor md = report . getModuleDescriptor ( ) ; getProject ( ) . setProperty ( ""ivy.organisation"" , md . getModuleRevisionId ( ) . getOrganisation ( ) ) ; settings . setVariable ( ""ivy.organisation"" , md . getModuleRevisionId ( ) . getOrganisation ( ) ) ; getProject ( ) . setProperty ( ""ivy.module"" , md . getModuleRevisionId ( ) . getName ( ) ) ; settings . setVariable ( ""ivy.module"" , md . getModuleRevisionId ( ) . getName ( ) ) ; getProject ( ) . setProperty ( ""ivy.revision"" , md . getResolvedModuleRevisionId ( ) . getRevision ( ) ) ; settings . setVariable ( ""ivy.revision"" , md . getResolvedModuleRevisionId ( ) . getRevision ( ) ) ; Boolean hasChanged = null ; if ( getCheckIfChanged ( ) ) { hasChanged = Boolean . valueOf ( report . hasChanged ( ) ) ; getProject ( ) . setProperty ( ""ivy.deps.changed"" , hasChanged . toString ( ) ) ; settings . setVariable ( ""ivy.deps.changed"" , hasChanged . toString ( ) ) ; } getProject ( ) . setProperty ( ""ivy.resolved.configurations"" , mergeConfs ( confs ) ) ; settings . setVariable ( ""ivy.resolved.configurations"" , mergeConfs ( confs ) ) ; if ( file != null ) { getProject ( ) . setProperty ( ""ivy.resolved.file"" , file . getAbsolutePath ( ) ) ; settings . setVariable ( ""ivy.resolved.file"" , file . getAbsolutePath ( ) ) ; } if ( resolveId != null ) { getProject ( ) . setProperty ( ""ivy.organisation."" + resolveId , md . getModuleRevisionId ( ) . getOrganisation ( ) ) ; settings . setVariable ( ""ivy.organisation."" + resolveId , md . getModuleRevisionId ( ) . getOrganisation ( ) ) ; getProject ( ) . setProperty ( ""ivy.module."" + resolveId , md . getModuleRevisionId ( ) . getName ( ) ) ; settings . setVariable ( ""ivy.module."" + resolveId , md . getModuleRevisionId ( ) . getName ( ) ) ; getProject ( ) . setProperty ( ""ivy.revision."" + resolveId , md . getResolvedModuleRevisionId ( ) . getRevision ( ) ) ; settings . setVariable ( ""ivy.revision."" + resolveId , md . getResolvedModuleRevisionId ( ) . getRevision ( ) ) ; if ( getCheckIfChanged ( ) ) { getProject ( ) . setProperty ( ""ivy.deps.changed."" + resolveId , hasChanged . toString ( ) ) ; settings . setVariable ( ""ivy.deps.changed."" + resolveId , hasChanged . toString ( ) ) ; } getProject ( ) . setProperty ( ""ivy.resolved.configurations."" + resolveId , mergeConfs ( confs ) ) ; settings . setVariable ( ""ivy.resolved.configurations."" + resolveId , mergeConfs ( confs ) ) ; if ( file != null ) { getProject ( ) . setProperty ( ""ivy.resolved.file."" + resolveId , file . getAbsolutePath ( ) ) ; settings . setVariable ( ""ivy.resolved.file."" + resolveId , file . getAbsolutePath ( ) ) ; } } } } catch ( MalformedURLException e ) { throw new BuildException ( ""unable to convert given ivy file to url: "" + file + "": "" + e , e ) ; } catch ( ParseException e ) { log ( e . getMessage ( ) , Project . MSG_ERR ) ; throw new BuildException ( ""syntax errors in ivy file: "" + e , e ) ; } catch ( ResolveProcessException e ) { throw new BuildException ( ""impossible to resolve dependencies:\n\t"" + e . getMessage ( ) , e ) ; } catch ( Exception e ) { throw new BuildException ( ""impossible to resolve dependencies:\n\t"" + e , e ) ; } } protected Collection getAllowedLogOptions ( ) { return Arrays . asList ( new String [ ] { LogOptions . LOG_DEFAULT , LogOptions . LOG_DOWNLOAD_ONLY , LogOptions . LOG_QUIET } ) ; } private ResolveOptions getResolveOptions ( Ivy ivy , String [ ] confs , IvySettings settings ) { if ( useOrigin ) { settings . useDeprecatedUseOrigin ( ) ; } return ( ( ResolveOptions ) new ResolveOptions ( ) . setLog ( log ) ) . setConfs ( confs ) . setValidate ( doValidate ( settings ) ) . setArtifactFilter ( FilterHelper . getArtifactTypeFilter ( type ) ) . setRevision ( revision ) . setDate ( getPubDate ( pubdate , null ) ) . setUseCacheOnly ( useCacheOnly ) . setRefresh ( refresh ) . setTransitive ( transitive ) . setResolveMode ( resolveMode ) . setResolveId ( resolveId ) . setCheckIfChanged ( checkIfChanged ) ; } public String getModule ( ) { return module ; } public void setModule ( String module ) { this . module = module ; } public String getOrganisation ( ) { return organisation ; } public void setOrganisation ( String organisation ) { this . organisation = organisation ; } public boolean isTransitive ( ) { return transitive ; } public void setTransitive ( boolean transitive ) { this . transitive = transitive ; } public boolean isChanging ( ) { return changing ; } public void setChanging ( boolean changing ) { this . changing = changing ; } public boolean isKeep ( ) { return keep == null ? organisation == null : keep . booleanValue ( ) ; } public void setKeep ( boolean keep ) { this . keep = Boolean . valueOf ( keep ) ; } public boolean isInline ( ) { return inline ; } public void setInline ( boolean inline ) { this . inline = inline ; } public String getResolveId ( ) { return resolveId ; } public void setResolveId ( String resolveId ) { this . resolveId = resolveId ; } public String getResolveMode ( ) { return resolveMode ; } public void setResolveMode ( String resolveMode ) { this . resolveMode = resolveMode ; } public boolean getCheckIfChanged ( ) { return checkIfChanged ; } public void setCheckIfChanged ( boolean checkIfChanged ) { this . checkIfChanged = checkIfChanged ; } }",Smelly
"public class XmppConsumer extends DefaultConsumer < XmppExchange > implements PacketListener , MessageListener { private static final transient Log LOG = LogFactory . getLog ( XmppConsumer . class ) ; private final XmppEndpoint endpoint ; private Chat privateChat ; private MultiUserChat muc ; public XmppConsumer ( XmppEndpoint endpoint , Processor processor ) { super ( endpoint , processor ) ; this . endpoint = endpoint ; } @ Override protected void doStart ( ) throws Exception { if ( endpoint . getRoom ( ) == null ) { privateChat = endpoint . getConnection ( ) . getChatManager ( ) . createChat ( endpoint . getParticipant ( ) , this ) ; LOG . info ( ""Open chat to "" + privateChat . getParticipant ( ) ) ; } else { muc = new MultiUserChat ( endpoint . getConnection ( ) , endpoint . resolveRoom ( ) ) ; muc . addMessageListener ( this ) ; DiscussionHistory history = new DiscussionHistory ( ) ; history . setMaxChars ( 0 ) ; muc . join ( endpoint . getNickname ( ) , null , history , SmackConfiguration . getPacketReplyTimeout ( ) ) ; LOG . info ( ""Joined room: "" + muc . getRoom ( ) ) ; } super . doStart ( ) ; } @ Override protected void doStop ( ) throws Exception { super . doStop ( ) ; if ( muc != null ) { muc . leave ( ) ; muc = null ; } } public void processPacket ( Packet packet ) { Message message = ( Message ) packet ; if ( LOG . isDebugEnabled ( ) ) { LOG . debug ( ""Recieved XMPP message: "" + message . getBody ( ) ) ; } XmppExchange exchange = endpoint . createExchange ( message ) ; try { getProcessor ( ) . process ( exchange ) ; } catch ( Exception e ) { LOG . error ( ""Error while processing message"" , e ) ; } } public void processMessage ( Chat chat , Message message ) { processPacket ( message ) ; } }",No
"public class UdpTransportBean extends TransportBean { public UdpTransportBean ( ) { super ( ) ; } public String toString ( String tabs ) { return tabs + ""UDP transport : \n"" + super . toString ( ""  "" + tabs ) ; } public String toString ( ) { return toString ( """" ) ; } }",No
"@ DomainService ( nature = NatureOfService . DOMAIN , menuOrder = """" + Integer . MAX_VALUE ) @ RequestScoped public class ChangedObjectsServiceInternal implements WithTransactionScope { private final Map < AdapterAndProperty , PreAndPostValues > enlistedObjectProperties = Maps . newLinkedHashMap ( ) ; private Set < Map . Entry < AdapterAndProperty , PreAndPostValues > > changedObjectProperties ; private final Map < ObjectAdapter , PublishedObject . ChangeKind > changeKindByEnlistedAdapter = Maps . newLinkedHashMap ( ) ; @ Programmatic public boolean isEnlisted ( ObjectAdapter adapter ) { return changeKindByEnlistedAdapter . containsKey ( adapter ) ; } @ Programmatic public void enlistCreated ( final ObjectAdapter adapter ) { if ( shouldIgnore ( adapter ) ) { return ; } enlistForPublishing ( adapter , PublishedObject . ChangeKind . CREATE ) ; for ( ObjectAssociation property : adapter . getSpecification ( ) . getAssociations ( Contributed . EXCLUDED , ObjectAssociation . Filters . PROPERTIES ) ) { final AdapterAndProperty aap = AdapterAndProperty . of ( adapter , property ) ; if ( property . isNotPersisted ( ) ) { continue ; } if ( enlistedObjectProperties . containsKey ( aap ) ) { return ; } PreAndPostValues papv = PreAndPostValues . pre ( IsisTransaction . Placeholder . NEW ) ; enlistedObjectProperties . put ( aap , papv ) ; } } @ Programmatic public void enlistUpdating ( final ObjectAdapter adapter ) { if ( shouldIgnore ( adapter ) ) { return ; } enlistForPublishing ( adapter , PublishedObject . ChangeKind . UPDATE ) ; for ( ObjectAssociation property : adapter . getSpecification ( ) . getAssociations ( Contributed . EXCLUDED , ObjectAssociation . Filters . PROPERTIES ) ) { final AdapterAndProperty aap = AdapterAndProperty . of ( adapter , property ) ; if ( property . isNotPersisted ( ) ) { continue ; } if ( enlistedObjectProperties . containsKey ( aap ) ) { continue ; } PreAndPostValues papv = PreAndPostValues . pre ( aap . getPropertyValue ( ) ) ; enlistedObjectProperties . put ( aap , papv ) ; } } @ Programmatic public void enlistDeleting ( final ObjectAdapter adapter ) { if ( shouldIgnore ( adapter ) ) { return ; } final boolean enlisted = enlistForPublishing ( adapter , PublishedObject . ChangeKind . DELETE ) ; if ( ! enlisted ) { return ; } for ( ObjectAssociation property : adapter . getSpecification ( ) . getAssociations ( Contributed . EXCLUDED , ObjectAssociation . Filters . PROPERTIES ) ) { final AdapterAndProperty aap = AdapterAndProperty . of ( adapter , property ) ; if ( property . isNotPersisted ( ) ) { continue ; } if ( enlistedObjectProperties . containsKey ( aap ) ) { return ; } PreAndPostValues papv = PreAndPostValues . pre ( aap . getPropertyValue ( ) ) ; enlistedObjectProperties . put ( aap , papv ) ; } } private boolean enlistForPublishing ( final ObjectAdapter adapter , final PublishedObject . ChangeKind current ) { final PublishedObject . ChangeKind previous = changeKindByEnlistedAdapter . get ( adapter ) ; if ( previous == null ) { changeKindByEnlistedAdapter . put ( adapter , current ) ; return true ; } switch ( previous ) { case CREATE : switch ( current ) { case DELETE : changeKindByEnlistedAdapter . remove ( adapter ) ; case CREATE : case UPDATE : return false ; } break ; case UPDATE : switch ( current ) { case DELETE : changeKindByEnlistedAdapter . put ( adapter , current ) ; return true ; case CREATE : case UPDATE : return false ; } break ; case DELETE : return false ; } return previous == null ; } @ Programmatic public Set < Map . Entry < AdapterAndProperty , PreAndPostValues > > getChangedObjectProperties ( ) { return changedObjectProperties != null ? changedObjectProperties : ( changedObjectProperties = capturePostValuesAndDrain ( enlistedObjectProperties ) ) ; } private Set < Map . Entry < AdapterAndProperty , PreAndPostValues > > capturePostValuesAndDrain ( final Map < AdapterAndProperty , PreAndPostValues > changedObjectProperties ) { return AdapterManager . ConcurrencyChecking . executeWithConcurrencyCheckingDisabled ( new Callable < Set < Map . Entry < AdapterAndProperty , PreAndPostValues > > > ( ) { @ Override public Set < Map . Entry < AdapterAndProperty , PreAndPostValues > > call ( ) { final Map < AdapterAndProperty , PreAndPostValues > processedObjectProperties = Maps . newLinkedHashMap ( ) ; while ( ! changedObjectProperties . isEmpty ( ) ) { final Set < AdapterAndProperty > keys = Sets . newLinkedHashSet ( changedObjectProperties . keySet ( ) ) ; for ( final AdapterAndProperty aap : keys ) { final PreAndPostValues papv = changedObjectProperties . remove ( aap ) ; final ObjectAdapter adapter = aap . getAdapter ( ) ; if ( adapter . isDestroyed ( ) ) { papv . setPost ( IsisTransaction . Placeholder . DELETED ) ; } else { papv . setPost ( aap . getPropertyValue ( ) ) ; } processedObjectProperties . put ( aap , papv ) ; } } return Collections . unmodifiableSet ( Sets . filter ( processedObjectProperties . entrySet ( ) , PreAndPostValues . Predicates . SHOULD_AUDIT ) ) ; } } ) ; } protected boolean shouldIgnore ( final ObjectAdapter adapter ) { final ObjectSpecification adapterSpec = adapter . getSpecification ( ) ; final Class < ? > adapterClass = adapterSpec . getCorrespondingClass ( ) ; return HasTransactionId . class . isAssignableFrom ( adapterClass ) ; } @ Programmatic public Map < ObjectAdapter , PublishedObject . ChangeKind > getChangeKindByEnlistedAdapter ( ) { return changeKindByEnlistedAdapter ; } @ Programmatic public int numberObjectsDirtied ( ) { return changeKindByEnlistedAdapter . size ( ) ; } @ Programmatic public int numberObjectPropertiesModified ( ) { if ( changedObjectProperties == null ) { getChangedObjectProperties ( ) ; } return changedObjectProperties . size ( ) ; } @ Override @ Programmatic public void resetForNextTransaction ( ) { enlistedObjectProperties . clear ( ) ; changedObjectProperties = null ; } static String asString ( Object object ) { return object != null ? object . toString ( ) : null ; } }",Smelly
 private static class getTabletStats_resultTupleSchemeFactory implements SchemeFactory { public getTabletStats_resultTupleScheme getScheme ( ) { return new getTabletStats_resultTupleScheme ( ) ; } ,No
"public class LockTest extends AbstractJCRTest { private static final int NUM_THREADS = 100 ; private static final int NUM_CHANGES = 10 ; private static final int NUM_VALUE_GETS = 10 ; public void testLockUtility ( ) throws RepositoryException { final Node lockable = testRootNode . addNode ( nodeName1 ) ; lockable . addMixin ( mixLockable ) ; testRootNode . save ( ) ; final List worker = new ArrayList ( ) ; for ( int i = 0 ; i < NUM_THREADS ; i ++ ) { worker . add ( new Thread ( ) { private final int threadNumber = worker . size ( ) ; public void run ( ) { Session s ; try { s = getHelper ( ) . getSuperuserSession ( ) ; } catch ( RepositoryException e ) { return ; } try { for ( int i = 0 ; i < NUM_CHANGES ; i ++ ) { Node n = ( Node ) s . getItem ( lockable . getPath ( ) ) ; new Locked ( ) { protected Object run ( Node n ) throws RepositoryException { String nodeName = ""node"" + threadNumber ; if ( n . hasNode ( nodeName ) ) { n . getNode ( nodeName ) . remove ( ) ; } else { n . addNode ( nodeName ) ; } n . save ( ) ; log . println ( ""Thread"" + threadNumber + "": saved modification"" ) ; return null ; } } . with ( n , false ) ; Thread . sleep ( new Random ( ) . nextInt ( 100 ) ) ; } } catch ( RepositoryException e ) { log . println ( ""exception while running code with lock:"" + e . getMessage ( ) ) ; } catch ( InterruptedException e ) { log . println ( Thread . currentThread ( ) + "" interrupted while waiting for lock"" ) ; } finally { s . logout ( ) ; } } } ) ; } for ( Iterator it = worker . iterator ( ) ; it . hasNext ( ) ; ) { ( ( Thread ) it . next ( ) ) . start ( ) ; } for ( Iterator it = worker . iterator ( ) ; it . hasNext ( ) ; ) { try { ( ( Thread ) it . next ( ) ) . join ( ) ; } catch ( InterruptedException e ) { e . printStackTrace ( ) ; } } } public void testSequence ( ) throws RepositoryException { final Node counter = testRootNode . addNode ( nodeName1 ) ; counter . setProperty ( ""value"" , 0 ) ; counter . addMixin ( mixLockable ) ; testRootNode . save ( ) ; final List worker = new ArrayList ( ) ; for ( int i = 0 ; i < NUM_THREADS ; i ++ ) { worker . add ( new Thread ( ) { private final int threadNumber = worker . size ( ) ; public void run ( ) { Session s ; try { s = getHelper ( ) . getSuperuserSession ( ) ; } catch ( RepositoryException e ) { return ; } try { for ( int i = 0 ; i < NUM_VALUE_GETS ; i ++ ) { Node n = ( Node ) s . getItem ( counter . getPath ( ) ) ; long currentValue = ( ( Long ) new Locked ( ) { protected Object run ( Node n ) throws RepositoryException { Property seqProp = n . getProperty ( ""value"" ) ; long value = seqProp . getLong ( ) ; seqProp . setValue ( ++ value ) ; seqProp . save ( ) ; return new Long ( value ) ; } } . with ( n , false ) ) . longValue ( ) ; log . println ( ""Thread"" + threadNumber + "": got sequence number: "" + currentValue ) ; Thread . sleep ( new Random ( ) . nextInt ( 100 ) ) ; } } catch ( RepositoryException e ) { log . println ( ""exception while running code with lock:"" + e . getMessage ( ) ) ; } catch ( InterruptedException e ) { log . println ( Thread . currentThread ( ) + "" interrupted while waiting for lock"" ) ; } finally { s . logout ( ) ; } } } ) ; } for ( Iterator it = worker . iterator ( ) ; it . hasNext ( ) ; ) { ( ( Thread ) it . next ( ) ) . start ( ) ; } for ( Iterator it = worker . iterator ( ) ; it . hasNext ( ) ; ) { try { ( ( Thread ) it . next ( ) ) . join ( ) ; } catch ( InterruptedException e ) { e . printStackTrace ( ) ; } } } public void testSequenceWithTimeout ( ) throws RepositoryException { final Node counter = testRootNode . addNode ( nodeName1 ) ; counter . setProperty ( ""value"" , 0 ) ; counter . addMixin ( mixLockable ) ; testRootNode . save ( ) ; final List worker = new ArrayList ( ) ; for ( int i = 0 ; i < NUM_THREADS ; i ++ ) { worker . add ( new Thread ( ) { private final int threadNumber = worker . size ( ) ; public void run ( ) { Session s ; try { s = getHelper ( ) . getSuperuserSession ( ) ; } catch ( RepositoryException e ) { return ; } try { for ( int i = 0 ; i < NUM_VALUE_GETS ; i ++ ) { Node n = ( Node ) s . getItem ( counter . getPath ( ) ) ; Object ret = new Locked ( ) { protected Object run ( Node n ) throws RepositoryException { Property seqProp = n . getProperty ( ""value"" ) ; long value = seqProp . getLong ( ) ; seqProp . setValue ( ++ value ) ; seqProp . save ( ) ; return new Long ( value ) ; } } . with ( n , false , 10 * 1000 ) ; if ( ret == Locked . TIMED_OUT ) { log . println ( ""Thread"" + threadNumber + "": could not get a sequence number within 10 seconds"" ) ; } else { long currentValue = ( ( Long ) ret ) . longValue ( ) ; log . println ( ""Thread"" + threadNumber + "": got sequence number: "" + currentValue ) ; } Thread . sleep ( new Random ( ) . nextInt ( 100 ) ) ; } } catch ( RepositoryException e ) { log . println ( ""exception while running code with lock:"" + e . getMessage ( ) ) ; } catch ( InterruptedException e ) { log . println ( Thread . currentThread ( ) + "" interrupted while waiting for lock"" ) ; } finally { s . logout ( ) ; } } } ) ; } for ( Iterator it = worker . iterator ( ) ; it . hasNext ( ) ; ) { ( ( Thread ) it . next ( ) ) . start ( ) ; } for ( Iterator it = worker . iterator ( ) ; it . hasNext ( ) ; ) { try { ( ( Thread ) it . next ( ) ) . join ( ) ; } catch ( InterruptedException e ) { e . printStackTrace ( ) ; } } } }",No
"public class RankedList extends ArrayList < Condition > { private static final long serialVersionUID = - 5978107285325156323L ; Map < Condition , Double > ranking ; Map < String , Double > idf ; public RankedList ( Map < String , Double > i ) { super ( ) ; ranking = new HashMap < Condition , Double > ( ) ; idf = i ; } public RankedList ( Collection < ? extends Condition > c , Map < String , Double > i ) { super ( ) ; ranking = new HashMap < Condition , Double > ( ) ; idf = i ; addAll ( c ) ; } @ Override public boolean add ( Condition e ) { boolean result ; double value ; if ( idf . containsKey ( e . getItem ( ) . getAnnotation ( ) . getType ( ) . getShortName ( ) ) ) value = idf . get ( e . getItem ( ) . getAnnotation ( ) . getType ( ) . getShortName ( ) ) ; else value = 1.0 ; if ( ranking . containsKey ( e ) ) { Double rank = ranking . get ( e ) ; rank = new Double ( rank . doubleValue ( ) + value ) ; ranking . put ( e , rank ) ; result = false ; } else { super . add ( e ) ; ranking . put ( e , new Double ( value ) ) ; result = true ; } return result ; } public void add ( double index , Condition e ) { if ( ranking . containsKey ( e ) ) { Double rank = ranking . get ( e ) ; rank = new Double ( rank . doubleValue ( ) + index ) ; ranking . put ( e , rank ) ; } else { super . add ( e ) ; ranking . put ( e , new Double ( index ) ) ; } } public void addAll ( RankedList list ) { for ( Condition each : list ) { add ( list . rankingOf ( each ) , each ) ; } } @ Override public boolean addAll ( Collection < ? extends Condition > c ) { for ( Condition each : c ) { add ( each ) ; } return true ; } public boolean addAll ( double index , Collection < ? extends Condition > c ) { for ( Condition each : c ) { add ( index , each ) ; } return true ; } @ Override public Condition remove ( int index ) { Condition element = super . get ( index ) ; if ( element != null ) { if ( ranking . containsKey ( element ) ) { ranking . remove ( element ) ; super . remove ( index ) ; return element ; } } return null ; } @ Override public boolean remove ( Object o ) { if ( size ( ) > 0 ) { if ( contains ( o ) && ranking . containsKey ( o ) ) { super . remove ( o ) ; ranking . remove ( o ) ; return true ; } } return false ; } @ Override public List < Condition > subList ( int start , int end ) { return super . subList ( start , end ) ; } @ Override public boolean contains ( Object o ) { return super . contains ( o ) ; } @ Override public void clear ( ) { super . clear ( ) ; ranking . clear ( ) ; } @ Override public int size ( ) { return super . size ( ) ; } @ Override public RankedList clone ( ) { RankedList clone = new RankedList ( idf ) ; for ( Condition element : subList ( 0 , size ( ) ) ) { clone . add ( rankingOf ( element ) , element . clone ( ) ) ; } return clone ; } @ Override public Condition get ( int i ) { return super . get ( i ) ; } public double rankingOf ( Condition each ) { if ( contains ( each ) ) { return ranking . get ( each ) . doubleValue ( ) ; } return 0 ; } public Map < Condition , Double > getRanking ( ) { return ranking ; } public void sort ( ) { List < Condition > newList = new ArrayList < Condition > ( ) ; for ( int i = 0 ; i < size ( ) ; i ++ ) { for ( int j = 0 ; j < newList . size ( ) ; j ++ ) { if ( ranking . get ( get ( i ) ) . doubleValue ( ) >= ranking . get ( newList . get ( j ) ) . doubleValue ( ) ) { newList . add ( j , get ( i ) ) ; break ; } } if ( ! newList . contains ( get ( i ) ) ) newList . add ( get ( i ) ) ; } super . clear ( ) ; super . addAll ( newList ) ; } public RankedList unite ( RankedList list ) { RankedList clone = clone ( ) ; for ( Condition element : list . subList ( 0 , list . size ( ) ) ) { clone . add ( list . rankingOf ( element ) , element . clone ( ) ) ; } clone . sort ( ) ; return clone ; } public RankedList cut ( RankedList list ) { RankedList clone = clone ( ) ; for ( Condition element : subList ( 0 , size ( ) ) ) { if ( list . contains ( element ) ) { clone . add ( list . rankingOf ( element ) , element . clone ( ) ) ; } else { clone . remove ( element ) ; } } clone . sort ( ) ; return clone ; } public RankedList subtract ( RankedList list ) { RankedList clone = clone ( ) ; for ( Condition element : subList ( 0 , size ( ) ) ) { if ( list . contains ( element ) ) { clone . remove ( element ) ; } else { clone . add ( list . rankingOf ( element ) , element . clone ( ) ) ; } } clone . sort ( ) ; return clone ; } @ Override public Condition set ( int index , Condition element ) { if ( size ( ) >= index ) { double value = ranking . get ( get ( index ) ) ; if ( contains ( element ) ) { ranking . put ( element , new Double ( ranking . get ( element ) . doubleValue ( ) + index ) ) ; super . remove ( element ) ; } else ranking . put ( element , value ) ; ranking . remove ( get ( index ) ) ; } return super . set ( index , element ) ; } @ Override public void add ( int index , Condition element ) { if ( size ( ) >= index ) { double value = ranking . get ( get ( index ) ) ; if ( ! contains ( element ) ) { ranking . put ( element , value ) ; super . add ( index , element ) ; } } } @ Override public boolean addAll ( int index , Collection < ? extends Condition > c ) { if ( size ( ) >= index ) { double value = ranking . get ( get ( index ) ) ; for ( Condition element : c ) { if ( ! contains ( element ) ) { ranking . put ( element , value ) ; super . add ( index , element ) ; return true ; } } } return false ; } @ Override protected void removeRange ( int fromIndex , int toIndex ) { for ( int i = fromIndex ; i < toIndex ; i ++ ) { ranking . remove ( get ( i ) ) ; } super . removeRange ( fromIndex , toIndex ) ; } }",Smelly
" static class SingularJoin < Z , X > extends FromImpl < Z , X > implements Join < Z , X > { private final JoinType joinType ; private boolean allowNull = false ; public SingularJoin ( FromImpl < ? , Z > from , Members . SingularAttributeImpl < ? super Z , X > member , JoinType jt ) { super ( from , member , member . getJavaType ( ) ) ; joinType = jt ; allowNull = joinType != JoinType . INNER ; } public JoinType getJoinType ( ) { return joinType ; } public FromImpl < ? , Z > getParent ( ) { return ( FromImpl < ? , Z > ) _parent ; } public Member < ? extends Z , X > getMember ( ) { return ( Member < ? extends Z , X > ) _member ; } public Attribute < ? super Z , ? > getAttribute ( ) { return ( Attribute < ? super Z , ? > ) _member ; } @ Override public Value toValue ( ExpressionFactory factory , CriteriaQueryImpl < ? > c ) { ClassMetaData meta = _member . fmd . getDeclaredTypeMetaData ( ) ; org . apache . openjpa . kernel . exps . Path path = null ; SubqueryImpl < ? > subquery = c . getDelegator ( ) ; PathImpl < ? , ? > parent = getInnermostParentPath ( ) ; Value val = c . getRegisteredValue ( this ) ; if ( val != null ) return val ; else if ( parent . inSubquery ( subquery ) ) { org . apache . openjpa . kernel . exps . Subquery subQ = subquery . getSubQ ( ) ; path = factory . newPath ( subQ ) ; path . setMetaData ( subQ . getMetaData ( ) ) ; path . setSchemaAlias ( c . getAlias ( this ) ) ; path . get ( _member . fmd , allowNull ) ; } else { path = ( org . apache . openjpa . kernel . exps . Path ) _parent . toValue ( factory , c ) ; path . get ( _member . fmd , allowNull ) ; path . setMetaData ( meta ) ; path . setImplicitType ( meta . getDescribedType ( ) ) ; } return path ; } @ Override public org . apache . openjpa . kernel . exps . Expression toKernelExpression ( ExpressionFactory factory , CriteriaQueryImpl < ? > c ) { ClassMetaData meta = _member . fmd . getDeclaredTypeMetaData ( ) ; org . apache . openjpa . kernel . exps . Path path = null ; SubqueryImpl < ? > subquery = c . getDelegator ( ) ; PathImpl < ? , ? > parent = getInnermostParentPath ( ) ; org . apache . openjpa . kernel . exps . Expression filter = null ; PathImpl < ? , ? > correlatedParentPath = null ; boolean bind = true ; java . util . Set < Join < ? , ? > > corrJoins = null ; org . apache . openjpa . kernel . exps . Expression join = null ; if ( ! isCorrelated ( ) ) { if ( subquery != null ) { corrJoins = subquery . getCorrelatedJoins ( ) ; org . apache . openjpa . kernel . exps . Subquery subQ = subquery . getSubQ ( ) ; if ( ( ! corrJoins . isEmpty ( ) && corrJoins . contains ( _parent ) ) || ( corrJoins . isEmpty ( ) && parent . inSubquery ( subquery ) && _parent . getCorrelatedPath ( ) != null ) ) { path = factory . newPath ( subQ ) ; correlatedParentPath = _parent . getCorrelatedPath ( ) ; bind = false ; } else { if ( c . isRegistered ( _parent ) ) { Value var = c . getRegisteredVariable ( _parent ) ; path = factory . newPath ( var ) ; } else { path = factory . newPath ( subQ ) ; } path . setMetaData ( meta ) ; path . get ( _member . fmd , allowNull ) ; path . setSchemaAlias ( c . getAlias ( _parent ) ) ; } } else if ( c . isRegistered ( _parent ) ) { Value var = c . getRegisteredVariable ( _parent ) ; path = factory . newPath ( var ) ; path . setMetaData ( meta ) ; path . get ( _member . fmd , allowNull ) ; } else path = ( org . apache . openjpa . kernel . exps . Path ) toValue ( factory , c ) ; Class < ? > type = meta == null ? AbstractExpressionBuilder . TYPE_OBJECT : meta . getDescribedType ( ) ; Value var = null ; if ( bind ) { var = factory . newBoundVariable ( c . getAlias ( this ) , type ) ; join = factory . bindVariable ( var , path ) ; c . registerVariable ( this , var , path ) ; } if ( ! _member . fmd . isTypePC ( ) ) { setImplicitContainsTypes ( path , var , AbstractExpressionBuilder . CONTAINS_TYPE_ELEMENT ) ; join = factory . contains ( path , var ) ; } } if ( getJoins ( ) != null ) { for ( Join < ? , ? > join1 : getJoins ( ) ) { filter = Expressions . and ( factory , ( ( FromImpl < ? , ? > ) join1 ) . toKernelExpression ( factory , c ) , filter ) ; } } org . apache . openjpa . kernel . exps . Expression expr = Expressions . and ( factory , join , filter ) ; if ( correlatedParentPath == null ) { return expr ; } else { org . apache . openjpa . kernel . exps . Path parentPath = null ; if ( corrJoins != null && corrJoins . contains ( _parent ) ) { Value var = getVariableForCorrPath ( subquery , correlatedParentPath ) ; parentPath = factory . newPath ( var ) ; } else { parentPath = ( org . apache . openjpa . kernel . exps . Path ) correlatedParentPath . toValue ( factory , c ) ; } parentPath . get ( _member . fmd , allowNull ) ; parentPath . setSchemaAlias ( c . getAlias ( correlatedParentPath ) ) ; if ( c . ctx ( ) . getParent ( ) != null && c . ctx ( ) . getVariable ( parentPath . getSchemaAlias ( ) ) == null ) parentPath . setSubqueryContext ( c . ctx ( ) , parentPath . getSchemaAlias ( ) ) ; path . setMetaData ( meta ) ; filter = factory . equal ( parentPath , path ) ; return Expressions . and ( factory , expr , filter ) ; } } private Value getVariableForCorrPath ( SubqueryImpl < ? > subquery , PathImpl < ? , ? > path ) { AbstractQuery < ? > parent = subquery . getParent ( ) ; if ( parent instanceof CriteriaQueryImpl ) { return ( ( CriteriaQueryImpl < ? > ) parent ) . getRegisteredVariable ( path ) ; } Value var = ( ( SubqueryImpl < ? > ) parent ) . getDelegate ( ) . getRegisteredVariable ( path ) ; if ( var != null ) return var ; return getVariableForCorrPath ( ( SubqueryImpl < ? > ) parent , path ) ; } public void setImplicitContainsTypes ( Value val1 , Value val2 , int op ) { if ( val1 . getType ( ) == AbstractExpressionBuilder . TYPE_OBJECT ) { if ( op == AbstractExpressionBuilder . CONTAINS_TYPE_ELEMENT ) val1 . setImplicitType ( Collection . class ) ; else val1 . setImplicitType ( Map . class ) ; } if ( val2 . getType ( ) == AbstractExpressionBuilder . TYPE_OBJECT && val1 instanceof Path ) { FieldMetaData fmd = ( ( org . apache . openjpa . kernel . exps . Path ) val1 ) . last ( ) ; ClassMetaData meta ; if ( fmd != null ) { if ( op == AbstractExpressionBuilder . CONTAINS_TYPE_ELEMENT || op == AbstractExpressionBuilder . CONTAINS_TYPE_VALUE ) { val2 . setImplicitType ( fmd . getElement ( ) . getDeclaredType ( ) ) ; meta = fmd . getElement ( ) . getDeclaredTypeMetaData ( ) ; if ( meta != null ) { val2 . setMetaData ( meta ) ; } } else { val2 . setImplicitType ( fmd . getKey ( ) . getDeclaredType ( ) ) ; meta = fmd . getKey ( ) . getDeclaredTypeMetaData ( ) ; if ( meta != null ) { val2 . setMetaData ( meta ) ; } } } } } @ Override public StringBuilder asVariable ( AliasContext q ) { return new StringBuilder ( "" "" + joinType + "" JOIN "" ) . append ( super . asVariable ( q ) ) ; } ",No
"public class JdbcMemoryTransactionStore extends MemoryTransactionStore { private HashMap < ActiveMQDestination , MessageStore > topicStores = new HashMap < ActiveMQDestination , MessageStore > ( ) ; public JdbcMemoryTransactionStore ( JDBCPersistenceAdapter jdbcPersistenceAdapter ) { super ( jdbcPersistenceAdapter ) ; } @ Override public void prepare ( TransactionId txid ) throws IOException { Tx tx = inflightTransactions . remove ( txid ) ; if ( tx == null ) { return ; } ConnectionContext ctx = new ConnectionContext ( ) ; ctx . setXid ( ( XATransactionId ) txid ) ; persistenceAdapter . beginTransaction ( ctx ) ; try { for ( Iterator < AddMessageCommand > iter = tx . messages . iterator ( ) ; iter . hasNext ( ) ; ) { AddMessageCommand cmd = iter . next ( ) ; cmd . run ( ctx ) ; } for ( Iterator < RemoveMessageCommand > iter = tx . acks . iterator ( ) ; iter . hasNext ( ) ; ) { RemoveMessageCommand cmd = iter . next ( ) ; cmd . run ( ctx ) ; } } catch ( IOException e ) { persistenceAdapter . rollbackTransaction ( ctx ) ; throw e ; } persistenceAdapter . commitTransaction ( ctx ) ; ctx . setXid ( null ) ; ArrayList < AddMessageCommand > updateFromPreparedStateCommands = new ArrayList < AddMessageCommand > ( ) ; for ( Iterator < AddMessageCommand > iter = tx . messages . iterator ( ) ; iter . hasNext ( ) ; ) { final AddMessageCommand addMessageCommand = iter . next ( ) ; updateFromPreparedStateCommands . add ( new AddMessageCommand ( ) { @ Override public Message getMessage ( ) { return addMessageCommand . getMessage ( ) ; } @ Override public MessageStore getMessageStore ( ) { return addMessageCommand . getMessageStore ( ) ; } @ Override public void run ( ConnectionContext context ) throws IOException { JDBCPersistenceAdapter jdbcPersistenceAdapter = ( JDBCPersistenceAdapter ) persistenceAdapter ; Message message = addMessageCommand . getMessage ( ) ; jdbcPersistenceAdapter . commitAdd ( context , message . getMessageId ( ) ) ; ( ( JDBCMessageStore ) addMessageCommand . getMessageStore ( ) ) . onAdd ( message . getMessageId ( ) , ( Long ) message . getMessageId ( ) . getDataLocator ( ) , message . getPriority ( ) ) ; } } ) ; } tx . messages = updateFromPreparedStateCommands ; preparedTransactions . put ( txid , tx ) ; } @ Override public void rollback ( TransactionId txid ) throws IOException { Tx tx = inflightTransactions . remove ( txid ) ; if ( tx == null ) { tx = preparedTransactions . remove ( txid ) ; if ( tx != null ) { ConnectionContext ctx = new ConnectionContext ( ) ; persistenceAdapter . beginTransaction ( ctx ) ; try { for ( Iterator < AddMessageCommand > iter = tx . messages . iterator ( ) ; iter . hasNext ( ) ; ) { final Message message = iter . next ( ) . getMessage ( ) ; ( ( JDBCPersistenceAdapter ) persistenceAdapter ) . commitRemove ( ctx , new MessageAck ( message , MessageAck . STANDARD_ACK_TYPE , 1 ) ) ; } for ( Iterator < RemoveMessageCommand > iter = tx . acks . iterator ( ) ; iter . hasNext ( ) ; ) { RemoveMessageCommand removeMessageCommand = iter . next ( ) ; if ( removeMessageCommand instanceof LastAckCommand ) { ( ( LastAckCommand ) removeMessageCommand ) . rollback ( ctx ) ; } else { ( ( JDBCPersistenceAdapter ) persistenceAdapter ) . commitAdd ( ctx , removeMessageCommand . getMessageAck ( ) . getLastMessageId ( ) ) ; } } } catch ( IOException e ) { persistenceAdapter . rollbackTransaction ( ctx ) ; throw e ; } persistenceAdapter . commitTransaction ( ctx ) ; } } } @ Override public void recover ( TransactionRecoveryListener listener ) throws IOException { ( ( JDBCPersistenceAdapter ) persistenceAdapter ) . recover ( this ) ; super . recover ( listener ) ; } public void recoverAdd ( long id , byte [ ] messageBytes ) throws IOException { final Message message = ( Message ) ( ( JDBCPersistenceAdapter ) persistenceAdapter ) . getWireFormat ( ) . unmarshal ( new ByteSequence ( messageBytes ) ) ; message . getMessageId ( ) . setDataLocator ( id ) ; Tx tx = getPreparedTx ( message . getTransactionId ( ) ) ; tx . add ( new AddMessageCommand ( ) { @ Override public Message getMessage ( ) { return message ; } @ Override public MessageStore getMessageStore ( ) { return null ; } @ Override public void run ( ConnectionContext context ) throws IOException { ( ( JDBCPersistenceAdapter ) persistenceAdapter ) . commitAdd ( null , message . getMessageId ( ) ) ; } } ) ; } public void recoverAck ( long id , byte [ ] xid , byte [ ] message ) throws IOException { Message msg = ( Message ) ( ( JDBCPersistenceAdapter ) persistenceAdapter ) . getWireFormat ( ) . unmarshal ( new ByteSequence ( message ) ) ; msg . getMessageId ( ) . setDataLocator ( id ) ; Tx tx = getPreparedTx ( new XATransactionId ( xid ) ) ; final MessageAck ack = new MessageAck ( msg , MessageAck . STANDARD_ACK_TYPE , 1 ) ; tx . add ( new RemoveMessageCommand ( ) { @ Override public MessageAck getMessageAck ( ) { return ack ; } @ Override public void run ( ConnectionContext context ) throws IOException { ( ( JDBCPersistenceAdapter ) persistenceAdapter ) . commitRemove ( context , ack ) ; } @ Override public MessageStore getMessageStore ( ) { return null ; } } ) ; } interface LastAckCommand extends RemoveMessageCommand { void rollback ( ConnectionContext context ) throws IOException ; String getClientId ( ) ; String getSubName ( ) ; long getSequence ( ) ; byte getPriority ( ) ; void setMessageStore ( JDBCTopicMessageStore jdbcTopicMessageStore ) ; } public void recoverLastAck ( byte [ ] encodedXid , final ActiveMQDestination destination , final String subName , final String clientId ) throws IOException { Tx tx = getPreparedTx ( new XATransactionId ( encodedXid ) ) ; DataByteArrayInputStream inputStream = new DataByteArrayInputStream ( encodedXid ) ; inputStream . skipBytes ( 1 ) ; final long lastAck = inputStream . readLong ( ) ; final byte priority = inputStream . readByte ( ) ; final MessageAck ack = new MessageAck ( ) ; ack . setDestination ( destination ) ; tx . add ( new LastAckCommand ( ) { JDBCTopicMessageStore jdbcTopicMessageStore ; @ Override public MessageAck getMessageAck ( ) { return ack ; } @ Override public MessageStore getMessageStore ( ) { return jdbcTopicMessageStore ; } @ Override public void run ( ConnectionContext context ) throws IOException { ( ( JDBCPersistenceAdapter ) persistenceAdapter ) . commitLastAck ( context , lastAck , priority , destination , subName , clientId ) ; jdbcTopicMessageStore . complete ( clientId , subName ) ; } @ Override public void rollback ( ConnectionContext context ) throws IOException { ( ( JDBCPersistenceAdapter ) persistenceAdapter ) . rollbackLastAck ( context , priority , jdbcTopicMessageStore . getDestination ( ) , subName , clientId ) ; jdbcTopicMessageStore . complete ( clientId , subName ) ; } @ Override public String getClientId ( ) { return clientId ; } @ Override public String getSubName ( ) { return subName ; } @ Override public long getSequence ( ) { return lastAck ; } @ Override public byte getPriority ( ) { return priority ; } @ Override public void setMessageStore ( JDBCTopicMessageStore jdbcTopicMessageStore ) { this . jdbcTopicMessageStore = jdbcTopicMessageStore ; } } ) ; } @ Override protected void onProxyTopicStore ( ProxyTopicMessageStore proxyTopicMessageStore ) { topicStores . put ( proxyTopicMessageStore . getDestination ( ) , proxyTopicMessageStore . getDelegate ( ) ) ; } @ Override protected void onRecovered ( Tx tx ) { for ( RemoveMessageCommand removeMessageCommand : tx . acks ) { if ( removeMessageCommand instanceof LastAckCommand ) { LastAckCommand lastAckCommand = ( LastAckCommand ) removeMessageCommand ; JDBCTopicMessageStore jdbcTopicMessageStore = ( JDBCTopicMessageStore ) topicStores . get ( lastAckCommand . getMessageAck ( ) . getDestination ( ) ) ; jdbcTopicMessageStore . pendingCompletion ( lastAckCommand . getClientId ( ) , lastAckCommand . getSubName ( ) , lastAckCommand . getSequence ( ) , lastAckCommand . getPriority ( ) ) ; lastAckCommand . setMessageStore ( jdbcTopicMessageStore ) ; } else { ( ( JDBCPersistenceAdapter ) persistenceAdapter ) . getBrokerService ( ) . getRegionBroker ( ) . getDestinationMap ( ) . get ( removeMessageCommand . getMessageAck ( ) . getDestination ( ) ) . getDestinationStatistics ( ) . getMessages ( ) . increment ( ) ; } } } @ Override public void acknowledge ( final TopicMessageStore topicMessageStore , final String clientId , final String subscriptionName , final MessageId messageId , final MessageAck ack ) throws IOException { if ( ack . isInTransaction ( ) ) { Tx tx = getTx ( ack . getTransactionId ( ) ) ; tx . add ( new LastAckCommand ( ) { public MessageAck getMessageAck ( ) { return ack ; } public void run ( ConnectionContext ctx ) throws IOException { topicMessageStore . acknowledge ( ctx , clientId , subscriptionName , messageId , ack ) ; } @ Override public MessageStore getMessageStore ( ) { return topicMessageStore ; } @ Override public void rollback ( ConnectionContext context ) throws IOException { JDBCTopicMessageStore jdbcTopicMessageStore = ( JDBCTopicMessageStore ) topicMessageStore ; ( ( JDBCPersistenceAdapter ) persistenceAdapter ) . rollbackLastAck ( context , jdbcTopicMessageStore , ack , subscriptionName , clientId ) ; jdbcTopicMessageStore . complete ( clientId , subscriptionName ) ; } @ Override public String getClientId ( ) { return clientId ; } @ Override public String getSubName ( ) { return subscriptionName ; } @ Override public long getSequence ( ) { throw new IllegalStateException ( ""Sequence id must be inferred from ack"" ) ; } @ Override public byte getPriority ( ) { throw new IllegalStateException ( ""Priority must be inferred from ack or row"" ) ; } @ Override public void setMessageStore ( JDBCTopicMessageStore jdbcTopicMessageStore ) { throw new IllegalStateException ( ""message store already known!"" ) ; } } ) ; } else { topicMessageStore . acknowledge ( null , clientId , subscriptionName , messageId , ack ) ; } } }",Smelly
"public abstract class AbstractTreeColumn < T , S > extends AbstractColumn < T , S > implements ITreeColumn < T , S > { private static final long serialVersionUID = 1L ; private TableTree < T , S > tree ; public AbstractTreeColumn ( IModel < String > displayModel ) { super ( displayModel ) ; } public AbstractTreeColumn ( IModel < String > displayModel , S sortProperty ) { super ( displayModel , sortProperty ) ; } @ Override public void setTree ( TableTree < T , S > tree ) { this . tree = tree ; } public TableTree < T , S > getTree ( ) { return tree ; } }",No
" public static class DrillFixedBinaryToTimeStampConverter extends PrimitiveConverter { private TimeStampWriter writer ; private TimeStampHolder holder = new TimeStampHolder ( ) ; public DrillFixedBinaryToTimeStampConverter ( TimeStampWriter writer ) { this . writer = writer ; } @ Override public void addBinary ( Binary value ) { holder . value = getDateTimeValueFromBinary ( value , true ) ; writer . write ( holder ) ; } } ",No
"public abstract class AbstractDnsTestCase { protected static final int MINIMUM_DNS_DATAGRAM_SIZE = 576 ; protected IoBuffer getTestQueryByteBuffer ( ) throws IOException { return getByteBufferFromFile ( ""DNS-QUERY.pdu"" ) ; } protected IoBuffer getTestResponseByteBuffer ( ) throws IOException { return getByteBufferFromFile ( ""DNS-RESPONSE.pdu"" ) ; } protected IoBuffer getTestMxQueryByteBuffer ( ) throws IOException { return getByteBufferFromFile ( ""MX-QUERY.pdu"" ) ; } protected IoBuffer getTestMxResponseByteBuffer ( ) throws IOException { return getByteBufferFromFile ( ""MX-RESPONSE.pdu"" ) ; } protected IoBuffer getByteBufferFromFile ( String file ) throws IOException { try ( InputStream is = getClass ( ) . getResourceAsStream ( file ) ) { byte [ ] bytes = new byte [ MINIMUM_DNS_DATAGRAM_SIZE ] ; int offset = 0 ; int numRead = 0 ; while ( offset < bytes . length && ( numRead = is . read ( bytes , offset , bytes . length - offset ) ) >= 0 ) { offset += numRead ; } is . close ( ) ; return IoBuffer . wrap ( bytes ) ; } } protected DnsMessage getTestQuery ( ) { DnsMessageModifier modifier = new DnsMessageModifier ( ) ; modifier . setTransactionId ( ( short ) 27799 ) ; modifier . setMessageType ( MessageType . QUERY ) ; modifier . setOpCode ( OpCode . QUERY ) ; modifier . setRecursionDesired ( true ) ; modifier . setQuestionRecords ( Collections . singletonList ( getTestQuestionRecord ( ) ) ) ; modifier . setResponseCode ( ResponseCode . NO_ERROR ) ; modifier . setAnswerRecords ( new ArrayList < ResourceRecord > ( ) ) ; modifier . setAuthorityRecords ( new ArrayList < ResourceRecord > ( ) ) ; modifier . setAdditionalRecords ( new ArrayList < ResourceRecord > ( ) ) ; return modifier . getDnsMessage ( ) ; } protected QuestionRecord getTestQuestionRecord ( ) { return new QuestionRecord ( ""www.example.com"" , RecordType . A , RecordClass . IN ) ; } protected DnsMessage getTestMxQuery ( ) { DnsMessageModifier modifier = new DnsMessageModifier ( ) ; modifier . setTransactionId ( 51511 ) ; modifier . setMessageType ( MessageType . QUERY ) ; modifier . setOpCode ( OpCode . QUERY ) ; modifier . setRecursionDesired ( true ) ; modifier . setQuestionRecords ( Collections . singletonList ( getTestMxQuestionRecord ( ) ) ) ; modifier . setResponseCode ( ResponseCode . NO_ERROR ) ; modifier . setAnswerRecords ( new ArrayList < ResourceRecord > ( ) ) ; modifier . setAuthorityRecords ( new ArrayList < ResourceRecord > ( ) ) ; modifier . setAdditionalRecords ( new ArrayList < ResourceRecord > ( ) ) ; return modifier . getDnsMessage ( ) ; } protected QuestionRecord getTestMxQuestionRecord ( ) { return new QuestionRecord ( ""apache.org"" , RecordType . MX , RecordClass . IN ) ; } protected DnsMessage getTestMxResponse ( ) throws UnknownHostException { DnsMessageModifier modifier = new DnsMessageModifier ( ) ; modifier . setTransactionId ( 51511 ) ; modifier . setMessageType ( MessageType . RESPONSE ) ; modifier . setOpCode ( OpCode . QUERY ) ; modifier . setRecursionDesired ( true ) ; modifier . setRecursionAvailable ( true ) ; modifier . setQuestionRecords ( Collections . singletonList ( getTestMxQuestionRecord ( ) ) ) ; modifier . setResponseCode ( ResponseCode . NO_ERROR ) ; modifier . setAnswerRecords ( getTestMxAnswerRecords ( ) ) ; modifier . setAuthorityRecords ( getTestMxAuthorityRecords ( ) ) ; modifier . setAdditionalRecords ( getTestMxAdditionalRecords ( ) ) ; return modifier . getDnsMessage ( ) ; } protected List < ResourceRecord > getTestMxAnswerRecords ( ) { List < ResourceRecord > records = new ArrayList < ResourceRecord > ( ) ; ResourceRecordModifier modifier = new ResourceRecordModifier ( ) ; modifier . setDnsName ( ""apache.org"" ) ; modifier . setDnsType ( RecordType . MX ) ; modifier . setDnsClass ( RecordClass . IN ) ; modifier . setDnsTtl ( 267 ) ; modifier . put ( DnsAttribute . MX_PREFERENCE , ""10"" ) ; modifier . put ( DnsAttribute . DOMAIN_NAME , ""herse.apache.org"" ) ; records . add ( modifier . getEntry ( ) ) ; modifier = new ResourceRecordModifier ( ) ; modifier . setDnsName ( ""apache.org"" ) ; modifier . setDnsType ( RecordType . MX ) ; modifier . setDnsClass ( RecordClass . IN ) ; modifier . setDnsTtl ( 267 ) ; modifier . put ( DnsAttribute . MX_PREFERENCE , ""20"" ) ; modifier . put ( DnsAttribute . DOMAIN_NAME , ""mail.apache.org"" ) ; records . add ( modifier . getEntry ( ) ) ; return records ; } protected List < ResourceRecord > getTestMxAuthorityRecords ( ) { List < ResourceRecord > records = new ArrayList < ResourceRecord > ( ) ; ResourceRecordModifier modifier = new ResourceRecordModifier ( ) ; modifier . setDnsClass ( RecordClass . IN ) ; modifier . setDnsName ( ""apache.org"" ) ; modifier . setDnsTtl ( 1932 ) ; modifier . setDnsType ( RecordType . NS ) ; modifier . put ( DnsAttribute . DOMAIN_NAME , ""ns.hyperreal.org"" ) ; records . add ( modifier . getEntry ( ) ) ; modifier = new ResourceRecordModifier ( ) ; modifier . setDnsClass ( RecordClass . IN ) ; modifier . setDnsName ( ""apache.org"" ) ; modifier . setDnsTtl ( 1932 ) ; modifier . setDnsType ( RecordType . NS ) ; modifier . put ( DnsAttribute . DOMAIN_NAME , ""ns1.eu.bitnames.com"" ) ; records . add ( modifier . getEntry ( ) ) ; modifier = new ResourceRecordModifier ( ) ; modifier . setDnsClass ( RecordClass . IN ) ; modifier . setDnsName ( ""apache.org"" ) ; modifier . setDnsTtl ( 1932 ) ; modifier . setDnsType ( RecordType . NS ) ; modifier . put ( DnsAttribute . DOMAIN_NAME , ""ns1.us.bitnames.com"" ) ; records . add ( modifier . getEntry ( ) ) ; modifier = new ResourceRecordModifier ( ) ; modifier . setDnsClass ( RecordClass . IN ) ; modifier . setDnsName ( ""apache.org"" ) ; modifier . setDnsTtl ( 1932 ) ; modifier . setDnsType ( RecordType . NS ) ; modifier . put ( DnsAttribute . DOMAIN_NAME , ""ns2.surfnet.nl"" ) ; records . add ( modifier . getEntry ( ) ) ; return records ; } protected List < ResourceRecord > getTestMxAdditionalRecords ( ) throws UnknownHostException { List < ResourceRecord > records = new ArrayList < ResourceRecord > ( ) ; ResourceRecordModifier modifier = new ResourceRecordModifier ( ) ; modifier . setDnsClass ( RecordClass . IN ) ; modifier . setDnsName ( ""herse.apache.org"" ) ; modifier . setDnsTtl ( 3313 ) ; modifier . setDnsType ( RecordType . A ) ; modifier . put ( DnsAttribute . IP_ADDRESS , InetAddress . getByName ( ""140.211.11.133"" ) . toString ( ) ) ; records . add ( modifier . getEntry ( ) ) ; modifier = new ResourceRecordModifier ( ) ; modifier . setDnsClass ( RecordClass . IN ) ; modifier . setDnsName ( ""mail.apache.org"" ) ; modifier . setDnsTtl ( 3313 ) ; modifier . setDnsType ( RecordType . A ) ; modifier . put ( DnsAttribute . IP_ADDRESS , InetAddress . getByName ( ""140.211.11.2"" ) . toString ( ) ) ; records . add ( modifier . getEntry ( ) ) ; modifier = new ResourceRecordModifier ( ) ; modifier . setDnsClass ( RecordClass . IN ) ; modifier . setDnsName ( ""ns1.eu.bitnames.com"" ) ; modifier . setDnsTtl ( 156234 ) ; modifier . setDnsType ( RecordType . A ) ; modifier . put ( DnsAttribute . IP_ADDRESS , InetAddress . getByName ( ""82.195.149.118"" ) . toString ( ) ) ; records . add ( modifier . getEntry ( ) ) ; modifier = new ResourceRecordModifier ( ) ; modifier . setDnsClass ( RecordClass . IN ) ; modifier . setDnsName ( ""ns1.us.bitnames.com"" ) ; modifier . setDnsTtl ( 156236 ) ; modifier . setDnsType ( RecordType . A ) ; modifier . put ( DnsAttribute . IP_ADDRESS , InetAddress . getByName ( ""216.52.237.236"" ) . toString ( ) ) ; records . add ( modifier . getEntry ( ) ) ; modifier = new ResourceRecordModifier ( ) ; modifier . setDnsClass ( RecordClass . IN ) ; modifier . setDnsName ( ""ns2.surfnet.nl"" ) ; modifier . setDnsTtl ( 77100 ) ; modifier . setDnsType ( RecordType . A ) ; modifier . put ( DnsAttribute . IP_ADDRESS , InetAddress . getByName ( ""192.87.36.2"" ) . toString ( ) ) ; records . add ( modifier . getEntry ( ) ) ; modifier = new ResourceRecordModifier ( ) ; modifier . setDnsClass ( RecordClass . IN ) ; modifier . setDnsName ( ""ns2.surfnet.nl"" ) ; modifier . setDnsTtl ( 77100 ) ; modifier . setDnsType ( RecordType . AAAA ) ; modifier . put ( DnsAttribute . IP_ADDRESS , InetAddress . getByName ( ""2001:610:3:200a:192:87:36:2"" ) . toString ( ) ) ; records . add ( modifier . getEntry ( ) ) ; return records ; } }",No
"@ SuppressWarnings ( ""serial"" ) public class BooleanSerializer extends DataTypeSerializer < Long > { public final static String [ ] TRUE_VALUE_SET = { ""true"" , ""t"" , ""on"" , ""yes"" } ; public BooleanSerializer ( DataType type ) { } @ Override public void serialize ( Long value , ByteBuffer out ) { out . putLong ( value ) ; } @ Override public Long deserialize ( ByteBuffer in ) { return in . getLong ( ) ; } @ Override public int peekLength ( ByteBuffer in ) { return 8 ; } @ Override public int maxLength ( ) { return 8 ; } @ Override public int getStorageBytesEstimate ( ) { return 8 ; } @ Override public Long valueOf ( String str ) { if ( str == null ) return Long . valueOf ( 0L ) ; else return Long . valueOf ( BooleanUtils . toInteger ( ArrayUtils . contains ( TRUE_VALUE_SET , str . toLowerCase ( ) ) ) ) ; } }",No
"@ Category ( { MediumTests . class , RegionServerTests . class } ) public class TestRegionOpen { @ ClassRule public static final HBaseClassTestRule CLASS_RULE = HBaseClassTestRule . forClass ( TestRegionOpen . class ) ; @ SuppressWarnings ( ""unused"" ) private static final Logger LOG = LoggerFactory . getLogger ( TestRegionOpen . class ) ; private static final int NB_SERVERS = 1 ; private static final HBaseTestingUtility HTU = new HBaseTestingUtility ( ) ; @ Rule public TestName name = new TestName ( ) ; @ BeforeClass public static void before ( ) throws Exception { HTU . startMiniCluster ( NB_SERVERS ) ; } @ AfterClass public static void afterClass ( ) throws Exception { HTU . shutdownMiniCluster ( ) ; } private static HRegionServer getRS ( ) { return HTU . getHBaseCluster ( ) . getLiveRegionServerThreads ( ) . get ( 0 ) . getRegionServer ( ) ; } @ Test public void testPriorityRegionIsOpenedWithSeparateThreadPool ( ) throws Exception { final TableName tableName = TableName . valueOf ( TestRegionOpen . class . getSimpleName ( ) ) ; ThreadPoolExecutor exec = getRS ( ) . getExecutorService ( ) . getExecutorThreadPool ( ExecutorType . RS_OPEN_PRIORITY_REGION ) ; long completed = exec . getCompletedTaskCount ( ) ; HTableDescriptor htd = new HTableDescriptor ( tableName ) ; htd . setPriority ( HConstants . HIGH_QOS ) ; htd . addFamily ( new HColumnDescriptor ( HConstants . CATALOG_FAMILY ) ) ; try ( Connection connection = ConnectionFactory . createConnection ( HTU . getConfiguration ( ) ) ; Admin admin = connection . getAdmin ( ) ) { admin . createTable ( htd ) ; } assertEquals ( completed + 1 , exec . getCompletedTaskCount ( ) ) ; } @ Test public void testNonExistentRegionReplica ( ) throws Exception { final TableName tableName = TableName . valueOf ( name . getMethodName ( ) ) ; final byte [ ] FAMILYNAME = Bytes . toBytes ( ""fam"" ) ; FileSystem fs = HTU . getTestFileSystem ( ) ; Admin admin = HTU . getAdmin ( ) ; Configuration conf = HTU . getConfiguration ( ) ; Path rootDir = HTU . getDataTestDirOnTestFS ( ) ; HTableDescriptor htd = new HTableDescriptor ( tableName ) ; htd . addFamily ( new HColumnDescriptor ( FAMILYNAME ) ) ; admin . createTable ( htd ) ; HTU . waitUntilNoRegionsInTransition ( 60000 ) ; HRegionInfo hri = new HRegionInfo ( htd . getTableName ( ) , Bytes . toBytes ( ""A"" ) , Bytes . toBytes ( ""B"" ) , false , System . currentTimeMillis ( ) , 2 ) ; HRegionFileSystem regionFs = HRegionFileSystem . createRegionOnFileSystem ( conf , fs , FSUtils . getTableDir ( rootDir , hri . getTable ( ) ) , hri ) ; Path regionDir = regionFs . getRegionDir ( ) ; try { HRegionFileSystem . loadRegionInfoFileContent ( fs , regionDir ) ; } catch ( IOException e ) { LOG . info ( ""Caught expected IOE due missing .regioninfo file, due: "" + e . getMessage ( ) + "" skipping region open."" ) ; List < HRegionInfo > regions = admin . getTableRegions ( tableName ) ; LOG . info ( ""Regions: "" + regions ) ; if ( regions . size ( ) != 1 ) { fail ( ""Table "" + tableName + "" should have only one region, but got more: "" + regions ) ; } return ; } fail ( ""Should have thrown IOE when attempting to open a non-existing region."" ) ; } }",No
" private static class ProxyNamespaceStats { public long numberOfMsgPublished ; public long numberOfBytesPublished ; public long numberOfPublishFailure ; public StatsBuckets publishMsgLatency ; public long numberOfMsgDelivered ; public long numberOfBytesDelivered ; public long numberOfMsgsAcked ; public ProxyNamespaceStats ( ) { this . publishMsgLatency = new StatsBuckets ( ENTRY_LATENCY_BUCKETS_USEC ) ; } public Metrics add ( String namespace ) { publishMsgLatency . refresh ( ) ; long [ ] latencyBuckets = publishMsgLatency . getBuckets ( ) ; Map < String , String > dimensionMap = Maps . newHashMap ( ) ; dimensionMap . put ( ""namespace"" , namespace ) ; Metrics dMetrics = Metrics . create ( dimensionMap ) ; dMetrics . put ( ""ns_msg_publish_rate"" , numberOfMsgPublished ) ; dMetrics . put ( ""ns_byte_publish_rate"" , numberOfBytesPublished ) ; dMetrics . put ( ""ns_msg_failure_rate"" , numberOfPublishFailure ) ; dMetrics . put ( ""ns_msg_deliver_rate"" , numberOfMsgDelivered ) ; dMetrics . put ( ""ns_byte_deliver_rate"" , numberOfBytesDelivered ) ; dMetrics . put ( ""ns_msg_ack_rate"" , numberOfMsgsAcked ) ; for ( int i = 0 ; i < latencyBuckets . length ; i ++ ) { final String latencyBucket = i >= ENTRY_LATENCY_BUCKETS_USEC . length ? ENTRY_LATENCY_BUCKETS_USEC [ ENTRY_LATENCY_BUCKETS_USEC . length - 1 ] + ""_higher"" : Long . toString ( ENTRY_LATENCY_BUCKETS_USEC [ i ] ) ; dMetrics . put ( ""ns_msg_publish_latency_"" + latencyBucket , latencyBuckets [ i ] ) ; } return dMetrics ; } ",No
"public class NodeIndexer { private static final Logger log = LoggerFactory . getLogger ( NodeIndexer . class ) ; protected static final float DEFAULT_BOOST = 1.0f ; protected final NodeState node ; protected final ItemStateManager stateProvider ; protected final NamespaceMappings mappings ; protected final NamePathResolver resolver ; private final Executor executor ; private final Parser parser ; protected IndexingConfiguration indexingConfig ; protected boolean supportHighlighting = false ; protected IndexFormatVersion indexFormatVersion = IndexFormatVersion . V1 ; protected List < Fieldable > doNotUseInExcerpt = new ArrayList < Fieldable > ( ) ; public NodeIndexer ( NodeState node , ItemStateManager stateProvider , NamespaceMappings mappings , Executor executor , Parser parser ) { this . node = node ; this . stateProvider = stateProvider ; this . mappings = mappings ; this . resolver = NamePathResolverImpl . create ( mappings ) ; this . executor = executor ; this . parser = parser ; } public NodeId getNodeId ( ) { return node . getNodeId ( ) ; } public void setSupportHighlighting ( boolean b ) { supportHighlighting = b ; } public void setIndexFormatVersion ( IndexFormatVersion indexFormatVersion ) { this . indexFormatVersion = indexFormatVersion ; } public void setIndexingConfiguration ( IndexingConfiguration config ) { this . indexingConfig = config ; } public Document createDoc ( ) throws RepositoryException { doNotUseInExcerpt . clear ( ) ; Document doc = new Document ( ) ; doc . setBoost ( getNodeBoost ( ) ) ; doc . add ( new Field ( FieldNames . UUID , node . getNodeId ( ) . toString ( ) , Field . Store . YES , Field . Index . NOT_ANALYZED_NO_NORMS ) ) ; try { if ( node . getParentId ( ) == null ) { doc . add ( new Field ( FieldNames . PARENT , """" , Field . Store . YES , Field . Index . NOT_ANALYZED_NO_NORMS ) ) ; addNodeName ( doc , """" , """" ) ; } else if ( node . getSharedSet ( ) . isEmpty ( ) ) { addParentChildRelation ( doc , node . getParentId ( ) ) ; } else { for ( NodeId id : node . getSharedSet ( ) ) { addParentChildRelation ( doc , id ) ; } doc . add ( new Field ( FieldNames . SHAREABLE_NODE , """" , Field . Store . NO , Field . Index . NOT_ANALYZED_NO_NORMS ) ) ; } } catch ( NoSuchItemStateException e ) { throwRepositoryException ( e ) ; } catch ( ItemStateException e ) { throwRepositoryException ( e ) ; } catch ( NamespaceException e ) { } Set < Name > props = node . getPropertyNames ( ) ; for ( Name propName : props ) { PropertyId id = new PropertyId ( node . getNodeId ( ) , propName ) ; try { PropertyState propState = ( PropertyState ) stateProvider . getItemState ( id ) ; if ( indexFormatVersion . getVersion ( ) >= IndexFormatVersion . V2 . getVersion ( ) ) { addPropertyName ( doc , propState . getName ( ) ) ; } InternalValue [ ] values = propState . getValues ( ) ; for ( InternalValue value : values ) { addValue ( doc , value , propState . getName ( ) ) ; } if ( values . length > 1 ) { addMVPName ( doc , propState . getName ( ) ) ; } } catch ( NoSuchItemStateException e ) { throwRepositoryException ( e ) ; } catch ( ItemStateException e ) { throwRepositoryException ( e ) ; } } for ( Fieldable field : doNotUseInExcerpt ) { doc . add ( field ) ; } return doc ; } protected void throwRepositoryException ( Exception e ) throws RepositoryException { String msg = ""Error while indexing node: "" + node . getNodeId ( ) + "" of "" + ""type: "" + node . getNodeTypeName ( ) ; throw new RepositoryException ( msg , e ) ; } protected void addMVPName ( Document doc , Name name ) { try { String propName = resolver . getJCRName ( name ) ; doc . add ( new Field ( FieldNames . MVP , propName , Field . Store . NO , Field . Index . NOT_ANALYZED_NO_NORMS , Field . TermVector . NO ) ) ; } catch ( NamespaceException e ) { } } protected void addValue ( Document doc , InternalValue value , Name name ) throws RepositoryException { String fieldName = name . getLocalName ( ) ; try { fieldName = resolver . getJCRName ( name ) ; } catch ( NamespaceException e ) { } switch ( value . getType ( ) ) { case PropertyType . BINARY : if ( isIndexed ( name ) ) { addBinaryValue ( doc , fieldName , value ) ; } break ; case PropertyType . BOOLEAN : if ( isIndexed ( name ) ) { addBooleanValue ( doc , fieldName , value . getBoolean ( ) ) ; } break ; case PropertyType . DATE : if ( isIndexed ( name ) ) { addCalendarValue ( doc , fieldName , value . getDate ( ) ) ; } break ; case PropertyType . DOUBLE : if ( isIndexed ( name ) ) { addDoubleValue ( doc , fieldName , value . getDouble ( ) ) ; } break ; case PropertyType . LONG : if ( isIndexed ( name ) ) { addLongValue ( doc , fieldName , value . getLong ( ) ) ; } break ; case PropertyType . REFERENCE : if ( isIndexed ( name ) ) { addReferenceValue ( doc , fieldName , value . getNodeId ( ) , false ) ; } break ; case PropertyType . WEAKREFERENCE : if ( isIndexed ( name ) ) { addReferenceValue ( doc , fieldName , value . getNodeId ( ) , true ) ; } break ; case PropertyType . PATH : if ( isIndexed ( name ) ) { addPathValue ( doc , fieldName , value . getPath ( ) ) ; } break ; case PropertyType . URI : if ( isIndexed ( name ) ) { addURIValue ( doc , fieldName , value . getURI ( ) ) ; } break ; case PropertyType . STRING : if ( isIndexed ( name ) ) { if ( name . equals ( NameConstants . JCR_UUID ) ) { addStringValue ( doc , fieldName , value . getString ( ) , false , false , DEFAULT_BOOST ) ; } else { addStringValue ( doc , fieldName , value . getString ( ) , true , isIncludedInNodeIndex ( name ) , getPropertyBoost ( name ) , useInExcerpt ( name ) ) ; } } break ; case PropertyType . NAME : if ( name . equals ( NameConstants . JCR_PRIMARYTYPE ) || name . equals ( NameConstants . JCR_MIXINTYPES ) || isIndexed ( name ) ) { addNameValue ( doc , fieldName , value . getName ( ) ) ; } break ; case PropertyType . DECIMAL : if ( isIndexed ( name ) ) { addDecimalValue ( doc , fieldName , value . getDecimal ( ) ) ; } break ; default : throw new IllegalArgumentException ( ""illegal internal value type: "" + value . getType ( ) ) ; } if ( indexFormatVersion . getVersion ( ) >= IndexFormatVersion . V3 . getVersion ( ) ) { addLength ( doc , fieldName , value ) ; } } protected void addPropertyName ( Document doc , Name name ) { String fieldName = name . getLocalName ( ) ; try { fieldName = resolver . getJCRName ( name ) ; } catch ( NamespaceException e ) { } doc . add ( new Field ( FieldNames . PROPERTIES_SET , fieldName , Field . Store . NO , Field . Index . NOT_ANALYZED_NO_NORMS ) ) ; } protected void addBinaryValue ( Document doc , String fieldName , InternalValue internalValue ) { try { String jcrData = mappings . getPrefix ( Name . NS_JCR_URI ) + "":data"" ; if ( ! jcrData . equals ( fieldName ) ) { return ; } InternalValue type = getValue ( NameConstants . JCR_MIMETYPE ) ; if ( type != null ) { Metadata metadata = new Metadata ( ) ; metadata . set ( Metadata . CONTENT_TYPE , type . getString ( ) ) ; InternalValue encoding = getValue ( NameConstants . JCR_ENCODING ) ; if ( encoding != null ) { metadata . set ( Metadata . CONTENT_ENCODING , encoding . getString ( ) ) ; } doc . add ( createFulltextField ( internalValue , metadata ) ) ; } } catch ( Throwable t ) { log . warn ( ""Exception while indexing binary property"" , t ) ; } } protected InternalValue getValue ( Name name ) throws ItemStateException { try { PropertyId id = new PropertyId ( node . getNodeId ( ) , name ) ; PropertyState property = ( PropertyState ) stateProvider . getItemState ( id ) ; InternalValue [ ] values = property . getValues ( ) ; if ( values . length > 0 ) { return values [ 0 ] ; } else { return null ; } } catch ( NoSuchItemStateException e ) { return null ; } } protected void addBooleanValue ( Document doc , String fieldName , Object internalValue ) { doc . add ( createFieldWithoutNorms ( fieldName , internalValue . toString ( ) , PropertyType . BOOLEAN ) ) ; } protected Field createFieldWithoutNorms ( String fieldName , String internalValue , int propertyType ) { if ( indexFormatVersion . getVersion ( ) >= IndexFormatVersion . V3 . getVersion ( ) ) { Field field = new Field ( FieldNames . PROPERTIES , new SingletonTokenStream ( FieldNames . createNamedValue ( fieldName , internalValue ) , propertyType ) ) ; field . setOmitNorms ( true ) ; return field ; } else { return new Field ( FieldNames . PROPERTIES , FieldNames . createNamedValue ( fieldName , internalValue ) , Field . Store . NO , Field . Index . NOT_ANALYZED_NO_NORMS , Field . TermVector . NO ) ; } } protected void addCalendarValue ( Document doc , String fieldName , Object internalValue ) { Calendar value = ( Calendar ) internalValue ; long millis = value . getTimeInMillis ( ) ; try { doc . add ( createFieldWithoutNorms ( fieldName , DateField . timeToString ( millis ) , PropertyType . DATE ) ) ; } catch ( IllegalArgumentException e ) { log . warn ( ""'{}' is outside of supported date value range."" , new Date ( value . getTimeInMillis ( ) ) ) ; } } protected void addDoubleValue ( Document doc , String fieldName , Object internalValue ) { double doubleVal = ( Double ) internalValue ; doc . add ( createFieldWithoutNorms ( fieldName , DoubleField . doubleToString ( doubleVal ) , PropertyType . DOUBLE ) ) ; } protected void addLongValue ( Document doc , String fieldName , Object internalValue ) { long longVal = ( Long ) internalValue ; doc . add ( createFieldWithoutNorms ( fieldName , LongField . longToString ( longVal ) , PropertyType . LONG ) ) ; } protected void addDecimalValue ( Document doc , String fieldName , Object internalValue ) { BigDecimal decVal = ( BigDecimal ) internalValue ; doc . add ( createFieldWithoutNorms ( fieldName , DecimalField . decimalToString ( decVal ) , PropertyType . DECIMAL ) ) ; } protected void addReferenceValue ( Document doc , String fieldName , Object internalValue , boolean weak ) { String uuid = internalValue . toString ( ) ; doc . add ( createFieldWithoutNorms ( fieldName , uuid , weak ? PropertyType . WEAKREFERENCE : PropertyType . REFERENCE ) ) ; doc . add ( new Field ( FieldNames . PROPERTIES , FieldNames . createNamedValue ( fieldName , uuid ) , Field . Store . YES , Field . Index . NO , Field . TermVector . NO ) ) ; if ( weak ) { doc . add ( new Field ( FieldNames . WEAK_REFS , uuid , Field . Store . NO , Field . Index . NOT_ANALYZED_NO_NORMS ) ) ; } } protected void addPathValue ( Document doc , String fieldName , Object internalValue ) { Path path = ( Path ) internalValue ; String pathString = path . toString ( ) ; try { pathString = resolver . getJCRPath ( path ) ; } catch ( NamespaceException e ) { } doc . add ( createFieldWithoutNorms ( fieldName , pathString , PropertyType . PATH ) ) ; } protected void addURIValue ( Document doc , String fieldName , Object internalValue ) { URI uri = ( URI ) internalValue ; doc . add ( createFieldWithoutNorms ( fieldName , uri . toString ( ) , PropertyType . URI ) ) ; } protected void addStringValue ( Document doc , String fieldName , Object internalValue ) { addStringValue ( doc , fieldName , internalValue , true , true , DEFAULT_BOOST ) ; } protected void addStringValue ( Document doc , String fieldName , Object internalValue , boolean tokenized ) { addStringValue ( doc , fieldName , internalValue , tokenized , true , DEFAULT_BOOST ) ; } protected void addStringValue ( Document doc , String fieldName , Object internalValue , boolean tokenized , boolean includeInNodeIndex , float boost ) { addStringValue ( doc , fieldName , internalValue , tokenized , includeInNodeIndex , boost , true ) ; } protected void addStringValue ( Document doc , String fieldName , Object internalValue , boolean tokenized , boolean includeInNodeIndex , float boost , boolean useInExcerpt ) { String stringValue = ( String ) internalValue ; doc . add ( createFieldWithoutNorms ( fieldName , stringValue , PropertyType . STRING ) ) ; if ( tokenized ) { if ( stringValue . length ( ) == 0 ) { return ; } int idx = fieldName . indexOf ( ':' ) ; fieldName = fieldName . substring ( 0 , idx + 1 ) + FieldNames . FULLTEXT_PREFIX + fieldName . substring ( idx + 1 ) ; Field f = new Field ( fieldName , stringValue , Field . Store . NO , Field . Index . ANALYZED , Field . TermVector . NO ) ; f . setBoost ( boost ) ; doc . add ( f ) ; if ( includeInNodeIndex ) { boolean store = supportHighlighting && useInExcerpt ; f = createFulltextField ( stringValue , store , supportHighlighting ) ; if ( useInExcerpt ) { doc . add ( f ) ; } else { doNotUseInExcerpt . add ( f ) ; } } } } protected void addNameValue ( Document doc , String fieldName , Object internalValue ) { try { Name qualiName = ( Name ) internalValue ; String normValue = mappings . getPrefix ( qualiName . getNamespaceURI ( ) ) + "":"" + qualiName . getLocalName ( ) ; doc . add ( createFieldWithoutNorms ( fieldName , normValue , PropertyType . NAME ) ) ; } catch ( NamespaceException e ) { } } protected Field createFulltextField ( String value ) { return createFulltextField ( value , supportHighlighting , supportHighlighting ) ; } protected Field createFulltextField ( String value , boolean store , boolean withOffsets ) { Field . TermVector tv ; if ( withOffsets ) { tv = Field . TermVector . WITH_OFFSETS ; } else { tv = Field . TermVector . NO ; } if ( store ) { Field . Store stored ; if ( value . length ( ) > 0x4000 ) { stored = Field . Store . COMPRESS ; } else { stored = Field . Store . YES ; } return new Field ( FieldNames . FULLTEXT , value , stored , Field . Index . ANALYZED , tv ) ; } else { return new Field ( FieldNames . FULLTEXT , value , Field . Store . NO , Field . Index . ANALYZED , tv ) ; } } protected Fieldable createFulltextField ( InternalValue value , Metadata metadata ) { return new LazyTextExtractorField ( parser , value , metadata , executor , supportHighlighting ) ; } protected boolean isIndexed ( Name propertyName ) { if ( indexingConfig == null ) { return true ; } else { return indexingConfig . isIndexed ( node , propertyName ) ; } } protected boolean isIncludedInNodeIndex ( Name propertyName ) { if ( indexingConfig == null ) { return true ; } else { return indexingConfig . isIncludedInNodeScopeIndex ( node , propertyName ) ; } } protected boolean useInExcerpt ( Name propertyName ) { if ( indexingConfig == null ) { return true ; } else { return indexingConfig . useInExcerpt ( node , propertyName ) ; } } protected float getPropertyBoost ( Name propertyName ) { if ( indexingConfig == null ) { return DEFAULT_BOOST ; } else { return indexingConfig . getPropertyBoost ( node , propertyName ) ; } } protected float getNodeBoost ( ) { if ( indexingConfig == null ) { return DEFAULT_BOOST ; } else { return indexingConfig . getNodeBoost ( node ) ; } } protected void addLength ( Document doc , String propertyName , InternalValue value ) { long length = Util . getLength ( value ) ; if ( length != - 1 ) { doc . add ( new Field ( FieldNames . PROPERTY_LENGTHS , FieldNames . createNamedLength ( propertyName , length ) , Field . Store . NO , Field . Index . NOT_ANALYZED_NO_NORMS ) ) ; } } protected void addNodeName ( Document doc , String namespaceURI , String localName ) throws NamespaceException { String name = mappings . getPrefix ( namespaceURI ) + "":"" + localName ; doc . add ( new Field ( FieldNames . LABEL , name , Field . Store . NO , Field . Index . NOT_ANALYZED_NO_NORMS ) ) ; if ( indexFormatVersion . getVersion ( ) >= IndexFormatVersion . V3 . getVersion ( ) ) { doc . add ( new Field ( FieldNames . NAMESPACE_URI , namespaceURI , Field . Store . NO , Field . Index . NOT_ANALYZED_NO_NORMS ) ) ; doc . add ( new Field ( FieldNames . LOCAL_NAME , localName , Field . Store . NO , Field . Index . NOT_ANALYZED_NO_NORMS ) ) ; } } protected void addParentChildRelation ( Document doc , NodeId parentId ) throws ItemStateException , RepositoryException { doc . add ( new Field ( FieldNames . PARENT , parentId . toString ( ) , Field . Store . YES , Field . Index . NOT_ANALYZED_NO_NORMS , Field . TermVector . NO ) ) ; NodeState parent = ( NodeState ) stateProvider . getItemState ( parentId ) ; ChildNodeEntry child = parent . getChildNodeEntry ( node . getNodeId ( ) ) ; if ( child == null ) { throw new RepositoryException ( ""Missing child node entry for node with id: "" + node . getNodeId ( ) ) ; } Name name = child . getName ( ) ; addNodeName ( doc , name . getNamespaceURI ( ) , name . getLocalName ( ) ) ; } }",Smelly
"public class BrentOptimizer extends UnivariateOptimizer { private static final double GOLDEN_SECTION = 0.5 * ( 3 - FastMath . sqrt ( 5 ) ) ; private static final double MIN_RELATIVE_TOLERANCE = 2 * FastMath . ulp ( 1d ) ; private final double relativeThreshold ; private final double absoluteThreshold ; public BrentOptimizer ( double rel , double abs , ConvergenceChecker < UnivariatePointValuePair > checker ) { super ( checker ) ; if ( rel < MIN_RELATIVE_TOLERANCE ) { throw new NumberIsTooSmallException ( rel , MIN_RELATIVE_TOLERANCE , true ) ; } if ( abs <= 0 ) { throw new NotStrictlyPositiveException ( abs ) ; } relativeThreshold = rel ; absoluteThreshold = abs ; } public BrentOptimizer ( double rel , double abs ) { this ( rel , abs , null ) ; } @ Override protected UnivariatePointValuePair doOptimize ( ) { final boolean isMinim = getGoalType ( ) == GoalType . MINIMIZE ; final double lo = getMin ( ) ; final double mid = getStartValue ( ) ; final double hi = getMax ( ) ; final ConvergenceChecker < UnivariatePointValuePair > checker = getConvergenceChecker ( ) ; double a ; double b ; if ( lo < hi ) { a = lo ; b = hi ; } else { a = hi ; b = lo ; } double x = mid ; double v = x ; double w = x ; double d = 0 ; double e = 0 ; double fx = computeObjectiveValue ( x ) ; if ( ! isMinim ) { fx = - fx ; } double fv = fx ; double fw = fx ; UnivariatePointValuePair previous = null ; UnivariatePointValuePair current = new UnivariatePointValuePair ( x , isMinim ? fx : - fx ) ; UnivariatePointValuePair best = current ; int iter = 0 ; while ( true ) { final double m = 0.5 * ( a + b ) ; final double tol1 = relativeThreshold * FastMath . abs ( x ) + absoluteThreshold ; final double tol2 = 2 * tol1 ; final boolean stop = FastMath . abs ( x - m ) <= tol2 - 0.5 * ( b - a ) ; if ( ! stop ) { double p = 0 ; double q = 0 ; double r = 0 ; double u = 0 ; if ( FastMath . abs ( e ) > tol1 ) { r = ( x - w ) * ( fx - fv ) ; q = ( x - v ) * ( fx - fw ) ; p = ( x - v ) * q - ( x - w ) * r ; q = 2 * ( q - r ) ; if ( q > 0 ) { p = - p ; } else { q = - q ; } r = e ; e = d ; if ( p > q * ( a - x ) && p < q * ( b - x ) && FastMath . abs ( p ) < FastMath . abs ( 0.5 * q * r ) ) { d = p / q ; u = x + d ; if ( u - a < tol2 || b - u < tol2 ) { if ( x <= m ) { d = tol1 ; } else { d = - tol1 ; } } } else { if ( x < m ) { e = b - x ; } else { e = a - x ; } d = GOLDEN_SECTION * e ; } } else { if ( x < m ) { e = b - x ; } else { e = a - x ; } d = GOLDEN_SECTION * e ; } if ( FastMath . abs ( d ) < tol1 ) { if ( d >= 0 ) { u = x + tol1 ; } else { u = x - tol1 ; } } else { u = x + d ; } double fu = computeObjectiveValue ( u ) ; if ( ! isMinim ) { fu = - fu ; } previous = current ; current = new UnivariatePointValuePair ( u , isMinim ? fu : - fu ) ; best = best ( best , best ( previous , current , isMinim ) , isMinim ) ; if ( checker != null && checker . converged ( iter , previous , current ) ) { return best ; } if ( fu <= fx ) { if ( u < x ) { b = x ; } else { a = x ; } v = w ; fv = fw ; w = x ; fw = fx ; x = u ; fx = fu ; } else { if ( u < x ) { a = u ; } else { b = u ; } if ( fu <= fw || Precision . equals ( w , x ) ) { v = w ; fv = fw ; w = u ; fw = fu ; } else if ( fu <= fv || Precision . equals ( v , x ) || Precision . equals ( v , w ) ) { v = u ; fv = fu ; } } } else { return best ( best , best ( previous , current , isMinim ) , isMinim ) ; } ++ iter ; } } private UnivariatePointValuePair best ( UnivariatePointValuePair a , UnivariatePointValuePair b , boolean isMinim ) { if ( a == null ) { return b ; } if ( b == null ) { return a ; } if ( isMinim ) { return a . getValue ( ) <= b . getValue ( ) ? a : b ; } else { return a . getValue ( ) >= b . getValue ( ) ? a : b ; } } }",No
"public class TestLocalCacheDirectoryManager { @ Test ( timeout = 10000 ) public void testHierarchicalSubDirectoryCreation ( ) { YarnConfiguration conf = new YarnConfiguration ( ) ; conf . set ( YarnConfiguration . NM_LOCAL_CACHE_MAX_FILES_PER_DIRECTORY , ""37"" ) ; LocalCacheDirectoryManager hDir = new LocalCacheDirectoryManager ( conf ) ; Assert . assertTrue ( hDir . getRelativePathForLocalization ( ) . isEmpty ( ) ) ; for ( int i = 1 ; i <= 37 * 36 * 36 ; i ++ ) { StringBuffer sb = new StringBuffer ( ) ; String num = Integer . toString ( i - 1 , 36 ) ; if ( num . length ( ) == 1 ) { sb . append ( num . charAt ( 0 ) ) ; } else { sb . append ( Integer . toString ( Integer . parseInt ( num . substring ( 0 , 1 ) , 36 ) - 1 , 36 ) ) ; } for ( int j = 1 ; j < num . length ( ) ; j ++ ) { sb . append ( Path . SEPARATOR ) . append ( num . charAt ( j ) ) ; } Assert . assertEquals ( sb . toString ( ) , hDir . getRelativePathForLocalization ( ) ) ; } String testPath1 = ""4"" ; String testPath2 = ""2"" ; hDir . decrementFileCountForPath ( testPath1 ) ; hDir . decrementFileCountForPath ( testPath2 ) ; Assert . assertEquals ( testPath1 , hDir . getRelativePathForLocalization ( ) ) ; Assert . assertEquals ( testPath2 , hDir . getRelativePathForLocalization ( ) ) ; } @ Test ( timeout = 10000 ) public void testMinimumPerDirectoryFileLimit ( ) { YarnConfiguration conf = new YarnConfiguration ( ) ; conf . set ( YarnConfiguration . NM_LOCAL_CACHE_MAX_FILES_PER_DIRECTORY , ""1"" ) ; Exception e = null ; ResourceLocalizationService service = new ResourceLocalizationService ( null , null , null , null ) ; try { service . init ( conf ) ; } catch ( Exception e1 ) { e = e1 ; } Assert . assertNotNull ( e ) ; Assert . assertEquals ( YarnRuntimeException . class , e . getClass ( ) ) ; Assert . assertEquals ( e . getMessage ( ) , YarnConfiguration . NM_LOCAL_CACHE_MAX_FILES_PER_DIRECTORY + "" parameter is configured with a value less than 37."" ) ; } @ Test ( timeout = 1000 ) public void testDirectoryStateChangeFromFullToNonFull ( ) { YarnConfiguration conf = new YarnConfiguration ( ) ; conf . set ( YarnConfiguration . NM_LOCAL_CACHE_MAX_FILES_PER_DIRECTORY , ""40"" ) ; LocalCacheDirectoryManager dir = new LocalCacheDirectoryManager ( conf ) ; String rootPath = """" ; String firstSubDir = ""0"" ; for ( int i = 0 ; i < 4 ; i ++ ) { Assert . assertEquals ( rootPath , dir . getRelativePathForLocalization ( ) ) ; } dir . decrementFileCountForPath ( rootPath ) ; dir . decrementFileCountForPath ( rootPath ) ; Assert . assertEquals ( rootPath , dir . getRelativePathForLocalization ( ) ) ; Assert . assertEquals ( rootPath , dir . getRelativePathForLocalization ( ) ) ; Assert . assertEquals ( firstSubDir , dir . getRelativePathForLocalization ( ) ) ; } }",No
"public class CodeGenOptionTest extends AbstractCodeGenTest { @ Test public void testFlagForGenStandAlone ( ) throws Exception { env . put ( ToolConstants . CFG_GEN_TYPES , ToolConstants . CFG_GEN_TYPES ) ; env . put ( ToolConstants . CFG_GEN_SEI , ToolConstants . CFG_GEN_SEI ) ; env . put ( ToolConstants . CFG_GEN_IMPL , ToolConstants . CFG_GEN_IMPL ) ; env . put ( ToolConstants . CFG_GEN_SERVICE , ToolConstants . CFG_GEN_SERVICE ) ; env . put ( ToolConstants . CFG_GEN_SERVER , ToolConstants . CFG_GEN_SERVER ) ; env . put ( ToolConstants . CFG_GEN_FAULT , ToolConstants . CFG_GEN_FAULT ) ; env . put ( ToolConstants . CFG_GEN_ANT , ToolConstants . CFG_GEN_ANT ) ; env . put ( ToolConstants . CFG_WSDLURL , getLocation ( ""/wsdl2java_wsdl/hello_world.wsdl"" ) ) ; processor . setContext ( env ) ; processor . execute ( ) ; Class < ? > greeterServer = classLoader . loadClass ( ""org.apache.cxf.w2j.hello_world_soap_http.Greeter_SoapPort_Server"" ) ; assertNotNull ( ""Server should be generated"" , greeterServer ) ; } @ Test public void testFlagForGenAdditional ( ) throws Exception { env . put ( ToolConstants . CFG_IMPL , ToolConstants . CFG_IMPL ) ; env . put ( ToolConstants . CFG_SERVER , ToolConstants . CFG_SERVER ) ; env . put ( ToolConstants . CFG_WSDLURL , getLocation ( ""/wsdl2java_wsdl/hello_world.wsdl"" ) ) ; processor . setContext ( env ) ; processor . execute ( ) ; Class < ? > greeterServer = classLoader . loadClass ( ""org.apache.cxf.w2j.hello_world_soap_http.Greeter_SoapPort_Server"" ) ; assertNotNull ( ""Server should be generated"" , greeterServer ) ; } @ Test public void testWSDLListOptionMultipleWSDL ( ) throws Exception { env . put ( ToolConstants . CFG_ALL , ToolConstants . CFG_ALL ) ; env . put ( ToolConstants . CFG_WSDLLIST , ToolConstants . CFG_WSDLLIST ) ; String wsdl1 = getLocation ( ""/wsdl2java_wsdl/hello_world.wsdl"" ) ; String wsdl2 = getLocation ( ""/wsdl2java_wsdl/cardealer.wsdl"" ) ; doWSDLListOptionTest ( null , Arrays . asList ( wsdl1 , wsdl2 ) ) ; Class < ? > greeterServer = classLoader . loadClass ( ""org.apache.cxf.w2j.hello_world_soap_http.Greeter_SoapPort_Server"" ) ; assertNotNull ( ""Server should be generated"" , greeterServer ) ; Class < ? > carDealerServer = classLoader . loadClass ( ""type_substitution.server.CarDealer_CarDealerPort_Server"" ) ; assertNotNull ( ""Server should be generated"" , carDealerServer ) ; } @ Test public void testWSDLListOptionOneWSDL ( ) throws Exception { env . put ( ToolConstants . CFG_ALL , ToolConstants . CFG_ALL ) ; env . put ( ToolConstants . CFG_WSDLLIST , ToolConstants . CFG_WSDLLIST ) ; String wsdl1 = getLocation ( ""/wsdl2java_wsdl/hello_world.wsdl"" ) ; doWSDLListOptionTest ( null , Arrays . asList ( wsdl1 ) ) ; Class < ? > greeterServer = classLoader . loadClass ( ""org.apache.cxf.w2j.hello_world_soap_http.Greeter_SoapPort_Server"" ) ; assertNotNull ( ""Server should be generated"" , greeterServer ) ; } @ Test public void testWSDLListOptionIncorrectWSDLUrl ( ) throws Exception { env . put ( ToolConstants . CFG_ALL , ToolConstants . CFG_ALL ) ; env . put ( ToolConstants . CFG_WSDLLIST , ToolConstants . CFG_WSDLLIST ) ; String wsdl1 = getLocation ( ""/wsdl2java_wsdl/hello_world.wsdl"" ) ; try { doWSDLListOptionTest ( null , Arrays . asList ( wsdl1 , ""test"" ) ) ; } catch ( WSDLRuntimeException e ) { return ; } fail ( ) ; } @ Test public void testWSDLListOptionIncorrectFile ( ) throws Exception { env . put ( ToolConstants . CFG_ALL , ToolConstants . CFG_ALL ) ; env . put ( ToolConstants . CFG_WSDLLIST , ToolConstants . CFG_WSDLLIST ) ; String wsdl1 = getLocation ( ""/wsdl2java_wsdl/hello_world.wsdl"" ) ; try { doWSDLListOptionTest ( ""/Temp/temp.txt"" , Arrays . asList ( wsdl1 ) ) ; } catch ( ToolException e ) { return ; } fail ( ) ; } private void doWSDLListOptionTest ( String wsdlURL , List < String > wsdls ) throws IOException , ToolException { File file = null ; if ( wsdlURL == null ) { file = tmpDir . newFile ( ""wsdl_list.txt"" ) ; PrintWriter writer = new PrintWriter ( new FileWriter ( file ) ) ; for ( String wsdl : wsdls ) { writer . println ( wsdl ) ; } writer . close ( ) ; wsdlURL = file . getPath ( ) ; } env . put ( ToolConstants . CFG_WSDLURL , wsdlURL ) ; processor . setContext ( env ) ; try { processor . execute ( ) ; } finally { if ( file != null ) { file . delete ( ) ; } } } @ Test public void testHelloWorldExternalBindingFile ( ) throws Exception { env . put ( ToolConstants . CFG_WSDLURL , getLocation ( ""/wsdl2java_wsdl/hello_world_jaxws_base.wsdl"" ) ) ; env . put ( ToolConstants . CFG_BINDING , getLocation ( ""/wsdl2java_wsdl/hello_world_jaxws_binding.wsdl"" ) ) ; processor . setContext ( env ) ; processor . execute ( ) ; assertNotNull ( output ) ; File org = new File ( output , ""org"" ) ; assertTrue ( org . exists ( ) ) ; File apache = new File ( org , ""apache"" ) ; assertTrue ( apache . exists ( ) ) ; Class < ? > clz = classLoader . loadClass ( ""org.apache.cxf.w2j.hello_world_async_soap_http.GreeterAsync"" ) ; assertEquals ( 3 , clz . getMethods ( ) . length ) ; } @ Test public void testGenFault ( ) throws Exception { env . put ( ToolConstants . CFG_WSDLURL , getLocation ( ""/wsdl2java_wsdl/hello_world.wsdl"" ) ) ; env . remove ( ToolConstants . CFG_COMPILE ) ; env . remove ( ToolConstants . CFG_IMPL ) ; env . put ( ToolConstants . CFG_GEN_FAULT , ToolConstants . CFG_GEN_FAULT ) ; processor . setContext ( env ) ; processor . execute ( ) ; File file = new File ( output , ""org/apache/cxf/w2j/hello_world_soap_http"" ) ; assertEquals ( 2 , file . list ( ) . length ) ; } @ Test public void testGetCatalog ( ) throws Exception { env . put ( ToolConstants . CFG_WSDLURL , getLocation ( ""/wsdl2java_wsdl/test_catalog_replaceme.wsdl"" ) ) ; env . put ( ToolConstants . CFG_CATALOG , getLocation ( ""/wsdl2java_wsdl/test_catalog.xml"" ) ) ; env . put ( ToolConstants . CFG_COMPILE , null ) ; env . put ( ToolConstants . CFG_CLASSDIR , null ) ; processor . setContext ( env ) ; processor . execute ( ) ; } @ Test public void testGetCatalogPublic ( ) throws Exception { env . put ( ToolConstants . CFG_WSDLURL , getLocation ( ""/wsdl2java_wsdl/cxf1053/myservice.wsdl"" ) ) ; env . put ( ToolConstants . CFG_CATALOG , getLocation ( ""/wsdl2java_wsdl/cxf1053/catalog.xml"" ) ) ; env . put ( ToolConstants . CFG_COMPILE , null ) ; env . put ( ToolConstants . CFG_CLASSDIR , null ) ; processor . setContext ( env ) ; processor . execute ( ) ; } @ Test public void testMarkGeneratedOption ( ) throws Exception { env . put ( ToolConstants . CFG_WSDLURL , getLocation ( ""/wsdl2java_wsdl/hello_world.wsdl"" ) ) ; env . put ( ToolConstants . CFG_MARK_GENERATED , ""true"" ) ; env . put ( ToolConstants . CFG_COMPILE , null ) ; env . put ( ToolConstants . CFG_CLASSDIR , null ) ; processor . setContext ( env ) ; processor . execute ( ) ; File dir = new File ( output , ""org"" ) ; assertTrue ( ""org directory is not found"" , dir . exists ( ) ) ; dir = new File ( dir , ""apache"" ) ; assertTrue ( ""apache directory is not found"" , dir . exists ( ) ) ; dir = new File ( dir , ""cxf"" ) ; assertTrue ( ""cxf directory is not found"" , dir . exists ( ) ) ; dir = new File ( dir , ""w2j"" ) ; assertTrue ( ""w2j directory is not found"" , dir . exists ( ) ) ; dir = new File ( dir , ""hello_world_soap_http"" ) ; assertTrue ( ""hello_world_soap_http directory is not found"" , dir . exists ( ) ) ; File types = new File ( dir , ""types"" ) ; assertTrue ( ""types directory is not found"" , dir . exists ( ) ) ; String str = IOUtils . readStringFromStream ( new FileInputStream ( new File ( dir , ""Greeter.java"" ) ) ) ; assertEquals ( 7 , countGeneratedAnnotations ( str ) ) ; str = IOUtils . readStringFromStream ( new FileInputStream ( new File ( types , ""SayHi.java"" ) ) ) ; assertEquals ( 1 , countGeneratedAnnotations ( str ) ) ; str = IOUtils . readStringFromStream ( new FileInputStream ( new File ( types , ""SayHiResponse.java"" ) ) ) ; assertEquals ( 4 , countGeneratedAnnotations ( str ) ) ; } private int countGeneratedAnnotations ( String str ) { int count = 0 ; int idx = str . indexOf ( ""@Generated"" ) ; while ( idx != - 1 ) { count ++ ; idx = str . indexOf ( ""@Generated"" , idx + 1 ) ; } return count ; } @ Test public void testResourceURLForWsdlLocation ( ) throws Exception { env . put ( ToolConstants . CFG_WSDLURL , getLocation ( ""/wsdl2java_wsdl/hello_world.wsdl"" ) ) ; env . put ( ToolConstants . CFG_WSDLLOCATION , ""/wsdl2java_wsdl/hello_world.wsdl"" ) ; env . put ( ToolConstants . CFG_COMPILE , null ) ; env . put ( ToolConstants . CFG_CLASSDIR , null ) ; processor . setContext ( env ) ; processor . execute ( ) ; File dir = new File ( output , ""org"" ) ; assertTrue ( ""org directory is not found"" , dir . exists ( ) ) ; dir = new File ( dir , ""apache"" ) ; assertTrue ( ""apache directory is not found"" , dir . exists ( ) ) ; dir = new File ( dir , ""cxf"" ) ; assertTrue ( ""cxf directory is not found"" , dir . exists ( ) ) ; dir = new File ( dir , ""w2j"" ) ; assertTrue ( ""w2j directory is not found"" , dir . exists ( ) ) ; dir = new File ( dir , ""hello_world_soap_http"" ) ; assertTrue ( ""hello_world_soap_http directory is not found"" , dir . exists ( ) ) ; String str = IOUtils . readStringFromStream ( new FileInputStream ( new File ( dir , ""SOAPService.java"" ) ) ) ; assertTrue ( str , str . contains ( ""getResource"" ) ) ; } @ Test public void testEncoding ( ) throws Exception { try { CodeWriter . class . getDeclaredField ( ""encoding"" ) ; } catch ( Throwable t ) { return ; } env . put ( ToolConstants . CFG_WSDLURL , getLocation ( ""/wsdl2java_wsdl/hello_world_encoding.wsdl"" ) ) ; env . put ( ToolConstants . CFG_WSDLLOCATION , ""/wsdl2java_wsdl/hello_world_encoding.wsdl"" ) ; env . put ( ToolConstants . CFG_ENCODING , ""Cp1251"" ) ; processor . setContext ( env ) ; processor . execute ( ) ; File dir = new File ( output , ""org"" ) ; assertTrue ( ""org directory is not found"" , dir . exists ( ) ) ; dir = new File ( dir , ""apache"" ) ; assertTrue ( ""apache directory is not found"" , dir . exists ( ) ) ; dir = new File ( dir , ""cxf"" ) ; assertTrue ( ""cxf directory is not found"" , dir . exists ( ) ) ; dir = new File ( dir , ""w2j"" ) ; assertTrue ( ""w2j directory is not found"" , dir . exists ( ) ) ; dir = new File ( dir , ""hello_world_soap_http"" ) ; assertTrue ( ""hello_world_soap_http directory is not found"" , dir . exists ( ) ) ; String str = IOUtils . readStringFromStream ( new FileInputStream ( new File ( dir , ""SOAPService.java"" ) ) ) ; assertTrue ( str , str . contains ( ""getResource"" ) ) ; Class < ? > clz = classLoader . loadClass ( ""org.apache.cxf.w2j.hello_world_soap_http.Greeter"" ) ; for ( Method m : clz . getMethods ( ) ) { String s = m . getName ( ) ; assertEquals ( 1039 , s . charAt ( 2 ) ) ; } } }",Smelly
"public class PasswordResetPanel extends Panel { public PasswordResetPanel ( final String id , final String uuid ) { super ( id ) ; StatelessForm < Void > form = new StatelessForm < > ( ""passwordResetForm"" ) ; addOrReplace ( form ) ; final PasswordTextField passwordField = new PasswordTextField ( ""password"" , Model . of ( """" ) ) ; passwordField . setLabel ( new ResourceModel ( ""passwordLabel"" ) ) ; form . add ( passwordField ) ; final PasswordTextField confirmPasswordField = new PasswordTextField ( ""confirmPassword"" , Model . of ( """" ) ) ; confirmPasswordField . setLabel ( new ResourceModel ( ""confirmPasswordLabel"" ) ) ; form . add ( confirmPasswordField ) ; form . add ( new EqualPasswordInputValidator ( passwordField , confirmPasswordField ) ) ; Button signUpButton = new Button ( ""passwordResetSubmit"" ) { @ Override public void onSubmit ( ) { super . onSubmit ( ) ; final String password = confirmPasswordField . getModelObject ( ) ; final AccountConfirmationMap accountConfirmationMap = getApplication ( ) . getMetaData ( AccountConfirmationMap . KEY ) ; Boolean passwordUpdated = getIsisSessionFactory ( ) . doInSession ( new Callable < Boolean > ( ) { @ Override public Boolean call ( ) throws Exception { String email = accountConfirmationMap . get ( uuid ) ; UserRegistrationService userRegistrationService = getIsisSessionFactory ( ) . getServicesInjector ( ) . lookupServiceElseFail ( UserRegistrationService . class ) ; return userRegistrationService . updatePasswordByEmail ( email , password ) ; } } ) ; if ( passwordUpdated ) { accountConfirmationMap . remove ( uuid ) ; success ( createPasswordChangeSuccessfulMessage ( ) ) ; } else { error ( getString ( ""passwordChangeUnsuccessful"" ) ) ; } } } ; form . add ( signUpButton ) ; } private INotificationMessage createPasswordChangeSuccessfulMessage ( ) { Class < ? extends Page > signInPage = pageClassRegistry . getPageClass ( PageType . SIGN_IN ) ; CharSequence signInUrl = urlFor ( signInPage , null ) ; Map < String , CharSequence > map = new HashMap < > ( ) ; map . put ( ""signInUrl"" , signInUrl ) ; String passwordChangeSuccessful = getString ( ""passwordChangeSuccessful"" , Model . ofMap ( map ) ) ; NotificationMessage message = new NotificationMessage ( Model . of ( passwordChangeSuccessful ) ) ; message . escapeModelStrings ( false ) ; return message ; } @ javax . inject . Inject private PageClassRegistry pageClassRegistry ; protected IsisSessionFactory getIsisSessionFactory ( ) { return IsisContext . getSessionFactory ( ) ; } }",No
"public abstract class AbstractQueryBuilder < T extends AbstractQueryBuilder < T > > implements Cloneable , PrologClause < T > , ValuesClause < T > { protected Query query ; private final Map < Var , Node > values ; public Node makeNode ( Object o ) { return makeNode ( o , query . getPrefixMapping ( ) ) ; } private Object makeNodeOrPath ( Object o ) { return makeNodeOrPath ( o , query . getPrefixMapping ( ) ) ; } public static Object makeNodeOrPath ( Object o , PrefixMapping pMapping ) { if ( o == null ) { return Node . ANY ; } if ( o instanceof Path ) { return o ; } if ( o instanceof FrontsNode ) { return ( ( FrontsNode ) o ) . asNode ( ) ; } if ( o instanceof Node ) { return o ; } if ( o instanceof String ) { try { final Path p = PathParser . parse ( ( String ) o , pMapping ) ; if ( p instanceof P_Link ) { return ( ( P_Link ) p ) . getNode ( ) ; } return p ; } catch ( final QueryParseException e ) { return makeNode ( o , pMapping ) ; } catch ( final Exception e ) { } } return NodeFactory . createLiteral ( LiteralLabelFactory . createTypedLiteral ( o ) ) ; } public ElementSubQuery asSubQuery ( ) { return getWhereHandler ( ) . makeSubQuery ( this ) ; } public TriplePath makeTriplePath ( Object s , Object p , Object o ) { final Object po = makeNodeOrPath ( p ) ; if ( po instanceof Path ) { return new TriplePath ( makeNode ( s ) , ( Path ) po , makeNode ( o ) ) ; } else { return new TriplePath ( new Triple ( makeNode ( s ) , ( Node ) po , makeNode ( o ) ) ) ; } } public Expr makeExpr ( String expression ) throws QueryParseException { return ExprUtils . parse ( query , expression , true ) ; } public static String quote ( String q ) { final int qt = q . indexOf ( '""' ) ; final int sqt = q . indexOf ( ""'"" ) ; if ( sqt == - 1 || qt < sqt ) { return String . format ( ""'%s'"" , q ) ; } return String . format ( ""\""%s\"""" , q ) ; } public static Node checkVar ( Node n ) { if ( n . isVariable ( ) ) { return Var . alloc ( n ) ; } return n ; } public static Node makeNode ( Object o , PrefixMapping pMapping ) { if ( o == null ) { return Node . ANY ; } if ( o instanceof FrontsNode ) { return checkVar ( ( ( FrontsNode ) o ) . asNode ( ) ) ; } if ( o instanceof Node ) { return checkVar ( ( Node ) o ) ; } if ( o instanceof String ) { try { return checkVar ( NodeFactoryExtra . parseNode ( ( String ) o , PrefixMapFactory . createForInput ( pMapping ) ) ) ; } catch ( final RiotException e ) { } } return NodeFactory . createLiteral ( LiteralLabelFactory . createTypedLiteral ( o ) ) ; } public static Var makeVar ( Object o ) throws ARQInternalErrorException { if ( o == null ) { return Var . ANON ; } if ( o instanceof Var ) { return ( Var ) o ; } Var retval = null ; if ( o instanceof FrontsNode ) { retval = Var . alloc ( ( ( FrontsNode ) o ) . asNode ( ) ) ; } else if ( o instanceof Node ) { retval = Var . alloc ( ( Node ) o ) ; } else if ( o instanceof ExprVar ) { retval = Var . alloc ( ( ExprVar ) o ) ; } else { retval = Var . alloc ( Var . canonical ( o . toString ( ) ) ) ; } if ( ""*"" . equals ( Var . canonical ( retval . toString ( ) ) ) ) { return null ; } return retval ; } protected AbstractQueryBuilder ( ) { query = new Query ( ) ; values = new HashMap < Var , Node > ( ) ; } public abstract HandlerBlock getHandlerBlock ( ) ; @ Override public final PrologHandler getPrologHandler ( ) { return getHandlerBlock ( ) . getPrologHandler ( ) ; } @ Override public ValuesHandler getValuesHandler ( ) { return getHandlerBlock ( ) . getValueHandler ( ) ; } public final WhereHandler getWhereHandler ( ) { return getHandlerBlock ( ) . getWhereHandler ( ) ; } @ SuppressWarnings ( ""unchecked"" ) public final T addWhere ( AbstractQueryBuilder < ? > whereClause ) { getWhereHandler ( ) . addAll ( whereClause . getWhereHandler ( ) ) ; return ( T ) this ; } @ Override public final ExprFactory getExprFactory ( ) { return getHandlerBlock ( ) . getPrologHandler ( ) . getExprFactory ( ) ; } public void setVar ( Var var , Node value ) { if ( value == null ) { values . remove ( var ) ; } else { values . put ( var , value ) ; } } public void setVar ( Object var , Object value ) { if ( value == null ) { setVar ( makeVar ( var ) , null ) ; } else { setVar ( makeVar ( var ) , makeNode ( value ) ) ; } } @ Override public T addPrefix ( String pfx , Resource uri ) { return addPrefix ( pfx , uri . getURI ( ) ) ; } @ Override public T addPrefix ( String pfx , Node uri ) { return addPrefix ( pfx , uri . getURI ( ) ) ; } @ SuppressWarnings ( ""unchecked"" ) @ Override public T addPrefix ( String pfx , String uri ) { getPrologHandler ( ) . addPrefix ( pfx , uri ) ; return ( T ) this ; } @ SuppressWarnings ( ""unchecked"" ) @ Override public T addPrefixes ( Map < String , String > prefixes ) { getPrologHandler ( ) . addPrefixes ( prefixes ) ; return ( T ) this ; } @ SuppressWarnings ( ""unchecked"" ) @ Override public T addPrefixes ( PrefixMapping prefixMapping ) { getPrologHandler ( ) . addPrefixes ( prefixMapping ) ; return ( T ) this ; } @ SuppressWarnings ( ""unchecked"" ) @ Override public T setBase ( String base ) { getPrologHandler ( ) . setBase ( base ) ; return ( T ) this ; } @ SuppressWarnings ( ""unchecked"" ) @ Override public T setBase ( Object base ) { setBase ( makeNode ( base ) . getURI ( ) ) ; return ( T ) this ; } public static Collection < Node > makeValueNodes ( Iterator < ? > iter , PrefixMapping prefixMapping ) { if ( iter == null || ! iter . hasNext ( ) ) { return null ; } final List < Node > values = new ArrayList < Node > ( ) ; while ( iter . hasNext ( ) ) { final Object o = iter . next ( ) ; if ( o == null ) { values . add ( null ) ; } else { values . add ( makeNode ( o , prefixMapping ) ) ; } } return values ; } public Collection < Node > makeValueNodes ( Iterator < ? > iter ) { return makeValueNodes ( iter , getPrologHandler ( ) . getPrefixes ( ) ) ; } @ SuppressWarnings ( ""unchecked"" ) @ Override public T addValueVar ( Object var ) { if ( var == null ) { throw new IllegalArgumentException ( ""var must not be null."" ) ; } if ( var instanceof Collection < ? > ) { final Collection < ? > column = ( Collection < ? > ) var ; if ( column . size ( ) == 0 ) { throw new IllegalArgumentException ( ""column must have at least one entry."" ) ; } final Iterator < ? > iter = column . iterator ( ) ; final Var v = makeVar ( iter . next ( ) ) ; getValuesHandler ( ) . addValueVar ( v , makeValueNodes ( iter ) ) ; } else { getValuesHandler ( ) . addValueVar ( makeVar ( var ) , null ) ; } return ( T ) this ; } @ SuppressWarnings ( ""unchecked"" ) @ Override public T addValueVar ( Object var , Object ... objects ) { Collection < Node > values = null ; if ( objects != null ) { values = makeValueNodes ( Arrays . asList ( objects ) . iterator ( ) ) ; } getValuesHandler ( ) . addValueVar ( makeVar ( var ) , values ) ; return ( T ) this ; } @ SuppressWarnings ( ""unchecked"" ) @ Override public < K extends Collection < ? > > T addValueVars ( Map < ? , K > dataTable ) { final ValuesHandler hdlr = new ValuesHandler ( null ) ; for ( final Map . Entry < ? , K > entry : dataTable . entrySet ( ) ) { Collection < Node > values = null ; if ( entry . getValue ( ) != null ) { values = makeValueNodes ( entry . getValue ( ) . iterator ( ) ) ; } hdlr . addValueVar ( makeVar ( entry . getKey ( ) ) , values ) ; } getValuesHandler ( ) . addAll ( hdlr ) ; return ( T ) this ; } @ SuppressWarnings ( ""unchecked"" ) @ Override public T addValueRow ( Object ... values ) { getValuesHandler ( ) . addValueRow ( makeValueNodes ( Arrays . asList ( values ) . iterator ( ) ) ) ; return ( T ) this ; } @ SuppressWarnings ( ""unchecked"" ) @ Override public T addValueRow ( Collection < ? > values ) { getValuesHandler ( ) . addValueRow ( makeValueNodes ( values . iterator ( ) ) ) ; return ( T ) this ; } @ Override public List < Var > getValuesVars ( ) { return getValuesHandler ( ) . getValuesVars ( ) ; } @ Override public Map < Var , List < Node > > getValuesMap ( ) { return getValuesHandler ( ) . getValuesMap ( ) ; } @ SuppressWarnings ( ""unchecked"" ) @ Override public T clearValues ( ) { getValuesHandler ( ) . clear ( ) ; return ( T ) this ; } @ Override public String toString ( ) { return buildString ( ) ; } public final String buildString ( ) { return build ( ) . toString ( ) ; } public final Query build ( ) { final Query q = new Query ( ) ; switch ( query . queryType ( ) ) { case ASK : q . setQueryAskType ( ) ; break ; case CONSTRUCT : q . setQueryConstructType ( ) ; break ; case DESCRIBE : q . setQueryDescribeType ( ) ; break ; case SELECT : q . setQuerySelectType ( ) ; break ; case UNKNOWN : break ; default : throw new IllegalStateException ( ""Internal query is not a known type: "" + q . queryType ( ) ) ; } final HandlerBlock handlerBlock = new HandlerBlock ( q ) ; handlerBlock . addAll ( getHandlerBlock ( ) ) ; handlerBlock . setVars ( values ) ; if ( q . getQueryPattern ( ) == null ) { q . setQueryPattern ( new ElementGroup ( ) ) ; } handlerBlock . build ( ) ; return q ; } public static Query clone ( Query q2 ) { final Query retval = new Query ( ) ; if ( q2 . isSelectType ( ) ) { retval . setQuerySelectType ( ) ; } else if ( q2 . isAskType ( ) ) { retval . setQueryAskType ( ) ; } else if ( q2 . isDescribeType ( ) ) { retval . setQueryDescribeType ( ) ; } else if ( q2 . isConstructType ( ) ) { retval . setQueryConstructType ( ) ; } final HandlerBlock hb = new HandlerBlock ( retval ) ; final HandlerBlock hb2 = new HandlerBlock ( q2 ) ; hb . addAll ( hb2 ) ; return retval ; } public static Query rewrite ( Query q2 , Map < Var , Node > values ) { final HandlerBlock hb = new HandlerBlock ( q2 ) ; hb . setVars ( values ) ; return q2 ; } }",Smelly
"public abstract class AbstractUtilities { protected static final Logger LOG = LoggerFactory . getLogger ( AbstractUtilities . class ) ; protected final Metadata metadata ; protected final FSManager fsManager ; protected final ODataDeserializer atomDeserializer ; protected final ODataDeserializer jsonDeserializer ; protected final ODataSerializer atomSerializer ; protected final ODataSerializer jsonSerializer ; public AbstractUtilities ( final Metadata metadata ) throws IOException { this . metadata = metadata ; fsManager = FSManager . instance ( ) ; atomDeserializer = new FITAtomDeserializer ( ) ; jsonDeserializer = new JsonDeserializer ( true ) ; atomSerializer = new AtomSerializer ( true ) ; jsonSerializer = new JsonSerializer ( true , ContentType . JSON_FULL_METADATA ) ; } public boolean isMediaContent ( final String entityName ) { return Commons . MEDIA_CONTENT . containsKey ( entityName ) ; } protected abstract InputStream addLinks ( final String entitySetName , final String entitykey , final InputStream is , final Set < String > links ) throws Exception ; protected abstract Set < String > retrieveAllLinkNames ( final InputStream is ) throws Exception ; protected abstract NavigationLinks retrieveNavigationInfo ( final String entitySetName , final InputStream is ) throws Exception ; protected abstract InputStream normalizeLinks ( final String entitySetName , final String entityKey , final InputStream is , final NavigationLinks links ) throws Exception ; public InputStream saveSingleEntity ( final String key , final String entitySetName , final InputStream is , final NavigationLinks links ) throws Exception { final String path = entitySetName + File . separatorChar + Commons . getEntityKey ( key ) + File . separatorChar + Constants . get ( ConstantKey . ENTITY ) ; final InputStream normalized = normalizeLinks ( entitySetName , key , is , links ) ; final FileObject fo = fsManager . putInMemory ( normalized , fsManager . getAbsolutePath ( path , getDefaultFormat ( ) ) ) ; return fo . getContent ( ) . getInputStream ( ) ; } private InputStream toInputStream ( final Entity entry ) throws ODataSerializerException { final StringWriter writer = new StringWriter ( ) ; atomSerializer . write ( writer , entry ) ; return IOUtils . toInputStream ( writer . toString ( ) , Constants . ENCODING ) ; } public InputStream addOrReplaceEntity ( final String key , final String entitySetName , final InputStream is , final Entity entry ) throws Exception { final ByteArrayOutputStream bos = new ByteArrayOutputStream ( ) ; IOUtils . copy ( is , bos ) ; IOUtils . closeQuietly ( is ) ; final Map < String , NavigationProperty > navigationProperties = metadata . getNavigationProperties ( entitySetName ) ; Set < String > linksToBeKept ; try { linksToBeKept = new HashSet < String > ( navigationProperties . keySet ( ) ) ; } catch ( NullPointerException e ) { linksToBeKept = Collections . < String > emptySet ( ) ; } for ( String availableLink : new HashSet < String > ( linksToBeKept ) ) { try { fsManager . resolve ( Commons . getLinksPath ( entitySetName , key , availableLink , Accept . JSON_FULLMETA ) ) ; } catch ( Exception e ) { linksToBeKept . remove ( availableLink ) ; } } for ( String linkName : retrieveAllLinkNames ( new ByteArrayInputStream ( bos . toByteArray ( ) ) ) ) { linksToBeKept . remove ( linkName ) ; } final String entityKey = key == null ? getDefaultEntryKey ( entitySetName , entry ) : key ; final String path = Commons . getEntityBasePath ( entitySetName , entityKey ) ; final NavigationLinks links = retrieveNavigationInfo ( entitySetName , new ByteArrayInputStream ( bos . toByteArray ( ) ) ) ; final InputStream createdEntity = saveSingleEntity ( entityKey , entitySetName , new ByteArrayInputStream ( bos . toByteArray ( ) ) , links ) ; bos . reset ( ) ; IOUtils . copy ( createdEntity , bos ) ; final InputStream normalizedEntity = addLinks ( entitySetName , entityKey , new ByteArrayInputStream ( bos . toByteArray ( ) ) , linksToBeKept ) ; IOUtils . closeQuietly ( bos ) ; final FileObject fo = fsManager . putInMemory ( normalizedEntity , fsManager . getAbsolutePath ( path + Constants . get ( ConstantKey . ENTITY ) , getDefaultFormat ( ) ) ) ; for ( Map . Entry < String , List < String > > link : links . getLinks ( ) ) { putLinksInMemory ( path , entitySetName , entityKey , link . getKey ( ) , link . getValue ( ) ) ; } final List < String > hrefs = new ArrayList < String > ( ) ; for ( final Link link : entry . getNavigationLinks ( ) ) { final NavigationProperty navProp = navigationProperties == null ? null : navigationProperties . get ( link . getTitle ( ) ) ; if ( navProp != null ) { final String inlineEntitySetName = navProp . getTarget ( ) ; if ( link . getInlineEntity ( ) != null ) { final String inlineEntryKey = getDefaultEntryKey ( inlineEntitySetName , link . getInlineEntity ( ) ) ; addOrReplaceEntity ( inlineEntryKey , inlineEntitySetName , toInputStream ( link . getInlineEntity ( ) ) , link . getInlineEntity ( ) ) ; hrefs . add ( inlineEntitySetName + ""("" + inlineEntryKey + "")"" ) ; } else if ( link . getInlineEntitySet ( ) != null ) { for ( Entity subentry : link . getInlineEntitySet ( ) . getEntities ( ) ) { final String inlineEntryKey = getDefaultEntryKey ( inlineEntitySetName , subentry ) ; addOrReplaceEntity ( inlineEntryKey , inlineEntitySetName , toInputStream ( subentry ) , subentry ) ; hrefs . add ( inlineEntitySetName + ""("" + inlineEntryKey + "")"" ) ; } } if ( ! hrefs . isEmpty ( ) ) { putLinksInMemory ( path , entitySetName , entityKey , link . getTitle ( ) , hrefs ) ; } } } return fo . getContent ( ) . getInputStream ( ) ; } public void addMediaEntityValue ( final String entitySetName , final String entityKey , final InputStream is ) throws Exception { final String path = Commons . getEntityBasePath ( entitySetName , entityKey ) ; fsManager . putInMemory ( is , fsManager . getAbsolutePath ( path + Constants . get ( ConstantKey . MEDIA_CONTENT_FILENAME ) , null ) ) ; IOUtils . closeQuietly ( is ) ; } public void putLinksInMemory ( final String basePath , final String entitySetName , final String entityKey , final String linkName , final Collection < String > links ) throws Exception { final HashSet < String > uris = new HashSet < String > ( ) ; final Map < String , NavigationProperty > navigationProperties = metadata . getNavigationProperties ( entitySetName ) ; if ( navigationProperties . get ( linkName ) != null && navigationProperties . get ( linkName ) . isEntitySet ( ) ) { try { final Map . Entry < String , List < String > > currents = extractLinkURIs ( entitySetName , entityKey , linkName ) ; uris . addAll ( currents . getValue ( ) ) ; } catch ( Exception ignore ) { } } uris . addAll ( links ) ; putLinksInMemory ( basePath , entitySetName , linkName , uris ) ; } public void putLinksInMemory ( final String basePath , final String entitySetName , final String linkName , final Collection < String > uris ) throws Exception { fsManager . putInMemory ( Commons . getLinksAsJSON ( entitySetName , new SimpleEntry < String , Collection < String > > ( linkName , uris ) ) , Commons . getLinksPath ( basePath , linkName , Accept . JSON_FULLMETA ) ) ; fsManager . putInMemory ( Commons . getLinksAsATOM ( new SimpleEntry < String , Collection < String > > ( linkName , uris ) ) , Commons . getLinksPath ( basePath , linkName , Accept . XML ) ) ; } public Response createResponse ( final String location , final InputStream entity , final String etag , final Accept accept ) { return createResponse ( location , entity , etag , accept , null ) ; } public Response createAsyncResponse ( final String location ) { final Response . ResponseBuilder builder = Response . accepted ( ) ; builder . header ( ""Location"" , location ) ; builder . header ( ""Preference-Applied"" , ""Respond-Async"" ) ; builder . header ( ""Retry-After"" , ""10"" ) ; return builder . build ( ) ; } public Response createMonitorResponse ( final InputStream res ) { final Response . ResponseBuilder builder = Response . ok ( ) ; builder . header ( ""Content-Type"" , ""application/http"" ) ; builder . header ( ""Content-Transfer-Encoding"" , ""binary"" ) ; return builder . entity ( res ) . build ( ) ; } public Response createResponse ( final InputStream entity , final String etag , final Accept accept ) { return createResponse ( null , entity , etag , accept , null ) ; } public Response createBatchResponse ( final InputStream stream ) { final Response . ResponseBuilder builder = Response . ok ( stream ) ; builder . header ( Constants . get ( ConstantKey . ODATA_SERVICE_VERSION ) , ODataServiceVersion . V40 . toString ( ) + "";"" ) ; return builder . build ( ) ; } public Response createResponse ( final InputStream entity , final String etag , final Accept accept , final Response . Status status ) { return createResponse ( null , entity , etag , accept , status ) ; } public Response createResponse ( final String location , final InputStream entity , final String etag , final Accept accept , final Response . Status status ) { final Response . ResponseBuilder builder = Response . ok ( ) ; if ( StringUtils . isNotBlank ( etag ) ) { builder . header ( ""ETag"" , etag ) ; } if ( status != null ) { builder . status ( status ) ; } int contentLength = 0 ; String contentTypeEncoding = StringUtils . EMPTY ; if ( entity != null ) { try { final InputStream toBeStreamedBack ; if ( Accept . JSON == accept || Accept . JSON_NOMETA == accept ) { toBeStreamedBack = Commons . changeFormat ( entity , accept ) ; } else { toBeStreamedBack = entity ; } final ByteArrayOutputStream bos = new ByteArrayOutputStream ( ) ; IOUtils . copy ( toBeStreamedBack , bos ) ; IOUtils . closeQuietly ( toBeStreamedBack ) ; contentLength = bos . size ( ) ; builder . entity ( new ByteArrayInputStream ( bos . toByteArray ( ) ) ) ; contentTypeEncoding = "";odata.streaming=true;charset=utf-8"" ; } catch ( IOException ioe ) { LOG . error ( ""Error streaming response entity back"" , ioe ) ; } } builder . header ( ""Content-Length"" , contentLength ) ; builder . header ( ""Content-Type"" , ( accept == null ? ""*/*"" : accept . toString ( ) ) + contentTypeEncoding ) ; if ( StringUtils . isNotBlank ( location ) ) { builder . header ( ""Location"" , location ) ; } return builder . build ( ) ; } public Response createFaultResponse ( final String accept , final Exception e ) { LOG . debug ( ""Create fault response about .... "" , e ) ; final Response . ResponseBuilder builder = Response . serverError ( ) ; final String ext ; final Accept contentType ; if ( accept . startsWith ( ""application/json"" ) ) { ext = "".json"" ; contentType = Accept . JSON ; } else if ( accept . startsWith ( ""application/xml"" ) ) { ext = "".xml"" ; contentType = Accept . XML ; } else { ext = "".json"" ; contentType = Accept . JSON ; } builder . header ( ""Content-Type"" , contentType ) ; final InputStream src ; if ( e instanceof ConcurrentModificationException ) { builder . status ( Response . Status . PRECONDITION_FAILED ) ; src = fsManager . readFile ( ""/badRequest"" + ext , null ) ; } else if ( e instanceof UnsupportedMediaTypeException ) { builder . status ( Response . Status . UNSUPPORTED_MEDIA_TYPE ) ; src = fsManager . readFile ( ""/unsupportedMediaType"" + ext , null ) ; } else if ( e instanceof NotFoundException ) { builder . status ( Response . Status . NOT_FOUND ) ; src = fsManager . readFile ( ""/notFound"" + ext , null ) ; } else { builder . status ( Response . Status . BAD_REQUEST ) ; src = fsManager . readFile ( ""/badRequest"" + ext , null ) ; } builder . entity ( src ) ; return builder . build ( ) ; } public EntityCollection readEntitySet ( final Accept accept , final InputStream entitySet ) throws ODataDeserializerException { return ( accept == Accept . ATOM || accept == Accept . XML ? atomDeserializer . toEntitySet ( entitySet ) : jsonDeserializer . toEntitySet ( entitySet ) ) . getPayload ( ) ; } public InputStream writeEntitySet ( final Accept accept , final ResWrap < EntityCollection > container ) throws ODataSerializerException , IOException { final StringWriter writer = new StringWriter ( ) ; if ( accept == Accept . ATOM || accept == Accept . XML ) { atomSerializer . write ( writer , container ) ; } else { jsonSerializer . write ( writer , container ) ; } writer . flush ( ) ; writer . close ( ) ; return IOUtils . toInputStream ( writer . toString ( ) , Constants . ENCODING ) ; } public ResWrap < Entity > readContainerEntity ( final Accept accept , final InputStream entity ) throws ODataDeserializerException { return accept == Accept . ATOM || accept == Accept . XML ? atomDeserializer . toEntity ( entity ) : jsonDeserializer . toEntity ( entity ) ; } public Entity readEntity ( final Accept accept , final InputStream entity ) throws IOException , ODataDeserializerException { return readContainerEntity ( accept , entity ) . getPayload ( ) ; } public InputStream writeEntity ( final Accept accept , final ResWrap < Entity > container ) throws ODataSerializerException { StringWriter writer = new StringWriter ( ) ; if ( accept == Accept . ATOM || accept == Accept . XML ) { atomSerializer . write ( writer , container ) ; } else { jsonSerializer . write ( writer , container ) ; } return IOUtils . toInputStream ( writer . toString ( ) , Constants . ENCODING ) ; } public InputStream writeProperty ( final Accept accept , final Property property ) throws ODataSerializerException { final StringWriter writer = new StringWriter ( ) ; if ( accept == Accept . XML || accept == Accept . ATOM ) { atomSerializer . write ( writer , property ) ; } else { jsonSerializer . write ( writer , property ) ; } return IOUtils . toInputStream ( writer . toString ( ) , Constants . ENCODING ) ; } public Property readProperty ( final Accept accept , final InputStream property ) throws ODataDeserializerException { return ( Accept . ATOM == accept || Accept . XML == accept ? atomDeserializer . toProperty ( property ) : jsonDeserializer . toProperty ( property ) ) . getPayload ( ) ; } public InputStream writeProperty ( final Accept accept , final ResWrap < Property > container ) throws ODataSerializerException { final StringWriter writer = new StringWriter ( ) ; if ( accept == Accept . XML || accept == Accept . ATOM ) { atomSerializer . write ( writer , container ) ; } else { jsonSerializer . write ( writer , container ) ; } return IOUtils . toInputStream ( writer . toString ( ) , Constants . ENCODING ) ; } private String getDefaultEntryKey ( final String entitySetName , final Entity entry , final String propertyName ) throws IOException { String res ; if ( entry . getProperty ( propertyName ) == null ) { if ( Commons . SEQUENCE . containsKey ( entitySetName ) ) { res = String . valueOf ( Commons . SEQUENCE . get ( entitySetName ) + 1 ) ; } else { throw new IOException ( String . format ( ""Unable to retrieve entity key value for %s"" , entitySetName ) ) ; } } else { res = entry . getProperty ( propertyName ) . asPrimitive ( ) . toString ( ) ; } Commons . SEQUENCE . put ( entitySetName , Integer . valueOf ( res ) ) ; return res ; } public String getDefaultEntryKey ( final String entitySetName , final Entity entity ) throws IOException { try { String res ; if ( ""OrderDetails"" . equals ( entitySetName ) ) { int productID ; if ( entity . getProperty ( ""OrderID"" ) == null || entity . getProperty ( ""ProductID"" ) == null ) { if ( Commons . SEQUENCE . containsKey ( entitySetName ) ) { productID = Commons . SEQUENCE . get ( entitySetName ) + 1 ; res = ""OrderID=1"" + "",ProductID="" + String . valueOf ( productID ) ; } else { throw new IOException ( String . format ( ""Unable to retrieve entity key value for %s"" , entitySetName ) ) ; } } else { productID = ( Integer ) entity . getProperty ( ""OrderID"" ) . asPrimitive ( ) ; res = ""OrderID="" + entity . getProperty ( ""OrderID"" ) . asPrimitive ( ) + "",ProductID="" + entity . getProperty ( ""ProductID"" ) . asPrimitive ( ) ; } Commons . SEQUENCE . put ( entitySetName , productID ) ; } else if ( ""Message"" . equals ( entitySetName ) ) { int messageId ; if ( entity . getProperty ( ""MessageId"" ) == null || entity . getProperty ( ""FromUsername"" ) == null ) { if ( Commons . SEQUENCE . containsKey ( entitySetName ) ) { messageId = Commons . SEQUENCE . get ( entitySetName ) + 1 ; res = ""FromUsername=1"" + "",MessageId="" + String . valueOf ( messageId ) ; } else { throw new IOException ( String . format ( ""Unable to retrieve entity key value for %s"" , entitySetName ) ) ; } } else { messageId = ( Integer ) entity . getProperty ( ""MessageId"" ) . asPrimitive ( ) ; res = ""FromUsername="" + entity . getProperty ( ""FromUsername"" ) . asPrimitive ( ) + "",MessageId="" + entity . getProperty ( ""MessageId"" ) . asPrimitive ( ) ; } Commons . SEQUENCE . put ( entitySetName , messageId ) ; } else if ( ""PersonDetails"" . equals ( entitySetName ) ) { res = getDefaultEntryKey ( entitySetName , entity , ""PersonID"" ) ; } else if ( ""Order"" . equals ( entitySetName ) ) { res = getDefaultEntryKey ( entitySetName , entity , ""OrderId"" ) ; } else if ( ""Product"" . equals ( entitySetName ) ) { res = getDefaultEntryKey ( entitySetName , entity , ""ProductId"" ) ; } else if ( ""Orders"" . equals ( entitySetName ) ) { res = getDefaultEntryKey ( entitySetName , entity , ""OrderID"" ) ; } else if ( ""Customer"" . equals ( entitySetName ) ) { res = getDefaultEntryKey ( entitySetName , entity , ""CustomerId"" ) ; } else if ( ""Customers"" . equals ( entitySetName ) ) { res = getDefaultEntryKey ( entitySetName , entity , ""PersonID"" ) ; } else if ( ""Person"" . equals ( entitySetName ) ) { res = getDefaultEntryKey ( entitySetName , entity , ""PersonId"" ) ; } else if ( ""ComputerDetail"" . equals ( entitySetName ) ) { res = getDefaultEntryKey ( entitySetName , entity , ""ComputerDetailId"" ) ; } else if ( ""AllGeoTypesSet"" . equals ( entitySetName ) ) { res = getDefaultEntryKey ( entitySetName , entity , ""Id"" ) ; } else if ( ""CustomerInfo"" . equals ( entitySetName ) ) { res = getDefaultEntryKey ( entitySetName , entity , ""CustomerInfoId"" ) ; } else if ( ""Car"" . equals ( entitySetName ) ) { res = getDefaultEntryKey ( entitySetName , entity , ""VIN"" ) ; } else if ( ""RowIndex"" . equals ( entitySetName ) ) { res = getDefaultEntryKey ( entitySetName , entity , ""Id"" ) ; } else if ( ""Login"" . equals ( entitySetName ) ) { res = ( String ) entity . getProperty ( ""Username"" ) . asPrimitive ( ) ; } else if ( ""Products"" . equals ( entitySetName ) ) { res = getDefaultEntryKey ( entitySetName , entity , ""ProductID"" ) ; } else if ( ""ProductDetails"" . equals ( entitySetName ) ) { int productId ; int productDetailId ; if ( entity . getProperty ( ""ProductID"" ) == null || entity . getProperty ( ""ProductDetailID"" ) == null ) { if ( Commons . SEQUENCE . containsKey ( entitySetName ) && Commons . SEQUENCE . containsKey ( ""Products"" ) ) { productId = Commons . SEQUENCE . get ( ""Products"" ) + 1 ; productDetailId = Commons . SEQUENCE . get ( entitySetName ) + 1 ; res = ""ProductID="" + String . valueOf ( productId ) + "",ProductDetailID="" + String . valueOf ( productDetailId ) ; } else { throw new IOException ( String . format ( ""Unable to retrieve entity key value for %s"" , entitySetName ) ) ; } Commons . SEQUENCE . put ( entitySetName , productDetailId ) ; } else { productId = ( Integer ) entity . getProperty ( ""ProductID"" ) . asPrimitive ( ) ; productDetailId = ( Integer ) entity . getProperty ( ""ProductDetailID"" ) . asPrimitive ( ) ; res = ""ProductID="" + entity . getProperty ( ""ProductID"" ) . asPrimitive ( ) + "",ProductDetailID="" + entity . getProperty ( ""ProductDetailID"" ) . asPrimitive ( ) ; } Commons . SEQUENCE . put ( entitySetName , productDetailId ) ; Commons . SEQUENCE . put ( ""Products"" , productId ) ; } else if ( ""PaymentInstrument"" . equals ( entitySetName ) ) { res = getDefaultEntryKey ( entitySetName , entity , ""PaymentInstrumentID"" ) ; } else if ( ""Advertisements"" . equals ( entitySetName ) ) { res = UUID . randomUUID ( ) . toString ( ) ; } else if ( ""People"" . equals ( entitySetName ) ) { res = getDefaultEntryKey ( entitySetName , entity , ""PersonID"" ) ; } else { throw new IOException ( String . format ( ""EntitySet '%s' not found"" , entitySetName ) ) ; } return res ; } catch ( Exception e ) { throw new NotFoundException ( e ) ; } } public String getLinksBasePath ( final String entitySetName , final String entityId ) { return entitySetName + File . separatorChar + Commons . getEntityKey ( entityId ) + File . separatorChar + Constants . get ( ConstantKey . LINKS_FILE_PATH ) + File . separatorChar ; } public LinkInfo readLinks ( final String entitySetName , final String entityId , final String linkName , final Accept accept ) throws Exception { final String basePath = getLinksBasePath ( entitySetName , entityId ) ; final LinkInfo linkInfo = new LinkInfo ( fsManager . readFile ( basePath + linkName , accept ) ) ; linkInfo . setEtag ( Commons . getETag ( basePath ) ) ; final Map < String , NavigationProperty > navigationProperties = metadata . getNavigationProperties ( entitySetName ) ; linkInfo . setFeed ( navigationProperties . get ( linkName . replaceAll ( ""\\(.*\\)"" , """" ) ) . isEntitySet ( ) ) ; return linkInfo ; } public InputStream putMediaInMemory ( final String entitySetName , final String entityId , final InputStream value ) throws IOException { return putMediaInMemory ( entitySetName , entityId , null , value ) ; } public InputStream putMediaInMemory ( final String entitySetName , final String entityId , final String name , final InputStream value ) throws IOException { final FileObject fo = fsManager . putInMemory ( value , fsManager . getAbsolutePath ( Commons . getEntityBasePath ( entitySetName , entityId ) + ( name == null ? Constants . get ( ConstantKey . MEDIA_CONTENT_FILENAME ) : name ) , null ) ) ; return fo . getContent ( ) . getInputStream ( ) ; } public Map . Entry < String , InputStream > readMediaEntity ( final String entitySetName , final String entityId ) { return readMediaEntity ( entitySetName , entityId , null ) ; } public Map . Entry < String , InputStream > readMediaEntity ( final String entitySetName , final String entityId , final String name ) { final String basePath = Commons . getEntityBasePath ( entitySetName , entityId ) ; return new SimpleEntry < String , InputStream > ( basePath , fsManager . readFile ( basePath + ( name == null ? Constants . get ( ConstantKey . MEDIA_CONTENT_FILENAME ) : name ) ) ) ; } public Map . Entry < String , InputStream > readEntity ( final String entitySetName , final String entityId , final Accept accept ) { if ( accept == Accept . XML || accept == Accept . TEXT ) { throw new UnsupportedMediaTypeException ( ""Unsupported media type"" ) ; } final String basePath = Commons . getEntityBasePath ( entitySetName , entityId ) ; return new SimpleEntry < String , InputStream > ( basePath , fsManager . readFile ( basePath + Constants . get ( ConstantKey . ENTITY ) , accept ) ) ; } public InputStream expandEntity ( final String entitySetName , final String entityId , final String linkName ) throws Exception { final Map . Entry < String , List < String > > links = extractLinkURIs ( entitySetName , entityId , linkName ) ; final Map < String , NavigationProperty > navigationProperties = metadata . getNavigationProperties ( entitySetName ) ; return readEntities ( links . getValue ( ) , linkName , links . getKey ( ) , navigationProperties . get ( linkName ) . isEntitySet ( ) ) ; } public InputStream expandEntity ( final String entitySetName , final String entityId , final InputStream entity , final String linkName ) throws Exception { return replaceLink ( entity , linkName , expandEntity ( entitySetName , entityId , linkName ) ) ; } public InputStream deleteProperty ( final String entitySetName , final String entityId , final List < String > path , final Accept accept ) throws Exception { final String basePath = Commons . getEntityBasePath ( entitySetName , entityId ) ; final Accept acceptType = accept == null || Accept . TEXT == accept ? Accept . XML : accept . getExtension ( ) . equals ( Accept . JSON . getExtension ( ) ) ? Accept . JSON_FULLMETA : accept ; InputStream stream = fsManager . readFile ( basePath + Constants . get ( ConstantKey . ENTITY ) , acceptType ) ; stream = deleteProperty ( stream , path ) ; fsManager . putInMemory ( stream , fsManager . getAbsolutePath ( basePath + Constants . get ( ConstantKey . ENTITY ) , acceptType ) ) ; return fsManager . readFile ( basePath + Constants . get ( ConstantKey . ENTITY ) , acceptType ) ; } public abstract InputStream readEntities ( final List < String > links , final String linkName , final String next , final boolean forceFeed ) throws Exception ; protected abstract InputStream replaceLink ( final InputStream toBeChanged , final String linkName , final InputStream replacement ) throws Exception ; public abstract InputStream selectEntity ( final InputStream entity , final String [ ] propertyNames ) throws Exception ; protected abstract Accept getDefaultFormat ( ) ; protected abstract Map < String , InputStream > getChanges ( final InputStream src ) throws Exception ; public abstract InputStream addEditLink ( final InputStream content , final String title , final String href ) throws Exception ; public abstract InputStream addOperation ( final InputStream content , final String name , final String metaAnchor , final String href ) throws Exception ; protected abstract InputStream replaceProperty ( final InputStream src , final InputStream replacement , final List < String > path , final boolean justValue ) throws Exception ; protected abstract InputStream deleteProperty ( final InputStream src , final List < String > path ) throws Exception ; public abstract Map . Entry < String , List < String > > extractLinkURIs ( final InputStream is ) throws Exception ; public abstract Map . Entry < String , List < String > > extractLinkURIs ( final String entitySetName , final String entityId , final String linkName ) throws Exception ; }",Smelly
"public final class ZipTestCase extends AbstractTestCase { @ Test public void testZipArchiveCreation ( ) throws Exception { final File output = new File ( dir , ""bla.zip"" ) ; final File file1 = getFile ( ""test1.xml"" ) ; final File file2 = getFile ( ""test2.xml"" ) ; final OutputStream out = new FileOutputStream ( output ) ; ArchiveOutputStream os = null ; try { os = new ArchiveStreamFactory ( ) . createArchiveOutputStream ( ""zip"" , out ) ; os . putArchiveEntry ( new ZipArchiveEntry ( ""testdata/test1.xml"" ) ) ; IOUtils . copy ( new FileInputStream ( file1 ) , os ) ; os . closeArchiveEntry ( ) ; os . putArchiveEntry ( new ZipArchiveEntry ( ""testdata/test2.xml"" ) ) ; IOUtils . copy ( new FileInputStream ( file2 ) , os ) ; os . closeArchiveEntry ( ) ; } finally { if ( os != null ) { os . close ( ) ; } } out . close ( ) ; final List < File > results = new ArrayList < > ( ) ; final InputStream is = new FileInputStream ( output ) ; ArchiveInputStream in = null ; try { in = new ArchiveStreamFactory ( ) . createArchiveInputStream ( ""zip"" , is ) ; ZipArchiveEntry entry = null ; while ( ( entry = ( ZipArchiveEntry ) in . getNextEntry ( ) ) != null ) { final File outfile = new File ( resultDir . getCanonicalPath ( ) + ""/result/"" + entry . getName ( ) ) ; outfile . getParentFile ( ) . mkdirs ( ) ; try ( OutputStream o = new FileOutputStream ( outfile ) ) { IOUtils . copy ( in , o ) ; } results . add ( outfile ) ; } } finally { if ( in != null ) { in . close ( ) ; } } is . close ( ) ; assertEquals ( results . size ( ) , 2 ) ; File result = results . get ( 0 ) ; assertEquals ( file1 . length ( ) , result . length ( ) ) ; result = results . get ( 1 ) ; assertEquals ( file2 . length ( ) , result . length ( ) ) ; } @ Test public void testZipArchiveCreationInMemory ( ) throws Exception { final File file1 = getFile ( ""test1.xml"" ) ; final File file2 = getFile ( ""test2.xml"" ) ; final byte [ ] file1Contents = new byte [ ( int ) file1 . length ( ) ] ; final byte [ ] file2Contents = new byte [ ( int ) file2 . length ( ) ] ; IOUtils . readFully ( new FileInputStream ( file1 ) , file1Contents ) ; IOUtils . readFully ( new FileInputStream ( file2 ) , file2Contents ) ; SeekableInMemoryByteChannel channel = new SeekableInMemoryByteChannel ( ) ; try ( ZipArchiveOutputStream os = new ZipArchiveOutputStream ( channel ) ) { os . putArchiveEntry ( new ZipArchiveEntry ( ""testdata/test1.xml"" ) ) ; os . write ( file1Contents ) ; os . closeArchiveEntry ( ) ; os . putArchiveEntry ( new ZipArchiveEntry ( ""testdata/test2.xml"" ) ) ; os . write ( file2Contents ) ; os . closeArchiveEntry ( ) ; } final List < byte [ ] > results = new ArrayList < > ( ) ; try ( ArchiveInputStream in = new ArchiveStreamFactory ( ) . createArchiveInputStream ( ""zip"" , new ByteArrayInputStream ( channel . array ( ) ) ) ) { ZipArchiveEntry entry ; while ( ( entry = ( ZipArchiveEntry ) in . getNextEntry ( ) ) != null ) { byte [ ] result = new byte [ ( int ) entry . getSize ( ) ] ; IOUtils . readFully ( in , result ) ; results . add ( result ) ; } } assertArrayEquals ( results . get ( 0 ) , file1Contents ) ; assertArrayEquals ( results . get ( 1 ) , file2Contents ) ; } @ Test public void testZipUnarchive ( ) throws Exception { final File input = getFile ( ""bla.zip"" ) ; try ( final InputStream is = new FileInputStream ( input ) ; final ArchiveInputStream in = new ArchiveStreamFactory ( ) . createArchiveInputStream ( ""zip"" , is ) ) { final ZipArchiveEntry entry = ( ZipArchiveEntry ) in . getNextEntry ( ) ; try ( final OutputStream out = new FileOutputStream ( new File ( dir , entry . getName ( ) ) ) ) { IOUtils . copy ( in , out ) ; } } } @ Test public void testSkipsPK00Prefix ( ) throws Exception { final File input = getFile ( ""COMPRESS-208.zip"" ) ; final ArrayList < String > al = new ArrayList < > ( ) ; al . add ( ""test1.xml"" ) ; al . add ( ""test2.xml"" ) ; try ( InputStream is = new FileInputStream ( input ) ) { checkArchiveContent ( new ZipArchiveInputStream ( is ) , al ) ; } } @ Test public void testTokenizationCompressionMethod ( ) throws IOException { final ZipFile moby = new ZipFile ( getFile ( ""moby.zip"" ) ) ; final ZipArchiveEntry entry = moby . getEntry ( ""README"" ) ; assertEquals ( ""method"" , ZipMethod . TOKENIZATION . getCode ( ) , entry . getMethod ( ) ) ; assertFalse ( moby . canReadEntryData ( entry ) ) ; moby . close ( ) ; } @ Test public void testSkipEntryWithUnsupportedCompressionMethod ( ) throws IOException { try ( ZipArchiveInputStream zip = new ZipArchiveInputStream ( new FileInputStream ( getFile ( ""moby.zip"" ) ) ) ) { final ZipArchiveEntry entry = zip . getNextZipEntry ( ) ; assertEquals ( ""method"" , ZipMethod . TOKENIZATION . getCode ( ) , entry . getMethod ( ) ) ; assertEquals ( ""README"" , entry . getName ( ) ) ; assertFalse ( zip . canReadEntryData ( entry ) ) ; try { assertNull ( zip . getNextZipEntry ( ) ) ; } catch ( final IOException e ) { e . printStackTrace ( ) ; fail ( ""COMPRESS-93: Unable to skip an unsupported zip entry"" ) ; } } } @ Test public void testListAllFilesWithNestedArchive ( ) throws Exception { final File input = getFile ( ""OSX_ArchiveWithNestedArchive.zip"" ) ; final List < String > results = new ArrayList < > ( ) ; final List < ZipException > expectedExceptions = new ArrayList < > ( ) ; final InputStream is = new FileInputStream ( input ) ; ArchiveInputStream in = null ; try { in = new ArchiveStreamFactory ( ) . createArchiveInputStream ( ""zip"" , is ) ; ZipArchiveEntry entry = null ; while ( ( entry = ( ZipArchiveEntry ) in . getNextEntry ( ) ) != null ) { results . add ( entry . getName ( ) ) ; final ArchiveInputStream nestedIn = new ArchiveStreamFactory ( ) . createArchiveInputStream ( ""zip"" , in ) ; try { ZipArchiveEntry nestedEntry = null ; while ( ( nestedEntry = ( ZipArchiveEntry ) nestedIn . getNextEntry ( ) ) != null ) { results . add ( nestedEntry . getName ( ) ) ; } } catch ( ZipException ex ) { expectedExceptions . add ( ex ) ; } } } finally { if ( in != null ) { in . close ( ) ; } } is . close ( ) ; assertTrue ( results . contains ( ""NestedArchiv.zip"" ) ) ; assertTrue ( results . contains ( ""test1.xml"" ) ) ; assertTrue ( results . contains ( ""test2.xml"" ) ) ; assertTrue ( results . contains ( ""test3.xml"" ) ) ; assertEquals ( 1 , expectedExceptions . size ( ) ) ; } @ Test public void testDirectoryEntryFromFile ( ) throws Exception { final File [ ] tmp = createTempDirAndFile ( ) ; File archive = null ; ZipArchiveOutputStream zos = null ; ZipFile zf = null ; try { archive = File . createTempFile ( ""test."" , "".zip"" , tmp [ 0 ] ) ; archive . deleteOnExit ( ) ; zos = new ZipArchiveOutputStream ( archive ) ; final long beforeArchiveWrite = tmp [ 0 ] . lastModified ( ) ; final ZipArchiveEntry in = new ZipArchiveEntry ( tmp [ 0 ] , ""foo"" ) ; zos . putArchiveEntry ( in ) ; zos . closeArchiveEntry ( ) ; zos . close ( ) ; zos = null ; zf = new ZipFile ( archive ) ; final ZipArchiveEntry out = zf . getEntry ( ""foo/"" ) ; assertNotNull ( out ) ; assertEquals ( ""foo/"" , out . getName ( ) ) ; assertEquals ( 0 , out . getSize ( ) ) ; assertEquals ( beforeArchiveWrite / 2000 , out . getLastModifiedDate ( ) . getTime ( ) / 2000 ) ; assertTrue ( out . isDirectory ( ) ) ; } finally { ZipFile . closeQuietly ( zf ) ; if ( zos != null ) { zos . close ( ) ; } tryHardToDelete ( archive ) ; tryHardToDelete ( tmp [ 1 ] ) ; rmdir ( tmp [ 0 ] ) ; } } @ Test public void testExplicitDirectoryEntry ( ) throws Exception { final File [ ] tmp = createTempDirAndFile ( ) ; File archive = null ; ZipArchiveOutputStream zos = null ; ZipFile zf = null ; try { archive = File . createTempFile ( ""test."" , "".zip"" , tmp [ 0 ] ) ; archive . deleteOnExit ( ) ; zos = new ZipArchiveOutputStream ( archive ) ; final long beforeArchiveWrite = tmp [ 0 ] . lastModified ( ) ; final ZipArchiveEntry in = new ZipArchiveEntry ( ""foo/"" ) ; in . setTime ( beforeArchiveWrite ) ; zos . putArchiveEntry ( in ) ; zos . closeArchiveEntry ( ) ; zos . close ( ) ; zos = null ; zf = new ZipFile ( archive ) ; final ZipArchiveEntry out = zf . getEntry ( ""foo/"" ) ; assertNotNull ( out ) ; assertEquals ( ""foo/"" , out . getName ( ) ) ; assertEquals ( 0 , out . getSize ( ) ) ; assertEquals ( beforeArchiveWrite / 2000 , out . getLastModifiedDate ( ) . getTime ( ) / 2000 ) ; assertTrue ( out . isDirectory ( ) ) ; } finally { ZipFile . closeQuietly ( zf ) ; if ( zos != null ) { zos . close ( ) ; } tryHardToDelete ( archive ) ; tryHardToDelete ( tmp [ 1 ] ) ; rmdir ( tmp [ 0 ] ) ; } } String first_payload = ""ABBA"" ; String second_payload = ""AAAAAAAAAAAA"" ; ZipArchiveEntryPredicate allFilesPredicate = new ZipArchiveEntryPredicate ( ) { @ Override public boolean test ( final ZipArchiveEntry zipArchiveEntry ) { return true ; } } ; @ Test public void testCopyRawEntriesFromFile ( ) throws IOException { final File [ ] tmp = createTempDirAndFile ( ) ; final File reference = createReferenceFile ( tmp [ 0 ] , Zip64Mode . Never , ""expected."" ) ; final File a1 = File . createTempFile ( ""src1."" , "".zip"" , tmp [ 0 ] ) ; try ( final ZipArchiveOutputStream zos = new ZipArchiveOutputStream ( a1 ) ) { zos . setUseZip64 ( Zip64Mode . Never ) ; createFirstEntry ( zos ) . close ( ) ; } final File a2 = File . createTempFile ( ""src2."" , "".zip"" , tmp [ 0 ] ) ; try ( final ZipArchiveOutputStream zos1 = new ZipArchiveOutputStream ( a2 ) ) { zos1 . setUseZip64 ( Zip64Mode . Never ) ; createSecondEntry ( zos1 ) . close ( ) ; } try ( final ZipFile zf1 = new ZipFile ( a1 ) ; final ZipFile zf2 = new ZipFile ( a2 ) ) { final File fileResult = File . createTempFile ( ""file-actual."" , "".zip"" , tmp [ 0 ] ) ; try ( final ZipArchiveOutputStream zos2 = new ZipArchiveOutputStream ( fileResult ) ) { zf1 . copyRawEntries ( zos2 , allFilesPredicate ) ; zf2 . copyRawEntries ( zos2 , allFilesPredicate ) ; } assertSameFileContents ( reference , fileResult ) ; } } @ Test public void testCopyRawZip64EntryFromFile ( ) throws IOException { final File [ ] tmp = createTempDirAndFile ( ) ; final File reference = File . createTempFile ( ""z64reference."" , "".zip"" , tmp [ 0 ] ) ; try ( final ZipArchiveOutputStream zos1 = new ZipArchiveOutputStream ( reference ) ) { zos1 . setUseZip64 ( Zip64Mode . Always ) ; createFirstEntry ( zos1 ) ; } final File a1 = File . createTempFile ( ""zip64src."" , "".zip"" , tmp [ 0 ] ) ; try ( final ZipArchiveOutputStream zos = new ZipArchiveOutputStream ( a1 ) ) { zos . setUseZip64 ( Zip64Mode . Always ) ; createFirstEntry ( zos ) . close ( ) ; } final File fileResult = File . createTempFile ( ""file-actual."" , "".zip"" , tmp [ 0 ] ) ; try ( final ZipFile zf1 = new ZipFile ( a1 ) ) { try ( final ZipArchiveOutputStream zos2 = new ZipArchiveOutputStream ( fileResult ) ) { zos2 . setUseZip64 ( Zip64Mode . Always ) ; zf1 . copyRawEntries ( zos2 , allFilesPredicate ) ; } assertSameFileContents ( reference , fileResult ) ; } } @ Test public void testUnixModeInAddRaw ( ) throws IOException { final File [ ] tmp = createTempDirAndFile ( ) ; final File a1 = File . createTempFile ( ""unixModeBits."" , "".zip"" , tmp [ 0 ] ) ; try ( final ZipArchiveOutputStream zos = new ZipArchiveOutputStream ( a1 ) ) { final ZipArchiveEntry archiveEntry = new ZipArchiveEntry ( ""fred"" ) ; archiveEntry . setUnixMode ( 0664 ) ; archiveEntry . setMethod ( ZipEntry . DEFLATED ) ; zos . addRawArchiveEntry ( archiveEntry , new ByteArrayInputStream ( ""fud"" . getBytes ( ) ) ) ; } try ( final ZipFile zf1 = new ZipFile ( a1 ) ) { final ZipArchiveEntry fred = zf1 . getEntry ( ""fred"" ) ; assertEquals ( 0664 , fred . getUnixMode ( ) ) ; } } private File createReferenceFile ( final File directory , final Zip64Mode zipMode , final String prefix ) throws IOException { final File reference = File . createTempFile ( prefix , "".zip"" , directory ) ; try ( final ZipArchiveOutputStream zos = new ZipArchiveOutputStream ( reference ) ) { zos . setUseZip64 ( zipMode ) ; createFirstEntry ( zos ) ; createSecondEntry ( zos ) ; } return reference ; } private ZipArchiveOutputStream createFirstEntry ( final ZipArchiveOutputStream zos ) throws IOException { createArchiveEntry ( first_payload , zos , ""file1.txt"" ) ; return zos ; } private ZipArchiveOutputStream createSecondEntry ( final ZipArchiveOutputStream zos ) throws IOException { createArchiveEntry ( second_payload , zos , ""file2.txt"" ) ; return zos ; } private void assertSameFileContents ( final File expectedFile , final File actualFile ) throws IOException { final int size = ( int ) Math . max ( expectedFile . length ( ) , actualFile . length ( ) ) ; try ( final ZipFile expected = new ZipFile ( expectedFile ) ; final ZipFile actual = new ZipFile ( actualFile ) ) { final byte [ ] expectedBuf = new byte [ size ] ; final byte [ ] actualBuf = new byte [ size ] ; final Enumeration < ZipArchiveEntry > actualInOrder = actual . getEntriesInPhysicalOrder ( ) ; final Enumeration < ZipArchiveEntry > expectedInOrder = expected . getEntriesInPhysicalOrder ( ) ; while ( actualInOrder . hasMoreElements ( ) ) { final ZipArchiveEntry actualElement = actualInOrder . nextElement ( ) ; final ZipArchiveEntry expectedElement = expectedInOrder . nextElement ( ) ; assertEquals ( expectedElement . getName ( ) , actualElement . getName ( ) ) ; assertEquals ( expectedElement . getMethod ( ) , actualElement . getMethod ( ) ) ; assertEquals ( expectedElement . getGeneralPurposeBit ( ) , actualElement . getGeneralPurposeBit ( ) ) ; assertEquals ( expectedElement . getCrc ( ) , actualElement . getCrc ( ) ) ; assertEquals ( expectedElement . getCompressedSize ( ) , actualElement . getCompressedSize ( ) ) ; assertEquals ( expectedElement . getSize ( ) , actualElement . getSize ( ) ) ; assertEquals ( expectedElement . getExternalAttributes ( ) , actualElement . getExternalAttributes ( ) ) ; assertEquals ( expectedElement . getInternalAttributes ( ) , actualElement . getInternalAttributes ( ) ) ; final InputStream actualIs = actual . getInputStream ( actualElement ) ; final InputStream expectedIs = expected . getInputStream ( expectedElement ) ; IOUtils . readFully ( expectedIs , expectedBuf ) ; IOUtils . readFully ( actualIs , actualBuf ) ; expectedIs . close ( ) ; actualIs . close ( ) ; Assert . assertArrayEquals ( expectedBuf , actualBuf ) ; } } } private void createArchiveEntry ( final String payload , final ZipArchiveOutputStream zos , final String name ) throws IOException { final ZipArchiveEntry in = new ZipArchiveEntry ( name ) ; zos . putArchiveEntry ( in ) ; zos . write ( payload . getBytes ( ) ) ; zos . closeArchiveEntry ( ) ; } @ Test public void testFileEntryFromFile ( ) throws Exception { final File [ ] tmp = createTempDirAndFile ( ) ; File archive = null ; ZipArchiveOutputStream zos = null ; ZipFile zf = null ; FileInputStream fis = null ; try { archive = File . createTempFile ( ""test."" , "".zip"" , tmp [ 0 ] ) ; archive . deleteOnExit ( ) ; zos = new ZipArchiveOutputStream ( archive ) ; final ZipArchiveEntry in = new ZipArchiveEntry ( tmp [ 1 ] , ""foo"" ) ; zos . putArchiveEntry ( in ) ; final byte [ ] b = new byte [ ( int ) tmp [ 1 ] . length ( ) ] ; fis = new FileInputStream ( tmp [ 1 ] ) ; while ( fis . read ( b ) > 0 ) { zos . write ( b ) ; } fis . close ( ) ; fis = null ; zos . closeArchiveEntry ( ) ; zos . close ( ) ; zos = null ; zf = new ZipFile ( archive ) ; final ZipArchiveEntry out = zf . getEntry ( ""foo"" ) ; assertNotNull ( out ) ; assertEquals ( ""foo"" , out . getName ( ) ) ; assertEquals ( tmp [ 1 ] . length ( ) , out . getSize ( ) ) ; assertEquals ( tmp [ 1 ] . lastModified ( ) / 2000 , out . getLastModifiedDate ( ) . getTime ( ) / 2000 ) ; assertFalse ( out . isDirectory ( ) ) ; } finally { ZipFile . closeQuietly ( zf ) ; if ( zos != null ) { zos . close ( ) ; } tryHardToDelete ( archive ) ; if ( fis != null ) { fis . close ( ) ; } tryHardToDelete ( tmp [ 1 ] ) ; rmdir ( tmp [ 0 ] ) ; } } @ Test public void testExplicitFileEntry ( ) throws Exception { final File [ ] tmp = createTempDirAndFile ( ) ; File archive = null ; ZipArchiveOutputStream zos = null ; ZipFile zf = null ; FileInputStream fis = null ; try { archive = File . createTempFile ( ""test."" , "".zip"" , tmp [ 0 ] ) ; archive . deleteOnExit ( ) ; zos = new ZipArchiveOutputStream ( archive ) ; final ZipArchiveEntry in = new ZipArchiveEntry ( ""foo"" ) ; in . setTime ( tmp [ 1 ] . lastModified ( ) ) ; in . setSize ( tmp [ 1 ] . length ( ) ) ; zos . putArchiveEntry ( in ) ; final byte [ ] b = new byte [ ( int ) tmp [ 1 ] . length ( ) ] ; fis = new FileInputStream ( tmp [ 1 ] ) ; while ( fis . read ( b ) > 0 ) { zos . write ( b ) ; } fis . close ( ) ; fis = null ; zos . closeArchiveEntry ( ) ; zos . close ( ) ; zos = null ; zf = new ZipFile ( archive ) ; final ZipArchiveEntry out = zf . getEntry ( ""foo"" ) ; assertNotNull ( out ) ; assertEquals ( ""foo"" , out . getName ( ) ) ; assertEquals ( tmp [ 1 ] . length ( ) , out . getSize ( ) ) ; assertEquals ( tmp [ 1 ] . lastModified ( ) / 2000 , out . getLastModifiedDate ( ) . getTime ( ) / 2000 ) ; assertFalse ( out . isDirectory ( ) ) ; } finally { ZipFile . closeQuietly ( zf ) ; if ( zos != null ) { zos . close ( ) ; } tryHardToDelete ( archive ) ; if ( fis != null ) { fis . close ( ) ; } tryHardToDelete ( tmp [ 1 ] ) ; rmdir ( tmp [ 0 ] ) ; } } @ Test public void inputStreamStatisticsOfZipBombExcel ( ) throws IOException , ArchiveException { Map < String , List < Long > > expected = new HashMap < String , List < Long > > ( ) { { put ( ""[Content_Types].xml"" , Arrays . asList ( 8390036L , 8600L ) ) ; put ( ""xl/worksheets/sheet1.xml"" , Arrays . asList ( 1348L , 508L ) ) ; } } ; testInputStreamStatistics ( ""zipbomb.xlsx"" , expected ) ; } @ Test public void inputStreamStatisticsForImplodedEntry ( ) throws IOException , ArchiveException { Map < String , List < Long > > expected = new HashMap < String , List < Long > > ( ) { { put ( ""LICENSE.TXT"" , Arrays . asList ( 11560L , 4131L ) ) ; } } ; testInputStreamStatistics ( ""imploding-8Kdict-3trees.zip"" , expected ) ; } @ Test public void inputStreamStatisticsForShrunkEntry ( ) throws IOException , ArchiveException { Map < String , List < Long > > expected = new HashMap < String , List < Long > > ( ) { { put ( ""TEST1.XML"" , Arrays . asList ( 76L , 66L ) ) ; put ( ""TEST2.XML"" , Arrays . asList ( 81L , 76L ) ) ; } } ; testInputStreamStatistics ( ""SHRUNK.ZIP"" , expected ) ; } @ Test public void inputStreamStatisticsForStoredEntry ( ) throws IOException , ArchiveException { Map < String , List < Long > > expected = new HashMap < String , List < Long > > ( ) { { put ( ""test.txt"" , Arrays . asList ( 5L , 5L ) ) ; } } ; testInputStreamStatistics ( ""COMPRESS-264.zip"" , expected ) ; } @ Test public void inputStreamStatisticsForBzip2Entry ( ) throws IOException , ArchiveException { Map < String , List < Long > > expected = new HashMap < String , List < Long > > ( ) { { put ( ""lots-of-as"" , Arrays . asList ( 42L , 39L ) ) ; } } ; testInputStreamStatistics ( ""bzip2-zip.zip"" , expected ) ; } @ Test public void inputStreamStatisticsForDeflate64Entry ( ) throws IOException , ArchiveException { Map < String , List < Long > > expected = new HashMap < String , List < Long > > ( ) { { put ( ""input2"" , Arrays . asList ( 3072L , 2111L ) ) ; } } ; testInputStreamStatistics ( ""COMPRESS-380/COMPRESS-380.zip"" , expected ) ; } private void testInputStreamStatistics ( String fileName , Map < String , List < Long > > expectedStatistics ) throws IOException , ArchiveException { final File input = getFile ( fileName ) ; final Map < String , List < List < Long > > > actualStatistics = new HashMap < > ( ) ; try ( final FileInputStream fis = new FileInputStream ( input ) ; final ArchiveInputStream in = new ArchiveStreamFactory ( ) . createArchiveInputStream ( ""zip"" , fis ) ) { for ( ArchiveEntry entry ; ( entry = in . getNextEntry ( ) ) != null ; ) { readStream ( in , entry , actualStatistics ) ; } } try ( final ZipFile zf = new ZipFile ( input ) ) { final Enumeration < ZipArchiveEntry > entries = zf . getEntries ( ) ; while ( entries . hasMoreElements ( ) ) { final ZipArchiveEntry zae = entries . nextElement ( ) ; try ( InputStream in = zf . getInputStream ( zae ) ) { readStream ( in , zae , actualStatistics ) ; } } } for ( Map . Entry < String , List < List < Long > > > me : actualStatistics . entrySet ( ) ) { assertEquals ( ""Mismatch of stats for: "" + me . getKey ( ) , me . getValue ( ) . get ( 0 ) , me . getValue ( ) . get ( 1 ) ) ; } for ( Map . Entry < String , List < Long > > me : expectedStatistics . entrySet ( ) ) { assertEquals ( ""Mismatch of stats with expected value for: "" + me . getKey ( ) , me . getValue ( ) , actualStatistics . get ( me . getKey ( ) ) . get ( 0 ) ) ; } } private void readStream ( final InputStream in , final ArchiveEntry entry , final Map < String , List < List < Long > > > map ) throws IOException { final byte [ ] buf = new byte [ 4096 ] ; final InputStreamStatistics stats = ( InputStreamStatistics ) in ; while ( in . read ( buf ) != - 1 ) ; final String name = entry . getName ( ) ; final List < List < Long > > l ; if ( map . containsKey ( name ) ) { l = map . get ( name ) ; } else { map . put ( name , l = new ArrayList < > ( ) ) ; } final long t = stats . getUncompressedCount ( ) ; final long b = stats . getCompressedCount ( ) ; l . add ( Arrays . asList ( t , b ) ) ; } }",Smelly
"public abstract class AbstractCompressedWholeFileQuadInputFormatTests extends AbstractNodeTupleInputFormatTests < Quad , QuadWritable > { private static final Charset utf8 = Charset . forName ( ""utf-8"" ) ; @ Override protected Configuration prepareConfiguration ( ) { Configuration config = super . prepareConfiguration ( ) ; config . set ( HadoopIOConstants . IO_COMPRESSION_CODECS , this . getCompressionCodec ( ) . getClass ( ) . getCanonicalName ( ) ) ; return config ; } @ Override protected OutputStream getOutputStream ( File f ) throws IOException { CompressionCodec codec = this . getCompressionCodec ( ) ; if ( codec instanceof Configurable ) { ( ( Configurable ) codec ) . setConf ( this . prepareConfiguration ( ) ) ; } FileOutputStream fileOutput = new FileOutputStream ( f , false ) ; return codec . createOutputStream ( fileOutput ) ; } protected abstract CompressionCodec getCompressionCodec ( ) ; @ Override protected boolean canSplitInputs ( ) { return false ; } private void writeTuples ( Dataset ds , OutputStream output ) { RDFDataMgr . write ( output , ds , RDFWriterRegistry . defaultSerialization ( this . getRdfLanguage ( ) ) ) ; } protected abstract Lang getRdfLanguage ( ) ; private void writeGoodTuples ( OutputStream output , int num ) { Dataset ds = DatasetFactory . createGeneral ( ) ; Model m = ModelFactory . createDefaultModel ( ) ; Resource currSubj = m . createResource ( ""http://example.org/subjects/0"" ) ; Property predicate = m . createProperty ( ""http://example.org/predicate"" ) ; for ( int i = 0 ; i < num ; i ++ ) { if ( i % 100 == 0 ) { ds . addNamedModel ( ""http://example.org/graphs/"" + ( i / 100 ) , m ) ; m = ModelFactory . createDefaultModel ( ) ; } if ( i % 10 == 0 ) { currSubj = m . createResource ( ""http://example.org/subjects/"" + ( i / 10 ) ) ; } m . add ( currSubj , predicate , m . createTypedLiteral ( i ) ) ; } if ( ! m . isEmpty ( ) ) { ds . addNamedModel ( ""http://example.org/graphs/extra"" , m ) ; } this . writeTuples ( ds , output ) ; } @ Override protected final void generateTuples ( OutputStream output , int num ) throws IOException { this . writeGoodTuples ( output , num ) ; output . close ( ) ; } @ Override protected final void generateMixedTuples ( OutputStream output , int num ) throws IOException { this . writeGoodTuples ( output , num / 2 ) ; byte [ ] junk = ""junk data\n"" . getBytes ( utf8 ) ; for ( int i = 0 ; i < num / 2 ; i ++ ) { output . write ( junk ) ; } output . flush ( ) ; output . close ( ) ; } @ Override protected final void generateBadTuples ( OutputStream output , int num ) throws IOException { byte [ ] junk = ""junk data\n"" . getBytes ( utf8 ) ; for ( int i = 0 ; i < num ; i ++ ) { output . write ( junk ) ; } output . flush ( ) ; output . close ( ) ; } }",No
"public class JAXRSOutInterceptor extends AbstractOutDatabindingInterceptor { private static final Logger LOG = LogUtils . getL7dLogger ( JAXRSOutInterceptor . class ) ; private static final ResourceBundle BUNDLE = BundleUtils . getBundle ( JAXRSOutInterceptor . class ) ; public JAXRSOutInterceptor ( ) { super ( Phase . MARSHAL ) ; } public void handleMessage ( Message message ) { ProviderFactory providerFactory = ProviderFactory . getInstance ( message ) ; try { processResponse ( providerFactory , message ) ; } finally { Object rootInstance = message . getExchange ( ) . remove ( JAXRSUtils . ROOT_INSTANCE ) ; Object rootProvider = message . getExchange ( ) . remove ( JAXRSUtils . ROOT_PROVIDER ) ; if ( rootInstance != null && rootProvider != null ) { try { ( ( ResourceProvider ) rootProvider ) . releaseInstance ( message , rootInstance ) ; } catch ( Throwable tex ) { LOG . warning ( ""Exception occurred during releasing the service instance, "" + tex . getMessage ( ) ) ; } } providerFactory . clearThreadLocalProxies ( ) ; ClassResourceInfo cri = ( ClassResourceInfo ) message . getExchange ( ) . get ( JAXRSUtils . ROOT_RESOURCE_CLASS ) ; if ( cri != null ) { cri . clearThreadLocalProxies ( ) ; } } } private void processResponse ( ProviderFactory providerFactory , Message message ) { if ( isResponseAlreadyHandled ( message ) ) { return ; } message . put ( Message . REST_MESSAGE , Boolean . TRUE ) ; MessageContentsList objs = MessageContentsList . getContentsList ( message ) ; if ( objs == null || objs . size ( ) == 0 ) { return ; } Object responseObj = objs . get ( 0 ) ; Response response = null ; if ( responseObj instanceof Response ) { response = ( Response ) responseObj ; } else { int status = getStatus ( message , responseObj != null ? 200 : 204 ) ; response = Response . status ( status ) . entity ( responseObj ) . build ( ) ; } Exchange exchange = message . getExchange ( ) ; OperationResourceInfo ori = ( OperationResourceInfo ) exchange . get ( OperationResourceInfo . class . getName ( ) ) ; JAXRSUtils . runContainerResponseFilters ( providerFactory , response , message , ori ) ; Response updatedResponse = message . get ( Response . class ) ; if ( updatedResponse != null ) { response = updatedResponse ; } List < ProviderInfo < ResponseHandler > > handlers = ProviderFactory . getInstance ( message ) . getResponseHandlers ( ) ; for ( ProviderInfo < ResponseHandler > rh : handlers ) { InjectionUtils . injectContexts ( rh . getProvider ( ) , rh , message . getExchange ( ) . getInMessage ( ) ) ; Response r = rh . getProvider ( ) . handleResponse ( message , ori , response ) ; if ( r != null ) { response = r ; } } serializeMessage ( message , response , ori , true ) ; } private int getStatus ( Message message , int defaultValue ) { Object customStatus = message . getExchange ( ) . get ( Message . RESPONSE_CODE ) ; return customStatus == null ? defaultValue : ( Integer ) customStatus ; } @ SuppressWarnings ( ""unchecked"" ) private void serializeMessage ( Message message , Response response , OperationResourceInfo ori , boolean firstTry ) { final Exchange exchange = message . getExchange ( ) ; int status = response . getStatus ( ) ; Object responseObj = response . getEntity ( ) ; if ( status == 200 && ! isResponseNull ( responseObj ) && firstTry && ori != null && JAXRSUtils . headMethodPossible ( ori . getHttpMethod ( ) , ( String ) exchange . getInMessage ( ) . get ( Message . HTTP_REQUEST_METHOD ) ) ) { LOG . info ( new org . apache . cxf . common . i18n . Message ( ""HEAD_WITHOUT_ENTITY"" , BUNDLE ) . toString ( ) ) ; responseObj = null ; } if ( status == - 1 ) { status = isResponseNull ( responseObj ) ? 204 : 200 ; } setResponseStatus ( message , status ) ; Map < String , List < Object > > theHeaders = ( Map < String , List < Object > > ) message . get ( Message . PROTOCOL_HEADERS ) ; if ( firstTry && theHeaders != null ) { theHeaders . putAll ( response . getMetadata ( ) ) ; } else { theHeaders = response . getMetadata ( ) ; } MultivaluedMap < String , Object > responseHeaders ; if ( ! ( theHeaders instanceof MultivaluedMap ) ) { responseHeaders = new MetadataMap < String , Object > ( theHeaders ) ; } else { responseHeaders = ( MultivaluedMap < String , Object > ) theHeaders ; } message . put ( Message . PROTOCOL_HEADERS , responseHeaders ) ; setResponseDate ( responseHeaders , firstTry ) ; if ( isResponseNull ( responseObj ) ) { responseHeaders . putSingle ( ""Content-Length"" , ""0"" ) ; return ; } Object ignoreWritersProp = exchange . get ( JAXRSUtils . IGNORE_MESSAGE_WRITERS ) ; boolean ignoreWriters = ignoreWritersProp == null ? false : Boolean . valueOf ( ignoreWritersProp . toString ( ) ) ; if ( ignoreWriters ) { writeResponseToStream ( message . getContent ( OutputStream . class ) , responseObj ) ; return ; } List < MediaType > availableContentTypes = computeAvailableContentTypes ( message , response ) ; Method invoked = null ; if ( firstTry ) { invoked = ori == null ? null : ori . getAnnotatedMethod ( ) == null ? ori . getMethodToInvoke ( ) : ori . getAnnotatedMethod ( ) ; } boolean asyncResponse = exchange . get ( AsyncResponse . class ) != null ; Class < ? > targetType = getRawResponseClass ( invoked , responseObj , asyncResponse ) ; Type genericType = getGenericResponseType ( invoked , responseObj , targetType , asyncResponse ) ; if ( genericType instanceof TypeVariable ) { genericType = InjectionUtils . getSuperType ( ori . getClassResourceInfo ( ) . getServiceClass ( ) , ( TypeVariable < ? > ) genericType ) ; } Annotation [ ] annotations = invoked != null ? invoked . getAnnotations ( ) : new Annotation [ ] { } ; List < WriterInterceptor > writers = null ; MediaType responseType = null ; for ( MediaType type : availableContentTypes ) { writers = ProviderFactory . getInstance ( message ) . createMessageBodyWriterInterceptor ( targetType , genericType , annotations , type , message ) ; if ( writers != null ) { responseType = type ; break ; } } OutputStream outOriginal = message . getContent ( OutputStream . class ) ; if ( writers == null ) { message . put ( Message . CONTENT_TYPE , ""text/plain"" ) ; message . put ( Message . RESPONSE_CODE , 500 ) ; writeResponseErrorMessage ( outOriginal , ""NO_MSG_WRITER"" , targetType . getSimpleName ( ) ) ; return ; } boolean enabled = checkBufferingMode ( message , writers , firstTry ) ; Object entity = getEntity ( responseObj ) ; try { responseType = checkFinalContentType ( responseType ) ; if ( LOG . isLoggable ( Level . FINE ) ) { LOG . fine ( ""Response content type is: "" + responseType . toString ( ) ) ; } message . put ( Message . CONTENT_TYPE , responseType . toString ( ) ) ; try { JAXRSUtils . writeMessageBody ( writers , entity , targetType , genericType , annotations , responseType , responseHeaders , message ) ; if ( isResponseRedirected ( message ) ) { return ; } Object newContentType = responseHeaders . getFirst ( HttpHeaders . CONTENT_TYPE ) ; if ( newContentType != null ) { message . put ( Message . CONTENT_TYPE , newContentType . toString ( ) ) ; } checkCachedStream ( message , outOriginal , enabled ) ; } finally { if ( enabled ) { message . setContent ( OutputStream . class , outOriginal ) ; message . put ( XMLStreamWriter . class . getName ( ) , null ) ; } } } catch ( IOException ex ) { handleWriteException ( message , response , ori , ex , entity , firstTry ) ; } catch ( Throwable ex ) { handleWriteException ( message , response , ori , ex , entity , firstTry ) ; } } private boolean isResponseNull ( Object o ) { return o == null || GenericEntity . class . isAssignableFrom ( o . getClass ( ) ) && ( ( GenericEntity < ? > ) o ) . getEntity ( ) == null ; } private Object getEntity ( Object o ) { return GenericEntity . class . isAssignableFrom ( o . getClass ( ) ) ? ( ( GenericEntity < ? > ) o ) . getEntity ( ) : o ; } private boolean checkBufferingMode ( Message m , List < WriterInterceptor > writers , boolean firstTry ) { if ( ! firstTry ) { return false ; } WriterInterceptor last = writers . get ( writers . size ( ) - 1 ) ; MessageBodyWriter < Object > w = ( ( WriterInterceptorMBW ) last ) . getMBW ( ) ; Object outBuf = m . getContextualProperty ( OUT_BUFFERING ) ; boolean enabled = MessageUtils . isTrue ( outBuf ) ; boolean configurableProvider = w instanceof AbstractConfigurableProvider ; if ( ! enabled && outBuf == null && configurableProvider ) { enabled = ( ( AbstractConfigurableProvider ) w ) . getEnableBuffering ( ) ; } if ( enabled ) { boolean streamingOn = configurableProvider ? ( ( AbstractConfigurableProvider ) w ) . getEnableStreaming ( ) : false ; if ( streamingOn ) { m . setContent ( XMLStreamWriter . class , new CachingXmlEventWriter ( ) ) ; } else { m . setContent ( OutputStream . class , new CachedOutputStream ( ) ) ; } } return enabled ; } private void checkCachedStream ( Message m , OutputStream osOriginal , boolean enabled ) throws Exception { XMLStreamWriter writer = null ; if ( enabled ) { writer = m . getContent ( XMLStreamWriter . class ) ; } else { writer = ( XMLStreamWriter ) m . get ( XMLStreamWriter . class . getName ( ) ) ; } if ( writer instanceof CachingXmlEventWriter ) { CachingXmlEventWriter cache = ( CachingXmlEventWriter ) writer ; if ( cache . getEvents ( ) . size ( ) != 0 ) { XMLStreamWriter origWriter = StaxUtils . createXMLStreamWriter ( osOriginal ) ; for ( XMLEvent event : cache . getEvents ( ) ) { StaxUtils . writeEvent ( event , origWriter ) ; } } m . setContent ( XMLStreamWriter . class , null ) ; return ; } if ( enabled ) { OutputStream os = m . getContent ( OutputStream . class ) ; if ( os != osOriginal && os instanceof CachedOutputStream ) { CachedOutputStream cos = ( CachedOutputStream ) os ; if ( cos . size ( ) != 0 ) { cos . writeCacheTo ( osOriginal ) ; } } } } private void handleWriteException ( Message message , Response response , OperationResourceInfo ori , Throwable ex , Object responseObj , boolean firstTry ) { OutputStream out = message . getContent ( OutputStream . class ) ; if ( firstTry ) { Response excResponse = JAXRSUtils . convertFaultToResponse ( ex , message ) ; if ( excResponse != null ) { serializeMessage ( message , excResponse , ori , false ) ; return ; } else { ex . printStackTrace ( ) ; } } setResponseStatus ( message , 500 ) ; writeResponseErrorMessage ( out , ""SERIALIZE_ERROR"" , responseObj . getClass ( ) . getSimpleName ( ) ) ; } private void writeResponseErrorMessage ( OutputStream out , String errorString , String parameter ) { try { org . apache . cxf . common . i18n . Message message = new org . apache . cxf . common . i18n . Message ( errorString , BUNDLE , parameter ) ; LOG . warning ( message . toString ( ) ) ; if ( out != null ) { out . write ( message . toString ( ) . getBytes ( ""UTF-8"" ) ) ; } } catch ( IOException another ) { } } @ SuppressWarnings ( ""unchecked"" ) private List < MediaType > computeAvailableContentTypes ( Message message , Response response ) { Object contentType = response . getMetadata ( ) . getFirst ( HttpHeaders . CONTENT_TYPE ) ; if ( contentType != null ) { return Collections . singletonList ( MediaType . valueOf ( contentType . toString ( ) ) ) ; } Exchange exchange = message . getExchange ( ) ; List < MediaType > produceTypes = null ; OperationResourceInfo operation = exchange . get ( OperationResourceInfo . class ) ; if ( operation != null ) { produceTypes = operation . getProduceTypes ( ) ; } else { produceTypes = Collections . singletonList ( MediaType . APPLICATION_OCTET_STREAM_TYPE ) ; } List < MediaType > acceptContentTypes = ( List < MediaType > ) exchange . get ( Message . ACCEPT_CONTENT_TYPE ) ; if ( acceptContentTypes == null ) { acceptContentTypes = Collections . singletonList ( MediaType . WILDCARD_TYPE ) ; } return JAXRSUtils . intersectMimeTypes ( acceptContentTypes , produceTypes , true ) ; } private Class < ? > getRawResponseClass ( Method invoked , Object targetObject , boolean async ) { if ( GenericEntity . class . isAssignableFrom ( targetObject . getClass ( ) ) ) { return ( ( GenericEntity < ? > ) targetObject ) . getRawType ( ) ; } else { Class < ? > targetClass = targetObject . getClass ( ) ; Class < ? > responseClass = async || invoked == null || ! invoked . getReturnType ( ) . isAssignableFrom ( targetClass ) ? targetClass : invoked . getReturnType ( ) ; return ClassHelper . getRealClassFromClass ( responseClass ) ; } } private Type getGenericResponseType ( Method invoked , Object targetObject , Class < ? > targetType , boolean async ) { if ( GenericEntity . class . isAssignableFrom ( targetObject . getClass ( ) ) ) { return ( ( GenericEntity < ? > ) targetObject ) . getType ( ) ; } else if ( async || invoked == null || ! invoked . getReturnType ( ) . isAssignableFrom ( targetType ) ) { return targetObject . getClass ( ) ; } else { return invoked . getGenericReturnType ( ) ; } } private MediaType checkFinalContentType ( MediaType mt ) { if ( mt . isWildcardType ( ) || mt . isWildcardSubtype ( ) ) { return MediaType . APPLICATION_OCTET_STREAM_TYPE ; } else if ( mt . getParameters ( ) . containsKey ( ""q"" ) ) { return MediaType . valueOf ( JAXRSUtils . removeMediaTypeParameter ( mt , ""q"" ) ) ; } else { return mt ; } } private void setResponseDate ( MultivaluedMap < String , Object > headers , boolean firstTry ) { if ( ! firstTry ) { return ; } SimpleDateFormat format = HttpUtils . getHttpDateFormat ( ) ; headers . putSingle ( HttpHeaders . DATE , format . format ( new Date ( ) ) ) ; } private boolean isResponseAlreadyHandled ( Message m ) { return isResponseAlreadyCommited ( m ) || isResponseRedirected ( m ) ; } private boolean isResponseAlreadyCommited ( Message m ) { return Boolean . TRUE . equals ( m . getExchange ( ) . get ( AbstractHTTPDestination . RESPONSE_COMMITED ) ) ; } private boolean isResponseRedirected ( Message outMessage ) { return Boolean . TRUE . equals ( outMessage . get ( AbstractHTTPDestination . REQUEST_REDIRECTED ) ) ; } private void writeResponseToStream ( OutputStream os , Object responseObj ) { try { byte [ ] bytes = responseObj . toString ( ) . getBytes ( ""UTF-8"" ) ; os . write ( bytes , 0 , bytes . length ) ; } catch ( Exception ex ) { LOG . severe ( ""Problem with writing the data to the output stream"" ) ; ex . printStackTrace ( ) ; throw new RuntimeException ( ex ) ; } } private void setResponseStatus ( Message message , int status ) { message . put ( Message . RESPONSE_CODE , status ) ; boolean responseHeadersCopied = isResponseHeadersCopied ( message ) ; if ( responseHeadersCopied ) { HttpServletResponse response = ( HttpServletResponse ) message . get ( AbstractHTTPDestination . HTTP_RESPONSE ) ; response . setStatus ( status ) ; } } private boolean isResponseHeadersCopied ( Message message ) { return MessageUtils . isTrue ( message . get ( AbstractHTTPDestination . RESPONSE_HEADERS_COPIED ) ) ; } }",Smelly
"public class TestBlockingRpc { public static final String MESSAGE = ""TestBlockingRpc"" ; private BlockingRpcServer server ; private BlockingRpcClient client ; private BlockingInterface stub ; private DummyProtocolBlockingImpl service ; RpcClientManager manager = RpcClientManager . getInstance ( ) ; private int retries ; @ Retention ( RetentionPolicy . RUNTIME ) @ Target ( ElementType . METHOD ) @ interface SetupRpcConnection { boolean setupRpcServer ( ) default true ; boolean setupRpcClient ( ) default true ; } @ Rule public ExternalResource resource = new ExternalResource ( ) { private Description description ; @ Override public Statement apply ( Statement base , Description description ) { this . description = description ; return super . apply ( base , description ) ; } @ Override protected void before ( ) throws Throwable { SetupRpcConnection setupRpcConnection = description . getAnnotation ( SetupRpcConnection . class ) ; if ( setupRpcConnection == null || setupRpcConnection . setupRpcServer ( ) ) { setUpRpcServer ( ) ; } if ( setupRpcConnection == null || setupRpcConnection . setupRpcClient ( ) ) { setUpRpcClient ( ) ; } } @ Override protected void after ( ) { SetupRpcConnection setupRpcConnection = description . getAnnotation ( SetupRpcConnection . class ) ; if ( setupRpcConnection == null || setupRpcConnection . setupRpcClient ( ) ) { try { tearDownRpcClient ( ) ; } catch ( Exception e ) { fail ( e . getMessage ( ) ) ; } } if ( setupRpcConnection == null || setupRpcConnection . setupRpcServer ( ) ) { try { tearDownRpcServer ( ) ; } catch ( Exception e ) { fail ( e . getMessage ( ) ) ; } } } } ; public void setUpRpcServer ( ) throws Exception { service = new DummyProtocolBlockingImpl ( ) ; server = new BlockingRpcServer ( DummyProtocol . class , service , new InetSocketAddress ( ""127.0.0.1"" , 0 ) , 2 ) ; server . start ( ) ; } public void setUpRpcClient ( ) throws Exception { retries = 1 ; Properties connParams = new Properties ( ) ; connParams . setProperty ( RpcConstants . CLIENT_RETRY_NUM , ""1"" ) ; connParams . setProperty ( RpcConstants . CLIENT_SOCKET_TIMEOUT , String . valueOf ( TimeUnit . SECONDS . toMillis ( 10 ) ) ) ; connParams . setProperty ( RpcConstants . CLIENT_HANG_DETECTION , ""true"" ) ; RpcConnectionKey rpcConnectionKey = new RpcConnectionKey ( RpcUtils . getConnectAddress ( server . getListenAddress ( ) ) , DummyProtocol . class , false ) ; client = manager . newClient ( rpcConnectionKey , connParams ) ; assertTrue ( client . isConnected ( ) ) ; stub = client . getStub ( ) ; } @ AfterClass public static void tearDownClass ( ) throws Exception { RpcClientManager . shutdown ( ) ; } public void tearDownRpcServer ( ) throws Exception { if ( server != null ) { server . shutdown ( true ) ; server = null ; } } public void tearDownRpcClient ( ) throws Exception { if ( client != null ) { client . close ( ) ; client = null ; } } @ Test public void testRpc ( ) throws Exception { SumRequest request = SumRequest . newBuilder ( ) . setX1 ( 1 ) . setX2 ( 2 ) . setX3 ( 3.15d ) . setX4 ( 2.0f ) . build ( ) ; SumResponse response1 = stub . sum ( null , request ) ; assertEquals ( 8.15d , response1 . getResult ( ) , 1e-15 ) ; EchoMessage message = EchoMessage . newBuilder ( ) . setMessage ( MESSAGE ) . build ( ) ; EchoMessage response2 = stub . echo ( null , message ) ; assertEquals ( MESSAGE , response2 . getMessage ( ) ) ; } @ Test public void testGetNull ( ) throws Exception { assertNull ( stub . getNull ( null , null ) ) ; assertTrue ( service . getNullCalled ) ; } @ Test public void testThrowException ( ) throws Exception { EchoMessage message = EchoMessage . newBuilder ( ) . setMessage ( MESSAGE ) . build ( ) ; try { stub . throwException ( null , message ) ; fail ( ""RpcCall should throw exception"" ) ; } catch ( TajoServiceException te ) { assertEquals ( ""Exception Test"" , te . getMessage ( ) ) ; assertEquals ( ""org.apache.tajo.rpc.test.DummyProtocol"" , te . getProtocol ( ) ) ; assertEquals ( server . getListenAddress ( ) . getAddress ( ) . getHostAddress ( ) + "":"" + server . getListenAddress ( ) . getPort ( ) , te . getRemoteAddress ( ) ) ; } } @ Test public void testThrowException2 ( ) throws Exception { EchoMessage message = EchoMessage . newBuilder ( ) . setMessage ( MESSAGE ) . build ( ) ; DefaultRpcController controller = new DefaultRpcController ( ) ; try { stub . throwException ( controller , message ) ; fail ( ""RpcCall should throw exception"" ) ; } catch ( TajoServiceException t ) { assertTrue ( controller . failed ( ) ) ; assertNotNull ( controller . errorText ( ) ) ; } controller . reset ( ) ; EchoMessage message1 = stub . delay ( controller , message ) ; assertEquals ( message , message1 ) ; assertFalse ( controller . failed ( ) ) ; assertNull ( controller . errorText ( ) ) ; } @ Test ( timeout = 60000 ) public void testServerShutdown1 ( ) throws Exception { EchoMessage message = EchoMessage . newBuilder ( ) . setMessage ( MESSAGE ) . build ( ) ; tearDownRpcServer ( ) ; boolean expect = false ; try { EchoMessage response = stub . echo ( null , message ) ; fail ( response . getMessage ( ) ) ; } catch ( TajoServiceException e ) { expect = true ; } assertTrue ( expect ) ; } @ Test ( timeout = 60000 ) public void testServerShutdown2 ( ) throws Exception { EchoMessage message = EchoMessage . newBuilder ( ) . setMessage ( MESSAGE ) . build ( ) ; tearDownRpcServer ( ) ; boolean expect = false ; try { BlockingInterface stub = client . getStub ( ) ; EchoMessage response = stub . echo ( null , message ) ; fail ( response . getMessage ( ) ) ; } catch ( TajoServiceException e ) { expect = true ; } assertTrue ( expect ) ; } @ Test ( timeout = 60000 ) public void testServerShutdown3 ( ) throws Exception { final StringBuilder error = new StringBuilder ( ) ; Thread callThread = new Thread ( ) { public void run ( ) { try { EchoMessage message = EchoMessage . newBuilder ( ) . setMessage ( MESSAGE ) . build ( ) ; stub . delay ( null , message ) ; } catch ( Exception e ) { error . append ( e . getMessage ( ) ) ; } synchronized ( error ) { error . notifyAll ( ) ; } } } ; callThread . start ( ) ; final CountDownLatch latch = new CountDownLatch ( 1 ) ; Thread shutdownThread = new Thread ( ) { public void run ( ) { try { Thread . sleep ( 1000 ) ; } catch ( InterruptedException e ) { } try { server . shutdown ( true ) ; latch . countDown ( ) ; } catch ( Throwable e ) { e . printStackTrace ( ) ; } } } ; shutdownThread . start ( ) ; latch . await ( ) ; synchronized ( error ) { error . wait ( 5 * 1000 ) ; } if ( ! error . toString ( ) . isEmpty ( ) ) { fail ( error . toString ( ) ) ; } } @ Test ( timeout = 60000 ) @ SetupRpcConnection ( setupRpcServer = false , setupRpcClient = false ) public void testClientRetryOnStartup ( ) throws Exception { retries = 10 ; ServerSocket serverSocket = new ServerSocket ( 0 ) ; final InetSocketAddress address = new InetSocketAddress ( ""127.0.0.1"" , serverSocket . getLocalPort ( ) ) ; serverSocket . close ( ) ; EchoMessage message = EchoMessage . newBuilder ( ) . setMessage ( MESSAGE ) . build ( ) ; Thread serverThread = new Thread ( new Runnable ( ) { @ Override public void run ( ) { try { Thread . sleep ( 1000 ) ; server = new BlockingRpcServer ( DummyProtocol . class , new DummyProtocolBlockingImpl ( ) , address , 2 ) ; } catch ( Exception e ) { fail ( e . getMessage ( ) ) ; } server . start ( ) ; } } ) ; serverThread . start ( ) ; RpcConnectionKey rpcConnectionKey = new RpcConnectionKey ( address , DummyProtocol . class , false ) ; Properties connParams = new Properties ( ) ; connParams . setProperty ( RpcConstants . CLIENT_RETRY_NUM , retries + """" ) ; BlockingRpcClient client = manager . newClient ( rpcConnectionKey , connParams ) ; assertTrue ( client . isConnected ( ) ) ; BlockingInterface stub = client . getStub ( ) ; EchoMessage response = stub . echo ( null , message ) ; assertEquals ( MESSAGE , response . getMessage ( ) ) ; client . close ( ) ; server . shutdown ( true ) ; } @ Test ( timeout = 60000 ) @ SetupRpcConnection ( setupRpcServer = false , setupRpcClient = false ) public void testClientRetryFailureOnStartup ( ) throws Exception { retries = 2 ; ServerSocket serverSocket = new ServerSocket ( 0 ) ; final InetSocketAddress address = new InetSocketAddress ( ""127.0.0.1"" , serverSocket . getLocalPort ( ) ) ; serverSocket . close ( ) ; EchoMessage message = EchoMessage . newBuilder ( ) . setMessage ( MESSAGE ) . build ( ) ; RpcConnectionKey rpcConnectionKey = new RpcConnectionKey ( address , DummyProtocol . class , false ) ; Properties connParams = new Properties ( ) ; connParams . setProperty ( RpcConstants . CLIENT_RETRY_NUM , retries + """" ) ; BlockingRpcClient client = new BlockingRpcClient ( NettyUtils . getDefaultEventLoopGroup ( ) , rpcConnectionKey , connParams ) ; try { client . connect ( ) ; fail ( ) ; } catch ( ConnectTimeoutException e ) { assertFalse ( e . getMessage ( ) , client . isConnected ( ) ) ; } BlockingInterface stub = client . getStub ( ) ; try { EchoMessage response = stub . echo ( null , message ) ; fail ( ) ; } catch ( TajoServiceException e ) { assertFalse ( e . getMessage ( ) , client . isConnected ( ) ) ; } RpcClientManager . cleanup ( client ) ; } @ Test ( timeout = 120000 ) @ SetupRpcConnection ( setupRpcServer = false , setupRpcClient = false ) public void testUnresolvedAddress ( ) throws Exception { InetSocketAddress address = new InetSocketAddress ( ""test"" , 0 ) ; boolean expected = false ; BlockingRpcClient client = null ; try { RpcConnectionKey rpcConnectionKey = new RpcConnectionKey ( address , DummyProtocol . class , true ) ; Properties connParams = new Properties ( ) ; connParams . setProperty ( RpcConstants . CLIENT_RETRY_NUM , retries + """" ) ; client = new BlockingRpcClient ( NettyUtils . getDefaultEventLoopGroup ( ) , rpcConnectionKey , connParams ) ; client . connect ( ) ; fail ( ) ; } catch ( ConnectException e ) { expected = true ; } catch ( Throwable throwable ) { fail ( throwable . getMessage ( ) ) ; } finally { client . close ( ) ; } assertTrue ( expected ) ; } @ Test ( timeout = 120000 ) @ SetupRpcConnection ( setupRpcClient = false ) public void testUnresolvedAddress2 ( ) throws Exception { String hostAndPort = RpcUtils . normalizeInetSocketAddress ( server . getListenAddress ( ) ) ; RpcConnectionKey rpcConnectionKey = new RpcConnectionKey ( RpcUtils . createUnresolved ( hostAndPort ) , DummyProtocol . class , false ) ; Properties connParams = new Properties ( ) ; connParams . setProperty ( RpcConstants . CLIENT_RETRY_NUM , retries + """" ) ; BlockingRpcClient client = new BlockingRpcClient ( NettyUtils . getDefaultEventLoopGroup ( ) , rpcConnectionKey , connParams ) ; client . connect ( ) ; assertTrue ( client . isConnected ( ) ) ; try { BlockingInterface stub = client . getStub ( ) ; EchoMessage message = EchoMessage . newBuilder ( ) . setMessage ( MESSAGE ) . build ( ) ; EchoMessage response2 = stub . echo ( null , message ) ; assertEquals ( MESSAGE , response2 . getMessage ( ) ) ; } finally { client . close ( ) ; } } @ Test ( timeout = 60000 ) @ SetupRpcConnection ( setupRpcClient = false ) public void testStubRecovery ( ) throws Exception { RpcConnectionKey rpcConnectionKey = new RpcConnectionKey ( server . getListenAddress ( ) , DummyProtocol . class , false ) ; Properties connParams = new Properties ( ) ; connParams . setProperty ( RpcConstants . CLIENT_RETRY_NUM , String . valueOf ( 1 ) ) ; BlockingRpcClient client = manager . newClient ( rpcConnectionKey , connParams ) ; EchoMessage echoMessage = EchoMessage . newBuilder ( ) . setMessage ( MESSAGE ) . build ( ) ; int repeat = 5 ; assertTrue ( client . isConnected ( ) ) ; BlockingInterface stub = client . getStub ( ) ; client . close ( ) ; assertFalse ( client . isConnected ( ) ) ; for ( int i = 0 ; i < repeat ; i ++ ) { try { EchoMessage response = stub . echo ( null , echoMessage ) ; assertEquals ( MESSAGE , response . getMessage ( ) ) ; assertTrue ( client . isConnected ( ) ) ; } finally { client . close ( ) ; assertFalse ( client . isConnected ( ) ) ; } } } @ Test ( timeout = 60000 ) @ SetupRpcConnection ( setupRpcClient = false ) public void testIdleTimeout ( ) throws Exception { RpcConnectionKey rpcConnectionKey = new RpcConnectionKey ( server . getListenAddress ( ) , DummyProtocol . class , false ) ; Properties connParams = new Properties ( ) ; connParams . setProperty ( RpcConstants . CLIENT_RETRY_NUM , retries + """" ) ; connParams . setProperty ( RpcConstants . CLIENT_SOCKET_TIMEOUT , String . valueOf ( 500 ) ) ; BlockingRpcClient client = manager . newClient ( rpcConnectionKey , connParams ) ; assertTrue ( client . isConnected ( ) ) ; Thread . sleep ( 600 ) ; assertFalse ( client . isConnected ( ) ) ; client . connect ( ) ; assertTrue ( client . isConnected ( ) ) ; Thread . sleep ( 600 ) ; assertFalse ( client . isConnected ( ) ) ; client . close ( ) ; } @ Test ( timeout = 60000 ) @ SetupRpcConnection ( setupRpcClient = false ) public void testPingOnIdle ( ) throws Exception { RpcConnectionKey rpcConnectionKey = new RpcConnectionKey ( server . getListenAddress ( ) , DummyProtocol . class , false ) ; Properties connParams = new Properties ( ) ; connParams . setProperty ( RpcConstants . CLIENT_RETRY_NUM , retries + """" ) ; connParams . setProperty ( RpcConstants . CLIENT_SOCKET_TIMEOUT , String . valueOf ( 500 ) ) ; connParams . setProperty ( RpcConstants . CLIENT_HANG_DETECTION , ""true"" ) ; BlockingRpcClient client = manager . newClient ( rpcConnectionKey , connParams ) ; assertTrue ( client . isConnected ( ) ) ; Thread . sleep ( 600 ) ; assertTrue ( client . isConnected ( ) ) ; Thread . sleep ( 600 ) ; assertTrue ( client . isConnected ( ) ) ; client . close ( ) ; } @ Test ( timeout = 60000 ) @ SetupRpcConnection ( setupRpcClient = false ) public void testIdleTimeoutWithActiveRequest ( ) throws Exception { RpcConnectionKey rpcConnectionKey = new RpcConnectionKey ( server . getListenAddress ( ) , DummyProtocol . class , false ) ; Properties connParams = new Properties ( ) ; connParams . setProperty ( RpcConstants . CLIENT_RETRY_NUM , retries + """" ) ; connParams . setProperty ( RpcConstants . CLIENT_SOCKET_TIMEOUT , String . valueOf ( 500 ) ) ; BlockingRpcClient client = manager . newClient ( rpcConnectionKey , connParams ) ; assertTrue ( client . isConnected ( ) ) ; BlockingInterface stub = client . getStub ( ) ; EchoMessage echoMessage = EchoMessage . newBuilder ( ) . setMessage ( MESSAGE ) . build ( ) ; EchoMessage message = stub . delay ( null , echoMessage ) ; assertEquals ( message , echoMessage ) ; assertTrue ( client . isConnected ( ) ) ; assertTrue ( client . getActiveRequests ( ) == 0 ) ; Thread . sleep ( 600 ) ; assertFalse ( client . isConnected ( ) ) ; } @ Test ( timeout = 60000 ) @ SetupRpcConnection ( setupRpcClient = false ) public void testRequestTimeoutOnBusy ( ) throws Exception { RpcConnectionKey rpcConnectionKey = new RpcConnectionKey ( server . getListenAddress ( ) , DummyProtocol . class , false ) ; Properties connParams = new Properties ( ) ; connParams . setProperty ( RpcConstants . CLIENT_RETRY_NUM , retries + """" ) ; connParams . setProperty ( RpcConstants . CLIENT_SOCKET_TIMEOUT , String . valueOf ( 500 ) ) ; connParams . setProperty ( RpcConstants . CLIENT_HANG_DETECTION , ""true"" ) ; BlockingRpcClient client = manager . newClient ( rpcConnectionKey , connParams ) ; assertTrue ( client . isConnected ( ) ) ; BlockingInterface stub = client . getStub ( ) ; EchoMessage echoMessage = EchoMessage . newBuilder ( ) . setMessage ( MESSAGE ) . build ( ) ; boolean expected = false ; try { EchoMessage message = stub . busy ( null , echoMessage ) ; fail ( ) ; } catch ( TajoServiceException e ) { expected = true ; } finally { client . close ( ) ; } assertTrue ( expected ) ; } }",Smelly
" static class AsyncProcessForThrowableCheck extends AsyncProcess { public AsyncProcessForThrowableCheck ( ClusterConnection hc , Configuration conf ) { super ( hc , conf , new RpcRetryingCallerFactory ( conf ) , new RpcControllerFactory ( conf ) ) ; } ",No
"public class AnchorTag extends AbstractClosingTag { private static final long serialVersionUID = - 1034616578492431113L ; protected String href ; public Component getBean ( ValueStack stack , HttpServletRequest req , HttpServletResponse res ) { return new Anchor ( stack , req , res ) ; } protected void populateParams ( ) { super . populateParams ( ) ; Anchor anchor = ( Anchor ) component ; anchor . setHref ( href ) ; } public void setHref ( String href ) { this . href = href ; } }",No
"public class TestMetadata { private static final String CONTENTTYPE = ""contenttype"" ; @ Test public void testWriteNonNull ( ) { Metadata met = new Metadata ( ) ; met . add ( CONTENTTYPE , null ) ; met . add ( CONTENTTYPE , ""text/bogus"" ) ; met . add ( CONTENTTYPE , ""text/bogus2"" ) ; met = writeRead ( met ) ; Assert . assertNotNull ( met ) ; Assert . assertEquals ( met . size ( ) , 1 ) ; boolean hasBogus = false , hasBogus2 = false ; String [ ] values = met . getValues ( CONTENTTYPE ) ; Assert . assertNotNull ( values ) ; Assert . assertEquals ( values . length , 2 ) ; for ( int i = 0 ; i < values . length ; i ++ ) { if ( values [ i ] . equals ( ""text/bogus"" ) ) { hasBogus = true ; } if ( values [ i ] . equals ( ""text/bogus2"" ) ) { hasBogus2 = true ; } } Assert . assertTrue ( hasBogus && hasBogus2 ) ; } @ Test public void testAdd ( ) { String [ ] values = null ; Metadata meta = new Metadata ( ) ; values = meta . getValues ( CONTENTTYPE ) ; Assert . assertEquals ( 0 , values . length ) ; meta . add ( CONTENTTYPE , ""value1"" ) ; values = meta . getValues ( CONTENTTYPE ) ; Assert . assertEquals ( 1 , values . length ) ; Assert . assertEquals ( ""value1"" , values [ 0 ] ) ; meta . add ( CONTENTTYPE , ""value2"" ) ; values = meta . getValues ( CONTENTTYPE ) ; Assert . assertEquals ( 2 , values . length ) ; Assert . assertEquals ( ""value1"" , values [ 0 ] ) ; Assert . assertEquals ( ""value2"" , values [ 1 ] ) ; meta . add ( CONTENTTYPE , ""value1"" ) ; values = meta . getValues ( CONTENTTYPE ) ; Assert . assertEquals ( 3 , values . length ) ; Assert . assertEquals ( ""value1"" , values [ 0 ] ) ; Assert . assertEquals ( ""value2"" , values [ 1 ] ) ; Assert . assertEquals ( ""value1"" , values [ 2 ] ) ; } @ Test public void testSet ( ) { String [ ] values = null ; Metadata meta = new Metadata ( ) ; values = meta . getValues ( CONTENTTYPE ) ; Assert . assertEquals ( 0 , values . length ) ; meta . set ( CONTENTTYPE , ""value1"" ) ; values = meta . getValues ( CONTENTTYPE ) ; Assert . assertEquals ( 1 , values . length ) ; Assert . assertEquals ( ""value1"" , values [ 0 ] ) ; meta . set ( CONTENTTYPE , ""value2"" ) ; values = meta . getValues ( CONTENTTYPE ) ; Assert . assertEquals ( 1 , values . length ) ; Assert . assertEquals ( ""value2"" , values [ 0 ] ) ; meta . set ( CONTENTTYPE , ""new value 1"" ) ; meta . add ( ""contenttype"" , ""new value 2"" ) ; values = meta . getValues ( CONTENTTYPE ) ; Assert . assertEquals ( 2 , values . length ) ; Assert . assertEquals ( ""new value 1"" , values [ 0 ] ) ; Assert . assertEquals ( ""new value 2"" , values [ 1 ] ) ; } @ Test public void testSetProperties ( ) { String [ ] values = null ; Metadata meta = new Metadata ( ) ; Properties props = new Properties ( ) ; meta . setAll ( props ) ; Assert . assertEquals ( 0 , meta . size ( ) ) ; props . setProperty ( ""name-one"" , ""value1.1"" ) ; meta . setAll ( props ) ; Assert . assertEquals ( 1 , meta . size ( ) ) ; values = meta . getValues ( ""name-one"" ) ; Assert . assertEquals ( 1 , values . length ) ; Assert . assertEquals ( ""value1.1"" , values [ 0 ] ) ; props . setProperty ( ""name-two"" , ""value2.1"" ) ; meta . setAll ( props ) ; Assert . assertEquals ( 2 , meta . size ( ) ) ; values = meta . getValues ( ""name-one"" ) ; Assert . assertEquals ( 1 , values . length ) ; Assert . assertEquals ( ""value1.1"" , values [ 0 ] ) ; values = meta . getValues ( ""name-two"" ) ; Assert . assertEquals ( 1 , values . length ) ; Assert . assertEquals ( ""value2.1"" , values [ 0 ] ) ; } @ Test public void testGet ( ) { Metadata meta = new Metadata ( ) ; Assert . assertNull ( meta . get ( ""a-name"" ) ) ; meta . add ( ""a-name"" , ""value-1"" ) ; Assert . assertEquals ( ""value-1"" , meta . get ( ""a-name"" ) ) ; meta . add ( ""a-name"" , ""value-2"" ) ; Assert . assertEquals ( ""value-1"" , meta . get ( ""a-name"" ) ) ; } @ Test public void testIsMultiValued ( ) { Metadata meta = new Metadata ( ) ; Assert . assertFalse ( meta . isMultiValued ( ""key"" ) ) ; meta . add ( ""key"" , ""value1"" ) ; Assert . assertFalse ( meta . isMultiValued ( ""key"" ) ) ; meta . add ( ""key"" , ""value2"" ) ; Assert . assertTrue ( meta . isMultiValued ( ""key"" ) ) ; } @ Test public void testNames ( ) { String [ ] names = null ; Metadata meta = new Metadata ( ) ; names = meta . names ( ) ; Assert . assertEquals ( 0 , names . length ) ; meta . add ( ""name-one"" , ""value"" ) ; names = meta . names ( ) ; Assert . assertEquals ( 1 , names . length ) ; Assert . assertEquals ( ""name-one"" , names [ 0 ] ) ; meta . add ( ""name-two"" , ""value"" ) ; names = meta . names ( ) ; Assert . assertEquals ( 2 , names . length ) ; } @ Test public void testRemove ( ) { Metadata meta = new Metadata ( ) ; meta . remove ( ""name-one"" ) ; Assert . assertEquals ( 0 , meta . size ( ) ) ; meta . add ( ""name-one"" , ""value-1.1"" ) ; meta . add ( ""name-one"" , ""value-1.2"" ) ; meta . add ( ""name-two"" , ""value-2.2"" ) ; Assert . assertEquals ( 2 , meta . size ( ) ) ; Assert . assertNotNull ( meta . get ( ""name-one"" ) ) ; Assert . assertNotNull ( meta . get ( ""name-two"" ) ) ; meta . remove ( ""name-one"" ) ; Assert . assertEquals ( 1 , meta . size ( ) ) ; Assert . assertNull ( meta . get ( ""name-one"" ) ) ; Assert . assertNotNull ( meta . get ( ""name-two"" ) ) ; meta . remove ( ""name-two"" ) ; Assert . assertEquals ( 0 , meta . size ( ) ) ; Assert . assertNull ( meta . get ( ""name-one"" ) ) ; Assert . assertNull ( meta . get ( ""name-two"" ) ) ; } @ Test public void testObject ( ) { Metadata meta1 = new Metadata ( ) ; Metadata meta2 = new Metadata ( ) ; Assert . assertFalse ( meta1 . equals ( null ) ) ; Assert . assertFalse ( meta1 . equals ( ""String"" ) ) ; Assert . assertTrue ( meta1 . equals ( meta2 ) ) ; meta1 . add ( ""name-one"" , ""value-1.1"" ) ; Assert . assertFalse ( meta1 . equals ( meta2 ) ) ; meta2 . add ( ""name-one"" , ""value-1.1"" ) ; Assert . assertTrue ( meta1 . equals ( meta2 ) ) ; meta1 . add ( ""name-one"" , ""value-1.2"" ) ; Assert . assertFalse ( meta1 . equals ( meta2 ) ) ; meta2 . add ( ""name-one"" , ""value-1.2"" ) ; Assert . assertTrue ( meta1 . equals ( meta2 ) ) ; meta1 . add ( ""name-two"" , ""value-2.1"" ) ; Assert . assertFalse ( meta1 . equals ( meta2 ) ) ; meta2 . add ( ""name-two"" , ""value-2.1"" ) ; Assert . assertTrue ( meta1 . equals ( meta2 ) ) ; meta1 . add ( ""name-two"" , ""value-2.2"" ) ; Assert . assertFalse ( meta1 . equals ( meta2 ) ) ; meta2 . add ( ""name-two"" , ""value-2.x"" ) ; Assert . assertFalse ( meta1 . equals ( meta2 ) ) ; } @ Test public void testWritable ( ) { Metadata result = null ; Metadata meta = new Metadata ( ) ; result = writeRead ( meta ) ; Assert . assertEquals ( 0 , result . size ( ) ) ; meta . add ( ""name-one"" , ""value-1.1"" ) ; result = writeRead ( meta ) ; Assert . assertEquals ( 1 , result . size ( ) ) ; Assert . assertEquals ( 1 , result . getValues ( ""name-one"" ) . length ) ; Assert . assertEquals ( ""value-1.1"" , result . get ( ""name-one"" ) ) ; meta . add ( ""name-two"" , ""value-2.1"" ) ; meta . add ( ""name-two"" , ""value-2.2"" ) ; result = writeRead ( meta ) ; Assert . assertEquals ( 2 , result . size ( ) ) ; Assert . assertEquals ( 1 , result . getValues ( ""name-one"" ) . length ) ; Assert . assertEquals ( ""value-1.1"" , result . getValues ( ""name-one"" ) [ 0 ] ) ; Assert . assertEquals ( 2 , result . getValues ( ""name-two"" ) . length ) ; Assert . assertEquals ( ""value-2.1"" , result . getValues ( ""name-two"" ) [ 0 ] ) ; Assert . assertEquals ( ""value-2.2"" , result . getValues ( ""name-two"" ) [ 1 ] ) ; } private Metadata writeRead ( Metadata meta ) { Metadata readed = new Metadata ( ) ; try { ByteArrayOutputStream out = new ByteArrayOutputStream ( ) ; meta . write ( new DataOutputStream ( out ) ) ; readed . readFields ( new DataInputStream ( new ByteArrayInputStream ( out . toByteArray ( ) ) ) ) ; } catch ( IOException ioe ) { Assert . fail ( ioe . toString ( ) ) ; } return readed ; } }",Smelly
"public final class PluginConstants { private PluginConstants ( ) { } public static final String PLUGIN_ID = PluginConstants . class . getPackage ( ) . getName ( ) ; public static final String PERSPECTIVE_SCHEMA_EDITOR_ID = Activator . getDefault ( ) . getPluginProperties ( ) . getString ( ""Perspective_SchemaEditor_id"" ) ; public static final String PERSPECTIVE_LDAP_BROWSER_ID = ""org.apache.directory.studio.ldapbrowser.ui.perspective.BrowserPerspective"" ; public static final String PERSPECTIVE_TOP_LEFT_FOLDER_ID = ""org.apache.directory.studio.schemaeditor.topleftfolder"" ; public static final String PERSPECTIVE_BOTTOM_FOLDER_ID = ""org.apache.directory.studio.schemaeditor.bottomfolder"" ; public static final String EDITOR_ATTRIBUTE_TYPE_ID = Activator . getDefault ( ) . getPluginProperties ( ) . getString ( ""Editor_AttributeTypeEditor_id"" ) ; public static final String EDITOR_OBJECT_CLASS_ID = Activator . getDefault ( ) . getPluginProperties ( ) . getString ( ""Editor_ObjectClassEditor_id"" ) ; public static final String EDITOR_SCHEMA_ID = Activator . getDefault ( ) . getPluginProperties ( ) . getString ( ""Editor_SchemaEditor_id"" ) ; public static final String PREF_PAGE_HIERARCHY_VIEW_ID = Activator . getDefault ( ) . getPluginProperties ( ) . getString ( ""PrefPage_HierarchyView_id"" ) ; public static final String PREF_PAGE_SCHEMA_VIEW_ID = Activator . getDefault ( ) . getPluginProperties ( ) . getString ( ""PrefPage_SchemaView_id"" ) ; public static final String PREF_PAGE_SEARCH_VIEW_ID = Activator . getDefault ( ) . getPluginProperties ( ) . getString ( ""PrefPage_SearchView_id"" ) ; public static final String VIEW_HIERARCHY_VIEW_ID = Activator . getDefault ( ) . getPluginProperties ( ) . getString ( ""View_HierarchyView_id"" ) ; public static final String VIEW_PROBLEMS_VIEW_ID = Activator . getDefault ( ) . getPluginProperties ( ) . getString ( ""View_ProblemsView_id"" ) ; public static final String VIEW_PROJECTS_VIEW_ID = Activator . getDefault ( ) . getPluginProperties ( ) . getString ( ""View_ProjectsView_id"" ) ; public static final String VIEW_SCHEMA_VIEW_ID = Activator . getDefault ( ) . getPluginProperties ( ) . getString ( ""View_SchemaView_id"" ) ; public static final String VIEW_SEARCH_VIEW_ID = Activator . getDefault ( ) . getPluginProperties ( ) . getString ( ""View_SearchView_id"" ) ; public static final String NEW_WIZARD_NEW_ATTRIBUTE_TYPE_WIZARD = Activator . getDefault ( ) . getPluginProperties ( ) . getString ( ""NewWizard_NewAttributeTypeWizard_id"" ) ; public static final String NEW_WIZARD_NEW_OBJECT_CLASS_WIZARD = Activator . getDefault ( ) . getPluginProperties ( ) . getString ( ""NewWizard_NewObjectClassWizard_id"" ) ; public static final String NEW_WIZARD_NEW_PROJECT_WIZARD = Activator . getDefault ( ) . getPluginProperties ( ) . getString ( ""NewWizard_NewProjectWizard_id"" ) ; public static final String NEW_WIZARD_NEW_SCHEMA_WIZARD = Activator . getDefault ( ) . getPluginProperties ( ) . getString ( ""NewWizard_NewSchemaWizard_id"" ) ; public static final String IMG_ATTRIBUTE_TYPE = ""resources/icons/attribute_type.gif"" ; public static final String IMG_ATTRIBUTE_TYPE_HIERARCHY_SELECTED = ""resources/icons/attribute_type_hierarchy_selected.gif"" ; public static final String IMG_ATTRIBUTE_TYPE_NEW = ""resources/icons/attribute_type_new.gif"" ; public static final String IMG_ATTRIBUTE_TYPE_NEW_WIZARD = ""resources/icons/attribute_type_new_wizard.png"" ; public static final String IMG_ATTRIBUTE_TYPE_OVERLAY_OPERATION = ""resources/icons/attribute_type_overlay_operation.gif"" ; public static final String IMG_ATTRIBUTE_TYPE_OVERLAY_USER_APPLICATION = ""resources/icons/attribute_type_overlay_userApplication.gif"" ; public static final String IMG_CONNECT = ""resources/icons/connect.gif"" ; public static final String IMG_COMMIT_CHANGES = ""resources/icons/commit_changes.gif"" ; public static final String IMG_COMMIT_CHANGES_WIZARD = ""resources/icons/commit_changes_wizard.png"" ; public static final String IMG_COLLAPSE_ALL = ""resources/icons/collapse_all.gif"" ; public static final String IMG_DELETE = ""resources/icons/delete.gif"" ; public static final String IMG_DISCONNECT = ""resources/icons/disconnect.gif"" ; public static final String IMG_DIFFERENCE_ATTRIBUTE_TYPE_ADD = ""resources/icons/difference_attribute_type_add.gif"" ; public static final String IMG_DIFFERENCE_ATTRIBUTE_TYPE_MODIFY = ""resources/icons/difference_attribute_type_modify.gif"" ; public static final String IMG_DIFFERENCE_ATTRIBUTE_TYPE_REMOVE = ""resources/icons/difference_attribute_type_remove.gif"" ; public static final String IMG_DIFFERENCE_OBJECT_CLASS_ADD = ""resources/icons/difference_object_class_add.gif"" ; public static final String IMG_DIFFERENCE_OBJECT_CLASS_MODIFY = ""resources/icons/difference_object_class_modify.gif"" ; public static final String IMG_DIFFERENCE_OBJECT_CLASS_REMOVE = ""resources/icons/difference_object_class_remove.gif"" ; public static final String IMG_DIFFERENCE_PROPERTY_ADD = ""resources/icons/difference_property_add.gif"" ; public static final String IMG_DIFFERENCE_PROPERTY_MODIFY = ""resources/icons/difference_property_modify.gif"" ; public static final String IMG_DIFFERENCE_PROPERTY_REMOVE = ""resources/icons/difference_property_remove.gif"" ; public static final String IMG_DIFFERENCE_SCHEMA_ADD = ""resources/icons/difference_schema_add.gif"" ; public static final String IMG_DIFFERENCE_SCHEMA_MODIFY = ""resources/icons/difference_schema_modify.gif"" ; public static final String IMG_DIFFERENCE_SCHEMA_REMOVE = ""resources/icons/difference_schema_remove.gif"" ; public static final String IMG_FOLDER = ""resources/icons/folder.gif"" ; public static final String IMG_FOLDER_AT = ""resources/icons/folder_at.gif"" ; public static final String IMG_FOLDER_OC = ""resources/icons/folder_oc.gif"" ; public static final String IMG_LINK_WITH_EDITOR = ""resources/icons/link_with_editor.gif"" ; public static final String IMG_OBJECT_CLASS = ""resources/icons/object_class.gif"" ; public static final String IMG_OBJECT_CLASS_HIERARCHY_SELECTED = ""resources/icons/object_class_hierarchy_selected.gif"" ; public static final String IMG_OBJECT_CLASS_NEW = ""resources/icons/object_class_new.gif"" ; public static final String IMG_OBJECT_CLASS_NEW_WIZARD = ""resources/icons/object_class_new_wizard.png"" ; public static final String IMG_OBJECT_CLASS_OVERLAY_ABSTRACT = ""resources/icons/object_class_overlay_abstract.gif"" ; public static final String IMG_OBJECT_CLASS_OVERLAY_AUXILIARY = ""resources/icons/object_class_overlay_auxiliary.gif"" ; public static final String IMG_OBJECT_CLASS_OVERLAY_STRUCTURAL = ""resources/icons/object_class_overlay_structural.gif"" ; public static final String IMG_OVERLAY_ERROR = ""resources/icons/overlay_error.gif"" ; public static final String IMG_OVERLAY_WARNING = ""resources/icons/overlay_warning.gif"" ; public static final String IMG_PROBLEMS_ERROR = ""resources/icons/problems_error.gif"" ; public static final String IMG_PROBLEMS_GROUP = ""resources/icons/problems_group.gif"" ; public static final String IMG_PROBLEMS_WARNING = ""resources/icons/problems_warning.gif"" ; public static final String IMG_PROJECT_EXPORT = ""resources/icons/project_export.gif"" ; public static final String IMG_PROJECT_EXPORT_WIZARD = ""resources/icons/project_export_wizard.png"" ; public static final String IMG_PROJECT_FILE = ""resources/icons/project_file.gif"" ; public static final String IMG_PROJECT_IMPORT = ""resources/icons/project_import.gif"" ; public static final String IMG_PROJECT_IMPORT_WIZARD = ""resources/icons/project_import_wizard.png"" ; public static final String IMG_PROJECT_NEW = ""resources/icons/project_new.gif"" ; public static final String IMG_PROJECT_NEW_WIZARD = ""resources/icons/project_new_wizard.png"" ; public static final String IMG_PROJECT_OFFLINE = ""resources/icons/project_offline.gif"" ; public static final String IMG_PROJECT_OFFLINE_CLOSED = ""resources/icons/project_offline_closed.gif"" ; public static final String IMG_PROJECT_ONLINE = ""resources/icons/project_online.gif"" ; public static final String IMG_PROJECT_ONLINE_CLOSED = ""resources/icons/project_online_closed.gif"" ; public static final String IMG_RENAME = ""resources/icons/rename.gif"" ; public static final String IMG_RUN_CURRENT_SEARCH_AGAIN = ""resources/icons/run_current_search_again.gif"" ; public static final String IMG_SCHEMA = ""resources/icons/schema.gif"" ; public static final String IMG_SCHEMA_CONNECTOR = ""resources/icons/schema_connector.gif"" ; public static final String IMG_SCHEMA_NEW = ""resources/icons/schema_new.gif"" ; public static final String IMG_SCHEMA_NEW_WIZARD = ""resources/icons/schema_new_wizard.png"" ; public static final String IMG_SCHEMAS_EXPORT = ""resources/icons/schemas_export.gif"" ; public static final String IMG_SCHEMAS_EXPORT_FOR_ADS = ""resources/icons/schemas_export_for_ads.gif"" ; public static final String IMG_SCHEMAS_EXPORT_FOR_ADS_WIZARD = ""resources/icons/schemas_export_for_ads_wizard.png"" ; public static final String IMG_SCHEMAS_EXPORT_WIZARD = ""resources/icons/schemas_export_wizard.png"" ; public static final String IMG_SCHEMAS_IMPORT = ""resources/icons/schemas_import.gif"" ; public static final String IMG_SCHEMAS_IMPORT_WIZARD = ""resources/icons/schemas_import_wizard.png"" ; public static final String IMG_SEARCH = ""resources/icons/search.gif"" ; public static final String IMG_SEARCH_HISTORY_ITEM = ""resources/icons/search_history_item.gif"" ; public static final String IMG_SHOW_SEARCH_FIELD = ""resources/icons/show_search_field.gif"" ; public static final String IMG_SHOW_SEARCH_HISTORY = ""resources/icons/show_search_history.gif"" ; public static final String IMG_SHOW_SUBTYPE_HIERARCHY = ""resources/icons/hierarchy_subtype.gif"" ; public static final String IMG_SHOW_SUPERTYPE_HIERARCHY = ""resources/icons/hierarchy_supertype.gif"" ; public static final String IMG_SHOW_TYPE_HIERARCHY = ""resources/icons/hierarchy_type.gif"" ; public static final String IMG_SORTING = ""resources/icons/sorting.gif"" ; public static final String IMG_TOOLBAR_MENU = ""resources/icons/toolbar_menu.gif"" ; public static final String IMG_TRANSPARENT_16X16 = ""resources/icons/transparent_16x16.gif"" ; public static final String IMG_WARNING_32X32 = ""resources/icons/warning_32x32.png"" ; public static final String CMD_DELETE_PROJECT = Activator . getDefault ( ) . getPluginProperties ( ) . getString ( ""Cmd_DeleteProject_id"" ) ; public static final String CMD_DELETE_SCHEMA_ELEMENT = Activator . getDefault ( ) . getPluginProperties ( ) . getString ( ""Cmd_DeleteSchemaElement_id"" ) ; public static final String CMD_OPEN_ELEMENT = Activator . getDefault ( ) . getPluginProperties ( ) . getString ( ""Cmd_OpenElement_id"" ) ; public static final String CMD_OPEN_TYPE_HIERARCHY = Activator . getDefault ( ) . getPluginProperties ( ) . getString ( ""Cmd_OpenTypeHierarchy_id"" ) ; public static final String CMD_NEW_ATTRIBUTE_TYPE = Activator . getDefault ( ) . getPluginProperties ( ) . getString ( ""Cmd_NewAttributeType_id"" ) ; public static final String CMD_NEW_OBJECT_CLASS = Activator . getDefault ( ) . getPluginProperties ( ) . getString ( ""Cmd_NewObjectClass_id"" ) ; public static final String CMD_NEW_PROJECT = Activator . getDefault ( ) . getPluginProperties ( ) . getString ( ""Cmd_NewProject_id"" ) ; public static final String CMD_NEW_SCHEMA = Activator . getDefault ( ) . getPluginProperties ( ) . getString ( ""Cmd_NewSchema_id"" ) ; public static final String CMD_RENAME_PROJECT = Activator . getDefault ( ) . getPluginProperties ( ) . getString ( ""Cmd_RenameProject_id"" ) ; public static final String CMD_RENAME_SCHEMA_ELEMENT = Activator . getDefault ( ) . getPluginProperties ( ) . getString ( ""Cmd_RenameSchemaElement_id"" ) ; public static final String PREFS_DIFFERENCES_WIDGET_GROUPING = PluginConstants . PLUGIN_ID + "".prefs.DifferencesWidget.grouping"" ; public static final int PREFS_DIFFERENCES_WIDGET_GROUPING_PROPERTY = 0 ; public static final int PREFS_DIFFERENCES_WIDGET_GROUPING_TYPE = 1 ; public static final String PREFS_SCHEMA_VIEW_SCHEMA_PRESENTATION = SchemaViewPreferencePage . ID + "".schemaPresentation"" ; public static final int PREFS_SCHEMA_VIEW_SCHEMA_PRESENTATION_FLAT = 0 ; public static final int PREFS_SCHEMA_VIEW_SCHEMA_PRESENTATION_HIERARCHICAL = 1 ; public static final String PREFS_SCHEMA_VIEW_LABEL = SchemaViewPreferencePage . ID + "".label.labelValue"" ; public static final int PREFS_SCHEMA_VIEW_LABEL_FIRST_NAME = 0 ; public static final int PREFS_SCHEMA_VIEW_LABEL_ALL_ALIASES = 1 ; public static final int PREFS_SCHEMA_VIEW_LABEL_OID = 2 ; public static final String PREFS_SCHEMA_VIEW_ABBREVIATE = SchemaViewPreferencePage . ID + "".label.abbreviate"" ; public static final String PREFS_SCHEMA_VIEW_ABBREVIATE_MAX_LENGTH = SchemaViewPreferencePage . ID + "".label.abbreviate.maxLength"" ; public static final String PREFS_SCHEMA_VIEW_SECONDARY_LABEL_DISPLAY = SchemaViewPreferencePage . ID + "".secondaryLabel.display"" ; public static final String PREFS_SCHEMA_VIEW_SECONDARY_LABEL = SchemaViewPreferencePage . ID + "".secondaryLabel.labelValue"" ; public static final String PREFS_SCHEMA_VIEW_SECONDARY_LABEL_ABBREVIATE = SchemaViewPreferencePage . ID + "".secondaryLabel.abbreviate"" ; public static final String PREFS_SCHEMA_VIEW_SECONDARY_LABEL_ABBREVIATE_MAX_LENGTH = SchemaViewPreferencePage . ID + "".secondaryLabel.abbreviate.maxLength"" ; public static final String PREFS_SCHEMA_VIEW_SCHEMA_LABEL_DISPLAY = SchemaViewPreferencePage . ID + "".schemaLabel.display"" ; public static final String PREFS_SCHEMA_VIEW_GROUPING = PluginConstants . PLUGIN_ID + "".preferences.SchemaView.grouping"" ; public static final int PREFS_SCHEMA_VIEW_GROUPING_FOLDERS = 0 ; public static final int PREFS_SCHEMA_VIEW_GROUPING_MIXED = 1 ; public static final String PREFS_SCHEMA_VIEW_SORTING_BY = PluginConstants . PLUGIN_ID + "".preferences.SchemaView.sortingBy"" ; public static final int PREFS_SCHEMA_VIEW_SORTING_BY_FIRSTNAME = 0 ; public static final int PREFS_SCHEMA_VIEW_SORTING_BY_OID = 1 ; public static final String PREFS_SCHEMA_VIEW_SORTING_ORDER = PluginConstants . PLUGIN_ID + "".preferences.SchemaView.sortingOrder"" ; public static final int PREFS_SCHEMA_VIEW_SORTING_ORDER_ASCENDING = 0 ; public static final int PREFS_SCHEMA_VIEW_SORTING_ORDER_DESCENDING = 1 ; public static final String PREFS_HIERARCHY_VIEW_MODE = PluginConstants . PLUGIN_ID + "".preferences.HierarchyView.mode"" ; public static final int PREFS_HIERARCHY_VIEW_MODE_SUPERTYPE = 0 ; public static final int PREFS_HIERARCHY_VIEW_MODE_SUBTYPE = 1 ; public static final int PREFS_HIERARCHY_VIEW_MODE_TYPE = 2 ; public static final String PREFS_HIERARCHY_VIEW_LABEL = HierarchyViewPreferencePage . ID + "".label.labelValue"" ; public static final int PREFS_HIERARCHY_VIEW_LABEL_FIRST_NAME = 0 ; public static final int PREFS_HIERARCHY_VIEW_LABEL_ALL_ALIASES = 1 ; public static final int PREFS_HIERARCHY_VIEW_LABEL_OID = 2 ; public static final String PREFS_HIERARCHY_VIEW_ABBREVIATE = HierarchyViewPreferencePage . ID + "".label.abbreviate"" ; public static final String PREFS_HIERARCHY_VIEW_ABBREVIATE_MAX_LENGTH = HierarchyViewPreferencePage . ID + "".label.abbreviate.maxLength"" ; public static final String PREFS_HIERARCHY_VIEW_SECONDARY_LABEL_DISPLAY = HierarchyViewPreferencePage . ID + "".secondaryLabel.display"" ; public static final String PREFS_HIERARCHY_VIEW_SECONDARY_LABEL = HierarchyViewPreferencePage . ID + "".secondaryLabel.labelValue"" ; public static final String PREFS_HIERARCHY_VIEW_SECONDARY_LABEL_ABBREVIATE = HierarchyViewPreferencePage . ID + "".secondaryLabel.abbreviate"" ; public static final String PREFS_HIERARCHY_VIEW_SECONDARY_LABEL_ABBREVIATE_MAX_LENGTH = HierarchyViewPreferencePage . ID + "".secondaryLabel.abbreviate.maxLength"" ; public static final String PREFS_SEARCH_PAGE_SEARCH_HISTORY = PluginConstants . PLUGIN_ID + "".preferences.SearchPage.searchHistory"" ; public static final String PREFS_SEARCH_PAGE_SEARCH_IN_ALIASES = PluginConstants . PLUGIN_ID + "".preferences.SearchPage.scopeAliases"" ; public static final String PREFS_SEARCH_PAGE_SEARCH_IN_OID = PluginConstants . PLUGIN_ID + "".preferences.SearchPage.scopeOid"" ; public static final String PREFS_SEARCH_PAGE_SEARCH_IN_DESCRIPTION = PluginConstants . PLUGIN_ID + "".preferences.SearchPage.scopeDescription"" ; public static final String PREFS_SEARCH_PAGE_SEARCH_IN_SUPERIOR = PluginConstants . PLUGIN_ID + "".preferences.SearchPage.scopeSuperior"" ; public static final String PREFS_SEARCH_PAGE_SEARCH_IN_SYNTAX = PluginConstants . PLUGIN_ID + "".preferences.SearchPage.scopeSyntax"" ; public static final String PREFS_SEARCH_PAGE_SEARCH_IN_MATCHING_RULES = PluginConstants . PLUGIN_ID + "".preferences.SearchPage.scopeMatchingRules"" ; public static final String PREFS_SEARCH_PAGE_SEARCH_IN_SUPERIORS = PluginConstants . PLUGIN_ID + "".preferences.SearchPage.scopeSuperiors"" ; public static final String PREFS_SEARCH_PAGE_SEARCH_IN_MANDATORY_ATTRIBUTES = PluginConstants . PLUGIN_ID + "".preferences.SearchPage.scopeMandatoryAttributes"" ; public static final String PREFS_SEARCH_PAGE_SEARCH_IN_OPTIONAL_ATTRIBUTES = PluginConstants . PLUGIN_ID + "".preferences.SearchPage.scopeOptionalAttributes"" ; public static final String PREFS_SEARCH_PAGE_SCOPE = PluginConstants . PLUGIN_ID + "".preferences.SearchPage.scope"" ; public static final int PREFS_SEARCH_PAGE_SCOPE_AT_AND_OC = 0 ; public static final int PREFS_SEARCH_PAGE_SCOPE_AT_ONLY = 1 ; public static final int PREFS_SEARCH_PAGE_SCOPE_OC_ONLY = 2 ; public static final String PREFS_SEARCH_VIEW_LABEL = SearchViewPreferencePage . ID + "".label.labelValue"" ; public static final int PREFS_SEARCH_VIEW_LABEL_FIRST_NAME = 0 ; public static final int PREFS_SEARCH_VIEW_LABEL_ALL_ALIASES = 1 ; public static final int PREFS_SEARCH_VIEW_LABEL_OID = 2 ; public static final String PREFS_SEARCH_VIEW_ABBREVIATE = SearchViewPreferencePage . ID + "".label.abbreviate"" ; public static final String PREFS_SEARCH_VIEW_ABBREVIATE_MAX_LENGTH = SearchViewPreferencePage . ID + "".label.abbreviate.maxLength"" ; public static final String PREFS_SEARCH_VIEW_SECONDARY_LABEL_DISPLAY = SearchViewPreferencePage . ID + "".secondaryLabel.display"" ; public static final String PREFS_SEARCH_VIEW_SECONDARY_LABEL = SearchViewPreferencePage . ID + "".secondaryLabel.labelValue"" ; public static final String PREFS_SEARCH_VIEW_SECONDARY_LABEL_ABBREVIATE = SearchViewPreferencePage . ID + "".secondaryLabel.abbreviate"" ; public static final String PREFS_SEARCH_VIEW_SECONDARY_LABEL_ABBREVIATE_MAX_LENGTH = SearchViewPreferencePage . ID + "".secondaryLabel.abbreviate.maxLength"" ; public static final String PREFS_SEARCH_VIEW_GROUPING = PluginConstants . PLUGIN_ID + "".preferences.SearchView.grouping"" ; public static final int PREFS_SEARCH_VIEW_GROUPING_ATTRIBUTE_TYPES_FIRST = 0 ; public static final int PREFS_SEARCH_VIEW_GROUPING_OBJECT_CLASSES_FIRST = 1 ; public static final int PREFS_SEARCH_VIEW_GROUPING_MIXED = 2 ; public static final String PREFS_SEARCH_VIEW_SORTING_BY = PluginConstants . PLUGIN_ID + "".preferences.SearchView.sortingBy"" ; public static final int PREFS_SEARCH_VIEW_SORTING_BY_FIRSTNAME = 0 ; public static final int PREFS_SEARCH_VIEW_SORTING_BY_OID = 1 ; public static final String PREFS_SEARCH_VIEW_SORTING_ORDER = PluginConstants . PLUGIN_ID + "".preferences.SchemaView.sortingOrder"" ; public static final int PREFS_SEARCH_VIEW_SORTING_ORDER_ASCENDING = 0 ; public static final int PREFS_SEARCH_VIEW_SORTING_ORDER_DESCENDING = 1 ; public static final String PREFS_SEARCH_VIEW_SCHEMA_LABEL_DISPLAY = SearchViewPreferencePage . ID + "".schemaLabel.display"" ; public static final String CONTEXT_SCHEMA_VIEW = PluginConstants . PLUGIN_ID + "".contexts.schemaView"" ; public static final String CONTEXT_PROJECTS_VIEW = PluginConstants . PLUGIN_ID + "".contexts.projectsView"" ; public static final String FILE_DIALOG_EXPORT_PROJECTS = PluginConstants . PLUGIN_ID + "".fileDialog.exportProjects"" ; public static final String FILE_DIALOG_EXPORT_SCHEMAS_OPENLDAP = PluginConstants . PLUGIN_ID + "".fileDialog.exportSchemasOpenLDAP"" ; public static final String FILE_DIALOG_EXPORT_SCHEMAS_XML = PluginConstants . PLUGIN_ID + "".fileDialog.exportSchemasXML"" ; public static final String FILE_DIALOG_EXPORT_SCHEMAS_APACHE_DS = PluginConstants . PLUGIN_ID + "".fileDialog.exportSchemasApacheDS"" ; public static final String FILE_DIALOG_IMPORT_PROJECTS = PluginConstants . PLUGIN_ID + "".fileDialog.importProjects"" ; public static final String FILE_DIALOG_IMPORT_SCHEMAS_OPENLDAP = PluginConstants . PLUGIN_ID + "".fileDialog.importSchemasOpenLDAP"" ; public static final String FILE_DIALOG_IMPORT_SCHEMAS_XML = PluginConstants . PLUGIN_ID + "".fileDialog.importSchemasXML"" ; public static final String DIALOG_SETTINGS_OID_HISTORY = PluginConstants . PLUGIN_ID + "".dialogSettings.oidHistory"" ; }",Smelly
public class IpForwarding extends ByteOption { public byte getTag ( ) { return 19 ; } },No
"public class TestReplaceText { @ Rule public ExpectedException exception = ExpectedException . none ( ) ; public TestRunner getRunner ( ) { TestRunner runner = TestRunners . newTestRunner ( ReplaceText . class ) ; runner . setValidateExpressionUsage ( false ) ; return runner ; } @ Test public void testConfigurationCornerCase ( ) throws IOException { final TestRunner runner = getRunner ( ) ; runner . run ( ) ; runner . enqueue ( Paths . get ( ""src/test/resources/hello.txt"" ) ) ; runner . run ( ) ; runner . assertAllFlowFilesTransferred ( ReplaceText . REL_SUCCESS , 1 ) ; final MockFlowFile out = runner . getFlowFilesForRelationship ( ReplaceText . REL_SUCCESS ) . get ( 0 ) ; out . assertContentEquals ( Paths . get ( ""src/test/resources/hello.txt"" ) ) ; } @ Test public void testIterativeRegexReplace ( ) { final TestRunner runner = getRunner ( ) ; runner . setProperty ( ReplaceText . SEARCH_VALUE , ""\""([a-z]+?)\"":\""(.*?)\"""" ) ; runner . setProperty ( ReplaceText . REPLACEMENT_VALUE , ""\""${'$1':toUpper()}\"":\""$2\"""" ) ; runner . enqueue ( ""{\""name\"":\""Smith\"",\""middle\"":\""nifi\"",\""firstname\"":\""John\""}"" ) ; runner . run ( ) ; runner . assertAllFlowFilesTransferred ( ReplaceText . REL_SUCCESS , 1 ) ; final MockFlowFile out = runner . getFlowFilesForRelationship ( ReplaceText . REL_SUCCESS ) . get ( 0 ) ; out . assertContentEquals ( ""{\""NAME\"":\""Smith\"",\""MIDDLE\"":\""nifi\"",\""FIRSTNAME\"":\""John\""}"" ) ; } @ Test public void testIterativeRegexReplaceLineByLine ( ) { final TestRunner runner = getRunner ( ) ; runner . setProperty ( ReplaceText . EVALUATION_MODE , ReplaceText . LINE_BY_LINE ) ; runner . setProperty ( ReplaceText . SEARCH_VALUE , ""\""([a-z]+?)\"":\""(.*?)\"""" ) ; runner . setProperty ( ReplaceText . REPLACEMENT_VALUE , ""\""${'$1':toUpper()}\"":\""$2\"""" ) ; runner . enqueue ( ""{\""name\"":\""Smith\"",\""middle\"":\""nifi\"",\""firstname\"":\""John\""}"" ) ; runner . run ( ) ; runner . assertAllFlowFilesTransferred ( ReplaceText . REL_SUCCESS , 1 ) ; final MockFlowFile out = runner . getFlowFilesForRelationship ( ReplaceText . REL_SUCCESS ) . get ( 0 ) ; out . assertContentEquals ( ""{\""NAME\"":\""Smith\"",\""MIDDLE\"":\""nifi\"",\""FIRSTNAME\"":\""John\""}"" ) ; } @ Test public void testSimple ( ) throws IOException { final TestRunner runner = getRunner ( ) ; runner . setProperty ( ReplaceText . SEARCH_VALUE , ""ell"" ) ; runner . setProperty ( ReplaceText . REPLACEMENT_VALUE , ""lle"" ) ; runner . enqueue ( Paths . get ( ""src/test/resources/hello.txt"" ) ) ; runner . run ( ) ; runner . assertAllFlowFilesTransferred ( ReplaceText . REL_SUCCESS , 1 ) ; final MockFlowFile out = runner . getFlowFilesForRelationship ( ReplaceText . REL_SUCCESS ) . get ( 0 ) ; out . assertContentEquals ( ""Hlleo, World!"" . getBytes ( ""UTF-8"" ) ) ; } @ Test public void testWithEscaped$InReplacement ( ) throws IOException { final TestRunner runner = getRunner ( ) ; runner . setProperty ( ReplaceText . SEARCH_VALUE , ""(?s:^.*$)"" ) ; runner . setProperty ( ReplaceText . REPLACEMENT_VALUE , ""a\\$b"" ) ; runner . enqueue ( ""a$a,b,c,d"" ) ; runner . run ( ) ; runner . assertAllFlowFilesTransferred ( ReplaceText . REL_SUCCESS , 1 ) ; final MockFlowFile out = runner . getFlowFilesForRelationship ( ReplaceText . REL_SUCCESS ) . get ( 0 ) ; out . assertContentEquals ( ""a\\$b"" . getBytes ( ""UTF-8"" ) ) ; } @ Test public void testWithUnEscaped$InReplacement ( ) throws IOException { final TestRunner runner = getRunner ( ) ; runner . setProperty ( ReplaceText . SEARCH_VALUE , ""(?s:^.*$)"" ) ; runner . setProperty ( ReplaceText . REPLACEMENT_VALUE , ""a$b"" ) ; runner . enqueue ( ""a$a,b,c,d"" ) ; runner . run ( ) ; runner . assertAllFlowFilesTransferred ( ReplaceText . REL_SUCCESS , 1 ) ; final MockFlowFile out = runner . getFlowFilesForRelationship ( ReplaceText . REL_SUCCESS ) . get ( 0 ) ; out . assertContentEquals ( ""a$b"" . getBytes ( ""UTF-8"" ) ) ; } @ Test public void testPrependSimple ( ) throws IOException { final TestRunner runner = getRunner ( ) ; runner . setProperty ( ReplaceText . REPLACEMENT_VALUE , ""TEST"" ) ; runner . setProperty ( ReplaceText . REPLACEMENT_STRATEGY , ReplaceText . PREPEND ) ; runner . enqueue ( Paths . get ( ""src/test/resources/hello.txt"" ) ) ; runner . run ( ) ; runner . assertAllFlowFilesTransferred ( ReplaceText . REL_SUCCESS , 1 ) ; final MockFlowFile out = runner . getFlowFilesForRelationship ( ReplaceText . REL_SUCCESS ) . get ( 0 ) ; out . assertContentEquals ( ""TESTHello, World!"" . getBytes ( ""UTF-8"" ) ) ; } @ Test public void testPrependLineByLine ( ) throws IOException { final TestRunner runner = getRunner ( ) ; runner . setProperty ( ReplaceText . REPLACEMENT_VALUE , ""_"" ) ; runner . setProperty ( ReplaceText . REPLACEMENT_STRATEGY , ReplaceText . PREPEND ) ; runner . setProperty ( ReplaceText . EVALUATION_MODE , ReplaceText . LINE_BY_LINE ) ; runner . enqueue ( ""hello\nthere\nmadam"" . getBytes ( ) ) ; runner . run ( ) ; runner . assertAllFlowFilesTransferred ( ReplaceText . REL_SUCCESS , 1 ) ; final MockFlowFile out = runner . getFlowFilesForRelationship ( ReplaceText . REL_SUCCESS ) . get ( 0 ) ; out . assertContentEquals ( ""_hello\n_there\n_madam"" . getBytes ( ""UTF-8"" ) ) ; } @ Test public void testAppendSimple ( ) throws IOException { final TestRunner runner = getRunner ( ) ; runner . setProperty ( ReplaceText . REPLACEMENT_VALUE , ""TEST"" ) ; runner . setProperty ( ReplaceText . REPLACEMENT_STRATEGY , ReplaceText . APPEND ) ; runner . enqueue ( Paths . get ( ""src/test/resources/hello.txt"" ) ) ; runner . run ( ) ; runner . assertAllFlowFilesTransferred ( ReplaceText . REL_SUCCESS , 1 ) ; final MockFlowFile out = runner . getFlowFilesForRelationship ( ReplaceText . REL_SUCCESS ) . get ( 0 ) ; out . assertContentEquals ( ""Hello, World!TEST"" . getBytes ( ""UTF-8"" ) ) ; } @ Test public void testAppendWithCarriageReturn ( ) throws IOException { final TestRunner runner = getRunner ( ) ; runner . setProperty ( ReplaceText . REPLACEMENT_VALUE , ""!"" ) ; runner . setProperty ( ReplaceText . REPLACEMENT_STRATEGY , ReplaceText . APPEND ) ; runner . setProperty ( ReplaceText . EVALUATION_MODE , ReplaceText . LINE_BY_LINE ) ; runner . enqueue ( ""hello\rthere\rsir"" . getBytes ( ) ) ; runner . run ( ) ; runner . assertAllFlowFilesTransferred ( ReplaceText . REL_SUCCESS , 1 ) ; final MockFlowFile out = runner . getFlowFilesForRelationship ( ReplaceText . REL_SUCCESS ) . get ( 0 ) ; out . assertContentEquals ( ""hello!\rthere!\rsir!"" ) ; } @ Test public void testAppendWithNewLine ( ) throws IOException { final TestRunner runner = getRunner ( ) ; runner . setProperty ( ReplaceText . REPLACEMENT_VALUE , ""!"" ) ; runner . setProperty ( ReplaceText . REPLACEMENT_STRATEGY , ReplaceText . APPEND ) ; runner . setProperty ( ReplaceText . EVALUATION_MODE , ReplaceText . LINE_BY_LINE ) ; runner . enqueue ( ""hello\nthere\nsir"" . getBytes ( ) ) ; runner . run ( ) ; runner . assertAllFlowFilesTransferred ( ReplaceText . REL_SUCCESS , 1 ) ; final MockFlowFile out = runner . getFlowFilesForRelationship ( ReplaceText . REL_SUCCESS ) . get ( 0 ) ; out . assertContentEquals ( ""hello!\nthere!\nsir!"" ) ; } @ Test public void testAppendWithCarriageReturnNewLine ( ) throws IOException { final TestRunner runner = getRunner ( ) ; runner . setProperty ( ReplaceText . REPLACEMENT_VALUE , ""!"" ) ; runner . setProperty ( ReplaceText . REPLACEMENT_STRATEGY , ReplaceText . APPEND ) ; runner . setProperty ( ReplaceText . EVALUATION_MODE , ReplaceText . LINE_BY_LINE ) ; runner . enqueue ( ""hello\r\nthere\r\nsir"" . getBytes ( ) ) ; runner . run ( ) ; runner . assertAllFlowFilesTransferred ( ReplaceText . REL_SUCCESS , 1 ) ; final MockFlowFile out = runner . getFlowFilesForRelationship ( ReplaceText . REL_SUCCESS ) . get ( 0 ) ; out . assertContentEquals ( ""hello!\r\nthere!\r\nsir!"" ) ; } @ Test public void testLiteralSimple ( ) throws IOException { final TestRunner runner = getRunner ( ) ; runner . setProperty ( ReplaceText . SEARCH_VALUE , ""ell"" ) ; runner . setProperty ( ReplaceText . REPLACEMENT_VALUE , ""lle"" ) ; runner . setProperty ( ReplaceText . REPLACEMENT_STRATEGY , ReplaceText . LITERAL_REPLACE ) ; runner . enqueue ( Paths . get ( ""src/test/resources/hello.txt"" ) ) ; runner . run ( ) ; runner . assertAllFlowFilesTransferred ( ReplaceText . REL_SUCCESS , 1 ) ; final MockFlowFile out = runner . getFlowFilesForRelationship ( ReplaceText . REL_SUCCESS ) . get ( 0 ) ; out . assertContentEquals ( ""Hlleo, World!"" . getBytes ( ""UTF-8"" ) ) ; } @ Test public void testLiteralBackReference ( ) throws IOException { final TestRunner runner = getRunner ( ) ; runner . setProperty ( ReplaceText . SEARCH_VALUE , ""ell"" ) ; runner . setProperty ( ReplaceText . REPLACEMENT_VALUE , ""[$1]"" ) ; runner . setProperty ( ReplaceText . REPLACEMENT_STRATEGY , ReplaceText . LITERAL_REPLACE ) ; runner . enqueue ( Paths . get ( ""src/test/resources/hello.txt"" ) ) ; runner . run ( ) ; runner . assertAllFlowFilesTransferred ( ReplaceText . REL_SUCCESS , 1 ) ; final MockFlowFile out = runner . getFlowFilesForRelationship ( ReplaceText . REL_SUCCESS ) . get ( 0 ) ; out . assertContentEquals ( ""H[$1]o, World!"" ) ; } @ Test public void testLiteral ( ) throws IOException { final TestRunner runner = getRunner ( ) ; runner . setProperty ( ReplaceText . SEARCH_VALUE , "".ell."" ) ; runner . setProperty ( ReplaceText . REPLACEMENT_VALUE , ""test"" ) ; runner . setProperty ( ReplaceText . REPLACEMENT_STRATEGY , ReplaceText . LITERAL_REPLACE ) ; runner . enqueue ( Paths . get ( ""src/test/resources/hello.txt"" ) ) ; runner . run ( ) ; runner . enqueue ( ""H.ell.o, World! .ell."" . getBytes ( ) ) ; runner . run ( ) ; runner . assertAllFlowFilesTransferred ( ReplaceText . REL_SUCCESS , 2 ) ; final MockFlowFile out = runner . getFlowFilesForRelationship ( ReplaceText . REL_SUCCESS ) . get ( 0 ) ; out . assertContentEquals ( ""Hello, World!"" ) ; final MockFlowFile out2 = runner . getFlowFilesForRelationship ( ReplaceText . REL_SUCCESS ) . get ( 1 ) ; out2 . assertContentEquals ( ""Htesto, World! test"" ) ; } @ Test public void testBackReference ( ) throws IOException { final TestRunner runner = getRunner ( ) ; runner . setProperty ( ReplaceText . SEARCH_VALUE , ""(ell)"" ) ; runner . setProperty ( ReplaceText . REPLACEMENT_VALUE , ""[$1]"" ) ; runner . enqueue ( Paths . get ( ""src/test/resources/hello.txt"" ) ) ; runner . run ( ) ; runner . assertAllFlowFilesTransferred ( ReplaceText . REL_SUCCESS , 1 ) ; final MockFlowFile out = runner . getFlowFilesForRelationship ( ReplaceText . REL_SUCCESS ) . get ( 0 ) ; out . assertContentEquals ( ""H[ell]o, World!"" ) ; } @ Test public void testBackRefFollowedByNumbers ( ) throws IOException { final TestRunner runner = getRunner ( ) ; String expected = ""Hell23o, World!"" ; runner . setProperty ( ReplaceText . SEARCH_VALUE , ""(ell)"" ) ; runner . setProperty ( ReplaceText . REPLACEMENT_VALUE , ""$123"" ) ; final Map < String , String > attributes = new HashMap < > ( ) ; attributes . put ( ""abc"" , ""notSupported"" ) ; runner . enqueue ( Paths . get ( ""src/test/resources/hello.txt"" ) , attributes ) ; runner . run ( ) ; runner . assertAllFlowFilesTransferred ( ReplaceText . REL_SUCCESS , 1 ) ; final MockFlowFile out = runner . getFlowFilesForRelationship ( ReplaceText . REL_SUCCESS ) . get ( 0 ) ; final String actual = new String ( out . toByteArray ( ) , StandardCharsets . UTF_8 ) ; System . out . println ( actual ) ; Assert . assertEquals ( expected , actual ) ; } @ Test public void testBackRefWithNoCapturingGroup ( ) throws IOException { final TestRunner runner = getRunner ( ) ; runner . setProperty ( ReplaceText . SEARCH_VALUE , ""ell"" ) ; runner . setProperty ( ReplaceText . REPLACEMENT_VALUE , ""$0123"" ) ; final Map < String , String > attributes = new HashMap < > ( ) ; attributes . put ( ""abc"" , ""notSupported"" ) ; runner . enqueue ( Paths . get ( ""src/test/resources/hello.txt"" ) , attributes ) ; runner . run ( ) ; runner . assertAllFlowFilesTransferred ( ReplaceText . REL_SUCCESS , 1 ) ; final MockFlowFile out = runner . getFlowFilesForRelationship ( ReplaceText . REL_SUCCESS ) . get ( 0 ) ; final String actual = new String ( out . toByteArray ( ) , StandardCharsets . UTF_8 ) ; Assert . assertEquals ( ""Hell123o, World!"" , actual ) ; } @ Test public void testReplacementWithExpressionLanguage ( ) throws IOException { final TestRunner runner = getRunner ( ) ; runner . setProperty ( ReplaceText . SEARCH_VALUE , ""${replaceKey}"" ) ; runner . setProperty ( ReplaceText . REPLACEMENT_VALUE , ""GoodBye"" ) ; final Map < String , String > attributes = new HashMap < > ( ) ; attributes . put ( ""replaceKey"" , ""H.*o"" ) ; runner . enqueue ( Paths . get ( ""src/test/resources/hello.txt"" ) , attributes ) ; runner . run ( ) ; runner . assertAllFlowFilesTransferred ( ReplaceText . REL_SUCCESS , 1 ) ; final MockFlowFile out = runner . getFlowFilesForRelationship ( ReplaceText . REL_SUCCESS ) . get ( 0 ) ; out . assertContentEquals ( ""Hello, World!"" ) ; } @ Test public void testReplacementWithExpressionLanguageIsEscaped ( ) throws IOException { final TestRunner runner = getRunner ( ) ; runner . setProperty ( ReplaceText . SEARCH_VALUE , ""(ell)"" ) ; runner . setProperty ( ReplaceText . REPLACEMENT_VALUE , ""[${abc}]"" ) ; final Map < String , String > attributes = new HashMap < > ( ) ; attributes . put ( ""abc"" , ""$1"" ) ; runner . enqueue ( Paths . get ( ""src/test/resources/hello.txt"" ) , attributes ) ; runner . run ( ) ; runner . assertAllFlowFilesTransferred ( ReplaceText . REL_SUCCESS , 1 ) ; final MockFlowFile out = runner . getFlowFilesForRelationship ( ReplaceText . REL_SUCCESS ) . get ( 0 ) ; out . assertContentEquals ( ""H[$1]o, World!"" ) ; } @ Test public void testRegexWithExpressionLanguage ( ) throws IOException { final TestRunner runner = getRunner ( ) ; runner . setProperty ( ReplaceText . SEARCH_VALUE , ""${replaceKey}"" ) ; runner . setProperty ( ReplaceText . REPLACEMENT_VALUE , ""${replaceValue}"" ) ; final Map < String , String > attributes = new HashMap < > ( ) ; attributes . put ( ""replaceKey"" , ""Hello"" ) ; attributes . put ( ""replaceValue"" , ""Good-bye"" ) ; runner . enqueue ( Paths . get ( ""src/test/resources/hello.txt"" ) , attributes ) ; runner . run ( ) ; runner . assertAllFlowFilesTransferred ( ReplaceText . REL_SUCCESS , 1 ) ; final MockFlowFile out = runner . getFlowFilesForRelationship ( ReplaceText . REL_SUCCESS ) . get ( 0 ) ; out . assertContentEquals ( ""Good-bye, World!"" ) ; } @ Test public void testRegexWithExpressionLanguageIsEscaped ( ) throws IOException { final TestRunner runner = getRunner ( ) ; runner . setProperty ( ReplaceText . SEARCH_VALUE , ""${replaceKey}"" ) ; runner . setProperty ( ReplaceText . REPLACEMENT_VALUE , ""${replaceValue}"" ) ; final Map < String , String > attributes = new HashMap < > ( ) ; attributes . put ( ""replaceKey"" , ""H.*o"" ) ; attributes . put ( ""replaceValue"" , ""Good-bye"" ) ; runner . enqueue ( Paths . get ( ""src/test/resources/hello.txt"" ) , attributes ) ; runner . run ( ) ; runner . assertAllFlowFilesTransferred ( ReplaceText . REL_SUCCESS , 1 ) ; final MockFlowFile out = runner . getFlowFilesForRelationship ( ReplaceText . REL_SUCCESS ) . get ( 0 ) ; out . assertContentEquals ( ""Hello, World!"" ) ; } @ Test public void testBackReferenceWithTooLargeOfIndexIsEscaped ( ) throws IOException { final TestRunner runner = getRunner ( ) ; runner . setProperty ( ReplaceText . SEARCH_VALUE , ""(ell)"" ) ; runner . setProperty ( ReplaceText . REPLACEMENT_VALUE , ""$1$2"" ) ; final Map < String , String > attributes = new HashMap < > ( ) ; attributes . put ( ""replaceKey"" , ""H.*o"" ) ; attributes . put ( ""replaceValue"" , ""Good-bye"" ) ; runner . enqueue ( Paths . get ( ""src/test/resources/hello.txt"" ) , attributes ) ; runner . run ( ) ; runner . assertAllFlowFilesTransferred ( ReplaceText . REL_SUCCESS , 1 ) ; final MockFlowFile out = runner . getFlowFilesForRelationship ( ReplaceText . REL_SUCCESS ) . get ( 0 ) ; out . assertContentEquals ( ""Hell$2o, World!"" ) ; } @ Test public void testBackReferenceWithInvalidReferenceIsEscaped ( ) throws IOException { final TestRunner runner = getRunner ( ) ; runner . setProperty ( ReplaceText . SEARCH_VALUE , ""(ell)"" ) ; runner . setProperty ( ReplaceText . REPLACEMENT_VALUE , ""$d"" ) ; final Map < String , String > attributes = new HashMap < > ( ) ; attributes . put ( ""replaceKey"" , ""H.*o"" ) ; attributes . put ( ""replaceValue"" , ""Good-bye"" ) ; runner . enqueue ( Paths . get ( ""src/test/resources/hello.txt"" ) , attributes ) ; runner . run ( ) ; runner . assertAllFlowFilesTransferred ( ReplaceText . REL_SUCCESS , 1 ) ; final MockFlowFile out = runner . getFlowFilesForRelationship ( ReplaceText . REL_SUCCESS ) . get ( 0 ) ; out . assertContentEquals ( ""H$do, World!"" ) ; } @ Test public void testEscapingDollarSign ( ) throws IOException { final TestRunner runner = getRunner ( ) ; runner . setProperty ( ReplaceText . SEARCH_VALUE , ""(ell)"" ) ; runner . setProperty ( ReplaceText . REPLACEMENT_VALUE , ""\\$1"" ) ; final Map < String , String > attributes = new HashMap < > ( ) ; attributes . put ( ""replaceKey"" , ""H.*o"" ) ; attributes . put ( ""replaceValue"" , ""Good-bye"" ) ; runner . enqueue ( Paths . get ( ""src/test/resources/hello.txt"" ) , attributes ) ; runner . run ( ) ; runner . assertAllFlowFilesTransferred ( ReplaceText . REL_SUCCESS , 1 ) ; final MockFlowFile out = runner . getFlowFilesForRelationship ( ReplaceText . REL_SUCCESS ) . get ( 0 ) ; out . assertContentEquals ( ""H$1o, World!"" ) ; } @ Test public void testReplaceWithEmptyString ( ) throws IOException { final TestRunner runner = getRunner ( ) ; runner . setProperty ( ReplaceText . SEARCH_VALUE , ""(ell)"" ) ; runner . setProperty ( ReplaceText . REPLACEMENT_VALUE , """" ) ; runner . enqueue ( Paths . get ( ""src/test/resources/hello.txt"" ) ) ; runner . run ( ) ; runner . assertAllFlowFilesTransferred ( ReplaceText . REL_SUCCESS , 1 ) ; final MockFlowFile out = runner . getFlowFilesForRelationship ( ReplaceText . REL_SUCCESS ) . get ( 0 ) ; out . assertContentEquals ( ""Ho, World!"" ) ; } @ Test public void testWithNoMatch ( ) throws IOException { final TestRunner runner = getRunner ( ) ; runner . setProperty ( ReplaceText . SEARCH_VALUE , ""Z"" ) ; runner . setProperty ( ReplaceText . REPLACEMENT_VALUE , ""Morning"" ) ; runner . enqueue ( Paths . get ( ""src/test/resources/hello.txt"" ) ) ; runner . run ( ) ; runner . assertAllFlowFilesTransferred ( ReplaceText . REL_SUCCESS , 1 ) ; final MockFlowFile out = runner . getFlowFilesForRelationship ( ReplaceText . REL_SUCCESS ) . get ( 0 ) ; out . assertContentEquals ( ""Hello, World!"" ) ; } @ Test public void testWithMultipleMatches ( ) throws IOException { final TestRunner runner = getRunner ( ) ; runner . setProperty ( ReplaceText . SEARCH_VALUE , ""l"" ) ; runner . setProperty ( ReplaceText . REPLACEMENT_VALUE , ""R"" ) ; runner . enqueue ( Paths . get ( ""src/test/resources/hello.txt"" ) ) ; runner . run ( ) ; runner . assertAllFlowFilesTransferred ( ReplaceText . REL_SUCCESS , 1 ) ; final MockFlowFile out = runner . getFlowFilesForRelationship ( ReplaceText . REL_SUCCESS ) . get ( 0 ) ; out . assertContentEquals ( ""HeRRo, WorRd!"" ) ; } @ Test public void testAttributeToContent ( ) throws IOException { final TestRunner runner = getRunner ( ) ; runner . setProperty ( ReplaceText . SEARCH_VALUE , "".*"" ) ; runner . setProperty ( ReplaceText . REPLACEMENT_VALUE , ""${abc}"" ) ; final Map < String , String > attributes = new HashMap < > ( ) ; attributes . put ( ""abc"" , ""Good"" ) ; runner . enqueue ( Paths . get ( ""src/test/resources/hello.txt"" ) , attributes ) ; runner . run ( ) ; runner . assertAllFlowFilesTransferred ( ReplaceText . REL_SUCCESS , 1 ) ; final MockFlowFile out = runner . getFlowFilesForRelationship ( ReplaceText . REL_SUCCESS ) . get ( 0 ) ; out . assertContentEquals ( ""Good"" ) ; } @ Test public void testRoutesToFailureIfTooLarge ( ) throws IOException { final TestRunner runner = getRunner ( ) ; runner . setProperty ( ReplaceText . SEARCH_VALUE , ""[123]"" ) ; runner . setProperty ( ReplaceText . MAX_BUFFER_SIZE , ""1 b"" ) ; runner . setProperty ( ReplaceText . REPLACEMENT_VALUE , ""${abc}"" ) ; final Map < String , String > attributes = new HashMap < > ( ) ; attributes . put ( ""abc"" , ""Good"" ) ; runner . enqueue ( Paths . get ( ""src/test/resources/hello.txt"" ) , attributes ) ; runner . run ( ) ; runner . assertAllFlowFilesTransferred ( ReplaceText . REL_FAILURE , 1 ) ; } @ Test public void testRoutesToSuccessIfTooLargeButRegexIsDotAsterisk ( ) throws IOException { final TestRunner runner = getRunner ( ) ; runner . setProperty ( ReplaceText . SEARCH_VALUE , "".*"" ) ; runner . setProperty ( ReplaceText . MAX_BUFFER_SIZE , ""1 b"" ) ; runner . setProperty ( ReplaceText . REPLACEMENT_VALUE , ""${abc}"" ) ; final Map < String , String > attributes = new HashMap < > ( ) ; attributes . put ( ""abc"" , ""Good"" ) ; runner . enqueue ( Paths . get ( ""src/test/resources/hello.txt"" ) , attributes ) ; runner . run ( ) ; runner . assertAllFlowFilesTransferred ( ReplaceText . REL_SUCCESS , 1 ) ; final MockFlowFile out = runner . getFlowFilesForRelationship ( ReplaceText . REL_SUCCESS ) . get ( 0 ) ; out . assertContentEquals ( ""Good"" ) ; } @ Test public void testProblematicCase1 ( ) throws IOException { final TestRunner runner = getRunner ( ) ; runner . setProperty ( ReplaceText . SEARCH_VALUE , "".*"" ) ; runner . setProperty ( ReplaceText . REPLACEMENT_VALUE , ""${filename}\t${now():format(\""yyyy/MM/dd'T'HHmmss'Z'\"")}\t${fileSize}\n"" ) ; final Map < String , String > attributes = new HashMap < > ( ) ; attributes . put ( ""filename"" , ""abc.txt"" ) ; runner . enqueue ( Paths . get ( ""src/test/resources/hello.txt"" ) , attributes ) ; runner . run ( ) ; runner . assertAllFlowFilesTransferred ( ReplaceText . REL_SUCCESS , 1 ) ; final MockFlowFile out = runner . getFlowFilesForRelationship ( ReplaceText . REL_SUCCESS ) . get ( 0 ) ; final String outContent = new String ( out . toByteArray ( ) , StandardCharsets . UTF_8 ) ; Assert . assertTrue ( outContent . startsWith ( ""abc.txt\t"" ) ) ; System . out . println ( outContent ) ; Assert . assertTrue ( outContent . endsWith ( ""13\n"" ) ) ; } @ Test public void testGetExistingContent ( ) throws IOException { final TestRunner runner = getRunner ( ) ; runner . setProperty ( ReplaceText . SEARCH_VALUE , ""(?s)(^.*)"" ) ; runner . setProperty ( ReplaceText . REPLACEMENT_VALUE , ""attribute header\n\n${filename}\n\ndata header\n\n$1\n\nfooter"" ) ; final Map < String , String > attributes = new HashMap < > ( ) ; attributes . put ( ""filename"" , ""abc.txt"" ) ; runner . enqueue ( ""Hello\nWorld!"" . getBytes ( ) , attributes ) ; runner . run ( ) ; runner . assertAllFlowFilesTransferred ( ReplaceText . REL_SUCCESS , 1 ) ; final MockFlowFile out = runner . getFlowFilesForRelationship ( ReplaceText . REL_SUCCESS ) . get ( 0 ) ; final String outContent = new String ( out . toByteArray ( ) , StandardCharsets . UTF_8 ) ; Assert . assertTrue ( outContent . equals ( ""attribute header\n\nabc.txt\n\ndata header\n\nHello\nWorld!\n\nfooter"" ) ) ; System . out . println ( outContent ) ; } @ Test public void testReplaceWithinCurlyBraces ( ) throws IOException { final TestRunner runner = getRunner ( ) ; runner . setProperty ( ReplaceText . SEARCH_VALUE , "".+"" ) ; runner . setProperty ( ReplaceText . REPLACEMENT_VALUE , ""{ ${filename} }"" ) ; final Map < String , String > attributes = new HashMap < > ( ) ; attributes . put ( ""filename"" , ""abc.txt"" ) ; runner . enqueue ( ""Hello"" . getBytes ( ) , attributes ) ; runner . run ( ) ; runner . assertAllFlowFilesTransferred ( ReplaceText . REL_SUCCESS , 1 ) ; final MockFlowFile out = runner . getFlowFilesForRelationship ( ReplaceText . REL_SUCCESS ) . get ( 0 ) ; out . assertContentEquals ( ""{ abc.txt }"" ) ; } @ Test public void testDefaultReplacement ( ) throws Exception { final String defaultValue = ""default-replacement-value"" ; final TestRunner runner = getRunner ( ) ; runner . setProperty ( ReplaceText . REPLACEMENT_VALUE , defaultValue ) ; final Map < String , String > attributes = new HashMap < > ( ) ; runner . enqueue ( ""original-text"" . getBytes ( StandardCharsets . UTF_8 ) , attributes ) ; runner . run ( ) ; runner . assertAllFlowFilesTransferred ( ReplaceText . REL_SUCCESS , 1 ) ; final MockFlowFile out = runner . getFlowFilesForRelationship ( ReplaceText . REL_SUCCESS ) . get ( 0 ) ; out . assertContentEquals ( defaultValue ) ; } @ Test public void testDefaultMultilineReplacement ( ) throws Exception { final String defaultValue = ""default-replacement-value"" ; final TestRunner runner = getRunner ( ) ; runner . setProperty ( ReplaceText . REPLACEMENT_VALUE , defaultValue ) ; final Map < String , String > attributes = new HashMap < > ( ) ; runner . enqueue ( ( ""original-text-line-1"" + System . lineSeparator ( ) + ""original-text-line-2"" ) . getBytes ( StandardCharsets . UTF_8 ) , attributes ) ; runner . run ( ) ; runner . assertAllFlowFilesTransferred ( ReplaceText . REL_SUCCESS , 1 ) ; final MockFlowFile out = runner . getFlowFilesForRelationship ( ReplaceText . REL_SUCCESS ) . get ( 0 ) ; out . assertContentEquals ( defaultValue ) ; } @ Test public void testSimpleLineByLine ( ) throws IOException { final TestRunner runner = getRunner ( ) ; runner . setProperty ( ReplaceText . EVALUATION_MODE , ReplaceText . LINE_BY_LINE ) ; runner . setProperty ( ReplaceText . SEARCH_VALUE , ""odo"" ) ; runner . setProperty ( ReplaceText . REPLACEMENT_VALUE , ""ood"" ) ; runner . enqueue ( translateNewLines ( Paths . get ( ""src/test/resources/TestReplaceTextLineByLine/testFile.txt"" ) ) ) ; runner . run ( ) ; runner . assertAllFlowFilesTransferred ( ReplaceText . REL_SUCCESS , 1 ) ; final MockFlowFile out = runner . getFlowFilesForRelationship ( ReplaceText . REL_SUCCESS ) . get ( 0 ) ; out . assertContentEquals ( translateNewLines ( new File ( ""src/test/resources/TestReplaceTextLineByLine/food.txt"" ) ) ) ; } @ Test public void testPrependSimpleLineByLine ( ) throws IOException { final TestRunner runner = getRunner ( ) ; runner . setProperty ( ReplaceText . EVALUATION_MODE , ReplaceText . LINE_BY_LINE ) ; runner . setProperty ( ReplaceText . REPLACEMENT_STRATEGY , ReplaceText . PREPEND ) ; runner . setProperty ( ReplaceText . REPLACEMENT_VALUE , ""TEST "" ) ; runner . enqueue ( translateNewLines ( Paths . get ( ""src/test/resources/TestReplaceTextLineByLine/testFile.txt"" ) ) ) ; runner . run ( ) ; runner . assertAllFlowFilesTransferred ( ReplaceText . REL_SUCCESS , 1 ) ; final MockFlowFile out = runner . getFlowFilesForRelationship ( ReplaceText . REL_SUCCESS ) . get ( 0 ) ; out . assertContentEquals ( translateNewLines ( new File ( ""src/test/resources/TestReplaceTextLineByLine/PrependLineByLineTest.txt"" ) ) ) ; } @ Test public void testAppendSimpleLineByLine ( ) throws IOException { final TestRunner runner = getRunner ( ) ; runner . setProperty ( ReplaceText . EVALUATION_MODE , ReplaceText . LINE_BY_LINE ) ; runner . setProperty ( ReplaceText . REPLACEMENT_STRATEGY , ReplaceText . APPEND ) ; runner . setProperty ( ReplaceText . REPLACEMENT_VALUE , "" TEST"" ) ; runner . enqueue ( translateNewLines ( Paths . get ( ""src/test/resources/TestReplaceTextLineByLine/testFile.txt"" ) ) ) ; runner . run ( ) ; runner . assertAllFlowFilesTransferred ( ReplaceText . REL_SUCCESS , 1 ) ; final MockFlowFile out = runner . getFlowFilesForRelationship ( ReplaceText . REL_SUCCESS ) . get ( 0 ) ; out . assertContentEquals ( translateNewLines ( new File ( ""src/test/resources/TestReplaceTextLineByLine/AppendLineByLineTest.txt"" ) ) ) ; } @ Test public void testAppendEndlineCR ( ) throws IOException { final TestRunner runner = getRunner ( ) ; runner . setProperty ( ReplaceText . EVALUATION_MODE , ReplaceText . LINE_BY_LINE ) ; runner . setProperty ( ReplaceText . REPLACEMENT_VALUE , ""TEST"" ) ; runner . setProperty ( ReplaceText . REPLACEMENT_STRATEGY , ReplaceText . APPEND ) ; runner . enqueue ( ""Hello \rWorld \r"" . getBytes ( ) ) ; runner . run ( ) ; runner . assertAllFlowFilesTransferred ( ReplaceText . REL_SUCCESS , 1 ) ; final MockFlowFile out = runner . getFlowFilesForRelationship ( ReplaceText . REL_SUCCESS ) . get ( 0 ) ; out . assertContentEquals ( ""Hello TEST\rWorld TEST\r"" . getBytes ( ""UTF-8"" ) ) ; } @ Test public void testAppendEndlineCRLF ( ) throws IOException { final TestRunner runner = getRunner ( ) ; runner . setProperty ( ReplaceText . EVALUATION_MODE , ReplaceText . LINE_BY_LINE ) ; runner . setProperty ( ReplaceText . REPLACEMENT_VALUE , ""TEST"" ) ; runner . setProperty ( ReplaceText . REPLACEMENT_STRATEGY , ReplaceText . APPEND ) ; runner . enqueue ( ""Hello \r\nWorld \r\n"" . getBytes ( ) ) ; runner . run ( ) ; runner . assertAllFlowFilesTransferred ( ReplaceText . REL_SUCCESS , 1 ) ; final MockFlowFile out = runner . getFlowFilesForRelationship ( ReplaceText . REL_SUCCESS ) . get ( 0 ) ; out . assertContentEquals ( ""Hello TEST\r\nWorld TEST\r\n"" . getBytes ( ""UTF-8"" ) ) ; } @ Test public void testSimpleLiteral ( ) throws IOException { final TestRunner runner = getRunner ( ) ; runner . setProperty ( ReplaceText . EVALUATION_MODE , ReplaceText . LINE_BY_LINE ) ; runner . setProperty ( ReplaceText . SEARCH_VALUE , ""odo"" ) ; runner . setProperty ( ReplaceText . REPLACEMENT_VALUE , ""ood"" ) ; runner . setProperty ( ReplaceText . REPLACEMENT_STRATEGY , ReplaceText . LITERAL_REPLACE ) ; runner . enqueue ( translateNewLines ( Paths . get ( ""src/test/resources/TestReplaceTextLineByLine/testFile.txt"" ) ) ) ; runner . run ( ) ; runner . assertAllFlowFilesTransferred ( ReplaceText . REL_SUCCESS , 1 ) ; final MockFlowFile out = runner . getFlowFilesForRelationship ( ReplaceText . REL_SUCCESS ) . get ( 0 ) ; out . assertContentEquals ( translateNewLines ( new File ( ""src/test/resources/TestReplaceTextLineByLine/food.txt"" ) ) ) ; } @ Test public void testLiteralBackReferenceLineByLine ( ) throws IOException { final TestRunner runner = getRunner ( ) ; runner . setProperty ( ReplaceText . EVALUATION_MODE , ReplaceText . LINE_BY_LINE ) ; runner . setProperty ( ReplaceText . SEARCH_VALUE , ""jo"" ) ; runner . setProperty ( ReplaceText . REPLACEMENT_VALUE , ""[$1]"" ) ; runner . setProperty ( ReplaceText . REPLACEMENT_STRATEGY , ReplaceText . LITERAL_REPLACE ) ; runner . enqueue ( translateNewLines ( Paths . get ( ""src/test/resources/TestReplaceTextLineByLine/testFile.txt"" ) ) ) ; runner . run ( ) ; runner . assertAllFlowFilesTransferred ( ReplaceText . REL_SUCCESS , 1 ) ; final MockFlowFile out = runner . getFlowFilesForRelationship ( ReplaceText . REL_SUCCESS ) . get ( 0 ) ; out . assertContentEquals ( translateNewLines ( new File ( ""src/test/resources/TestReplaceTextLineByLine/cu[$1]_Po[$1].txt"" ) ) ) ; } @ Test public void testLiteralLineByLine ( ) throws IOException { final TestRunner runner = getRunner ( ) ; runner . setProperty ( ReplaceText . EVALUATION_MODE , ReplaceText . LINE_BY_LINE ) ; runner . setProperty ( ReplaceText . SEARCH_VALUE , "".ell."" ) ; runner . setProperty ( ReplaceText . REPLACEMENT_VALUE , ""test"" ) ; runner . setProperty ( ReplaceText . REPLACEMENT_STRATEGY , ReplaceText . LITERAL_REPLACE ) ; runner . enqueue ( ""H.ell.o, World! .ell. \n .ell. .ell."" . getBytes ( ) ) ; runner . run ( ) ; runner . assertAllFlowFilesTransferred ( ReplaceText . REL_SUCCESS , 1 ) ; final MockFlowFile out = runner . getFlowFilesForRelationship ( ReplaceText . REL_SUCCESS ) . get ( 0 ) ; out . assertContentEquals ( ""Htesto, World! test \n test test"" ) ; } @ Test public void testBackReferenceLineByLine ( ) throws IOException { final TestRunner runner = getRunner ( ) ; runner . setProperty ( ReplaceText . EVALUATION_MODE , ReplaceText . LINE_BY_LINE ) ; runner . setProperty ( ReplaceText . SEARCH_VALUE , ""(DODO)"" ) ; runner . setProperty ( ReplaceText . REPLACEMENT_VALUE , ""[$1]"" ) ; runner . enqueue ( translateNewLines ( Paths . get ( ""src/test/resources/TestReplaceTextLineByLine/testFile.txt"" ) ) ) ; runner . run ( ) ; runner . assertAllFlowFilesTransferred ( ReplaceText . REL_SUCCESS , 1 ) ; final MockFlowFile out = runner . getFlowFilesForRelationship ( ReplaceText . REL_SUCCESS ) . get ( 0 ) ; out . assertContentEquals ( translateNewLines ( new File ( ""src/test/resources/TestReplaceTextLineByLine/[DODO].txt"" ) ) ) ; } @ Test public void testReplacementWithExpressionLanguageIsEscapedLineByLine ( ) throws IOException { final TestRunner runner = getRunner ( ) ; runner . setProperty ( ReplaceText . EVALUATION_MODE , ReplaceText . LINE_BY_LINE ) ; runner . setProperty ( ReplaceText . SEARCH_VALUE , ""(jo)"" ) ; runner . setProperty ( ReplaceText . REPLACEMENT_VALUE , ""[${abc}]"" ) ; final Map < String , String > attributes = new HashMap < > ( ) ; attributes . put ( ""abc"" , ""$1"" ) ; runner . enqueue ( translateNewLines ( Paths . get ( ""src/test/resources/TestReplaceTextLineByLine/testFile.txt"" ) ) , attributes ) ; runner . run ( ) ; runner . assertAllFlowFilesTransferred ( ReplaceText . REL_SUCCESS , 1 ) ; final MockFlowFile out = runner . getFlowFilesForRelationship ( ReplaceText . REL_SUCCESS ) . get ( 0 ) ; out . assertContentEquals ( translateNewLines ( new File ( ""src/test/resources/TestReplaceTextLineByLine/cu[$1]_Po[$1].txt"" ) ) ) ; } @ Test public void testRegexWithExpressionLanguageLineByLine ( ) throws IOException { final TestRunner runner = getRunner ( ) ; runner . setProperty ( ReplaceText . EVALUATION_MODE , ReplaceText . LINE_BY_LINE ) ; runner . setProperty ( ReplaceText . SEARCH_VALUE , ""${replaceKey}"" ) ; runner . setProperty ( ReplaceText . REPLACEMENT_VALUE , ""${replaceValue}"" ) ; final Map < String , String > attributes = new HashMap < > ( ) ; attributes . put ( ""replaceKey"" , ""Riley"" ) ; attributes . put ( ""replaceValue"" , ""Spider"" ) ; runner . enqueue ( translateNewLines ( Paths . get ( ""src/test/resources/TestReplaceTextLineByLine/testFile.txt"" ) ) , attributes ) ; runner . run ( ) ; runner . assertAllFlowFilesTransferred ( ReplaceText . REL_SUCCESS , 1 ) ; final MockFlowFile out = runner . getFlowFilesForRelationship ( ReplaceText . REL_SUCCESS ) . get ( 0 ) ; out . assertContentEquals ( translateNewLines ( new File ( ""src/test/resources/TestReplaceTextLineByLine/Spider.txt"" ) ) ) ; } @ Test public void testRegexWithExpressionLanguageIsEscapedLineByLine ( ) throws IOException { final TestRunner runner = getRunner ( ) ; runner . setProperty ( ReplaceText . EVALUATION_MODE , ReplaceText . LINE_BY_LINE ) ; runner . setProperty ( ReplaceText . SEARCH_VALUE , ""${replaceKey}"" ) ; runner . setProperty ( ReplaceText . REPLACEMENT_VALUE , ""${replaceValue}"" ) ; final Map < String , String > attributes = new HashMap < > ( ) ; attributes . put ( ""replaceKey"" , ""R.*y"" ) ; attributes . put ( ""replaceValue"" , ""Spider"" ) ; runner . enqueue ( translateNewLines ( Paths . get ( ""src/test/resources/TestReplaceTextLineByLine/testFile.txt"" ) ) , attributes ) ; runner . run ( ) ; runner . assertAllFlowFilesTransferred ( ReplaceText . REL_SUCCESS , 1 ) ; final MockFlowFile out = runner . getFlowFilesForRelationship ( ReplaceText . REL_SUCCESS ) . get ( 0 ) ; out . assertContentEquals ( translateNewLines ( new File ( ""src/test/resources/TestReplaceTextLineByLine/testFile.txt"" ) ) ) ; } @ Test public void testBackReferenceWithTooLargeOfIndexIsEscapedLineByLine ( ) throws IOException { final TestRunner runner = getRunner ( ) ; runner . setProperty ( ReplaceText . EVALUATION_MODE , ReplaceText . LINE_BY_LINE ) ; runner . setProperty ( ReplaceText . SEARCH_VALUE , ""(lu)"" ) ; runner . setProperty ( ReplaceText . REPLACEMENT_VALUE , ""$1$2"" ) ; final Map < String , String > attributes = new HashMap < > ( ) ; attributes . put ( ""replaceKey"" , ""R.*y"" ) ; attributes . put ( ""replaceValue"" , ""Spiderman"" ) ; runner . enqueue ( translateNewLines ( Paths . get ( ""src/test/resources/TestReplaceTextLineByLine/testFile.txt"" ) ) , attributes ) ; runner . run ( ) ; runner . assertAllFlowFilesTransferred ( ReplaceText . REL_SUCCESS , 1 ) ; final MockFlowFile out = runner . getFlowFilesForRelationship ( ReplaceText . REL_SUCCESS ) . get ( 0 ) ; out . assertContentEquals ( translateNewLines ( new File ( ""src/test/resources/TestReplaceTextLineByLine/Blu$2e_clu$2e.txt"" ) ) ) ; } @ Test public void testBackReferenceWithInvalidReferenceIsEscapedLineByLine ( ) throws IOException { final TestRunner runner = getRunner ( ) ; runner . setProperty ( ReplaceText . EVALUATION_MODE , ReplaceText . LINE_BY_LINE ) ; runner . setProperty ( ReplaceText . SEARCH_VALUE , ""(ew)"" ) ; runner . setProperty ( ReplaceText . REPLACEMENT_VALUE , ""$d"" ) ; final Map < String , String > attributes = new HashMap < > ( ) ; attributes . put ( ""replaceKey"" , ""H.*o"" ) ; attributes . put ( ""replaceValue"" , ""Good-bye"" ) ; runner . enqueue ( translateNewLines ( Paths . get ( ""src/test/resources/TestReplaceTextLineByLine/testFile.txt"" ) ) , attributes ) ; runner . run ( ) ; runner . assertAllFlowFilesTransferred ( ReplaceText . REL_SUCCESS , 1 ) ; final MockFlowFile out = runner . getFlowFilesForRelationship ( ReplaceText . REL_SUCCESS ) . get ( 0 ) ; out . assertContentEquals ( translateNewLines ( new File ( ""src/test/resources/TestReplaceTextLineByLine/D$d_h$d.txt"" ) ) ) ; } @ Test public void testEscapingDollarSignLineByLine ( ) throws IOException { final TestRunner runner = getRunner ( ) ; runner . setProperty ( ReplaceText . EVALUATION_MODE , ReplaceText . LINE_BY_LINE ) ; runner . setProperty ( ReplaceText . SEARCH_VALUE , ""(DO)"" ) ; runner . setProperty ( ReplaceText . REPLACEMENT_VALUE , ""\\$1"" ) ; final Map < String , String > attributes = new HashMap < > ( ) ; attributes . put ( ""replaceKey"" , ""H.*o"" ) ; attributes . put ( ""replaceValue"" , ""Good-bye"" ) ; runner . enqueue ( translateNewLines ( Paths . get ( ""src/test/resources/TestReplaceTextLineByLine/testFile.txt"" ) ) , attributes ) ; runner . run ( ) ; runner . assertAllFlowFilesTransferred ( ReplaceText . REL_SUCCESS , 1 ) ; final MockFlowFile out = runner . getFlowFilesForRelationship ( ReplaceText . REL_SUCCESS ) . get ( 0 ) ; out . assertContentEquals ( translateNewLines ( new File ( ""src/test/resources/TestReplaceTextLineByLine/$1$1.txt"" ) ) ) ; } @ Test public void testReplaceWithEmptyStringLineByLine ( ) throws IOException { final TestRunner runner = getRunner ( ) ; runner . setProperty ( ReplaceText . EVALUATION_MODE , ReplaceText . LINE_BY_LINE ) ; runner . setProperty ( ReplaceText . SEARCH_VALUE , ""(jo)"" ) ; runner . setProperty ( ReplaceText . REPLACEMENT_VALUE , """" ) ; runner . enqueue ( translateNewLines ( Paths . get ( ""src/test/resources/TestReplaceTextLineByLine/testFile.txt"" ) ) ) ; runner . run ( ) ; runner . assertAllFlowFilesTransferred ( ReplaceText . REL_SUCCESS , 1 ) ; final MockFlowFile out = runner . getFlowFilesForRelationship ( ReplaceText . REL_SUCCESS ) . get ( 0 ) ; out . assertContentEquals ( translateNewLines ( new File ( ""src/test/resources/TestReplaceTextLineByLine/cu_Po.txt"" ) ) ) ; } @ Test public void testWithNoMatchLineByLine ( ) throws IOException { final TestRunner runner = getRunner ( ) ; runner . setProperty ( ReplaceText . EVALUATION_MODE , ReplaceText . LINE_BY_LINE ) ; runner . setProperty ( ReplaceText . SEARCH_VALUE , ""Z"" ) ; runner . setProperty ( ReplaceText . REPLACEMENT_VALUE , ""Morning"" ) ; runner . enqueue ( translateNewLines ( Paths . get ( ""src/test/resources/TestReplaceTextLineByLine/testFile.txt"" ) ) ) ; runner . run ( ) ; runner . assertAllFlowFilesTransferred ( ReplaceText . REL_SUCCESS , 1 ) ; final MockFlowFile out = runner . getFlowFilesForRelationship ( ReplaceText . REL_SUCCESS ) . get ( 0 ) ; out . assertContentEquals ( translateNewLines ( new File ( ""src/test/resources/TestReplaceTextLineByLine/testFile.txt"" ) ) ) ; } @ Test public void testWithMultipleMatchesLineByLine ( ) throws IOException { final TestRunner runner = getRunner ( ) ; runner . setProperty ( ReplaceText . EVALUATION_MODE , ReplaceText . LINE_BY_LINE ) ; runner . setProperty ( ReplaceText . SEARCH_VALUE , ""l"" ) ; runner . setProperty ( ReplaceText . REPLACEMENT_VALUE , ""R"" ) ; runner . enqueue ( translateNewLines ( Paths . get ( ""src/test/resources/TestReplaceTextLineByLine/testFile.txt"" ) ) ) ; runner . run ( ) ; runner . assertAllFlowFilesTransferred ( ReplaceText . REL_SUCCESS , 1 ) ; final MockFlowFile out = runner . getFlowFilesForRelationship ( ReplaceText . REL_SUCCESS ) . get ( 0 ) ; out . assertContentEquals ( translateNewLines ( new File ( ""src/test/resources/TestReplaceTextLineByLine/BRue_cRue_RiRey.txt"" ) ) ) ; } @ Test public void testAttributeToContentLineByLine ( ) throws IOException { final TestRunner runner = getRunner ( ) ; runner . setProperty ( ReplaceText . EVALUATION_MODE , ReplaceText . LINE_BY_LINE ) ; runner . setProperty ( ReplaceText . SEARCH_VALUE , "".*"" ) ; runner . setProperty ( ReplaceText . REPLACEMENT_VALUE , ""${abc}"" ) ; final Map < String , String > attributes = new HashMap < > ( ) ; attributes . put ( ""abc"" , ""Good"" ) ; runner . enqueue ( Paths . get ( ""src/test/resources/TestReplaceTextLineByLine/testFile.txt"" ) , attributes ) ; runner . run ( ) ; runner . assertAllFlowFilesTransferred ( ReplaceText . REL_SUCCESS , 1 ) ; final MockFlowFile out = runner . getFlowFilesForRelationship ( ReplaceText . REL_SUCCESS ) . get ( 0 ) ; out . assertContentEquals ( ""Good\nGood\nGood\nGood\nGood\nGood\nGood\nGood\nGood\nGood\nGood"" ) ; } @ Test public void testAttributeToContentWindows ( ) throws IOException { final TestRunner runner = getRunner ( ) ; runner . setProperty ( ReplaceText . EVALUATION_MODE , ReplaceText . LINE_BY_LINE ) ; runner . setProperty ( ReplaceText . SEARCH_VALUE , "".*"" ) ; runner . setProperty ( ReplaceText . REPLACEMENT_VALUE , ""${abc}"" ) ; final Map < String , String > attributes = new HashMap < > ( ) ; attributes . put ( ""abc"" , ""Good"" ) ; runner . enqueue ( ""<<<HEADER>>>\r\n<<BODY>>\r\n<<<FOOTER>>>\r"" . getBytes ( ) , attributes ) ; runner . run ( ) ; runner . assertAllFlowFilesTransferred ( ReplaceText . REL_SUCCESS , 1 ) ; final MockFlowFile out = runner . getFlowFilesForRelationship ( ReplaceText . REL_SUCCESS ) . get ( 0 ) ; out . assertContentEquals ( ""Good\r\nGood\r\nGood\r"" ) ; } @ Test public void testProblematicCase1LineByLine ( ) throws IOException { final TestRunner runner = getRunner ( ) ; runner . setProperty ( ReplaceText . EVALUATION_MODE , ReplaceText . LINE_BY_LINE ) ; runner . setProperty ( ReplaceText . SEARCH_VALUE , "".*"" ) ; runner . setProperty ( ReplaceText . REPLACEMENT_VALUE , ""${filename}\t${now():format(\""yyyy/MM/dd'T'HHmmss'Z'\"")}\t${fileSize}\n"" ) ; final Map < String , String > attributes = new HashMap < > ( ) ; attributes . put ( ""filename"" , ""abc.txt"" ) ; runner . enqueue ( translateNewLines ( Paths . get ( ""src/test/resources/TestReplaceTextLineByLine/testFile.txt"" ) ) , attributes ) ; runner . run ( ) ; runner . assertAllFlowFilesTransferred ( ReplaceText . REL_SUCCESS , 1 ) ; final MockFlowFile out = runner . getFlowFilesForRelationship ( ReplaceText . REL_SUCCESS ) . get ( 0 ) ; final String outContent = translateNewLines ( new String ( out . toByteArray ( ) , StandardCharsets . UTF_8 ) ) ; Assert . assertTrue ( outContent . startsWith ( ""abc.txt\t"" ) ) ; System . out . println ( outContent ) ; Assert . assertTrue ( outContent . endsWith ( ""193\n"" ) || outContent . endsWith ( ""203\r\n"" ) ) ; } @ Test public void testGetExistingContentLineByLine ( ) throws IOException { final TestRunner runner = getRunner ( ) ; runner . setProperty ( ReplaceText . EVALUATION_MODE , ReplaceText . LINE_BY_LINE ) ; runner . setProperty ( ReplaceText . SEARCH_VALUE , ""(?s)(^.*)"" ) ; runner . setProperty ( ReplaceText . REPLACEMENT_VALUE , ""attribute header\n\n${filename}\n\ndata header\n\n$1\n\nfooter\n"" ) ; final Map < String , String > attributes = new HashMap < > ( ) ; attributes . put ( ""filename"" , ""abc.txt"" ) ; runner . enqueue ( ""Hello\nWorld!"" . getBytes ( ) , attributes ) ; runner . run ( ) ; runner . assertAllFlowFilesTransferred ( ReplaceText . REL_SUCCESS , 1 ) ; final MockFlowFile out = runner . getFlowFilesForRelationship ( ReplaceText . REL_SUCCESS ) . get ( 0 ) ; final String outContent = new String ( out . toByteArray ( ) , StandardCharsets . UTF_8 ) ; System . out . println ( outContent ) ; Assert . assertTrue ( outContent . equals ( ""attribute header\n\nabc.txt\n\ndata header\n\nHello\n\n\nfooter\n"" + ""attribute header\n\nabc.txt\n\ndata header\n\nWorld!\n\nfooter\n"" ) ) ; } @ Test public void testCapturingGroupInExpressionLanguage ( ) { final TestRunner runner = getRunner ( ) ; runner . setProperty ( ReplaceText . EVALUATION_MODE , ReplaceText . LINE_BY_LINE ) ; runner . setProperty ( ReplaceText . SEARCH_VALUE , ""(.*?),(.*?),(\\d+.*)"" ) ; runner . setProperty ( ReplaceText . REPLACEMENT_VALUE , ""$1,$2,${ '$3':toDate('ddMMMyyyy'):format('yyyy/MM/dd') }"" ) ; final String csvIn = ""2006,10-01-2004,10may2004\n"" + ""2007,15-05-2006,10jun2005\r\n"" + ""2009,8-8-2008,10aug2008"" ; final String expectedCsvOut = ""2006,10-01-2004,2004/05/10\n"" + ""2007,15-05-2006,2005/06/10\r\n"" + ""2009,8-8-2008,2008/08/10"" ; runner . enqueue ( csvIn . getBytes ( ) ) ; runner . run ( ) ; runner . assertAllFlowFilesTransferred ( ReplaceText . REL_SUCCESS , 1 ) ; final MockFlowFile out = runner . getFlowFilesForRelationship ( ReplaceText . REL_SUCCESS ) . get ( 0 ) ; out . assertContentEquals ( expectedCsvOut ) ; } @ Test public void testCapturingGroupInExpressionLanguage2 ( ) { final TestRunner runner = getRunner ( ) ; runner . setProperty ( ReplaceText . EVALUATION_MODE , ReplaceText . LINE_BY_LINE ) ; runner . setProperty ( ReplaceText . SEARCH_VALUE , ""(.*)/(.*?).jpg"" ) ; runner . setProperty ( ReplaceText . REPLACEMENT_VALUE , ""$1/${ '$2':substring(0,1) }.png"" ) ; final String csvIn = ""1,2,3,https://123.jpg,email@mydomain.com\n"" + ""3,2,1,https://321.jpg,other.email@mydomain.com"" ; final String expectedCsvOut = ""1,2,3,https://1.png,email@mydomain.com\n"" + ""3,2,1,https://3.png,other.email@mydomain.com"" ; runner . enqueue ( csvIn . getBytes ( ) ) ; runner . run ( ) ; runner . assertAllFlowFilesTransferred ( ReplaceText . REL_SUCCESS , 1 ) ; final MockFlowFile out = runner . getFlowFilesForRelationship ( ReplaceText . REL_SUCCESS ) . get ( 0 ) ; out . assertContentEquals ( expectedCsvOut ) ; } @ Test public void testAlwaysReplaceEntireText ( ) { final TestRunner runner = getRunner ( ) ; runner . setProperty ( ReplaceText . EVALUATION_MODE , ReplaceText . ENTIRE_TEXT ) ; runner . setProperty ( ReplaceText . REPLACEMENT_STRATEGY , ReplaceText . ALWAYS_REPLACE ) ; runner . setProperty ( ReplaceText . SEARCH_VALUE , ""i do not exist anywhere in the text"" ) ; runner . setProperty ( ReplaceText . REPLACEMENT_VALUE , ""${filename}"" ) ; final Map < String , String > attributes = new HashMap < > ( ) ; attributes . put ( ""filename"" , ""abc.txt"" ) ; runner . enqueue ( ""Hello\nWorld!"" . getBytes ( ) , attributes ) ; runner . run ( ) ; runner . assertAllFlowFilesTransferred ( ReplaceText . REL_SUCCESS , 1 ) ; final MockFlowFile out = runner . getFlowFilesForRelationship ( ReplaceText . REL_SUCCESS ) . get ( 0 ) ; out . assertContentEquals ( ""abc.txt"" ) ; } @ Test public void testAlwaysReplaceLineByLine ( ) { final TestRunner runner = getRunner ( ) ; runner . setProperty ( ReplaceText . EVALUATION_MODE , ReplaceText . LINE_BY_LINE ) ; runner . setProperty ( ReplaceText . REPLACEMENT_STRATEGY , ReplaceText . ALWAYS_REPLACE ) ; runner . setProperty ( ReplaceText . SEARCH_VALUE , ""i do not exist anywhere in the text"" ) ; runner . setProperty ( ReplaceText . REPLACEMENT_VALUE , ""${filename}"" ) ; final Map < String , String > attributes = new HashMap < > ( ) ; attributes . put ( ""filename"" , ""abc.txt"" ) ; runner . enqueue ( ""Hello\nWorld!\r\ntoday!\n"" . getBytes ( ) , attributes ) ; runner . run ( ) ; runner . assertAllFlowFilesTransferred ( ReplaceText . REL_SUCCESS , 1 ) ; final MockFlowFile out = runner . getFlowFilesForRelationship ( ReplaceText . REL_SUCCESS ) . get ( 0 ) ; out . assertContentEquals ( ""abc.txt\nabc.txt\r\nabc.txt\n"" ) ; } @ Test public void testRegexWithBadCaptureGroup ( ) throws IOException { final TestRunner runner = getRunner ( ) ; runner . setProperty ( ReplaceText . SEARCH_VALUE , ""(?s:^.*$)"" ) ; runner . setProperty ( ReplaceText . REPLACEMENT_VALUE , ""${'$1':toUpper()}"" ) ; runner . setProperty ( ReplaceText . REPLACEMENT_STRATEGY , ReplaceText . REGEX_REPLACE ) ; runner . setProperty ( ReplaceText . EVALUATION_MODE , ReplaceText . ENTIRE_TEXT ) ; runner . enqueue ( ""testing\n123"" . getBytes ( ) ) ; runner . run ( ) ; runner . assertAllFlowFilesTransferred ( ReplaceText . REL_SUCCESS , 1 ) ; final MockFlowFile out = runner . getFlowFilesForRelationship ( ReplaceText . REL_SUCCESS ) . get ( 0 ) ; out . assertContentEquals ( """" ) ; } @ Test public void testRegexWithGoodCaptureGroup ( ) throws IOException { final TestRunner runner = getRunner ( ) ; runner . setProperty ( ReplaceText . SEARCH_VALUE , ""(?s)(^.*$)"" ) ; runner . setProperty ( ReplaceText . REPLACEMENT_VALUE , ""${'$1':toUpper()}"" ) ; runner . setProperty ( ReplaceText . REPLACEMENT_STRATEGY , ReplaceText . REGEX_REPLACE ) ; runner . setProperty ( ReplaceText . EVALUATION_MODE , ReplaceText . ENTIRE_TEXT ) ; runner . enqueue ( ""testing\n123"" . getBytes ( ) ) ; runner . run ( ) ; runner . assertAllFlowFilesTransferred ( ReplaceText . REL_SUCCESS , 1 ) ; final MockFlowFile out = runner . getFlowFilesForRelationship ( ReplaceText . REL_SUCCESS ) . get ( 0 ) ; out . assertContentEquals ( ""TESTING\n123"" ) ; } @ Test public void testRegexNoCaptureDefaultReplacement ( ) throws IOException { final TestRunner runner = getRunner ( ) ; runner . setProperty ( ReplaceText . SEARCH_VALUE , ""(?s:^.*$)"" ) ; runner . setProperty ( ReplaceText . REPLACEMENT_VALUE , ""$1"" ) ; runner . setProperty ( ReplaceText . REPLACEMENT_STRATEGY , ReplaceText . REGEX_REPLACE ) ; runner . setProperty ( ReplaceText . EVALUATION_MODE , ReplaceText . ENTIRE_TEXT ) ; exception . expect ( AssertionError . class ) ; exception . expectMessage ( ""java.lang.IndexOutOfBoundsException: No group 1"" ) ; runner . enqueue ( ""testing\n123"" . getBytes ( ) ) ; runner . run ( ) ; } @ Test public void testProcessorConfigurationRegexNotValid ( ) throws IOException { final TestRunner runner = getRunner ( ) ; runner . setProperty ( ReplaceText . SEARCH_VALUE , ""(?<!\\),*"" ) ; runner . setProperty ( ReplaceText . REPLACEMENT_VALUE , ""hello"" ) ; runner . setProperty ( ReplaceText . REPLACEMENT_STRATEGY , ReplaceText . REGEX_REPLACE ) ; runner . setProperty ( ReplaceText . EVALUATION_MODE , ReplaceText . ENTIRE_TEXT ) ; runner . assertNotValid ( ) ; runner . setProperty ( ReplaceText . REPLACEMENT_STRATEGY , ReplaceText . LITERAL_REPLACE ) ; runner . assertValid ( ) ; runner . enqueue ( ""(?<!\\),*"" . getBytes ( ) ) ; runner . run ( ) ; runner . assertAllFlowFilesTransferred ( ReplaceText . REL_SUCCESS , 1 ) ; final MockFlowFile out = runner . getFlowFilesForRelationship ( ReplaceText . REL_SUCCESS ) . get ( 0 ) ; out . assertContentEquals ( ""hello"" ) ; runner . setProperty ( ReplaceText . SEARCH_VALUE , """" ) ; runner . assertNotValid ( ) ; runner . setProperty ( ReplaceText . REPLACEMENT_STRATEGY , ReplaceText . APPEND ) ; runner . assertValid ( ) ; runner . setProperty ( ReplaceText . REPLACEMENT_STRATEGY , ReplaceText . PREPEND ) ; runner . assertValid ( ) ; runner . setProperty ( ReplaceText . REPLACEMENT_STRATEGY , ReplaceText . ALWAYS_REPLACE ) ; runner . assertValid ( ) ; } @ Test public void testBackReferenceEscapeWithRegexReplaceUsingEL ( ) throws Exception { final TestRunner runner = getRunner ( ) ; runner . setProperty ( ReplaceText . SEARCH_VALUE , ""(?s)(^.*$)"" ) ; runner . setProperty ( ReplaceText . REPLACEMENT_VALUE , ""${'$1':toUpper()}"" ) ; runner . setProperty ( ReplaceText . REPLACEMENT_STRATEGY , ReplaceText . REGEX_REPLACE ) ; runner . setProperty ( ReplaceText . EVALUATION_MODE , ReplaceText . ENTIRE_TEXT ) ; runner . assertValid ( ) ; runner . enqueue ( ""wo$rd"" . getBytes ( ) ) ; runner . run ( ) ; runner . assertAllFlowFilesTransferred ( ReplaceText . REL_SUCCESS , 1 ) ; MockFlowFile out = runner . getFlowFilesForRelationship ( ReplaceText . REL_SUCCESS ) . get ( 0 ) ; out . assertContentEquals ( ""WO$RD"" ) ; runner . enqueue ( ""wo$1rd"" . getBytes ( ) ) ; runner . run ( ) ; runner . assertAllFlowFilesTransferred ( ReplaceText . REL_SUCCESS , 2 ) ; out = runner . getFlowFilesForRelationship ( ReplaceText . REL_SUCCESS ) . get ( 1 ) ; out . assertContentEquals ( ""WO$1RD"" ) ; runner . enqueue ( ""wo$1r$2d"" . getBytes ( ) ) ; runner . run ( ) ; runner . assertAllFlowFilesTransferred ( ReplaceText . REL_SUCCESS , 3 ) ; out = runner . getFlowFilesForRelationship ( ReplaceText . REL_SUCCESS ) . get ( 2 ) ; out . assertContentEquals ( ""WO$1R$2D"" ) ; } @ Test public void testForStackOverflow ( ) throws Exception { final TestRunner runner = getRunner ( ) ; runner . setProperty ( ReplaceText . REPLACEMENT_VALUE , ""New text"" ) ; runner . setProperty ( ReplaceText . REPLACEMENT_STRATEGY , ReplaceText . REGEX_REPLACE ) ; runner . setProperty ( ReplaceText . EVALUATION_MODE , ReplaceText . ENTIRE_TEXT ) ; runner . setProperty ( ReplaceText . MAX_BUFFER_SIZE , ""10 MB"" ) ; runner . setProperty ( ReplaceText . SEARCH_VALUE , ""(?s)(^(A|B)*$)"" ) ; runner . assertValid ( ) ; char [ ] data = new char [ 1_000_000 ] ; Arrays . fill ( data , 'A' ) ; runner . enqueue ( new String ( data ) ) ; runner . run ( ) ; runner . assertAllFlowFilesTransferred ( ReplaceText . REL_FAILURE , 1 ) ; } @ Test public void testWithInvalidExpression ( ) { final TestRunner runner = getRunner ( ) ; runner . setProperty ( ReplaceText . EVALUATION_MODE , ReplaceText . ENTIRE_TEXT ) ; runner . setProperty ( ReplaceText . SEARCH_VALUE , "".*"" ) ; runner . setProperty ( ReplaceText . REPLACEMENT_VALUE , ""${date:toDate(\""yyyy/MM/dd\"")}"" ) ; final Map < String , String > attributes = new HashMap < > ( ) ; attributes . put ( ""date"" , ""12"" ) ; runner . enqueue ( ""hi"" , attributes ) ; runner . run ( ) ; runner . assertAllFlowFilesTransferred ( ReplaceText . REL_FAILURE , 1 ) ; final MockFlowFile out = runner . getFlowFilesForRelationship ( ReplaceText . REL_FAILURE ) . get ( 0 ) ; final String outContent = translateNewLines ( new String ( out . toByteArray ( ) , StandardCharsets . UTF_8 ) ) ; Assert . assertTrue ( outContent . equals ( ""hi"" ) ) ; } private String translateNewLines ( final File file ) throws IOException { return translateNewLines ( file . toPath ( ) ) ; } private String translateNewLines ( final Path path ) throws IOException { final byte [ ] data = Files . readAllBytes ( path ) ; final String text = new String ( data , StandardCharsets . UTF_8 ) ; return translateNewLines ( text ) ; } private String translateNewLines ( final String text ) { final String lineSeparator = System . getProperty ( ""line.separator"" ) ; final Pattern pattern = Pattern . compile ( ""\n"" , Pattern . MULTILINE ) ; final String translated = pattern . matcher ( text ) . replaceAll ( lineSeparator ) ; return translated ; } }",Smelly
"public class SslFactoryTest { @ Test public void testSslFactoryConfiguration ( ) throws Exception { File trustStoreFile = File . createTempFile ( ""truststore"" , "".jks"" ) ; Map < String , Object > serverSslConfig = TestSslUtils . createSslConfig ( false , true , Mode . SERVER , trustStoreFile , ""server"" ) ; SslFactory sslFactory = new SslFactory ( Mode . SERVER ) ; sslFactory . configure ( serverSslConfig ) ; SSLEngine engine = sslFactory . createSslEngine ( ""localhost"" , 0 ) ; assertNotNull ( engine ) ; assertEquals ( Utils . mkSet ( ""TLSv1.2"" ) , Utils . mkSet ( engine . getEnabledProtocols ( ) ) ) ; assertEquals ( false , engine . getUseClientMode ( ) ) ; } @ Test public void testSslFactoryWithCustomKeyManagerConfiguration ( ) { TestProviderCreator testProviderCreator = new TestProviderCreator ( ) ; Map < String , Object > serverSslConfig = TestSslUtils . createSslConfig ( TestKeyManagerFactory . ALGORITHM , TestTrustManagerFactory . ALGORITHM ) ; serverSslConfig . put ( SecurityConfig . SECURITY_PROVIDERS_CONFIG , testProviderCreator . getClass ( ) . getName ( ) ) ; SslFactory sslFactory = new SslFactory ( Mode . SERVER ) ; sslFactory . configure ( serverSslConfig ) ; assertNotNull ( ""SslEngineBuilder not created"" , sslFactory . sslEngineBuilder ( ) ) ; Security . removeProvider ( testProviderCreator . getProvider ( ) . getName ( ) ) ; } @ Test ( expected = KafkaException . class ) public void testSslFactoryWithoutProviderClassConfiguration ( ) { Map < String , Object > serverSslConfig = TestSslUtils . createSslConfig ( TestKeyManagerFactory . ALGORITHM , TestTrustManagerFactory . ALGORITHM ) ; SslFactory sslFactory = new SslFactory ( Mode . SERVER ) ; sslFactory . configure ( serverSslConfig ) ; } @ Test ( expected = KafkaException . class ) public void testSslFactoryWithIncorrectProviderClassConfiguration ( ) { Map < String , Object > serverSslConfig = TestSslUtils . createSslConfig ( TestKeyManagerFactory . ALGORITHM , TestTrustManagerFactory . ALGORITHM ) ; serverSslConfig . put ( SecurityConfig . SECURITY_PROVIDERS_CONFIG , ""com.fake.ProviderClass1,com.fake.ProviderClass2"" ) ; SslFactory sslFactory = new SslFactory ( Mode . SERVER ) ; sslFactory . configure ( serverSslConfig ) ; } @ Test public void testSslFactoryWithoutPasswordConfiguration ( ) throws Exception { File trustStoreFile = File . createTempFile ( ""truststore"" , "".jks"" ) ; Map < String , Object > serverSslConfig = TestSslUtils . createSslConfig ( false , true , Mode . SERVER , trustStoreFile , ""server"" ) ; serverSslConfig . remove ( SslConfigs . SSL_TRUSTSTORE_PASSWORD_CONFIG ) ; SslFactory sslFactory = new SslFactory ( Mode . SERVER ) ; try { sslFactory . configure ( serverSslConfig ) ; } catch ( Exception e ) { fail ( ""An exception was thrown when configuring the truststore without a password: "" + e ) ; } } @ Test public void testClientMode ( ) throws Exception { File trustStoreFile = File . createTempFile ( ""truststore"" , "".jks"" ) ; Map < String , Object > clientSslConfig = TestSslUtils . createSslConfig ( false , true , Mode . CLIENT , trustStoreFile , ""client"" ) ; SslFactory sslFactory = new SslFactory ( Mode . CLIENT ) ; sslFactory . configure ( clientSslConfig ) ; SSLEngine engine = sslFactory . createSslEngine ( ""localhost"" , 0 ) ; assertTrue ( engine . getUseClientMode ( ) ) ; } @ Test public void testReconfiguration ( ) throws Exception { File trustStoreFile = File . createTempFile ( ""truststore"" , "".jks"" ) ; Map < String , Object > sslConfig = TestSslUtils . createSslConfig ( false , true , Mode . SERVER , trustStoreFile , ""server"" ) ; SslFactory sslFactory = new SslFactory ( Mode . SERVER ) ; sslFactory . configure ( sslConfig ) ; SslEngineBuilder sslEngineBuilder = sslFactory . sslEngineBuilder ( ) ; assertNotNull ( ""SslEngineBuilder not created"" , sslEngineBuilder ) ; sslFactory . reconfigure ( sslConfig ) ; assertSame ( ""SslEngineBuilder recreated unnecessarily"" , sslEngineBuilder , sslFactory . sslEngineBuilder ( ) ) ; trustStoreFile = File . createTempFile ( ""truststore"" , "".jks"" ) ; sslConfig = TestSslUtils . createSslConfig ( false , true , Mode . SERVER , trustStoreFile , ""server"" ) ; sslFactory . reconfigure ( sslConfig ) ; assertNotSame ( ""SslEngineBuilder not recreated"" , sslEngineBuilder , sslFactory . sslEngineBuilder ( ) ) ; sslEngineBuilder = sslFactory . sslEngineBuilder ( ) ; trustStoreFile . setLastModified ( System . currentTimeMillis ( ) + 10000 ) ; sslFactory . reconfigure ( sslConfig ) ; assertNotSame ( ""SslEngineBuilder not recreated"" , sslEngineBuilder , sslFactory . sslEngineBuilder ( ) ) ; sslEngineBuilder = sslFactory . sslEngineBuilder ( ) ; File keyStoreFile = new File ( ( String ) sslConfig . get ( SslConfigs . SSL_KEYSTORE_LOCATION_CONFIG ) ) ; keyStoreFile . setLastModified ( System . currentTimeMillis ( ) + 10000 ) ; sslFactory . reconfigure ( sslConfig ) ; assertNotSame ( ""SslEngineBuilder not recreated"" , sslEngineBuilder , sslFactory . sslEngineBuilder ( ) ) ; sslEngineBuilder = sslFactory . sslEngineBuilder ( ) ; keyStoreFile . setLastModified ( System . currentTimeMillis ( ) + 15000 ) ; sslFactory . validateReconfiguration ( sslConfig ) ; sslFactory . reconfigure ( sslConfig ) ; assertNotSame ( ""SslEngineBuilder not recreated"" , sslEngineBuilder , sslFactory . sslEngineBuilder ( ) ) ; sslEngineBuilder = sslFactory . sslEngineBuilder ( ) ; keyStoreFile . setLastModified ( System . currentTimeMillis ( ) + 20000 ) ; Files . delete ( keyStoreFile . toPath ( ) ) ; sslFactory . reconfigure ( sslConfig ) ; assertSame ( ""SslEngineBuilder recreated unnecessarily"" , sslEngineBuilder , sslFactory . sslEngineBuilder ( ) ) ; } @ Test public void testReconfigurationWithoutTruststore ( ) throws Exception { File trustStoreFile = File . createTempFile ( ""truststore"" , "".jks"" ) ; Map < String , Object > sslConfig = TestSslUtils . createSslConfig ( false , true , Mode . SERVER , trustStoreFile , ""server"" ) ; sslConfig . remove ( SslConfigs . SSL_TRUSTSTORE_LOCATION_CONFIG ) ; sslConfig . remove ( SslConfigs . SSL_TRUSTSTORE_PASSWORD_CONFIG ) ; sslConfig . remove ( SslConfigs . SSL_TRUSTSTORE_TYPE_CONFIG ) ; SslFactory sslFactory = new SslFactory ( Mode . SERVER ) ; sslFactory . configure ( sslConfig ) ; SSLContext sslContext = sslFactory . sslEngineBuilder ( ) . sslContext ( ) ; assertNotNull ( ""SSL context not created"" , sslContext ) ; assertSame ( ""SSL context recreated unnecessarily"" , sslContext , sslFactory . sslEngineBuilder ( ) . sslContext ( ) ) ; assertFalse ( sslFactory . createSslEngine ( ""localhost"" , 0 ) . getUseClientMode ( ) ) ; Map < String , Object > sslConfig2 = TestSslUtils . createSslConfig ( false , true , Mode . SERVER , trustStoreFile , ""server"" ) ; try { sslFactory . validateReconfiguration ( sslConfig2 ) ; fail ( ""Truststore configured dynamically for listener without previous truststore"" ) ; } catch ( ConfigException e ) { } } @ Test public void testReconfigurationWithoutKeystore ( ) throws Exception { File trustStoreFile = File . createTempFile ( ""truststore"" , "".jks"" ) ; Map < String , Object > sslConfig = TestSslUtils . createSslConfig ( false , true , Mode . SERVER , trustStoreFile , ""server"" ) ; sslConfig . remove ( SslConfigs . SSL_KEYSTORE_LOCATION_CONFIG ) ; sslConfig . remove ( SslConfigs . SSL_KEYSTORE_PASSWORD_CONFIG ) ; sslConfig . remove ( SslConfigs . SSL_KEYSTORE_TYPE_CONFIG ) ; SslFactory sslFactory = new SslFactory ( Mode . SERVER ) ; sslFactory . configure ( sslConfig ) ; SSLContext sslContext = sslFactory . sslEngineBuilder ( ) . sslContext ( ) ; assertNotNull ( ""SSL context not created"" , sslContext ) ; assertSame ( ""SSL context recreated unnecessarily"" , sslContext , sslFactory . sslEngineBuilder ( ) . sslContext ( ) ) ; assertFalse ( sslFactory . createSslEngine ( ""localhost"" , 0 ) . getUseClientMode ( ) ) ; File newTrustStoreFile = File . createTempFile ( ""truststore"" , "".jks"" ) ; sslConfig = TestSslUtils . createSslConfig ( false , true , Mode . SERVER , newTrustStoreFile , ""server"" ) ; sslConfig . remove ( SslConfigs . SSL_KEYSTORE_LOCATION_CONFIG ) ; sslConfig . remove ( SslConfigs . SSL_KEYSTORE_PASSWORD_CONFIG ) ; sslConfig . remove ( SslConfigs . SSL_KEYSTORE_TYPE_CONFIG ) ; sslFactory . reconfigure ( sslConfig ) ; assertNotSame ( ""SSL context not recreated"" , sslContext , sslFactory . sslEngineBuilder ( ) . sslContext ( ) ) ; sslConfig = TestSslUtils . createSslConfig ( false , true , Mode . SERVER , newTrustStoreFile , ""server"" ) ; try { sslFactory . validateReconfiguration ( sslConfig ) ; fail ( ""Keystore configured dynamically for listener without previous keystore"" ) ; } catch ( ConfigException e ) { } } @ Test public void testKeyStoreTrustStoreValidation ( ) throws Exception { File trustStoreFile = File . createTempFile ( ""truststore"" , "".jks"" ) ; Map < String , Object > serverSslConfig = TestSslUtils . createSslConfig ( false , true , Mode . SERVER , trustStoreFile , ""server"" ) ; SslFactory sslFactory = new SslFactory ( Mode . SERVER ) ; sslFactory . configure ( serverSslConfig ) ; assertNotNull ( ""SslEngineBuilder not created"" , sslFactory . sslEngineBuilder ( ) ) ; } @ Test public void testUntrustedKeyStoreValidationFails ( ) throws Exception { File trustStoreFile1 = File . createTempFile ( ""truststore1"" , "".jks"" ) ; File trustStoreFile2 = File . createTempFile ( ""truststore2"" , "".jks"" ) ; Map < String , Object > sslConfig1 = TestSslUtils . createSslConfig ( false , true , Mode . SERVER , trustStoreFile1 , ""server"" ) ; Map < String , Object > sslConfig2 = TestSslUtils . createSslConfig ( false , true , Mode . SERVER , trustStoreFile2 , ""server"" ) ; SslFactory sslFactory = new SslFactory ( Mode . SERVER , null , true ) ; for ( String key : Arrays . asList ( SslConfigs . SSL_TRUSTSTORE_LOCATION_CONFIG , SslConfigs . SSL_TRUSTSTORE_PASSWORD_CONFIG , SslConfigs . SSL_TRUSTSTORE_TYPE_CONFIG , SslConfigs . SSL_TRUSTMANAGER_ALGORITHM_CONFIG ) ) { sslConfig1 . put ( key , sslConfig2 . get ( key ) ) ; } try { sslFactory . configure ( sslConfig1 ) ; fail ( ""Validation did not fail with untrusted truststore"" ) ; } catch ( ConfigException e ) { } } @ Test public void testKeystoreVerifiableUsingTruststore ( ) throws Exception { File trustStoreFile1 = File . createTempFile ( ""truststore1"" , "".jks"" ) ; Map < String , Object > sslConfig1 = TestSslUtils . createSslConfig ( false , true , Mode . SERVER , trustStoreFile1 , ""server"" ) ; SslFactory sslFactory = new SslFactory ( Mode . SERVER , null , true ) ; sslFactory . configure ( sslConfig1 ) ; File trustStoreFile2 = File . createTempFile ( ""truststore2"" , "".jks"" ) ; Map < String , Object > sslConfig2 = TestSslUtils . createSslConfig ( false , true , Mode . SERVER , trustStoreFile2 , ""server"" ) ; try { sslFactory . validateReconfiguration ( sslConfig2 ) ; fail ( ""ValidateReconfiguration did not fail as expected"" ) ; } catch ( ConfigException e ) { } } @ Test public void testCertificateEntriesValidation ( ) throws Exception { File trustStoreFile = File . createTempFile ( ""truststore"" , "".jks"" ) ; Map < String , Object > serverSslConfig = TestSslUtils . createSslConfig ( false , true , Mode . SERVER , trustStoreFile , ""server"" ) ; Map < String , Object > newCnConfig = TestSslUtils . createSslConfig ( false , true , Mode . SERVER , File . createTempFile ( ""truststore"" , "".jks"" ) , ""server"" , ""Another CN"" ) ; KeyStore ks1 = sslKeyStore ( serverSslConfig ) . load ( ) ; KeyStore ks2 = sslKeyStore ( serverSslConfig ) . load ( ) ; assertEquals ( SslFactory . CertificateEntries . create ( ks1 ) , SslFactory . CertificateEntries . create ( ks2 ) ) ; ks2 . setCertificateEntry ( ""another"" , ks1 . getCertificate ( ""localhost"" ) ) ; assertEquals ( SslFactory . CertificateEntries . create ( ks1 ) , SslFactory . CertificateEntries . create ( ks2 ) ) ; KeyStore ks3 = sslKeyStore ( newCnConfig ) . load ( ) ; assertNotEquals ( SslFactory . CertificateEntries . create ( ks1 ) , SslFactory . CertificateEntries . create ( ks3 ) ) ; } private SslEngineBuilder . SecurityStore sslKeyStore ( Map < String , Object > sslConfig ) { return new SslEngineBuilder . SecurityStore ( ( String ) sslConfig . get ( SslConfigs . SSL_KEYSTORE_TYPE_CONFIG ) , ( String ) sslConfig . get ( SslConfigs . SSL_KEYSTORE_LOCATION_CONFIG ) , ( Password ) sslConfig . get ( SslConfigs . SSL_KEYSTORE_PASSWORD_CONFIG ) , ( Password ) sslConfig . get ( SslConfigs . SSL_KEY_PASSWORD_CONFIG ) ) ; } private SslEngineBuilder . SecurityStore sslTrustStore ( Map < String , Object > sslConfig ) { return new SslEngineBuilder . SecurityStore ( ( String ) sslConfig . get ( SslConfigs . SSL_TRUSTSTORE_TYPE_CONFIG ) , ( String ) sslConfig . get ( SslConfigs . SSL_TRUSTSTORE_LOCATION_CONFIG ) , ( Password ) sslConfig . get ( SslConfigs . SSL_TRUSTSTORE_PASSWORD_CONFIG ) , null ) ; } }",No
"public class RangerDefaultPolicyEvaluator extends RangerAbstractPolicyEvaluator { private static final Log LOG = LogFactory . getLog ( RangerDefaultPolicyEvaluator . class ) ; private static final Log PERF_POLICY_INIT_LOG = RangerPerfTracer . getPerfLogger ( ""policy.init"" ) ; private static final Log PERF_POLICY_REQUEST_LOG = RangerPerfTracer . getPerfLogger ( ""policy.request"" ) ; private RangerPolicyResourceMatcher resourceMatcher ; private List < RangerPolicyItemEvaluator > allowEvaluators ; private List < RangerPolicyItemEvaluator > denyEvaluators ; private List < RangerPolicyItemEvaluator > allowExceptionEvaluators ; private List < RangerPolicyItemEvaluator > denyExceptionEvaluators ; private int customConditionsCount ; private List < RangerDataMaskPolicyItemEvaluator > dataMaskEvaluators ; private List < RangerRowFilterPolicyItemEvaluator > rowFilterEvaluators ; private String perfTag ; protected boolean needsDynamicEval ( ) { return resourceMatcher != null && resourceMatcher . getNeedsDynamicEval ( ) ; } @ Override public int getCustomConditionsCount ( ) { return customConditionsCount ; } @ Override public RangerPolicyResourceMatcher getPolicyResourceMatcher ( ) { return resourceMatcher ; } @ Override public RangerResourceMatcher getResourceMatcher ( String resourceName ) { return resourceMatcher != null ? resourceMatcher . getResourceMatcher ( resourceName ) : null ; } @ Override public void init ( RangerPolicy policy , RangerServiceDef serviceDef , RangerPolicyEngineOptions options ) { if ( LOG . isDebugEnabled ( ) ) { LOG . debug ( ""==> RangerDefaultPolicyEvaluator.init()"" ) ; } StringBuilder perfTagBuffer = new StringBuilder ( ) ; if ( policy != null ) { perfTagBuffer . append ( ""policyId="" ) . append ( policy . getId ( ) ) . append ( "", policyName="" ) . append ( policy . getName ( ) ) ; } perfTag = perfTagBuffer . toString ( ) ; RangerPerfTracer perf = null ; if ( RangerPerfTracer . isPerfTraceEnabled ( PERF_POLICY_INIT_LOG ) ) { perf = RangerPerfTracer . getPerfTracer ( PERF_POLICY_INIT_LOG , ""RangerPolicyEvaluator.init("" + perfTag + "")"" ) ; } super . init ( policy , serviceDef , options ) ; preprocessPolicy ( policy , serviceDef ) ; resourceMatcher = new RangerDefaultPolicyResourceMatcher ( ) ; resourceMatcher . setServiceDef ( serviceDef ) ; resourceMatcher . setPolicy ( policy ) ; resourceMatcher . setServiceDefHelper ( options . getServiceDefHelper ( ) ) ; resourceMatcher . init ( ) ; if ( policy != null ) { allowEvaluators = createPolicyItemEvaluators ( policy , serviceDef , options , RangerPolicyItemEvaluator . POLICY_ITEM_TYPE_ALLOW ) ; denyEvaluators = createPolicyItemEvaluators ( policy , serviceDef , options , RangerPolicyItemEvaluator . POLICY_ITEM_TYPE_DENY ) ; allowExceptionEvaluators = createPolicyItemEvaluators ( policy , serviceDef , options , RangerPolicyItemEvaluator . POLICY_ITEM_TYPE_ALLOW_EXCEPTIONS ) ; denyExceptionEvaluators = createPolicyItemEvaluators ( policy , serviceDef , options , RangerPolicyItemEvaluator . POLICY_ITEM_TYPE_DENY_EXCEPTIONS ) ; dataMaskEvaluators = createDataMaskPolicyItemEvaluators ( policy , serviceDef , options , policy . getDataMaskPolicyItems ( ) ) ; rowFilterEvaluators = createRowFilterPolicyItemEvaluators ( policy , serviceDef , options , policy . getRowFilterPolicyItems ( ) ) ; } else { allowEvaluators = Collections . < RangerPolicyItemEvaluator > emptyList ( ) ; denyEvaluators = Collections . < RangerPolicyItemEvaluator > emptyList ( ) ; allowExceptionEvaluators = Collections . < RangerPolicyItemEvaluator > emptyList ( ) ; denyExceptionEvaluators = Collections . < RangerPolicyItemEvaluator > emptyList ( ) ; dataMaskEvaluators = Collections . < RangerDataMaskPolicyItemEvaluator > emptyList ( ) ; rowFilterEvaluators = Collections . < RangerRowFilterPolicyItemEvaluator > emptyList ( ) ; } RangerPolicyItemEvaluator . EvalOrderComparator comparator = new RangerPolicyItemEvaluator . EvalOrderComparator ( ) ; Collections . sort ( allowEvaluators , comparator ) ; Collections . sort ( denyEvaluators , comparator ) ; Collections . sort ( allowExceptionEvaluators , comparator ) ; Collections . sort ( denyExceptionEvaluators , comparator ) ; RangerPerfTracer . log ( perf ) ; if ( LOG . isDebugEnabled ( ) ) { LOG . debug ( ""<== RangerDefaultPolicyEvaluator.init()"" ) ; } } @ Override public void evaluate ( RangerAccessRequest request , RangerAccessResult result ) { if ( LOG . isDebugEnabled ( ) ) { LOG . debug ( ""==> RangerDefaultPolicyEvaluator.evaluate("" + request + "", "" + result + "")"" ) ; } RangerPerfTracer perf = null ; if ( RangerPerfTracer . isPerfTraceEnabled ( PERF_POLICY_REQUEST_LOG ) ) { perf = RangerPerfTracer . getPerfTracer ( PERF_POLICY_REQUEST_LOG , ""RangerPolicyEvaluator.evaluate(requestHashCode="" + Integer . toHexString ( System . identityHashCode ( request ) ) + "","" + perfTag + "")"" ) ; } if ( request != null && result != null ) { if ( ! result . getIsAccessDetermined ( ) || ! result . getIsAuditedDetermined ( ) ) { RangerPolicyResourceMatcher . MatchType matchType ; if ( RangerTagAccessRequest . class . isInstance ( request ) ) { matchType = ( ( RangerTagAccessRequest ) request ) . getMatchType ( ) ; } else { matchType = resourceMatcher != null ? resourceMatcher . getMatchType ( request . getResource ( ) , request . getContext ( ) ) : RangerPolicyResourceMatcher . MatchType . NONE ; } final boolean isMatched = matchType != RangerPolicyResourceMatcher . MatchType . NONE ; ; if ( isMatched ) { if ( RangerTagAccessRequest . class . isInstance ( request ) ) { if ( matchType == RangerPolicyResourceMatcher . MatchType . DESCENDANT && ! request . isAccessTypeAny ( ) && request . getResourceMatchingScope ( ) == RangerAccessRequest . ResourceMatchingScope . SELF_OR_DESCENDANTS ) { if ( LOG . isDebugEnabled ( ) ) { LOG . debug ( ""Setting matchType from DESCENDANT to SELF, so that any DENY policy-items will take effect."" ) ; } matchType = RangerPolicyResourceMatcher . MatchType . SELF ; } } if ( ! result . getIsAuditedDetermined ( ) ) { if ( isAuditEnabled ( ) ) { result . setIsAudited ( true ) ; result . setAuditPolicyId ( getPolicy ( ) . getId ( ) ) ; } } if ( ! result . getIsAccessDetermined ( ) ) { if ( hasMatchablePolicyItem ( request ) ) { evaluatePolicyItems ( request , matchType , result ) ; } } } } } RangerPerfTracer . log ( perf ) ; if ( LOG . isDebugEnabled ( ) ) { LOG . debug ( ""<== RangerDefaultPolicyEvaluator.evaluate("" + request + "", "" + result + "")"" ) ; } } @ Override public boolean isMatch ( RangerAccessResource resource , Map < String , Object > evalContext ) { if ( LOG . isDebugEnabled ( ) ) { LOG . debug ( ""==> RangerDefaultPolicyEvaluator.isMatch("" + resource + "", "" + evalContext + "")"" ) ; } boolean ret = false ; RangerPerfTracer perf = null ; if ( RangerPerfTracer . isPerfTraceEnabled ( PERF_POLICY_REQUEST_LOG ) ) { perf = RangerPerfTracer . getPerfTracer ( PERF_POLICY_REQUEST_LOG , ""RangerPolicyEvaluator.isMatch(resource="" + resource . getAsString ( ) + "","" + evalContext + "","" + perfTag + "")"" ) ; } if ( resourceMatcher != null ) { ret = resourceMatcher . isMatch ( resource , evalContext ) ; } RangerPerfTracer . log ( perf ) ; if ( LOG . isDebugEnabled ( ) ) { LOG . debug ( ""<== RangerDefaultPolicyEvaluator.isMatch("" + resource + "", "" + evalContext + ""): "" + ret ) ; } return ret ; } @ Override public boolean isCompleteMatch ( RangerAccessResource resource , Map < String , Object > evalContext ) { if ( LOG . isDebugEnabled ( ) ) { LOG . debug ( ""==> RangerDefaultPolicyEvaluator.isCompleteMatch("" + resource + "", "" + evalContext + "")"" ) ; } boolean ret = resourceMatcher != null && resourceMatcher . isCompleteMatch ( resource , evalContext ) ; if ( LOG . isDebugEnabled ( ) ) { LOG . debug ( ""<== RangerDefaultPolicyEvaluator.isCompleteMatch("" + resource + ""): "" + ret ) ; } return ret ; } @ Override public boolean isCompleteMatch ( Map < String , RangerPolicyResource > resources , Map < String , Object > evalContext ) { if ( LOG . isDebugEnabled ( ) ) { LOG . debug ( ""==> RangerDefaultPolicyEvaluator.isCompleteMatch("" + resources + "", "" + evalContext + "")"" ) ; } boolean ret = resourceMatcher != null && resourceMatcher . isCompleteMatch ( resources , evalContext ) ; if ( LOG . isDebugEnabled ( ) ) { LOG . debug ( ""<== RangerDefaultPolicyEvaluator.isCompleteMatch("" + resources + "", "" + evalContext + ""): "" + ret ) ; } return ret ; } @ Override public boolean isAccessAllowed ( RangerAccessResource resource , String user , Set < String > userGroups , String accessType ) { if ( LOG . isDebugEnabled ( ) ) { LOG . debug ( ""==> RangerDefaultPolicyEvaluator.isAccessAllowed("" + resource + "", "" + user + "", "" + userGroups + "", "" + accessType + "")"" ) ; } Map < String , Object > evalContext = new HashMap < > ( ) ; RangerAccessRequestUtil . setCurrentUserInContext ( evalContext , user ) ; boolean ret = isAccessAllowed ( user , userGroups , accessType ) && isMatch ( resource , evalContext ) ; if ( LOG . isDebugEnabled ( ) ) { LOG . debug ( ""<== RangerDefaultPolicyEvaluator.isAccessAllowed("" + resource + "", "" + user + "", "" + userGroups + "", "" + accessType + ""): "" + ret ) ; } return ret ; } @ Override public boolean isAccessAllowed ( Map < String , RangerPolicyResource > resources , String user , Set < String > userGroups , String accessType ) { if ( LOG . isDebugEnabled ( ) ) { LOG . debug ( ""==> RangerDefaultPolicyEvaluator.isAccessAllowed("" + resources + "", "" + user + "", "" + userGroups + "", "" + accessType + "")"" ) ; } Map < String , Object > evalContext = new HashMap < > ( ) ; RangerAccessRequestUtil . setCurrentUserInContext ( evalContext , user ) ; boolean ret = isAccessAllowed ( user , userGroups , accessType ) && isMatch ( resources , evalContext ) ; if ( LOG . isDebugEnabled ( ) ) { LOG . debug ( ""<== RangerDefaultPolicyEvaluator.isAccessAllowed("" + resources + "", "" + user + "", "" + userGroups + "", "" + accessType + ""): "" + ret ) ; } return ret ; } @ Override public void getResourceAccessInfo ( RangerAccessRequest request , RangerResourceAccessInfo result ) { if ( LOG . isDebugEnabled ( ) ) { LOG . debug ( ""==> RangerDefaultPolicyEvaluator.getResourceAccessInfo("" + request + "", "" + result + "")"" ) ; } RangerPolicyResourceMatcher . MatchType matchType ; if ( RangerTagAccessRequest . class . isInstance ( request ) ) { matchType = ( ( RangerTagAccessRequest ) request ) . getMatchType ( ) ; } else { matchType = resourceMatcher != null ? resourceMatcher . getMatchType ( request . getResource ( ) , request . getContext ( ) ) : RangerPolicyResourceMatcher . MatchType . NONE ; } final boolean isMatched = matchType != RangerPolicyResourceMatcher . MatchType . NONE ; ; if ( isMatched ) { if ( CollectionUtils . isNotEmpty ( allowEvaluators ) ) { Set < String > users = new HashSet < > ( ) ; Set < String > groups = new HashSet < > ( ) ; getResourceAccessInfo ( request , allowEvaluators , users , groups ) ; if ( CollectionUtils . isNotEmpty ( allowExceptionEvaluators ) ) { Set < String > exceptionUsers = new HashSet < > ( ) ; Set < String > exceptionGroups = new HashSet < > ( ) ; getResourceAccessInfo ( request , allowExceptionEvaluators , exceptionUsers , exceptionGroups ) ; users . removeAll ( exceptionUsers ) ; groups . removeAll ( exceptionGroups ) ; } result . getAllowedUsers ( ) . addAll ( users ) ; result . getAllowedGroups ( ) . addAll ( groups ) ; } if ( matchType != RangerPolicyResourceMatcher . MatchType . DESCENDANT ) { if ( CollectionUtils . isNotEmpty ( denyEvaluators ) ) { Set < String > users = new HashSet < String > ( ) ; Set < String > groups = new HashSet < String > ( ) ; getResourceAccessInfo ( request , denyEvaluators , users , groups ) ; if ( CollectionUtils . isNotEmpty ( denyExceptionEvaluators ) ) { Set < String > exceptionUsers = new HashSet < String > ( ) ; Set < String > exceptionGroups = new HashSet < String > ( ) ; getResourceAccessInfo ( request , denyExceptionEvaluators , exceptionUsers , exceptionGroups ) ; users . removeAll ( exceptionUsers ) ; groups . removeAll ( exceptionGroups ) ; } result . getDeniedUsers ( ) . addAll ( users ) ; result . getDeniedGroups ( ) . addAll ( groups ) ; } } } if ( LOG . isDebugEnabled ( ) ) { LOG . debug ( ""<== RangerDefaultPolicyEvaluator.getResourceAccessInfo("" + request + "", "" + result + "")"" ) ; } } protected void evaluatePolicyItems ( RangerAccessRequest request , RangerPolicyResourceMatcher . MatchType matchType , RangerAccessResult result ) { if ( LOG . isDebugEnabled ( ) ) { LOG . debug ( ""==> RangerDefaultPolicyEvaluator.evaluatePolicyItems("" + request + "", "" + result + "", "" + matchType + "")"" ) ; } RangerPolicyItemEvaluator matchedPolicyItem = getMatchingPolicyItem ( request , result ) ; if ( matchedPolicyItem != null ) { matchedPolicyItem . updateAccessResult ( result , matchType , getPolicy ( ) . getId ( ) ) ; } if ( LOG . isDebugEnabled ( ) ) { LOG . debug ( ""<== RangerDefaultPolicyEvaluator.evaluatePolicyItems("" + request + "", "" + result + "", "" + matchType + "")"" ) ; } } protected RangerPolicyItemEvaluator getDeterminingPolicyItem ( String user , Set < String > userGroups , String accessType ) { if ( LOG . isDebugEnabled ( ) ) { LOG . debug ( ""==> RangerDefaultPolicyEvaluator.getDeterminingPolicyItem("" + user + "", "" + userGroups + "", "" + accessType + "")"" ) ; } RangerPolicyItemEvaluator ret = null ; ret = getMatchingPolicyItem ( user , userGroups , accessType , denyEvaluators , denyExceptionEvaluators ) ; if ( ret == null ) { ret = getMatchingPolicyItem ( user , userGroups , accessType , allowEvaluators , allowExceptionEvaluators ) ; } if ( LOG . isDebugEnabled ( ) ) { LOG . debug ( ""<== RangerDefaultPolicyEvaluator.getDeterminingPolicyItem("" + user + "", "" + userGroups + "", "" + accessType + ""): "" + ret ) ; } return ret ; } private void getResourceAccessInfo ( RangerAccessRequest request , List < ? extends RangerPolicyItemEvaluator > policyItems , Set < String > users , Set < String > groups ) { if ( LOG . isDebugEnabled ( ) ) { LOG . debug ( ""==> RangerDefaultPolicyEvaluator.getResourceAccessInfo("" + request + "", "" + policyItems + "", "" + users + "", "" + groups + "")"" ) ; } if ( CollectionUtils . isNotEmpty ( policyItems ) ) { for ( RangerPolicyItemEvaluator policyItemEvaluator : policyItems ) { if ( policyItemEvaluator . matchAccessType ( request . getAccessType ( ) ) && policyItemEvaluator . matchCustomConditions ( request ) ) { if ( CollectionUtils . isNotEmpty ( policyItemEvaluator . getPolicyItem ( ) . getUsers ( ) ) ) { users . addAll ( policyItemEvaluator . getPolicyItem ( ) . getUsers ( ) ) ; } if ( CollectionUtils . isNotEmpty ( policyItemEvaluator . getPolicyItem ( ) . getGroups ( ) ) ) { groups . addAll ( policyItemEvaluator . getPolicyItem ( ) . getGroups ( ) ) ; } } } } if ( LOG . isDebugEnabled ( ) ) { LOG . debug ( ""<== RangerDefaultPolicyEvaluator.getResourceAccessInfo("" + request + "", "" + policyItems + "", "" + users + "", "" + groups + "")"" ) ; } } protected boolean isMatch ( Map < String , RangerPolicyResource > resources , Map < String , Object > evalContext ) { if ( LOG . isDebugEnabled ( ) ) { LOG . debug ( ""==> RangerDefaultPolicyEvaluator.isMatch("" + resources + "", "" + evalContext + "")"" ) ; } boolean ret = resourceMatcher != null && resourceMatcher . isMatch ( resources , evalContext ) ; if ( LOG . isDebugEnabled ( ) ) { LOG . debug ( ""<== RangerDefaultPolicyEvaluator.isMatch("" + resources + "", "" + evalContext + ""): "" + ret ) ; } return ret ; } protected boolean isAccessAllowed ( String user , Set < String > userGroups , String accessType ) { if ( LOG . isDebugEnabled ( ) ) { LOG . debug ( ""==> RangerDefaultPolicyEvaluator.isAccessAllowed("" + user + "", "" + userGroups + "", "" + accessType + "")"" ) ; } boolean ret = false ; RangerPerfTracer perf = null ; if ( RangerPerfTracer . isPerfTraceEnabled ( PERF_POLICY_REQUEST_LOG ) ) { perf = RangerPerfTracer . getPerfTracer ( PERF_POLICY_REQUEST_LOG , ""RangerPolicyEvaluator.isAccessAllowed(hashCode="" + Integer . toHexString ( System . identityHashCode ( this ) ) + "","" + perfTag + "")"" ) ; } RangerPolicyItemEvaluator item = this . getDeterminingPolicyItem ( user , userGroups , accessType ) ; if ( item != null && item . getPolicyItemType ( ) == RangerPolicyItemEvaluator . POLICY_ITEM_TYPE_ALLOW ) { ret = true ; } RangerPerfTracer . log ( perf ) ; if ( LOG . isDebugEnabled ( ) ) { LOG . debug ( ""<== RangerDefaultPolicyEvaluator.isAccessAllowed("" + user + "", "" + userGroups + "", "" + accessType + ""): "" + ret ) ; } return ret ; } public StringBuilder toString ( StringBuilder sb ) { sb . append ( ""RangerDefaultPolicyEvaluator={"" ) ; super . toString ( sb ) ; sb . append ( ""resourceMatcher={"" ) ; if ( resourceMatcher != null ) { resourceMatcher . toString ( sb ) ; } sb . append ( ""} "" ) ; sb . append ( ""}"" ) ; return sb ; } private void preprocessPolicy ( RangerPolicy policy , RangerServiceDef serviceDef ) { if ( policy == null || ( ! hasAllow ( ) && ! hasDeny ( ) ) || serviceDef == null ) { return ; } Map < String , Collection < String > > impliedAccessGrants = getImpliedAccessGrants ( serviceDef ) ; if ( impliedAccessGrants == null || impliedAccessGrants . isEmpty ( ) ) { return ; } preprocessPolicyItems ( policy . getPolicyItems ( ) , impliedAccessGrants ) ; preprocessPolicyItems ( policy . getDenyPolicyItems ( ) , impliedAccessGrants ) ; preprocessPolicyItems ( policy . getAllowExceptions ( ) , impliedAccessGrants ) ; preprocessPolicyItems ( policy . getDenyExceptions ( ) , impliedAccessGrants ) ; preprocessPolicyItems ( policy . getDataMaskPolicyItems ( ) , impliedAccessGrants ) ; preprocessPolicyItems ( policy . getRowFilterPolicyItems ( ) , impliedAccessGrants ) ; } private void preprocessPolicyItems ( List < ? extends RangerPolicyItem > policyItems , Map < String , Collection < String > > impliedAccessGrants ) { for ( RangerPolicyItem policyItem : policyItems ) { if ( CollectionUtils . isEmpty ( policyItem . getAccesses ( ) ) ) { continue ; } for ( Map . Entry < String , Collection < String > > e : impliedAccessGrants . entrySet ( ) ) { String accessType = e . getKey ( ) ; Collection < String > impliedGrants = e . getValue ( ) ; RangerPolicyItemAccess access = getAccess ( policyItem , accessType ) ; if ( access == null ) { continue ; } for ( String impliedGrant : impliedGrants ) { RangerPolicyItemAccess impliedAccess = getAccess ( policyItem , impliedGrant ) ; if ( impliedAccess == null ) { impliedAccess = new RangerPolicyItemAccess ( impliedGrant , access . getIsAllowed ( ) ) ; policyItem . getAccesses ( ) . add ( impliedAccess ) ; } else { if ( ! impliedAccess . getIsAllowed ( ) ) { impliedAccess . setIsAllowed ( access . getIsAllowed ( ) ) ; } } } } } } private Map < String , Collection < String > > getImpliedAccessGrants ( RangerServiceDef serviceDef ) { Map < String , Collection < String > > ret = null ; if ( serviceDef != null && ! CollectionUtils . isEmpty ( serviceDef . getAccessTypes ( ) ) ) { for ( RangerAccessTypeDef accessTypeDef : serviceDef . getAccessTypes ( ) ) { if ( ! CollectionUtils . isEmpty ( accessTypeDef . getImpliedGrants ( ) ) ) { if ( ret == null ) { ret = new HashMap < > ( ) ; } Collection < String > impliedAccessGrants = ret . get ( accessTypeDef . getName ( ) ) ; if ( impliedAccessGrants == null ) { impliedAccessGrants = new HashSet < > ( ) ; ret . put ( accessTypeDef . getName ( ) , impliedAccessGrants ) ; } impliedAccessGrants . addAll ( accessTypeDef . getImpliedGrants ( ) ) ; } } } return ret ; } private RangerPolicyItemAccess getAccess ( RangerPolicyItem policyItem , String accessType ) { RangerPolicyItemAccess ret = null ; if ( policyItem != null && CollectionUtils . isNotEmpty ( policyItem . getAccesses ( ) ) ) { for ( RangerPolicyItemAccess itemAccess : policyItem . getAccesses ( ) ) { if ( StringUtils . equalsIgnoreCase ( itemAccess . getType ( ) , accessType ) ) { ret = itemAccess ; break ; } } } return ret ; } private List < RangerPolicyItemEvaluator > createPolicyItemEvaluators ( RangerPolicy policy , RangerServiceDef serviceDef , RangerPolicyEngineOptions options , int policyItemType ) { List < RangerPolicyItemEvaluator > ret = null ; List < RangerPolicyItem > policyItems = null ; if ( isPolicyItemTypeEnabled ( serviceDef , policyItemType ) ) { if ( policyItemType == RangerPolicyItemEvaluator . POLICY_ITEM_TYPE_ALLOW ) { policyItems = policy . getPolicyItems ( ) ; } else if ( policyItemType == RangerPolicyItemEvaluator . POLICY_ITEM_TYPE_DENY ) { policyItems = policy . getDenyPolicyItems ( ) ; } else if ( policyItemType == RangerPolicyItemEvaluator . POLICY_ITEM_TYPE_ALLOW_EXCEPTIONS ) { policyItems = policy . getAllowExceptions ( ) ; } else if ( policyItemType == RangerPolicyItemEvaluator . POLICY_ITEM_TYPE_DENY_EXCEPTIONS ) { policyItems = policy . getDenyExceptions ( ) ; } } if ( CollectionUtils . isNotEmpty ( policyItems ) ) { ret = new ArrayList < > ( ) ; int policyItemCounter = 1 ; for ( RangerPolicyItem policyItem : policyItems ) { RangerPolicyItemEvaluator itemEvaluator = new RangerDefaultPolicyItemEvaluator ( serviceDef , policy , policyItem , policyItemType , policyItemCounter ++ , options ) ; itemEvaluator . init ( ) ; ret . add ( itemEvaluator ) ; if ( CollectionUtils . isNotEmpty ( itemEvaluator . getConditionEvaluators ( ) ) ) { customConditionsCount += itemEvaluator . getConditionEvaluators ( ) . size ( ) ; } } } else { ret = Collections . < RangerPolicyItemEvaluator > emptyList ( ) ; } return ret ; } private List < RangerDataMaskPolicyItemEvaluator > createDataMaskPolicyItemEvaluators ( RangerPolicy policy , RangerServiceDef serviceDef , RangerPolicyEngineOptions options , List < RangerDataMaskPolicyItem > policyItems ) { List < RangerDataMaskPolicyItemEvaluator > ret = null ; if ( CollectionUtils . isNotEmpty ( policyItems ) ) { ret = new ArrayList < > ( ) ; int policyItemCounter = 1 ; for ( RangerDataMaskPolicyItem policyItem : policyItems ) { RangerDataMaskPolicyItemEvaluator itemEvaluator = new RangerDefaultDataMaskPolicyItemEvaluator ( serviceDef , policy , policyItem , policyItemCounter ++ , options ) ; itemEvaluator . init ( ) ; ret . add ( itemEvaluator ) ; if ( CollectionUtils . isNotEmpty ( itemEvaluator . getConditionEvaluators ( ) ) ) { customConditionsCount += itemEvaluator . getConditionEvaluators ( ) . size ( ) ; } } } else { ret = Collections . < RangerDataMaskPolicyItemEvaluator > emptyList ( ) ; } return ret ; } private List < RangerRowFilterPolicyItemEvaluator > createRowFilterPolicyItemEvaluators ( RangerPolicy policy , RangerServiceDef serviceDef , RangerPolicyEngineOptions options , List < RangerRowFilterPolicyItem > policyItems ) { List < RangerRowFilterPolicyItemEvaluator > ret = null ; if ( CollectionUtils . isNotEmpty ( policyItems ) ) { ret = new ArrayList < > ( ) ; int policyItemCounter = 1 ; for ( RangerRowFilterPolicyItem policyItem : policyItems ) { RangerRowFilterPolicyItemEvaluator itemEvaluator = new RangerDefaultRowFilterPolicyItemEvaluator ( serviceDef , policy , policyItem , policyItemCounter ++ , options ) ; itemEvaluator . init ( ) ; ret . add ( itemEvaluator ) ; if ( CollectionUtils . isNotEmpty ( itemEvaluator . getConditionEvaluators ( ) ) ) { customConditionsCount += itemEvaluator . getConditionEvaluators ( ) . size ( ) ; } } } else { ret = Collections . < RangerRowFilterPolicyItemEvaluator > emptyList ( ) ; } return ret ; } private boolean isPolicyItemTypeEnabled ( RangerServiceDef serviceDef , int policyItemType ) { boolean ret = true ; if ( policyItemType == RangerPolicyItemEvaluator . POLICY_ITEM_TYPE_DENY || policyItemType == RangerPolicyItemEvaluator . POLICY_ITEM_TYPE_ALLOW_EXCEPTIONS || policyItemType == RangerPolicyItemEvaluator . POLICY_ITEM_TYPE_DENY_EXCEPTIONS ) { ret = ServiceDefUtil . getOption_enableDenyAndExceptionsInPolicies ( serviceDef ) ; } return ret ; } protected RangerPolicyItemEvaluator getMatchingPolicyItem ( RangerAccessRequest request , RangerAccessResult result ) { RangerPolicyItemEvaluator ret = null ; Integer policyType = getPolicy ( ) . getPolicyType ( ) ; if ( policyType == null ) { policyType = RangerPolicy . POLICY_TYPE_ACCESS ; } switch ( policyType ) { case RangerPolicy . POLICY_TYPE_ACCESS : { ret = getMatchingPolicyItem ( request , denyEvaluators , denyExceptionEvaluators ) ; if ( ret == null && ! result . getIsAllowed ( ) ) { ret = getMatchingPolicyItem ( request , allowEvaluators , allowExceptionEvaluators ) ; } break ; } case RangerPolicy . POLICY_TYPE_DATAMASK : { ret = getMatchingPolicyItem ( request , dataMaskEvaluators ) ; break ; } case RangerPolicy . POLICY_TYPE_ROWFILTER : { ret = getMatchingPolicyItem ( request , rowFilterEvaluators ) ; break ; } default : break ; } return ret ; } protected < T extends RangerPolicyItemEvaluator > T getMatchingPolicyItem ( RangerAccessRequest request , List < T > evaluators ) { T ret = getMatchingPolicyItem ( request , evaluators , null ) ; return ret ; } private < T extends RangerPolicyItemEvaluator > T getMatchingPolicyItem ( RangerAccessRequest request , List < T > evaluators , List < T > exceptionEvaluators ) { if ( LOG . isDebugEnabled ( ) ) { LOG . debug ( ""==> RangerDefaultPolicyEvaluator.getMatchingPolicyItem("" + request + "")"" ) ; } T ret = null ; if ( CollectionUtils . isNotEmpty ( evaluators ) ) { for ( T evaluator : evaluators ) { if ( evaluator . isMatch ( request ) ) { ret = evaluator ; break ; } } } if ( ret != null && CollectionUtils . isNotEmpty ( exceptionEvaluators ) ) { for ( T exceptionEvaluator : exceptionEvaluators ) { if ( exceptionEvaluator . isMatch ( request ) ) { if ( LOG . isDebugEnabled ( ) ) { LOG . debug ( ""RangerDefaultPolicyEvaluator.getMatchingPolicyItem("" + request + ""): found exception policyItem("" + exceptionEvaluator . getPolicyItem ( ) + ""); ignoring the matchedPolicyItem("" + ret . getPolicyItem ( ) + "")"" ) ; } ret = null ; break ; } } } if ( LOG . isDebugEnabled ( ) ) { LOG . debug ( ""<== RangerDefaultPolicyEvaluator.getMatchingPolicyItem("" + request + ""): "" + ret ) ; } return ret ; } private < T extends RangerPolicyItemEvaluator > T getMatchingPolicyItem ( String user , Set < String > userGroups , String accessType , List < T > evaluators , List < T > exceptionEvaluators ) { if ( LOG . isDebugEnabled ( ) ) { LOG . debug ( ""==> RangerDefaultPolicyEvaluator.getMatchingPolicyItem("" + user + "", "" + userGroups + "", "" + accessType + "")"" ) ; } T ret = null ; if ( CollectionUtils . isNotEmpty ( evaluators ) ) { for ( T evaluator : evaluators ) { if ( evaluator . matchUserGroup ( user , userGroups ) && evaluator . matchAccessType ( accessType ) ) { ret = evaluator ; break ; } } } if ( ret != null && CollectionUtils . isNotEmpty ( exceptionEvaluators ) ) { for ( T exceptionEvaluator : exceptionEvaluators ) { if ( exceptionEvaluator . matchUserGroup ( user , userGroups ) && exceptionEvaluator . matchAccessType ( accessType ) ) { if ( LOG . isDebugEnabled ( ) ) { LOG . debug ( ""RangerDefaultPolicyEvaluator.getMatchingPolicyItem("" + user + "", "" + userGroups + "", "" + accessType + ""): found exception policyItem("" + exceptionEvaluator . getPolicyItem ( ) + ""); ignoring the matchedPolicyItem("" + ret . getPolicyItem ( ) + "")"" ) ; } ret = null ; break ; } } } if ( LOG . isDebugEnabled ( ) ) { LOG . debug ( ""<== RangerDefaultPolicyEvaluator.getMatchingPolicyItem("" + user + "", "" + userGroups + "", "" + accessType + ""): "" + ret ) ; } return ret ; } }",Smelly
"public class IncrementalListResponse extends ListResponse { protected int fullSize ; public IncrementalListResponse ( List objectList , int fullSize ) { super ( objectList ) ; this . fullSize = fullSize ; } public int getFullSize ( ) { return fullSize ; } }",No
"public class TripleSplitToNodesMapperTest extends AbstractTripleSplitToNodesTests { @ Override protected Mapper < LongWritable , TripleWritable , LongWritable , NodeWritable > getInstance ( ) { return new TripleSplitToNodesMapper < LongWritable > ( ) ; } }",No
"public class LedgerEntriesImplTest { private final int entryNumber = 7 ; private LedgerEntriesImpl ledgerEntriesImpl ; private final List < LedgerEntry > entryList = Lists . newArrayList ( ) ; private final long ledgerId = 1234L ; private final long entryId = 5678L ; private final long length = 9876L ; private final byte [ ] dataBytes = ""test-ledger-entry-impl"" . getBytes ( UTF_8 ) ; private final ArrayList < ByteBuf > bufs = Lists . newArrayListWithExpectedSize ( entryNumber ) ; public LedgerEntriesImplTest ( ) { for ( int i = 0 ; i < entryNumber ; i ++ ) { ByteBuf buf = Unpooled . wrappedBuffer ( dataBytes ) ; bufs . add ( buf ) ; entryList . add ( LedgerEntryImpl . create ( ledgerId + i , entryId + i , length + i , buf ) ) ; } ledgerEntriesImpl = LedgerEntriesImpl . create ( entryList ) ; } @ After public void tearDown ( ) { ledgerEntriesImpl . close ( ) ; bufs . forEach ( byteBuf -> assertEquals ( 0 , byteBuf . refCnt ( ) ) ) ; try { ledgerEntriesImpl . getEntry ( entryId ) ; fail ( ""should fail getEntry after close"" ) ; } catch ( NullPointerException e ) { } try { ledgerEntriesImpl . iterator ( ) ; fail ( ""should fail iterator after close"" ) ; } catch ( NullPointerException e ) { } } @ Test public void testGetEntry ( ) { for ( int i = 0 ; i < entryNumber ; i ++ ) { LedgerEntry entry = ledgerEntriesImpl . getEntry ( entryId + i ) ; assertEquals ( entryList . get ( i ) . getLedgerId ( ) , entry . getLedgerId ( ) ) ; assertEquals ( entryList . get ( i ) . getEntryId ( ) , entry . getEntryId ( ) ) ; assertEquals ( entryList . get ( i ) . getLength ( ) , entry . getLength ( ) ) ; ByteBuf buf = entry . getEntryBuffer ( ) ; byte [ ] content = new byte [ buf . readableBytes ( ) ] ; buf . readBytes ( content ) ; assertArrayEquals ( dataBytes , content ) ; assertEquals ( 1 , entry . getEntryBuffer ( ) . refCnt ( ) ) ; } try { LedgerEntry entry = ledgerEntriesImpl . getEntry ( entryId - 1 ) ; fail ( ""Should get IndexOutOfBoundsException"" ) ; } catch ( IndexOutOfBoundsException e ) { } try { LedgerEntry entry = ledgerEntriesImpl . getEntry ( entryId + entryNumber ) ; fail ( ""Should get IndexOutOfBoundsException"" ) ; } catch ( IndexOutOfBoundsException e ) { } } @ Test public void testIterator ( ) { Iterator < LedgerEntry > entryIterator = ledgerEntriesImpl . iterator ( ) ; entryIterator . forEachRemaining ( ledgerEntry -> assertEquals ( 1 , ledgerEntry . getEntryBuffer ( ) . refCnt ( ) ) ) ; } }",No
"public class ActiveMQConnectionFactory extends JNDIBaseStorable implements ConnectionFactory , QueueConnectionFactory , TopicConnectionFactory , StatsCapable , Cloneable { public static final String DEFAULT_BROKER_BIND_URL = ""tcp://localhost:61616"" ; public static final String DEFAULT_BROKER_URL = ""failover://"" + DEFAULT_BROKER_BIND_URL ; public static final String DEFAULT_USER = null ; public static final String DEFAULT_PASSWORD = null ; public static final int DEFAULT_PRODUCER_WINDOW_SIZE = 0 ; protected URI brokerURL ; protected String userName ; protected String password ; protected String clientID ; protected boolean dispatchAsync = true ; protected boolean alwaysSessionAsync = true ; JMSStatsImpl factoryStats = new JMSStatsImpl ( ) ; private IdGenerator clientIdGenerator ; private String clientIDPrefix ; private IdGenerator connectionIdGenerator ; private String connectionIDPrefix ; private ActiveMQPrefetchPolicy prefetchPolicy = new ActiveMQPrefetchPolicy ( ) ; private RedeliveryPolicyMap redeliveryPolicyMap = new RedeliveryPolicyMap ( ) ; { redeliveryPolicyMap . setDefaultEntry ( new RedeliveryPolicy ( ) ) ; } private BlobTransferPolicy blobTransferPolicy = new BlobTransferPolicy ( ) ; private MessageTransformer transformer ; private boolean disableTimeStampsByDefault ; private boolean optimizedMessageDispatch = true ; private long optimizeAcknowledgeTimeOut = 300 ; private long optimizedAckScheduledAckInterval = 0 ; private boolean copyMessageOnSend = true ; private boolean useCompression ; private boolean objectMessageSerializationDefered ; private boolean useAsyncSend ; private boolean optimizeAcknowledge ; private int closeTimeout = 15000 ; private boolean useRetroactiveConsumer ; private boolean exclusiveConsumer ; private boolean nestedMapAndListEnabled = true ; private boolean alwaysSyncSend ; private boolean watchTopicAdvisories = true ; private int producerWindowSize = DEFAULT_PRODUCER_WINDOW_SIZE ; private long warnAboutUnstartedConnectionTimeout = 500L ; private int sendTimeout = 0 ; private boolean sendAcksAsync = true ; private TransportListener transportListener ; private ExceptionListener exceptionListener ; private int auditDepth = ActiveMQMessageAudit . DEFAULT_WINDOW_SIZE ; private int auditMaximumProducerNumber = ActiveMQMessageAudit . MAXIMUM_PRODUCER_COUNT ; private boolean useDedicatedTaskRunner ; private long consumerFailoverRedeliveryWaitPeriod = 0 ; private boolean checkForDuplicates = true ; private ClientInternalExceptionListener clientInternalExceptionListener ; private boolean messagePrioritySupported = true ; private boolean transactedIndividualAck = false ; private boolean nonBlockingRedelivery = false ; private int maxThreadPoolSize = ActiveMQConnection . DEFAULT_THREAD_POOL_SIZE ; private TaskRunnerFactory sessionTaskRunner ; private RejectedExecutionHandler rejectedTaskHandler = null ; public ActiveMQConnectionFactory ( ) { this ( DEFAULT_BROKER_URL ) ; } public ActiveMQConnectionFactory ( String brokerURL ) { this ( createURI ( brokerURL ) ) ; } public ActiveMQConnectionFactory ( URI brokerURL ) { setBrokerURL ( brokerURL . toString ( ) ) ; } public ActiveMQConnectionFactory ( String userName , String password , URI brokerURL ) { setUserName ( userName ) ; setPassword ( password ) ; setBrokerURL ( brokerURL . toString ( ) ) ; } public ActiveMQConnectionFactory ( String userName , String password , String brokerURL ) { setUserName ( userName ) ; setPassword ( password ) ; setBrokerURL ( brokerURL ) ; } public ActiveMQConnectionFactory copy ( ) { try { return ( ActiveMQConnectionFactory ) super . clone ( ) ; } catch ( CloneNotSupportedException e ) { throw new RuntimeException ( ""This should never happen: "" + e , e ) ; } } private static URI createURI ( String brokerURL ) { try { return new URI ( brokerURL ) ; } catch ( URISyntaxException e ) { throw ( IllegalArgumentException ) new IllegalArgumentException ( ""Invalid broker URI: "" + brokerURL ) . initCause ( e ) ; } } public Connection createConnection ( ) throws JMSException { return createActiveMQConnection ( ) ; } public Connection createConnection ( String userName , String password ) throws JMSException { return createActiveMQConnection ( userName , password ) ; } public QueueConnection createQueueConnection ( ) throws JMSException { return createActiveMQConnection ( ) . enforceQueueOnlyConnection ( ) ; } public QueueConnection createQueueConnection ( String userName , String password ) throws JMSException { return createActiveMQConnection ( userName , password ) . enforceQueueOnlyConnection ( ) ; } public TopicConnection createTopicConnection ( ) throws JMSException { return createActiveMQConnection ( ) ; } public TopicConnection createTopicConnection ( String userName , String password ) throws JMSException { return createActiveMQConnection ( userName , password ) ; } public StatsImpl getStats ( ) { return this . factoryStats ; } protected ActiveMQConnection createActiveMQConnection ( ) throws JMSException { return createActiveMQConnection ( userName , password ) ; } protected Transport createTransport ( ) throws JMSException { try { return TransportFactory . connect ( brokerURL ) ; } catch ( Exception e ) { throw JMSExceptionSupport . create ( ""Could not create Transport. Reason: "" + e , e ) ; } } protected ActiveMQConnection createActiveMQConnection ( String userName , String password ) throws JMSException { if ( brokerURL == null ) { throw new ConfigurationException ( ""brokerURL not set."" ) ; } ActiveMQConnection connection = null ; try { Transport transport = createTransport ( ) ; connection = createActiveMQConnection ( transport , factoryStats ) ; connection . setUserName ( userName ) ; connection . setPassword ( password ) ; configureConnection ( connection ) ; transport . start ( ) ; if ( clientID != null ) { connection . setDefaultClientID ( clientID ) ; } return connection ; } catch ( JMSException e ) { try { connection . close ( ) ; } catch ( Throwable ignore ) { } throw e ; } catch ( Exception e ) { try { connection . close ( ) ; } catch ( Throwable ignore ) { } throw JMSExceptionSupport . create ( ""Could not connect to broker URL: "" + brokerURL + "". Reason: "" + e , e ) ; } } protected ActiveMQConnection createActiveMQConnection ( Transport transport , JMSStatsImpl stats ) throws Exception { ActiveMQConnection connection = new ActiveMQConnection ( transport , getClientIdGenerator ( ) , getConnectionIdGenerator ( ) , stats ) ; return connection ; } protected void configureConnection ( ActiveMQConnection connection ) throws JMSException { connection . setPrefetchPolicy ( getPrefetchPolicy ( ) ) ; connection . setDisableTimeStampsByDefault ( isDisableTimeStampsByDefault ( ) ) ; connection . setOptimizedMessageDispatch ( isOptimizedMessageDispatch ( ) ) ; connection . setCopyMessageOnSend ( isCopyMessageOnSend ( ) ) ; connection . setUseCompression ( isUseCompression ( ) ) ; connection . setObjectMessageSerializationDefered ( isObjectMessageSerializationDefered ( ) ) ; connection . setDispatchAsync ( isDispatchAsync ( ) ) ; connection . setUseAsyncSend ( isUseAsyncSend ( ) ) ; connection . setAlwaysSyncSend ( isAlwaysSyncSend ( ) ) ; connection . setAlwaysSessionAsync ( isAlwaysSessionAsync ( ) ) ; connection . setOptimizeAcknowledge ( isOptimizeAcknowledge ( ) ) ; connection . setOptimizeAcknowledgeTimeOut ( getOptimizeAcknowledgeTimeOut ( ) ) ; connection . setOptimizedAckScheduledAckInterval ( getOptimizedAckScheduledAckInterval ( ) ) ; connection . setUseRetroactiveConsumer ( isUseRetroactiveConsumer ( ) ) ; connection . setExclusiveConsumer ( isExclusiveConsumer ( ) ) ; connection . setRedeliveryPolicyMap ( getRedeliveryPolicyMap ( ) ) ; connection . setTransformer ( getTransformer ( ) ) ; connection . setBlobTransferPolicy ( getBlobTransferPolicy ( ) . copy ( ) ) ; connection . setWatchTopicAdvisories ( isWatchTopicAdvisories ( ) ) ; connection . setProducerWindowSize ( getProducerWindowSize ( ) ) ; connection . setWarnAboutUnstartedConnectionTimeout ( getWarnAboutUnstartedConnectionTimeout ( ) ) ; connection . setSendTimeout ( getSendTimeout ( ) ) ; connection . setCloseTimeout ( getCloseTimeout ( ) ) ; connection . setSendAcksAsync ( isSendAcksAsync ( ) ) ; connection . setAuditDepth ( getAuditDepth ( ) ) ; connection . setAuditMaximumProducerNumber ( getAuditMaximumProducerNumber ( ) ) ; connection . setUseDedicatedTaskRunner ( isUseDedicatedTaskRunner ( ) ) ; connection . setConsumerFailoverRedeliveryWaitPeriod ( getConsumerFailoverRedeliveryWaitPeriod ( ) ) ; connection . setCheckForDuplicates ( isCheckForDuplicates ( ) ) ; connection . setMessagePrioritySupported ( isMessagePrioritySupported ( ) ) ; connection . setTransactedIndividualAck ( isTransactedIndividualAck ( ) ) ; connection . setNonBlockingRedelivery ( isNonBlockingRedelivery ( ) ) ; connection . setMaxThreadPoolSize ( getMaxThreadPoolSize ( ) ) ; connection . setSessionTaskRunner ( getSessionTaskRunner ( ) ) ; connection . setRejectedTaskHandler ( getRejectedTaskHandler ( ) ) ; connection . setNestedMapAndListEnabled ( isNestedMapAndListEnabled ( ) ) ; if ( transportListener != null ) { connection . addTransportListener ( transportListener ) ; } if ( exceptionListener != null ) { connection . setExceptionListener ( exceptionListener ) ; } if ( clientInternalExceptionListener != null ) { connection . setClientInternalExceptionListener ( clientInternalExceptionListener ) ; } } public String getBrokerURL ( ) { return brokerURL == null ? null : brokerURL . toString ( ) ; } public void setBrokerURL ( String brokerURL ) { this . brokerURL = createURI ( brokerURL ) ; if ( this . brokerURL . getQuery ( ) != null ) { try { Map < String , String > map = URISupport . parseQuery ( this . brokerURL . getQuery ( ) ) ; Map < String , Object > jmsOptionsMap = IntrospectionSupport . extractProperties ( map , ""jms."" ) ; if ( buildFromMap ( jmsOptionsMap ) ) { if ( ! jmsOptionsMap . isEmpty ( ) ) { String msg = ""There are "" + jmsOptionsMap . size ( ) + "" jms options that couldn't be set on the ConnectionFactory."" + "" Check the options are spelled correctly."" + "" Unknown parameters=["" + jmsOptionsMap + ""]."" + "" This connection factory cannot be started."" ; throw new IllegalArgumentException ( msg ) ; } this . brokerURL = URISupport . createRemainingURI ( this . brokerURL , map ) ; } } catch ( URISyntaxException e ) { } } else { try { CompositeData data = URISupport . parseComposite ( this . brokerURL ) ; Map < String , Object > jmsOptionsMap = IntrospectionSupport . extractProperties ( data . getParameters ( ) , ""jms."" ) ; if ( buildFromMap ( jmsOptionsMap ) ) { if ( ! jmsOptionsMap . isEmpty ( ) ) { String msg = ""There are "" + jmsOptionsMap . size ( ) + "" jms options that couldn't be set on the ConnectionFactory."" + "" Check the options are spelled correctly."" + "" Unknown parameters=["" + jmsOptionsMap + ""]."" + "" This connection factory cannot be started."" ; throw new IllegalArgumentException ( msg ) ; } this . brokerURL = data . toURI ( ) ; } } catch ( URISyntaxException e ) { } } } public String getClientID ( ) { return clientID ; } public void setClientID ( String clientID ) { this . clientID = clientID ; } public boolean isCopyMessageOnSend ( ) { return copyMessageOnSend ; } public void setCopyMessageOnSend ( boolean copyMessageOnSend ) { this . copyMessageOnSend = copyMessageOnSend ; } public boolean isDisableTimeStampsByDefault ( ) { return disableTimeStampsByDefault ; } public void setDisableTimeStampsByDefault ( boolean disableTimeStampsByDefault ) { this . disableTimeStampsByDefault = disableTimeStampsByDefault ; } public boolean isOptimizedMessageDispatch ( ) { return optimizedMessageDispatch ; } public void setOptimizedMessageDispatch ( boolean optimizedMessageDispatch ) { this . optimizedMessageDispatch = optimizedMessageDispatch ; } public String getPassword ( ) { return password ; } public void setPassword ( String password ) { this . password = password ; } public ActiveMQPrefetchPolicy getPrefetchPolicy ( ) { return prefetchPolicy ; } public void setPrefetchPolicy ( ActiveMQPrefetchPolicy prefetchPolicy ) { this . prefetchPolicy = prefetchPolicy ; } public boolean isUseAsyncSend ( ) { return useAsyncSend ; } public BlobTransferPolicy getBlobTransferPolicy ( ) { return blobTransferPolicy ; } public void setBlobTransferPolicy ( BlobTransferPolicy blobTransferPolicy ) { this . blobTransferPolicy = blobTransferPolicy ; } public void setUseAsyncSend ( boolean useAsyncSend ) { this . useAsyncSend = useAsyncSend ; } public synchronized boolean isWatchTopicAdvisories ( ) { return watchTopicAdvisories ; } public synchronized void setWatchTopicAdvisories ( boolean watchTopicAdvisories ) { this . watchTopicAdvisories = watchTopicAdvisories ; } public boolean isAlwaysSyncSend ( ) { return this . alwaysSyncSend ; } public void setAlwaysSyncSend ( boolean alwaysSyncSend ) { this . alwaysSyncSend = alwaysSyncSend ; } public String getUserName ( ) { return userName ; } public void setUserName ( String userName ) { this . userName = userName ; } public boolean isUseRetroactiveConsumer ( ) { return useRetroactiveConsumer ; } public void setUseRetroactiveConsumer ( boolean useRetroactiveConsumer ) { this . useRetroactiveConsumer = useRetroactiveConsumer ; } public boolean isExclusiveConsumer ( ) { return exclusiveConsumer ; } public void setExclusiveConsumer ( boolean exclusiveConsumer ) { this . exclusiveConsumer = exclusiveConsumer ; } public RedeliveryPolicy getRedeliveryPolicy ( ) { return redeliveryPolicyMap . getDefaultEntry ( ) ; } public void setRedeliveryPolicy ( RedeliveryPolicy redeliveryPolicy ) { this . redeliveryPolicyMap . setDefaultEntry ( redeliveryPolicy ) ; } public RedeliveryPolicyMap getRedeliveryPolicyMap ( ) { return this . redeliveryPolicyMap ; } public void setRedeliveryPolicyMap ( RedeliveryPolicyMap redeliveryPolicyMap ) { this . redeliveryPolicyMap = redeliveryPolicyMap ; } public MessageTransformer getTransformer ( ) { return transformer ; } public int getSendTimeout ( ) { return sendTimeout ; } public void setSendTimeout ( int sendTimeout ) { this . sendTimeout = sendTimeout ; } public boolean isSendAcksAsync ( ) { return sendAcksAsync ; } public void setSendAcksAsync ( boolean sendAcksAsync ) { this . sendAcksAsync = sendAcksAsync ; } public boolean isMessagePrioritySupported ( ) { return this . messagePrioritySupported ; } public void setMessagePrioritySupported ( boolean messagePrioritySupported ) { this . messagePrioritySupported = messagePrioritySupported ; } public void setTransformer ( MessageTransformer transformer ) { this . transformer = transformer ; } @ SuppressWarnings ( { ""unchecked"" , ""rawtypes"" } ) @ Override public void buildFromProperties ( Properties properties ) { if ( properties == null ) { properties = new Properties ( ) ; } String temp = properties . getProperty ( Context . PROVIDER_URL ) ; if ( temp == null || temp . length ( ) == 0 ) { temp = properties . getProperty ( ""brokerURL"" ) ; } if ( temp != null && temp . length ( ) > 0 ) { setBrokerURL ( temp ) ; } Map < String , Object > p = new HashMap ( properties ) ; buildFromMap ( p ) ; } public boolean buildFromMap ( Map < String , Object > properties ) { boolean rc = false ; ActiveMQPrefetchPolicy p = new ActiveMQPrefetchPolicy ( ) ; if ( IntrospectionSupport . setProperties ( p , properties , ""prefetchPolicy."" ) ) { setPrefetchPolicy ( p ) ; rc = true ; } RedeliveryPolicy rp = new RedeliveryPolicy ( ) ; if ( IntrospectionSupport . setProperties ( rp , properties , ""redeliveryPolicy."" ) ) { setRedeliveryPolicy ( rp ) ; rc = true ; } BlobTransferPolicy blobTransferPolicy = new BlobTransferPolicy ( ) ; if ( IntrospectionSupport . setProperties ( blobTransferPolicy , properties , ""blobTransferPolicy."" ) ) { setBlobTransferPolicy ( blobTransferPolicy ) ; rc = true ; } rc |= IntrospectionSupport . setProperties ( this , properties ) ; return rc ; } @ Override public void populateProperties ( Properties props ) { props . setProperty ( ""dispatchAsync"" , Boolean . toString ( isDispatchAsync ( ) ) ) ; if ( getBrokerURL ( ) != null ) { props . setProperty ( Context . PROVIDER_URL , getBrokerURL ( ) ) ; props . setProperty ( ""brokerURL"" , getBrokerURL ( ) ) ; } if ( getClientID ( ) != null ) { props . setProperty ( ""clientID"" , getClientID ( ) ) ; } IntrospectionSupport . getProperties ( getPrefetchPolicy ( ) , props , ""prefetchPolicy."" ) ; IntrospectionSupport . getProperties ( getRedeliveryPolicy ( ) , props , ""redeliveryPolicy."" ) ; IntrospectionSupport . getProperties ( getBlobTransferPolicy ( ) , props , ""blobTransferPolicy."" ) ; props . setProperty ( ""copyMessageOnSend"" , Boolean . toString ( isCopyMessageOnSend ( ) ) ) ; props . setProperty ( ""disableTimeStampsByDefault"" , Boolean . toString ( isDisableTimeStampsByDefault ( ) ) ) ; props . setProperty ( ""objectMessageSerializationDefered"" , Boolean . toString ( isObjectMessageSerializationDefered ( ) ) ) ; props . setProperty ( ""optimizedMessageDispatch"" , Boolean . toString ( isOptimizedMessageDispatch ( ) ) ) ; if ( getPassword ( ) != null ) { props . setProperty ( ""password"" , getPassword ( ) ) ; } props . setProperty ( ""useAsyncSend"" , Boolean . toString ( isUseAsyncSend ( ) ) ) ; props . setProperty ( ""useCompression"" , Boolean . toString ( isUseCompression ( ) ) ) ; props . setProperty ( ""useRetroactiveConsumer"" , Boolean . toString ( isUseRetroactiveConsumer ( ) ) ) ; props . setProperty ( ""watchTopicAdvisories"" , Boolean . toString ( isWatchTopicAdvisories ( ) ) ) ; if ( getUserName ( ) != null ) { props . setProperty ( ""userName"" , getUserName ( ) ) ; } props . setProperty ( ""closeTimeout"" , Integer . toString ( getCloseTimeout ( ) ) ) ; props . setProperty ( ""alwaysSessionAsync"" , Boolean . toString ( isAlwaysSessionAsync ( ) ) ) ; props . setProperty ( ""optimizeAcknowledge"" , Boolean . toString ( isOptimizeAcknowledge ( ) ) ) ; props . setProperty ( ""statsEnabled"" , Boolean . toString ( isStatsEnabled ( ) ) ) ; props . setProperty ( ""alwaysSyncSend"" , Boolean . toString ( isAlwaysSyncSend ( ) ) ) ; props . setProperty ( ""producerWindowSize"" , Integer . toString ( getProducerWindowSize ( ) ) ) ; props . setProperty ( ""sendTimeout"" , Integer . toString ( getSendTimeout ( ) ) ) ; props . setProperty ( ""sendAcksAsync"" , Boolean . toString ( isSendAcksAsync ( ) ) ) ; props . setProperty ( ""auditDepth"" , Integer . toString ( getAuditDepth ( ) ) ) ; props . setProperty ( ""auditMaximumProducerNumber"" , Integer . toString ( getAuditMaximumProducerNumber ( ) ) ) ; props . setProperty ( ""checkForDuplicates"" , Boolean . toString ( isCheckForDuplicates ( ) ) ) ; props . setProperty ( ""messagePrioritySupported"" , Boolean . toString ( isMessagePrioritySupported ( ) ) ) ; props . setProperty ( ""transactedIndividualAck"" , Boolean . toString ( isTransactedIndividualAck ( ) ) ) ; props . setProperty ( ""nonBlockingRedelivery"" , Boolean . toString ( isNonBlockingRedelivery ( ) ) ) ; props . setProperty ( ""maxThreadPoolSize"" , Integer . toString ( getMaxThreadPoolSize ( ) ) ) ; props . setProperty ( ""nestedMapAndListEnabled"" , Boolean . toString ( isNestedMapAndListEnabled ( ) ) ) ; } public boolean isUseCompression ( ) { return useCompression ; } public void setUseCompression ( boolean useCompression ) { this . useCompression = useCompression ; } public boolean isObjectMessageSerializationDefered ( ) { return objectMessageSerializationDefered ; } public void setObjectMessageSerializationDefered ( boolean objectMessageSerializationDefered ) { this . objectMessageSerializationDefered = objectMessageSerializationDefered ; } public boolean isDispatchAsync ( ) { return dispatchAsync ; } public void setDispatchAsync ( boolean asyncDispatch ) { this . dispatchAsync = asyncDispatch ; } public int getCloseTimeout ( ) { return closeTimeout ; } public void setCloseTimeout ( int closeTimeout ) { this . closeTimeout = closeTimeout ; } public boolean isAlwaysSessionAsync ( ) { return alwaysSessionAsync ; } public void setAlwaysSessionAsync ( boolean alwaysSessionAsync ) { this . alwaysSessionAsync = alwaysSessionAsync ; } public boolean isOptimizeAcknowledge ( ) { return optimizeAcknowledge ; } public void setOptimizeAcknowledge ( boolean optimizeAcknowledge ) { this . optimizeAcknowledge = optimizeAcknowledge ; } public void setOptimizeAcknowledgeTimeOut ( long optimizeAcknowledgeTimeOut ) { this . optimizeAcknowledgeTimeOut = optimizeAcknowledgeTimeOut ; } public long getOptimizeAcknowledgeTimeOut ( ) { return optimizeAcknowledgeTimeOut ; } public boolean isNestedMapAndListEnabled ( ) { return nestedMapAndListEnabled ; } public void setNestedMapAndListEnabled ( boolean structuredMapsEnabled ) { this . nestedMapAndListEnabled = structuredMapsEnabled ; } public String getClientIDPrefix ( ) { return clientIDPrefix ; } public void setClientIDPrefix ( String clientIDPrefix ) { this . clientIDPrefix = clientIDPrefix ; } protected synchronized IdGenerator getClientIdGenerator ( ) { if ( clientIdGenerator == null ) { if ( clientIDPrefix != null ) { clientIdGenerator = new IdGenerator ( clientIDPrefix ) ; } else { clientIdGenerator = new IdGenerator ( ) ; } } return clientIdGenerator ; } protected void setClientIdGenerator ( IdGenerator clientIdGenerator ) { this . clientIdGenerator = clientIdGenerator ; } public void setConnectionIDPrefix ( String connectionIDPrefix ) { this . connectionIDPrefix = connectionIDPrefix ; } protected synchronized IdGenerator getConnectionIdGenerator ( ) { if ( connectionIdGenerator == null ) { if ( connectionIDPrefix != null ) { connectionIdGenerator = new IdGenerator ( connectionIDPrefix ) ; } else { connectionIdGenerator = new IdGenerator ( ) ; } } return connectionIdGenerator ; } protected void setConnectionIdGenerator ( IdGenerator connectionIdGenerator ) { this . connectionIdGenerator = connectionIdGenerator ; } public boolean isStatsEnabled ( ) { return this . factoryStats . isEnabled ( ) ; } public void setStatsEnabled ( boolean statsEnabled ) { this . factoryStats . setEnabled ( statsEnabled ) ; } public synchronized int getProducerWindowSize ( ) { return producerWindowSize ; } public synchronized void setProducerWindowSize ( int producerWindowSize ) { this . producerWindowSize = producerWindowSize ; } public long getWarnAboutUnstartedConnectionTimeout ( ) { return warnAboutUnstartedConnectionTimeout ; } public void setWarnAboutUnstartedConnectionTimeout ( long warnAboutUnstartedConnectionTimeout ) { this . warnAboutUnstartedConnectionTimeout = warnAboutUnstartedConnectionTimeout ; } public TransportListener getTransportListener ( ) { return transportListener ; } public void setTransportListener ( TransportListener transportListener ) { this . transportListener = transportListener ; } public ExceptionListener getExceptionListener ( ) { return exceptionListener ; } public void setExceptionListener ( ExceptionListener exceptionListener ) { this . exceptionListener = exceptionListener ; } public int getAuditDepth ( ) { return auditDepth ; } public void setAuditDepth ( int auditDepth ) { this . auditDepth = auditDepth ; } public int getAuditMaximumProducerNumber ( ) { return auditMaximumProducerNumber ; } public void setAuditMaximumProducerNumber ( int auditMaximumProducerNumber ) { this . auditMaximumProducerNumber = auditMaximumProducerNumber ; } public void setUseDedicatedTaskRunner ( boolean useDedicatedTaskRunner ) { this . useDedicatedTaskRunner = useDedicatedTaskRunner ; } public boolean isUseDedicatedTaskRunner ( ) { return useDedicatedTaskRunner ; } public void setConsumerFailoverRedeliveryWaitPeriod ( long consumerFailoverRedeliveryWaitPeriod ) { this . consumerFailoverRedeliveryWaitPeriod = consumerFailoverRedeliveryWaitPeriod ; } public long getConsumerFailoverRedeliveryWaitPeriod ( ) { return consumerFailoverRedeliveryWaitPeriod ; } public ClientInternalExceptionListener getClientInternalExceptionListener ( ) { return clientInternalExceptionListener ; } public void setClientInternalExceptionListener ( ClientInternalExceptionListener clientInternalExceptionListener ) { this . clientInternalExceptionListener = clientInternalExceptionListener ; } public boolean isCheckForDuplicates ( ) { return this . checkForDuplicates ; } public void setCheckForDuplicates ( boolean checkForDuplicates ) { this . checkForDuplicates = checkForDuplicates ; } public boolean isTransactedIndividualAck ( ) { return transactedIndividualAck ; } public void setTransactedIndividualAck ( boolean transactedIndividualAck ) { this . transactedIndividualAck = transactedIndividualAck ; } public boolean isNonBlockingRedelivery ( ) { return nonBlockingRedelivery ; } public void setNonBlockingRedelivery ( boolean nonBlockingRedelivery ) { this . nonBlockingRedelivery = nonBlockingRedelivery ; } public int getMaxThreadPoolSize ( ) { return maxThreadPoolSize ; } public void setMaxThreadPoolSize ( int maxThreadPoolSize ) { this . maxThreadPoolSize = maxThreadPoolSize ; } public TaskRunnerFactory getSessionTaskRunner ( ) { return sessionTaskRunner ; } public void setSessionTaskRunner ( TaskRunnerFactory sessionTaskRunner ) { this . sessionTaskRunner = sessionTaskRunner ; } public RejectedExecutionHandler getRejectedTaskHandler ( ) { return rejectedTaskHandler ; } public void setRejectedTaskHandler ( RejectedExecutionHandler rejectedTaskHandler ) { this . rejectedTaskHandler = rejectedTaskHandler ; } public long getOptimizedAckScheduledAckInterval ( ) { return optimizedAckScheduledAckInterval ; } public void setOptimizedAckScheduledAckInterval ( long optimizedAckScheduledAckInterval ) { this . optimizedAckScheduledAckInterval = optimizedAckScheduledAckInterval ; } }",Smelly
" public class GTAggregateScanner implements IGTScanner , IGTBypassChecker { private static final Logger logger = LoggerFactory . getLogger ( GTAggregateScanner . class ) ; private static final int MAX_BUFFER_SIZE = 64 * 1024 * 1024 ; final GTInfo info ; final ImmutableBitSet dimensions ; final ImmutableBitSet groupBy ; final ImmutableBitSet metrics ; final String [ ] metricsAggrFuncs ; final IGTScanner inputScanner ; final BufferedMeasureCodec measureCodec ; final AggregationCache aggrCache ; long spillThreshold ; final int storagePushDownLimit ; final StorageLimitLevel storageLimitLevel ; final boolean spillEnabled ; final TupleFilter havingFilter ; private long inputRowCount = 0L ; private MemoryWaterLevel memTracker ; private boolean [ ] aggrMask ; public GTAggregateScanner ( IGTScanner inputScanner , GTScanRequest req ) { this ( inputScanner , req , true ) ; } public GTAggregateScanner ( IGTScanner input , GTScanRequest req , boolean spillEnabled ) { if ( ! req . hasAggregation ( ) ) throw new IllegalStateException ( ) ; if ( input instanceof GTFilterScanner ) { logger . info ( ""setting IGTBypassChecker of child"" ) ; ( ( GTFilterScanner ) input ) . setChecker ( this ) ; } else { logger . info ( ""applying a GTFilterScanner with IGTBypassChecker on top child"" ) ; input = new GTFilterScanner ( input , null , this ) ; } this . inputScanner = input ; this . info = this . inputScanner . getInfo ( ) ; this . dimensions = req . getDimensions ( ) ; this . groupBy = req . getAggrGroupBy ( ) ; this . metrics = req . getAggrMetrics ( ) ; this . metricsAggrFuncs = req . getAggrMetricsFuncs ( ) ; this . measureCodec = req . createMeasureCodec ( ) ; this . spillThreshold = ( long ) ( req . getAggCacheMemThreshold ( ) * MemoryBudgetController . ONE_GB ) ; this . aggrMask = new boolean [ metricsAggrFuncs . length ] ; this . storagePushDownLimit = req . getStoragePushDownLimit ( ) ; this . storageLimitLevel = req . getStorageLimitLevel ( ) ; this . spillEnabled = spillEnabled ; this . havingFilter = req . getHavingFilterPushDown ( ) ; this . aggrCache = new AggregationCache ( ) ; Arrays . fill ( aggrMask , true ) ; } public static long estimateSizeOfAggrCache ( byte [ ] keySample , MeasureAggregator < ? > [ ] aggrSample , int size ) { return ( estimateSizeOf ( keySample ) + estimateSizeOf ( aggrSample ) + 64 ) * size ; } public static long estimateSizeOf ( MeasureAggregator [ ] aggrs ) { long est = ( aggrs . length + 1 ) / 2 * 8L + 4 + ( 4 ) ; for ( MeasureAggregator aggr : aggrs ) { if ( aggr != null ) est += aggr . getMemBytesEstimate ( ) ; } return est ; } public static long estimateSizeOf ( byte [ ] bytes ) { return ( bytes . length + 7 ) / 8 * 8L + 4 + ( 4 ) ; } public void trackMemoryLevel ( MemoryWaterLevel tracker ) { this . memTracker = tracker ; } @ Override public GTInfo getInfo ( ) { return info ; } public long getInputRowCount ( ) { return inputRowCount ; } @ Override public void close ( ) throws IOException { inputScanner . close ( ) ; aggrCache . close ( ) ; } @ Override public Iterator < GTRecord > iterator ( ) { long count = 0 ; for ( GTRecord r : inputScanner ) { boolean ret = aggrCache . aggregate ( r ) ; if ( ! ret ) { logger . info ( ""abort reading inputScanner because storage push down limit is hit"" ) ; break ; } count ++ ; } logger . info ( ""GTAggregateScanner input rows: "" + count ) ; return aggrCache . iterator ( ) ; } public int getNumOfSpills ( ) { return aggrCache . dumps . size ( ) ; } public void setAggrMask ( boolean [ ] aggrMask ) { this . aggrMask = aggrMask ; } public long getEstimateSizeOfAggrCache ( ) { return aggrCache . estimatedMemSize ( ) ; } public boolean shouldBypass ( GTRecord record ) { return aggrCache . shouldBypass ( record ) ; } class AggregationCache implements Closeable { class ByPassChecker { private int aggregateBufferSizeLimit = - 1 ; private byte [ ] currentLastKey = null ; private int [ ] groupOffsetsInLastKey = null ; private int byPassCounter = 0 ; ByPassChecker ( int aggregateBufferSizeLimit ) { this . aggregateBufferSizeLimit = aggregateBufferSizeLimit ; int p = 0 ; int idx = 0 ; this . groupOffsetsInLastKey = new int [ groupBy . trueBitCount ( ) ] ; for ( int i = 0 ; i < dimensions . trueBitCount ( ) ; i ++ ) { int c = dimensions . trueBitAt ( i ) ; int l = info . codeSystem . maxCodeLength ( c ) ; if ( groupBy . get ( c ) ) groupOffsetsInLastKey [ idx ++ ] = p ; p += l ; } } boolean shouldByPass ( GTRecord record ) { if ( dumps . size ( ) > 0 ) { return false ; } Preconditions . checkState ( aggBufMap . size ( ) <= aggregateBufferSizeLimit ) ; if ( aggBufMap . size ( ) == aggregateBufferSizeLimit ) { Preconditions . checkNotNull ( currentLastKey ) ; for ( int i = 0 ; i < groupBy . trueBitCount ( ) ; i ++ ) { int c = groupBy . trueBitAt ( i ) ; ByteArray col = record . get ( c ) ; int compare = Bytes . compareTo ( col . array ( ) , col . offset ( ) , col . length ( ) , currentLastKey , groupOffsetsInLastKey [ i ] , col . length ( ) ) ; if ( compare > 0 ) { byPassCounter ++ ; return true ; } else if ( compare < 0 ) { return false ; } } } return false ; } void updateOnBufferChange ( ) { if ( aggBufMap . size ( ) > aggregateBufferSizeLimit ) { aggBufMap . pollLastEntry ( ) ; Preconditions . checkState ( aggBufMap . size ( ) == aggregateBufferSizeLimit ) ; } currentLastKey = aggBufMap . lastKey ( ) ; } int getByPassCounter ( ) { return byPassCounter ; } } final List < Dump > dumps ; final int keyLength ; final boolean [ ] compareMask ; boolean compareAll = true ; long sumSpilledSize = 0 ; ByPassChecker byPassChecker = null ; final Comparator < byte [ ] > bytesComparator = new Comparator < byte [ ] > ( ) { @ Override public int compare ( byte [ ] o1 , byte [ ] o2 ) { if ( compareAll ) { return Bytes . compareTo ( o1 , o2 ) ; } int result = 0 ; for ( int i = 0 ; i < keyLength ; ++ i ) { if ( compareMask [ i ] ) { int a = ( o1 [ i ] & 0xff ) ; int b = ( o2 [ i ] & 0xff ) ; result = a - b ; if ( result == 0 ) { continue ; } else { return result ; } } } return result ; } } ; TreeMap < byte [ ] , MeasureAggregator [ ] > aggBufMap ; public AggregationCache ( ) { compareMask = createCompareMask ( ) ; for ( boolean l : compareMask ) { compareAll = compareAll && l ; } keyLength = compareMask . length ; dumps = Lists . newArrayList ( ) ; aggBufMap = createBuffMap ( ) ; if ( storageLimitLevel == StorageLimitLevel . LIMIT_ON_RETURN_SIZE ) { byPassChecker = new ByPassChecker ( storagePushDownLimit ) ; } } public boolean shouldBypass ( GTRecord record ) { if ( byPassChecker == null ) { return false ; } boolean b = byPassChecker . shouldByPass ( record ) ; return b ; } private boolean [ ] createCompareMask ( ) { int keyLength = 0 ; for ( int i = 0 ; i < dimensions . trueBitCount ( ) ; i ++ ) { int c = dimensions . trueBitAt ( i ) ; int l = info . codeSystem . maxCodeLength ( c ) ; keyLength += l ; } boolean [ ] mask = new boolean [ keyLength ] ; int p = 0 ; for ( int i = 0 ; i < dimensions . trueBitCount ( ) ; i ++ ) { int c = dimensions . trueBitAt ( i ) ; int l = info . codeSystem . maxCodeLength ( c ) ; boolean m = groupBy . get ( c ) ? true : false ; for ( int j = 0 ; j < l ; j ++ ) { mask [ p ++ ] = m ; } } return mask ; } private TreeMap < byte [ ] , MeasureAggregator [ ] > createBuffMap ( ) { return Maps . newTreeMap ( bytesComparator ) ; } private byte [ ] createKey ( GTRecord record ) { byte [ ] result = new byte [ keyLength ] ; int offset = 0 ; for ( int i = 0 ; i < dimensions . trueBitCount ( ) ; i ++ ) { int c = dimensions . trueBitAt ( i ) ; final ByteArray byteArray = record . cols [ c ] ; final int columnLength = info . codeSystem . maxCodeLength ( c ) ; System . arraycopy ( byteArray . array ( ) , byteArray . offset ( ) , result , offset , byteArray . length ( ) ) ; offset += columnLength ; } assert offset == result . length ; return result ; } boolean aggregate ( GTRecord r ) { if ( ++ inputRowCount % 100000 == 0 ) { if ( memTracker != null ) { memTracker . markHigh ( ) ; } final long estMemSize = estimatedMemSize ( ) ; if ( spillThreshold > 0 && estMemSize > spillThreshold ) { if ( ! spillEnabled ) { throw new ResourceLimitExceededException ( ""aggregation's memory consumption "" + estMemSize + "" exceeds threshold "" + spillThreshold ) ; } spillBuffMap ( estMemSize ) ; aggBufMap = createBuffMap ( ) ; } } final byte [ ] key = createKey ( r ) ; MeasureAggregator [ ] aggrs = aggBufMap . get ( key ) ; if ( aggrs == null ) { if ( getNumOfSpills ( ) == 0 && storageLimitLevel == StorageLimitLevel . LIMIT_ON_SCAN && aggBufMap . size ( ) >= storagePushDownLimit ) { return false ; } aggrs = newAggregators ( ) ; aggBufMap . put ( key , aggrs ) ; } for ( int i = 0 ; i < aggrs . length ; i ++ ) { if ( aggrMask [ i ] ) { int col = metrics . trueBitAt ( i ) ; Object metrics = info . codeSystem . decodeColumnValue ( col , r . cols [ col ] . asBuffer ( ) ) ; aggrs [ i ] . aggregate ( metrics ) ; } } if ( byPassChecker != null ) { byPassChecker . updateOnBufferChange ( ) ; } return true ; } private void spillBuffMap ( long estMemSize ) throws RuntimeException { try { Dump dump = new Dump ( aggBufMap , estMemSize ) ; dump . flush ( ) ; dumps . add ( dump ) ; sumSpilledSize += dump . size ( ) ; if ( sumSpilledSize > spillThreshold ) { for ( Dump current : dumps ) { current . spill ( ) ; } spillThreshold += sumSpilledSize ; sumSpilledSize = 0 ; } else { spillThreshold -= dump . size ( ) ; } } catch ( Exception e ) { throw new RuntimeException ( ""AggregationCache failed to spill"" , e ) ; } } @ Override public void close ( ) throws RuntimeException { try { logger . info ( ""closing aggrCache"" ) ; if ( byPassChecker != null ) { logger . info ( ""AggregationCache byPassChecker helps to skip {} cuboid rows"" , byPassChecker . getByPassCounter ( ) ) ; } for ( Dump dump : dumps ) { dump . terminate ( ) ; } } catch ( Exception e ) { throw new RuntimeException ( ""AggregationCache close failed: "" + e . getMessage ( ) ) ; } } private MeasureAggregator [ ] newAggregators ( ) { return info . codeSystem . newMetricsAggregators ( metrics , metricsAggrFuncs ) ; } public long estimatedMemSize ( ) { if ( aggBufMap . isEmpty ( ) ) return 0 ; byte [ ] sampleKey = aggBufMap . firstKey ( ) ; MeasureAggregator < ? > [ ] sampleValue = aggBufMap . get ( sampleKey ) ; return estimateSizeOfAggrCache ( sampleKey , sampleValue , aggBufMap . size ( ) ) ; } public Iterator < GTRecord > iterator ( ) { Iterator < Entry < byte [ ] , MeasureAggregator [ ] > > it = null ; if ( dumps . isEmpty ( ) ) { it = aggBufMap . entrySet ( ) . iterator ( ) ; } else { if ( ! aggBufMap . isEmpty ( ) ) { spillBuffMap ( getEstimateSizeOfAggrCache ( ) ) ; } DumpMerger merger = new DumpMerger ( dumps ) ; it = merger . iterator ( ) ; } final Iterator < Entry < byte [ ] , MeasureAggregator [ ] > > input = it ; return new Iterator < GTRecord > ( ) { final ReturningRecord returningRecord = new ReturningRecord ( ) ; Entry < byte [ ] , MeasureAggregator [ ] > returningEntry = null ; final HavingFilterChecker havingFilterChecker = ( havingFilter == null ) ? null : new HavingFilterChecker ( ) ; @ Override public boolean hasNext ( ) { while ( returningEntry == null && input . hasNext ( ) ) { returningEntry = input . next ( ) ; if ( havingFilterChecker != null ) returningEntry = havingFilterChecker . check ( returningEntry ) ; } return returningEntry != null ; } @ Override public GTRecord next ( ) { returningRecord . load ( returningEntry . getKey ( ) , returningEntry . getValue ( ) ) ; returningEntry = null ; return returningRecord . record ; } @ Override public void remove ( ) { throw new UnsupportedOperationException ( ) ; } } ; } class HavingFilterChecker { final HavingFilterTuple tuple = new HavingFilterTuple ( ) ; final IFilterCodeSystem cs = new HavingFilterCodeSys ( ) ; HavingFilterChecker ( ) { logger . info ( ""Evaluating 'having' filter -- "" + havingFilter ) ; } public Entry < byte [ ] , MeasureAggregator [ ] > check ( Entry < byte [ ] , MeasureAggregator [ ] > returningEntry ) { tuple . aggrValues = returningEntry . getValue ( ) ; boolean pass = havingFilter . evaluate ( tuple , cs ) ; return pass ? returningEntry : null ; } } private class HavingFilterCodeSys implements IFilterCodeSystem { Object o2Cache ; double n2Cache ; @ Override public int compare ( Object o1 , Object o2 ) { if ( o1 == null && o2 == null ) return 0 ; if ( o1 == null ) return 1 ; if ( o2 == null ) return - 1 ; double n1 ; if ( o1 instanceof Number ) { n1 = ( ( Number ) o1 ) . doubleValue ( ) ; } else if ( o1 instanceof HLLCounter ) { n1 = ( ( HLLCounter ) o1 ) . getCountEstimate ( ) ; } else if ( o1 instanceof BitmapCounter ) { n1 = ( ( BitmapCounter ) o1 ) . getCount ( ) ; } else if ( o1 instanceof PercentileCounter ) { n1 = ( ( PercentileCounter ) o1 ) . getResultEstimate ( ) ; } else { throw new RuntimeException ( ""Unknown datatype: value="" + o1 + "", class="" + o1 . getClass ( ) ) ; } double n2 = ( o2Cache == o2 ) ? n2Cache : Double . parseDouble ( ( String ) o2 ) ; if ( o2Cache == null ) { o2Cache = o2 ; n2Cache = n2 ; } return Double . compare ( n1 , n2 ) ; } @ Override public boolean isNull ( Object code ) { return code == null ; } @ Override public void serialize ( Object code , ByteBuffer buf ) { throw new UnsupportedOperationException ( ) ; } @ Override public Object deserialize ( ByteBuffer buf ) { throw new UnsupportedOperationException ( ) ; } } private class HavingFilterTuple implements ITuple { MeasureAggregator [ ] aggrValues ; @ Override public Object getValue ( TblColRef col ) { return aggrValues [ col . getColumnDesc ( ) . getZeroBasedIndex ( ) ] . getState ( ) ; } @ Override public List < String > getAllFields ( ) { throw new UnsupportedOperationException ( ) ; } @ Override public List < TblColRef > getAllColumns ( ) { throw new UnsupportedOperationException ( ) ; } @ Override public Object [ ] getAllValues ( ) { throw new UnsupportedOperationException ( ) ; } @ Override public ITuple makeCopy ( ) { throw new UnsupportedOperationException ( ) ; } } ; class ReturningRecord { final GTRecord record = new GTRecord ( info ) ; final Object [ ] tmpValues = new Object [ metrics . trueBitCount ( ) ] ; void load ( byte [ ] key , MeasureAggregator [ ] value ) { int offset = 0 ; for ( int i = 0 ; i < dimensions . trueBitCount ( ) ; i ++ ) { int c = dimensions . trueBitAt ( i ) ; final int columnLength = info . codeSystem . maxCodeLength ( c ) ; record . cols [ c ] . reset ( key , offset , columnLength ) ; offset += columnLength ; } for ( int i = 0 ; i < value . length ; i ++ ) { tmpValues [ i ] = value [ i ] . getState ( ) ; } byte [ ] bytes = measureCodec . encode ( tmpValues ) . array ( ) ; int [ ] sizes = measureCodec . getMeasureSizes ( ) ; offset = 0 ; for ( int i = 0 ; i < value . length ; i ++ ) { int col = metrics . trueBitAt ( i ) ; record . cols [ col ] . reset ( bytes , offset , sizes [ i ] ) ; offset += sizes [ i ] ; } } } class Dump implements Iterable < Pair < byte [ ] , byte [ ] > > { final File dumpedFile ; SortedMap < byte [ ] , MeasureAggregator [ ] > buffMap ; final long estMemSize ; byte [ ] spillBuffer ; DataInputStream dis ; public Dump ( SortedMap < byte [ ] , MeasureAggregator [ ] > buffMap , long estMemSize ) throws IOException { this . dumpedFile = File . createTempFile ( ""KYLIN_SPILL_"" , "".tmp"" ) ; this . buffMap = buffMap ; this . estMemSize = estMemSize ; } @ Override public Iterator < Pair < byte [ ] , byte [ ] > > iterator ( ) { try { if ( dumpedFile == null || ! dumpedFile . exists ( ) ) { throw new RuntimeException ( ""Dumped file cannot be found at: "" + ( dumpedFile == null ? ""<null>"" : dumpedFile . getAbsolutePath ( ) ) ) ; } if ( spillBuffer == null ) { dis = new DataInputStream ( new FileInputStream ( dumpedFile ) ) ; } else { dis = new DataInputStream ( new ByteArrayInputStream ( spillBuffer ) ) ; } final int count = dis . readInt ( ) ; return new Iterator < Pair < byte [ ] , byte [ ] > > ( ) { int cursorIdx = 0 ; @ Override public boolean hasNext ( ) { return cursorIdx < count ; } @ Override public Pair < byte [ ] , byte [ ] > next ( ) { try { cursorIdx ++ ; int keyLen = dis . readInt ( ) ; byte [ ] key = new byte [ keyLen ] ; dis . read ( key ) ; int valueLen = dis . readInt ( ) ; byte [ ] value = new byte [ valueLen ] ; dis . read ( value ) ; return new Pair < > ( key , value ) ; } catch ( Exception e ) { throw new RuntimeException ( ""Cannot read AggregationCache from dumped file: "" + e . getMessage ( ) ) ; } } @ Override public void remove ( ) { throw new UnsupportedOperationException ( ) ; } } ; } catch ( Exception e ) { throw new RuntimeException ( ""Failed to read dumped file: "" + e . getMessage ( ) ) ; } } public void spill ( ) throws IOException { if ( spillBuffer == null ) return ; OutputStream ops = new FileOutputStream ( dumpedFile ) ; InputStream ips = new ByteArrayInputStream ( spillBuffer ) ; IOUtils . copy ( ips , ops ) ; spillBuffer = null ; IOUtils . closeQuietly ( ips ) ; IOUtils . closeQuietly ( ops ) ; logger . info ( ""Spill buffer to disk, location: {}, size = {}."" , dumpedFile . getAbsolutePath ( ) , dumpedFile . length ( ) ) ; } public int size ( ) { return spillBuffer == null ? 0 : spillBuffer . length ; } public void flush ( ) throws IOException { logger . info ( ""AggregationCache(size={} est_mem_size={} threshold={}) will spill to {}"" , buffMap . size ( ) , estMemSize , spillThreshold , dumpedFile . getAbsolutePath ( ) ) ; ByteArrayOutputStream baos = new ByteArrayOutputStream ( MAX_BUFFER_SIZE ) ; if ( buffMap != null ) { DataOutputStream bos = new DataOutputStream ( baos ) ; Object [ ] aggrResult = null ; try { bos . writeInt ( buffMap . size ( ) ) ; for ( Entry < byte [ ] , MeasureAggregator [ ] > entry : buffMap . entrySet ( ) ) { MeasureAggregators aggs = new MeasureAggregators ( entry . getValue ( ) ) ; aggrResult = new Object [ metrics . trueBitCount ( ) ] ; aggs . collectStates ( aggrResult ) ; ByteBuffer metricsBuf = measureCodec . encode ( aggrResult ) ; bos . writeInt ( entry . getKey ( ) . length ) ; bos . write ( entry . getKey ( ) ) ; bos . writeInt ( metricsBuf . position ( ) ) ; bos . write ( metricsBuf . array ( ) , 0 , metricsBuf . position ( ) ) ; } } finally { buffMap = null ; IOUtils . closeQuietly ( bos ) ; } } spillBuffer = baos . toByteArray ( ) ; IOUtils . closeQuietly ( baos ) ; logger . info ( ""Accurately spill data size = {}"" , spillBuffer . length ) ; } public void terminate ( ) throws IOException { buffMap = null ; if ( dis != null ) IOUtils . closeQuietly ( dis ) ; if ( dumpedFile != null && dumpedFile . exists ( ) ) dumpedFile . delete ( ) ; spillBuffer = null ; } } class DumpMerger implements Iterable < Entry < byte [ ] , MeasureAggregator [ ] > > { final PriorityQueue < Entry < byte [ ] , Integer > > minHeap ; final List < Iterator < Pair < byte [ ] , byte [ ] > > > dumpIterators ; final List < Object [ ] > dumpCurrentValues ; final MeasureAggregator [ ] resultMeasureAggregators = newAggregators ( ) ; final MeasureAggregators resultAggrs = new MeasureAggregators ( resultMeasureAggregators ) ; public DumpMerger ( List < Dump > dumps ) { minHeap = new PriorityQueue < > ( dumps . size ( ) , new Comparator < Entry < byte [ ] , Integer > > ( ) { @ Override public int compare ( Entry < byte [ ] , Integer > o1 , Entry < byte [ ] , Integer > o2 ) { return bytesComparator . compare ( o1 . getKey ( ) , o2 . getKey ( ) ) ; } } ) ; dumpIterators = Lists . newArrayListWithCapacity ( dumps . size ( ) ) ; dumpCurrentValues = Lists . newArrayListWithCapacity ( dumps . size ( ) ) ; Iterator < Pair < byte [ ] , byte [ ] > > it ; for ( int i = 0 ; i < dumps . size ( ) ; i ++ ) { it = dumps . get ( i ) . iterator ( ) ; dumpCurrentValues . add ( i , null ) ; if ( it . hasNext ( ) ) { dumpIterators . add ( i , it ) ; enqueueFromDump ( i ) ; } else { dumpIterators . add ( i , null ) ; } } } private void enqueueFromDump ( int index ) { if ( dumpIterators . get ( index ) != null && dumpIterators . get ( index ) . hasNext ( ) ) { Pair < byte [ ] , byte [ ] > pair = dumpIterators . get ( index ) . next ( ) ; minHeap . offer ( new SimpleEntry ( pair . getFirst ( ) , index ) ) ; Object [ ] metricValues = new Object [ metrics . trueBitCount ( ) ] ; measureCodec . decode ( ByteBuffer . wrap ( pair . getSecond ( ) ) , metricValues ) ; dumpCurrentValues . set ( index , metricValues ) ; } } @ Override public Iterator < Entry < byte [ ] , MeasureAggregator [ ] > > iterator ( ) { return new Iterator < Entry < byte [ ] , MeasureAggregator [ ] > > ( ) { @ Override public boolean hasNext ( ) { return ! minHeap . isEmpty ( ) ; } private void internalAggregate ( ) { Entry < byte [ ] , Integer > peekEntry = minHeap . poll ( ) ; resultAggrs . aggregate ( dumpCurrentValues . get ( peekEntry . getValue ( ) ) ) ; enqueueFromDump ( peekEntry . getValue ( ) ) ; } @ Override public Entry < byte [ ] , MeasureAggregator [ ] > next ( ) { resultAggrs . reset ( ) ; byte [ ] peekKey = minHeap . peek ( ) . getKey ( ) ; internalAggregate ( ) ; while ( ! minHeap . isEmpty ( ) && bytesComparator . compare ( peekKey , minHeap . peek ( ) . getKey ( ) ) == 0 ) { internalAggregate ( ) ; } return new SimpleEntry ( peekKey , resultMeasureAggregators ) ; } @ Override public void remove ( ) { throw new UnsupportedOperationException ( ) ; } } ; } } } private static class SimpleEntry < K , V > implements Entry < K , V > { K k ; V v ; SimpleEntry ( K k , V v ) { this . k = k ; this . v = v ; } @ Override public K getKey ( ) { return k ; } @ Override public V getValue ( ) { return v ; } @ Override public V setValue ( V value ) { V oldV = v ; this . v = value ; return oldV ; } } ",Smelly
"public class AlignmentContext implements Constants { private int areaHeight ; private int lineHeight ; private int alignmentPoint ; private int baselineShiftValue ; private int alignmentBaselineIdentifier ; private int xHeight ; private ScaledBaselineTable scaledBaselineTable ; private ScaledBaselineTable actualBaselineTable ; private AlignmentContext parentAlignmentContext ; AlignmentContext ( int height , Length alignmentAdjust , int alignmentBaseline , Length baselineShift , int dominantBaseline , AlignmentContext parentAlignmentContext ) { this ( height , 0 , height , height , alignmentAdjust , alignmentBaseline , baselineShift , dominantBaseline , parentAlignmentContext ) ; } AlignmentContext ( Font font , int lineHeight , Length alignmentAdjust , int alignmentBaseline , Length baselineShift , int dominantBaseline , AlignmentContext parentAlignmentContext ) { this ( font . getAscender ( ) , font . getDescender ( ) , lineHeight , font . getXHeight ( ) , alignmentAdjust , alignmentBaseline , baselineShift , dominantBaseline , parentAlignmentContext ) ; } private AlignmentContext ( int altitude , int depth , int lineHeight , int xHeight , Length alignmentAdjust , int alignmentBaseline , Length baselineShift , int dominantBaseline , AlignmentContext parentAlignmentContext ) { this . areaHeight = altitude - depth ; this . lineHeight = lineHeight ; this . xHeight = xHeight ; this . parentAlignmentContext = parentAlignmentContext ; this . scaledBaselineTable = parentAlignmentContext . getScaledBaselineTable ( ) ; setAlignmentBaselineIdentifier ( alignmentBaseline , parentAlignmentContext . getDominantBaselineIdentifier ( ) ) ; setBaselineShift ( baselineShift ) ; int dominantBaselineIdentifier = parentAlignmentContext . getDominantBaselineIdentifier ( ) ; boolean newScaledBaselineTableRequired = false ; if ( baselineShiftValue != 0 ) { newScaledBaselineTableRequired = true ; } switch ( dominantBaseline ) { case EN_AUTO : newScaledBaselineTableRequired = baselineShiftValue != 0 ; break ; case EN_USE_SCRIPT : break ; case EN_NO_CHANGE : break ; case EN_RESET_SIZE : newScaledBaselineTableRequired = true ; break ; default : newScaledBaselineTableRequired = true ; dominantBaselineIdentifier = dominantBaseline ; break ; } actualBaselineTable = new ScaledBaselineTable ( altitude , depth , xHeight , dominantBaselineIdentifier , scaledBaselineTable . getWritingMode ( ) ) ; if ( newScaledBaselineTableRequired ) { scaledBaselineTable = new ScaledBaselineTable ( altitude , depth , xHeight , dominantBaselineIdentifier , scaledBaselineTable . getWritingMode ( ) ) ; } setAlignmentAdjust ( alignmentAdjust ) ; } AlignmentContext ( Font font , int lineHeight , WritingMode writingMode ) { this . areaHeight = font . getAscender ( ) - font . getDescender ( ) ; this . lineHeight = lineHeight ; this . xHeight = font . getXHeight ( ) ; this . scaledBaselineTable = new ScaledBaselineTable ( font . getAscender ( ) , font . getDescender ( ) , font . getXHeight ( ) , Constants . EN_ALPHABETIC , writingMode ) ; this . actualBaselineTable = scaledBaselineTable ; this . alignmentBaselineIdentifier = getDominantBaselineIdentifier ( ) ; this . alignmentPoint = font . getAscender ( ) ; this . baselineShiftValue = 0 ; } public int getAlignmentPoint ( ) { return alignmentPoint ; } public int getBaselineShiftValue ( ) { return baselineShiftValue ; } public int getAlignmentBaselineIdentifier ( ) { return alignmentBaselineIdentifier ; } private void setAlignmentBaselineIdentifier ( int alignmentBaseline , int parentDominantBaselineIdentifier ) { switch ( alignmentBaseline ) { case EN_AUTO : case EN_BASELINE : this . alignmentBaselineIdentifier = parentDominantBaselineIdentifier ; break ; case EN_BEFORE_EDGE : case EN_TEXT_BEFORE_EDGE : case EN_CENTRAL : case EN_MIDDLE : case EN_AFTER_EDGE : case EN_TEXT_AFTER_EDGE : case EN_IDEOGRAPHIC : case EN_ALPHABETIC : case EN_HANGING : case EN_MATHEMATICAL : this . alignmentBaselineIdentifier = alignmentBaseline ; break ; default : throw new IllegalArgumentException ( String . valueOf ( alignmentBaseline ) ) ; } } private void setAlignmentAdjust ( Length alignmentAdjust ) { int beforeEdge = actualBaselineTable . getBaseline ( EN_BEFORE_EDGE ) ; switch ( alignmentAdjust . getEnum ( ) ) { case EN_AUTO : alignmentPoint = beforeEdge - actualBaselineTable . getBaseline ( alignmentBaselineIdentifier ) ; break ; case EN_BASELINE : alignmentPoint = beforeEdge ; break ; case EN_BEFORE_EDGE : case EN_TEXT_BEFORE_EDGE : case EN_CENTRAL : case EN_MIDDLE : case EN_AFTER_EDGE : case EN_TEXT_AFTER_EDGE : case EN_IDEOGRAPHIC : case EN_ALPHABETIC : case EN_HANGING : case EN_MATHEMATICAL : alignmentPoint = beforeEdge - actualBaselineTable . getBaseline ( alignmentAdjust . getEnum ( ) ) ; break ; default : alignmentPoint = beforeEdge + alignmentAdjust . getValue ( new SimplePercentBaseContext ( null , LengthBase . ALIGNMENT_ADJUST , lineHeight ) ) ; break ; } } private ScaledBaselineTable getScaledBaselineTable ( ) { return this . scaledBaselineTable ; } public int getDominantBaselineIdentifier ( ) { return actualBaselineTable . getDominantBaselineIdentifier ( ) ; } private void setBaselineShift ( Length baselineShift ) { baselineShiftValue = 0 ; switch ( baselineShift . getEnum ( ) ) { case EN_BASELINE : break ; case EN_SUB : baselineShiftValue = Math . round ( - ( ( float ) xHeight / 2 ) + ( float ) parentAlignmentContext . getActualBaselineOffset ( EN_ALPHABETIC ) ) ; break ; case EN_SUPER : baselineShiftValue = Math . round ( ( float ) parentAlignmentContext . getXHeight ( ) + ( float ) parentAlignmentContext . getActualBaselineOffset ( EN_ALPHABETIC ) ) ; break ; case 0 : baselineShiftValue = baselineShift . getValue ( new SimplePercentBaseContext ( null , LengthBase . CUSTOM_BASE , parentAlignmentContext . getLineHeight ( ) ) ) ; break ; default : throw new IllegalArgumentException ( String . valueOf ( baselineShift . getEnum ( ) ) ) ; } } public AlignmentContext getParentAlignmentContext ( ) { return parentAlignmentContext ; } private int getBaselineOffset ( ) { if ( parentAlignmentContext == null ) { return 0 ; } return parentAlignmentContext . getScaledBaselineTable ( ) . getBaseline ( alignmentBaselineIdentifier ) - scaledBaselineTable . deriveScaledBaselineTable ( parentAlignmentContext . getDominantBaselineIdentifier ( ) ) . getBaseline ( alignmentBaselineIdentifier ) - scaledBaselineTable . getBaseline ( parentAlignmentContext . getDominantBaselineIdentifier ( ) ) + baselineShiftValue ; } private int getTotalBaselineOffset ( ) { int offset = 0 ; if ( parentAlignmentContext != null ) { offset = getBaselineOffset ( ) + parentAlignmentContext . getTotalBaselineOffset ( ) ; } return offset ; } public int getTotalAlignmentBaselineOffset ( ) { return getTotalAlignmentBaselineOffset ( alignmentBaselineIdentifier ) ; } private int getTotalAlignmentBaselineOffset ( int alignmentBaselineId ) { int offset = baselineShiftValue ; if ( parentAlignmentContext != null ) { offset = parentAlignmentContext . getTotalBaselineOffset ( ) + parentAlignmentContext . getScaledBaselineTable ( ) . getBaseline ( alignmentBaselineId ) + baselineShiftValue ; } return offset ; } private int getActualBaselineOffset ( int baselineIdentifier ) { int offset = getTotalAlignmentBaselineOffset ( ) - getTotalBaselineOffset ( ) ; offset += actualBaselineTable . deriveScaledBaselineTable ( alignmentBaselineIdentifier ) . getBaseline ( baselineIdentifier ) ; return offset ; } private int getTotalTopOffset ( ) { int offset = getTotalAlignmentBaselineOffset ( ) + getAltitude ( ) ; return offset ; } public int getHeight ( ) { return areaHeight ; } private int getLineHeight ( ) { return lineHeight ; } public int getAltitude ( ) { return alignmentPoint ; } public int getDepth ( ) { return getHeight ( ) - alignmentPoint ; } private int getXHeight ( ) { return this . xHeight ; } public void resizeLine ( int newLineHeight , int newAlignmentPoint ) { areaHeight = newLineHeight ; alignmentPoint = newAlignmentPoint ; scaledBaselineTable . setBeforeAndAfterBaselines ( alignmentPoint , alignmentPoint - areaHeight ) ; } public int getOffset ( ) { int offset = 0 ; if ( parentAlignmentContext != null ) { offset = parentAlignmentContext . getTotalTopOffset ( ) - getTotalTopOffset ( ) ; } else { offset = getAltitude ( ) - scaledBaselineTable . getBaseline ( EN_TEXT_BEFORE_EDGE ) ; } return offset ; } public boolean usesInitialBaselineTable ( ) { return parentAlignmentContext == null || ( scaledBaselineTable == parentAlignmentContext . getScaledBaselineTable ( ) && parentAlignmentContext . usesInitialBaselineTable ( ) ) ; } public String toString ( ) { StringBuffer sb = new StringBuffer ( 64 ) ; sb . append ( ""areaHeight="" ) . append ( areaHeight ) ; sb . append ( "" lineHeight="" ) . append ( lineHeight ) ; sb . append ( "" alignmentPoint="" ) . append ( alignmentPoint ) ; sb . append ( "" alignmentBaselineID="" ) . append ( alignmentBaselineIdentifier ) ; sb . append ( "" baselineShift="" ) . append ( baselineShiftValue ) ; return sb . toString ( ) ; } }",No
"class URIBitSets { protected static final BitSet percent = new BitSet ( 256 ) ; static { percent . set ( '%' ) ; } protected static final BitSet digit = new BitSet ( 256 ) ; static { for ( int i = '0' ; i <= '9' ; i ++ ) { digit . set ( i ) ; } } protected static final BitSet alpha = new BitSet ( 256 ) ; static { for ( int i = 'a' ; i <= 'z' ; i ++ ) { alpha . set ( i ) ; } for ( int i = 'A' ; i <= 'Z' ; i ++ ) { alpha . set ( i ) ; } } protected static final BitSet alphanum = new BitSet ( 256 ) ; static { alphanum . or ( alpha ) ; alphanum . or ( digit ) ; } protected static final BitSet hex = new BitSet ( 256 ) ; static { hex . or ( digit ) ; for ( int i = 'a' ; i <= 'f' ; i ++ ) { hex . set ( i ) ; } for ( int i = 'A' ; i <= 'F' ; i ++ ) { hex . set ( i ) ; } } protected static final BitSet escaped = new BitSet ( 256 ) ; static { escaped . or ( percent ) ; escaped . or ( hex ) ; } protected static final BitSet mark = new BitSet ( 256 ) ; static { mark . set ( '-' ) ; mark . set ( '_' ) ; mark . set ( '.' ) ; mark . set ( '!' ) ; mark . set ( '~' ) ; mark . set ( '*' ) ; mark . set ( '\'' ) ; mark . set ( '(' ) ; mark . set ( ')' ) ; } protected static final BitSet unreserved = new BitSet ( 256 ) ; static { unreserved . or ( alphanum ) ; unreserved . or ( mark ) ; } protected static final BitSet reserved = new BitSet ( 256 ) ; static { reserved . set ( ';' ) ; reserved . set ( '/' ) ; reserved . set ( '?' ) ; reserved . set ( ':' ) ; reserved . set ( '@' ) ; reserved . set ( '&' ) ; reserved . set ( '=' ) ; reserved . set ( '+' ) ; reserved . set ( '$' ) ; reserved . set ( ',' ) ; } protected static final BitSet uric = new BitSet ( 256 ) ; static { uric . or ( reserved ) ; uric . or ( unreserved ) ; uric . or ( escaped ) ; } protected static final BitSet fragment = uric ; protected static final BitSet query = uric ; protected static final BitSet pchar = new BitSet ( 256 ) ; static { pchar . or ( unreserved ) ; pchar . or ( escaped ) ; pchar . set ( ':' ) ; pchar . set ( '@' ) ; pchar . set ( '&' ) ; pchar . set ( '=' ) ; pchar . set ( '+' ) ; pchar . set ( '$' ) ; pchar . set ( ',' ) ; } protected static final BitSet param = pchar ; protected static final BitSet segment = new BitSet ( 256 ) ; static { segment . or ( pchar ) ; segment . set ( ';' ) ; segment . or ( param ) ; } protected static final BitSet path_segments = new BitSet ( 256 ) ; static { path_segments . set ( '/' ) ; path_segments . or ( segment ) ; } protected static final BitSet abs_path = new BitSet ( 256 ) ; static { abs_path . set ( '/' ) ; abs_path . or ( path_segments ) ; } protected static final BitSet uric_no_slash = new BitSet ( 256 ) ; static { uric_no_slash . or ( unreserved ) ; uric_no_slash . or ( escaped ) ; uric_no_slash . set ( ';' ) ; uric_no_slash . set ( '?' ) ; uric_no_slash . set ( ';' ) ; uric_no_slash . set ( '@' ) ; uric_no_slash . set ( '&' ) ; uric_no_slash . set ( '=' ) ; uric_no_slash . set ( '+' ) ; uric_no_slash . set ( '$' ) ; uric_no_slash . set ( ',' ) ; } protected static final BitSet opaque_part = new BitSet ( 256 ) ; static { opaque_part . or ( uric_no_slash ) ; opaque_part . or ( uric ) ; } protected static final BitSet path = new BitSet ( 256 ) ; static { path . or ( abs_path ) ; path . or ( opaque_part ) ; } protected static final BitSet port = digit ; protected static final BitSet IPv4address = new BitSet ( 256 ) ; static { IPv4address . or ( digit ) ; IPv4address . set ( '.' ) ; } protected static final BitSet IPv6address = new BitSet ( 256 ) ; static { IPv6address . or ( hex ) ; IPv6address . set ( ':' ) ; IPv6address . or ( IPv4address ) ; } protected static final BitSet IPv6reference = new BitSet ( 256 ) ; static { IPv6reference . set ( '[' ) ; IPv6reference . or ( IPv6address ) ; IPv6reference . set ( ']' ) ; } protected static final BitSet toplabel = new BitSet ( 256 ) ; static { toplabel . or ( alphanum ) ; toplabel . set ( '-' ) ; } protected static final BitSet domainlabel = toplabel ; protected static final BitSet hostname = new BitSet ( 256 ) ; static { hostname . or ( toplabel ) ; hostname . set ( '.' ) ; } protected static final BitSet host = new BitSet ( 256 ) ; static { host . or ( hostname ) ; host . or ( IPv6reference ) ; } protected static final BitSet hostport = new BitSet ( 256 ) ; static { hostport . or ( host ) ; hostport . set ( ':' ) ; hostport . or ( port ) ; } protected static final BitSet userinfo = new BitSet ( 256 ) ; static { userinfo . or ( unreserved ) ; userinfo . or ( escaped ) ; userinfo . set ( ';' ) ; userinfo . set ( ':' ) ; userinfo . set ( '&' ) ; userinfo . set ( '=' ) ; userinfo . set ( '+' ) ; userinfo . set ( '$' ) ; userinfo . set ( ',' ) ; } public static final BitSet within_userinfo = new BitSet ( 256 ) ; static { within_userinfo . or ( userinfo ) ; within_userinfo . clear ( ';' ) ; within_userinfo . clear ( ':' ) ; within_userinfo . clear ( '@' ) ; within_userinfo . clear ( '?' ) ; within_userinfo . clear ( '/' ) ; } protected static final BitSet server = new BitSet ( 256 ) ; static { server . or ( userinfo ) ; server . set ( '@' ) ; server . or ( hostport ) ; } protected static final BitSet reg_name = new BitSet ( 256 ) ; static { reg_name . or ( unreserved ) ; reg_name . or ( escaped ) ; reg_name . set ( '$' ) ; reg_name . set ( ',' ) ; reg_name . set ( ';' ) ; reg_name . set ( ':' ) ; reg_name . set ( '@' ) ; reg_name . set ( '&' ) ; reg_name . set ( '=' ) ; reg_name . set ( '+' ) ; } protected static final BitSet authority = new BitSet ( 256 ) ; static { authority . or ( server ) ; authority . or ( reg_name ) ; } protected static final BitSet scheme = new BitSet ( 256 ) ; static { scheme . or ( alpha ) ; scheme . or ( digit ) ; scheme . set ( '+' ) ; scheme . set ( '-' ) ; scheme . set ( '.' ) ; } protected static final BitSet rel_segment = new BitSet ( 256 ) ; static { rel_segment . or ( unreserved ) ; rel_segment . or ( escaped ) ; rel_segment . set ( ';' ) ; rel_segment . set ( '@' ) ; rel_segment . set ( '&' ) ; rel_segment . set ( '=' ) ; rel_segment . set ( '+' ) ; rel_segment . set ( '$' ) ; rel_segment . set ( ',' ) ; } protected static final BitSet rel_path = new BitSet ( 256 ) ; static { rel_path . or ( rel_segment ) ; rel_path . or ( abs_path ) ; } protected static final BitSet net_path = new BitSet ( 256 ) ; static { net_path . set ( '/' ) ; net_path . or ( authority ) ; net_path . or ( abs_path ) ; } protected static final BitSet hier_part = new BitSet ( 256 ) ; static { hier_part . or ( net_path ) ; hier_part . or ( abs_path ) ; hier_part . or ( query ) ; } protected static final BitSet relativeURI = new BitSet ( 256 ) ; static { relativeURI . or ( net_path ) ; relativeURI . or ( abs_path ) ; relativeURI . or ( rel_path ) ; relativeURI . or ( query ) ; } protected static final BitSet absoluteURI = new BitSet ( 256 ) ; static { absoluteURI . or ( scheme ) ; absoluteURI . set ( ':' ) ; absoluteURI . or ( hier_part ) ; absoluteURI . or ( opaque_part ) ; } protected static final BitSet URI_reference = new BitSet ( 256 ) ; static { URI_reference . or ( absoluteURI ) ; URI_reference . or ( relativeURI ) ; URI_reference . set ( '#' ) ; URI_reference . or ( fragment ) ; } public static final BitSet control = new BitSet ( 256 ) ; static { for ( int i = 0 ; i <= 0x1F ; i ++ ) { control . set ( i ) ; } control . set ( 0x7F ) ; } public static final BitSet space = new BitSet ( 256 ) ; static { space . set ( 0x20 ) ; } public static final BitSet delims = new BitSet ( 256 ) ; static { delims . set ( '<' ) ; delims . set ( '>' ) ; delims . set ( '#' ) ; delims . set ( '%' ) ; delims . set ( '""' ) ; } public static final BitSet unwise = new BitSet ( 256 ) ; static { unwise . set ( '{' ) ; unwise . set ( '}' ) ; unwise . set ( '|' ) ; unwise . set ( '\\' ) ; unwise . set ( '^' ) ; unwise . set ( '[' ) ; unwise . set ( ']' ) ; unwise . set ( '`' ) ; } public static final BitSet disallowed_rel_path = new BitSet ( 256 ) ; static { disallowed_rel_path . or ( uric ) ; disallowed_rel_path . andNot ( rel_path ) ; } public static final BitSet disallowed_opaque_part = new BitSet ( 256 ) ; static { disallowed_opaque_part . or ( uric ) ; disallowed_opaque_part . andNot ( opaque_part ) ; } public static final BitSet allowed_authority = new BitSet ( 256 ) ; static { allowed_authority . or ( authority ) ; allowed_authority . clear ( '%' ) ; } public static final BitSet allowed_opaque_part = new BitSet ( 256 ) ; static { allowed_opaque_part . or ( opaque_part ) ; allowed_opaque_part . clear ( '%' ) ; } public static final BitSet allowed_reg_name = new BitSet ( 256 ) ; static { allowed_reg_name . or ( reg_name ) ; allowed_reg_name . clear ( '%' ) ; } public static final BitSet allowed_userinfo = new BitSet ( 256 ) ; static { allowed_userinfo . or ( userinfo ) ; allowed_userinfo . clear ( '%' ) ; } public static final BitSet allowed_within_userinfo = new BitSet ( 256 ) ; static { allowed_within_userinfo . or ( within_userinfo ) ; allowed_within_userinfo . clear ( '%' ) ; } public static final BitSet allowed_IPv6reference = new BitSet ( 256 ) ; static { allowed_IPv6reference . or ( IPv6reference ) ; allowed_IPv6reference . clear ( '[' ) ; allowed_IPv6reference . clear ( ']' ) ; } public static final BitSet allowed_host = new BitSet ( 256 ) ; static { allowed_host . or ( hostname ) ; allowed_host . or ( allowed_IPv6reference ) ; } public static final BitSet allowed_within_authority = new BitSet ( 256 ) ; static { allowed_within_authority . or ( server ) ; allowed_within_authority . or ( reg_name ) ; allowed_within_authority . clear ( ';' ) ; allowed_within_authority . clear ( ':' ) ; allowed_within_authority . clear ( '@' ) ; allowed_within_authority . clear ( '?' ) ; allowed_within_authority . clear ( '/' ) ; } public static final BitSet allowed_abs_path = new BitSet ( 256 ) ; static { allowed_abs_path . or ( abs_path ) ; allowed_abs_path . andNot ( percent ) ; allowed_abs_path . clear ( '+' ) ; } public static final BitSet allowed_rel_path = new BitSet ( 256 ) ; static { allowed_rel_path . or ( rel_path ) ; allowed_rel_path . clear ( '%' ) ; allowed_rel_path . clear ( '+' ) ; } public static final BitSet allowed_within_path = new BitSet ( 256 ) ; static { allowed_within_path . or ( abs_path ) ; allowed_within_path . clear ( '/' ) ; allowed_within_path . clear ( ';' ) ; allowed_within_path . clear ( '=' ) ; allowed_within_path . clear ( '?' ) ; } public static final BitSet allowed_query = new BitSet ( 256 ) ; static { allowed_query . or ( uric ) ; allowed_query . clear ( '%' ) ; } public static final BitSet allowed_within_query = new BitSet ( 256 ) ; static { allowed_within_query . or ( allowed_query ) ; allowed_within_query . andNot ( reserved ) ; } public static final BitSet allowed_fragment = new BitSet ( 256 ) ; static { allowed_fragment . or ( uric ) ; allowed_fragment . clear ( '%' ) ; } private URIBitSets ( ) { } }",Smelly
"public class ServletContextResourceResolver implements ResourceResolver { ServletContext servletContext ; Map < String , URL > urlMap = new ConcurrentHashMap < String , URL > ( ) ; public ServletContextResourceResolver ( ServletContext sc ) { servletContext = sc ; } public final InputStream getAsStream ( final String string ) { if ( urlMap . containsKey ( string ) ) { try { return urlMap . get ( string ) . openStream ( ) ; } catch ( IOException e ) { } } return servletContext . getResourceAsStream ( string ) ; } public final < T > T resolve ( final String entryName , final Class < T > clz ) { Object obj = null ; try { if ( entryName != null ) { InitialContext ic = new InitialContext ( ) ; try { obj = ic . lookup ( entryName ) ; } finally { ic . close ( ) ; } } } catch ( Throwable e ) { } if ( obj != null && clz . isInstance ( obj ) ) { return clz . cast ( obj ) ; } if ( clz . isAssignableFrom ( URL . class ) ) { if ( urlMap . containsKey ( entryName ) ) { return clz . cast ( urlMap . get ( entryName ) ) ; } try { URL url = servletContext . getResource ( entryName ) ; if ( url != null && ""file"" . equals ( url . getProtocol ( ) ) && ! ( new File ( url . toURI ( ) ) . exists ( ) ) ) { url = null ; } if ( url != null ) { urlMap . put ( url . toString ( ) , url ) ; return clz . cast ( url ) ; } } catch ( MalformedURLException e ) { } catch ( URISyntaxException e ) { } try { URL url = servletContext . getResource ( ""/"" + entryName ) ; if ( url != null && ""file"" . equals ( url . getProtocol ( ) ) && ! ( new File ( url . toURI ( ) ) . exists ( ) ) ) { url = null ; } if ( url != null ) { urlMap . put ( url . toString ( ) , url ) ; return clz . cast ( url ) ; } } catch ( MalformedURLException e1 ) { } catch ( URISyntaxException e ) { } } else if ( clz . isAssignableFrom ( InputStream . class ) ) { return clz . cast ( getAsStream ( entryName ) ) ; } return null ; } }",No
"class JavaGenerator extends CodeGenerator { JavaGenerator ( ) { } @ Override void genCode ( String name , ArrayList < JFile > ilist , ArrayList < JRecord > rlist , String destDir , ArrayList < String > options ) throws IOException { for ( Iterator < JRecord > iter = rlist . iterator ( ) ; iter . hasNext ( ) ; ) { JRecord rec = iter . next ( ) ; rec . genJavaCode ( destDir , options ) ; } } }",No
"public class Pings extends UIAction { private static Log log = LogFactory . getLog ( Pings . class ) ; private String pingTargetId = null ; private PingTarget pingTarget = null ; private List < PingTarget > commonPingTargets = Collections . emptyList ( ) ; private Map pingStatus = Collections . EMPTY_MAP ; public Pings ( ) { this . actionName = ""pings"" ; this . desiredMenu = ""editor"" ; this . pageTitle = ""pings.title"" ; } public String requireWeblogPermissions ( ) { return WeblogPermission . ADMIN ; } public void myPrepare ( ) { PingTargetManager pingTargetMgr = WebloggerFactory . getWeblogger ( ) . getPingTargetManager ( ) ; if ( getPingTargetId ( ) != null ) { try { setPingTarget ( pingTargetMgr . getPingTarget ( getPingTargetId ( ) ) ) ; } catch ( WebloggerException ex ) { log . error ( ""Error looking up ping target - "" + getPingTargetId ( ) , ex ) ; } } try { setCommonPingTargets ( pingTargetMgr . getCommonPingTargets ( ) ) ; } catch ( WebloggerException ex ) { log . error ( ""Error loading ping target lists for weblog - "" + getActionWeblog ( ) . getHandle ( ) , ex ) ; addError ( ""Error loading ping targets"" ) ; } } public String execute ( ) { buildIsEnabledMap ( ) ; return LIST ; } public String enable ( ) { if ( getPingTarget ( ) != null ) { try { AutoPingManager autoPingMgr = WebloggerFactory . getWeblogger ( ) . getAutopingManager ( ) ; AutoPing autoPing = new AutoPing ( null , getPingTarget ( ) , getActionWeblog ( ) ) ; autoPingMgr . saveAutoPing ( autoPing ) ; WebloggerFactory . getWeblogger ( ) . flush ( ) ; } catch ( Exception ex ) { log . error ( ""Error saving auto ping for target - "" + getPingTargetId ( ) , ex ) ; addError ( ""Error enabling auto ping"" ) ; } } return execute ( ) ; } public String disable ( ) { if ( getPingTarget ( ) != null ) { try { AutoPingManager autoPingMgr = WebloggerFactory . getWeblogger ( ) . getAutopingManager ( ) ; autoPingMgr . removeAutoPing ( getPingTarget ( ) , getActionWeblog ( ) ) ; WebloggerFactory . getWeblogger ( ) . flush ( ) ; } catch ( Exception ex ) { log . error ( ""Error removing auto ping for target - "" + getPingTargetId ( ) , ex ) ; addError ( ""Error disabling auto ping"" ) ; } } return execute ( ) ; } public String pingNow ( ) { if ( getPingTarget ( ) != null ) { try { if ( PingConfig . getSuspendPingProcessing ( ) ) { log . debug ( ""Ping processing is disabled."" ) ; addError ( ""ping.pingProcessingIsSuspended"" ) ; } else { WeblogUpdatePinger . PingResult pingResult = WeblogUpdatePinger . sendPing ( getPingTarget ( ) , getActionWeblog ( ) ) ; if ( pingResult . isError ( ) ) { log . debug ( ""Ping Result: "" + pingResult ) ; if ( pingResult . getMessage ( ) != null && pingResult . getMessage ( ) . trim ( ) . length ( ) > 0 ) { addError ( ""ping.transmittedButError"" ) ; addError ( pingResult . getMessage ( ) ) ; } else { addError ( ""ping.transmissionFailed"" ) ; } } else { addMessage ( ""ping.successful"" ) ; } } } catch ( IOException ex ) { log . debug ( ex ) ; addError ( ""ping.transmissionFailed"" ) ; addSpecificMessages ( ex ) ; } catch ( XmlRpcException ex ) { log . debug ( ex ) ; addError ( ""ping.transmissionFailed"" ) ; addSpecificMessages ( ex ) ; } } return execute ( ) ; } private void addSpecificMessages ( Exception ex ) { if ( ex instanceof UnknownHostException ) { addError ( ""ping.unknownHost"" ) ; } else if ( ex instanceof SocketException ) { addError ( ""ping.networkConnectionFailed"" ) ; } } private void buildIsEnabledMap ( ) { AutoPingManager autoPingMgr = WebloggerFactory . getWeblogger ( ) . getAutopingManager ( ) ; Map < String , Boolean > isEnabled = new HashMap < String , Boolean > ( ) ; List < AutoPing > autoPings = Collections . emptyList ( ) ; try { autoPings = autoPingMgr . getAutoPingsByWebsite ( getActionWeblog ( ) ) ; } catch ( WebloggerException ex ) { log . error ( ""Error looking up auto pings for weblog - "" + getActionWeblog ( ) . getHandle ( ) , ex ) ; } for ( AutoPing autoPing : autoPings ) { isEnabled . put ( autoPing . getPingTarget ( ) . getId ( ) , Boolean . TRUE ) ; } for ( PingTarget inPingTarget : getCommonPingTargets ( ) ) { if ( isEnabled . get ( inPingTarget . getId ( ) ) == null ) { isEnabled . put ( inPingTarget . getId ( ) , Boolean . FALSE ) ; } } if ( isEnabled . size ( ) > 0 ) { setPingStatus ( isEnabled ) ; } } public String getPingTargetId ( ) { return pingTargetId ; } public void setPingTargetId ( String pingTargetId ) { this . pingTargetId = pingTargetId ; } public PingTarget getPingTarget ( ) { return pingTarget ; } public void setPingTarget ( PingTarget pingTarget ) { this . pingTarget = pingTarget ; } public List < PingTarget > getCommonPingTargets ( ) { return commonPingTargets ; } public void setCommonPingTargets ( List < PingTarget > commonPingTargets ) { this . commonPingTargets = commonPingTargets ; } public Map getPingStatus ( ) { return pingStatus ; } public void setPingStatus ( Map pingStatus ) { this . pingStatus = pingStatus ; } }",No
"public final class DtoFactory { @ SuppressWarnings ( ""rawtypes"" ) private final static Comparator < Class > CLASS_NAME_COMPARATOR = new Comparator < Class > ( ) { @ Override public int compare ( final Class class1 , final Class class2 ) { return Collator . getInstance ( Locale . US ) . compare ( class1 . getSimpleName ( ) , class2 . getSimpleName ( ) ) ; } } ; public static final String SENSITIVE_VALUE_MASK = ""********"" ; private BulletinRepository bulletinRepository ; private ControllerServiceProvider controllerServiceProvider ; private EntityFactory entityFactory ; private Authorizer authorizer ; private ExtensionManager extensionManager ; public ControllerConfigurationDTO createControllerConfigurationDto ( final ControllerFacade controllerFacade ) { final ControllerConfigurationDTO dto = new ControllerConfigurationDTO ( ) ; dto . setMaxTimerDrivenThreadCount ( controllerFacade . getMaxTimerDrivenThreadCount ( ) ) ; dto . setMaxEventDrivenThreadCount ( controllerFacade . getMaxEventDrivenThreadCount ( ) ) ; return dto ; } public FlowConfigurationDTO createFlowConfigurationDto ( final String autoRefreshInterval , final Long defaultBackPressureObjectThreshold , final String defaultBackPressureDataSizeThreshold ) { final FlowConfigurationDTO dto = new FlowConfigurationDTO ( ) ; final long refreshInterval = FormatUtils . getTimeDuration ( autoRefreshInterval , TimeUnit . SECONDS ) ; dto . setAutoRefreshIntervalSeconds ( refreshInterval ) ; dto . setSupportsManagedAuthorizer ( AuthorizerCapabilityDetection . isManagedAuthorizer ( authorizer ) ) ; dto . setSupportsConfigurableUsersAndGroups ( AuthorizerCapabilityDetection . isConfigurableUserGroupProvider ( authorizer ) ) ; dto . setSupportsConfigurableAuthorizer ( AuthorizerCapabilityDetection . isConfigurableAccessPolicyProvider ( authorizer ) ) ; final Date now = new Date ( ) ; dto . setTimeOffset ( TimeZone . getDefault ( ) . getOffset ( now . getTime ( ) ) ) ; dto . setCurrentTime ( now ) ; dto . setDefaultBackPressureDataSizeThreshold ( defaultBackPressureDataSizeThreshold ) ; dto . setDefaultBackPressureObjectThreshold ( defaultBackPressureObjectThreshold ) ; return dto ; } public ActionDTO createActionDto ( final Action action ) { final ActionDTO actionDto = new ActionDTO ( ) ; actionDto . setId ( action . getId ( ) ) ; actionDto . setSourceId ( action . getSourceId ( ) ) ; actionDto . setSourceName ( action . getSourceName ( ) ) ; actionDto . setSourceType ( action . getSourceType ( ) . toString ( ) ) ; actionDto . setTimestamp ( action . getTimestamp ( ) ) ; actionDto . setUserIdentity ( action . getUserIdentity ( ) ) ; actionDto . setOperation ( action . getOperation ( ) . toString ( ) ) ; actionDto . setActionDetails ( createActionDetailsDto ( action . getActionDetails ( ) ) ) ; actionDto . setComponentDetails ( createComponentDetailsDto ( action . getComponentDetails ( ) ) ) ; return actionDto ; } private ActionDetailsDTO createActionDetailsDto ( final ActionDetails actionDetails ) { if ( actionDetails == null ) { return null ; } if ( actionDetails instanceof FlowChangeConfigureDetails ) { final ConfigureDetailsDTO configureDetails = new ConfigureDetailsDTO ( ) ; configureDetails . setName ( ( ( ConfigureDetails ) actionDetails ) . getName ( ) ) ; configureDetails . setPreviousValue ( ( ( ConfigureDetails ) actionDetails ) . getPreviousValue ( ) ) ; configureDetails . setValue ( ( ( ConfigureDetails ) actionDetails ) . getValue ( ) ) ; return configureDetails ; } else if ( actionDetails instanceof FlowChangeConnectDetails ) { final ConnectDetailsDTO connectDetails = new ConnectDetailsDTO ( ) ; connectDetails . setSourceId ( ( ( ConnectDetails ) actionDetails ) . getSourceId ( ) ) ; connectDetails . setSourceName ( ( ( ConnectDetails ) actionDetails ) . getSourceName ( ) ) ; connectDetails . setSourceType ( ( ( ConnectDetails ) actionDetails ) . getSourceType ( ) . toString ( ) ) ; connectDetails . setRelationship ( ( ( ConnectDetails ) actionDetails ) . getRelationship ( ) ) ; connectDetails . setDestinationId ( ( ( ConnectDetails ) actionDetails ) . getDestinationId ( ) ) ; connectDetails . setDestinationName ( ( ( ConnectDetails ) actionDetails ) . getDestinationName ( ) ) ; connectDetails . setDestinationType ( ( ( ConnectDetails ) actionDetails ) . getDestinationType ( ) . toString ( ) ) ; return connectDetails ; } else if ( actionDetails instanceof FlowChangeMoveDetails ) { final MoveDetailsDTO moveDetails = new MoveDetailsDTO ( ) ; moveDetails . setPreviousGroup ( ( ( MoveDetails ) actionDetails ) . getPreviousGroup ( ) ) ; moveDetails . setPreviousGroupId ( ( ( MoveDetails ) actionDetails ) . getPreviousGroupId ( ) ) ; moveDetails . setGroup ( ( ( MoveDetails ) actionDetails ) . getGroup ( ) ) ; moveDetails . setGroupId ( ( ( MoveDetails ) actionDetails ) . getGroupId ( ) ) ; return moveDetails ; } else if ( actionDetails instanceof FlowChangePurgeDetails ) { final PurgeDetailsDTO purgeDetails = new PurgeDetailsDTO ( ) ; purgeDetails . setEndDate ( ( ( PurgeDetails ) actionDetails ) . getEndDate ( ) ) ; return purgeDetails ; } else { throw new WebApplicationException ( new IllegalArgumentException ( String . format ( ""Unrecognized type of action details encountered %s during serialization."" , actionDetails . toString ( ) ) ) ) ; } } private ComponentDetailsDTO createComponentDetailsDto ( final ComponentDetails componentDetails ) { if ( componentDetails == null ) { return null ; } if ( componentDetails instanceof FlowChangeExtensionDetails ) { final ExtensionDetailsDTO processorDetails = new ExtensionDetailsDTO ( ) ; processorDetails . setType ( ( ( ExtensionDetails ) componentDetails ) . getType ( ) ) ; return processorDetails ; } else if ( componentDetails instanceof FlowChangeRemoteProcessGroupDetails ) { final RemoteProcessGroupDetailsDTO remoteProcessGroupDetails = new RemoteProcessGroupDetailsDTO ( ) ; remoteProcessGroupDetails . setUri ( ( ( RemoteProcessGroupDetails ) componentDetails ) . getUri ( ) ) ; return remoteProcessGroupDetails ; } else { throw new WebApplicationException ( new IllegalArgumentException ( String . format ( ""Unrecognized type of component details encountered %s during serialization. "" , componentDetails . toString ( ) ) ) ) ; } } public HistoryDTO createHistoryDto ( final History history ) { final HistoryDTO historyDto = new HistoryDTO ( ) ; historyDto . setTotal ( history . getTotal ( ) ) ; historyDto . setLastRefreshed ( history . getLastRefreshed ( ) ) ; return historyDto ; } public ComponentStateDTO createComponentStateDTO ( final String componentId , final Class < ? > componentClass , final StateMap localState , final StateMap clusterState ) { final ComponentStateDTO dto = new ComponentStateDTO ( ) ; dto . setComponentId ( componentId ) ; dto . setStateDescription ( getStateDescription ( componentClass ) ) ; dto . setLocalState ( createStateMapDTO ( Scope . LOCAL , localState ) ) ; dto . setClusterState ( createStateMapDTO ( Scope . CLUSTER , clusterState ) ) ; return dto ; } private String getStateDescription ( final Class < ? > componentClass ) { final Stateful capabilityDesc = componentClass . getAnnotation ( Stateful . class ) ; if ( capabilityDesc != null ) { return capabilityDesc . description ( ) ; } else { return null ; } } public StateMapDTO createStateMapDTO ( final Scope scope , final StateMap stateMap ) { if ( stateMap == null ) { return null ; } final StateMapDTO dto = new StateMapDTO ( ) ; dto . setScope ( scope . toString ( ) ) ; final TreeMap < String , String > sortedState = new TreeMap < > ( SortedStateUtils . getKeyComparator ( ) ) ; final Map < String , String > state = stateMap . toMap ( ) ; sortedState . putAll ( state ) ; int count = 0 ; final List < StateEntryDTO > stateEntries = new ArrayList < > ( ) ; final Set < Map . Entry < String , String > > entrySet = sortedState . entrySet ( ) ; for ( final Iterator < Entry < String , String > > iter = entrySet . iterator ( ) ; iter . hasNext ( ) && count ++ < SortedStateUtils . MAX_COMPONENT_STATE_ENTRIES ; ) { final Map . Entry < String , String > entry = iter . next ( ) ; final StateEntryDTO entryDTO = new StateEntryDTO ( ) ; entryDTO . setKey ( entry . getKey ( ) ) ; entryDTO . setValue ( entry . getValue ( ) ) ; stateEntries . add ( entryDTO ) ; } dto . setTotalEntryCount ( state . size ( ) ) ; dto . setState ( stateEntries ) ; return dto ; } public CountersSnapshotDTO createCountersDto ( final Collection < CounterDTO > counterDtos ) { final CountersSnapshotDTO dto = new CountersSnapshotDTO ( ) ; dto . setCounters ( counterDtos ) ; dto . setGenerated ( new Date ( ) ) ; return dto ; } public CounterDTO createCounterDto ( final Counter counter ) { final CounterDTO dto = new CounterDTO ( ) ; dto . setId ( counter . getIdentifier ( ) ) ; dto . setContext ( counter . getContext ( ) ) ; dto . setName ( counter . getName ( ) ) ; dto . setValueCount ( counter . getValue ( ) ) ; dto . setValue ( FormatUtils . formatCount ( counter . getValue ( ) ) ) ; return dto ; } public PositionDTO createPositionDto ( final Position position ) { return new PositionDTO ( position . getX ( ) , position . getY ( ) ) ; } private boolean isDropRequestComplete ( final DropFlowFileState state ) { return DropFlowFileState . COMPLETE . equals ( state ) || DropFlowFileState . CANCELED . equals ( state ) || DropFlowFileState . FAILURE . equals ( state ) ; } public DropRequestDTO createDropRequestDTO ( final DropFlowFileStatus dropRequest ) { final DropRequestDTO dto = new DropRequestDTO ( ) ; dto . setId ( dropRequest . getRequestIdentifier ( ) ) ; dto . setSubmissionTime ( new Date ( dropRequest . getRequestSubmissionTime ( ) ) ) ; dto . setLastUpdated ( new Date ( dropRequest . getLastUpdated ( ) ) ) ; dto . setState ( dropRequest . getState ( ) . toString ( ) ) ; dto . setFailureReason ( dropRequest . getFailureReason ( ) ) ; dto . setFinished ( isDropRequestComplete ( dropRequest . getState ( ) ) ) ; final QueueSize dropped = dropRequest . getDroppedSize ( ) ; dto . setDroppedCount ( dropped . getObjectCount ( ) ) ; dto . setDroppedSize ( dropped . getByteCount ( ) ) ; dto . setDropped ( FormatUtils . formatCount ( dropped . getObjectCount ( ) ) + "" / "" + FormatUtils . formatDataSize ( dropped . getByteCount ( ) ) ) ; final QueueSize current = dropRequest . getCurrentSize ( ) ; dto . setCurrentCount ( current . getObjectCount ( ) ) ; dto . setCurrentSize ( current . getByteCount ( ) ) ; dto . setCurrent ( FormatUtils . formatCount ( current . getObjectCount ( ) ) + "" / "" + FormatUtils . formatDataSize ( current . getByteCount ( ) ) ) ; final QueueSize original = dropRequest . getOriginalSize ( ) ; dto . setOriginalCount ( original . getObjectCount ( ) ) ; dto . setOriginalSize ( original . getByteCount ( ) ) ; dto . setOriginal ( FormatUtils . formatCount ( original . getObjectCount ( ) ) + "" / "" + FormatUtils . formatDataSize ( original . getByteCount ( ) ) ) ; if ( isDropRequestComplete ( dropRequest . getState ( ) ) ) { dto . setPercentCompleted ( 100 ) ; } else { dto . setPercentCompleted ( ( dropped . getObjectCount ( ) * 100 ) / original . getObjectCount ( ) ) ; } return dto ; } private boolean isListingRequestComplete ( final ListFlowFileState state ) { return ListFlowFileState . COMPLETE . equals ( state ) || ListFlowFileState . CANCELED . equals ( state ) || ListFlowFileState . FAILURE . equals ( state ) ; } private QueueSizeDTO createQueueSizeDTO ( final QueueSize queueSize ) { final QueueSizeDTO dto = new QueueSizeDTO ( ) ; dto . setByteCount ( queueSize . getByteCount ( ) ) ; dto . setObjectCount ( queueSize . getObjectCount ( ) ) ; return dto ; } public ListingRequestDTO createListingRequestDTO ( final ListFlowFileStatus listingRequest ) { final ListingRequestDTO dto = new ListingRequestDTO ( ) ; dto . setId ( listingRequest . getRequestIdentifier ( ) ) ; dto . setSubmissionTime ( new Date ( listingRequest . getRequestSubmissionTime ( ) ) ) ; dto . setLastUpdated ( new Date ( listingRequest . getLastUpdated ( ) ) ) ; dto . setState ( listingRequest . getState ( ) . toString ( ) ) ; dto . setFailureReason ( listingRequest . getFailureReason ( ) ) ; dto . setFinished ( isListingRequestComplete ( listingRequest . getState ( ) ) ) ; dto . setMaxResults ( listingRequest . getMaxResults ( ) ) ; dto . setPercentCompleted ( listingRequest . getCompletionPercentage ( ) ) ; dto . setQueueSize ( createQueueSizeDTO ( listingRequest . getQueueSize ( ) ) ) ; if ( isListingRequestComplete ( listingRequest . getState ( ) ) ) { final List < FlowFileSummary > flowFileSummaries = listingRequest . getFlowFileSummaries ( ) ; if ( flowFileSummaries != null ) { final Date now = new Date ( ) ; final List < FlowFileSummaryDTO > summaryDtos = new ArrayList < > ( flowFileSummaries . size ( ) ) ; for ( final FlowFileSummary summary : flowFileSummaries ) { summaryDtos . add ( createFlowFileSummaryDTO ( summary , now ) ) ; } dto . setFlowFileSummaries ( summaryDtos ) ; } } return dto ; } public FlowFileSummaryDTO createFlowFileSummaryDTO ( final FlowFileSummary summary , final Date now ) { final FlowFileSummaryDTO dto = new FlowFileSummaryDTO ( ) ; dto . setUuid ( summary . getUuid ( ) ) ; dto . setFilename ( summary . getFilename ( ) ) ; dto . setPenalized ( summary . isPenalized ( ) ) ; final long penaltyExpiration = summary . getPenaltyExpirationMillis ( ) - now . getTime ( ) ; dto . setPenaltyExpiresIn ( penaltyExpiration >= 0 ? penaltyExpiration : 0 ) ; dto . setPosition ( summary . getPosition ( ) ) ; dto . setSize ( summary . getSize ( ) ) ; final long queuedDuration = now . getTime ( ) - summary . getLastQueuedTime ( ) ; dto . setQueuedDuration ( queuedDuration ) ; final long age = now . getTime ( ) - summary . getLineageStartDate ( ) ; dto . setLineageDuration ( age ) ; return dto ; } public FlowFileDTO createFlowFileDTO ( final FlowFileRecord record ) { final Date now = new Date ( ) ; final FlowFileDTO dto = new FlowFileDTO ( ) ; dto . setUuid ( record . getAttribute ( CoreAttributes . UUID . key ( ) ) ) ; dto . setFilename ( record . getAttribute ( CoreAttributes . FILENAME . key ( ) ) ) ; dto . setPenalized ( record . isPenalized ( ) ) ; final long penaltyExpiration = record . getPenaltyExpirationMillis ( ) - now . getTime ( ) ; dto . setPenaltyExpiresIn ( penaltyExpiration >= 0 ? penaltyExpiration : 0 ) ; dto . setSize ( record . getSize ( ) ) ; dto . setAttributes ( record . getAttributes ( ) ) ; final long queuedDuration = now . getTime ( ) - record . getLastQueueDate ( ) ; dto . setQueuedDuration ( queuedDuration ) ; final long age = now . getTime ( ) - record . getLineageStartDate ( ) ; dto . setLineageDuration ( age ) ; final ContentClaim contentClaim = record . getContentClaim ( ) ; if ( contentClaim != null ) { final ResourceClaim resourceClaim = contentClaim . getResourceClaim ( ) ; dto . setContentClaimSection ( resourceClaim . getSection ( ) ) ; dto . setContentClaimContainer ( resourceClaim . getContainer ( ) ) ; dto . setContentClaimIdentifier ( resourceClaim . getId ( ) ) ; dto . setContentClaimOffset ( contentClaim . getOffset ( ) + record . getContentClaimOffset ( ) ) ; dto . setContentClaimFileSizeBytes ( record . getSize ( ) ) ; dto . setContentClaimFileSize ( FormatUtils . formatDataSize ( record . getSize ( ) ) ) ; } return dto ; } public ConnectionDTO createConnectionDto ( final Connection connection ) { if ( connection == null ) { return null ; } final ConnectionDTO dto = new ConnectionDTO ( ) ; dto . setId ( connection . getIdentifier ( ) ) ; dto . setParentGroupId ( connection . getProcessGroup ( ) . getIdentifier ( ) ) ; final List < PositionDTO > bendPoints = new ArrayList < > ( ) ; for ( final Position bendPoint : connection . getBendPoints ( ) ) { bendPoints . add ( createPositionDto ( bendPoint ) ) ; } dto . setBends ( bendPoints ) ; dto . setName ( connection . getName ( ) ) ; dto . setLabelIndex ( connection . getLabelIndex ( ) ) ; dto . setzIndex ( connection . getZIndex ( ) ) ; dto . setSource ( createConnectableDto ( connection . getSource ( ) ) ) ; dto . setDestination ( createConnectableDto ( connection . getDestination ( ) ) ) ; dto . setVersionedComponentId ( connection . getVersionedComponentId ( ) . orElse ( null ) ) ; final FlowFileQueue flowFileQueue = connection . getFlowFileQueue ( ) ; dto . setBackPressureObjectThreshold ( flowFileQueue . getBackPressureObjectThreshold ( ) ) ; dto . setBackPressureDataSizeThreshold ( flowFileQueue . getBackPressureDataSizeThreshold ( ) ) ; dto . setFlowFileExpiration ( flowFileQueue . getFlowFileExpiration ( ) ) ; dto . setPrioritizers ( new ArrayList < String > ( ) ) ; for ( final FlowFilePrioritizer comparator : flowFileQueue . getPriorities ( ) ) { dto . getPrioritizers ( ) . add ( comparator . getClass ( ) . getCanonicalName ( ) ) ; } for ( final Relationship selectedRelationship : connection . getRelationships ( ) ) { if ( ! Relationship . ANONYMOUS . equals ( selectedRelationship ) ) { if ( dto . getSelectedRelationships ( ) == null ) { dto . setSelectedRelationships ( new TreeSet < String > ( Collator . getInstance ( Locale . US ) ) ) ; } dto . getSelectedRelationships ( ) . add ( selectedRelationship . getName ( ) ) ; } } for ( final Relationship availableRelationship : connection . getSource ( ) . getRelationships ( ) ) { if ( ! Relationship . ANONYMOUS . equals ( availableRelationship ) ) { if ( dto . getAvailableRelationships ( ) == null ) { dto . setAvailableRelationships ( new TreeSet < String > ( Collator . getInstance ( Locale . US ) ) ) ; } dto . getAvailableRelationships ( ) . add ( availableRelationship . getName ( ) ) ; } } final LoadBalanceStrategy loadBalanceStrategy = flowFileQueue . getLoadBalanceStrategy ( ) ; dto . setLoadBalancePartitionAttribute ( flowFileQueue . getPartitioningAttribute ( ) ) ; dto . setLoadBalanceStrategy ( loadBalanceStrategy . name ( ) ) ; dto . setLoadBalanceCompression ( flowFileQueue . getLoadBalanceCompression ( ) . name ( ) ) ; if ( loadBalanceStrategy == LoadBalanceStrategy . DO_NOT_LOAD_BALANCE ) { dto . setLoadBalanceStatus ( ConnectionDTO . LOAD_BALANCE_NOT_CONFIGURED ) ; } else if ( flowFileQueue . isActivelyLoadBalancing ( ) ) { dto . setLoadBalanceStatus ( ConnectionDTO . LOAD_BALANCE_ACTIVE ) ; } else { dto . setLoadBalanceStatus ( ConnectionDTO . LOAD_BALANCE_INACTIVE ) ; } return dto ; } public ConnectableDTO createConnectableDto ( final Connectable connectable ) { if ( connectable == null ) { return null ; } boolean isAuthorized = connectable . isAuthorized ( authorizer , RequestAction . READ , NiFiUserUtils . getNiFiUser ( ) ) ; final ConnectableDTO dto = new ConnectableDTO ( ) ; dto . setId ( connectable . getIdentifier ( ) ) ; dto . setName ( isAuthorized ? connectable . getName ( ) : connectable . getIdentifier ( ) ) ; dto . setType ( connectable . getConnectableType ( ) . name ( ) ) ; dto . setVersionedComponentId ( connectable . getVersionedComponentId ( ) . orElse ( null ) ) ; if ( connectable instanceof RemoteGroupPort ) { final RemoteGroupPort remoteGroupPort = ( RemoteGroupPort ) connectable ; final RemoteProcessGroup remoteGroup = remoteGroupPort . getRemoteProcessGroup ( ) ; dto . setGroupId ( remoteGroup . getIdentifier ( ) ) ; dto . setRunning ( remoteGroupPort . isTargetRunning ( ) ) ; dto . setTransmitting ( remoteGroupPort . isRunning ( ) ) ; dto . setExists ( remoteGroupPort . getTargetExists ( ) ) ; if ( isAuthorized ) { dto . setComments ( remoteGroup . getComments ( ) ) ; } } else { dto . setGroupId ( connectable . getProcessGroup ( ) . getIdentifier ( ) ) ; dto . setRunning ( connectable . isRunning ( ) ) ; if ( isAuthorized ) { dto . setComments ( connectable . getComments ( ) ) ; } } return dto ; } public LabelDTO createLabelDto ( final Label label ) { if ( label == null ) { return null ; } final LabelDTO dto = new LabelDTO ( ) ; dto . setId ( label . getIdentifier ( ) ) ; dto . setPosition ( createPositionDto ( label . getPosition ( ) ) ) ; dto . setStyle ( label . getStyle ( ) ) ; dto . setHeight ( label . getSize ( ) . getHeight ( ) ) ; dto . setWidth ( label . getSize ( ) . getWidth ( ) ) ; dto . setLabel ( label . getValue ( ) ) ; dto . setParentGroupId ( label . getProcessGroup ( ) . getIdentifier ( ) ) ; dto . setVersionedComponentId ( label . getVersionedComponentId ( ) . orElse ( null ) ) ; return dto ; } public UserDTO createUserDto ( final User user , final Set < TenantEntity > groups , final Set < AccessPolicySummaryEntity > accessPolicies ) { if ( user == null ) { return null ; } final UserDTO dto = new UserDTO ( ) ; dto . setId ( user . getIdentifier ( ) ) ; dto . setUserGroups ( groups ) ; dto . setIdentity ( user . getIdentity ( ) ) ; dto . setConfigurable ( AuthorizerCapabilityDetection . isUserConfigurable ( authorizer , user ) ) ; dto . setAccessPolicies ( accessPolicies ) ; return dto ; } public TenantDTO createTenantDTO ( User user ) { if ( user == null ) { return null ; } final TenantDTO dto = new TenantDTO ( ) ; dto . setId ( user . getIdentifier ( ) ) ; dto . setIdentity ( user . getIdentity ( ) ) ; dto . setConfigurable ( AuthorizerCapabilityDetection . isUserConfigurable ( authorizer , user ) ) ; return dto ; } public UserGroupDTO createUserGroupDto ( final Group userGroup , Set < TenantEntity > users , final Set < AccessPolicySummaryEntity > accessPolicies ) { if ( userGroup == null ) { return null ; } final Set < AccessPolicyEntity > policies = accessPolicies . stream ( ) . map ( summaryEntity -> { final AccessPolicyDTO policy = new AccessPolicyDTO ( ) ; policy . setId ( summaryEntity . getId ( ) ) ; if ( summaryEntity . getPermissions ( ) . getCanRead ( ) ) { final AccessPolicySummaryDTO summary = summaryEntity . getComponent ( ) ; policy . setResource ( summary . getResource ( ) ) ; policy . setAction ( summary . getAction ( ) ) ; policy . setConfigurable ( summary . getConfigurable ( ) ) ; policy . setComponentReference ( summary . getComponentReference ( ) ) ; } return entityFactory . createAccessPolicyEntity ( policy , summaryEntity . getRevision ( ) , summaryEntity . getPermissions ( ) ) ; } ) . collect ( Collectors . toSet ( ) ) ; final UserGroupDTO dto = new UserGroupDTO ( ) ; dto . setId ( userGroup . getIdentifier ( ) ) ; dto . setUsers ( users ) ; dto . setIdentity ( userGroup . getName ( ) ) ; dto . setConfigurable ( AuthorizerCapabilityDetection . isGroupConfigurable ( authorizer , userGroup ) ) ; dto . setAccessPolicies ( policies ) ; return dto ; } public TenantDTO createTenantDTO ( Group userGroup ) { if ( userGroup == null ) { return null ; } final TenantDTO dto = new TenantDTO ( ) ; dto . setId ( userGroup . getIdentifier ( ) ) ; dto . setIdentity ( userGroup . getName ( ) ) ; dto . setConfigurable ( AuthorizerCapabilityDetection . isGroupConfigurable ( authorizer , userGroup ) ) ; return dto ; } public FunnelDTO createFunnelDto ( final Funnel funnel ) { if ( funnel == null ) { return null ; } final FunnelDTO dto = new FunnelDTO ( ) ; dto . setId ( funnel . getIdentifier ( ) ) ; dto . setPosition ( createPositionDto ( funnel . getPosition ( ) ) ) ; dto . setParentGroupId ( funnel . getProcessGroup ( ) . getIdentifier ( ) ) ; dto . setVersionedComponentId ( funnel . getVersionedComponentId ( ) . orElse ( null ) ) ; return dto ; } public SnippetDTO createSnippetDto ( final Snippet snippet ) { final SnippetDTO dto = new SnippetDTO ( ) ; dto . setId ( snippet . getId ( ) ) ; dto . setParentGroupId ( snippet . getParentGroupId ( ) ) ; dto . setConnections ( mapRevisionToDto ( snippet . getConnections ( ) ) ) ; dto . setFunnels ( mapRevisionToDto ( snippet . getFunnels ( ) ) ) ; dto . setInputPorts ( mapRevisionToDto ( snippet . getInputPorts ( ) ) ) ; dto . setLabels ( mapRevisionToDto ( snippet . getLabels ( ) ) ) ; dto . setOutputPorts ( mapRevisionToDto ( snippet . getOutputPorts ( ) ) ) ; dto . setProcessGroups ( mapRevisionToDto ( snippet . getProcessGroups ( ) ) ) ; dto . setProcessors ( mapRevisionToDto ( snippet . getProcessors ( ) ) ) ; dto . setRemoteProcessGroups ( mapRevisionToDto ( snippet . getRemoteProcessGroups ( ) ) ) ; return dto ; } private Map < String , RevisionDTO > mapRevisionToDto ( final Map < String , Revision > revisionMap ) { final Map < String , RevisionDTO > dtos = new HashMap < > ( revisionMap . size ( ) ) ; for ( final Map . Entry < String , Revision > entry : revisionMap . entrySet ( ) ) { final Revision revision = entry . getValue ( ) ; final RevisionDTO revisionDto = new RevisionDTO ( ) ; revisionDto . setClientId ( revision . getClientId ( ) ) ; revisionDto . setVersion ( revision . getVersion ( ) ) ; dtos . put ( entry . getKey ( ) , revisionDto ) ; } return dtos ; } public TemplateDTO createTemplateDTO ( final Template template ) { if ( template == null ) { return null ; } final TemplateDTO original = template . getDetails ( ) ; final TemplateDTO copy = new TemplateDTO ( ) ; copy . setId ( original . getId ( ) ) ; copy . setGroupId ( template . getProcessGroup ( ) . getIdentifier ( ) ) ; copy . setName ( original . getName ( ) ) ; copy . setDescription ( original . getDescription ( ) ) ; copy . setTimestamp ( original . getTimestamp ( ) ) ; copy . setUri ( original . getUri ( ) ) ; copy . setEncodingVersion ( original . getEncodingVersion ( ) ) ; return copy ; } public RemoteProcessGroupStatusDTO createRemoteProcessGroupStatusDto ( final RemoteProcessGroup remoteProcessGroup , final RemoteProcessGroupStatus remoteProcessGroupStatus ) { final RemoteProcessGroupStatusDTO dto = new RemoteProcessGroupStatusDTO ( ) ; dto . setId ( remoteProcessGroupStatus . getId ( ) ) ; dto . setGroupId ( remoteProcessGroupStatus . getGroupId ( ) ) ; dto . setTargetUri ( remoteProcessGroupStatus . getTargetUri ( ) ) ; dto . setName ( remoteProcessGroupStatus . getName ( ) ) ; dto . setTransmissionStatus ( remoteProcessGroupStatus . getTransmissionStatus ( ) . toString ( ) ) ; dto . setStatsLastRefreshed ( new Date ( ) ) ; dto . setValidationStatus ( getRemoteProcessGroupValidationStatus ( remoteProcessGroup ) . name ( ) ) ; final RemoteProcessGroupStatusSnapshotDTO snapshot = new RemoteProcessGroupStatusSnapshotDTO ( ) ; dto . setAggregateSnapshot ( snapshot ) ; snapshot . setId ( remoteProcessGroupStatus . getId ( ) ) ; snapshot . setGroupId ( remoteProcessGroupStatus . getGroupId ( ) ) ; snapshot . setName ( remoteProcessGroupStatus . getName ( ) ) ; snapshot . setTargetUri ( remoteProcessGroupStatus . getTargetUri ( ) ) ; snapshot . setTransmissionStatus ( remoteProcessGroupStatus . getTransmissionStatus ( ) . toString ( ) ) ; snapshot . setActiveThreadCount ( remoteProcessGroupStatus . getActiveThreadCount ( ) ) ; snapshot . setFlowFilesSent ( remoteProcessGroupStatus . getSentCount ( ) ) ; snapshot . setBytesSent ( remoteProcessGroupStatus . getSentContentSize ( ) ) ; snapshot . setFlowFilesReceived ( remoteProcessGroupStatus . getReceivedCount ( ) ) ; snapshot . setBytesReceived ( remoteProcessGroupStatus . getReceivedContentSize ( ) ) ; StatusMerger . updatePrettyPrintedFields ( snapshot ) ; return dto ; } private ValidationStatus getRemoteProcessGroupValidationStatus ( RemoteProcessGroup remoteProcessGroup ) { final boolean hasAuthIssue = remoteProcessGroup . getAuthorizationIssue ( ) != null && ! remoteProcessGroup . getAuthorizationIssue ( ) . isEmpty ( ) ; final Collection < ValidationResult > validationResults = remoteProcessGroup . validate ( ) ; final boolean hasValidationIssue = validationResults != null && ! validationResults . isEmpty ( ) ; return hasAuthIssue || hasValidationIssue ? ValidationStatus . INVALID : ValidationStatus . VALID ; } public ProcessGroupStatusDTO createConciseProcessGroupStatusDto ( final ProcessGroupStatus processGroupStatus ) { final ProcessGroupStatusDTO processGroupStatusDto = new ProcessGroupStatusDTO ( ) ; processGroupStatusDto . setId ( processGroupStatus . getId ( ) ) ; processGroupStatusDto . setName ( processGroupStatus . getName ( ) ) ; processGroupStatusDto . setStatsLastRefreshed ( new Date ( ) ) ; final ProcessGroupStatusSnapshotDTO snapshot = new ProcessGroupStatusSnapshotDTO ( ) ; processGroupStatusDto . setAggregateSnapshot ( snapshot ) ; snapshot . setId ( processGroupStatus . getId ( ) ) ; snapshot . setName ( processGroupStatus . getName ( ) ) ; if ( processGroupStatus . getVersionedFlowState ( ) != null ) { snapshot . setVersionedFlowState ( processGroupStatus . getVersionedFlowState ( ) . name ( ) ) ; } snapshot . setFlowFilesQueued ( processGroupStatus . getQueuedCount ( ) ) ; snapshot . setBytesQueued ( processGroupStatus . getQueuedContentSize ( ) ) ; snapshot . setBytesRead ( processGroupStatus . getBytesRead ( ) ) ; snapshot . setBytesWritten ( processGroupStatus . getBytesWritten ( ) ) ; snapshot . setFlowFilesIn ( processGroupStatus . getInputCount ( ) ) ; snapshot . setBytesIn ( processGroupStatus . getInputContentSize ( ) ) ; snapshot . setFlowFilesOut ( processGroupStatus . getOutputCount ( ) ) ; snapshot . setBytesOut ( processGroupStatus . getOutputContentSize ( ) ) ; snapshot . setFlowFilesTransferred ( processGroupStatus . getFlowFilesTransferred ( ) ) ; snapshot . setBytesTransferred ( processGroupStatus . getBytesTransferred ( ) ) ; snapshot . setFlowFilesSent ( processGroupStatus . getFlowFilesSent ( ) ) ; snapshot . setBytesSent ( processGroupStatus . getBytesSent ( ) ) ; snapshot . setFlowFilesReceived ( processGroupStatus . getFlowFilesReceived ( ) ) ; snapshot . setBytesReceived ( processGroupStatus . getBytesReceived ( ) ) ; snapshot . setActiveThreadCount ( processGroupStatus . getActiveThreadCount ( ) ) ; snapshot . setTerminatedThreadCount ( processGroupStatus . getTerminatedThreadCount ( ) ) ; StatusMerger . updatePrettyPrintedFields ( snapshot ) ; return processGroupStatusDto ; } public ProcessGroupStatusDTO createProcessGroupStatusDto ( final ProcessGroup processGroup , final ProcessGroupStatus processGroupStatus ) { final ProcessGroupStatusDTO processGroupStatusDto = createConciseProcessGroupStatusDto ( processGroupStatus ) ; final ProcessGroupStatusSnapshotDTO snapshot = processGroupStatusDto . getAggregateSnapshot ( ) ; final Collection < ProcessorStatusSnapshotEntity > processorStatusSnapshotEntities = new ArrayList < > ( ) ; snapshot . setProcessorStatusSnapshots ( processorStatusSnapshotEntities ) ; final Collection < ProcessorStatus > processorStatusCollection = processGroupStatus . getProcessorStatus ( ) ; if ( processorStatusCollection != null ) { for ( final ProcessorStatus processorStatus : processorStatusCollection ) { final ProcessorStatusDTO processorStatusDto = createProcessorStatusDto ( processorStatus ) ; final ProcessorNode processor = processGroup . findProcessor ( processorStatusDto . getId ( ) ) ; final PermissionsDTO processorPermissions = createPermissionsDto ( processor ) ; processorStatusSnapshotEntities . add ( entityFactory . createProcessorStatusSnapshotEntity ( processorStatusDto . getAggregateSnapshot ( ) , processorPermissions ) ) ; } } final Collection < ConnectionStatusSnapshotEntity > connectionStatusDtoCollection = new ArrayList < > ( ) ; snapshot . setConnectionStatusSnapshots ( connectionStatusDtoCollection ) ; final Collection < ConnectionStatus > connectionStatusCollection = processGroupStatus . getConnectionStatus ( ) ; if ( connectionStatusCollection != null ) { for ( final ConnectionStatus connectionStatus : connectionStatusCollection ) { final ConnectionStatusDTO connectionStatusDto = createConnectionStatusDto ( connectionStatus ) ; final Connection connection = processGroup . findConnection ( connectionStatusDto . getId ( ) ) ; final PermissionsDTO connectionPermissions = createPermissionsDto ( connection ) ; connectionStatusDtoCollection . add ( entityFactory . createConnectionStatusSnapshotEntity ( connectionStatusDto . getAggregateSnapshot ( ) , connectionPermissions ) ) ; } } final Collection < ProcessGroupStatusSnapshotEntity > childProcessGroupStatusDtoCollection = new ArrayList < > ( ) ; snapshot . setProcessGroupStatusSnapshots ( childProcessGroupStatusDtoCollection ) ; final Collection < ProcessGroupStatus > childProcessGroupStatusCollection = processGroupStatus . getProcessGroupStatus ( ) ; if ( childProcessGroupStatusCollection != null ) { for ( final ProcessGroupStatus childProcessGroupStatus : childProcessGroupStatusCollection ) { final ProcessGroupStatusDTO childProcessGroupStatusDto = createProcessGroupStatusDto ( processGroup , childProcessGroupStatus ) ; final ProcessGroup childProcessGroup = processGroup . findProcessGroup ( childProcessGroupStatusDto . getId ( ) ) ; final PermissionsDTO childProcessGroupPermissions = createPermissionsDto ( childProcessGroup ) ; childProcessGroupStatusDtoCollection . add ( entityFactory . createProcessGroupStatusSnapshotEntity ( childProcessGroupStatusDto . getAggregateSnapshot ( ) , childProcessGroupPermissions ) ) ; } } final Collection < RemoteProcessGroupStatusSnapshotEntity > childRemoteProcessGroupStatusDtoCollection = new ArrayList < > ( ) ; snapshot . setRemoteProcessGroupStatusSnapshots ( childRemoteProcessGroupStatusDtoCollection ) ; final Collection < RemoteProcessGroupStatus > childRemoteProcessGroupStatusCollection = processGroupStatus . getRemoteProcessGroupStatus ( ) ; if ( childRemoteProcessGroupStatusCollection != null ) { for ( final RemoteProcessGroupStatus childRemoteProcessGroupStatus : childRemoteProcessGroupStatusCollection ) { final RemoteProcessGroup remoteProcessGroup = processGroup . findRemoteProcessGroup ( childRemoteProcessGroupStatus . getId ( ) ) ; final RemoteProcessGroupStatusDTO childRemoteProcessGroupStatusDto = createRemoteProcessGroupStatusDto ( remoteProcessGroup , childRemoteProcessGroupStatus ) ; final PermissionsDTO remoteProcessGroupPermissions = createPermissionsDto ( remoteProcessGroup ) ; childRemoteProcessGroupStatusDtoCollection . add ( entityFactory . createRemoteProcessGroupStatusSnapshotEntity ( childRemoteProcessGroupStatusDto . getAggregateSnapshot ( ) , remoteProcessGroupPermissions ) ) ; } } final Collection < PortStatusSnapshotEntity > inputPortStatusDtoCollection = new ArrayList < > ( ) ; snapshot . setInputPortStatusSnapshots ( inputPortStatusDtoCollection ) ; final Collection < PortStatus > inputPortStatusCollection = processGroupStatus . getInputPortStatus ( ) ; if ( inputPortStatusCollection != null ) { for ( final PortStatus portStatus : inputPortStatusCollection ) { final PortStatusDTO portStatusDto = createPortStatusDto ( portStatus ) ; final Port inputPort = processGroup . findInputPort ( portStatus . getId ( ) ) ; final PermissionsDTO inputPortPermissions = createPermissionsDto ( inputPort ) ; inputPortStatusDtoCollection . add ( entityFactory . createPortStatusSnapshotEntity ( portStatusDto . getAggregateSnapshot ( ) , inputPortPermissions ) ) ; } } final Collection < PortStatusSnapshotEntity > outputPortStatusDtoCollection = new ArrayList < > ( ) ; snapshot . setOutputPortStatusSnapshots ( outputPortStatusDtoCollection ) ; final Collection < PortStatus > outputPortStatusCollection = processGroupStatus . getOutputPortStatus ( ) ; if ( outputPortStatusCollection != null ) { for ( final PortStatus portStatus : outputPortStatusCollection ) { final PortStatusDTO portStatusDto = createPortStatusDto ( portStatus ) ; final Port outputPort = processGroup . findOutputPort ( portStatus . getId ( ) ) ; final PermissionsDTO outputPortPermissions = createPermissionsDto ( outputPort ) ; outputPortStatusDtoCollection . add ( entityFactory . createPortStatusSnapshotEntity ( portStatusDto . getAggregateSnapshot ( ) , outputPortPermissions ) ) ; } } return processGroupStatusDto ; } public ConnectionStatusDTO createConnectionStatusDto ( final ConnectionStatus connectionStatus ) { final ConnectionStatusDTO connectionStatusDto = new ConnectionStatusDTO ( ) ; connectionStatusDto . setGroupId ( connectionStatus . getGroupId ( ) ) ; connectionStatusDto . setId ( connectionStatus . getId ( ) ) ; connectionStatusDto . setName ( connectionStatus . getName ( ) ) ; connectionStatusDto . setSourceId ( connectionStatus . getSourceId ( ) ) ; connectionStatusDto . setSourceName ( connectionStatus . getSourceName ( ) ) ; connectionStatusDto . setDestinationId ( connectionStatus . getDestinationId ( ) ) ; connectionStatusDto . setDestinationName ( connectionStatus . getDestinationName ( ) ) ; connectionStatusDto . setStatsLastRefreshed ( new Date ( ) ) ; final ConnectionStatusSnapshotDTO snapshot = new ConnectionStatusSnapshotDTO ( ) ; connectionStatusDto . setAggregateSnapshot ( snapshot ) ; snapshot . setId ( connectionStatus . getId ( ) ) ; snapshot . setGroupId ( connectionStatus . getGroupId ( ) ) ; snapshot . setName ( connectionStatus . getName ( ) ) ; snapshot . setSourceName ( connectionStatus . getSourceName ( ) ) ; snapshot . setDestinationName ( connectionStatus . getDestinationName ( ) ) ; snapshot . setFlowFilesQueued ( connectionStatus . getQueuedCount ( ) ) ; snapshot . setBytesQueued ( connectionStatus . getQueuedBytes ( ) ) ; snapshot . setFlowFilesIn ( connectionStatus . getInputCount ( ) ) ; snapshot . setBytesIn ( connectionStatus . getInputBytes ( ) ) ; snapshot . setFlowFilesOut ( connectionStatus . getOutputCount ( ) ) ; snapshot . setBytesOut ( connectionStatus . getOutputBytes ( ) ) ; if ( connectionStatus . getBackPressureObjectThreshold ( ) > 0 ) { snapshot . setPercentUseCount ( Math . min ( 100 , StatusMerger . getUtilization ( connectionStatus . getQueuedCount ( ) , connectionStatus . getBackPressureObjectThreshold ( ) ) ) ) ; } if ( connectionStatus . getBackPressureBytesThreshold ( ) > 0 ) { snapshot . setPercentUseBytes ( Math . min ( 100 , StatusMerger . getUtilization ( connectionStatus . getQueuedBytes ( ) , connectionStatus . getBackPressureBytesThreshold ( ) ) ) ) ; } StatusMerger . updatePrettyPrintedFields ( snapshot ) ; return connectionStatusDto ; } public ProcessorStatusDTO createProcessorStatusDto ( final ProcessorStatus procStatus ) { final ProcessorStatusDTO dto = new ProcessorStatusDTO ( ) ; dto . setId ( procStatus . getId ( ) ) ; dto . setGroupId ( procStatus . getGroupId ( ) ) ; dto . setName ( procStatus . getName ( ) ) ; dto . setStatsLastRefreshed ( new Date ( ) ) ; dto . setRunStatus ( procStatus . getRunStatus ( ) . toString ( ) ) ; final ProcessorStatusSnapshotDTO snapshot = new ProcessorStatusSnapshotDTO ( ) ; dto . setAggregateSnapshot ( snapshot ) ; snapshot . setId ( procStatus . getId ( ) ) ; snapshot . setGroupId ( procStatus . getGroupId ( ) ) ; snapshot . setName ( procStatus . getName ( ) ) ; snapshot . setFlowFilesOut ( procStatus . getOutputCount ( ) ) ; snapshot . setBytesOut ( procStatus . getOutputBytes ( ) ) ; snapshot . setFlowFilesIn ( procStatus . getInputCount ( ) ) ; snapshot . setBytesIn ( procStatus . getInputBytes ( ) ) ; snapshot . setBytesRead ( procStatus . getBytesRead ( ) ) ; snapshot . setBytesWritten ( procStatus . getBytesWritten ( ) ) ; snapshot . setTaskCount ( procStatus . getInvocations ( ) ) ; snapshot . setTasksDurationNanos ( procStatus . getProcessingNanos ( ) ) ; snapshot . setTasksDuration ( FormatUtils . formatHoursMinutesSeconds ( procStatus . getProcessingNanos ( ) , TimeUnit . NANOSECONDS ) ) ; snapshot . setRunStatus ( procStatus . getRunStatus ( ) . toString ( ) ) ; snapshot . setExecutionNode ( procStatus . getExecutionNode ( ) . toString ( ) ) ; snapshot . setActiveThreadCount ( procStatus . getActiveThreadCount ( ) ) ; snapshot . setTerminatedThreadCount ( procStatus . getTerminatedThreadCount ( ) ) ; snapshot . setType ( procStatus . getType ( ) ) ; StatusMerger . updatePrettyPrintedFields ( snapshot ) ; return dto ; } public PortStatusDTO createPortStatusDto ( final PortStatus portStatus ) { final PortStatusDTO dto = new PortStatusDTO ( ) ; dto . setId ( portStatus . getId ( ) ) ; dto . setGroupId ( portStatus . getGroupId ( ) ) ; dto . setName ( portStatus . getName ( ) ) ; dto . setRunStatus ( portStatus . getRunStatus ( ) . toString ( ) ) ; dto . setTransmitting ( portStatus . isTransmitting ( ) ) ; dto . setStatsLastRefreshed ( new Date ( ) ) ; final PortStatusSnapshotDTO snapshot = new PortStatusSnapshotDTO ( ) ; dto . setAggregateSnapshot ( snapshot ) ; snapshot . setId ( portStatus . getId ( ) ) ; snapshot . setGroupId ( portStatus . getGroupId ( ) ) ; snapshot . setName ( portStatus . getName ( ) ) ; snapshot . setRunStatus ( portStatus . getRunStatus ( ) . toString ( ) ) ; snapshot . setActiveThreadCount ( portStatus . getActiveThreadCount ( ) ) ; snapshot . setFlowFilesOut ( portStatus . getOutputCount ( ) ) ; snapshot . setBytesOut ( portStatus . getOutputBytes ( ) ) ; snapshot . setFlowFilesIn ( portStatus . getInputCount ( ) ) ; snapshot . setBytesIn ( portStatus . getInputBytes ( ) ) ; StatusMerger . updatePrettyPrintedFields ( snapshot ) ; return dto ; } public FlowSnippetDTO copySnippetContents ( final FlowSnippetDTO originalSnippet ) { final FlowSnippetDTO copySnippet = new FlowSnippetDTO ( ) ; if ( originalSnippet . getConnections ( ) != null ) { for ( final ConnectionDTO connection : originalSnippet . getConnections ( ) ) { copySnippet . getConnections ( ) . add ( copy ( connection ) ) ; } } if ( originalSnippet . getInputPorts ( ) != null ) { for ( final PortDTO port : originalSnippet . getInputPorts ( ) ) { copySnippet . getInputPorts ( ) . add ( copy ( port ) ) ; } } if ( originalSnippet . getOutputPorts ( ) != null ) { for ( final PortDTO port : originalSnippet . getOutputPorts ( ) ) { copySnippet . getOutputPorts ( ) . add ( copy ( port ) ) ; } } if ( originalSnippet . getProcessGroups ( ) != null ) { for ( final ProcessGroupDTO processGroup : originalSnippet . getProcessGroups ( ) ) { copySnippet . getProcessGroups ( ) . add ( copy ( processGroup , true ) ) ; } } if ( originalSnippet . getProcessors ( ) != null ) { for ( final ProcessorDTO processor : originalSnippet . getProcessors ( ) ) { copySnippet . getProcessors ( ) . add ( copy ( processor ) ) ; } } if ( originalSnippet . getLabels ( ) != null ) { for ( final LabelDTO label : originalSnippet . getLabels ( ) ) { copySnippet . getLabels ( ) . add ( copy ( label ) ) ; } } if ( originalSnippet . getFunnels ( ) != null ) { for ( final FunnelDTO funnel : originalSnippet . getFunnels ( ) ) { copySnippet . getFunnels ( ) . add ( copy ( funnel ) ) ; } } if ( originalSnippet . getRemoteProcessGroups ( ) != null ) { for ( final RemoteProcessGroupDTO remoteGroup : originalSnippet . getRemoteProcessGroups ( ) ) { copySnippet . getRemoteProcessGroups ( ) . add ( copy ( remoteGroup ) ) ; } } if ( originalSnippet . getControllerServices ( ) != null ) { for ( final ControllerServiceDTO controllerService : originalSnippet . getControllerServices ( ) ) { copySnippet . getControllerServices ( ) . add ( copy ( controllerService ) ) ; } } return copySnippet ; } public PortDTO createPortDto ( final Port port ) { if ( port == null ) { return null ; } final PortDTO dto = new PortDTO ( ) ; dto . setId ( port . getIdentifier ( ) ) ; dto . setPosition ( createPositionDto ( port . getPosition ( ) ) ) ; dto . setName ( port . getName ( ) ) ; dto . setComments ( port . getComments ( ) ) ; dto . setConcurrentlySchedulableTaskCount ( port . getMaxConcurrentTasks ( ) ) ; dto . setParentGroupId ( port . getProcessGroup ( ) . getIdentifier ( ) ) ; dto . setState ( port . getScheduledState ( ) . toString ( ) ) ; dto . setType ( port . getConnectableType ( ) . name ( ) ) ; dto . setVersionedComponentId ( port . getVersionedComponentId ( ) . orElse ( null ) ) ; if ( port instanceof RootGroupPort ) { final RootGroupPort rootGroupPort = ( RootGroupPort ) port ; dto . setTransmitting ( rootGroupPort . isTransmitting ( ) ) ; dto . setGroupAccessControl ( rootGroupPort . getGroupAccessControl ( ) ) ; dto . setUserAccessControl ( rootGroupPort . getUserAccessControl ( ) ) ; } final Collection < ValidationResult > validationErrors = port . getValidationErrors ( ) ; if ( validationErrors != null && ! validationErrors . isEmpty ( ) ) { final List < String > errors = new ArrayList < > ( ) ; for ( final ValidationResult validationResult : validationErrors ) { errors . add ( validationResult . toString ( ) ) ; } dto . setValidationErrors ( errors ) ; } return dto ; } public ReportingTaskDTO createReportingTaskDto ( final ReportingTaskNode reportingTaskNode ) { final BundleCoordinate bundleCoordinate = reportingTaskNode . getBundleCoordinate ( ) ; final List < Bundle > compatibleBundles = extensionManager . getBundles ( reportingTaskNode . getCanonicalClassName ( ) ) . stream ( ) . filter ( bundle -> { final BundleCoordinate coordinate = bundle . getBundleDetails ( ) . getCoordinate ( ) ; return bundleCoordinate . getGroup ( ) . equals ( coordinate . getGroup ( ) ) && bundleCoordinate . getId ( ) . equals ( coordinate . getId ( ) ) ; } ) . collect ( Collectors . toList ( ) ) ; final ReportingTaskDTO dto = new ReportingTaskDTO ( ) ; dto . setId ( reportingTaskNode . getIdentifier ( ) ) ; dto . setName ( reportingTaskNode . getName ( ) ) ; dto . setType ( reportingTaskNode . getCanonicalClassName ( ) ) ; dto . setBundle ( createBundleDto ( bundleCoordinate ) ) ; dto . setSchedulingStrategy ( reportingTaskNode . getSchedulingStrategy ( ) . name ( ) ) ; dto . setSchedulingPeriod ( reportingTaskNode . getSchedulingPeriod ( ) ) ; dto . setState ( reportingTaskNode . getScheduledState ( ) . name ( ) ) ; dto . setActiveThreadCount ( reportingTaskNode . getActiveThreadCount ( ) ) ; dto . setAnnotationData ( reportingTaskNode . getAnnotationData ( ) ) ; dto . setComments ( reportingTaskNode . getComments ( ) ) ; dto . setPersistsState ( reportingTaskNode . getReportingTask ( ) . getClass ( ) . isAnnotationPresent ( Stateful . class ) ) ; dto . setRestricted ( reportingTaskNode . isRestricted ( ) ) ; dto . setDeprecated ( reportingTaskNode . isDeprecated ( ) ) ; dto . setExtensionMissing ( reportingTaskNode . isExtensionMissing ( ) ) ; dto . setMultipleVersionsAvailable ( compatibleBundles . size ( ) > 1 ) ; final Map < String , String > defaultSchedulingPeriod = new HashMap < > ( ) ; defaultSchedulingPeriod . put ( SchedulingStrategy . TIMER_DRIVEN . name ( ) , SchedulingStrategy . TIMER_DRIVEN . getDefaultSchedulingPeriod ( ) ) ; defaultSchedulingPeriod . put ( SchedulingStrategy . CRON_DRIVEN . name ( ) , SchedulingStrategy . CRON_DRIVEN . getDefaultSchedulingPeriod ( ) ) ; dto . setDefaultSchedulingPeriod ( defaultSchedulingPeriod ) ; final Map < PropertyDescriptor , String > sortedProperties = new TreeMap < > ( new Comparator < PropertyDescriptor > ( ) { @ Override public int compare ( final PropertyDescriptor o1 , final PropertyDescriptor o2 ) { return Collator . getInstance ( Locale . US ) . compare ( o1 . getName ( ) , o2 . getName ( ) ) ; } } ) ; sortedProperties . putAll ( reportingTaskNode . getProperties ( ) ) ; final ReportingTask reportingTask = reportingTaskNode . getReportingTask ( ) ; final Map < PropertyDescriptor , String > orderedProperties = new LinkedHashMap < > ( ) ; final List < PropertyDescriptor > descriptors = reportingTask . getPropertyDescriptors ( ) ; if ( descriptors != null && ! descriptors . isEmpty ( ) ) { for ( final PropertyDescriptor descriptor : descriptors ) { orderedProperties . put ( descriptor , null ) ; } } orderedProperties . putAll ( sortedProperties ) ; dto . setDescriptors ( new LinkedHashMap < String , PropertyDescriptorDTO > ( ) ) ; dto . setProperties ( new LinkedHashMap < String , String > ( ) ) ; for ( final Map . Entry < PropertyDescriptor , String > entry : orderedProperties . entrySet ( ) ) { final PropertyDescriptor descriptor = entry . getKey ( ) ; dto . getDescriptors ( ) . put ( descriptor . getName ( ) , createPropertyDescriptorDto ( descriptor , null ) ) ; String propertyValue = entry . getValue ( ) ; if ( propertyValue != null && descriptor . isSensitive ( ) ) { propertyValue = SENSITIVE_VALUE_MASK ; } dto . getProperties ( ) . put ( descriptor . getName ( ) , propertyValue ) ; } final ValidationStatus validationStatus = reportingTaskNode . getValidationStatus ( 1 , TimeUnit . MILLISECONDS ) ; dto . setValidationStatus ( validationStatus . name ( ) ) ; final Collection < ValidationResult > validationErrors = reportingTaskNode . getValidationErrors ( ) ; if ( validationErrors != null && ! validationErrors . isEmpty ( ) ) { final List < String > errors = new ArrayList < > ( ) ; for ( final ValidationResult validationResult : validationErrors ) { errors . add ( validationResult . toString ( ) ) ; } dto . setValidationErrors ( errors ) ; } return dto ; } public ControllerServiceDTO createControllerServiceDto ( final ControllerServiceNode controllerServiceNode ) { final BundleCoordinate bundleCoordinate = controllerServiceNode . getBundleCoordinate ( ) ; final List < Bundle > compatibleBundles = extensionManager . getBundles ( controllerServiceNode . getCanonicalClassName ( ) ) . stream ( ) . filter ( bundle -> { final BundleCoordinate coordinate = bundle . getBundleDetails ( ) . getCoordinate ( ) ; return bundleCoordinate . getGroup ( ) . equals ( coordinate . getGroup ( ) ) && bundleCoordinate . getId ( ) . equals ( coordinate . getId ( ) ) ; } ) . collect ( Collectors . toList ( ) ) ; final ControllerServiceDTO dto = new ControllerServiceDTO ( ) ; dto . setId ( controllerServiceNode . getIdentifier ( ) ) ; dto . setParentGroupId ( controllerServiceNode . getProcessGroup ( ) == null ? null : controllerServiceNode . getProcessGroup ( ) . getIdentifier ( ) ) ; dto . setName ( controllerServiceNode . getName ( ) ) ; dto . setType ( controllerServiceNode . getCanonicalClassName ( ) ) ; dto . setBundle ( createBundleDto ( bundleCoordinate ) ) ; dto . setControllerServiceApis ( createControllerServiceApiDto ( controllerServiceNode . getControllerServiceImplementation ( ) . getClass ( ) ) ) ; dto . setState ( controllerServiceNode . getState ( ) . name ( ) ) ; dto . setAnnotationData ( controllerServiceNode . getAnnotationData ( ) ) ; dto . setComments ( controllerServiceNode . getComments ( ) ) ; dto . setPersistsState ( controllerServiceNode . getControllerServiceImplementation ( ) . getClass ( ) . isAnnotationPresent ( Stateful . class ) ) ; dto . setRestricted ( controllerServiceNode . isRestricted ( ) ) ; dto . setDeprecated ( controllerServiceNode . isDeprecated ( ) ) ; dto . setExtensionMissing ( controllerServiceNode . isExtensionMissing ( ) ) ; dto . setMultipleVersionsAvailable ( compatibleBundles . size ( ) > 1 ) ; dto . setVersionedComponentId ( controllerServiceNode . getVersionedComponentId ( ) . orElse ( null ) ) ; final Map < PropertyDescriptor , String > sortedProperties = new TreeMap < > ( new Comparator < PropertyDescriptor > ( ) { @ Override public int compare ( final PropertyDescriptor o1 , final PropertyDescriptor o2 ) { return Collator . getInstance ( Locale . US ) . compare ( o1 . getName ( ) , o2 . getName ( ) ) ; } } ) ; sortedProperties . putAll ( controllerServiceNode . getProperties ( ) ) ; final ControllerService controllerService = controllerServiceNode . getControllerServiceImplementation ( ) ; final Map < PropertyDescriptor , String > orderedProperties = new LinkedHashMap < > ( ) ; final List < PropertyDescriptor > descriptors = controllerService . getPropertyDescriptors ( ) ; if ( descriptors != null && ! descriptors . isEmpty ( ) ) { for ( final PropertyDescriptor descriptor : descriptors ) { orderedProperties . put ( descriptor , null ) ; } } orderedProperties . putAll ( sortedProperties ) ; dto . setDescriptors ( new LinkedHashMap < String , PropertyDescriptorDTO > ( ) ) ; dto . setProperties ( new LinkedHashMap < String , String > ( ) ) ; for ( final Map . Entry < PropertyDescriptor , String > entry : orderedProperties . entrySet ( ) ) { final PropertyDescriptor descriptor = entry . getKey ( ) ; final String groupId = controllerServiceNode . getProcessGroup ( ) == null ? null : controllerServiceNode . getProcessGroup ( ) . getIdentifier ( ) ; dto . getDescriptors ( ) . put ( descriptor . getName ( ) , createPropertyDescriptorDto ( descriptor , groupId ) ) ; String propertyValue = entry . getValue ( ) ; if ( propertyValue != null && descriptor . isSensitive ( ) ) { propertyValue = SENSITIVE_VALUE_MASK ; } dto . getProperties ( ) . put ( descriptor . getName ( ) , propertyValue ) ; } dto . setValidationStatus ( controllerServiceNode . getValidationStatus ( 1 , TimeUnit . MILLISECONDS ) . name ( ) ) ; final Collection < ValidationResult > validationErrors = controllerServiceNode . getValidationErrors ( ) ; if ( validationErrors != null && ! validationErrors . isEmpty ( ) ) { final List < String > errors = new ArrayList < > ( ) ; for ( final ValidationResult validationResult : validationErrors ) { errors . add ( validationResult . toString ( ) ) ; } dto . setValidationErrors ( errors ) ; } return dto ; } public ControllerServiceReferencingComponentDTO createControllerServiceReferencingComponentDTO ( final ComponentNode component ) { final ControllerServiceReferencingComponentDTO dto = new ControllerServiceReferencingComponentDTO ( ) ; dto . setId ( component . getIdentifier ( ) ) ; dto . setName ( component . getName ( ) ) ; String processGroupId = null ; List < PropertyDescriptor > propertyDescriptors = null ; Collection < ValidationResult > validationErrors = null ; if ( component instanceof ProcessorNode ) { final ProcessorNode node = ( ( ProcessorNode ) component ) ; dto . setGroupId ( node . getProcessGroup ( ) . getIdentifier ( ) ) ; dto . setState ( node . getScheduledState ( ) . name ( ) ) ; dto . setActiveThreadCount ( node . getActiveThreadCount ( ) ) ; dto . setType ( node . getComponentType ( ) ) ; dto . setReferenceType ( Processor . class . getSimpleName ( ) ) ; propertyDescriptors = node . getProcessor ( ) . getPropertyDescriptors ( ) ; validationErrors = node . getValidationErrors ( ) ; processGroupId = node . getProcessGroup ( ) . getIdentifier ( ) ; } else if ( component instanceof ControllerServiceNode ) { final ControllerServiceNode node = ( ( ControllerServiceNode ) component ) ; dto . setState ( node . getState ( ) . name ( ) ) ; dto . setType ( node . getComponentType ( ) ) ; dto . setReferenceType ( ControllerService . class . getSimpleName ( ) ) ; propertyDescriptors = node . getControllerServiceImplementation ( ) . getPropertyDescriptors ( ) ; validationErrors = node . getValidationErrors ( ) ; processGroupId = node . getProcessGroup ( ) == null ? null : node . getProcessGroup ( ) . getIdentifier ( ) ; } else if ( component instanceof ReportingTaskNode ) { final ReportingTaskNode node = ( ( ReportingTaskNode ) component ) ; dto . setState ( node . getScheduledState ( ) . name ( ) ) ; dto . setActiveThreadCount ( node . getActiveThreadCount ( ) ) ; dto . setType ( node . getComponentType ( ) ) ; dto . setReferenceType ( ReportingTask . class . getSimpleName ( ) ) ; propertyDescriptors = node . getReportingTask ( ) . getPropertyDescriptors ( ) ; validationErrors = node . getValidationErrors ( ) ; processGroupId = null ; } if ( propertyDescriptors == null ) { propertyDescriptors = new ArrayList < > ( ) ; } final Map < PropertyDescriptor , String > sortedProperties = new TreeMap < > ( new Comparator < PropertyDescriptor > ( ) { @ Override public int compare ( final PropertyDescriptor o1 , final PropertyDescriptor o2 ) { return Collator . getInstance ( Locale . US ) . compare ( o1 . getName ( ) , o2 . getName ( ) ) ; } } ) ; sortedProperties . putAll ( component . getProperties ( ) ) ; final Map < PropertyDescriptor , String > orderedProperties = new LinkedHashMap < > ( ) ; for ( final PropertyDescriptor descriptor : propertyDescriptors ) { orderedProperties . put ( descriptor , null ) ; } orderedProperties . putAll ( sortedProperties ) ; dto . setDescriptors ( new LinkedHashMap < String , PropertyDescriptorDTO > ( ) ) ; dto . setProperties ( new LinkedHashMap < String , String > ( ) ) ; for ( final Map . Entry < PropertyDescriptor , String > entry : orderedProperties . entrySet ( ) ) { final PropertyDescriptor descriptor = entry . getKey ( ) ; dto . getDescriptors ( ) . put ( descriptor . getName ( ) , createPropertyDescriptorDto ( descriptor , processGroupId ) ) ; String propertyValue = entry . getValue ( ) ; if ( propertyValue != null && descriptor . isSensitive ( ) ) { propertyValue = SENSITIVE_VALUE_MASK ; } dto . getProperties ( ) . put ( descriptor . getName ( ) , propertyValue ) ; } if ( validationErrors != null && ! validationErrors . isEmpty ( ) ) { final List < String > errors = new ArrayList < > ( ) ; for ( final ValidationResult validationResult : validationErrors ) { errors . add ( validationResult . toString ( ) ) ; } dto . setValidationErrors ( errors ) ; } return dto ; } public RemoteProcessGroupPortDTO createRemoteProcessGroupPortDto ( final RemoteGroupPort port ) { if ( port == null ) { return null ; } final RemoteProcessGroupPortDTO dto = new RemoteProcessGroupPortDTO ( ) ; dto . setId ( port . getIdentifier ( ) ) ; dto . setGroupId ( port . getRemoteProcessGroup ( ) . getIdentifier ( ) ) ; dto . setTargetId ( port . getTargetIdentifier ( ) ) ; dto . setName ( port . getName ( ) ) ; dto . setComments ( port . getComments ( ) ) ; dto . setTransmitting ( port . isRunning ( ) ) ; dto . setTargetRunning ( port . isTargetRunning ( ) ) ; dto . setConcurrentlySchedulableTaskCount ( port . getMaxConcurrentTasks ( ) ) ; dto . setUseCompression ( port . isUseCompression ( ) ) ; dto . setExists ( port . getTargetExists ( ) ) ; dto . setVersionedComponentId ( port . getVersionedComponentId ( ) . orElse ( null ) ) ; final BatchSettingsDTO batchDTO = new BatchSettingsDTO ( ) ; batchDTO . setCount ( port . getBatchCount ( ) ) ; batchDTO . setSize ( port . getBatchSize ( ) ) ; batchDTO . setDuration ( port . getBatchDuration ( ) ) ; dto . setBatchSettings ( batchDTO ) ; if ( ConnectableType . REMOTE_OUTPUT_PORT . equals ( port . getConnectableType ( ) ) ) { dto . setConnected ( ! port . getConnections ( ) . isEmpty ( ) ) ; } else { dto . setConnected ( port . hasIncomingConnection ( ) ) ; } return dto ; } public RemoteProcessGroupDTO createRemoteProcessGroupDto ( final RemoteProcessGroup group ) { if ( group == null ) { return null ; } final Set < RemoteProcessGroupPortDTO > inputPorts = new HashSet < > ( ) ; final Set < RemoteProcessGroupPortDTO > outputPorts = new HashSet < > ( ) ; int activeRemoteInputPortCount = 0 ; int inactiveRemoteInputPortCount = 0 ; for ( final Port port : group . getInputPorts ( ) ) { inputPorts . add ( createRemoteProcessGroupPortDto ( ( RemoteGroupPort ) port ) ) ; if ( port . hasIncomingConnection ( ) ) { if ( port . isRunning ( ) ) { activeRemoteInputPortCount ++ ; } else { inactiveRemoteInputPortCount ++ ; } } } int activeRemoteOutputPortCount = 0 ; int inactiveRemoteOutputPortCount = 0 ; for ( final Port port : group . getOutputPorts ( ) ) { outputPorts . add ( createRemoteProcessGroupPortDto ( ( RemoteGroupPort ) port ) ) ; if ( ! port . getConnections ( ) . isEmpty ( ) ) { if ( port . isRunning ( ) ) { activeRemoteOutputPortCount ++ ; } else { inactiveRemoteOutputPortCount ++ ; } } } final RemoteProcessGroupContentsDTO contents = new RemoteProcessGroupContentsDTO ( ) ; contents . setInputPorts ( inputPorts ) ; contents . setOutputPorts ( outputPorts ) ; final RemoteProcessGroupDTO dto = new RemoteProcessGroupDTO ( ) ; dto . setId ( group . getIdentifier ( ) ) ; dto . setName ( group . getName ( ) ) ; dto . setPosition ( createPositionDto ( group . getPosition ( ) ) ) ; dto . setComments ( group . getComments ( ) ) ; dto . setTransmitting ( group . isTransmitting ( ) ) ; dto . setCommunicationsTimeout ( group . getCommunicationsTimeout ( ) ) ; dto . setYieldDuration ( group . getYieldDuration ( ) ) ; dto . setParentGroupId ( group . getProcessGroup ( ) . getIdentifier ( ) ) ; dto . setTargetUris ( group . getTargetUris ( ) ) ; dto . setFlowRefreshed ( group . getLastRefreshTime ( ) ) ; dto . setContents ( contents ) ; dto . setTransportProtocol ( group . getTransportProtocol ( ) . name ( ) ) ; dto . setProxyHost ( group . getProxyHost ( ) ) ; dto . setProxyPort ( group . getProxyPort ( ) ) ; dto . setProxyUser ( group . getProxyUser ( ) ) ; if ( ! StringUtils . isEmpty ( group . getProxyPassword ( ) ) ) { dto . setProxyPassword ( SENSITIVE_VALUE_MASK ) ; } if ( group . isSiteToSiteEnabled ( ) ) { dto . setTargetSecure ( group . getSecureFlag ( ) ) ; } if ( group . getAuthorizationIssue ( ) != null ) { dto . setAuthorizationIssues ( Arrays . asList ( group . getAuthorizationIssue ( ) ) ) ; } final Collection < ValidationResult > validationErrors = group . validate ( ) ; if ( validationErrors != null && ! validationErrors . isEmpty ( ) ) { final List < String > errors = new ArrayList < > ( ) ; for ( final ValidationResult validationResult : validationErrors ) { errors . add ( validationResult . toString ( ) ) ; } dto . setValidationErrors ( errors ) ; } dto . setLocalNetworkInterface ( group . getNetworkInterface ( ) ) ; dto . setActiveRemoteInputPortCount ( activeRemoteInputPortCount ) ; dto . setInactiveRemoteInputPortCount ( inactiveRemoteInputPortCount ) ; dto . setActiveRemoteOutputPortCount ( activeRemoteOutputPortCount ) ; dto . setInactiveRemoteOutputPortCount ( inactiveRemoteOutputPortCount ) ; dto . setVersionedComponentId ( group . getVersionedComponentId ( ) . orElse ( null ) ) ; final RemoteProcessGroupCounts counts = group . getCounts ( ) ; if ( counts != null ) { dto . setInputPortCount ( counts . getInputPortCount ( ) ) ; dto . setOutputPortCount ( counts . getOutputPortCount ( ) ) ; } return dto ; } private FlowBreadcrumbEntity createBreadcrumbEntity ( final ProcessGroup group ) { if ( group == null ) { return null ; } final FlowBreadcrumbDTO dto = createBreadcrumbDto ( group ) ; final PermissionsDTO permissions = createPermissionsDto ( group ) ; final FlowBreadcrumbEntity entity = entityFactory . createFlowBreadcrumbEntity ( dto , permissions ) ; if ( group . getParent ( ) != null ) { entity . setParentBreadcrumb ( createBreadcrumbEntity ( group . getParent ( ) ) ) ; } return entity ; } private FlowBreadcrumbDTO createBreadcrumbDto ( final ProcessGroup group ) { if ( group == null ) { return null ; } final FlowBreadcrumbDTO dto = new FlowBreadcrumbDTO ( ) ; dto . setId ( group . getIdentifier ( ) ) ; dto . setName ( group . getName ( ) ) ; final VersionControlInformationDTO versionControlInformation = createVersionControlInformationDto ( group ) ; dto . setVersionControlInformation ( versionControlInformation ) ; return dto ; } public ComponentReferenceDTO createComponentReferenceDto ( final Authorizable authorizable ) { if ( authorizable == null || ! ( authorizable instanceof ComponentAuthorizable ) ) { return null ; } final ComponentAuthorizable componentAuthorizable = ( ComponentAuthorizable ) authorizable ; final ComponentReferenceDTO dto = new ComponentReferenceDTO ( ) ; dto . setId ( componentAuthorizable . getIdentifier ( ) ) ; dto . setParentGroupId ( componentAuthorizable . getProcessGroupIdentifier ( ) ) ; dto . setName ( authorizable . getResource ( ) . getName ( ) ) ; return dto ; } public AccessPolicySummaryDTO createAccessPolicySummaryDto ( final AccessPolicy accessPolicy , final ComponentReferenceEntity componentReference ) { if ( accessPolicy == null ) { return null ; } final AccessPolicySummaryDTO dto = new AccessPolicySummaryDTO ( ) ; dto . setId ( accessPolicy . getIdentifier ( ) ) ; dto . setResource ( accessPolicy . getResource ( ) ) ; dto . setAction ( accessPolicy . getAction ( ) . toString ( ) ) ; dto . setConfigurable ( AuthorizerCapabilityDetection . isAccessPolicyConfigurable ( authorizer , accessPolicy ) ) ; dto . setComponentReference ( componentReference ) ; return dto ; } public AccessPolicyDTO createAccessPolicyDto ( final AccessPolicy accessPolicy , final Set < TenantEntity > userGroups , final Set < TenantEntity > users , final ComponentReferenceEntity componentReference ) { if ( accessPolicy == null ) { return null ; } final AccessPolicyDTO dto = new AccessPolicyDTO ( ) ; dto . setUserGroups ( userGroups ) ; dto . setUsers ( users ) ; dto . setId ( accessPolicy . getIdentifier ( ) ) ; dto . setResource ( accessPolicy . getResource ( ) ) ; dto . setAction ( accessPolicy . getAction ( ) . toString ( ) ) ; dto . setConfigurable ( AuthorizerCapabilityDetection . isAccessPolicyConfigurable ( authorizer , accessPolicy ) ) ; dto . setComponentReference ( componentReference ) ; return dto ; } public PermissionsDTO createPermissionsDto ( final Authorizable authorizable ) { return createPermissionsDto ( authorizable , NiFiUserUtils . getNiFiUser ( ) ) ; } public PermissionsDTO createPermissionsDto ( final Authorizable authorizable , final NiFiUser user ) { final PermissionsDTO dto = new PermissionsDTO ( ) ; dto . setCanRead ( authorizable . isAuthorized ( authorizer , RequestAction . READ , user ) ) ; dto . setCanWrite ( authorizable . isAuthorized ( authorizer , RequestAction . WRITE , user ) ) ; return dto ; } public AffectedComponentEntity createAffectedComponentEntity ( final ProcessorEntity processorEntity ) { if ( processorEntity == null ) { return null ; } final AffectedComponentEntity component = new AffectedComponentEntity ( ) ; component . setBulletins ( processorEntity . getBulletins ( ) ) ; component . setId ( processorEntity . getId ( ) ) ; component . setPermissions ( processorEntity . getPermissions ( ) ) ; component . setPosition ( processorEntity . getPosition ( ) ) ; component . setRevision ( processorEntity . getRevision ( ) ) ; component . setUri ( processorEntity . getUri ( ) ) ; final ProcessorDTO processorDto = processorEntity . getComponent ( ) ; final AffectedComponentDTO componentDto = new AffectedComponentDTO ( ) ; componentDto . setId ( processorDto . getId ( ) ) ; componentDto . setName ( processorDto . getName ( ) ) ; componentDto . setProcessGroupId ( processorDto . getParentGroupId ( ) ) ; componentDto . setReferenceType ( AffectedComponentDTO . COMPONENT_TYPE_PROCESSOR ) ; componentDto . setState ( processorDto . getState ( ) ) ; componentDto . setValidationErrors ( processorDto . getValidationErrors ( ) ) ; component . setComponent ( componentDto ) ; return component ; } public AffectedComponentEntity createAffectedComponentEntity ( final PortEntity portEntity , final String referenceType ) { if ( portEntity == null ) { return null ; } final AffectedComponentEntity component = new AffectedComponentEntity ( ) ; component . setBulletins ( portEntity . getBulletins ( ) ) ; component . setId ( portEntity . getId ( ) ) ; component . setPermissions ( portEntity . getPermissions ( ) ) ; component . setPosition ( portEntity . getPosition ( ) ) ; component . setRevision ( portEntity . getRevision ( ) ) ; component . setUri ( portEntity . getUri ( ) ) ; final PortDTO portDto = portEntity . getComponent ( ) ; final AffectedComponentDTO componentDto = new AffectedComponentDTO ( ) ; componentDto . setId ( portDto . getId ( ) ) ; componentDto . setName ( portDto . getName ( ) ) ; componentDto . setProcessGroupId ( portDto . getParentGroupId ( ) ) ; componentDto . setReferenceType ( referenceType ) ; componentDto . setState ( portDto . getState ( ) ) ; componentDto . setValidationErrors ( portDto . getValidationErrors ( ) ) ; component . setComponent ( componentDto ) ; return component ; } public AffectedComponentEntity createAffectedComponentEntity ( final ControllerServiceEntity serviceEntity ) { if ( serviceEntity == null ) { return null ; } final AffectedComponentEntity component = new AffectedComponentEntity ( ) ; component . setBulletins ( serviceEntity . getBulletins ( ) ) ; component . setId ( serviceEntity . getId ( ) ) ; component . setPermissions ( serviceEntity . getPermissions ( ) ) ; component . setPosition ( serviceEntity . getPosition ( ) ) ; component . setRevision ( serviceEntity . getRevision ( ) ) ; component . setUri ( serviceEntity . getUri ( ) ) ; final ControllerServiceDTO serviceDto = serviceEntity . getComponent ( ) ; final AffectedComponentDTO componentDto = new AffectedComponentDTO ( ) ; componentDto . setId ( serviceDto . getId ( ) ) ; componentDto . setName ( serviceDto . getName ( ) ) ; componentDto . setProcessGroupId ( serviceDto . getParentGroupId ( ) ) ; componentDto . setReferenceType ( AffectedComponentDTO . COMPONENT_TYPE_CONTROLLER_SERVICE ) ; componentDto . setState ( serviceDto . getState ( ) ) ; componentDto . setValidationErrors ( serviceDto . getValidationErrors ( ) ) ; component . setComponent ( componentDto ) ; return component ; } public AffectedComponentEntity createAffectedComponentEntity ( final RemoteProcessGroupPortDTO remotePortDto , final String referenceType , final RemoteProcessGroupEntity rpgEntity ) { if ( remotePortDto == null ) { return null ; } final AffectedComponentEntity component = new AffectedComponentEntity ( ) ; component . setId ( remotePortDto . getId ( ) ) ; component . setPermissions ( rpgEntity . getPermissions ( ) ) ; component . setRevision ( rpgEntity . getRevision ( ) ) ; component . setUri ( rpgEntity . getUri ( ) ) ; final AffectedComponentDTO componentDto = new AffectedComponentDTO ( ) ; componentDto . setId ( remotePortDto . getId ( ) ) ; componentDto . setName ( remotePortDto . getName ( ) ) ; componentDto . setProcessGroupId ( remotePortDto . getGroupId ( ) ) ; componentDto . setReferenceType ( referenceType ) ; componentDto . setState ( remotePortDto . isTransmitting ( ) ? ""Running"" : ""Stopped"" ) ; component . setComponent ( componentDto ) ; return component ; } public AffectedComponentDTO createAffectedComponentDto ( final ComponentNode component ) { final AffectedComponentDTO dto = new AffectedComponentDTO ( ) ; dto . setId ( component . getIdentifier ( ) ) ; dto . setName ( component . getName ( ) ) ; dto . setProcessGroupId ( component . getProcessGroupIdentifier ( ) ) ; if ( component instanceof ProcessorNode ) { final ProcessorNode node = ( ( ProcessorNode ) component ) ; dto . setState ( node . getScheduledState ( ) . name ( ) ) ; dto . setActiveThreadCount ( node . getActiveThreadCount ( ) ) ; dto . setReferenceType ( AffectedComponentDTO . COMPONENT_TYPE_PROCESSOR ) ; } else if ( component instanceof ControllerServiceNode ) { final ControllerServiceNode node = ( ( ControllerServiceNode ) component ) ; dto . setState ( node . getState ( ) . name ( ) ) ; dto . setReferenceType ( AffectedComponentDTO . COMPONENT_TYPE_CONTROLLER_SERVICE ) ; } final Collection < ValidationResult > validationErrors = component . getValidationErrors ( ) ; if ( validationErrors != null && ! validationErrors . isEmpty ( ) ) { final List < String > errors = new ArrayList < > ( ) ; for ( final ValidationResult validationResult : validationErrors ) { errors . add ( validationResult . toString ( ) ) ; } dto . setValidationErrors ( errors ) ; } return dto ; } public ProcessGroupDTO createProcessGroupDto ( final ProcessGroup group ) { return createProcessGroupDto ( group , false ) ; } public ProcessGroupFlowDTO createProcessGroupFlowDto ( final ProcessGroup group , final ProcessGroupStatus groupStatus , final RevisionManager revisionManager , final Function < ProcessGroup , List < BulletinEntity > > getProcessGroupBulletins ) { final ProcessGroupFlowDTO dto = new ProcessGroupFlowDTO ( ) ; dto . setId ( group . getIdentifier ( ) ) ; dto . setLastRefreshed ( new Date ( ) ) ; dto . setBreadcrumb ( createBreadcrumbEntity ( group ) ) ; dto . setFlow ( createFlowDto ( group , groupStatus , revisionManager , getProcessGroupBulletins ) ) ; final ProcessGroup parent = group . getParent ( ) ; if ( parent != null ) { dto . setParentGroupId ( parent . getIdentifier ( ) ) ; } return dto ; } public FlowDTO createFlowDto ( final ProcessGroup group , final ProcessGroupStatus groupStatus , final FlowSnippetDTO snippet , final RevisionManager revisionManager , final Function < ProcessGroup , List < BulletinEntity > > getProcessGroupBulletins ) { if ( snippet == null ) { return null ; } final FlowDTO flow = new FlowDTO ( ) ; for ( final ConnectionDTO snippetConnection : snippet . getConnections ( ) ) { final Connection connection = group . getConnection ( snippetConnection . getId ( ) ) ; final ConnectionDTO dto = createConnectionDto ( connection ) ; final RevisionDTO revision = createRevisionDTO ( revisionManager . getRevision ( connection . getIdentifier ( ) ) ) ; final PermissionsDTO accessPolicy = createPermissionsDto ( connection ) ; final ConnectionStatusDTO status = getComponentStatus ( ( ) -> groupStatus . getConnectionStatus ( ) . stream ( ) . filter ( connectionStatus -> connection . getIdentifier ( ) . equals ( connectionStatus . getId ( ) ) ) . findFirst ( ) . orElse ( null ) , connectionStatus -> createConnectionStatusDto ( connectionStatus ) ) ; flow . getConnections ( ) . add ( entityFactory . createConnectionEntity ( dto , revision , accessPolicy , status ) ) ; } for ( final FunnelDTO snippetFunnel : snippet . getFunnels ( ) ) { final Funnel funnel = group . getFunnel ( snippetFunnel . getId ( ) ) ; final FunnelDTO dto = createFunnelDto ( funnel ) ; final RevisionDTO revision = createRevisionDTO ( revisionManager . getRevision ( funnel . getIdentifier ( ) ) ) ; final PermissionsDTO accessPolicy = createPermissionsDto ( funnel ) ; flow . getFunnels ( ) . add ( entityFactory . createFunnelEntity ( dto , revision , accessPolicy ) ) ; } for ( final PortDTO snippetInputPort : snippet . getInputPorts ( ) ) { final Port inputPort = group . getInputPort ( snippetInputPort . getId ( ) ) ; final PortDTO dto = createPortDto ( inputPort ) ; final RevisionDTO revision = createRevisionDTO ( revisionManager . getRevision ( inputPort . getIdentifier ( ) ) ) ; final PermissionsDTO permissions = createPermissionsDto ( inputPort ) ; final PermissionsDTO operatePermissions = createPermissionsDto ( new OperationAuthorizable ( inputPort ) ) ; final PortStatusDTO status = getComponentStatus ( ( ) -> groupStatus . getInputPortStatus ( ) . stream ( ) . filter ( inputPortStatus -> inputPort . getIdentifier ( ) . equals ( inputPortStatus . getId ( ) ) ) . findFirst ( ) . orElse ( null ) , inputPortStatus -> createPortStatusDto ( inputPortStatus ) ) ; final List < BulletinDTO > bulletins = createBulletinDtos ( bulletinRepository . findBulletinsForSource ( inputPort . getIdentifier ( ) ) ) ; final List < BulletinEntity > bulletinEntities = bulletins . stream ( ) . map ( bulletin -> entityFactory . createBulletinEntity ( bulletin , permissions . getCanRead ( ) ) ) . collect ( Collectors . toList ( ) ) ; flow . getInputPorts ( ) . add ( entityFactory . createPortEntity ( dto , revision , permissions , operatePermissions , status , bulletinEntities ) ) ; } for ( final PortDTO snippetOutputPort : snippet . getOutputPorts ( ) ) { final Port outputPort = group . getOutputPort ( snippetOutputPort . getId ( ) ) ; final PortDTO dto = createPortDto ( outputPort ) ; final RevisionDTO revision = createRevisionDTO ( revisionManager . getRevision ( outputPort . getIdentifier ( ) ) ) ; final PermissionsDTO permissions = createPermissionsDto ( outputPort ) ; final PermissionsDTO operatePermissions = createPermissionsDto ( new OperationAuthorizable ( outputPort ) ) ; final PortStatusDTO status = getComponentStatus ( ( ) -> groupStatus . getOutputPortStatus ( ) . stream ( ) . filter ( outputPortStatus -> outputPort . getIdentifier ( ) . equals ( outputPortStatus . getId ( ) ) ) . findFirst ( ) . orElse ( null ) , outputPortStatus -> createPortStatusDto ( outputPortStatus ) ) ; final List < BulletinDTO > bulletins = createBulletinDtos ( bulletinRepository . findBulletinsForSource ( outputPort . getIdentifier ( ) ) ) ; final List < BulletinEntity > bulletinEntities = bulletins . stream ( ) . map ( bulletin -> entityFactory . createBulletinEntity ( bulletin , permissions . getCanRead ( ) ) ) . collect ( Collectors . toList ( ) ) ; flow . getOutputPorts ( ) . add ( entityFactory . createPortEntity ( dto , revision , permissions , operatePermissions , status , bulletinEntities ) ) ; } for ( final LabelDTO snippetLabel : snippet . getLabels ( ) ) { final Label label = group . getLabel ( snippetLabel . getId ( ) ) ; final LabelDTO dto = createLabelDto ( label ) ; final RevisionDTO revision = createRevisionDTO ( revisionManager . getRevision ( label . getIdentifier ( ) ) ) ; final PermissionsDTO accessPolicy = createPermissionsDto ( label ) ; flow . getLabels ( ) . add ( entityFactory . createLabelEntity ( dto , revision , accessPolicy ) ) ; } for ( final ProcessGroupDTO snippetProcessGroup : snippet . getProcessGroups ( ) ) { final ProcessGroup processGroup = group . getProcessGroup ( snippetProcessGroup . getId ( ) ) ; final ProcessGroupDTO dto = createProcessGroupDto ( processGroup ) ; final RevisionDTO revision = createRevisionDTO ( revisionManager . getRevision ( processGroup . getIdentifier ( ) ) ) ; final PermissionsDTO permissions = createPermissionsDto ( processGroup ) ; final ProcessGroupStatusDTO status = getComponentStatus ( ( ) -> groupStatus . getProcessGroupStatus ( ) . stream ( ) . filter ( processGroupStatus -> processGroup . getIdentifier ( ) . equals ( processGroupStatus . getId ( ) ) ) . findFirst ( ) . orElse ( null ) , processGroupStatus -> createConciseProcessGroupStatusDto ( processGroupStatus ) ) ; final List < BulletinEntity > bulletins = getProcessGroupBulletins . apply ( processGroup ) ; flow . getProcessGroups ( ) . add ( entityFactory . createProcessGroupEntity ( dto , revision , permissions , status , bulletins ) ) ; } for ( final ProcessorDTO snippetProcessor : snippet . getProcessors ( ) ) { final ProcessorNode processor = group . getProcessor ( snippetProcessor . getId ( ) ) ; final ProcessorDTO dto = createProcessorDto ( processor ) ; final RevisionDTO revision = createRevisionDTO ( revisionManager . getRevision ( processor . getIdentifier ( ) ) ) ; final PermissionsDTO permissions = createPermissionsDto ( processor ) ; final PermissionsDTO operatePermissions = createPermissionsDto ( new OperationAuthorizable ( processor ) ) ; final ProcessorStatusDTO status = getComponentStatus ( ( ) -> groupStatus . getProcessorStatus ( ) . stream ( ) . filter ( processorStatus -> processor . getIdentifier ( ) . equals ( processorStatus . getId ( ) ) ) . findFirst ( ) . orElse ( null ) , processorStatus -> createProcessorStatusDto ( processorStatus ) ) ; final List < BulletinDTO > bulletins = createBulletinDtos ( bulletinRepository . findBulletinsForSource ( processor . getIdentifier ( ) ) ) ; final List < BulletinEntity > bulletinEntities = bulletins . stream ( ) . map ( bulletin -> entityFactory . createBulletinEntity ( bulletin , permissions . getCanRead ( ) ) ) . collect ( Collectors . toList ( ) ) ; flow . getProcessors ( ) . add ( entityFactory . createProcessorEntity ( dto , revision , permissions , operatePermissions , status , bulletinEntities ) ) ; } for ( final RemoteProcessGroupDTO snippetRemoteProcessGroup : snippet . getRemoteProcessGroups ( ) ) { final RemoteProcessGroup remoteProcessGroup = group . getRemoteProcessGroup ( snippetRemoteProcessGroup . getId ( ) ) ; final RemoteProcessGroupDTO dto = createRemoteProcessGroupDto ( remoteProcessGroup ) ; final RevisionDTO revision = createRevisionDTO ( revisionManager . getRevision ( remoteProcessGroup . getIdentifier ( ) ) ) ; final PermissionsDTO permissions = createPermissionsDto ( remoteProcessGroup ) ; final PermissionsDTO operatePermissions = createPermissionsDto ( new OperationAuthorizable ( remoteProcessGroup ) ) ; final RemoteProcessGroupStatusDTO status = getComponentStatus ( ( ) -> groupStatus . getRemoteProcessGroupStatus ( ) . stream ( ) . filter ( rpgStatus -> remoteProcessGroup . getIdentifier ( ) . equals ( rpgStatus . getId ( ) ) ) . findFirst ( ) . orElse ( null ) , remoteProcessGroupStatus -> createRemoteProcessGroupStatusDto ( remoteProcessGroup , remoteProcessGroupStatus ) ) ; final List < BulletinDTO > bulletins = createBulletinDtos ( bulletinRepository . findBulletinsForSource ( remoteProcessGroup . getIdentifier ( ) ) ) ; final List < BulletinEntity > bulletinEntities = bulletins . stream ( ) . map ( bulletin -> entityFactory . createBulletinEntity ( bulletin , permissions . getCanRead ( ) ) ) . collect ( Collectors . toList ( ) ) ; flow . getRemoteProcessGroups ( ) . add ( entityFactory . createRemoteProcessGroupEntity ( dto , revision , permissions , operatePermissions , status , bulletinEntities ) ) ; } return flow ; } private < T , S > T getComponentStatus ( final Supplier < S > getComponentStatus , final Function < S , T > convertToDto ) { final T statusDTO ; final S status = getComponentStatus . get ( ) ; if ( status != null ) { statusDTO = convertToDto . apply ( status ) ; } else { statusDTO = null ; } return statusDTO ; } public FlowDTO createFlowDto ( final ProcessGroup group , final ProcessGroupStatus groupStatus , final RevisionManager revisionManager , final Function < ProcessGroup , List < BulletinEntity > > getProcessGroupBulletins ) { final FlowDTO dto = new FlowDTO ( ) ; for ( final ProcessorNode procNode : group . getProcessors ( ) ) { final RevisionDTO revision = createRevisionDTO ( revisionManager . getRevision ( procNode . getIdentifier ( ) ) ) ; final PermissionsDTO permissions = createPermissionsDto ( procNode ) ; final PermissionsDTO operatePermissions = createPermissionsDto ( new OperationAuthorizable ( procNode ) ) ; final ProcessorStatusDTO status = getComponentStatus ( ( ) -> groupStatus . getProcessorStatus ( ) . stream ( ) . filter ( processorStatus -> procNode . getIdentifier ( ) . equals ( processorStatus . getId ( ) ) ) . findFirst ( ) . orElse ( null ) , processorStatus -> createProcessorStatusDto ( processorStatus ) ) ; final List < BulletinDTO > bulletins = createBulletinDtos ( bulletinRepository . findBulletinsForSource ( procNode . getIdentifier ( ) ) ) ; final List < BulletinEntity > bulletinEntities = bulletins . stream ( ) . map ( bulletin -> entityFactory . createBulletinEntity ( bulletin , permissions . getCanRead ( ) ) ) . collect ( Collectors . toList ( ) ) ; dto . getProcessors ( ) . add ( entityFactory . createProcessorEntity ( createProcessorDto ( procNode ) , revision , permissions , operatePermissions , status , bulletinEntities ) ) ; } for ( final Connection connNode : group . getConnections ( ) ) { final RevisionDTO revision = createRevisionDTO ( revisionManager . getRevision ( connNode . getIdentifier ( ) ) ) ; final PermissionsDTO permissions = createPermissionsDto ( connNode ) ; final ConnectionStatusDTO status = getComponentStatus ( ( ) -> groupStatus . getConnectionStatus ( ) . stream ( ) . filter ( connectionStatus -> connNode . getIdentifier ( ) . equals ( connectionStatus . getId ( ) ) ) . findFirst ( ) . orElse ( null ) , connectionStatus -> createConnectionStatusDto ( connectionStatus ) ) ; dto . getConnections ( ) . add ( entityFactory . createConnectionEntity ( createConnectionDto ( connNode ) , revision , permissions , status ) ) ; } for ( final Label label : group . getLabels ( ) ) { final RevisionDTO revision = createRevisionDTO ( revisionManager . getRevision ( label . getIdentifier ( ) ) ) ; final PermissionsDTO permissions = createPermissionsDto ( label ) ; dto . getLabels ( ) . add ( entityFactory . createLabelEntity ( createLabelDto ( label ) , revision , permissions ) ) ; } for ( final Funnel funnel : group . getFunnels ( ) ) { final RevisionDTO revision = createRevisionDTO ( revisionManager . getRevision ( funnel . getIdentifier ( ) ) ) ; final PermissionsDTO permissions = createPermissionsDto ( funnel ) ; dto . getFunnels ( ) . add ( entityFactory . createFunnelEntity ( createFunnelDto ( funnel ) , revision , permissions ) ) ; } for ( final ProcessGroup childGroup : group . getProcessGroups ( ) ) { final RevisionDTO revision = createRevisionDTO ( revisionManager . getRevision ( childGroup . getIdentifier ( ) ) ) ; final PermissionsDTO permissions = createPermissionsDto ( childGroup ) ; final ProcessGroupStatusDTO status = getComponentStatus ( ( ) -> groupStatus . getProcessGroupStatus ( ) . stream ( ) . filter ( processGroupStatus -> childGroup . getIdentifier ( ) . equals ( processGroupStatus . getId ( ) ) ) . findFirst ( ) . orElse ( null ) , processGroupStatus -> createConciseProcessGroupStatusDto ( processGroupStatus ) ) ; final List < BulletinEntity > bulletins = getProcessGroupBulletins . apply ( childGroup ) ; dto . getProcessGroups ( ) . add ( entityFactory . createProcessGroupEntity ( createProcessGroupDto ( childGroup ) , revision , permissions , status , bulletins ) ) ; } for ( final RemoteProcessGroup rpg : group . getRemoteProcessGroups ( ) ) { final RevisionDTO revision = createRevisionDTO ( revisionManager . getRevision ( rpg . getIdentifier ( ) ) ) ; final PermissionsDTO permissions = createPermissionsDto ( rpg ) ; final PermissionsDTO operatePermissions = createPermissionsDto ( new OperationAuthorizable ( rpg ) ) ; final RemoteProcessGroupStatusDTO status = getComponentStatus ( ( ) -> groupStatus . getRemoteProcessGroupStatus ( ) . stream ( ) . filter ( remoteProcessGroupStatus -> rpg . getIdentifier ( ) . equals ( remoteProcessGroupStatus . getId ( ) ) ) . findFirst ( ) . orElse ( null ) , remoteProcessGroupStatus -> createRemoteProcessGroupStatusDto ( rpg , remoteProcessGroupStatus ) ) ; final List < BulletinDTO > bulletins = createBulletinDtos ( bulletinRepository . findBulletinsForSource ( rpg . getIdentifier ( ) ) ) ; final List < BulletinEntity > bulletinEntities = bulletins . stream ( ) . map ( bulletin -> entityFactory . createBulletinEntity ( bulletin , permissions . getCanRead ( ) ) ) . collect ( Collectors . toList ( ) ) ; dto . getRemoteProcessGroups ( ) . add ( entityFactory . createRemoteProcessGroupEntity ( createRemoteProcessGroupDto ( rpg ) , revision , permissions , operatePermissions , status , bulletinEntities ) ) ; } for ( final Port inputPort : group . getInputPorts ( ) ) { final RevisionDTO revision = createRevisionDTO ( revisionManager . getRevision ( inputPort . getIdentifier ( ) ) ) ; final PermissionsDTO permissions = createPermissionsDto ( inputPort ) ; final PermissionsDTO operatePermissions = createPermissionsDto ( new OperationAuthorizable ( inputPort ) ) ; final PortStatusDTO status = getComponentStatus ( ( ) -> groupStatus . getInputPortStatus ( ) . stream ( ) . filter ( inputPortStatus -> inputPort . getIdentifier ( ) . equals ( inputPortStatus . getId ( ) ) ) . findFirst ( ) . orElse ( null ) , inputPortStatus -> createPortStatusDto ( inputPortStatus ) ) ; final List < BulletinDTO > bulletins = createBulletinDtos ( bulletinRepository . findBulletinsForSource ( inputPort . getIdentifier ( ) ) ) ; final List < BulletinEntity > bulletinEntities = bulletins . stream ( ) . map ( bulletin -> entityFactory . createBulletinEntity ( bulletin , permissions . getCanRead ( ) ) ) . collect ( Collectors . toList ( ) ) ; dto . getInputPorts ( ) . add ( entityFactory . createPortEntity ( createPortDto ( inputPort ) , revision , permissions , operatePermissions , status , bulletinEntities ) ) ; } for ( final Port outputPort : group . getOutputPorts ( ) ) { final RevisionDTO revision = createRevisionDTO ( revisionManager . getRevision ( outputPort . getIdentifier ( ) ) ) ; final PermissionsDTO permissions = createPermissionsDto ( outputPort ) ; final PermissionsDTO operatePermissions = createPermissionsDto ( new OperationAuthorizable ( outputPort ) ) ; final PortStatusDTO status = getComponentStatus ( ( ) -> groupStatus . getOutputPortStatus ( ) . stream ( ) . filter ( outputPortStatus -> outputPort . getIdentifier ( ) . equals ( outputPortStatus . getId ( ) ) ) . findFirst ( ) . orElse ( null ) , outputPortStatus -> createPortStatusDto ( outputPortStatus ) ) ; final List < BulletinDTO > bulletins = createBulletinDtos ( bulletinRepository . findBulletinsForSource ( outputPort . getIdentifier ( ) ) ) ; final List < BulletinEntity > bulletinEntities = bulletins . stream ( ) . map ( bulletin -> entityFactory . createBulletinEntity ( bulletin , permissions . getCanRead ( ) ) ) . collect ( Collectors . toList ( ) ) ; dto . getOutputPorts ( ) . add ( entityFactory . createPortEntity ( createPortDto ( outputPort ) , revision , permissions , operatePermissions , status , bulletinEntities ) ) ; } return dto ; } public ProcessGroupDTO createProcessGroupDto ( final ProcessGroup group , final boolean recurse ) { final ProcessGroupDTO dto = createConciseProcessGroupDto ( group ) ; dto . setContents ( createProcessGroupContentsDto ( group , recurse ) ) ; return dto ; } private ProcessGroupDTO createConciseProcessGroupDto ( final ProcessGroup group ) { if ( group == null ) { return null ; } final ProcessGroupDTO dto = new ProcessGroupDTO ( ) ; dto . setId ( group . getIdentifier ( ) ) ; dto . setPosition ( createPositionDto ( group . getPosition ( ) ) ) ; dto . setComments ( group . getComments ( ) ) ; dto . setName ( group . getName ( ) ) ; dto . setVersionedComponentId ( group . getVersionedComponentId ( ) . orElse ( null ) ) ; dto . setVersionControlInformation ( createVersionControlInformationDto ( group ) ) ; final Map < String , String > variables = group . getVariableRegistry ( ) . getVariableMap ( ) . entrySet ( ) . stream ( ) . collect ( Collectors . toMap ( entry -> entry . getKey ( ) . getName ( ) , entry -> entry . getValue ( ) ) ) ; dto . setVariables ( variables ) ; final ProcessGroup parentGroup = group . getParent ( ) ; if ( parentGroup != null ) { dto . setParentGroupId ( parentGroup . getIdentifier ( ) ) ; } final ProcessGroupCounts counts = group . getCounts ( ) ; dto . setRunningCount ( counts . getRunningCount ( ) ) ; dto . setStoppedCount ( counts . getStoppedCount ( ) ) ; dto . setInvalidCount ( counts . getInvalidCount ( ) ) ; dto . setDisabledCount ( counts . getDisabledCount ( ) ) ; dto . setInputPortCount ( counts . getInputPortCount ( ) ) ; dto . setOutputPortCount ( counts . getOutputPortCount ( ) ) ; dto . setActiveRemotePortCount ( counts . getActiveRemotePortCount ( ) ) ; dto . setInactiveRemotePortCount ( counts . getInactiveRemotePortCount ( ) ) ; dto . setUpToDateCount ( counts . getUpToDateCount ( ) ) ; dto . setLocallyModifiedCount ( counts . getLocallyModifiedCount ( ) ) ; dto . setStaleCount ( counts . getStaleCount ( ) ) ; dto . setLocallyModifiedAndStaleCount ( counts . getLocallyModifiedAndStaleCount ( ) ) ; dto . setSyncFailureCount ( counts . getSyncFailureCount ( ) ) ; return dto ; } public Set < ComponentDifferenceDTO > createComponentDifferenceDtos ( final FlowComparison comparison ) { final Map < ComponentDifferenceDTO , List < DifferenceDTO > > differencesByComponent = new HashMap < > ( ) ; for ( final FlowDifference difference : comparison . getDifferences ( ) ) { if ( difference . getDifferenceType ( ) == DifferenceType . BUNDLE_CHANGED ) { continue ; } if ( FlowDifferenceFilters . isAddedOrRemovedRemotePort ( difference ) ) { continue ; } if ( FlowDifferenceFilters . isIgnorableVersionedFlowCoordinateChange ( difference ) ) { continue ; } final ComponentDifferenceDTO componentDiff = createComponentDifference ( difference ) ; final List < DifferenceDTO > differences = differencesByComponent . computeIfAbsent ( componentDiff , key -> new ArrayList < > ( ) ) ; final DifferenceDTO dto = new DifferenceDTO ( ) ; dto . setDifferenceType ( difference . getDifferenceType ( ) . getDescription ( ) ) ; dto . setDifference ( difference . getDescription ( ) ) ; differences . add ( dto ) ; } for ( final Map . Entry < ComponentDifferenceDTO , List < DifferenceDTO > > entry : differencesByComponent . entrySet ( ) ) { entry . getKey ( ) . setDifferences ( entry . getValue ( ) ) ; } return differencesByComponent . keySet ( ) ; } private ComponentDifferenceDTO createComponentDifference ( final FlowDifference difference ) { VersionedComponent component = difference . getComponentA ( ) ; if ( component == null || difference . getComponentB ( ) instanceof InstantiatedVersionedComponent ) { component = difference . getComponentB ( ) ; } final ComponentDifferenceDTO dto = new ComponentDifferenceDTO ( ) ; dto . setComponentName ( component . getName ( ) ) ; dto . setComponentType ( component . getComponentType ( ) . toString ( ) ) ; if ( component instanceof InstantiatedVersionedComponent ) { final InstantiatedVersionedComponent instantiatedComponent = ( InstantiatedVersionedComponent ) component ; dto . setComponentId ( instantiatedComponent . getInstanceId ( ) ) ; dto . setProcessGroupId ( instantiatedComponent . getInstanceGroupId ( ) ) ; } else { dto . setComponentId ( component . getIdentifier ( ) ) ; dto . setProcessGroupId ( dto . getProcessGroupId ( ) ) ; } return dto ; } public VersionControlInformationDTO createVersionControlInformationDto ( final ProcessGroup group ) { if ( group == null ) { return null ; } final VersionControlInformation versionControlInfo = group . getVersionControlInformation ( ) ; if ( versionControlInfo == null ) { return null ; } final VersionControlInformationDTO dto = new VersionControlInformationDTO ( ) ; dto . setGroupId ( group . getIdentifier ( ) ) ; dto . setRegistryId ( versionControlInfo . getRegistryIdentifier ( ) ) ; dto . setRegistryName ( versionControlInfo . getRegistryName ( ) ) ; dto . setBucketId ( versionControlInfo . getBucketIdentifier ( ) ) ; dto . setBucketName ( versionControlInfo . getBucketName ( ) ) ; dto . setFlowId ( versionControlInfo . getFlowIdentifier ( ) ) ; dto . setFlowName ( versionControlInfo . getFlowName ( ) ) ; dto . setFlowDescription ( versionControlInfo . getFlowDescription ( ) ) ; dto . setVersion ( versionControlInfo . getVersion ( ) ) ; final VersionedFlowStatus status = versionControlInfo . getStatus ( ) ; final VersionedFlowState state = status . getState ( ) ; dto . setState ( state == null ? null : state . name ( ) ) ; dto . setStateExplanation ( status . getStateExplanation ( ) ) ; return dto ; } public Map < String , String > createVersionControlComponentMappingDto ( final InstantiatedVersionedProcessGroup group ) { final Map < String , String > mapping = new HashMap < > ( ) ; mapping . put ( group . getInstanceId ( ) , group . getIdentifier ( ) ) ; group . getProcessors ( ) . stream ( ) . map ( proc -> ( InstantiatedVersionedProcessor ) proc ) . forEach ( proc -> mapping . put ( proc . getInstanceId ( ) , proc . getIdentifier ( ) ) ) ; group . getFunnels ( ) . stream ( ) . map ( funnel -> ( InstantiatedVersionedFunnel ) funnel ) . forEach ( funnel -> mapping . put ( funnel . getInstanceId ( ) , funnel . getIdentifier ( ) ) ) ; group . getInputPorts ( ) . stream ( ) . map ( port -> ( InstantiatedVersionedPort ) port ) . forEach ( port -> mapping . put ( port . getInstanceId ( ) , port . getIdentifier ( ) ) ) ; group . getOutputPorts ( ) . stream ( ) . map ( port -> ( InstantiatedVersionedPort ) port ) . forEach ( port -> mapping . put ( port . getInstanceId ( ) , port . getIdentifier ( ) ) ) ; group . getControllerServices ( ) . stream ( ) . map ( service -> ( InstantiatedVersionedControllerService ) service ) . forEach ( service -> mapping . put ( service . getInstanceId ( ) , service . getIdentifier ( ) ) ) ; group . getLabels ( ) . stream ( ) . map ( label -> ( InstantiatedVersionedLabel ) label ) . forEach ( label -> mapping . put ( label . getInstanceId ( ) , label . getIdentifier ( ) ) ) ; group . getConnections ( ) . stream ( ) . map ( conn -> ( InstantiatedVersionedConnection ) conn ) . forEach ( conn -> mapping . put ( conn . getInstanceId ( ) , conn . getIdentifier ( ) ) ) ; group . getRemoteProcessGroups ( ) . stream ( ) . map ( rpg -> ( InstantiatedVersionedRemoteProcessGroup ) rpg ) . forEach ( rpg -> { mapping . put ( rpg . getInstanceId ( ) , rpg . getIdentifier ( ) ) ; if ( rpg . getInputPorts ( ) != null ) { rpg . getInputPorts ( ) . stream ( ) . map ( port -> ( InstantiatedVersionedRemoteGroupPort ) port ) . forEach ( port -> mapping . put ( port . getInstanceId ( ) , port . getIdentifier ( ) ) ) ; } if ( rpg . getOutputPorts ( ) != null ) { rpg . getOutputPorts ( ) . stream ( ) . map ( port -> ( InstantiatedVersionedRemoteGroupPort ) port ) . forEach ( port -> mapping . put ( port . getInstanceId ( ) , port . getIdentifier ( ) ) ) ; } } ) ; group . getProcessGroups ( ) . stream ( ) . map ( child -> ( InstantiatedVersionedProcessGroup ) child ) . forEach ( child -> { final Map < String , String > childMapping = createVersionControlComponentMappingDto ( child ) ; mapping . putAll ( childMapping ) ; } ) ; return mapping ; } private FlowSnippetDTO createProcessGroupContentsDto ( final ProcessGroup group , final boolean recurse ) { if ( group == null ) { return null ; } final FlowSnippetDTO dto = new FlowSnippetDTO ( ) ; for ( final ProcessorNode procNode : group . getProcessors ( ) ) { dto . getProcessors ( ) . add ( createProcessorDto ( procNode ) ) ; } for ( final Connection connNode : group . getConnections ( ) ) { dto . getConnections ( ) . add ( createConnectionDto ( connNode ) ) ; } for ( final Label label : group . getLabels ( ) ) { dto . getLabels ( ) . add ( createLabelDto ( label ) ) ; } for ( final Funnel funnel : group . getFunnels ( ) ) { dto . getFunnels ( ) . add ( createFunnelDto ( funnel ) ) ; } for ( final ProcessGroup childGroup : group . getProcessGroups ( ) ) { if ( recurse ) { dto . getProcessGroups ( ) . add ( createProcessGroupDto ( childGroup , recurse ) ) ; } else { dto . getProcessGroups ( ) . add ( createConciseProcessGroupDto ( childGroup ) ) ; } } for ( final RemoteProcessGroup remoteProcessGroup : group . getRemoteProcessGroups ( ) ) { dto . getRemoteProcessGroups ( ) . add ( createRemoteProcessGroupDto ( remoteProcessGroup ) ) ; } for ( final Port inputPort : group . getInputPorts ( ) ) { dto . getInputPorts ( ) . add ( createPortDto ( inputPort ) ) ; } for ( final Port outputPort : group . getOutputPorts ( ) ) { dto . getOutputPorts ( ) . add ( createPortDto ( outputPort ) ) ; } return dto ; } private boolean isRestricted ( final Class < ? > cls ) { return cls . isAnnotationPresent ( Restricted . class ) ; } private String getUsageRestriction ( final Class < ? > cls ) { final Restricted restricted = cls . getAnnotation ( Restricted . class ) ; if ( restricted == null ) { return null ; } if ( StringUtils . isBlank ( restricted . value ( ) ) ) { return null ; } return restricted . value ( ) ; } private Set < ExplicitRestrictionDTO > getExplicitRestrictions ( final Class < ? > cls ) { final Restricted restricted = cls . getAnnotation ( Restricted . class ) ; if ( restricted == null ) { return null ; } final Restriction [ ] restrictions = restricted . restrictions ( ) ; if ( restrictions == null || restrictions . length == 0 ) { return null ; } return Arrays . stream ( restrictions ) . map ( restriction -> { final RequiredPermissionDTO requiredPermission = new RequiredPermissionDTO ( ) ; requiredPermission . setId ( restriction . requiredPermission ( ) . getPermissionIdentifier ( ) ) ; requiredPermission . setLabel ( restriction . requiredPermission ( ) . getPermissionLabel ( ) ) ; final ExplicitRestrictionDTO usageRestriction = new ExplicitRestrictionDTO ( ) ; usageRestriction . setRequiredPermission ( requiredPermission ) ; usageRestriction . setExplanation ( restriction . explanation ( ) ) ; return usageRestriction ; } ) . collect ( Collectors . toSet ( ) ) ; } private String getDeprecationReason ( final Class < ? > cls ) { final DeprecationNotice deprecationNotice = cls . getAnnotation ( DeprecationNotice . class ) ; return deprecationNotice == null ? null : deprecationNotice . reason ( ) ; } public Set < AffectedComponentEntity > createAffectedComponentEntities ( final Set < ComponentNode > affectedComponents , final RevisionManager revisionManager ) { return affectedComponents . stream ( ) . map ( component -> { final AffectedComponentDTO affectedComponent = createAffectedComponentDto ( component ) ; final PermissionsDTO permissions = createPermissionsDto ( component ) ; final RevisionDTO revision = createRevisionDTO ( revisionManager . getRevision ( component . getIdentifier ( ) ) ) ; return entityFactory . createAffectedComponentEntity ( affectedComponent , revision , permissions ) ; } ) . collect ( Collectors . toSet ( ) ) ; } public VariableRegistryDTO createVariableRegistryDto ( final ProcessGroup processGroup , final RevisionManager revisionManager ) { final ComponentVariableRegistry variableRegistry = processGroup . getVariableRegistry ( ) ; final List < String > variableNames = variableRegistry . getVariableMap ( ) . keySet ( ) . stream ( ) . map ( descriptor -> descriptor . getName ( ) ) . collect ( Collectors . toList ( ) ) ; final Set < VariableEntity > variableEntities = new LinkedHashSet < > ( ) ; for ( final String variableName : variableNames ) { final VariableDTO variableDto = new VariableDTO ( ) ; variableDto . setName ( variableName ) ; variableDto . setValue ( variableRegistry . getVariableValue ( variableName ) ) ; variableDto . setProcessGroupId ( processGroup . getIdentifier ( ) ) ; final Set < AffectedComponentEntity > affectedComponentEntities = createAffectedComponentEntities ( processGroup . getComponentsAffectedByVariable ( variableName ) , revisionManager ) ; boolean canWrite = true ; for ( final AffectedComponentEntity affectedComponent : affectedComponentEntities ) { final PermissionsDTO permissions = affectedComponent . getPermissions ( ) ; if ( ! permissions . getCanRead ( ) || ! permissions . getCanWrite ( ) ) { canWrite = false ; break ; } } variableDto . setAffectedComponents ( affectedComponentEntities ) ; final VariableEntity variableEntity = new VariableEntity ( ) ; variableEntity . setVariable ( variableDto ) ; variableEntity . setCanWrite ( canWrite ) ; variableEntities . add ( variableEntity ) ; } final VariableRegistryDTO registryDto = new VariableRegistryDTO ( ) ; registryDto . setProcessGroupId ( processGroup . getIdentifier ( ) ) ; registryDto . setVariables ( variableEntities ) ; return registryDto ; } public VariableRegistryUpdateRequestDTO createVariableRegistryUpdateRequestDto ( final VariableRegistryUpdateRequest request ) { final VariableRegistryUpdateRequestDTO dto = new VariableRegistryUpdateRequestDTO ( ) ; dto . setComplete ( request . isComplete ( ) ) ; dto . setFailureReason ( request . getFailureReason ( ) ) ; dto . setLastUpdated ( request . getLastUpdated ( ) ) ; dto . setProcessGroupId ( request . getProcessGroupId ( ) ) ; dto . setRequestId ( request . getRequestId ( ) ) ; dto . setSubmissionTime ( request . getSubmissionTime ( ) ) ; final List < VariableRegistryUpdateStepDTO > updateSteps = new ArrayList < > ( ) ; updateSteps . add ( createVariableRegistryUpdateStepDto ( request . getIdentifyRelevantComponentsStep ( ) ) ) ; updateSteps . add ( createVariableRegistryUpdateStepDto ( request . getStopProcessorsStep ( ) ) ) ; updateSteps . add ( createVariableRegistryUpdateStepDto ( request . getDisableServicesStep ( ) ) ) ; updateSteps . add ( createVariableRegistryUpdateStepDto ( request . getApplyUpdatesStep ( ) ) ) ; updateSteps . add ( createVariableRegistryUpdateStepDto ( request . getEnableServicesStep ( ) ) ) ; updateSteps . add ( createVariableRegistryUpdateStepDto ( request . getStartProcessorsStep ( ) ) ) ; dto . setUpdateSteps ( updateSteps ) ; dto . setAffectedComponents ( new HashSet < > ( request . getAffectedComponents ( ) . values ( ) ) ) ; return dto ; } public VariableRegistryUpdateStepDTO createVariableRegistryUpdateStepDto ( final VariableRegistryUpdateStep step ) { final VariableRegistryUpdateStepDTO dto = new VariableRegistryUpdateStepDTO ( ) ; dto . setComplete ( step . isComplete ( ) ) ; dto . setDescription ( step . getDescription ( ) ) ; dto . setFailureReason ( step . getFailureReason ( ) ) ; return dto ; } public VariableRegistryDTO populateAffectedComponents ( final VariableRegistryDTO variableRegistry , final ProcessGroup group , final RevisionManager revisionManager ) { if ( ! group . getIdentifier ( ) . equals ( variableRegistry . getProcessGroupId ( ) ) ) { throw new IllegalArgumentException ( ""Variable Registry does not have the same Group ID as the given Process Group"" ) ; } final Set < VariableEntity > variableEntities = new LinkedHashSet < > ( ) ; if ( variableRegistry . getVariables ( ) != null ) { for ( final VariableEntity inputEntity : variableRegistry . getVariables ( ) ) { final VariableEntity entity = new VariableEntity ( ) ; final VariableDTO inputDto = inputEntity . getVariable ( ) ; final VariableDTO variableDto = new VariableDTO ( ) ; variableDto . setName ( inputDto . getName ( ) ) ; variableDto . setValue ( inputDto . getValue ( ) ) ; variableDto . setProcessGroupId ( group . getIdentifier ( ) ) ; final Set < AffectedComponentEntity > affectedComponentEntities = createAffectedComponentEntities ( group . getComponentsAffectedByVariable ( variableDto . getName ( ) ) , revisionManager ) ; boolean canWrite = true ; for ( final AffectedComponentEntity affectedComponent : affectedComponentEntities ) { final PermissionsDTO permissions = affectedComponent . getPermissions ( ) ; if ( ! permissions . getCanRead ( ) || ! permissions . getCanWrite ( ) ) { canWrite = false ; break ; } } variableDto . setAffectedComponents ( affectedComponentEntities ) ; entity . setCanWrite ( canWrite ) ; entity . setVariable ( inputDto ) ; variableEntities . add ( entity ) ; } } final VariableRegistryDTO registryDto = new VariableRegistryDTO ( ) ; registryDto . setProcessGroupId ( group . getIdentifier ( ) ) ; registryDto . setVariables ( variableEntities ) ; return registryDto ; } private String getCapabilityDescription ( final Class < ? > cls ) { final CapabilityDescription capabilityDesc = cls . getAnnotation ( CapabilityDescription . class ) ; return capabilityDesc == null ? null : capabilityDesc . value ( ) ; } private Set < String > getTags ( final Class < ? > cls ) { final Set < String > tags = new HashSet < > ( ) ; final Tags tagsAnnotation = cls . getAnnotation ( Tags . class ) ; if ( tagsAnnotation != null ) { for ( final String tag : tagsAnnotation . value ( ) ) { tags . add ( tag ) ; } } if ( cls . isAnnotationPresent ( Restricted . class ) ) { tags . add ( ""restricted"" ) ; } return tags ; } public BundleDTO createBundleDto ( final BundleCoordinate coordinate ) { final BundleDTO dto = new BundleDTO ( ) ; dto . setGroup ( coordinate . getGroup ( ) ) ; dto . setArtifact ( coordinate . getId ( ) ) ; dto . setVersion ( coordinate . getVersion ( ) ) ; return dto ; } private List < ControllerServiceApiDTO > createControllerServiceApiDto ( final Class cls ) { final Set < Class > serviceApis = new HashSet < > ( ) ; if ( ControllerService . class . isAssignableFrom ( cls ) ) { final List < Class < ? > > interfaces = ClassUtils . getAllInterfaces ( cls ) ; for ( final Class i : interfaces ) { if ( ControllerService . class . isAssignableFrom ( i ) && ! ControllerService . class . equals ( i ) ) { serviceApis . add ( i ) ; } } final List < ControllerServiceApiDTO > dtos = new ArrayList < > ( ) ; for ( final Class serviceApi : serviceApis ) { final Bundle bundle = extensionManager . getBundle ( serviceApi . getClassLoader ( ) ) ; final BundleCoordinate bundleCoordinate = bundle . getBundleDetails ( ) . getCoordinate ( ) ; final ControllerServiceApiDTO dto = new ControllerServiceApiDTO ( ) ; dto . setType ( serviceApi . getName ( ) ) ; dto . setBundle ( createBundleDto ( bundleCoordinate ) ) ; dtos . add ( dto ) ; } return dtos ; } else { return null ; } } public Set < DocumentedTypeDTO > fromDocumentedTypes ( final Map < Class , Bundle > classes , final String bundleGroupFilter , final String bundleArtifactFilter , final String typeFilter ) { final Set < DocumentedTypeDTO > types = new LinkedHashSet < > ( ) ; final List < Class > sortedClasses = new ArrayList < > ( classes . keySet ( ) ) ; Collections . sort ( sortedClasses , CLASS_NAME_COMPARATOR ) ; for ( final Class cls : sortedClasses ) { final Bundle bundle = classes . get ( cls ) ; final BundleCoordinate coordinate = bundle . getBundleDetails ( ) . getCoordinate ( ) ; if ( bundleGroupFilter != null && ! bundleGroupFilter . equals ( coordinate . getGroup ( ) ) ) { continue ; } if ( bundleArtifactFilter != null && ! bundleArtifactFilter . equals ( coordinate . getId ( ) ) ) { continue ; } if ( typeFilter != null && ! typeFilter . equals ( cls . getName ( ) ) ) { continue ; } final DocumentedTypeDTO dto = new DocumentedTypeDTO ( ) ; dto . setType ( cls . getName ( ) ) ; dto . setBundle ( createBundleDto ( coordinate ) ) ; dto . setControllerServiceApis ( createControllerServiceApiDto ( cls ) ) ; dto . setDescription ( getCapabilityDescription ( cls ) ) ; dto . setRestricted ( isRestricted ( cls ) ) ; dto . setUsageRestriction ( getUsageRestriction ( cls ) ) ; dto . setExplicitRestrictions ( getExplicitRestrictions ( cls ) ) ; dto . setDeprecationReason ( getDeprecationReason ( cls ) ) ; dto . setTags ( getTags ( cls ) ) ; types . add ( dto ) ; } return types ; } public Set < DocumentedTypeDTO > fromDocumentedTypes ( final Set < Class > classes , final String bundleGroupFilter , final String bundleArtifactFilter , final String typeFilter ) { final Map < Class , Bundle > classBundles = new HashMap < > ( ) ; for ( final Class cls : classes ) { classBundles . put ( cls , extensionManager . getBundle ( cls . getClassLoader ( ) ) ) ; } return fromDocumentedTypes ( classBundles , bundleGroupFilter , bundleArtifactFilter , typeFilter ) ; } public ProcessorDTO createProcessorDto ( final ProcessorNode node ) { if ( node == null ) { return null ; } final BundleCoordinate bundleCoordinate = node . getBundleCoordinate ( ) ; final List < Bundle > compatibleBundles = extensionManager . getBundles ( node . getCanonicalClassName ( ) ) . stream ( ) . filter ( bundle -> { final BundleCoordinate coordinate = bundle . getBundleDetails ( ) . getCoordinate ( ) ; return bundleCoordinate . getGroup ( ) . equals ( coordinate . getGroup ( ) ) && bundleCoordinate . getId ( ) . equals ( coordinate . getId ( ) ) ; } ) . collect ( Collectors . toList ( ) ) ; final ProcessorDTO dto = new ProcessorDTO ( ) ; dto . setId ( node . getIdentifier ( ) ) ; dto . setPosition ( createPositionDto ( node . getPosition ( ) ) ) ; dto . setStyle ( node . getStyle ( ) ) ; dto . setParentGroupId ( node . getProcessGroup ( ) . getIdentifier ( ) ) ; dto . setInputRequirement ( node . getInputRequirement ( ) . name ( ) ) ; dto . setPersistsState ( node . getProcessor ( ) . getClass ( ) . isAnnotationPresent ( Stateful . class ) ) ; dto . setRestricted ( node . isRestricted ( ) ) ; dto . setDeprecated ( node . isDeprecated ( ) ) ; dto . setExecutionNodeRestricted ( node . isExecutionNodeRestricted ( ) ) ; dto . setExtensionMissing ( node . isExtensionMissing ( ) ) ; dto . setMultipleVersionsAvailable ( compatibleBundles . size ( ) > 1 ) ; dto . setVersionedComponentId ( node . getVersionedComponentId ( ) . orElse ( null ) ) ; dto . setType ( node . getCanonicalClassName ( ) ) ; dto . setBundle ( createBundleDto ( bundleCoordinate ) ) ; dto . setName ( node . getName ( ) ) ; dto . setState ( node . getScheduledState ( ) . toString ( ) ) ; final List < RelationshipDTO > relationships = new ArrayList < > ( ) ; for ( final Relationship rel : node . getRelationships ( ) ) { final RelationshipDTO relationshipDTO = new RelationshipDTO ( ) ; relationshipDTO . setDescription ( rel . getDescription ( ) ) ; relationshipDTO . setName ( rel . getName ( ) ) ; relationshipDTO . setAutoTerminate ( node . isAutoTerminated ( rel ) ) ; relationships . add ( relationshipDTO ) ; } Collections . sort ( relationships , new Comparator < RelationshipDTO > ( ) { @ Override public int compare ( final RelationshipDTO r1 , final RelationshipDTO r2 ) { return Collator . getInstance ( Locale . US ) . compare ( r1 . getName ( ) , r2 . getName ( ) ) ; } } ) ; dto . setRelationships ( relationships ) ; dto . setDescription ( getCapabilityDescription ( node . getClass ( ) ) ) ; dto . setSupportsParallelProcessing ( ! node . isTriggeredSerially ( ) ) ; dto . setSupportsEventDriven ( node . isEventDrivenSupported ( ) ) ; dto . setSupportsBatching ( node . isSessionBatchingSupported ( ) ) ; dto . setConfig ( createProcessorConfigDto ( node ) ) ; final ValidationStatus validationStatus = node . getValidationStatus ( 1 , TimeUnit . MILLISECONDS ) ; dto . setValidationStatus ( validationStatus . name ( ) ) ; final Collection < ValidationResult > validationErrors = node . getValidationErrors ( ) ; if ( validationErrors != null && ! validationErrors . isEmpty ( ) ) { final List < String > errors = new ArrayList < > ( ) ; for ( final ValidationResult validationResult : validationErrors ) { errors . add ( validationResult . toString ( ) ) ; } dto . setValidationErrors ( errors ) ; } return dto ; } public BulletinBoardDTO createBulletinBoardDto ( final List < BulletinEntity > bulletins ) { Collections . sort ( bulletins , new Comparator < BulletinEntity > ( ) { @ Override public int compare ( final BulletinEntity bulletin1 , final BulletinEntity bulletin2 ) { if ( bulletin1 == null && bulletin2 == null ) { return 0 ; } else if ( bulletin1 == null ) { return 1 ; } else if ( bulletin2 == null ) { return - 1 ; } final Date timestamp1 = bulletin1 . getTimestamp ( ) ; final Date timestamp2 = bulletin2 . getTimestamp ( ) ; if ( timestamp1 == null && timestamp2 == null ) { return 0 ; } else if ( timestamp1 == null ) { return 1 ; } else if ( timestamp2 == null ) { return - 1 ; } else { return timestamp1 . compareTo ( timestamp2 ) ; } } } ) ; final BulletinBoardDTO bulletinBoard = new BulletinBoardDTO ( ) ; bulletinBoard . setBulletins ( bulletins ) ; bulletinBoard . setGenerated ( new Date ( ) ) ; return bulletinBoard ; } public List < BulletinDTO > createBulletinDtos ( final List < Bulletin > bulletins ) { final List < BulletinDTO > bulletinDtos = new ArrayList < > ( bulletins . size ( ) ) ; for ( final Bulletin bulletin : bulletins ) { bulletinDtos . add ( createBulletinDto ( bulletin ) ) ; } return bulletinDtos ; } public BulletinDTO createBulletinDto ( final Bulletin bulletin ) { final BulletinDTO dto = new BulletinDTO ( ) ; dto . setId ( bulletin . getId ( ) ) ; dto . setNodeAddress ( bulletin . getNodeAddress ( ) ) ; dto . setTimestamp ( bulletin . getTimestamp ( ) ) ; dto . setGroupId ( bulletin . getGroupId ( ) ) ; dto . setSourceId ( bulletin . getSourceId ( ) ) ; dto . setSourceName ( bulletin . getSourceName ( ) ) ; dto . setCategory ( bulletin . getCategory ( ) ) ; dto . setLevel ( bulletin . getLevel ( ) ) ; dto . setMessage ( bulletin . getMessage ( ) ) ; return dto ; } public ProvenanceNodeDTO createProvenanceEventNodeDTO ( final ProvenanceEventLineageNode node ) { final ProvenanceNodeDTO dto = new ProvenanceNodeDTO ( ) ; dto . setId ( node . getIdentifier ( ) ) ; dto . setType ( ""EVENT"" ) ; dto . setEventType ( node . getEventType ( ) . toString ( ) ) ; dto . setTimestamp ( new Date ( node . getTimestamp ( ) ) ) ; dto . setMillis ( node . getTimestamp ( ) ) ; dto . setFlowFileUuid ( node . getFlowFileUuid ( ) ) ; dto . setParentUuids ( node . getParentUuids ( ) ) ; dto . setChildUuids ( node . getChildUuids ( ) ) ; return dto ; } public ProvenanceNodeDTO createFlowFileNodeDTO ( final LineageNode node ) { final ProvenanceNodeDTO dto = new ProvenanceNodeDTO ( ) ; dto . setId ( node . getIdentifier ( ) ) ; dto . setType ( ""FLOWFILE"" ) ; dto . setTimestamp ( new Date ( node . getTimestamp ( ) ) ) ; dto . setMillis ( node . getTimestamp ( ) ) ; dto . setFlowFileUuid ( node . getFlowFileUuid ( ) ) ; return dto ; } public ProvenanceLinkDTO createProvenanceLinkDTO ( final LineageEdge edge ) { final LineageNode source = edge . getSource ( ) ; final LineageNode target = edge . getDestination ( ) ; final ProvenanceLinkDTO dto = new ProvenanceLinkDTO ( ) ; dto . setTimestamp ( new Date ( target . getTimestamp ( ) ) ) ; dto . setMillis ( target . getTimestamp ( ) ) ; dto . setFlowFileUuid ( edge . getUuid ( ) ) ; dto . setSourceId ( source . getIdentifier ( ) ) ; dto . setTargetId ( target . getIdentifier ( ) ) ; return dto ; } public LineageDTO createLineageDto ( final ComputeLineageSubmission computeLineageSubmission ) { final LineageDTO dto = new LineageDTO ( ) ; final LineageRequestDTO requestDto = new LineageRequestDTO ( ) ; final LineageResultsDTO resultsDto = new LineageResultsDTO ( ) ; dto . setRequest ( requestDto ) ; dto . setResults ( resultsDto ) ; switch ( computeLineageSubmission . getLineageComputationType ( ) ) { case EXPAND_CHILDREN : requestDto . setEventId ( computeLineageSubmission . getExpandedEventId ( ) ) ; requestDto . setLineageRequestType ( LineageRequestType . CHILDREN ) ; break ; case EXPAND_PARENTS : requestDto . setEventId ( computeLineageSubmission . getExpandedEventId ( ) ) ; requestDto . setLineageRequestType ( LineageRequestType . PARENTS ) ; break ; case FLOWFILE_LINEAGE : final Collection < String > uuids = computeLineageSubmission . getLineageFlowFileUuids ( ) ; if ( uuids . size ( ) == 1 ) { requestDto . setUuid ( uuids . iterator ( ) . next ( ) ) ; } requestDto . setEventId ( computeLineageSubmission . getExpandedEventId ( ) ) ; requestDto . setLineageRequestType ( LineageRequestType . FLOWFILE ) ; break ; } dto . setId ( computeLineageSubmission . getLineageIdentifier ( ) ) ; dto . setSubmissionTime ( computeLineageSubmission . getSubmissionTime ( ) ) ; final ComputeLineageResult results = computeLineageSubmission . getResult ( ) ; dto . setFinished ( results . isFinished ( ) ) ; dto . setPercentCompleted ( results . getPercentComplete ( ) ) ; dto . setExpiration ( results . getExpiration ( ) ) ; final List < LineageNode > nodes = results . getNodes ( ) ; final List < LineageEdge > edges = results . getEdges ( ) ; final List < ProvenanceNodeDTO > nodeDtos = new ArrayList < > ( ) ; if ( results . isFinished ( ) ) { for ( final LineageNode node : nodes ) { switch ( node . getNodeType ( ) ) { case FLOWFILE_NODE : nodeDtos . add ( createFlowFileNodeDTO ( node ) ) ; break ; case PROVENANCE_EVENT_NODE : nodeDtos . add ( createProvenanceEventNodeDTO ( ( ProvenanceEventLineageNode ) node ) ) ; break ; } } } resultsDto . setNodes ( nodeDtos ) ; if ( results . getError ( ) != null ) { final Set < String > errors = new HashSet < > ( ) ; errors . add ( results . getError ( ) ) ; resultsDto . setErrors ( errors ) ; } final List < ProvenanceLinkDTO > linkDtos = new ArrayList < > ( ) ; for ( final LineageEdge edge : edges ) { linkDtos . add ( createProvenanceLinkDTO ( edge ) ) ; } resultsDto . setLinks ( linkDtos ) ; return dto ; } public SystemDiagnosticsDTO createSystemDiagnosticsDto ( final SystemDiagnostics sysDiagnostics ) { final SystemDiagnosticsDTO dto = new SystemDiagnosticsDTO ( ) ; final SystemDiagnosticsSnapshotDTO snapshot = new SystemDiagnosticsSnapshotDTO ( ) ; dto . setAggregateSnapshot ( snapshot ) ; snapshot . setStatsLastRefreshed ( new Date ( sysDiagnostics . getCreationTimestamp ( ) ) ) ; snapshot . setAvailableProcessors ( sysDiagnostics . getAvailableProcessors ( ) ) ; snapshot . setProcessorLoadAverage ( sysDiagnostics . getProcessorLoadAverage ( ) ) ; snapshot . setDaemonThreads ( sysDiagnostics . getDaemonThreads ( ) ) ; snapshot . setTotalThreads ( sysDiagnostics . getTotalThreads ( ) ) ; snapshot . setMaxHeap ( FormatUtils . formatDataSize ( sysDiagnostics . getMaxHeap ( ) ) ) ; snapshot . setMaxHeapBytes ( sysDiagnostics . getMaxHeap ( ) ) ; snapshot . setTotalHeap ( FormatUtils . formatDataSize ( sysDiagnostics . getTotalHeap ( ) ) ) ; snapshot . setTotalHeapBytes ( sysDiagnostics . getTotalHeap ( ) ) ; snapshot . setUsedHeap ( FormatUtils . formatDataSize ( sysDiagnostics . getUsedHeap ( ) ) ) ; snapshot . setUsedHeapBytes ( sysDiagnostics . getUsedHeap ( ) ) ; snapshot . setFreeHeap ( FormatUtils . formatDataSize ( sysDiagnostics . getFreeHeap ( ) ) ) ; snapshot . setFreeHeapBytes ( sysDiagnostics . getFreeHeap ( ) ) ; if ( sysDiagnostics . getHeapUtilization ( ) != - 1 ) { snapshot . setHeapUtilization ( FormatUtils . formatUtilization ( sysDiagnostics . getHeapUtilization ( ) ) ) ; } snapshot . setMaxNonHeap ( FormatUtils . formatDataSize ( sysDiagnostics . getMaxNonHeap ( ) ) ) ; snapshot . setMaxNonHeapBytes ( sysDiagnostics . getMaxNonHeap ( ) ) ; snapshot . setTotalNonHeap ( FormatUtils . formatDataSize ( sysDiagnostics . getTotalNonHeap ( ) ) ) ; snapshot . setTotalNonHeapBytes ( sysDiagnostics . getTotalNonHeap ( ) ) ; snapshot . setUsedNonHeap ( FormatUtils . formatDataSize ( sysDiagnostics . getUsedNonHeap ( ) ) ) ; snapshot . setUsedNonHeapBytes ( sysDiagnostics . getUsedNonHeap ( ) ) ; snapshot . setFreeNonHeap ( FormatUtils . formatDataSize ( sysDiagnostics . getFreeNonHeap ( ) ) ) ; snapshot . setFreeNonHeapBytes ( sysDiagnostics . getFreeNonHeap ( ) ) ; if ( sysDiagnostics . getNonHeapUtilization ( ) != - 1 ) { snapshot . setNonHeapUtilization ( FormatUtils . formatUtilization ( sysDiagnostics . getNonHeapUtilization ( ) ) ) ; } final SystemDiagnosticsSnapshotDTO . StorageUsageDTO flowFileRepositoryStorageUsageDto = createStorageUsageDTO ( null , sysDiagnostics . getFlowFileRepositoryStorageUsage ( ) ) ; snapshot . setFlowFileRepositoryStorageUsage ( flowFileRepositoryStorageUsageDto ) ; final Set < SystemDiagnosticsSnapshotDTO . StorageUsageDTO > contentRepositoryStorageUsageDtos = new LinkedHashSet < > ( ) ; snapshot . setContentRepositoryStorageUsage ( contentRepositoryStorageUsageDtos ) ; for ( final Map . Entry < String , StorageUsage > entry : sysDiagnostics . getContentRepositoryStorageUsage ( ) . entrySet ( ) ) { contentRepositoryStorageUsageDtos . add ( createStorageUsageDTO ( entry . getKey ( ) , entry . getValue ( ) ) ) ; } final Set < SystemDiagnosticsSnapshotDTO . StorageUsageDTO > provenanceRepositoryStorageUsageDtos = new LinkedHashSet < > ( ) ; snapshot . setProvenanceRepositoryStorageUsage ( provenanceRepositoryStorageUsageDtos ) ; for ( final Map . Entry < String , StorageUsage > entry : sysDiagnostics . getProvenanceRepositoryStorageUsage ( ) . entrySet ( ) ) { provenanceRepositoryStorageUsageDtos . add ( createStorageUsageDTO ( entry . getKey ( ) , entry . getValue ( ) ) ) ; } final Set < SystemDiagnosticsSnapshotDTO . GarbageCollectionDTO > garbageCollectionDtos = new LinkedHashSet < > ( ) ; snapshot . setGarbageCollection ( garbageCollectionDtos ) ; for ( final Map . Entry < String , GarbageCollection > entry : sysDiagnostics . getGarbageCollection ( ) . entrySet ( ) ) { garbageCollectionDtos . add ( createGarbageCollectionDTO ( entry . getKey ( ) , entry . getValue ( ) ) ) ; } final SystemDiagnosticsSnapshotDTO . VersionInfoDTO versionInfoDto = createVersionInfoDTO ( ) ; snapshot . setVersionInfo ( versionInfoDto ) ; snapshot . setUptime ( FormatUtils . formatHoursMinutesSeconds ( sysDiagnostics . getUptime ( ) , TimeUnit . MILLISECONDS ) ) ; return dto ; } public SystemDiagnosticsSnapshotDTO . StorageUsageDTO createStorageUsageDTO ( final String identifier , final StorageUsage storageUsage ) { final SystemDiagnosticsSnapshotDTO . StorageUsageDTO dto = new SystemDiagnosticsSnapshotDTO . StorageUsageDTO ( ) ; dto . setIdentifier ( identifier ) ; dto . setFreeSpace ( FormatUtils . formatDataSize ( storageUsage . getFreeSpace ( ) ) ) ; dto . setTotalSpace ( FormatUtils . formatDataSize ( storageUsage . getTotalSpace ( ) ) ) ; dto . setUsedSpace ( FormatUtils . formatDataSize ( storageUsage . getUsedSpace ( ) ) ) ; dto . setFreeSpaceBytes ( storageUsage . getFreeSpace ( ) ) ; dto . setTotalSpaceBytes ( storageUsage . getTotalSpace ( ) ) ; dto . setUsedSpaceBytes ( storageUsage . getUsedSpace ( ) ) ; dto . setUtilization ( FormatUtils . formatUtilization ( storageUsage . getDiskUtilization ( ) ) ) ; return dto ; } public SystemDiagnosticsSnapshotDTO . GarbageCollectionDTO createGarbageCollectionDTO ( final String name , final GarbageCollection garbageCollection ) { final SystemDiagnosticsSnapshotDTO . GarbageCollectionDTO dto = new SystemDiagnosticsSnapshotDTO . GarbageCollectionDTO ( ) ; dto . setName ( name ) ; dto . setCollectionCount ( garbageCollection . getCollectionCount ( ) ) ; dto . setCollectionTime ( FormatUtils . formatHoursMinutesSeconds ( garbageCollection . getCollectionTime ( ) , TimeUnit . MILLISECONDS ) ) ; dto . setCollectionMillis ( garbageCollection . getCollectionTime ( ) ) ; return dto ; } public SystemDiagnosticsSnapshotDTO . VersionInfoDTO createVersionInfoDTO ( ) { final SystemDiagnosticsSnapshotDTO . VersionInfoDTO dto = new SystemDiagnosticsSnapshotDTO . VersionInfoDTO ( ) ; dto . setJavaVendor ( System . getProperty ( ""java.vendor"" ) ) ; dto . setJavaVersion ( System . getProperty ( ""java.version"" ) ) ; dto . setOsName ( System . getProperty ( ""os.name"" ) ) ; dto . setOsVersion ( System . getProperty ( ""os.version"" ) ) ; dto . setOsArchitecture ( System . getProperty ( ""os.arch"" ) ) ; final Bundle frameworkBundle = NarClassLoadersHolder . getInstance ( ) . getFrameworkBundle ( ) ; if ( frameworkBundle != null ) { final BundleDetails frameworkDetails = frameworkBundle . getBundleDetails ( ) ; dto . setNiFiVersion ( frameworkDetails . getCoordinate ( ) . getVersion ( ) ) ; dto . setBuildTag ( frameworkDetails . getBuildTag ( ) ) ; dto . setBuildRevision ( frameworkDetails . getBuildRevision ( ) ) ; dto . setBuildBranch ( frameworkDetails . getBuildBranch ( ) ) ; dto . setBuildTimestamp ( frameworkDetails . getBuildTimestampDate ( ) ) ; } return dto ; } public ResourceDTO createResourceDto ( final Resource resource ) { final ResourceDTO dto = new ResourceDTO ( ) ; dto . setIdentifier ( resource . getIdentifier ( ) ) ; dto . setName ( resource . getName ( ) ) ; return dto ; } public ProcessorDiagnosticsDTO createProcessorDiagnosticsDto ( final ProcessorNode procNode , final ProcessorStatus procStatus , final BulletinRepository bulletinRepo , final FlowController flowController , final Function < String , ControllerServiceEntity > serviceEntityFactory ) { final ProcessorDiagnosticsDTO procDiagnostics = new ProcessorDiagnosticsDTO ( ) ; procDiagnostics . setClassLoaderDiagnostics ( createClassLoaderDiagnosticsDto ( procNode ) ) ; procDiagnostics . setIncomingConnections ( procNode . getIncomingConnections ( ) . stream ( ) . map ( this :: createConnectionDiagnosticsDto ) . collect ( Collectors . toSet ( ) ) ) ; procDiagnostics . setOutgoingConnections ( procNode . getConnections ( ) . stream ( ) . map ( this :: createConnectionDiagnosticsDto ) . collect ( Collectors . toSet ( ) ) ) ; procDiagnostics . setJvmDiagnostics ( createJvmDiagnosticsDto ( flowController ) ) ; procDiagnostics . setProcessor ( createProcessorDto ( procNode ) ) ; procDiagnostics . setProcessorStatus ( createProcessorStatusDto ( procStatus ) ) ; procDiagnostics . setThreadDumps ( createThreadDumpDtos ( procNode ) ) ; final Set < ControllerServiceDiagnosticsDTO > referencedServiceDiagnostics = createReferencedServiceDiagnostics ( procNode . getProperties ( ) , flowController . getControllerServiceProvider ( ) , serviceEntityFactory ) ; procDiagnostics . setReferencedControllerServices ( referencedServiceDiagnostics ) ; return procDiagnostics ; } private Set < ControllerServiceDiagnosticsDTO > createReferencedServiceDiagnostics ( final Map < PropertyDescriptor , String > properties , final ControllerServiceProvider serviceProvider , final Function < String , ControllerServiceEntity > serviceEntityFactory ) { final Set < ControllerServiceDiagnosticsDTO > referencedServiceDiagnostics = new HashSet < > ( ) ; for ( final Map . Entry < PropertyDescriptor , String > entry : properties . entrySet ( ) ) { final PropertyDescriptor descriptor = entry . getKey ( ) ; if ( descriptor . getControllerServiceDefinition ( ) == null ) { continue ; } final String serviceId = entry . getValue ( ) ; if ( serviceId == null ) { continue ; } final ControllerServiceNode serviceNode = serviceProvider . getControllerServiceNode ( serviceId ) ; if ( serviceNode == null ) { continue ; } final ControllerServiceDiagnosticsDTO serviceDiagnostics = createControllerServiceDiagnosticsDto ( serviceNode , serviceEntityFactory , serviceProvider ) ; if ( serviceDiagnostics != null ) { referencedServiceDiagnostics . add ( serviceDiagnostics ) ; } } return referencedServiceDiagnostics ; } public ControllerServiceDiagnosticsDTO createControllerServiceDiagnosticsDto ( final ControllerServiceNode serviceNode , final Function < String , ControllerServiceEntity > serviceEntityFactory , final ControllerServiceProvider serviceProvider ) { final ControllerServiceDiagnosticsDTO serviceDiagnostics = new ControllerServiceDiagnosticsDTO ( ) ; final ControllerServiceEntity serviceEntity = serviceEntityFactory . apply ( serviceNode . getIdentifier ( ) ) ; serviceDiagnostics . setControllerService ( serviceEntity ) ; serviceDiagnostics . setClassLoaderDiagnostics ( createClassLoaderDiagnosticsDto ( serviceNode ) ) ; return serviceDiagnostics ; } private ClassLoaderDiagnosticsDTO createClassLoaderDiagnosticsDto ( final ControllerServiceNode serviceNode ) { ClassLoader componentClassLoader = extensionManager . getInstanceClassLoader ( serviceNode . getIdentifier ( ) ) ; if ( componentClassLoader == null ) { componentClassLoader = serviceNode . getControllerServiceImplementation ( ) . getClass ( ) . getClassLoader ( ) ; } return createClassLoaderDiagnosticsDto ( componentClassLoader ) ; } private ClassLoaderDiagnosticsDTO createClassLoaderDiagnosticsDto ( final ProcessorNode procNode ) { ClassLoader componentClassLoader = extensionManager . getInstanceClassLoader ( procNode . getIdentifier ( ) ) ; if ( componentClassLoader == null ) { componentClassLoader = procNode . getProcessor ( ) . getClass ( ) . getClassLoader ( ) ; } return createClassLoaderDiagnosticsDto ( componentClassLoader ) ; } private ClassLoaderDiagnosticsDTO createClassLoaderDiagnosticsDto ( final ClassLoader classLoader ) { final ClassLoaderDiagnosticsDTO dto = new ClassLoaderDiagnosticsDTO ( ) ; final Bundle bundle = extensionManager . getBundle ( classLoader ) ; if ( bundle != null ) { dto . setBundle ( createBundleDto ( bundle . getBundleDetails ( ) . getCoordinate ( ) ) ) ; } final ClassLoader parentClassLoader = classLoader . getParent ( ) ; if ( parentClassLoader != null ) { dto . setParentClassLoader ( createClassLoaderDiagnosticsDto ( parentClassLoader ) ) ; } return dto ; } private ConnectionDiagnosticsDTO createConnectionDiagnosticsDto ( final Connection connection ) { final ConnectionDiagnosticsDTO dto = new ConnectionDiagnosticsDTO ( ) ; dto . setConnection ( createConnectionDto ( connection ) ) ; dto . setAggregateSnapshot ( createConnectionDiagnosticsSnapshotDto ( connection ) ) ; return dto ; } private ConnectionDiagnosticsSnapshotDTO createConnectionDiagnosticsSnapshotDto ( final Connection connection ) { final ConnectionDiagnosticsSnapshotDTO dto = new ConnectionDiagnosticsSnapshotDTO ( ) ; final QueueDiagnostics queueDiagnostics = connection . getFlowFileQueue ( ) . getQueueDiagnostics ( ) ; final FlowFileQueue queue = connection . getFlowFileQueue ( ) ; final QueueSize totalSize = queue . size ( ) ; dto . setTotalByteCount ( totalSize . getByteCount ( ) ) ; dto . setTotalFlowFileCount ( totalSize . getObjectCount ( ) ) ; final LocalQueuePartitionDiagnostics localDiagnostics = queueDiagnostics . getLocalQueuePartitionDiagnostics ( ) ; dto . setLocalQueuePartition ( createLocalQueuePartitionDto ( localDiagnostics ) ) ; final List < RemoteQueuePartitionDiagnostics > remoteDiagnostics = queueDiagnostics . getRemoteQueuePartitionDiagnostics ( ) ; if ( remoteDiagnostics != null ) { final List < RemoteQueuePartitionDTO > remoteDiagnosticsDtos = remoteDiagnostics . stream ( ) . map ( this :: createRemoteQueuePartitionDto ) . collect ( Collectors . toList ( ) ) ; dto . setRemoteQueuePartitions ( remoteDiagnosticsDtos ) ; } return dto ; } private LocalQueuePartitionDTO createLocalQueuePartitionDto ( final LocalQueuePartitionDiagnostics queueDiagnostics ) { final LocalQueuePartitionDTO dto = new LocalQueuePartitionDTO ( ) ; final QueueSize activeSize = queueDiagnostics . getActiveQueueSize ( ) ; dto . setActiveQueueByteCount ( activeSize . getByteCount ( ) ) ; dto . setActiveQueueFlowFileCount ( activeSize . getObjectCount ( ) ) ; final QueueSize inFlightSize = queueDiagnostics . getUnacknowledgedQueueSize ( ) ; dto . setInFlightByteCount ( inFlightSize . getByteCount ( ) ) ; dto . setInFlightFlowFileCount ( inFlightSize . getObjectCount ( ) ) ; final QueueSize swapSize = queueDiagnostics . getSwapQueueSize ( ) ; dto . setSwapByteCount ( swapSize . getByteCount ( ) ) ; dto . setSwapFlowFileCount ( swapSize . getObjectCount ( ) ) ; dto . setSwapFiles ( queueDiagnostics . getSwapFileCount ( ) ) ; dto . setTotalByteCount ( activeSize . getByteCount ( ) + inFlightSize . getByteCount ( ) + swapSize . getByteCount ( ) ) ; dto . setTotalFlowFileCount ( activeSize . getObjectCount ( ) + inFlightSize . getObjectCount ( ) + swapSize . getObjectCount ( ) ) ; dto . setAllActiveQueueFlowFilesPenalized ( queueDiagnostics . isAllActiveFlowFilesPenalized ( ) ) ; dto . setAnyActiveQueueFlowFilesPenalized ( queueDiagnostics . isAnyActiveFlowFilePenalized ( ) ) ; return dto ; } private RemoteQueuePartitionDTO createRemoteQueuePartitionDto ( final RemoteQueuePartitionDiagnostics queueDiagnostics ) { final RemoteQueuePartitionDTO dto = new RemoteQueuePartitionDTO ( ) ; dto . setNodeIdentifier ( queueDiagnostics . getNodeIdentifier ( ) ) ; final QueueSize activeSize = queueDiagnostics . getActiveQueueSize ( ) ; dto . setActiveQueueByteCount ( activeSize . getByteCount ( ) ) ; dto . setActiveQueueFlowFileCount ( activeSize . getObjectCount ( ) ) ; final QueueSize inFlightSize = queueDiagnostics . getUnacknowledgedQueueSize ( ) ; dto . setInFlightByteCount ( inFlightSize . getByteCount ( ) ) ; dto . setInFlightFlowFileCount ( inFlightSize . getObjectCount ( ) ) ; final QueueSize swapSize = queueDiagnostics . getSwapQueueSize ( ) ; dto . setSwapByteCount ( swapSize . getByteCount ( ) ) ; dto . setSwapFlowFileCount ( swapSize . getObjectCount ( ) ) ; dto . setSwapFiles ( queueDiagnostics . getSwapFileCount ( ) ) ; dto . setTotalByteCount ( activeSize . getByteCount ( ) + inFlightSize . getByteCount ( ) + swapSize . getByteCount ( ) ) ; dto . setTotalFlowFileCount ( activeSize . getObjectCount ( ) + inFlightSize . getObjectCount ( ) + swapSize . getObjectCount ( ) ) ; return dto ; } private JVMDiagnosticsDTO createJvmDiagnosticsDto ( final FlowController flowController ) { final JVMDiagnosticsDTO dto = new JVMDiagnosticsDTO ( ) ; dto . setAggregateSnapshot ( createJvmDiagnosticsSnapshotDto ( flowController ) ) ; dto . setClustered ( flowController . isClustered ( ) ) ; dto . setConnected ( flowController . isConnected ( ) ) ; return dto ; } private JVMDiagnosticsSnapshotDTO createJvmDiagnosticsSnapshotDto ( final FlowController flowController ) { final JVMDiagnosticsSnapshotDTO dto = new JVMDiagnosticsSnapshotDTO ( ) ; final JVMControllerDiagnosticsSnapshotDTO controllerDiagnosticsDto = new JVMControllerDiagnosticsSnapshotDTO ( ) ; final JVMFlowDiagnosticsSnapshotDTO flowDiagnosticsDto = new JVMFlowDiagnosticsSnapshotDTO ( ) ; final JVMSystemDiagnosticsSnapshotDTO systemDiagnosticsDto = new JVMSystemDiagnosticsSnapshotDTO ( ) ; dto . setControllerDiagnostics ( controllerDiagnosticsDto ) ; dto . setFlowDiagnosticsDto ( flowDiagnosticsDto ) ; dto . setSystemDiagnosticsDto ( systemDiagnosticsDto ) ; final SystemDiagnostics systemDiagnostics = flowController . getSystemDiagnostics ( ) ; final Set < BundleDTO > bundlesLoaded = extensionManager . getAllBundles ( ) . stream ( ) . map ( bundle -> bundle . getBundleDetails ( ) . getCoordinate ( ) ) . sorted ( ( a , b ) -> a . getCoordinate ( ) . compareTo ( b . getCoordinate ( ) ) ) . map ( this :: createBundleDto ) . collect ( Collectors . toCollection ( LinkedHashSet :: new ) ) ; flowDiagnosticsDto . setActiveEventDrivenThreads ( flowController . getActiveEventDrivenThreadCount ( ) ) ; flowDiagnosticsDto . setActiveTimerDrivenThreads ( flowController . getActiveTimerDrivenThreadCount ( ) ) ; flowDiagnosticsDto . setBundlesLoaded ( bundlesLoaded ) ; flowDiagnosticsDto . setTimeZone ( System . getProperty ( ""user.timezone"" ) ) ; flowDiagnosticsDto . setUptime ( FormatUtils . formatHoursMinutesSeconds ( systemDiagnostics . getUptime ( ) , TimeUnit . MILLISECONDS ) ) ; controllerDiagnosticsDto . setClusterCoordinator ( flowController . isClusterCoordinator ( ) ) ; controllerDiagnosticsDto . setPrimaryNode ( flowController . isPrimary ( ) ) ; controllerDiagnosticsDto . setMaxEventDrivenThreads ( flowController . getMaxEventDrivenThreadCount ( ) ) ; controllerDiagnosticsDto . setMaxTimerDrivenThreads ( flowController . getMaxTimerDrivenThreadCount ( ) ) ; systemDiagnosticsDto . setMaxOpenFileDescriptors ( systemDiagnostics . getMaxOpenFileHandles ( ) ) ; systemDiagnosticsDto . setOpenFileDescriptors ( systemDiagnostics . getOpenFileHandles ( ) ) ; systemDiagnosticsDto . setPhysicalMemoryBytes ( systemDiagnostics . getTotalPhysicalMemory ( ) ) ; systemDiagnosticsDto . setPhysicalMemory ( FormatUtils . formatDataSize ( systemDiagnostics . getTotalPhysicalMemory ( ) ) ) ; final NumberFormat percentageFormat = NumberFormat . getPercentInstance ( ) ; percentageFormat . setMaximumFractionDigits ( 2 ) ; final Set < RepositoryUsageDTO > contentRepoUsage = new HashSet < > ( ) ; for ( final Map . Entry < String , StorageUsage > entry : systemDiagnostics . getContentRepositoryStorageUsage ( ) . entrySet ( ) ) { final String repoName = entry . getKey ( ) ; final StorageUsage usage = entry . getValue ( ) ; final RepositoryUsageDTO usageDto = new RepositoryUsageDTO ( ) ; usageDto . setName ( repoName ) ; usageDto . setFileStoreHash ( DigestUtils . sha256Hex ( flowController . getContentRepoFileStoreName ( repoName ) ) ) ; usageDto . setFreeSpace ( FormatUtils . formatDataSize ( usage . getFreeSpace ( ) ) ) ; usageDto . setFreeSpaceBytes ( usage . getFreeSpace ( ) ) ; usageDto . setTotalSpace ( FormatUtils . formatDataSize ( usage . getTotalSpace ( ) ) ) ; usageDto . setTotalSpaceBytes ( usage . getTotalSpace ( ) ) ; final double usedPercentage = ( usage . getTotalSpace ( ) - usage . getFreeSpace ( ) ) / ( double ) usage . getTotalSpace ( ) ; final String utilization = percentageFormat . format ( usedPercentage ) ; usageDto . setUtilization ( utilization ) ; contentRepoUsage . add ( usageDto ) ; } final Set < RepositoryUsageDTO > provRepoUsage = new HashSet < > ( ) ; for ( final Map . Entry < String , StorageUsage > entry : systemDiagnostics . getProvenanceRepositoryStorageUsage ( ) . entrySet ( ) ) { final String repoName = entry . getKey ( ) ; final StorageUsage usage = entry . getValue ( ) ; final RepositoryUsageDTO usageDto = new RepositoryUsageDTO ( ) ; usageDto . setName ( repoName ) ; usageDto . setFileStoreHash ( DigestUtils . sha256Hex ( flowController . getProvenanceRepoFileStoreName ( repoName ) ) ) ; usageDto . setFreeSpace ( FormatUtils . formatDataSize ( usage . getFreeSpace ( ) ) ) ; usageDto . setFreeSpaceBytes ( usage . getFreeSpace ( ) ) ; usageDto . setTotalSpace ( FormatUtils . formatDataSize ( usage . getTotalSpace ( ) ) ) ; usageDto . setTotalSpaceBytes ( usage . getTotalSpace ( ) ) ; final double usedPercentage = ( usage . getTotalSpace ( ) - usage . getFreeSpace ( ) ) / ( double ) usage . getTotalSpace ( ) ; final String utilization = percentageFormat . format ( usedPercentage ) ; usageDto . setUtilization ( utilization ) ; provRepoUsage . add ( usageDto ) ; } final RepositoryUsageDTO flowFileRepoUsage = new RepositoryUsageDTO ( ) ; for ( final Map . Entry < String , StorageUsage > entry : systemDiagnostics . getProvenanceRepositoryStorageUsage ( ) . entrySet ( ) ) { final String repoName = entry . getKey ( ) ; final StorageUsage usage = entry . getValue ( ) ; flowFileRepoUsage . setName ( repoName ) ; flowFileRepoUsage . setFileStoreHash ( DigestUtils . sha256Hex ( flowController . getFlowRepoFileStoreName ( ) ) ) ; flowFileRepoUsage . setFreeSpace ( FormatUtils . formatDataSize ( usage . getFreeSpace ( ) ) ) ; flowFileRepoUsage . setFreeSpaceBytes ( usage . getFreeSpace ( ) ) ; flowFileRepoUsage . setTotalSpace ( FormatUtils . formatDataSize ( usage . getTotalSpace ( ) ) ) ; flowFileRepoUsage . setTotalSpaceBytes ( usage . getTotalSpace ( ) ) ; final double usedPercentage = ( usage . getTotalSpace ( ) - usage . getFreeSpace ( ) ) / ( double ) usage . getTotalSpace ( ) ; final String utilization = percentageFormat . format ( usedPercentage ) ; flowFileRepoUsage . setUtilization ( utilization ) ; } systemDiagnosticsDto . setContentRepositoryStorageUsage ( contentRepoUsage ) ; systemDiagnosticsDto . setCpuCores ( systemDiagnostics . getAvailableProcessors ( ) ) ; systemDiagnosticsDto . setCpuLoadAverage ( systemDiagnostics . getProcessorLoadAverage ( ) ) ; systemDiagnosticsDto . setFlowFileRepositoryStorageUsage ( flowFileRepoUsage ) ; systemDiagnosticsDto . setMaxHeapBytes ( systemDiagnostics . getMaxHeap ( ) ) ; systemDiagnosticsDto . setMaxHeap ( FormatUtils . formatDataSize ( systemDiagnostics . getMaxHeap ( ) ) ) ; systemDiagnosticsDto . setProvenanceRepositoryStorageUsage ( provRepoUsage ) ; final GarbageCollectionHistory gcHistory = flowController . getGarbageCollectionHistory ( ) ; final List < GarbageCollectionDiagnosticsDTO > gcDiagnostics = new ArrayList < > ( ) ; for ( final String memoryManager : gcHistory . getMemoryManagerNames ( ) ) { final List < GarbageCollectionStatus > statuses = gcHistory . getGarbageCollectionStatuses ( memoryManager ) ; final List < GCDiagnosticsSnapshotDTO > gcSnapshots = new ArrayList < > ( ) ; for ( final GarbageCollectionStatus status : statuses ) { final GCDiagnosticsSnapshotDTO snapshotDto = new GCDiagnosticsSnapshotDTO ( ) ; snapshotDto . setTimestamp ( status . getTimestamp ( ) ) ; snapshotDto . setCollectionCount ( status . getCollectionCount ( ) ) ; snapshotDto . setCollectionMillis ( status . getCollectionMillis ( ) ) ; gcSnapshots . add ( snapshotDto ) ; } gcSnapshots . sort ( Comparator . comparing ( GCDiagnosticsSnapshotDTO :: getTimestamp ) . reversed ( ) ) ; final GarbageCollectionDiagnosticsDTO gcDto = new GarbageCollectionDiagnosticsDTO ( ) ; gcDto . setMemoryManagerName ( memoryManager ) ; gcDto . setSnapshots ( gcSnapshots ) ; gcDiagnostics . add ( gcDto ) ; } systemDiagnosticsDto . setGarbageCollectionDiagnostics ( gcDiagnostics ) ; return dto ; } private List < ThreadDumpDTO > createThreadDumpDtos ( final ProcessorNode procNode ) { final List < ThreadDumpDTO > threadDumps = new ArrayList < > ( ) ; final List < ActiveThreadInfo > activeThreads = procNode . getActiveThreads ( ) ; for ( final ActiveThreadInfo threadInfo : activeThreads ) { final ThreadDumpDTO dto = new ThreadDumpDTO ( ) ; dto . setStackTrace ( threadInfo . getStackTrace ( ) ) ; dto . setThreadActiveMillis ( threadInfo . getActiveMillis ( ) ) ; dto . setThreadName ( threadInfo . getThreadName ( ) ) ; dto . setTaskTerminated ( threadInfo . isTerminated ( ) ) ; threadDumps . add ( dto ) ; } return threadDumps ; } public ProcessorConfigDTO createProcessorConfigDto ( final ProcessorNode procNode ) { if ( procNode == null ) { return null ; } final ProcessorConfigDTO dto = new ProcessorConfigDTO ( ) ; final Map < PropertyDescriptor , String > sortedProperties = new TreeMap < > ( new Comparator < PropertyDescriptor > ( ) { @ Override public int compare ( final PropertyDescriptor o1 , final PropertyDescriptor o2 ) { return Collator . getInstance ( Locale . US ) . compare ( o1 . getName ( ) , o2 . getName ( ) ) ; } } ) ; sortedProperties . putAll ( procNode . getProperties ( ) ) ; final Processor processor = procNode . getProcessor ( ) ; final Map < PropertyDescriptor , String > orderedProperties = new LinkedHashMap < > ( ) ; final List < PropertyDescriptor > descriptors = processor . getPropertyDescriptors ( ) ; if ( descriptors != null && ! descriptors . isEmpty ( ) ) { for ( final PropertyDescriptor descriptor : descriptors ) { orderedProperties . put ( descriptor , null ) ; } } orderedProperties . putAll ( sortedProperties ) ; dto . setDescriptors ( new LinkedHashMap < String , PropertyDescriptorDTO > ( ) ) ; dto . setProperties ( new LinkedHashMap < String , String > ( ) ) ; for ( final Map . Entry < PropertyDescriptor , String > entry : orderedProperties . entrySet ( ) ) { final PropertyDescriptor descriptor = entry . getKey ( ) ; dto . getDescriptors ( ) . put ( descriptor . getName ( ) , createPropertyDescriptorDto ( descriptor , procNode . getProcessGroup ( ) . getIdentifier ( ) ) ) ; String propertyValue = entry . getValue ( ) ; if ( propertyValue != null && descriptor . isSensitive ( ) ) { propertyValue = SENSITIVE_VALUE_MASK ; } else if ( propertyValue == null && descriptor . getDefaultValue ( ) != null ) { propertyValue = descriptor . getDefaultValue ( ) ; } dto . getProperties ( ) . put ( descriptor . getName ( ) , propertyValue ) ; } dto . setSchedulingPeriod ( procNode . getSchedulingPeriod ( ) ) ; dto . setPenaltyDuration ( procNode . getPenalizationPeriod ( ) ) ; dto . setYieldDuration ( procNode . getYieldPeriod ( ) ) ; dto . setRunDurationMillis ( procNode . getRunDuration ( TimeUnit . MILLISECONDS ) ) ; dto . setConcurrentlySchedulableTaskCount ( procNode . getMaxConcurrentTasks ( ) ) ; dto . setLossTolerant ( procNode . isLossTolerant ( ) ) ; dto . setComments ( procNode . getComments ( ) ) ; dto . setBulletinLevel ( procNode . getBulletinLevel ( ) . name ( ) ) ; dto . setSchedulingStrategy ( procNode . getSchedulingStrategy ( ) . name ( ) ) ; dto . setExecutionNode ( procNode . getExecutionNode ( ) . name ( ) ) ; dto . setAnnotationData ( procNode . getAnnotationData ( ) ) ; final Map < String , String > defaultConcurrentTasks = new HashMap < > ( ) ; defaultConcurrentTasks . put ( SchedulingStrategy . TIMER_DRIVEN . name ( ) , String . valueOf ( SchedulingStrategy . TIMER_DRIVEN . getDefaultConcurrentTasks ( ) ) ) ; defaultConcurrentTasks . put ( SchedulingStrategy . EVENT_DRIVEN . name ( ) , String . valueOf ( SchedulingStrategy . EVENT_DRIVEN . getDefaultConcurrentTasks ( ) ) ) ; defaultConcurrentTasks . put ( SchedulingStrategy . CRON_DRIVEN . name ( ) , String . valueOf ( SchedulingStrategy . CRON_DRIVEN . getDefaultConcurrentTasks ( ) ) ) ; dto . setDefaultConcurrentTasks ( defaultConcurrentTasks ) ; final Map < String , String > defaultSchedulingPeriod = new HashMap < > ( ) ; defaultSchedulingPeriod . put ( SchedulingStrategy . TIMER_DRIVEN . name ( ) , SchedulingStrategy . TIMER_DRIVEN . getDefaultSchedulingPeriod ( ) ) ; defaultSchedulingPeriod . put ( SchedulingStrategy . CRON_DRIVEN . name ( ) , SchedulingStrategy . CRON_DRIVEN . getDefaultSchedulingPeriod ( ) ) ; dto . setDefaultSchedulingPeriod ( defaultSchedulingPeriod ) ; return dto ; } public PropertyDescriptorDTO createPropertyDescriptorDto ( final PropertyDescriptor propertyDescriptor , final String groupId ) { if ( propertyDescriptor == null ) { return null ; } final PropertyDescriptorDTO dto = new PropertyDescriptorDTO ( ) ; dto . setName ( propertyDescriptor . getName ( ) ) ; dto . setDisplayName ( propertyDescriptor . getDisplayName ( ) ) ; dto . setRequired ( propertyDescriptor . isRequired ( ) ) ; dto . setSensitive ( propertyDescriptor . isSensitive ( ) ) ; dto . setDynamic ( propertyDescriptor . isDynamic ( ) ) ; dto . setDescription ( propertyDescriptor . getDescription ( ) ) ; dto . setDefaultValue ( propertyDescriptor . getDefaultValue ( ) ) ; dto . setSupportsEl ( propertyDescriptor . isExpressionLanguageSupported ( ) ) ; String description = propertyDescriptor . isExpressionLanguageSupported ( ) && propertyDescriptor . getExpressionLanguageScope ( ) . equals ( ExpressionLanguageScope . NONE ) ? ""true (undefined scope)"" : propertyDescriptor . getExpressionLanguageScope ( ) . getDescription ( ) ; dto . setExpressionLanguageScope ( description ) ; if ( propertyDescriptor . getControllerServiceDefinition ( ) != null ) { final Class serviceClass = propertyDescriptor . getControllerServiceDefinition ( ) ; final Bundle serviceBundle = extensionManager . getBundle ( serviceClass . getClassLoader ( ) ) ; dto . setIdentifiesControllerService ( serviceClass . getName ( ) ) ; dto . setIdentifiesControllerServiceBundle ( createBundleDto ( serviceBundle . getBundleDetails ( ) . getCoordinate ( ) ) ) ; } final Class < ? extends ControllerService > serviceDefinition = propertyDescriptor . getControllerServiceDefinition ( ) ; if ( propertyDescriptor . getAllowableValues ( ) == null ) { if ( serviceDefinition == null ) { dto . setAllowableValues ( null ) ; } else { final List < AllowableValueEntity > allowableValues = new ArrayList < > ( ) ; final List < String > controllerServiceIdentifiers = new ArrayList < > ( controllerServiceProvider . getControllerServiceIdentifiers ( serviceDefinition , groupId ) ) ; Collections . sort ( controllerServiceIdentifiers , Collator . getInstance ( Locale . US ) ) ; for ( final String serviceIdentifier : controllerServiceIdentifiers ) { final ControllerServiceNode service = controllerServiceProvider . getControllerServiceNode ( serviceIdentifier ) ; final boolean isServiceAuthorized = service . isAuthorized ( authorizer , RequestAction . READ , NiFiUserUtils . getNiFiUser ( ) ) ; final String displayName = isServiceAuthorized ? service . getName ( ) : serviceIdentifier ; final AllowableValueDTO allowableValue = new AllowableValueDTO ( ) ; allowableValue . setDisplayName ( displayName ) ; allowableValue . setValue ( serviceIdentifier ) ; allowableValues . add ( entityFactory . createAllowableValueEntity ( allowableValue , isServiceAuthorized ) ) ; } dto . setAllowableValues ( allowableValues ) ; } } else { final List < AllowableValueEntity > allowableValues = new ArrayList < > ( ) ; for ( final AllowableValue allowableValue : propertyDescriptor . getAllowableValues ( ) ) { final AllowableValueDTO allowableValueDto = new AllowableValueDTO ( ) ; allowableValueDto . setDisplayName ( allowableValue . getDisplayName ( ) ) ; allowableValueDto . setValue ( allowableValue . getValue ( ) ) ; allowableValueDto . setDescription ( allowableValue . getDescription ( ) ) ; allowableValues . add ( entityFactory . createAllowableValueEntity ( allowableValueDto , true ) ) ; } dto . setAllowableValues ( allowableValues ) ; } return dto ; } public LabelDTO copy ( final LabelDTO original ) { final LabelDTO copy = new LabelDTO ( ) ; copy . setId ( original . getId ( ) ) ; copy . setParentGroupId ( original . getParentGroupId ( ) ) ; copy . setLabel ( original . getLabel ( ) ) ; copy . setStyle ( copy ( original . getStyle ( ) ) ) ; copy . setPosition ( original . getPosition ( ) ) ; copy . setWidth ( original . getWidth ( ) ) ; copy . setHeight ( original . getHeight ( ) ) ; copy . setVersionedComponentId ( original . getVersionedComponentId ( ) ) ; return copy ; } public ControllerServiceDTO copy ( final ControllerServiceDTO original ) { final ControllerServiceDTO copy = new ControllerServiceDTO ( ) ; copy . setAnnotationData ( original . getAnnotationData ( ) ) ; copy . setControllerServiceApis ( original . getControllerServiceApis ( ) ) ; copy . setComments ( original . getComments ( ) ) ; copy . setCustomUiUrl ( original . getCustomUiUrl ( ) ) ; copy . setDescriptors ( copy ( original . getDescriptors ( ) ) ) ; copy . setId ( original . getId ( ) ) ; copy . setParentGroupId ( original . getParentGroupId ( ) ) ; copy . setName ( original . getName ( ) ) ; copy . setProperties ( copy ( original . getProperties ( ) ) ) ; copy . setReferencingComponents ( copy ( original . getReferencingComponents ( ) ) ) ; copy . setState ( original . getState ( ) ) ; copy . setType ( original . getType ( ) ) ; copy . setBundle ( copy ( original . getBundle ( ) ) ) ; copy . setExtensionMissing ( original . getExtensionMissing ( ) ) ; copy . setMultipleVersionsAvailable ( original . getMultipleVersionsAvailable ( ) ) ; copy . setPersistsState ( original . getPersistsState ( ) ) ; copy . setValidationErrors ( copy ( original . getValidationErrors ( ) ) ) ; copy . setValidationStatus ( original . getValidationStatus ( ) ) ; copy . setVersionedComponentId ( original . getVersionedComponentId ( ) ) ; return copy ; } public FunnelDTO copy ( final FunnelDTO original ) { final FunnelDTO copy = new FunnelDTO ( ) ; copy . setId ( original . getId ( ) ) ; copy . setParentGroupId ( original . getParentGroupId ( ) ) ; copy . setPosition ( original . getPosition ( ) ) ; copy . setVersionedComponentId ( original . getVersionedComponentId ( ) ) ; return copy ; } private < T > List < T > copy ( final List < T > original ) { if ( original == null ) { return null ; } else { return new ArrayList < > ( original ) ; } } private < T > List < T > copy ( final Collection < T > original ) { if ( original == null ) { return null ; } else { return new ArrayList < > ( original ) ; } } private < T > Set < T > copy ( final Set < T > original ) { if ( original == null ) { return null ; } else { return new LinkedHashSet < > ( original ) ; } } private < S , T > Map < S , T > copy ( final Map < S , T > original ) { if ( original == null ) { return null ; } else { return new LinkedHashMap < > ( original ) ; } } public BundleDTO copy ( final BundleDTO original ) { if ( original == null ) { return null ; } final BundleDTO copy = new BundleDTO ( ) ; copy . setGroup ( original . getGroup ( ) ) ; copy . setArtifact ( original . getArtifact ( ) ) ; copy . setVersion ( original . getVersion ( ) ) ; return copy ; } public ProcessorDTO copy ( final ProcessorDTO original ) { final ProcessorDTO copy = new ProcessorDTO ( ) ; copy . setConfig ( copy ( original . getConfig ( ) ) ) ; copy . setPosition ( original . getPosition ( ) ) ; copy . setId ( original . getId ( ) ) ; copy . setName ( original . getName ( ) ) ; copy . setDescription ( original . getDescription ( ) ) ; copy . setParentGroupId ( original . getParentGroupId ( ) ) ; copy . setRelationships ( copy ( original . getRelationships ( ) ) ) ; copy . setState ( original . getState ( ) ) ; copy . setStyle ( copy ( original . getStyle ( ) ) ) ; copy . setType ( original . getType ( ) ) ; copy . setBundle ( copy ( original . getBundle ( ) ) ) ; copy . setSupportsParallelProcessing ( original . getSupportsParallelProcessing ( ) ) ; copy . setSupportsEventDriven ( original . getSupportsEventDriven ( ) ) ; copy . setSupportsBatching ( original . getSupportsBatching ( ) ) ; copy . setPersistsState ( original . getPersistsState ( ) ) ; copy . setExecutionNodeRestricted ( original . isExecutionNodeRestricted ( ) ) ; copy . setExtensionMissing ( original . getExtensionMissing ( ) ) ; copy . setMultipleVersionsAvailable ( original . getMultipleVersionsAvailable ( ) ) ; copy . setValidationErrors ( copy ( original . getValidationErrors ( ) ) ) ; copy . setValidationStatus ( original . getValidationStatus ( ) ) ; copy . setVersionedComponentId ( original . getVersionedComponentId ( ) ) ; return copy ; } private ProcessorConfigDTO copy ( final ProcessorConfigDTO original ) { final ProcessorConfigDTO copy = new ProcessorConfigDTO ( ) ; copy . setAnnotationData ( original . getAnnotationData ( ) ) ; copy . setAutoTerminatedRelationships ( copy ( original . getAutoTerminatedRelationships ( ) ) ) ; copy . setComments ( original . getComments ( ) ) ; copy . setSchedulingStrategy ( original . getSchedulingStrategy ( ) ) ; copy . setExecutionNode ( original . getExecutionNode ( ) ) ; copy . setConcurrentlySchedulableTaskCount ( original . getConcurrentlySchedulableTaskCount ( ) ) ; copy . setCustomUiUrl ( original . getCustomUiUrl ( ) ) ; copy . setDescriptors ( copy ( original . getDescriptors ( ) ) ) ; copy . setProperties ( copy ( original . getProperties ( ) ) ) ; copy . setSchedulingPeriod ( original . getSchedulingPeriod ( ) ) ; copy . setPenaltyDuration ( original . getPenaltyDuration ( ) ) ; copy . setYieldDuration ( original . getYieldDuration ( ) ) ; copy . setRunDurationMillis ( original . getRunDurationMillis ( ) ) ; copy . setBulletinLevel ( original . getBulletinLevel ( ) ) ; copy . setDefaultConcurrentTasks ( original . getDefaultConcurrentTasks ( ) ) ; copy . setDefaultSchedulingPeriod ( original . getDefaultSchedulingPeriod ( ) ) ; copy . setLossTolerant ( original . isLossTolerant ( ) ) ; return copy ; } public ConnectionDTO copy ( final ConnectionDTO original ) { final ConnectionDTO copy = new ConnectionDTO ( ) ; copy . setAvailableRelationships ( copy ( original . getAvailableRelationships ( ) ) ) ; copy . setDestination ( original . getDestination ( ) ) ; copy . setPosition ( original . getPosition ( ) ) ; copy . setId ( original . getId ( ) ) ; copy . setName ( original . getName ( ) ) ; copy . setParentGroupId ( original . getParentGroupId ( ) ) ; copy . setSelectedRelationships ( copy ( original . getSelectedRelationships ( ) ) ) ; copy . setFlowFileExpiration ( original . getFlowFileExpiration ( ) ) ; copy . setBackPressureObjectThreshold ( original . getBackPressureObjectThreshold ( ) ) ; copy . setBackPressureDataSizeThreshold ( original . getBackPressureDataSizeThreshold ( ) ) ; copy . setPrioritizers ( copy ( original . getPrioritizers ( ) ) ) ; copy . setSource ( original . getSource ( ) ) ; copy . setzIndex ( original . getzIndex ( ) ) ; copy . setLabelIndex ( original . getLabelIndex ( ) ) ; copy . setBends ( copy ( original . getBends ( ) ) ) ; copy . setLoadBalancePartitionAttribute ( original . getLoadBalancePartitionAttribute ( ) ) ; copy . setLoadBalanceStrategy ( original . getLoadBalanceStrategy ( ) ) ; copy . setLoadBalanceCompression ( original . getLoadBalanceCompression ( ) ) ; copy . setLoadBalanceStatus ( original . getLoadBalanceStatus ( ) ) ; copy . setVersionedComponentId ( original . getVersionedComponentId ( ) ) ; return copy ; } public BulletinDTO copy ( final BulletinDTO original ) { final BulletinDTO copy = new BulletinDTO ( ) ; copy . setId ( original . getId ( ) ) ; copy . setTimestamp ( original . getTimestamp ( ) ) ; copy . setGroupId ( original . getGroupId ( ) ) ; copy . setSourceId ( original . getSourceId ( ) ) ; copy . setSourceName ( original . getSourceName ( ) ) ; copy . setCategory ( original . getCategory ( ) ) ; copy . setLevel ( original . getLevel ( ) ) ; copy . setMessage ( original . getMessage ( ) ) ; copy . setNodeAddress ( original . getNodeAddress ( ) ) ; return copy ; } public PortDTO copy ( final PortDTO original ) { final PortDTO copy = new PortDTO ( ) ; copy . setPosition ( original . getPosition ( ) ) ; copy . setId ( original . getId ( ) ) ; copy . setName ( original . getName ( ) ) ; copy . setComments ( original . getComments ( ) ) ; copy . setParentGroupId ( original . getParentGroupId ( ) ) ; copy . setState ( original . getState ( ) ) ; copy . setType ( original . getType ( ) ) ; copy . setTransmitting ( original . isTransmitting ( ) ) ; copy . setConcurrentlySchedulableTaskCount ( original . getConcurrentlySchedulableTaskCount ( ) ) ; copy . setUserAccessControl ( copy ( original . getUserAccessControl ( ) ) ) ; copy . setGroupAccessControl ( copy ( original . getGroupAccessControl ( ) ) ) ; copy . setValidationErrors ( copy ( original . getValidationErrors ( ) ) ) ; copy . setVersionedComponentId ( original . getVersionedComponentId ( ) ) ; return copy ; } public RemoteProcessGroupPortDTO copy ( final RemoteProcessGroupPortDTO original ) { final RemoteProcessGroupPortDTO copy = new RemoteProcessGroupPortDTO ( ) ; copy . setId ( original . getId ( ) ) ; copy . setTargetId ( original . getTargetId ( ) ) ; copy . setGroupId ( original . getGroupId ( ) ) ; copy . setName ( original . getName ( ) ) ; copy . setComments ( original . getComments ( ) ) ; copy . setConnected ( original . isConnected ( ) ) ; copy . setTargetRunning ( original . isTargetRunning ( ) ) ; copy . setTransmitting ( original . isTransmitting ( ) ) ; copy . setConcurrentlySchedulableTaskCount ( original . getConcurrentlySchedulableTaskCount ( ) ) ; copy . setUseCompression ( original . getUseCompression ( ) ) ; copy . setExists ( original . getExists ( ) ) ; copy . setVersionedComponentId ( original . getVersionedComponentId ( ) ) ; final BatchSettingsDTO batchOrg = original . getBatchSettings ( ) ; if ( batchOrg != null ) { final BatchSettingsDTO batchCopy = new BatchSettingsDTO ( ) ; batchCopy . setCount ( batchOrg . getCount ( ) ) ; batchCopy . setSize ( batchOrg . getSize ( ) ) ; batchCopy . setDuration ( batchOrg . getDuration ( ) ) ; copy . setBatchSettings ( batchCopy ) ; } return copy ; } public ProcessGroupDTO copy ( final ProcessGroupDTO original , final boolean deep ) { final ProcessGroupDTO copy = new ProcessGroupDTO ( ) ; copy . setComments ( original . getComments ( ) ) ; copy . setContents ( copy ( original . getContents ( ) , deep ) ) ; copy . setPosition ( original . getPosition ( ) ) ; copy . setId ( original . getId ( ) ) ; copy . setInputPortCount ( original . getInputPortCount ( ) ) ; copy . setInvalidCount ( original . getInvalidCount ( ) ) ; copy . setName ( original . getName ( ) ) ; copy . setVersionControlInformation ( copy ( original . getVersionControlInformation ( ) ) ) ; copy . setOutputPortCount ( original . getOutputPortCount ( ) ) ; copy . setParentGroupId ( original . getParentGroupId ( ) ) ; copy . setVersionedComponentId ( original . getVersionedComponentId ( ) ) ; copy . setRunningCount ( original . getRunningCount ( ) ) ; copy . setStoppedCount ( original . getStoppedCount ( ) ) ; copy . setDisabledCount ( original . getDisabledCount ( ) ) ; copy . setActiveRemotePortCount ( original . getActiveRemotePortCount ( ) ) ; copy . setInactiveRemotePortCount ( original . getInactiveRemotePortCount ( ) ) ; copy . setUpToDateCount ( original . getUpToDateCount ( ) ) ; copy . setLocallyModifiedCount ( original . getLocallyModifiedCount ( ) ) ; copy . setStaleCount ( original . getStaleCount ( ) ) ; copy . setLocallyModifiedAndStaleCount ( original . getLocallyModifiedAndStaleCount ( ) ) ; copy . setSyncFailureCount ( original . getSyncFailureCount ( ) ) ; if ( original . getVariables ( ) != null ) { copy . setVariables ( new HashMap < > ( original . getVariables ( ) ) ) ; } return copy ; } public VersionControlInformationDTO copy ( final VersionControlInformationDTO original ) { if ( original == null ) { return null ; } final VersionControlInformationDTO copy = new VersionControlInformationDTO ( ) ; copy . setRegistryId ( original . getRegistryId ( ) ) ; copy . setRegistryName ( original . getRegistryName ( ) ) ; copy . setBucketId ( original . getBucketId ( ) ) ; copy . setBucketName ( original . getBucketName ( ) ) ; copy . setFlowId ( original . getFlowId ( ) ) ; copy . setFlowName ( original . getFlowName ( ) ) ; copy . setFlowDescription ( original . getFlowDescription ( ) ) ; copy . setVersion ( original . getVersion ( ) ) ; copy . setState ( original . getState ( ) ) ; copy . setStateExplanation ( original . getStateExplanation ( ) ) ; return copy ; } public RemoteProcessGroupDTO copy ( final RemoteProcessGroupDTO original ) { final RemoteProcessGroupContentsDTO originalContents = original . getContents ( ) ; final RemoteProcessGroupContentsDTO copyContents = new RemoteProcessGroupContentsDTO ( ) ; if ( originalContents . getInputPorts ( ) != null ) { final Set < RemoteProcessGroupPortDTO > inputPorts = new HashSet < > ( ) ; for ( final RemoteProcessGroupPortDTO port : originalContents . getInputPorts ( ) ) { inputPorts . add ( copy ( port ) ) ; } copyContents . setInputPorts ( inputPorts ) ; } if ( originalContents . getOutputPorts ( ) != null ) { final Set < RemoteProcessGroupPortDTO > outputPorts = new HashSet < > ( ) ; for ( final RemoteProcessGroupPortDTO port : originalContents . getOutputPorts ( ) ) { outputPorts . add ( copy ( port ) ) ; } copyContents . setOutputPorts ( outputPorts ) ; } final RemoteProcessGroupDTO copy = new RemoteProcessGroupDTO ( ) ; copy . setComments ( original . getComments ( ) ) ; copy . setPosition ( original . getPosition ( ) ) ; copy . setId ( original . getId ( ) ) ; copy . setCommunicationsTimeout ( original . getCommunicationsTimeout ( ) ) ; copy . setYieldDuration ( original . getYieldDuration ( ) ) ; copy . setName ( original . getName ( ) ) ; copy . setInputPortCount ( original . getInputPortCount ( ) ) ; copy . setOutputPortCount ( original . getOutputPortCount ( ) ) ; copy . setActiveRemoteInputPortCount ( original . getActiveRemoteInputPortCount ( ) ) ; copy . setInactiveRemoteInputPortCount ( original . getInactiveRemoteInputPortCount ( ) ) ; copy . setActiveRemoteOutputPortCount ( original . getActiveRemoteOutputPortCount ( ) ) ; copy . setInactiveRemoteOutputPortCount ( original . getInactiveRemoteOutputPortCount ( ) ) ; copy . setParentGroupId ( original . getParentGroupId ( ) ) ; copy . setTargetUris ( original . getTargetUris ( ) ) ; copy . setTransportProtocol ( original . getTransportProtocol ( ) ) ; copy . setProxyHost ( original . getProxyHost ( ) ) ; copy . setProxyPort ( original . getProxyPort ( ) ) ; copy . setProxyUser ( original . getProxyUser ( ) ) ; copy . setProxyPassword ( original . getProxyPassword ( ) ) ; copy . setLocalNetworkInterface ( original . getLocalNetworkInterface ( ) ) ; copy . setVersionedComponentId ( original . getVersionedComponentId ( ) ) ; copy . setContents ( copyContents ) ; return copy ; } public ConnectableDTO createConnectableDto ( final PortDTO port , final ConnectableType type ) { final ConnectableDTO connectable = new ConnectableDTO ( ) ; connectable . setGroupId ( port . getParentGroupId ( ) ) ; connectable . setId ( port . getId ( ) ) ; connectable . setName ( port . getName ( ) ) ; connectable . setType ( type . name ( ) ) ; connectable . setVersionedComponentId ( port . getVersionedComponentId ( ) ) ; return connectable ; } public ConnectableDTO createConnectableDto ( final ProcessorDTO processor ) { final ConnectableDTO connectable = new ConnectableDTO ( ) ; connectable . setGroupId ( processor . getParentGroupId ( ) ) ; connectable . setId ( processor . getId ( ) ) ; connectable . setName ( processor . getName ( ) ) ; connectable . setType ( ConnectableType . PROCESSOR . name ( ) ) ; connectable . setVersionedComponentId ( processor . getVersionedComponentId ( ) ) ; return connectable ; } public ConnectableDTO createConnectableDto ( final FunnelDTO funnel ) { final ConnectableDTO connectable = new ConnectableDTO ( ) ; connectable . setGroupId ( funnel . getParentGroupId ( ) ) ; connectable . setId ( funnel . getId ( ) ) ; connectable . setType ( ConnectableType . FUNNEL . name ( ) ) ; connectable . setVersionedComponentId ( funnel . getVersionedComponentId ( ) ) ; return connectable ; } public ConnectableDTO createConnectableDto ( final RemoteProcessGroupPortDTO remoteGroupPort , final ConnectableType type ) { final ConnectableDTO connectable = new ConnectableDTO ( ) ; connectable . setGroupId ( remoteGroupPort . getGroupId ( ) ) ; connectable . setId ( remoteGroupPort . getId ( ) ) ; connectable . setName ( remoteGroupPort . getName ( ) ) ; connectable . setType ( type . name ( ) ) ; connectable . setVersionedComponentId ( connectable . getVersionedComponentId ( ) ) ; return connectable ; } private FlowSnippetDTO copy ( final FlowSnippetDTO original , final boolean deep ) { final FlowSnippetDTO copy = new FlowSnippetDTO ( ) ; final Set < ConnectionDTO > connections = new LinkedHashSet < > ( ) ; final Set < ProcessGroupDTO > groups = new LinkedHashSet < > ( ) ; final Set < PortDTO > inputPorts = new LinkedHashSet < > ( ) ; final Set < PortDTO > outputPorts = new LinkedHashSet < > ( ) ; final Set < LabelDTO > labels = new LinkedHashSet < > ( ) ; final Set < ProcessorDTO > processors = new LinkedHashSet < > ( ) ; final Set < RemoteProcessGroupDTO > remoteProcessGroups = new LinkedHashSet < > ( ) ; final Set < FunnelDTO > funnels = new LinkedHashSet < > ( ) ; final Set < ControllerServiceDTO > controllerServices = new LinkedHashSet < > ( ) ; if ( deep ) { for ( final ProcessGroupDTO group : original . getProcessGroups ( ) ) { groups . add ( copy ( group , deep ) ) ; } for ( final PortDTO port : original . getInputPorts ( ) ) { inputPorts . add ( copy ( port ) ) ; } for ( final PortDTO port : original . getOutputPorts ( ) ) { outputPorts . add ( copy ( port ) ) ; } for ( final LabelDTO label : original . getLabels ( ) ) { labels . add ( copy ( label ) ) ; } for ( final ProcessorDTO processor : original . getProcessors ( ) ) { processors . add ( copy ( processor ) ) ; } for ( final RemoteProcessGroupDTO remoteGroup : original . getRemoteProcessGroups ( ) ) { remoteProcessGroups . add ( copy ( remoteGroup ) ) ; } for ( final FunnelDTO funnel : original . getFunnels ( ) ) { funnels . add ( copy ( funnel ) ) ; } for ( final ConnectionDTO connection : original . getConnections ( ) ) { connections . add ( copy ( connection ) ) ; } for ( final ControllerServiceDTO controllerService : original . getControllerServices ( ) ) { controllerServices . add ( copy ( controllerService ) ) ; } } else { if ( original . getConnections ( ) != null ) { connections . addAll ( copy ( original . getConnections ( ) ) ) ; } if ( original . getProcessGroups ( ) != null ) { groups . addAll ( copy ( original . getProcessGroups ( ) ) ) ; } if ( original . getInputPorts ( ) != null ) { inputPorts . addAll ( copy ( original . getInputPorts ( ) ) ) ; } if ( original . getOutputPorts ( ) != null ) { outputPorts . addAll ( copy ( original . getOutputPorts ( ) ) ) ; } if ( original . getLabels ( ) != null ) { labels . addAll ( copy ( original . getLabels ( ) ) ) ; } if ( original . getProcessors ( ) != null ) { processors . addAll ( copy ( original . getProcessors ( ) ) ) ; } if ( original . getRemoteProcessGroups ( ) != null ) { remoteProcessGroups . addAll ( copy ( original . getRemoteProcessGroups ( ) ) ) ; } if ( original . getFunnels ( ) != null ) { funnels . addAll ( copy ( original . getFunnels ( ) ) ) ; } if ( original . getControllerServices ( ) != null ) { controllerServices . addAll ( copy ( original . getControllerServices ( ) ) ) ; } } copy . setConnections ( connections ) ; copy . setProcessGroups ( groups ) ; copy . setInputPorts ( inputPorts ) ; copy . setLabels ( labels ) ; copy . setOutputPorts ( outputPorts ) ; copy . setProcessors ( processors ) ; copy . setRemoteProcessGroups ( remoteProcessGroups ) ; copy . setFunnels ( funnels ) ; copy . setControllerServices ( controllerServices ) ; return copy ; } public RevisionDTO createRevisionDTO ( final FlowModification lastMod ) { final Revision revision = lastMod . getRevision ( ) ; final RevisionDTO revisionDTO = new RevisionDTO ( ) ; revisionDTO . setVersion ( revision . getVersion ( ) ) ; revisionDTO . setClientId ( revision . getClientId ( ) ) ; revisionDTO . setLastModifier ( lastMod . getLastModifier ( ) ) ; return revisionDTO ; } public RevisionDTO createRevisionDTO ( final Revision revision ) { final RevisionDTO dto = new RevisionDTO ( ) ; dto . setVersion ( revision . getVersion ( ) ) ; dto . setClientId ( revision . getClientId ( ) ) ; return dto ; } public NodeDTO createNodeDTO ( final NodeIdentifier nodeId , final NodeConnectionStatus status , final NodeHeartbeat nodeHeartbeat , final List < NodeEvent > events , final Set < String > roles ) { final NodeDTO nodeDto = new NodeDTO ( ) ; nodeDto . setNodeId ( nodeId . getId ( ) ) ; nodeDto . setAddress ( nodeId . getApiAddress ( ) ) ; nodeDto . setApiPort ( nodeId . getApiPort ( ) ) ; nodeDto . setStatus ( status . getState ( ) . name ( ) ) ; nodeDto . setRoles ( roles ) ; if ( status . getConnectionRequestTime ( ) != null ) { final Date connectionRequested = new Date ( status . getConnectionRequestTime ( ) ) ; nodeDto . setConnectionRequested ( connectionRequested ) ; } if ( nodeHeartbeat != null ) { final Date heartbeat = new Date ( nodeHeartbeat . getTimestamp ( ) ) ; nodeDto . setHeartbeat ( heartbeat ) ; nodeDto . setNodeStartTime ( new Date ( nodeHeartbeat . getSystemStartTime ( ) ) ) ; nodeDto . setActiveThreadCount ( nodeHeartbeat . getActiveThreadCount ( ) ) ; nodeDto . setQueued ( FormatUtils . formatCount ( nodeHeartbeat . getFlowFileCount ( ) ) + "" / "" + FormatUtils . formatDataSize ( nodeHeartbeat . getFlowFileBytes ( ) ) ) ; } final List < NodeEvent > nodeEvents = new ArrayList < > ( events ) ; Collections . sort ( nodeEvents , new Comparator < NodeEvent > ( ) { @ Override public int compare ( final NodeEvent event1 , final NodeEvent event2 ) { return new Date ( event2 . getTimestamp ( ) ) . compareTo ( new Date ( event1 . getTimestamp ( ) ) ) ; } } ) ; final List < NodeEventDTO > nodeEventDtos = new ArrayList < > ( ) ; for ( final NodeEvent event : nodeEvents ) { final NodeEventDTO nodeEventDto = new NodeEventDTO ( ) ; nodeEventDtos . add ( nodeEventDto ) ; nodeEventDto . setMessage ( event . getMessage ( ) ) ; nodeEventDto . setCategory ( event . getSeverity ( ) . name ( ) ) ; nodeEventDto . setTimestamp ( new Date ( event . getTimestamp ( ) ) ) ; } nodeDto . setEvents ( nodeEventDtos ) ; return nodeDto ; } public RegistryDTO createRegistryDto ( FlowRegistry registry ) { final RegistryDTO dto = new RegistryDTO ( ) ; dto . setDescription ( registry . getDescription ( ) ) ; dto . setId ( registry . getIdentifier ( ) ) ; dto . setName ( registry . getName ( ) ) ; dto . setUri ( registry . getURL ( ) ) ; return dto ; } public void setControllerServiceProvider ( final ControllerServiceProvider controllerServiceProvider ) { this . controllerServiceProvider = controllerServiceProvider ; } public void setAuthorizer ( final Authorizer authorizer ) { this . authorizer = authorizer ; } public void setEntityFactory ( final EntityFactory entityFactory ) { this . entityFactory = entityFactory ; } public void setBulletinRepository ( BulletinRepository bulletinRepository ) { this . bulletinRepository = bulletinRepository ; } public void setExtensionManager ( ExtensionManager extensionManager ) { this . extensionManager = extensionManager ; } }",Smelly
"public static class SnapshotCopy extends INodeAttributes . SnapshotCopy implements INodeFileAttributes { private final long header ; public SnapshotCopy ( byte [ ] name , PermissionStatus permissions , long modificationTime , long accessTime , short replication , long preferredBlockSize ) { super ( name , permissions , modificationTime , accessTime ) ; final long h = HeaderFormat . combineReplication ( 0L , replication ) ; header = HeaderFormat . combinePreferredBlockSize ( h , preferredBlockSize ) ; } public SnapshotCopy ( INodeFile file ) { super ( file ) ; this . header = file . getHeaderLong ( ) ; } @ Override public short getFileReplication ( ) { return HeaderFormat . getReplication ( header ) ; } @ Override public long getPreferredBlockSize ( ) { return HeaderFormat . getPreferredBlockSize ( header ) ; } @ Override public long getHeaderLong ( ) { return header ; } }",No
" @ SeeAlso ( MergeContent . class ) public class UnpackContent extends AbstractProcessor { public static final String FRAGMENT_ID = FragmentAttributes . FRAGMENT_ID . key ( ) ; public static final String FRAGMENT_INDEX = FragmentAttributes . FRAGMENT_INDEX . key ( ) ; public static final String FRAGMENT_COUNT = FragmentAttributes . FRAGMENT_COUNT . key ( ) ; public static final String SEGMENT_ORIGINAL_FILENAME = FragmentAttributes . SEGMENT_ORIGINAL_FILENAME . key ( ) ; public static final String AUTO_DETECT_FORMAT_NAME = ""use mime.type attribute"" ; public static final String TAR_FORMAT_NAME = ""tar"" ; public static final String ZIP_FORMAT_NAME = ""zip"" ; public static final String FLOWFILE_STREAM_FORMAT_V3_NAME = ""flowfile-stream-v3"" ; public static final String FLOWFILE_STREAM_FORMAT_V2_NAME = ""flowfile-stream-v2"" ; public static final String FLOWFILE_TAR_FORMAT_NAME = ""flowfile-tar-v1"" ; public static final String OCTET_STREAM = ""application/octet-stream"" ; public static final PropertyDescriptor PACKAGING_FORMAT = new PropertyDescriptor . Builder ( ) . name ( ""Packaging Format"" ) . description ( ""The Packaging Format used to create the file"" ) . required ( true ) . allowableValues ( PackageFormat . AUTO_DETECT_FORMAT . toString ( ) , PackageFormat . TAR_FORMAT . toString ( ) , PackageFormat . ZIP_FORMAT . toString ( ) , PackageFormat . FLOWFILE_STREAM_FORMAT_V3 . toString ( ) , PackageFormat . FLOWFILE_STREAM_FORMAT_V2 . toString ( ) , PackageFormat . FLOWFILE_TAR_FORMAT . toString ( ) ) . defaultValue ( PackageFormat . AUTO_DETECT_FORMAT . toString ( ) ) . build ( ) ; public static final PropertyDescriptor FILE_FILTER = new PropertyDescriptor . Builder ( ) . name ( ""File Filter"" ) . description ( ""Only files contained in the archive whose names match the given regular expression will be extracted (tar/zip only)"" ) . required ( true ) . defaultValue ( "".*"" ) . addValidator ( StandardValidators . REGULAR_EXPRESSION_VALIDATOR ) . build ( ) ; public static final Relationship REL_SUCCESS = new Relationship . Builder ( ) . name ( ""success"" ) . description ( ""Unpacked FlowFiles are sent to this relationship"" ) . build ( ) ; public static final Relationship REL_ORIGINAL = new Relationship . Builder ( ) . name ( ""original"" ) . description ( ""The original FlowFile is sent to this relationship after it has been successfully unpacked"" ) . build ( ) ; public static final Relationship REL_FAILURE = new Relationship . Builder ( ) . name ( ""failure"" ) . description ( ""The original FlowFile is sent to this relationship when it cannot be unpacked for some reason"" ) . build ( ) ; private Set < Relationship > relationships ; private List < PropertyDescriptor > properties ; private Pattern fileFilter ; private Unpacker tarUnpacker ; private Unpacker zipUnpacker ; @ Override protected void init ( final ProcessorInitializationContext context ) { final Set < Relationship > relationships = new HashSet < > ( ) ; relationships . add ( REL_SUCCESS ) ; relationships . add ( REL_ORIGINAL ) ; relationships . add ( REL_FAILURE ) ; this . relationships = Collections . unmodifiableSet ( relationships ) ; final List < PropertyDescriptor > properties = new ArrayList < > ( ) ; properties . add ( PACKAGING_FORMAT ) ; properties . add ( FILE_FILTER ) ; this . properties = Collections . unmodifiableList ( properties ) ; } @ Override public Set < Relationship > getRelationships ( ) { return relationships ; } @ Override protected List < PropertyDescriptor > getSupportedPropertyDescriptors ( ) { return properties ; } @ OnStopped public void onStopped ( ) { fileFilter = null ; } @ OnScheduled public void onScheduled ( ProcessContext context ) throws ProcessException { if ( fileFilter == null ) { fileFilter = Pattern . compile ( context . getProperty ( FILE_FILTER ) . getValue ( ) ) ; tarUnpacker = new TarUnpacker ( fileFilter ) ; zipUnpacker = new ZipUnpacker ( fileFilter ) ; } } @ Override public void onTrigger ( final ProcessContext context , final ProcessSession session ) throws ProcessException { FlowFile flowFile = session . get ( ) ; if ( flowFile == null ) { return ; } final ComponentLog logger = getLogger ( ) ; PackageFormat packagingFormat = PackageFormat . getFormat ( context . getProperty ( PACKAGING_FORMAT ) . getValue ( ) . toLowerCase ( ) ) ; if ( packagingFormat == PackageFormat . AUTO_DETECT_FORMAT ) { packagingFormat = null ; final String mimeType = flowFile . getAttribute ( CoreAttributes . MIME_TYPE . key ( ) ) ; if ( mimeType == null ) { logger . error ( ""No mime.type attribute set for {}; routing to failure"" , new Object [ ] { flowFile } ) ; session . transfer ( flowFile , REL_FAILURE ) ; return ; } for ( PackageFormat format : PackageFormat . values ( ) ) { if ( mimeType . toLowerCase ( ) . equals ( format . getMimeType ( ) ) ) { packagingFormat = format ; } } if ( packagingFormat == null ) { logger . info ( ""Cannot unpack {} because its mime.type attribute is set to '{}', which is not a format that can be unpacked; routing to 'success'"" , new Object [ ] { flowFile , mimeType } ) ; session . transfer ( flowFile , REL_SUCCESS ) ; return ; } } final Unpacker unpacker ; final boolean addFragmentAttrs ; switch ( packagingFormat ) { case TAR_FORMAT : case X_TAR_FORMAT : unpacker = tarUnpacker ; addFragmentAttrs = true ; break ; case ZIP_FORMAT : unpacker = zipUnpacker ; addFragmentAttrs = true ; break ; case FLOWFILE_STREAM_FORMAT_V2 : unpacker = new FlowFileStreamUnpacker ( new FlowFileUnpackagerV2 ( ) ) ; addFragmentAttrs = false ; break ; case FLOWFILE_STREAM_FORMAT_V3 : unpacker = new FlowFileStreamUnpacker ( new FlowFileUnpackagerV3 ( ) ) ; addFragmentAttrs = false ; break ; case FLOWFILE_TAR_FORMAT : unpacker = new FlowFileStreamUnpacker ( new FlowFileUnpackagerV1 ( ) ) ; addFragmentAttrs = false ; break ; case AUTO_DETECT_FORMAT : default : throw new ProcessException ( packagingFormat + "" is not a valid packaging format"" ) ; } final List < FlowFile > unpacked = new ArrayList < > ( ) ; try { unpacker . unpack ( session , flowFile , unpacked ) ; if ( unpacked . isEmpty ( ) ) { logger . error ( ""Unable to unpack {} because it does not appear to have any entries; routing to failure"" , new Object [ ] { flowFile } ) ; session . transfer ( flowFile , REL_FAILURE ) ; return ; } if ( addFragmentAttrs ) { finishFragmentAttributes ( session , flowFile , unpacked ) ; } session . transfer ( unpacked , REL_SUCCESS ) ; final String fragmentId = unpacked . size ( ) > 0 ? unpacked . get ( 0 ) . getAttribute ( FRAGMENT_ID ) : null ; flowFile = FragmentAttributes . copyAttributesToOriginal ( session , flowFile , fragmentId , unpacked . size ( ) ) ; session . transfer ( flowFile , REL_ORIGINAL ) ; session . getProvenanceReporter ( ) . fork ( flowFile , unpacked ) ; logger . info ( ""Unpacked {} into {} and transferred to success"" , new Object [ ] { flowFile , unpacked } ) ; } catch ( final Exception e ) { logger . error ( ""Unable to unpack {} due to {}; routing to failure"" , new Object [ ] { flowFile , e } ) ; session . transfer ( flowFile , REL_FAILURE ) ; session . remove ( unpacked ) ; } } private static abstract class Unpacker { private Pattern fileFilter = null ; public Unpacker ( ) { } public Unpacker ( Pattern fileFilter ) { this . fileFilter = fileFilter ; } abstract void unpack ( ProcessSession session , FlowFile source , List < FlowFile > unpacked ) ; protected boolean fileMatches ( ArchiveEntry entry ) { return fileFilter == null || fileFilter . matcher ( entry . getName ( ) ) . find ( ) ; } } private static class TarUnpacker extends Unpacker { public TarUnpacker ( Pattern fileFilter ) { super ( fileFilter ) ; } @ Override public void unpack ( final ProcessSession session , final FlowFile source , final List < FlowFile > unpacked ) { final String fragmentId = UUID . randomUUID ( ) . toString ( ) ; session . read ( source , new InputStreamCallback ( ) { @ Override public void process ( final InputStream in ) throws IOException { int fragmentCount = 0 ; try ( final TarArchiveInputStream tarIn = new TarArchiveInputStream ( new BufferedInputStream ( in ) ) ) { TarArchiveEntry tarEntry ; while ( ( tarEntry = tarIn . getNextTarEntry ( ) ) != null ) { if ( tarEntry . isDirectory ( ) || ! fileMatches ( tarEntry ) ) { continue ; } final File file = new File ( tarEntry . getName ( ) ) ; final Path filePath = file . toPath ( ) ; final String filePathString = filePath . getParent ( ) + ""/"" ; final Path absPath = filePath . toAbsolutePath ( ) ; final String absPathString = absPath . getParent ( ) . toString ( ) + ""/"" ; FlowFile unpackedFile = session . create ( source ) ; try { final Map < String , String > attributes = new HashMap < > ( ) ; attributes . put ( CoreAttributes . FILENAME . key ( ) , file . getName ( ) ) ; attributes . put ( CoreAttributes . PATH . key ( ) , filePathString ) ; attributes . put ( CoreAttributes . ABSOLUTE_PATH . key ( ) , absPathString ) ; attributes . put ( CoreAttributes . MIME_TYPE . key ( ) , OCTET_STREAM ) ; attributes . put ( FRAGMENT_ID , fragmentId ) ; attributes . put ( FRAGMENT_INDEX , String . valueOf ( ++ fragmentCount ) ) ; unpackedFile = session . putAllAttributes ( unpackedFile , attributes ) ; final long fileSize = tarEntry . getSize ( ) ; unpackedFile = session . write ( unpackedFile , new OutputStreamCallback ( ) { @ Override public void process ( final OutputStream out ) throws IOException { StreamUtils . copy ( tarIn , out , fileSize ) ; } } ) ; } finally { unpacked . add ( unpackedFile ) ; } } } } } ) ; } } private static class ZipUnpacker extends Unpacker { public ZipUnpacker ( Pattern fileFilter ) { super ( fileFilter ) ; } @ Override public void unpack ( final ProcessSession session , final FlowFile source , final List < FlowFile > unpacked ) { final String fragmentId = UUID . randomUUID ( ) . toString ( ) ; session . read ( source , new InputStreamCallback ( ) { @ Override public void process ( final InputStream in ) throws IOException { int fragmentCount = 0 ; try ( final ZipArchiveInputStream zipIn = new ZipArchiveInputStream ( new BufferedInputStream ( in ) ) ) { ArchiveEntry zipEntry ; while ( ( zipEntry = zipIn . getNextEntry ( ) ) != null ) { if ( zipEntry . isDirectory ( ) || ! fileMatches ( zipEntry ) ) { continue ; } final File file = new File ( zipEntry . getName ( ) ) ; final String parentDirectory = ( file . getParent ( ) == null ) ? ""/"" : file . getParent ( ) ; final Path absPath = file . toPath ( ) . toAbsolutePath ( ) ; final String absPathString = absPath . getParent ( ) . toString ( ) + ""/"" ; FlowFile unpackedFile = session . create ( source ) ; try { final Map < String , String > attributes = new HashMap < > ( ) ; attributes . put ( CoreAttributes . FILENAME . key ( ) , file . getName ( ) ) ; attributes . put ( CoreAttributes . PATH . key ( ) , parentDirectory ) ; attributes . put ( CoreAttributes . ABSOLUTE_PATH . key ( ) , absPathString ) ; attributes . put ( CoreAttributes . MIME_TYPE . key ( ) , OCTET_STREAM ) ; attributes . put ( FRAGMENT_ID , fragmentId ) ; attributes . put ( FRAGMENT_INDEX , String . valueOf ( ++ fragmentCount ) ) ; unpackedFile = session . putAllAttributes ( unpackedFile , attributes ) ; unpackedFile = session . write ( unpackedFile , new OutputStreamCallback ( ) { @ Override public void process ( final OutputStream out ) throws IOException { StreamUtils . copy ( zipIn , out ) ; } } ) ; } finally { unpacked . add ( unpackedFile ) ; } } } } } ) ; } } private static class FlowFileStreamUnpacker extends Unpacker { private final FlowFileUnpackager unpackager ; public FlowFileStreamUnpacker ( final FlowFileUnpackager unpackager ) { this . unpackager = unpackager ; } @ Override public void unpack ( final ProcessSession session , final FlowFile source , final List < FlowFile > unpacked ) { session . read ( source , new InputStreamCallback ( ) { @ Override public void process ( final InputStream rawIn ) throws IOException { try ( final InputStream in = new BufferedInputStream ( rawIn ) ) { while ( unpackager . hasMoreData ( ) ) { final AtomicReference < Map < String , String > > attributesRef = new AtomicReference < > ( null ) ; FlowFile unpackedFile = session . create ( source ) ; try { unpackedFile = session . write ( unpackedFile , new OutputStreamCallback ( ) { @ Override public void process ( final OutputStream rawOut ) throws IOException { try ( final OutputStream out = new BufferedOutputStream ( rawOut ) ) { final Map < String , String > attributes = unpackager . unpackageFlowFile ( in , out ) ; if ( attributes == null ) { throw new IOException ( ""Failed to unpack "" + source + "": stream had no Attributes"" ) ; } attributesRef . set ( attributes ) ; } } } ) ; final Map < String , String > attributes = attributesRef . get ( ) ; attributes . remove ( CoreAttributes . UUID . key ( ) ) ; mapAttributes ( attributes , ""nf.file.name"" , CoreAttributes . FILENAME . key ( ) ) ; mapAttributes ( attributes , ""nf.file.path"" , CoreAttributes . PATH . key ( ) ) ; mapAttributes ( attributes , ""content-encoding"" , CoreAttributes . MIME_TYPE . key ( ) ) ; mapAttributes ( attributes , ""content-type"" , CoreAttributes . MIME_TYPE . key ( ) ) ; if ( ! attributes . containsKey ( CoreAttributes . MIME_TYPE . key ( ) ) ) { attributes . put ( CoreAttributes . MIME_TYPE . key ( ) , OCTET_STREAM ) ; } unpackedFile = session . putAllAttributes ( unpackedFile , attributes ) ; } finally { unpacked . add ( unpackedFile ) ; } } } } } ) ; } } private static void mapAttributes ( final Map < String , String > attributes , final String oldKey , final String newKey ) { if ( ! attributes . containsKey ( newKey ) && attributes . containsKey ( oldKey ) ) { attributes . put ( newKey , attributes . get ( oldKey ) ) ; } } private void finishFragmentAttributes ( final ProcessSession session , final FlowFile source , final List < FlowFile > unpacked ) { int fragmentCount = 0 ; for ( FlowFile ff : unpacked ) { String fragmentIndex = ff . getAttribute ( FRAGMENT_INDEX ) ; if ( fragmentIndex != null ) { fragmentCount ++ ; } else { return ; } } String originalFilename = source . getAttribute ( CoreAttributes . FILENAME . key ( ) ) ; if ( originalFilename . endsWith ( "".tar"" ) || originalFilename . endsWith ( "".zip"" ) || originalFilename . endsWith ( "".pkg"" ) ) { originalFilename = originalFilename . substring ( 0 , originalFilename . length ( ) - 4 ) ; } ArrayList < FlowFile > newList = new ArrayList < > ( unpacked ) ; unpacked . clear ( ) ; for ( FlowFile ff : newList ) { final Map < String , String > attributes = new HashMap < > ( ) ; attributes . put ( FRAGMENT_COUNT , String . valueOf ( fragmentCount ) ) ; attributes . put ( SEGMENT_ORIGINAL_FILENAME , originalFilename ) ; FlowFile newFF = session . putAllAttributes ( ff , attributes ) ; unpacked . add ( newFF ) ; } } protected enum PackageFormat { AUTO_DETECT_FORMAT ( AUTO_DETECT_FORMAT_NAME ) , TAR_FORMAT ( TAR_FORMAT_NAME , ""application/tar"" ) , X_TAR_FORMAT ( TAR_FORMAT_NAME , ""application/x-tar"" ) , ZIP_FORMAT ( ZIP_FORMAT_NAME , ""application/zip"" ) , FLOWFILE_STREAM_FORMAT_V3 ( FLOWFILE_STREAM_FORMAT_V3_NAME , ""application/flowfile-v3"" ) , FLOWFILE_STREAM_FORMAT_V2 ( FLOWFILE_STREAM_FORMAT_V2_NAME , ""application/flowfile-v2"" ) , FLOWFILE_TAR_FORMAT ( FLOWFILE_TAR_FORMAT_NAME , ""application/flowfile-v1"" ) ; private final String textValue ; private String mimeType ; PackageFormat ( String textValue , String mimeType ) { this . textValue = textValue ; this . mimeType = mimeType ; } PackageFormat ( String textValue ) { this . textValue = textValue ; } @ Override public String toString ( ) { return textValue ; } public String getMimeType ( ) { return mimeType ; } public static PackageFormat getFormat ( String textValue ) { switch ( textValue ) { case AUTO_DETECT_FORMAT_NAME : return AUTO_DETECT_FORMAT ; case TAR_FORMAT_NAME : return TAR_FORMAT ; case ZIP_FORMAT_NAME : return ZIP_FORMAT ; case FLOWFILE_STREAM_FORMAT_V3_NAME : return FLOWFILE_STREAM_FORMAT_V3 ; case FLOWFILE_STREAM_FORMAT_V2_NAME : return FLOWFILE_STREAM_FORMAT_V2 ; case FLOWFILE_TAR_FORMAT_NAME : return FLOWFILE_TAR_FORMAT ; } return null ; } } ",Smelly
"public class FnNameQueryTest extends AbstractQueryTest { public void testFnName ( ) throws RepositoryException { Node n1 = testRootNode . addNode ( nodeName1 ) ; n1 . setProperty ( propertyName1 , 1 ) ; Node n2 = testRootNode . addNode ( nodeName2 ) ; n2 . setProperty ( propertyName1 , 2 ) ; Node n3 = testRootNode . addNode ( nodeName3 ) ; n3 . setProperty ( propertyName1 , 3 ) ; testRootNode . save ( ) ; String base = testPath + ""/*[@"" + propertyName1 ; executeXPathQuery ( base + "" = 1 and fn:name() = '"" + nodeName1 + ""']"" , new Node [ ] { n1 } ) ; executeXPathQuery ( base + "" = 1 and fn:name() = '"" + nodeName2 + ""']"" , new Node [ ] { } ) ; executeXPathQuery ( base + "" > 0 and fn:name() = '"" + nodeName2 + ""']"" , new Node [ ] { n2 } ) ; executeXPathQuery ( base + "" > 0 and (fn:name() = '"" + nodeName1 + ""' or fn:name() = '"" + nodeName2 + ""')]"" , new Node [ ] { n1 , n2 } ) ; executeXPathQuery ( base + "" > 0 and not(fn:name() = '"" + nodeName1 + ""')]"" , new Node [ ] { n2 , n3 } ) ; } public void testFnNameWithSpace ( ) throws RepositoryException { Node n1 = testRootNode . addNode ( ""My Documents"" ) ; n1 . setProperty ( propertyName1 , 1 ) ; testRootNode . save ( ) ; String base = testPath + ""/*[@"" + propertyName1 ; executeXPathQuery ( base + "" = 1 and fn:name() = 'My Documents']"" , new Node [ ] { } ) ; executeXPathQuery ( base + "" = 1 and fn:name() = 'My_x0020_Documents']"" , new Node [ ] { n1 } ) ; } }",No
"public class TestTopicsTest { private static final Logger log = LoggerFactory . getLogger ( TestTopicsTest . class ) ; private final static String INPUT_TOPIC = ""input"" ; private final static String OUTPUT_TOPIC = ""output1"" ; private final static String INPUT_TOPIC_MAP = OUTPUT_TOPIC ; private final static String OUTPUT_TOPIC_MAP = ""output2"" ; private TopologyTestDriver testDriver ; private final Serde < String > stringSerde = new Serdes . StringSerde ( ) ; private final Serde < Long > longSerde = new Serdes . LongSerde ( ) ; private final Properties config = mkProperties ( mkMap ( mkEntry ( StreamsConfig . APPLICATION_ID_CONFIG , ""TestTopicsTest"" ) , mkEntry ( StreamsConfig . BOOTSTRAP_SERVERS_CONFIG , ""dummy:1234"" ) ) ) ; private final Instant testBaseTime = Instant . parse ( ""2019-06-01T10:00:00Z"" ) ; @ Before public void setup ( ) { final StreamsBuilder builder = new StreamsBuilder ( ) ; builder . stream ( INPUT_TOPIC ) . to ( OUTPUT_TOPIC ) ; final KStream < Long , String > source = builder . stream ( INPUT_TOPIC_MAP , Consumed . with ( longSerde , stringSerde ) ) ; final KStream < String , Long > mapped = source . map ( ( key , value ) -> new KeyValue < > ( value , key ) ) ; mapped . to ( OUTPUT_TOPIC_MAP , Produced . with ( stringSerde , longSerde ) ) ; testDriver = new TopologyTestDriver ( builder . build ( ) , config ) ; } @ After public void tearDown ( ) { try { testDriver . close ( ) ; } catch ( final RuntimeException e ) { log . warn ( ""Ignoring exception, test failing in Windows due this exception: {}"" , e . getLocalizedMessage ( ) ) ; } } @ Test public void testValue ( ) { final TestInputTopic < String , String > inputTopic = testDriver . createInputTopic ( INPUT_TOPIC , stringSerde . serializer ( ) , stringSerde . serializer ( ) ) ; final TestOutputTopic < String , String > outputTopic = testDriver . createOutputTopic ( OUTPUT_TOPIC , stringSerde . deserializer ( ) , stringSerde . deserializer ( ) ) ; inputTopic . pipeInput ( ""Hello"" ) ; assertThat ( outputTopic . readValue ( ) , equalTo ( ""Hello"" ) ) ; assertThat ( outputTopic . isEmpty ( ) , is ( true ) ) ; } @ Test public void testValueList ( ) { final TestInputTopic < String , String > inputTopic = testDriver . createInputTopic ( INPUT_TOPIC , stringSerde . serializer ( ) , stringSerde . serializer ( ) ) ; final TestOutputTopic < String , String > outputTopic = testDriver . createOutputTopic ( OUTPUT_TOPIC , stringSerde . deserializer ( ) , stringSerde . deserializer ( ) ) ; final List < String > inputList = Arrays . asList ( ""This"" , ""is"" , ""an"" , ""example"" ) ; inputTopic . pipeValueList ( inputList ) ; final List < String > output = outputTopic . readValuesToList ( ) ; assertThat ( output , hasItems ( ""This"" , ""is"" , ""an"" , ""example"" ) ) ; assertThat ( output , is ( equalTo ( inputList ) ) ) ; } @ Test public void testKeyValue ( ) { final TestInputTopic < Long , String > inputTopic = testDriver . createInputTopic ( INPUT_TOPIC , longSerde . serializer ( ) , stringSerde . serializer ( ) ) ; final TestOutputTopic < Long , String > outputTopic = testDriver . createOutputTopic ( OUTPUT_TOPIC , longSerde . deserializer ( ) , stringSerde . deserializer ( ) ) ; inputTopic . pipeInput ( 1L , ""Hello"" ) ; assertThat ( outputTopic . readKeyValue ( ) , equalTo ( new KeyValue < > ( 1L , ""Hello"" ) ) ) ; assertThat ( outputTopic . isEmpty ( ) , is ( true ) ) ; } @ Test public void testKeyValueList ( ) { final TestInputTopic < Long , String > inputTopic = testDriver . createInputTopic ( INPUT_TOPIC_MAP , longSerde . serializer ( ) , stringSerde . serializer ( ) ) ; final TestOutputTopic < String , Long > outputTopic = testDriver . createOutputTopic ( OUTPUT_TOPIC_MAP , stringSerde . deserializer ( ) , longSerde . deserializer ( ) ) ; final List < String > inputList = Arrays . asList ( ""This"" , ""is"" , ""an"" , ""example"" ) ; final List < KeyValue < Long , String > > input = new LinkedList < > ( ) ; final List < KeyValue < String , Long > > expected = new LinkedList < > ( ) ; long i = 0 ; for ( final String s : inputList ) { input . add ( new KeyValue < > ( i , s ) ) ; expected . add ( new KeyValue < > ( s , i ) ) ; i ++ ; } inputTopic . pipeKeyValueList ( input ) ; final List < KeyValue < String , Long > > output = outputTopic . readKeyValuesToList ( ) ; assertThat ( output , is ( equalTo ( expected ) ) ) ; } @ Test public void testKeyValuesToMap ( ) { final TestInputTopic < Long , String > inputTopic = testDriver . createInputTopic ( INPUT_TOPIC_MAP , longSerde . serializer ( ) , stringSerde . serializer ( ) ) ; final TestOutputTopic < String , Long > outputTopic = testDriver . createOutputTopic ( OUTPUT_TOPIC_MAP , stringSerde . deserializer ( ) , longSerde . deserializer ( ) ) ; final List < String > inputList = Arrays . asList ( ""This"" , ""is"" , ""an"" , ""example"" ) ; final List < KeyValue < Long , String > > input = new LinkedList < > ( ) ; final Map < String , Long > expected = new HashMap < > ( ) ; long i = 0 ; for ( final String s : inputList ) { input . add ( new KeyValue < > ( i , s ) ) ; expected . put ( s , i ) ; i ++ ; } inputTopic . pipeKeyValueList ( input ) ; final Map < String , Long > output = outputTopic . readKeyValuesToMap ( ) ; assertThat ( output , is ( equalTo ( expected ) ) ) ; } @ Test public void testKeyValuesToMapWithNull ( ) { final TestInputTopic < Long , String > inputTopic = testDriver . createInputTopic ( INPUT_TOPIC , longSerde . serializer ( ) , stringSerde . serializer ( ) ) ; final TestOutputTopic < Long , String > outputTopic = testDriver . createOutputTopic ( OUTPUT_TOPIC , longSerde . deserializer ( ) , stringSerde . deserializer ( ) ) ; inputTopic . pipeInput ( ""value"" ) ; assertThrows ( IllegalStateException . class , outputTopic :: readKeyValuesToMap ) ; } @ Test public void testKeyValueListDuration ( ) { final TestInputTopic < Long , String > inputTopic = testDriver . createInputTopic ( INPUT_TOPIC_MAP , longSerde . serializer ( ) , stringSerde . serializer ( ) ) ; final TestOutputTopic < String , Long > outputTopic = testDriver . createOutputTopic ( OUTPUT_TOPIC_MAP , stringSerde . deserializer ( ) , longSerde . deserializer ( ) ) ; final List < String > inputList = Arrays . asList ( ""This"" , ""is"" , ""an"" , ""example"" ) ; final List < KeyValue < Long , String > > input = new LinkedList < > ( ) ; final List < TestRecord < String , Long > > expected = new LinkedList < > ( ) ; long i = 0 ; final Duration advance = Duration . ofSeconds ( 15 ) ; Instant recordInstant = testBaseTime ; for ( final String s : inputList ) { input . add ( new KeyValue < > ( i , s ) ) ; expected . add ( new TestRecord < > ( s , i , recordInstant ) ) ; i ++ ; recordInstant = recordInstant . plus ( advance ) ; } inputTopic . pipeKeyValueList ( input , testBaseTime , advance ) ; final List < TestRecord < String , Long > > output = outputTopic . readRecordsToList ( ) ; assertThat ( output , is ( equalTo ( expected ) ) ) ; } @ Test public void testRecordList ( ) { final TestInputTopic < Long , String > inputTopic = testDriver . createInputTopic ( INPUT_TOPIC_MAP , longSerde . serializer ( ) , stringSerde . serializer ( ) ) ; final TestOutputTopic < String , Long > outputTopic = testDriver . createOutputTopic ( OUTPUT_TOPIC_MAP , stringSerde . deserializer ( ) , longSerde . deserializer ( ) ) ; final List < String > inputList = Arrays . asList ( ""This"" , ""is"" , ""an"" , ""example"" ) ; final List < TestRecord < Long , String > > input = new LinkedList < > ( ) ; final List < TestRecord < String , Long > > expected = new LinkedList < > ( ) ; final Duration advance = Duration . ofSeconds ( 15 ) ; Instant recordInstant = testBaseTime ; Long i = 0L ; for ( final String s : inputList ) { input . add ( new TestRecord < > ( i , s , recordInstant ) ) ; expected . add ( new TestRecord < > ( s , i , recordInstant ) ) ; i ++ ; recordInstant = recordInstant . plus ( advance ) ; } inputTopic . pipeRecordList ( input ) ; final List < TestRecord < String , Long > > output = outputTopic . readRecordsToList ( ) ; assertThat ( output , is ( equalTo ( expected ) ) ) ; } @ Test public void testTimestamp ( ) { long baseTime = 3 ; final TestInputTopic < Long , String > inputTopic = testDriver . createInputTopic ( INPUT_TOPIC , longSerde . serializer ( ) , stringSerde . serializer ( ) ) ; final TestOutputTopic < Long , String > outputTopic = testDriver . createOutputTopic ( OUTPUT_TOPIC , longSerde . deserializer ( ) , stringSerde . deserializer ( ) ) ; inputTopic . pipeInput ( null , ""Hello"" , baseTime ) ; assertThat ( outputTopic . readRecord ( ) , is ( equalTo ( new TestRecord < > ( null , ""Hello"" , null , baseTime ) ) ) ) ; inputTopic . pipeInput ( 2L , ""Kafka"" , ++ baseTime ) ; assertThat ( outputTopic . readRecord ( ) , is ( equalTo ( new TestRecord < > ( 2L , ""Kafka"" , null , baseTime ) ) ) ) ; inputTopic . pipeInput ( 2L , ""Kafka"" , testBaseTime ) ; assertThat ( outputTopic . readRecord ( ) , is ( equalTo ( new TestRecord < > ( 2L , ""Kafka"" , testBaseTime ) ) ) ) ; final List < String > inputList = Arrays . asList ( ""Advancing"" , ""time"" ) ; final Duration advance = Duration . ofSeconds ( 15 ) ; final Instant recordInstant = testBaseTime . plus ( Duration . ofDays ( 1 ) ) ; inputTopic . pipeValueList ( inputList , recordInstant , advance ) ; assertThat ( outputTopic . readRecord ( ) , is ( equalTo ( new TestRecord < > ( null , ""Advancing"" , recordInstant ) ) ) ) ; assertThat ( outputTopic . readRecord ( ) , is ( equalTo ( new TestRecord < > ( null , ""time"" , null , recordInstant . plus ( advance ) ) ) ) ) ; } @ Test public void testWithHeaders ( ) { long baseTime = 3 ; final Headers headers = new RecordHeaders ( new Header [ ] { new RecordHeader ( ""foo"" , ""value"" . getBytes ( ) ) , new RecordHeader ( ""bar"" , ( byte [ ] ) null ) , new RecordHeader ( ""\""A\\u00ea\\u00f1\\u00fcC\"""" , ""value"" . getBytes ( ) ) } ) ; final TestInputTopic < Long , String > inputTopic = testDriver . createInputTopic ( INPUT_TOPIC , longSerde . serializer ( ) , stringSerde . serializer ( ) ) ; final TestOutputTopic < Long , String > outputTopic = testDriver . createOutputTopic ( OUTPUT_TOPIC , longSerde . deserializer ( ) , stringSerde . deserializer ( ) ) ; inputTopic . pipeInput ( new TestRecord < > ( 1L , ""Hello"" , headers ) ) ; assertThat ( outputTopic . readRecord ( ) , allOf ( hasProperty ( ""key"" , equalTo ( 1L ) ) , hasProperty ( ""value"" , equalTo ( ""Hello"" ) ) , hasProperty ( ""headers"" , equalTo ( headers ) ) ) ) ; inputTopic . pipeInput ( new TestRecord < > ( 2L , ""Kafka"" , headers , ++ baseTime ) ) ; assertThat ( outputTopic . readRecord ( ) , is ( equalTo ( new TestRecord < > ( 2L , ""Kafka"" , headers , baseTime ) ) ) ) ; } @ Test public void testStartTimestamp ( ) { final Duration advance = Duration . ofSeconds ( 2 ) ; final TestInputTopic < Long , String > inputTopic = testDriver . createInputTopic ( INPUT_TOPIC , longSerde . serializer ( ) , stringSerde . serializer ( ) , testBaseTime , Duration . ZERO ) ; final TestOutputTopic < Long , String > outputTopic = testDriver . createOutputTopic ( OUTPUT_TOPIC , longSerde . deserializer ( ) , stringSerde . deserializer ( ) ) ; inputTopic . pipeInput ( 1L , ""Hello"" ) ; assertThat ( outputTopic . readRecord ( ) , is ( equalTo ( new TestRecord < > ( 1L , ""Hello"" , testBaseTime ) ) ) ) ; inputTopic . pipeInput ( 2L , ""World"" ) ; assertThat ( outputTopic . readRecord ( ) , is ( equalTo ( new TestRecord < > ( 2L , ""World"" , null , testBaseTime . toEpochMilli ( ) ) ) ) ) ; inputTopic . advanceTime ( advance ) ; inputTopic . pipeInput ( 3L , ""Kafka"" ) ; assertThat ( outputTopic . readRecord ( ) , is ( equalTo ( new TestRecord < > ( 3L , ""Kafka"" , testBaseTime . plus ( advance ) ) ) ) ) ; } @ Test public void testTimestampAutoAdvance ( ) { final Duration advance = Duration . ofSeconds ( 2 ) ; final TestInputTopic < Long , String > inputTopic = testDriver . createInputTopic ( INPUT_TOPIC , longSerde . serializer ( ) , stringSerde . serializer ( ) , testBaseTime , advance ) ; final TestOutputTopic < Long , String > outputTopic = testDriver . createOutputTopic ( OUTPUT_TOPIC , longSerde . deserializer ( ) , stringSerde . deserializer ( ) ) ; inputTopic . pipeInput ( ""Hello"" ) ; assertThat ( outputTopic . readRecord ( ) , is ( equalTo ( new TestRecord < > ( null , ""Hello"" , testBaseTime ) ) ) ) ; inputTopic . pipeInput ( 2L , ""Kafka"" ) ; assertThat ( outputTopic . readRecord ( ) , is ( equalTo ( new TestRecord < > ( 2L , ""Kafka"" , testBaseTime . plus ( advance ) ) ) ) ) ; } @ Test public void testMultipleTopics ( ) { final TestInputTopic < Long , String > inputTopic1 = testDriver . createInputTopic ( INPUT_TOPIC , longSerde . serializer ( ) , stringSerde . serializer ( ) ) ; final TestInputTopic < Long , String > inputTopic2 = testDriver . createInputTopic ( INPUT_TOPIC_MAP , longSerde . serializer ( ) , stringSerde . serializer ( ) ) ; final TestOutputTopic < Long , String > outputTopic1 = testDriver . createOutputTopic ( OUTPUT_TOPIC , longSerde . deserializer ( ) , stringSerde . deserializer ( ) ) ; final TestOutputTopic < String , Long > outputTopic2 = testDriver . createOutputTopic ( OUTPUT_TOPIC_MAP , stringSerde . deserializer ( ) , longSerde . deserializer ( ) ) ; inputTopic1 . pipeInput ( 1L , ""Hello"" ) ; assertThat ( outputTopic1 . readKeyValue ( ) , equalTo ( new KeyValue < > ( 1L , ""Hello"" ) ) ) ; assertThat ( outputTopic2 . readKeyValue ( ) , equalTo ( new KeyValue < > ( ""Hello"" , 1L ) ) ) ; assertThat ( outputTopic1 . isEmpty ( ) , is ( true ) ) ; assertThat ( outputTopic2 . isEmpty ( ) , is ( true ) ) ; inputTopic2 . pipeInput ( 1L , ""Hello"" ) ; assertThat ( outputTopic2 . readKeyValue ( ) , equalTo ( new KeyValue < > ( ""Hello"" , 1L ) ) ) ; assertThat ( outputTopic1 . isEmpty ( ) , is ( true ) ) ; assertThat ( outputTopic2 . isEmpty ( ) , is ( true ) ) ; } @ Test public void testNonExistingOutputTopic ( ) { final TestOutputTopic < Long , String > outputTopic = testDriver . createOutputTopic ( ""no-exist"" , longSerde . deserializer ( ) , stringSerde . deserializer ( ) ) ; assertThrows ( ""Unknown topic"" , IllegalArgumentException . class , outputTopic :: readRecord ) ; } @ Test public void testNonUsedOutputTopic ( ) { final TestOutputTopic < Long , String > outputTopic = testDriver . createOutputTopic ( OUTPUT_TOPIC , longSerde . deserializer ( ) , stringSerde . deserializer ( ) ) ; assertThrows ( ""Uninitialized topic"" , NoSuchElementException . class , outputTopic :: readRecord ) ; } @ Test public void testEmptyTopic ( ) { final TestInputTopic < String , String > inputTopic = testDriver . createInputTopic ( INPUT_TOPIC , stringSerde . serializer ( ) , stringSerde . serializer ( ) ) ; final TestOutputTopic < String , String > outputTopic = testDriver . createOutputTopic ( OUTPUT_TOPIC , stringSerde . deserializer ( ) , stringSerde . deserializer ( ) ) ; inputTopic . pipeInput ( ""Hello"" ) ; assertThat ( outputTopic . readValue ( ) , equalTo ( ""Hello"" ) ) ; assertThrows ( ""Empty topic"" , NoSuchElementException . class , outputTopic :: readRecord ) ; } @ Test public void testNonExistingInputTopic ( ) { final TestInputTopic < Long , String > inputTopic = testDriver . createInputTopic ( ""no-exist"" , longSerde . serializer ( ) , stringSerde . serializer ( ) ) ; assertThrows ( ""Unknown topic"" , IllegalArgumentException . class , ( ) -> inputTopic . pipeInput ( 1L , ""Hello"" ) ) ; } @ Test ( expected = NullPointerException . class ) public void shouldNotAllowToCreateTopicWithNullTopicName ( ) { testDriver . createInputTopic ( null , stringSerde . serializer ( ) , stringSerde . serializer ( ) ) ; } @ Test ( expected = NullPointerException . class ) public void shouldNotAllowToCreateWithNullDriver ( ) { new TestInputTopic < > ( null , INPUT_TOPIC , stringSerde . serializer ( ) , stringSerde . serializer ( ) , Instant . now ( ) , Duration . ZERO ) ; } @ Test ( expected = StreamsException . class ) public void testWrongSerde ( ) { final TestInputTopic < String , String > inputTopic = testDriver . createInputTopic ( INPUT_TOPIC_MAP , stringSerde . serializer ( ) , stringSerde . serializer ( ) ) ; inputTopic . pipeInput ( ""1L"" , ""Hello"" ) ; } @ Test ( expected = IllegalArgumentException . class ) public void testDuration ( ) { testDriver . createInputTopic ( INPUT_TOPIC_MAP , stringSerde . serializer ( ) , stringSerde . serializer ( ) , testBaseTime , Duration . ofDays ( - 1 ) ) ; } @ Test ( expected = IllegalArgumentException . class ) public void testNegativeAdvance ( ) { final TestInputTopic < String , String > inputTopic = testDriver . createInputTopic ( INPUT_TOPIC_MAP , stringSerde . serializer ( ) , stringSerde . serializer ( ) ) ; inputTopic . advanceTime ( Duration . ofDays ( - 1 ) ) ; } @ Test public void testInputToString ( ) { final TestInputTopic < String , String > inputTopic = testDriver . createInputTopic ( ""topicName"" , stringSerde . serializer ( ) , stringSerde . serializer ( ) ) ; assertThat ( inputTopic . toString ( ) , allOf ( containsString ( ""TestInputTopic"" ) , containsString ( ""topic='topicName'"" ) , containsString ( ""StringSerializer"" ) ) ) ; } @ Test ( expected = NullPointerException . class ) public void shouldNotAllowToCreateOutputTopicWithNullTopicName ( ) { testDriver . createOutputTopic ( null , stringSerde . deserializer ( ) , stringSerde . deserializer ( ) ) ; } @ Test ( expected = NullPointerException . class ) public void shouldNotAllowToCreateOutputWithNullDriver ( ) { new TestOutputTopic < > ( null , OUTPUT_TOPIC , stringSerde . deserializer ( ) , stringSerde . deserializer ( ) ) ; } @ Test ( expected = SerializationException . class ) public void testOutputWrongSerde ( ) { final TestInputTopic < Long , String > inputTopic = testDriver . createInputTopic ( INPUT_TOPIC_MAP , longSerde . serializer ( ) , stringSerde . serializer ( ) ) ; final TestOutputTopic < Long , String > outputTopic = testDriver . createOutputTopic ( OUTPUT_TOPIC_MAP , longSerde . deserializer ( ) , stringSerde . deserializer ( ) ) ; inputTopic . pipeInput ( 1L , ""Hello"" ) ; assertThat ( outputTopic . readKeyValue ( ) , equalTo ( new KeyValue < > ( 1L , ""Hello"" ) ) ) ; } @ Test public void testOutputToString ( ) { final TestOutputTopic < String , String > outputTopic = testDriver . createOutputTopic ( OUTPUT_TOPIC , stringSerde . deserializer ( ) , stringSerde . deserializer ( ) ) ; assertThat ( outputTopic . toString ( ) , allOf ( containsString ( ""TestOutputTopic"" ) , containsString ( ""topic='output1'"" ) , containsString ( ""size=0"" ) , containsString ( ""StringDeserializer"" ) ) ) ; } @ Test public void testRecordsToList ( ) { final TestInputTopic < Long , String > inputTopic = testDriver . createInputTopic ( INPUT_TOPIC_MAP , longSerde . serializer ( ) , stringSerde . serializer ( ) ) ; final TestOutputTopic < String , Long > outputTopic = testDriver . createOutputTopic ( OUTPUT_TOPIC_MAP , stringSerde . deserializer ( ) , longSerde . deserializer ( ) ) ; final List < String > inputList = Arrays . asList ( ""This"" , ""is"" , ""an"" , ""example"" ) ; final List < KeyValue < Long , String > > input = new LinkedList < > ( ) ; final List < TestRecord < String , Long > > expected = new LinkedList < > ( ) ; long i = 0 ; final Duration advance = Duration . ofSeconds ( 15 ) ; Instant recordInstant = Instant . parse ( ""2019-06-01T10:00:00Z"" ) ; for ( final String s : inputList ) { input . add ( new KeyValue < > ( i , s ) ) ; expected . add ( new TestRecord < > ( s , i , recordInstant ) ) ; i ++ ; recordInstant = recordInstant . plus ( advance ) ; } inputTopic . pipeKeyValueList ( input , Instant . parse ( ""2019-06-01T10:00:00Z"" ) , advance ) ; final List < TestRecord < String , Long > > output = outputTopic . readRecordsToList ( ) ; assertThat ( output , is ( equalTo ( expected ) ) ) ; } }",Smelly
"public class LogFileValue implements Writable { private static final List < Mutation > empty = Collections . emptyList ( ) ; public List < Mutation > mutations = empty ; @ Override public void readFields ( DataInput in ) throws IOException { int count = in . readInt ( ) ; mutations = new ArrayList < > ( count ) ; for ( int i = 0 ; i < count ; i ++ ) { ServerMutation mutation = new ServerMutation ( ) ; mutation . readFields ( in ) ; mutations . add ( mutation ) ; } } @ Override public void write ( DataOutput out ) throws IOException { out . writeInt ( mutations . size ( ) ) ; for ( Mutation m : mutations ) { m . write ( out ) ; } } private static String displayLabels ( byte [ ] labels ) { String s = new String ( labels , UTF_8 ) ; s = s . replace ( ""&"" , "" & "" ) ; s = s . replace ( ""|"" , "" | "" ) ; return s ; } public static String format ( LogFileValue lfv , int maxMutations ) { if ( lfv . mutations . size ( ) == 0 ) return """" ; StringBuilder builder = new StringBuilder ( ) ; builder . append ( lfv . mutations . size ( ) + "" mutations:\n"" ) ; int i = 0 ; for ( Mutation m : lfv . mutations ) { if ( i ++ >= maxMutations ) { builder . append ( ""..."" ) ; break ; } builder . append ( ""  "" ) . append ( new String ( m . getRow ( ) , UTF_8 ) ) . append ( ""\n"" ) ; for ( ColumnUpdate update : m . getUpdates ( ) ) { String value = new String ( update . getValue ( ) ) ; builder . append ( ""      "" ) . append ( new String ( update . getColumnFamily ( ) , UTF_8 ) ) . append ( "":"" ) . append ( new String ( update . getColumnQualifier ( ) , UTF_8 ) ) . append ( "" "" ) . append ( update . hasTimestamp ( ) ? ""[user]:"" : ""[system]:"" ) . append ( update . getTimestamp ( ) ) . append ( "" ["" ) . append ( displayLabels ( update . getColumnVisibility ( ) ) ) . append ( ""] "" ) . append ( update . isDeleted ( ) ? ""<deleted>"" : value ) . append ( ""\n"" ) ; } } return builder . toString ( ) ; } @ Override public String toString ( ) { return format ( this , 5 ) ; } }",No
"@ RunWith ( FrameworkRunner . class ) @ CreateDS ( allowAnonAccess = true , name = ""AddIT-class"" , partitions = { @ CreatePartition ( name = ""example"" , suffix = ""dc=example,dc=com"" , contextEntry = @ ContextEntry ( entryLdif = ""dn: dc=example,dc=com\n"" + ""dc: example\n"" + ""objectClass: top\n"" + ""objectClass: domain\n\n"" ) , indexes = { @ CreateIndex ( attribute = ""objectClass"" ) , @ CreateIndex ( attribute = ""dc"" ) , @ CreateIndex ( attribute = ""ou"" ) } ) , @ CreatePartition ( name = ""directory"" , suffix = ""dc=directory,dc=apache,dc=org"" , contextEntry = @ ContextEntry ( entryLdif = ""dn: dc=directory,dc=apache,dc=org\n"" + ""dc: directory\n"" + ""objectClass: top\n"" + ""objectClass: domain\n\n"" ) , indexes = { @ CreateIndex ( attribute = ""objectClass"" ) , @ CreateIndex ( attribute = ""dc"" ) , @ CreateIndex ( attribute = ""ou"" ) } ) } ) @ CreateLdapServer ( name = ""ADDIT"" , transports = { @ CreateTransport ( protocol = ""LDAP"" , port = - 1 ) } ) @ ApplyLdifs ( { ""dn: cn=The Person,ou=system"" , ""objectClass: person"" , ""objectClass: top"" , ""cn: The Person"" , ""description: this is a person"" , ""sn: Person"" , ""dn: uid=akarasulu,ou=users,ou=system"" , ""objectClass: uidObject"" , ""objectClass: person"" , ""objectClass: top"" , ""uid: akarasulu"" , ""cn: Alex Karasulu"" , ""sn: karasulu"" , ""dn: ou=Computers,uid=akarasulu,ou=users,ou=system"" , ""objectClass: organizationalUnit"" , ""objectClass: top"" , ""ou: computers"" , ""description: Computers for Alex"" , ""seeAlso: ou=Machines,uid=akarasulu,ou=users,ou=system"" , ""dn: uid=akarasuluref,ou=users,ou=system"" , ""objectClass: uidObject"" , ""objectClass: referral"" , ""objectClass: top"" , ""uid: akarasuluref"" , ""ref: ldap://localhost:10389/uid=akarasulu,ou=users,ou=system"" , ""ref: ldap://foo:10389/uid=akarasulu,ou=users,ou=system"" , ""ref: ldap://bar:10389/uid=akarasulu,ou=users,ou=system"" } ) public class AddIT extends AbstractLdapTestUnit { private static final Logger LOG = LoggerFactory . getLogger ( AddIT . class ) ; private static final String RDN = ""cn=The Person"" ; private static final String BASE = ""ou=system"" ; private static final String BASE_EXAMPLE_COM = ""dc=example,dc=com"" ; private static final String BASE_DIRECTORY_APACHE_ORG = ""dc=directory,dc=apache,dc=org"" ; @ Test public void testAddObjectClasses ( ) throws Exception { DirContext ctx = ( DirContext ) getWiredContext ( getLdapServer ( ) ) . lookup ( BASE ) ; Attributes attributes = LdifUtils . createJndiAttributes ( ""objectClass: organizationalPerson"" , ""objectClass: inetOrgPerson"" ) ; DirContext person = ( DirContext ) ctx . lookup ( RDN ) ; person . modifyAttributes ( """" , DirContext . ADD_ATTRIBUTE , attributes ) ; person = ( DirContext ) ctx . lookup ( RDN ) ; attributes = person . getAttributes ( """" ) ; javax . naming . directory . Attribute newOcls = attributes . get ( ""objectClass"" ) ; String [ ] expectedOcls = { ""top"" , ""person"" , ""organizationalPerson"" , ""inetOrgPerson"" } ; for ( String name : expectedOcls ) { assertTrue ( ""object class "" + name + "" is present"" , newOcls . contains ( name ) ) ; } } @ Test public void testModifyDescription ( ) throws Exception { DirContext ctx = ( DirContext ) getWiredContext ( getLdapServer ( ) ) . lookup ( BASE ) ; String newDescription = ""More info on the user ..."" ; Attributes attributes = new BasicAttributes ( true ) ; javax . naming . directory . Attribute desc = new BasicAttribute ( ""description"" , newDescription ) ; attributes . put ( desc ) ; DirContext person = ( DirContext ) ctx . lookup ( RDN ) ; person . modifyAttributes ( """" , DirContext . REPLACE_ATTRIBUTE , attributes ) ; person = ( DirContext ) ctx . lookup ( RDN ) ; attributes = person . getAttributes ( """" ) ; javax . naming . directory . Attribute newDesc = attributes . get ( ""description"" ) ; assertTrue ( ""new Description"" , newDesc . contains ( newDescription ) ) ; } @ Test public void testAddWithMissingRequiredAttributes ( ) throws Exception { DirContext ctx = ( DirContext ) getWiredContext ( getLdapServer ( ) ) . lookup ( BASE ) ; Attributes attrs = new BasicAttributes ( true ) ; javax . naming . directory . Attribute ocls = new BasicAttribute ( ""objectClass"" ) ; ocls . add ( ""top"" ) ; ocls . add ( ""person"" ) ; attrs . put ( ocls ) ; attrs . put ( ""cn"" , ""Fiona Apple"" ) ; try { ctx . createSubcontext ( ""cn=Fiona Apple"" , attrs ) ; fail ( ""creation of entry should fail"" ) ; } catch ( SchemaViolationException e ) { } } @ Test public void testAddEntryWithTwoDescriptions ( ) throws Exception { LdapConnection con = getAdminConnection ( getLdapServer ( ) ) ; String dn = ""cn=Kate Bush,"" + BASE ; Entry kate = new DefaultEntry ( dn ) ; kate . add ( ""objectclass"" , ""top"" , ""person"" ) ; kate . add ( ""sn"" , ""Bush"" ) ; kate . add ( ""cn"" , ""Kate Bush"" ) ; String descr [ ] = { ""a British singer-songwriter with an expressive four-octave voice"" , ""one of the most influential female artists of the twentieth century"" } ; kate . add ( ""description"" , descr ) ; con . add ( kate ) ; Entry kateReloaded = con . lookup ( dn ) ; assertNotNull ( kateReloaded ) ; Attribute attr = kateReloaded . get ( ""description"" ) ; assertNotNull ( attr ) ; assertEquals ( 2 , attr . size ( ) ) ; con . delete ( dn ) ; con . unBind ( ) ; } @ Test public void testAddEntryWithTwoDescriptionsVariant ( ) throws Exception { LdapConnection con = getAdminConnection ( getLdapServer ( ) ) ; String dn = ""cn=Kate Bush,"" + BASE ; Entry kate = new DefaultEntry ( dn ) ; kate . add ( ""objectclass"" , ""top"" , ""person"" ) ; kate . add ( ""sn"" , ""Bush"" ) ; kate . add ( ""cn"" , ""Kate Bush"" ) ; String descr [ ] = { ""a British singer-songwriter with an expressive four-octave voice"" , ""one of the most influential female artists of the twentieth century"" } ; kate . add ( ""description"" , descr [ 0 ] ) ; kate . add ( ""description"" , descr [ 1 ] ) ; con . add ( kate ) ; Entry kateReloaded = con . lookup ( dn ) ; assertNotNull ( kateReloaded ) ; Attribute attr = kateReloaded . get ( ""description"" ) ; assertNotNull ( attr ) ; assertEquals ( 2 , attr . size ( ) ) ; con . delete ( dn ) ; con . unBind ( ) ; } @ Test public void testAddEntryWithTwoDescriptionsSecondVariant ( ) throws Exception { LdapConnection con = getAdminConnection ( getLdapServer ( ) ) ; String dn = ""cn=Kate Bush,"" + BASE ; Entry kate = new DefaultEntry ( dn ) ; kate . add ( ""objectclass"" , ""top"" , ""person"" ) ; kate . add ( ""sn"" , ""Bush"" ) ; String descr [ ] = { ""a British singer-songwriter with an expressive four-octave voice"" , ""one of the most influential female artists of the twentieth century"" } ; kate . add ( ""description"" , descr [ 0 ] ) ; kate . add ( ""cn"" , ""Kate Bush"" ) ; kate . add ( ""description"" , descr [ 1 ] ) ; con . add ( kate ) ; Entry kateReloaded = con . lookup ( dn ) ; assertNotNull ( kateReloaded ) ; Attribute attr = kateReloaded . get ( ""description"" ) ; assertNotNull ( attr ) ; assertEquals ( 2 , attr . size ( ) ) ; con . delete ( dn ) ; con . unBind ( ) ; } @ Test public void testAddWithInvalidNumberOfAttributeValues ( ) throws Exception { DirContext ctx = ( DirContext ) getWiredContext ( getLdapServer ( ) ) . lookup ( BASE ) ; Attributes attrs = new BasicAttributes ( true ) ; javax . naming . directory . Attribute ocls = new BasicAttribute ( ""objectClass"" ) ; ocls . add ( ""top"" ) ; ocls . add ( ""inetOrgPerson"" ) ; attrs . put ( ocls ) ; attrs . put ( ""cn"" , ""Fiona Apple"" ) ; attrs . put ( ""sn"" , ""Apple"" ) ; javax . naming . directory . Attribute displayName = new BasicAttribute ( ""displayName"" ) ; displayName . add ( ""Fiona"" ) ; displayName . add ( ""Fiona A."" ) ; attrs . put ( displayName ) ; try { ctx . createSubcontext ( ""cn=Fiona Apple"" , attrs ) ; fail ( ""creation of entry should fail"" ) ; } catch ( InvalidAttributeValueException e ) { } } @ Test public void testAddAlias ( ) throws Exception { DirContext ctx = ( DirContext ) getWiredContext ( getLdapServer ( ) ) . lookup ( BASE ) ; Attributes entry = new BasicAttributes ( true ) ; javax . naming . directory . Attribute entryOcls = new BasicAttribute ( SchemaConstants . OBJECT_CLASS_AT ) ; entryOcls . add ( SchemaConstants . TOP_OC ) ; entryOcls . add ( SchemaConstants . ORGANIZATIONAL_UNIT_OC ) ; entry . put ( entryOcls ) ; entry . put ( SchemaConstants . OU_AT , ""favorite"" ) ; String entryRdn = ""ou=favorite"" ; ctx . createSubcontext ( entryRdn , entry ) ; String aliasedObjectName = entryRdn + "","" + ctx . getNameInNamespace ( ) ; Attributes alias = new BasicAttributes ( true ) ; javax . naming . directory . Attribute aliasOcls = new BasicAttribute ( SchemaConstants . OBJECT_CLASS_AT ) ; aliasOcls . add ( SchemaConstants . TOP_OC ) ; aliasOcls . add ( SchemaConstants . EXTENSIBLE_OBJECT_OC ) ; aliasOcls . add ( SchemaConstants . ALIAS_OC ) ; alias . put ( aliasOcls ) ; alias . put ( SchemaConstants . OU_AT , ""bestFruit"" ) ; alias . put ( SchemaConstants . ALIASED_OBJECT_NAME_AT , aliasedObjectName ) ; String rdnAlias = ""ou=bestFruit"" ; ctx . createSubcontext ( rdnAlias , alias ) ; ctx . destroySubcontext ( rdnAlias ) ; ctx . destroySubcontext ( entryRdn ) ; } @ Test public void testAddAliasInContainer ( ) throws Exception { DirContext ctx = ( DirContext ) getWiredContext ( getLdapServer ( ) ) . lookup ( BASE ) ; Attributes container = new BasicAttributes ( true ) ; javax . naming . directory . Attribute containerOcls = new BasicAttribute ( SchemaConstants . OBJECT_CLASS_AT ) ; containerOcls . add ( SchemaConstants . TOP_OC ) ; containerOcls . add ( SchemaConstants . ORGANIZATIONAL_UNIT_OC ) ; container . put ( containerOcls ) ; container . put ( SchemaConstants . OU_AT , ""Fruits"" ) ; String containerRdn = ""ou=Fruits"" ; DirContext containerCtx = ctx . createSubcontext ( containerRdn , container ) ; Attributes entry = new BasicAttributes ( true ) ; javax . naming . directory . Attribute entryOcls = new BasicAttribute ( SchemaConstants . OBJECT_CLASS_AT ) ; entryOcls . add ( SchemaConstants . TOP_OC ) ; entryOcls . add ( SchemaConstants . ORGANIZATIONAL_UNIT_OC ) ; entry . put ( entryOcls ) ; entry . put ( SchemaConstants . OU_AT , ""favorite"" ) ; String entryRdn = ""ou=favorite"" ; containerCtx . createSubcontext ( entryRdn , entry ) ; String aliasedObjectName = entryRdn + "","" + containerCtx . getNameInNamespace ( ) ; Attributes alias = new BasicAttributes ( true ) ; javax . naming . directory . Attribute aliasOcls = new BasicAttribute ( SchemaConstants . OBJECT_CLASS_AT ) ; aliasOcls . add ( SchemaConstants . TOP_OC ) ; aliasOcls . add ( SchemaConstants . EXTENSIBLE_OBJECT_OC ) ; aliasOcls . add ( SchemaConstants . ALIAS_OC ) ; alias . put ( aliasOcls ) ; alias . put ( SchemaConstants . OU_AT , ""bestFruit"" ) ; alias . put ( SchemaConstants . ALIASED_OBJECT_NAME_AT , aliasedObjectName ) ; String rdnAlias = ""ou=bestFruit"" ; containerCtx . createSubcontext ( rdnAlias , alias ) ; SearchControls controls = new SearchControls ( ) ; controls . setDerefLinkFlag ( true ) ; controls . setSearchScope ( SearchControls . ONELEVEL_SCOPE ) ; containerCtx . addToEnvironment ( ""java.naming.ldap.derefAliases"" , ""never"" ) ; Set < String > names = new HashSet < String > ( ) ; NamingEnumeration < SearchResult > ne = containerCtx . search ( """" , ""(objectClass=*)"" , controls ) ; assertTrue ( ne . hasMore ( ) ) ; SearchResult sr = ne . next ( ) ; names . add ( sr . getName ( ) ) ; assertTrue ( ne . hasMore ( ) ) ; sr = ne . next ( ) ; names . add ( sr . getName ( ) ) ; assertFalse ( ne . hasMore ( ) ) ; assertEquals ( 2 , names . size ( ) ) ; assertTrue ( names . contains ( ""ou=favorite"" ) ) ; assertTrue ( names . contains ( ""ou=bestFruit"" ) ) ; controls = new SearchControls ( ) ; controls . setDerefLinkFlag ( true ) ; controls . setSearchScope ( SearchControls . ONELEVEL_SCOPE ) ; containerCtx . addToEnvironment ( ""java.naming.ldap.derefAliases"" , ""always"" ) ; ne = containerCtx . search ( """" , ""(objectClass=*)"" , controls ) ; assertTrue ( ne . hasMore ( ) ) ; sr = ne . next ( ) ; assertEquals ( ""ou=favorite"" , sr . getName ( ) ) ; assertFalse ( ne . hasMore ( ) ) ; controls = new SearchControls ( ) ; controls . setDerefLinkFlag ( false ) ; controls . setSearchScope ( SearchControls . OBJECT_SCOPE ) ; containerCtx . addToEnvironment ( ""java.naming.ldap.derefAliases"" , ""always"" ) ; ne = containerCtx . search ( ""ou=bestFruit"" , ""(objectClass=*)"" , controls ) ; assertTrue ( ne . hasMore ( ) ) ; sr = ne . next ( ) ; assertEquals ( Network . ldapLoopbackUrl ( getLdapServer ( ) . getPort ( ) ) + ""/ou=favorite,ou=Fruits,ou=system"" , sr . getName ( ) ) ; assertFalse ( ne . hasMore ( ) ) ; containerCtx . destroySubcontext ( rdnAlias ) ; containerCtx . destroySubcontext ( entryRdn ) ; ctx . destroySubcontext ( containerRdn ) ; } @ Test public void testAddDeleteAlias ( ) throws Exception { DirContext ctx = ( DirContext ) getWiredContext ( getLdapServer ( ) ) . lookup ( BASE ) ; Attributes entry = new BasicAttributes ( true ) ; javax . naming . directory . Attribute entryOcls = new BasicAttribute ( SchemaConstants . OBJECT_CLASS_AT ) ; entryOcls . add ( SchemaConstants . TOP_OC ) ; entryOcls . add ( SchemaConstants . ORGANIZATIONAL_UNIT_OC ) ; entry . put ( entryOcls ) ; entry . put ( SchemaConstants . OU_AT , ""favorite"" ) ; String entryRdn = ""ou=favorite"" ; ctx . createSubcontext ( entryRdn , entry ) ; String aliasedObjectName = entryRdn + "","" + ctx . getNameInNamespace ( ) ; Attributes alias = new BasicAttributes ( true ) ; javax . naming . directory . Attribute aliasOcls = new BasicAttribute ( SchemaConstants . OBJECT_CLASS_AT ) ; aliasOcls . add ( SchemaConstants . TOP_OC ) ; aliasOcls . add ( SchemaConstants . EXTENSIBLE_OBJECT_OC ) ; aliasOcls . add ( SchemaConstants . ALIAS_OC ) ; alias . put ( aliasOcls ) ; alias . put ( SchemaConstants . OU_AT , ""bestFruit"" ) ; alias . put ( SchemaConstants . ALIASED_OBJECT_NAME_AT , aliasedObjectName ) ; String rdnAlias = ""ou=bestFruit"" ; ctx . createSubcontext ( rdnAlias , alias ) ; ctx . destroySubcontext ( rdnAlias ) ; ctx . destroySubcontext ( entryRdn ) ; } @ Test public void testAddDeleteAlias2 ( ) throws Exception { DirContext ctx = ( DirContext ) getWiredContext ( getLdapServer ( ) ) . lookup ( BASE_EXAMPLE_COM ) ; Attributes entry = new BasicAttributes ( true ) ; javax . naming . directory . Attribute entryOcls = new BasicAttribute ( SchemaConstants . OBJECT_CLASS_AT ) ; entryOcls . add ( SchemaConstants . TOP_OC ) ; entryOcls . add ( SchemaConstants . ORGANIZATIONAL_UNIT_OC ) ; entry . put ( entryOcls ) ; entry . put ( SchemaConstants . OU_AT , ""favorite"" ) ; String entryRdn = ""ou=favorite"" ; ctx . createSubcontext ( entryRdn , entry ) ; String aliasedObjectName = entryRdn + "","" + ctx . getNameInNamespace ( ) ; Attributes alias = new BasicAttributes ( true ) ; javax . naming . directory . Attribute aliasOcls = new BasicAttribute ( SchemaConstants . OBJECT_CLASS_AT ) ; aliasOcls . add ( SchemaConstants . TOP_OC ) ; aliasOcls . add ( SchemaConstants . EXTENSIBLE_OBJECT_OC ) ; aliasOcls . add ( SchemaConstants . ALIAS_OC ) ; alias . put ( aliasOcls ) ; alias . put ( SchemaConstants . OU_AT , ""bestFruit"" ) ; alias . put ( SchemaConstants . ALIASED_OBJECT_NAME_AT , aliasedObjectName ) ; String rdnAlias = ""ou=bestFruit"" ; ctx . createSubcontext ( rdnAlias , alias ) ; ctx . destroySubcontext ( rdnAlias ) ; ctx . destroySubcontext ( entryRdn ) ; } @ Test public void testAddDeleteAlias3 ( ) throws Exception { DirContext ctx = ( DirContext ) getWiredContext ( getLdapServer ( ) ) . lookup ( BASE_DIRECTORY_APACHE_ORG ) ; Attributes entry = new BasicAttributes ( true ) ; javax . naming . directory . Attribute entryOcls = new BasicAttribute ( SchemaConstants . OBJECT_CLASS_AT ) ; entryOcls . add ( SchemaConstants . TOP_OC ) ; entryOcls . add ( SchemaConstants . ORGANIZATIONAL_UNIT_OC ) ; entry . put ( entryOcls ) ; entry . put ( SchemaConstants . OU_AT , ""favorite"" ) ; String entryRdn = ""ou=favorite"" ; ctx . createSubcontext ( entryRdn , entry ) ; String aliasedObjectName = entryRdn + "","" + ctx . getNameInNamespace ( ) ; Attributes alias = new BasicAttributes ( true ) ; javax . naming . directory . Attribute aliasOcls = new BasicAttribute ( SchemaConstants . OBJECT_CLASS_AT ) ; aliasOcls . add ( SchemaConstants . TOP_OC ) ; aliasOcls . add ( SchemaConstants . EXTENSIBLE_OBJECT_OC ) ; aliasOcls . add ( SchemaConstants . ALIAS_OC ) ; alias . put ( aliasOcls ) ; alias . put ( SchemaConstants . OU_AT , ""bestFruit"" ) ; alias . put ( SchemaConstants . ALIASED_OBJECT_NAME_AT , aliasedObjectName ) ; String rdnAlias = ""ou=bestFruit"" ; ctx . createSubcontext ( rdnAlias , alias ) ; ctx . destroySubcontext ( rdnAlias ) ; ctx . destroySubcontext ( entryRdn ) ; } @ Test public void testOnReferralWithManageDsaITControl ( ) throws Exception { LDAPConnection conn = getNsdkWiredConnection ( getLdapServer ( ) ) ; LDAPConstraints constraints = new LDAPSearchConstraints ( ) ; constraints . setClientControls ( new LDAPControl ( LDAPControl . MANAGEDSAIT , true , Strings . EMPTY_BYTES ) ) ; constraints . setServerControls ( new LDAPControl ( LDAPControl . MANAGEDSAIT , true , Strings . EMPTY_BYTES ) ) ; conn . setConstraints ( constraints ) ; LDAPAttributeSet attrSet = new LDAPAttributeSet ( ) ; attrSet . add ( new LDAPAttribute ( ""objectClass"" , ""organizationalUnit"" ) ) ; attrSet . add ( new LDAPAttribute ( ""ou"" , ""UnderReferral"" ) ) ; LDAPEntry entry = new LDAPEntry ( ""ou=UnderReferral,uid=akarasuluref,ou=users,ou=system"" , attrSet ) ; try { conn . add ( entry , constraints ) ; fail ( ) ; } catch ( LDAPException le ) { assertEquals ( ResultCodeEnum . REFERRAL . getValue ( ) , le . getLDAPResultCode ( ) ) ; } try { conn . read ( ""ou=UnderReferral,uid=akarasuluref,ou=users,ou=system"" , ( LDAPSearchConstraints ) constraints ) ; fail ( ) ; } catch ( LDAPException le ) { } conn . disconnect ( ) ; } public static LdapContext getContext ( String principalDn , DirectoryService service , String dn ) throws Exception { if ( principalDn == null ) { principalDn = """" ; } Dn userDn = new Dn ( service . getSchemaManager ( ) , principalDn ) ; LdapPrincipal principal = new LdapPrincipal ( service . getSchemaManager ( ) , userDn , AuthenticationLevel . SIMPLE ) ; if ( dn == null ) { dn = """" ; } CoreSession session = service . getSession ( principal ) ; LdapContext ctx = new ServerLdapContext ( service , session , new LdapName ( dn ) ) ; return ctx ; } @ Test public void testOnReferralWitJNDIIgnore ( ) throws Exception { LdapContext MNNCtx = getContext ( ServerDNConstants . ADMIN_SYSTEM_DN , getLdapServer ( ) . getDirectoryService ( ) , ""uid=akarasuluref,ou=users,ou=system"" ) ; MNNCtx . addToEnvironment ( Context . REFERRAL , ""ignore"" ) ; try { Attributes userEntry = new BasicAttributes ( ""objectClass"" , ""top"" , true ) ; userEntry . get ( ""objectClass"" ) . add ( ""person"" ) ; userEntry . put ( ""sn"" , ""elecharny"" ) ; userEntry . put ( ""cn"" , ""Emmanuel Lecharny"" ) ; MNNCtx . createSubcontext ( ""cn=Emmanuel Lecharny, ou=apache, ou=people"" , userEntry ) ; fail ( ) ; } catch ( PartialResultException pre ) { assertTrue ( true ) ; } } @ Test public void testAncestorReferral ( ) throws Exception { LOG . debug ( """" ) ; LDAPConnection conn = getNsdkWiredConnection ( getLdapServer ( ) ) ; LDAPConstraints constraints = new LDAPConstraints ( ) ; conn . setConstraints ( constraints ) ; LDAPAttributeSet attrSet = new LDAPAttributeSet ( ) ; attrSet . add ( new LDAPAttribute ( ""objectClass"" , ""organizationalUnit"" ) ) ; attrSet . add ( new LDAPAttribute ( ""ou"" , ""UnderReferral"" ) ) ; LDAPEntry entry = new LDAPEntry ( ""ou=UnderReferral,ou=Computers,uid=akarasuluref,ou=users,ou=system"" , attrSet ) ; LDAPResponseListener listener = conn . add ( entry , null , constraints ) ; LDAPResponse response = listener . getResponse ( ) ; assertEquals ( ResultCodeEnum . REFERRAL . getValue ( ) , response . getResultCode ( ) ) ; assertEquals ( ""ldap://localhost:10389/ou=UnderReferral,ou=Computers,uid=akarasulu,ou=users,ou=system"" , response . getReferrals ( ) [ 0 ] ) ; assertEquals ( ""ldap://foo:10389/ou=UnderReferral,ou=Computers,uid=akarasulu,ou=users,ou=system"" , response . getReferrals ( ) [ 1 ] ) ; assertEquals ( ""ldap://bar:10389/ou=UnderReferral,ou=Computers,uid=akarasulu,ou=users,ou=system"" , response . getReferrals ( ) [ 2 ] ) ; conn . disconnect ( ) ; } @ Test public void testOnReferral ( ) throws Exception { LDAPConnection conn = getNsdkWiredConnection ( getLdapServer ( ) ) ; LDAPConstraints constraints = new LDAPConstraints ( ) ; constraints . setReferrals ( false ) ; conn . setConstraints ( constraints ) ; LDAPAttributeSet attrSet = new LDAPAttributeSet ( ) ; attrSet . add ( new LDAPAttribute ( ""objectClass"" , ""organizationalUnit"" ) ) ; attrSet . add ( new LDAPAttribute ( ""ou"" , ""UnderReferral"" ) ) ; LDAPEntry entry = new LDAPEntry ( ""ou=UnderReferral,uid=akarasuluref,ou=users,ou=system"" , attrSet ) ; LDAPResponseListener listener = null ; LDAPResponse response = null ; listener = conn . add ( entry , null , constraints ) ; response = listener . getResponse ( ) ; assertEquals ( ResultCodeEnum . REFERRAL . getValue ( ) , response . getResultCode ( ) ) ; assertEquals ( ""ldap://localhost:10389/ou=UnderReferral,uid=akarasulu,ou=users,ou=system"" , response . getReferrals ( ) [ 0 ] ) ; assertEquals ( ""ldap://foo:10389/ou=UnderReferral,uid=akarasulu,ou=users,ou=system"" , response . getReferrals ( ) [ 1 ] ) ; assertEquals ( ""ldap://bar:10389/ou=UnderReferral,uid=akarasulu,ou=users,ou=system"" , response . getReferrals ( ) [ 2 ] ) ; conn . disconnect ( ) ; } @ Test public void testThrowOnReferralWithJndi ( ) throws Exception { LdapContext ctx = getWiredContextThrowOnRefferal ( getLdapServer ( ) ) ; SearchControls controls = new SearchControls ( ) ; controls . setReturningAttributes ( new String [ 0 ] ) ; controls . setSearchScope ( SearchControls . OBJECT_SCOPE ) ; Attributes attrs = new BasicAttributes ( ""objectClass"" , ""organizationalUnit"" , true ) ; attrs . put ( ""ou"" , ""UnderReferral"" ) ; try { ctx . createSubcontext ( ""ou=UnderReferral,uid=akarasuluref,ou=users,ou=system"" , attrs ) ; fail ( ""Should never get here: add should fail with ReferralExcpetion"" ) ; } catch ( ReferralException e ) { assertEquals ( ""ldap://localhost:10389/ou=UnderReferral,uid=akarasulu,ou=users,ou=system"" , e . getReferralInfo ( ) ) ; } ctx . close ( ) ; } @ Test public void testDIRSERVER_1183 ( ) throws Exception { LdapContext ctx = ( LdapContext ) getWiredContext ( getLdapServer ( ) ) . lookup ( BASE ) ; Attributes attrs = new BasicAttributes ( ""objectClass"" , ""inetOrgPerson"" , true ) ; attrs . get ( ""objectClass"" ) . add ( ""organizationalPerson"" ) ; attrs . get ( ""objectClass"" ) . add ( ""person"" ) ; attrs . put ( ""givenName"" , ""Jim"" ) ; attrs . put ( ""sn"" , ""Bean"" ) ; attrs . put ( ""cn"" , ""Jim, Bean"" ) ; DirContext jimBeanCtx = ctx . createSubcontext ( ""cn=\""Jim, Bean\"""" , attrs ) ; assertNotNull ( jimBeanCtx ) ; } @ Test public void testAddEntryNoRDNInEntry ( ) throws Exception { DirContext ctx = ( DirContext ) getWiredContext ( getLdapServer ( ) ) . lookup ( BASE ) ; Attributes person = new BasicAttributes ( ""objectClass"" , ""inetOrgPerson"" , true ) ; person . get ( ""objectClass"" ) . add ( ""top"" ) ; person . get ( ""objectClass"" ) . add ( ""person"" ) ; person . get ( ""objectClass"" ) . add ( ""organizationalPerson"" ) ; person . put ( ""sn"" , ""Michael Jackson"" ) ; person . put ( ""cn"" , ""Jackson"" ) ; DirContext michaelCtx = ctx . createSubcontext ( ""givenname=Michael"" , person ) ; assertNotNull ( michaelCtx ) ; DirContext jackson = ( DirContext ) ctx . lookup ( ""givenname=Michael"" ) ; person = jackson . getAttributes ( """" ) ; javax . naming . directory . Attribute newOcls = person . get ( ""objectClass"" ) ; String [ ] expectedOcls = { ""top"" , ""person"" , ""organizationalPerson"" , ""inetOrgPerson"" } ; for ( String name : expectedOcls ) { assertTrue ( ""object class "" + name + "" is present"" , newOcls . contains ( name ) ) ; } javax . naming . directory . Attribute givenName = person . get ( ""givenname"" ) ; assertEquals ( ""Michael"" , givenName . get ( ) ) ; } @ Test public void testAddEntryDifferentRDNInEntry ( ) throws Exception { DirContext ctx = ( DirContext ) getWiredContext ( getLdapServer ( ) ) . lookup ( BASE ) ; Attributes person = new BasicAttributes ( ""objectClass"" , ""inetOrgPerson"" , true ) ; person . get ( ""objectClass"" ) . add ( ""top"" ) ; person . get ( ""objectClass"" ) . add ( ""person"" ) ; person . get ( ""objectClass"" ) . add ( ""organizationalPerson"" ) ; person . put ( ""givenName"" , ""Michael"" ) ; person . put ( ""sn"" , ""Michael Jackson"" ) ; person . put ( ""cn"" , ""Jackson"" ) ; DirContext michaelCtx = ctx . createSubcontext ( ""cn=Michael"" , person ) ; assertNotNull ( michaelCtx ) ; DirContext jackson = ( DirContext ) ctx . lookup ( ""cn=Michael"" ) ; person = jackson . getAttributes ( """" ) ; javax . naming . directory . Attribute newOcls = person . get ( ""objectClass"" ) ; String [ ] expectedOcls = { ""top"" , ""person"" , ""organizationalPerson"" , ""inetOrgPerson"" } ; for ( String name : expectedOcls ) { assertTrue ( ""object class "" + name + "" is present"" , newOcls . contains ( name ) ) ; } javax . naming . directory . Attribute cn = person . get ( ""cn"" ) ; assertEquals ( 2 , cn . size ( ) ) ; String [ ] expectedCns = { ""Jackson"" , ""Michael"" } ; for ( String name : expectedCns ) { assertTrue ( ""CN "" + name + "" is present"" , cn . contains ( name ) ) ; } } @ Test public void testAddEntryDifferentRDNSingleValuedInEntry ( ) throws Exception { DirContext ctx = ( DirContext ) getWiredContext ( getLdapServer ( ) ) . lookup ( BASE ) ; Attributes person = new BasicAttributes ( ""objectClass"" , ""inetOrgPerson"" , true ) ; person . get ( ""objectClass"" ) . add ( ""top"" ) ; person . get ( ""objectClass"" ) . add ( ""person"" ) ; person . get ( ""objectClass"" ) . add ( ""organizationalPerson"" ) ; person . put ( ""displayName"" , ""Michael"" ) ; person . put ( ""sn"" , ""Michael Jackson"" ) ; person . put ( ""cn"" , ""Jackson"" ) ; DirContext michaelCtx = ctx . createSubcontext ( ""displayName=test"" , person ) ; assertNotNull ( michaelCtx ) ; DirContext jackson = ( DirContext ) ctx . lookup ( ""displayName=test"" ) ; person = jackson . getAttributes ( """" ) ; javax . naming . directory . Attribute newOcls = person . get ( ""objectClass"" ) ; String [ ] expectedOcls = { ""top"" , ""person"" , ""organizationalPerson"" , ""inetOrgPerson"" } ; for ( String name : expectedOcls ) { assertTrue ( ""object class "" + name + "" is present"" , newOcls . contains ( name ) ) ; } javax . naming . directory . Attribute displayName = person . get ( ""displayName"" ) ; assertEquals ( 1 , displayName . size ( ) ) ; assertTrue ( displayName . contains ( ""test"" ) ) ; } @ Test public void testAddEntryComposedRDN ( ) throws Exception { DirContext ctx = ( DirContext ) getWiredContext ( getLdapServer ( ) ) . lookup ( BASE ) ; Attributes person = new BasicAttributes ( ""objectClass"" , ""inetOrgPerson"" , true ) ; person . get ( ""objectClass"" ) . add ( ""top"" ) ; person . get ( ""objectClass"" ) . add ( ""person"" ) ; person . get ( ""objectClass"" ) . add ( ""organizationalPerson"" ) ; person . put ( ""sn"" , ""Michael Jackson"" ) ; person . put ( ""cn"" , ""Jackson"" ) ; DirContext michaelCtx = ctx . createSubcontext ( ""displayName=test+cn=Michael"" , person ) ; assertNotNull ( michaelCtx ) ; DirContext jackson = ( DirContext ) ctx . lookup ( ""displayName=test+cn=Michael"" ) ; person = jackson . getAttributes ( """" ) ; javax . naming . directory . Attribute newOcls = person . get ( ""objectClass"" ) ; String [ ] expectedOcls = { ""top"" , ""person"" , ""organizationalPerson"" , ""inetOrgPerson"" } ; for ( String name : expectedOcls ) { assertTrue ( ""object class "" + name + "" is present"" , newOcls . contains ( name ) ) ; } javax . naming . directory . Attribute displayName = person . get ( ""displayName"" ) ; assertEquals ( 1 , displayName . size ( ) ) ; assertTrue ( displayName . contains ( ""test"" ) ) ; javax . naming . directory . Attribute cn = person . get ( ""cn"" ) ; assertEquals ( 2 , cn . size ( ) ) ; assertTrue ( cn . contains ( ""Jackson"" ) ) ; assertTrue ( cn . contains ( ""Michael"" ) ) ; } @ Test public void testAddPDUExceedingMaxSizeJNDI ( ) throws Exception { getLdapServer ( ) . getDirectoryService ( ) . setMaxPDUSize ( 1024 ) ; DirContext ctx = ( DirContext ) getWiredContext ( getLdapServer ( ) ) . lookup ( BASE ) ; Attributes attributes = new BasicAttributes ( true ) ; javax . naming . directory . Attribute ocls = new BasicAttribute ( ""description"" ) ; StringBuilder sb = new StringBuilder ( ) ; for ( int i = 0 ; i < 128 ; i ++ ) { sb . append ( ""0123456789ABCDEF"" ) ; } ocls . add ( sb . toString ( ) ) ; attributes . put ( ocls ) ; DirContext person = ( DirContext ) ctx . lookup ( RDN ) ; try { person . modifyAttributes ( """" , DirContext . ADD_ATTRIBUTE , attributes ) ; fail ( ) ; } catch ( Exception e ) { } getLdapServer ( ) . getDirectoryService ( ) . setMaxPDUSize ( 4096 ) ; ctx = ( DirContext ) getWiredContext ( getLdapServer ( ) ) . lookup ( BASE ) ; person = ( DirContext ) ctx . lookup ( RDN ) ; try { person . modifyAttributes ( """" , DirContext . ADD_ATTRIBUTE , attributes ) ; } catch ( Exception e ) { fail ( ) ; } ctx = ( DirContext ) getWiredContext ( getLdapServer ( ) ) . lookup ( BASE ) ; person = ( DirContext ) ctx . lookup ( RDN ) ; assertNotNull ( person ) ; attributes = person . getAttributes ( """" ) ; javax . naming . directory . Attribute newOcls = attributes . get ( ""objectClass"" ) ; assertNotNull ( newOcls ) ; } @ Test public void testAddPDUExceedingMaxSizeLdapApi ( ) throws Exception { getLdapServer ( ) . getDirectoryService ( ) . setMaxPDUSize ( 1024 ) ; LdapConnection connection = new LdapNetworkConnection ( Network . LOOPBACK_HOSTNAME , getLdapServer ( ) . getPort ( ) ) ; connection . bind ( ""uid=admin,ou=system"" , ""secret"" ) ; StringBuilder sb = new StringBuilder ( ) ; for ( int i = 0 ; i < 128 ; i ++ ) { sb . append ( ""0123456789ABCDEF"" ) ; } Attribute description = new DefaultAttribute ( ""description"" , sb . toString ( ) ) ; try { Modification modification = new DefaultModification ( ModificationOperation . ADD_ATTRIBUTE , description ) ; connection . modify ( ""cn=the person, ou=system"" , modification ) ; fail ( ) ; } catch ( Exception e ) { if ( connection . isConnected ( ) ) { Thread . sleep ( 1000 ) ; } assertFalse ( connection . isConnected ( ) ) ; } } @ Test public void testAddUnescapedRdnValue_DIRSERVER_1311 ( ) throws Exception { LdapContext ctx = ( LdapContext ) getWiredContext ( getLdapServer ( ) ) . lookup ( BASE ) ; Attributes tori = new BasicAttributes ( true ) ; javax . naming . directory . Attribute toriOC = new BasicAttribute ( ""objectClass"" ) ; toriOC . add ( ""top"" ) ; toriOC . add ( ""person"" ) ; tori . put ( toriOC ) ; tori . put ( ""cn"" , ""Tori,Amos"" ) ; tori . put ( ""sn"" , ""Amos"" ) ; ctx . createSubcontext ( "" cn = Amos\\,Tori "" , tori ) ; Attributes binary = new BasicAttributes ( true ) ; javax . naming . directory . Attribute binaryOC = new BasicAttribute ( ""objectClass"" ) ; binaryOC . add ( ""top"" ) ; binaryOC . add ( ""person"" ) ; binary . put ( binaryOC ) ; binary . put ( ""cn"" , ""Binary"" ) ; binary . put ( ""sn"" , ""Binary"" ) ; binary . put ( ""userPassword"" , ""test"" ) ; ctx . createSubcontext ( "" userPassword = #414243 "" , binary ) ; SearchControls controls = new SearchControls ( ) ; NamingEnumeration < SearchResult > res ; res = ctx . search ( """" , ""(cn=Amos,Tori)"" , controls ) ; assertTrue ( res . hasMore ( ) ) ; javax . naming . directory . Attribute cnAttribute = res . next ( ) . getAttributes ( ) . get ( ""cn"" ) ; assertEquals ( 2 , cnAttribute . size ( ) ) ; assertTrue ( cnAttribute . contains ( ""Tori,Amos"" ) ) ; assertTrue ( cnAttribute . contains ( ""Amos\\,Tori"" ) ) ; assertFalse ( res . hasMore ( ) ) ; res = ctx . search ( """" , ""(userPassword=\\41\\42\\43)"" , controls ) ; assertTrue ( res . hasMore ( ) ) ; javax . naming . directory . Attribute userPasswordAttribute = res . next ( ) . getAttributes ( ) . get ( ""userPassword"" ) ; assertEquals ( 2 , userPasswordAttribute . size ( ) ) ; assertTrue ( userPasswordAttribute . contains ( Strings . getBytesUtf8 ( ""test"" ) ) ) ; assertTrue ( userPasswordAttribute . contains ( Strings . getBytesUtf8 ( ""ABC"" ) ) ) ; assertFalse ( res . hasMore ( ) ) ; } @ Test public void testAddEntryUUIDAndCSNAttributes ( ) throws Exception { LdapConnection con = getAdminConnection ( getLdapServer ( ) ) ; String dn = ""cn=Kate Bush,"" + BASE ; Entry entry = new DefaultEntry ( dn ) ; entry . add ( ""objectclass"" , ""top"" , ""person"" ) ; entry . add ( ""sn"" , ""Bush"" ) ; entry . add ( ""cn"" , ""Kate Bush"" ) ; String descr = ""a British singer-songwriter with an expressive four-octave voice"" ; entry . add ( ""description"" , descr ) ; UUID uuid = UUID . randomUUID ( ) ; entry . add ( SchemaConstants . ENTRY_UUID_AT , uuid . toString ( ) ) ; CsnFactory csnFac = new CsnFactory ( 0 ) ; Csn csn = csnFac . newInstance ( ) ; entry . add ( SchemaConstants . ENTRY_CSN_AT , csn . toString ( ) ) ; con . add ( entry ) ; Entry addedEntry = con . lookup ( dn , ""*"" , ""+"" ) ; assertNotNull ( addedEntry ) ; Attribute attr = addedEntry . get ( SchemaConstants . ENTRY_UUID_AT ) ; assertNotNull ( attr ) ; assertEquals ( uuid . toString ( ) , attr . getString ( ) ) ; attr = addedEntry . get ( SchemaConstants . ENTRY_CSN_AT ) ; assertNotNull ( attr ) ; assertEquals ( csn . toString ( ) , attr . getString ( ) ) ; con . delete ( dn ) ; con . unBind ( ) ; } protected Attributes getPersonAttributes ( String sn , String cn ) { Attributes attrs = new BasicAttributes ( true ) ; javax . naming . directory . Attribute ocls = new BasicAttribute ( ""objectClass"" ) ; ocls . add ( ""top"" ) ; ocls . add ( ""person"" ) ; attrs . put ( ocls ) ; attrs . put ( ""cn"" , cn ) ; attrs . put ( ""sn"" , sn ) ; return attrs ; } protected Attributes getOrgUnitAttributes ( String ou ) { Attributes attrs = new BasicAttributes ( true ) ; javax . naming . directory . Attribute ocls = new BasicAttribute ( ""objectClass"" ) ; ocls . add ( ""top"" ) ; ocls . add ( ""organizationalUnit"" ) ; attrs . put ( ocls ) ; attrs . put ( ""ou"" , ou ) ; return attrs ; } @ Test @ CreateDS ( enableChangeLog = false , name = ""DSAlias"" ) @ CreateLdapServer ( name = ""DSAlias"" , transports = { @ CreateTransport ( protocol = ""LDAP"" , port = - 1 ) } ) public void test_DIRSERVER_1357 ( ) throws Exception { DirContext ctx = ( DirContext ) ServerIntegrationUtils . getWiredContext ( getLdapServer ( ) ) . lookup ( ""ou=system"" ) ; Attributes salesAttrs = getOrgUnitAttributes ( ""sales"" ) ; ctx . createSubcontext ( ""ou=sales"" , salesAttrs ) ; Attributes engAttrs = getOrgUnitAttributes ( ""engineering"" ) ; ctx . createSubcontext ( ""ou=engineering"" , engAttrs ) ; Attributes fooAttrs = getPersonAttributes ( ""real"" , ""real"" ) ; ctx . createSubcontext ( ""cn=real,ou=sales"" , fooAttrs ) ; Attributes aliasAttrs = new BasicAttributes ( true ) ; javax . naming . directory . Attribute aliasOC = new BasicAttribute ( ""objectClass"" ) ; aliasOC . add ( ""top"" ) ; aliasOC . add ( ""alias"" ) ; aliasOC . add ( ""extensibleObject"" ) ; aliasAttrs . put ( aliasOC ) ; aliasAttrs . put ( ""cn"" , ""alias"" ) ; aliasAttrs . put ( ""aliasedObjectName"" , ""cn=real,ou=sales,ou=system"" ) ; ctx . createSubcontext ( ""cn=alias,ou=engineering"" , aliasAttrs ) ; ctx . destroySubcontext ( ""cn=real,ou=sales"" ) ; ctx . destroySubcontext ( ""cn=alias,ou=engineering"" ) ; } @ Test public void testAddEntryNonExistingAT ( ) throws Exception { LdapConnection connection = getAdminConnection ( getLdapServer ( ) ) ; Dn dn = new Dn ( ""cn=Kate Bush,"" + BASE ) ; Entry personEntry = new DefaultEntry ( ) ; personEntry . add ( SchemaConstants . OBJECT_CLASS_AT , ""person"" ) ; personEntry . add ( SchemaConstants . CN_AT , ""Kate Bush"" ) ; personEntry . add ( SchemaConstants . SN_AT , ""Bush"" ) ; personEntry . add ( ""nonExistingAttribute"" , ""value"" ) ; personEntry . setDn ( dn ) ; try { connection . add ( personEntry ) ; fail ( ""should throw LdapNoSuchAttributeException"" ) ; } catch ( LdapNoSuchAttributeException e ) { } Entry entry = connection . lookup ( dn ) ; assertNull ( entry ) ; connection . close ( ) ; } @ Test ( expected = LdapOperationException . class ) public void testAddEntryNonExistingOC ( ) throws Exception { LdapConnection connection = getAdminConnection ( getLdapServer ( ) ) ; Dn dn = new Dn ( ""cn=Kate Bush,"" + BASE ) ; Entry personEntry = new DefaultEntry ( ) ; personEntry . add ( SchemaConstants . OBJECT_CLASS_AT , ""nonexistingOC"" ) ; personEntry . add ( SchemaConstants . CN_AT , ""Kate Bush"" ) ; personEntry . add ( SchemaConstants . SN_AT , ""Bush"" ) ; personEntry . setDn ( dn ) ; connection . add ( personEntry ) ; } @ Test ( expected = LdapException . class ) public void testAddEntry100KData ( ) throws Exception { LdapConnection connection = getAdminConnection ( getLdapServer ( ) ) ; int size = 100 * 1024 ; byte [ ] dataBytes = new byte [ size ] ; for ( int i = 0 ; i < size ; i ++ ) { dataBytes [ i ] = 'A' ; } String data = Strings . utf8ToString ( dataBytes ) ; Dn dn = new Dn ( ""cn=Kate Bush,"" + BASE ) ; Entry personEntry = new DefaultEntry ( ""cn=Kate Bush,"" + BASE , ""objectClass: top"" , ""objectClass: person"" , ""cn: Kate Bush"" , ""sn: Bush"" , ""description"" , data ) ; connection . add ( personEntry ) ; Entry entry = connection . lookup ( dn , ""description"" , ""cn"" , ""sn"" ) ; String description = entry . get ( ""description"" ) . getString ( ) ; assertNotNull ( description ) ; assertTrue ( description . startsWith ( ""AAA"" ) ) ; assertEquals ( size , description . length ( ) ) ; for ( int i = 0 ; i < size ; i ++ ) { assertEquals ( 'A' , description . charAt ( i ) ) ; } } }",Smelly
"public class OlcDatabaseConfig extends OlcConfig { @ ConfigurationElement ( attributeType = ""olcAccess"" , version = ""2.4.0"" ) private List < String > olcAccess = new ArrayList < > ( ) ; @ ConfigurationElement ( attributeType = ""olcAddContentAcl"" , version = ""2.4.13"" ) private Boolean olcAddContentAcl ; @ ConfigurationElement ( attributeType = ""olcDatabase"" , isOptional = false , isRdn = true , version = ""2.4.0"" ) private String olcDatabase ; @ ConfigurationElement ( attributeType = ""olcDisabled"" , version = ""2.4.36"" ) private Boolean olcDisabled ; @ ConfigurationElement ( attributeType = ""olcExtraAttrs"" , version = ""2.4.22"" ) private List < String > olcExtraAttrs ; @ ConfigurationElement ( attributeType = ""olcHidden"" , version = ""2.4.0"" ) private Boolean olcHidden ; @ ConfigurationElement ( attributeType = ""olcLastMod"" , version = ""2.4.0"" ) private Boolean olcLastMod ; @ ConfigurationElement ( attributeType = ""olcLimits"" , version = ""2.4.0"" ) private List < String > olcLimits = new ArrayList < > ( ) ; @ ConfigurationElement ( attributeType = ""olcMaxDerefDepth"" , version = ""2.4.0"" ) private Integer olcMaxDerefDepth ; @ ConfigurationElement ( attributeType = ""olcMirrorMode"" , version = ""2.4.0"" ) private Boolean olcMirrorMode ; @ ConfigurationElement ( attributeType = ""olcMonitoring"" , version = ""2.4.0"" ) private Boolean olcMonitoring ; @ ConfigurationElement ( attributeType = ""olcPlugin"" , version = ""2.4.0"" ) private List < String > olcPlugin = new ArrayList < > ( ) ; @ ConfigurationElement ( attributeType = ""olcReadOnly"" , version = ""2.4.0"" ) private Boolean olcReadOnly ; @ ConfigurationElement ( attributeType = ""olcReplica"" , version = ""2.4.0"" ) private List < String > olcReplica = new ArrayList < > ( ) ; @ ConfigurationElement ( attributeType = ""olcReplicaArgsFile"" , version = ""2.4.0"" ) private String olcReplicaArgsFile ; @ ConfigurationElement ( attributeType = ""olcReplicaPidFile"" , version = ""2.4.0"" ) private String olcReplicaPidFile ; @ ConfigurationElement ( attributeType = ""olcReplicationInterval"" , version = ""2.4.0"" ) private Integer olcReplicationInterval ; @ ConfigurationElement ( attributeType = ""olcReplogFile"" , version = ""2.4.0"" ) private String olcReplogFile ; @ ConfigurationElement ( attributeType = ""olcRequires"" , version = ""2.4.0"" ) private List < String > olcRequires = new ArrayList < > ( ) ; @ ConfigurationElement ( attributeType = ""olcRestrict"" , version = ""2.4.0"" ) private List < String > olcRestrict = new ArrayList < > ( ) ; @ ConfigurationElement ( attributeType = ""olcRootDN"" , version = ""2.4.0"" ) private Dn olcRootDN ; @ ConfigurationElement ( attributeType = ""olcRootPW"" , version = ""2.4.0"" ) private String olcRootPW ; @ ConfigurationElement ( attributeType = ""olcSchemaDN"" , version = ""2.4.0"" ) private Dn olcSchemaDN ; @ ConfigurationElement ( attributeType = ""olcSecurity"" , version = ""2.4.0"" ) private List < String > olcSecurity = new ArrayList < > ( ) ; @ ConfigurationElement ( attributeType = ""olcSizeLimit"" , version = ""2.4.0"" ) private String olcSizeLimit ; @ ConfigurationElement ( attributeType = ""olcSubordinate"" , version = ""2.4.0"" ) private String olcSubordinate ; @ ConfigurationElement ( attributeType = ""olcSuffix"" , version = ""2.4.0"" ) private List < Dn > olcSuffix = new ArrayList < > ( ) ; @ ConfigurationElement ( attributeType = ""olcSyncrepl"" , version = ""2.4.0"" ) private List < String > olcSyncrepl = new ArrayList < > ( ) ; @ ConfigurationElement ( attributeType = ""olcSyncUseSubentry"" , version = ""2.4.20"" ) private Boolean olcSyncUseSubentry ; @ ConfigurationElement ( attributeType = ""olcTimeLimit"" , version = ""2.4.0"" ) private List < String > olcTimeLimit = new ArrayList < > ( ) ; @ ConfigurationElement ( attributeType = ""olcUpdateDN"" , version = ""2.4.0"" ) private Dn olcUpdateDN ; @ ConfigurationElement ( attributeType = ""olcUpdateRef"" , version = ""2.4.0"" ) private List < String > olcUpdateRef = new ArrayList < > ( ) ; private List < OlcOverlayConfig > overlays = new ArrayList < > ( ) ; public void addOlcAccess ( String ... strings ) { for ( String string : strings ) { olcAccess . add ( string ) ; } } public void addOlcExtraAttrs ( String ... strings ) { for ( String string : strings ) { olcExtraAttrs . add ( string ) ; } } public void addOlcLimits ( String ... strings ) { for ( String string : strings ) { olcLimits . add ( string ) ; } } public void addOlcPlugin ( String ... strings ) { for ( String string : strings ) { olcPlugin . add ( string ) ; } } public void addOlcReplica ( String ... strings ) { for ( String string : strings ) { olcReplica . add ( string ) ; } } public void addOlcRequires ( String ... strings ) { for ( String string : strings ) { olcRequires . add ( string ) ; } } public void addOlcRestrict ( String ... strings ) { for ( String string : strings ) { olcRestrict . add ( string ) ; } } public void addOlcSecurity ( String ... strings ) { for ( String string : strings ) { olcSecurity . add ( string ) ; } } public void addOlcSuffix ( Dn ... dns ) { for ( Dn dn : dns ) { olcSuffix . add ( dn ) ; } } public void addOlcSyncrepl ( String ... strings ) { for ( String string : strings ) { olcSyncrepl . add ( string ) ; } } public void addOlcTimeLimit ( String ... strings ) { for ( String string : strings ) { olcTimeLimit . add ( string ) ; } } public void addOlcUpdateRef ( String ... strings ) { for ( String string : strings ) { olcUpdateRef . add ( string ) ; } } public void clearOlcAccess ( ) { olcAccess . clear ( ) ; } public void clearOlcExtraAttrs ( ) { olcExtraAttrs . clear ( ) ; } public void clearOlcLimits ( ) { olcLimits . clear ( ) ; } public void clearOlcPlugin ( ) { olcPlugin . clear ( ) ; } public void clearOlcReplica ( ) { olcReplica . clear ( ) ; } public void clearOlcRequires ( ) { olcRequires . clear ( ) ; } public void clearOlcRestrict ( ) { olcRestrict . clear ( ) ; } public void clearOlcSecurity ( ) { olcSecurity . clear ( ) ; } public void clearOlcSuffix ( ) { olcSuffix . clear ( ) ; } public void clearOlcSyncrepl ( ) { olcSyncrepl . clear ( ) ; } public void clearOlcTimeLimit ( ) { olcTimeLimit . clear ( ) ; } public void clearOlcUpdateRef ( ) { olcUpdateRef . clear ( ) ; } public List < String > getOlcAccess ( ) { return copyListString ( olcAccess ) ; } public Boolean getOlcAddContentAcl ( ) { return olcAddContentAcl ; } public String getOlcDatabase ( ) { return olcDatabase ; } public Boolean getOlcDisabled ( ) { return olcDisabled ; } public List < String > getOlcExtraAttrs ( ) { return copyListString ( olcExtraAttrs ) ; } public Boolean getOlcHidden ( ) { return olcHidden ; } public Boolean getOlcLastMod ( ) { return olcLastMod ; } public List < String > getOlcLimits ( ) { return copyListString ( olcLimits ) ; } public Integer getOlcMaxDerefDepth ( ) { return olcMaxDerefDepth ; } public Boolean getOlcMirrorMode ( ) { return olcMirrorMode ; } public Boolean getOlcMonitoring ( ) { return olcMonitoring ; } public List < String > getOlcPlugin ( ) { return copyListString ( olcPlugin ) ; } public Boolean getOlcReadOnly ( ) { return olcReadOnly ; } public List < String > getOlcReplica ( ) { return copyListString ( olcReplica ) ; } public String getOlcReplicaArgsFile ( ) { return olcReplicaArgsFile ; } public String getOlcReplicaPidFile ( ) { return olcReplicaPidFile ; } public Integer getOlcReplicationInterval ( ) { return olcReplicationInterval ; } public String getOlcReplogFile ( ) { return olcReplogFile ; } public List < String > getOlcRequires ( ) { return copyListString ( olcRequires ) ; } public List < String > getOlcRestrict ( ) { return copyListString ( olcRestrict ) ; } public Dn getOlcRootDN ( ) { return olcRootDN ; } public String getOlcRootPW ( ) { return olcRootPW ; } public Dn getOlcSchemaDN ( ) { return olcSchemaDN ; } public List < String > getOlcSecurity ( ) { return copyListString ( olcSecurity ) ; } public String getOlcSizeLimit ( ) { return olcSizeLimit ; } public String getOlcSubordinate ( ) { return olcSubordinate ; } public List < Dn > getOlcSuffix ( ) { return olcSuffix ; } public List < String > getOlcSyncrepl ( ) { return copyListString ( olcSyncrepl ) ; } public Boolean getOlcSyncUseSubentry ( ) { return olcSyncUseSubentry ; } public List < String > getOlcTimeLimit ( ) { return copyListString ( olcTimeLimit ) ; } public Dn getOlcUpdateDN ( ) { return olcUpdateDN ; } public List < String > getOlcUpdateRef ( ) { return copyListString ( olcUpdateRef ) ; } public List < OlcOverlayConfig > getOverlays ( ) { return overlays ; } public void setOverlays ( List < OlcOverlayConfig > overlays ) { this . overlays = overlays ; } public void clearOverlays ( ) { overlays . clear ( ) ; } public boolean addOverlay ( OlcOverlayConfig o ) { return overlays . add ( o ) ; } public boolean removeOverlay ( OlcOverlayConfig o ) { return overlays . remove ( o ) ; } public void setOlcAccess ( List < String > olcAccess ) { this . olcAccess = copyListString ( olcAccess ) ; } public void setOlcAddContentAcl ( Boolean olcAddContentAcl ) { this . olcAddContentAcl = olcAddContentAcl ; } public void setOlcDatabase ( String olcDatabase ) { this . olcDatabase = olcDatabase ; } public void setOlcDisabled ( Boolean olcDisabled ) { this . olcDisabled = olcDisabled ; } public void setOlcExtraAttrs ( List < String > olcExtraAttrs ) { this . olcExtraAttrs = copyListString ( olcExtraAttrs ) ; } public void setOlcHidden ( Boolean olcHidden ) { this . olcHidden = olcHidden ; } public void setOlcLastMod ( Boolean olcLastMod ) { this . olcLastMod = olcLastMod ; } public void setOlcLimits ( List < String > olcLimits ) { this . olcLimits = copyListString ( olcLimits ) ; } public void setOlcMaxDerefDepth ( Integer olcMaxDerefDepth ) { this . olcMaxDerefDepth = olcMaxDerefDepth ; } public void setOlcMirrorMode ( Boolean olcMirrorMode ) { this . olcMirrorMode = olcMirrorMode ; } public void setOlcMonitoring ( Boolean olcMonitoring ) { this . olcMonitoring = olcMonitoring ; } public void setOlcPlugin ( List < String > olcPlugin ) { this . olcPlugin = copyListString ( olcPlugin ) ; } public void setOlcReadOnly ( Boolean olcReadOnly ) { this . olcReadOnly = olcReadOnly ; } public void setOlcReplica ( List < String > olcReplica ) { this . olcReplica = copyListString ( olcReplica ) ; } public void setOlcReplicaArgsFile ( String olcReplicaArgsFile ) { this . olcReplicaArgsFile = olcReplicaArgsFile ; } public void setOlcReplicaPidFile ( String olcReplicaPidFile ) { this . olcReplicaPidFile = olcReplicaPidFile ; } public void setOlcReplicationInterval ( Integer olcReplicationInterval ) { this . olcReplicationInterval = olcReplicationInterval ; } public void setOlcReplogFile ( String olcReplogFile ) { this . olcReplogFile = olcReplogFile ; } public void setOlcRequires ( List < String > olcRequires ) { this . olcRequires = copyListString ( olcRequires ) ; } public void setOlcRestrict ( List < String > olcRestrict ) { this . olcRestrict = copyListString ( olcRestrict ) ; } public void setOlcRootDN ( Dn olcRootDN ) { this . olcRootDN = olcRootDN ; } public void setOlcRootPW ( String olcRootPW ) { this . olcRootPW = olcRootPW ; } public void setOlcSchemaDN ( Dn olcSchemaDN ) { this . olcSchemaDN = olcSchemaDN ; } public void setOlcSecurity ( List < String > olcSecurity ) { this . olcSecurity = copyListString ( olcSecurity ) ; } public void setOlcSizeLimit ( String olcSizeLimit ) { this . olcSizeLimit = olcSizeLimit ; } public void setOlcSubordinate ( String olcSubordinate ) { this . olcSubordinate = olcSubordinate ; } public void setOlcSuffix ( List < Dn > olcSuffix ) { this . olcSuffix = olcSuffix ; } public void setOlcSyncrepl ( List < String > olcSyncrepl ) { this . olcSyncrepl = copyListString ( olcSyncrepl ) ; } public void setOlcSyncUseSubentry ( Boolean olcSyncUseSubentry ) { this . olcSyncUseSubentry = olcSyncUseSubentry ; } public void setOlcTimeLimit ( List < String > olcTimeLimit ) { this . olcTimeLimit = copyListString ( olcTimeLimit ) ; } public void setOlcUpdateDN ( Dn olcUpdateDN ) { this . olcUpdateDN = olcUpdateDN ; } public void setOlcUpdateRef ( List < String > olcUpdateRef ) { this . olcUpdateRef = copyListString ( olcUpdateRef ) ; } public String getOlcDatabaseType ( ) { return ""default"" ; } }",Smelly
" private class SinglySplitTrieNode extends TrieNode { final int lower ; final BinaryComparable mySplitPoint ; SinglySplitTrieNode ( int level , BinaryComparable [ ] splitPoints , int lower ) { super ( level ) ; this . lower = lower ; this . mySplitPoint = splitPoints [ lower ] ; } public int findPartition ( BinaryComparable key ) { return lower + ( key . compareTo ( mySplitPoint ) < 0 ? 0 : 1 ) ; } ",No
"public final class XMLUtils { private static final Logger LOG = LogUtils . getL7dLogger ( XMLUtils . class ) ; private static final Map < ClassLoader , DocumentBuilderFactory > DOCUMENT_BUILDER_FACTORIES = Collections . synchronizedMap ( new WeakHashMap < ClassLoader , DocumentBuilderFactory > ( ) ) ; private static final Map < ClassLoader , TransformerFactory > TRANSFORMER_FACTORIES = Collections . synchronizedMap ( new WeakHashMap < ClassLoader , TransformerFactory > ( ) ) ; private XMLUtils ( ) { } private static TransformerFactory getTransformerFactory ( ) { ClassLoader loader = Thread . currentThread ( ) . getContextClassLoader ( ) ; if ( loader == null ) { loader = XMLUtils . class . getClassLoader ( ) ; } if ( loader == null ) { return TransformerFactory . newInstance ( ) ; } TransformerFactory factory = TRANSFORMER_FACTORIES . get ( loader ) ; if ( factory == null ) { factory = TransformerFactory . newInstance ( ) ; TRANSFORMER_FACTORIES . put ( loader , factory ) ; } return factory ; } private static DocumentBuilderFactory getDocumentBuilderFactory ( ) { ClassLoader loader = Thread . currentThread ( ) . getContextClassLoader ( ) ; if ( loader == null ) { loader = XMLUtils . class . getClassLoader ( ) ; } if ( loader == null ) { return DocumentBuilderFactory . newInstance ( ) ; } DocumentBuilderFactory factory = DOCUMENT_BUILDER_FACTORIES . get ( loader ) ; if ( factory == null ) { factory = DocumentBuilderFactory . newInstance ( ) ; factory . setNamespaceAware ( true ) ; DOCUMENT_BUILDER_FACTORIES . put ( loader , factory ) ; } return factory ; } public static Transformer newTransformer ( ) throws TransformerConfigurationException { return getTransformerFactory ( ) . newTransformer ( ) ; } public static Transformer newTransformer ( int indent ) throws TransformerConfigurationException { if ( indent > 0 ) { TransformerFactory f = TransformerFactory . newInstance ( ) ; try { f . setAttribute ( ""indent-number"" , Integer . toString ( indent ) ) ; } catch ( Throwable t ) { } return f . newTransformer ( ) ; } return getTransformerFactory ( ) . newTransformer ( ) ; } public static DocumentBuilder getParser ( ) throws ParserConfigurationException { return getDocumentBuilderFactory ( ) . newDocumentBuilder ( ) ; } public static Document parse ( InputSource is ) throws ParserConfigurationException , SAXException , IOException { return getParser ( ) . parse ( is ) ; } public static Document parse ( File is ) throws ParserConfigurationException , SAXException , IOException { return getParser ( ) . parse ( is ) ; } public static Document parse ( InputStream in ) throws ParserConfigurationException , SAXException , IOException { if ( in == null && LOG . isLoggable ( Level . FINE ) ) { LOG . fine ( ""XMLUtils trying to parse a null inputstream"" ) ; } return getParser ( ) . parse ( in ) ; } public static Document parse ( String in ) throws ParserConfigurationException , SAXException , IOException { return parse ( in . getBytes ( ) ) ; } public static Document parse ( byte [ ] in ) throws ParserConfigurationException , SAXException , IOException { if ( in == null ) { if ( LOG . isLoggable ( Level . FINE ) ) { LOG . fine ( ""XMLUtils trying to parse a null bytes"" ) ; } return null ; } return getParser ( ) . parse ( new ByteArrayInputStream ( in ) ) ; } public static Document newDocument ( ) throws ParserConfigurationException { return getParser ( ) . newDocument ( ) ; } public static void writeTo ( Node node , OutputStream os ) { writeTo ( new DOMSource ( node ) , os ) ; } public static void writeTo ( Node node , OutputStream os , int indent ) { writeTo ( new DOMSource ( node ) , os , indent ) ; } public static void writeTo ( Source src , OutputStream os ) { writeTo ( src , os , - 1 ) ; } public static void writeTo ( Node node , Writer os ) { writeTo ( new DOMSource ( node ) , os ) ; } public static void writeTo ( Node node , Writer os , int indent ) { writeTo ( new DOMSource ( node ) , os , indent ) ; } public static void writeTo ( Source src , Writer os ) { writeTo ( src , os , - 1 ) ; } public static void writeTo ( Source src , OutputStream os , int indent ) { String enc = null ; if ( src instanceof DOMSource && ( ( DOMSource ) src ) . getNode ( ) instanceof Document ) { try { enc = ( ( Document ) ( ( DOMSource ) src ) . getNode ( ) ) . getXmlEncoding ( ) ; } catch ( Exception ex ) { } } writeTo ( src , os , indent , enc , ""no"" ) ; } public static void writeTo ( Source src , Writer os , int indent ) { String enc = null ; if ( src instanceof DOMSource && ( ( DOMSource ) src ) . getNode ( ) instanceof Document ) { try { enc = ( ( Document ) ( ( DOMSource ) src ) . getNode ( ) ) . getXmlEncoding ( ) ; } catch ( Exception ex ) { } } writeTo ( src , os , indent , enc , ""no"" ) ; } public static void writeTo ( Source src , OutputStream os , int indent , String charset , String omitXmlDecl ) { Transformer it ; try { if ( StringUtils . isEmpty ( charset ) ) { charset = ""utf-8"" ; } it = newTransformer ( indent ) ; it . setOutputProperty ( OutputKeys . METHOD , ""xml"" ) ; if ( indent > - 1 ) { it . setOutputProperty ( OutputKeys . INDENT , ""yes"" ) ; it . setOutputProperty ( ""{http://xml.apache.org/xslt}indent-amount"" , Integer . toString ( indent ) ) ; } it . setOutputProperty ( OutputKeys . OMIT_XML_DECLARATION , omitXmlDecl ) ; it . setOutputProperty ( OutputKeys . ENCODING , charset ) ; it . transform ( src , new StreamResult ( os ) ) ; } catch ( TransformerException e ) { throw new RuntimeException ( ""Failed to configure TRaX"" , e ) ; } } public static void writeTo ( Source src , Writer os , int indent , String charset , String omitXmlDecl ) { Transformer it ; try { if ( StringUtils . isEmpty ( charset ) ) { charset = ""utf-8"" ; } it = newTransformer ( indent ) ; it . setOutputProperty ( OutputKeys . METHOD , ""xml"" ) ; if ( indent > - 1 ) { it . setOutputProperty ( OutputKeys . INDENT , ""yes"" ) ; it . setOutputProperty ( ""{http://xml.apache.org/xslt}indent-amount"" , Integer . toString ( indent ) ) ; } it . setOutputProperty ( OutputKeys . OMIT_XML_DECLARATION , omitXmlDecl ) ; it . setOutputProperty ( OutputKeys . ENCODING , charset ) ; it . transform ( src , new StreamResult ( os ) ) ; } catch ( TransformerException e ) { throw new RuntimeException ( ""Failed to configure TRaX"" , e ) ; } } public static String toString ( Source source ) throws TransformerException , IOException { return toString ( source , null ) ; } public static String toString ( Source source , Properties props ) throws TransformerException , IOException { StringWriter bos = new StringWriter ( ) ; StreamResult sr = new StreamResult ( bos ) ; Transformer trans = newTransformer ( ) ; if ( props == null ) { props = new Properties ( ) ; props . put ( OutputKeys . OMIT_XML_DECLARATION , ""yes"" ) ; } trans . setOutputProperties ( props ) ; trans . transform ( source , sr ) ; bos . close ( ) ; return bos . toString ( ) ; } public static String toString ( Node node , int indent ) { ByteArrayOutputStream out = new ByteArrayOutputStream ( ) ; writeTo ( node , out , indent ) ; return out . toString ( ) ; } public static String toString ( Node node ) { ByteArrayOutputStream out = new ByteArrayOutputStream ( ) ; writeTo ( node , out ) ; return out . toString ( ) ; } public static void printDOM ( Node node ) { printDOM ( """" , node ) ; } public static void printDOM ( String words , Node node ) { System . out . println ( words ) ; System . out . println ( toString ( node ) ) ; } public static Attr getAttribute ( Element el , String attrName ) { return el . getAttributeNode ( attrName ) ; } public static void replaceAttribute ( Element element , String attr , String value ) { if ( element . hasAttribute ( attr ) ) { element . removeAttribute ( attr ) ; } element . setAttribute ( attr , value ) ; } public static boolean hasAttribute ( Element element , String value ) { NamedNodeMap attributes = element . getAttributes ( ) ; for ( int i = 0 ; i < attributes . getLength ( ) ; i ++ ) { Node node = attributes . item ( i ) ; if ( value . equals ( node . getNodeValue ( ) ) ) { return true ; } } return false ; } public static void printAttributes ( Element element ) { NamedNodeMap attributes = element . getAttributes ( ) ; for ( int i = 0 ; i < attributes . getLength ( ) ; i ++ ) { Node node = attributes . item ( i ) ; System . err . println ( ""## prefix="" + node . getPrefix ( ) + "" localname:"" + node . getLocalName ( ) + "" value="" + node . getNodeValue ( ) ) ; } } public static QName getNamespace ( Map < String , String > namespaces , String str , String defaultNamespace ) { String prefix = null ; String localName = null ; StringTokenizer tokenizer = new StringTokenizer ( str , "":"" ) ; if ( tokenizer . countTokens ( ) == 2 ) { prefix = tokenizer . nextToken ( ) ; localName = tokenizer . nextToken ( ) ; } else if ( tokenizer . countTokens ( ) == 1 ) { localName = tokenizer . nextToken ( ) ; } String namespceURI = defaultNamespace ; if ( prefix != null ) { namespceURI = namespaces . get ( prefix ) ; } return new QName ( namespceURI , localName ) ; } public static void generateXMLFile ( Element element , Writer writer ) { try { Transformer it = newTransformer ( ) ; it . setOutputProperty ( OutputKeys . METHOD , ""xml"" ) ; it . setOutputProperty ( OutputKeys . INDENT , ""yes"" ) ; it . setOutputProperty ( ""{http://xml.apache.org/xslt}indent-amount"" , ""2"" ) ; it . setOutputProperty ( OutputKeys . ENCODING , ""UTF-8"" ) ; it . transform ( new DOMSource ( element ) , new StreamResult ( writer ) ) ; } catch ( Exception e ) { e . printStackTrace ( ) ; } } public static Element createElementNS ( Node node , QName name ) { return createElementNS ( node . getOwnerDocument ( ) , name . getNamespaceURI ( ) , name . getLocalPart ( ) ) ; } public static Element createElementNS ( Document root , QName name ) { return createElementNS ( root , name . getNamespaceURI ( ) , name . getLocalPart ( ) ) ; } public static Element createElementNS ( Document root , String namespaceURI , String qualifiedName ) { return root . createElementNS ( namespaceURI , qualifiedName ) ; } public static Text createTextNode ( Document root , String data ) { return root . createTextNode ( data ) ; } public static Text createTextNode ( Node node , String data ) { return createTextNode ( node . getOwnerDocument ( ) , data ) ; } public static void removeContents ( Node parent ) { Node node = parent . getFirstChild ( ) ; while ( node != null ) { parent . removeChild ( node ) ; node = node . getNextSibling ( ) ; } } public static InputStream getInputStream ( Document doc ) throws Exception { DOMImplementationLS impl = null ; DOMImplementation docImpl = doc . getImplementation ( ) ; if ( docImpl != null && docImpl . hasFeature ( ""LS"" , ""3.0"" ) ) { impl = ( DOMImplementationLS ) docImpl . getFeature ( ""LS"" , ""3.0"" ) ; } else { DOMImplementationRegistry registry = DOMImplementationRegistry . newInstance ( ) ; impl = ( DOMImplementationLS ) registry . getDOMImplementation ( ""LS"" ) ; if ( impl == null ) { System . setProperty ( DOMImplementationRegistry . PROPERTY , ""com.sun.org.apache.xerces.internal.dom.DOMImplementationSourceImpl"" ) ; registry = DOMImplementationRegistry . newInstance ( ) ; impl = ( DOMImplementationLS ) registry . getDOMImplementation ( ""LS"" ) ; } } LSOutput output = impl . createLSOutput ( ) ; ByteArrayOutputStream byteArrayOutputStream = new ByteArrayOutputStream ( ) ; output . setByteStream ( byteArrayOutputStream ) ; LSSerializer writer = impl . createLSSerializer ( ) ; writer . write ( doc , output ) ; byte [ ] buf = byteArrayOutputStream . toByteArray ( ) ; return new ByteArrayInputStream ( buf ) ; } public static Element fetchElementByNameAttribute ( Element parent , String targetName , String nameValue ) { List < Element > elemList = DOMUtils . findAllElementsByTagName ( parent , targetName ) ; for ( Element elem : elemList ) { if ( elem . getAttribute ( ""name"" ) . equals ( nameValue ) ) { return elem ; } } return null ; } public static QName getQName ( String value , Node node ) { if ( value == null ) { return null ; } int index = value . indexOf ( "":"" ) ; if ( index == - 1 ) { return new QName ( value ) ; } String prefix = value . substring ( 0 , index ) ; String localName = value . substring ( index + 1 ) ; String ns = node . lookupNamespaceURI ( prefix ) ; if ( ns == null || localName == null ) { throw new RuntimeException ( ""Invalid QName in mapping: "" + value ) ; } return new QName ( ns , localName , prefix ) ; } public static Node fromSource ( Source src ) throws Exception { Transformer trans = TransformerFactory . newInstance ( ) . newTransformer ( ) ; DOMResult res = new DOMResult ( ) ; trans . transform ( src , res ) ; return res . getNode ( ) ; } public static QName convertStringToQName ( String expandedQName ) { return convertStringToQName ( expandedQName , """" ) ; } public static QName convertStringToQName ( String expandedQName , String prefix ) { int ind1 = expandedQName . indexOf ( '{' ) ; if ( ind1 != 0 ) { return new QName ( expandedQName ) ; } int ind2 = expandedQName . indexOf ( '}' ) ; if ( ind2 <= ind1 + 1 || ind2 >= expandedQName . length ( ) - 1 ) { return null ; } String ns = expandedQName . substring ( ind1 + 1 , ind2 ) ; String localName = expandedQName . substring ( ind2 + 1 ) ; return new QName ( ns , localName , prefix ) ; } public static Set < QName > convertStringsToQNames ( List < String > expandedQNames ) { Set < QName > dropElements = Collections . emptySet ( ) ; if ( expandedQNames != null ) { dropElements = new LinkedHashSet < QName > ( expandedQNames . size ( ) ) ; for ( String val : expandedQNames ) { dropElements . add ( XMLUtils . convertStringToQName ( val ) ) ; } } return dropElements ; } }",Smelly
"public class GiraphConfiguration extends Configuration implements GiraphConstants { private ByteBufAllocator nettyBufferAllocator = null ; public GiraphConfiguration ( ) { configureHadoopSecurity ( ) ; } public GiraphConfiguration ( Configuration conf ) { super ( conf ) ; configureHadoopSecurity ( ) ; } public String getComputationName ( ) { ComputationFactory compFactory = ReflectionUtils . newInstance ( getComputationFactoryClass ( ) ) ; return compFactory . computationName ( this ) ; } public Class < ? extends ComputationFactory > getComputationFactoryClass ( ) { return COMPUTATION_FACTORY_CLASS . get ( this ) ; } public Class < ? extends Computation > getComputationClass ( ) { return COMPUTATION_CLASS . get ( this ) ; } public void setComputationClass ( Class < ? extends Computation > computationClass ) { COMPUTATION_CLASS . set ( this , computationClass ) ; } public final void setVertexValueFactoryClass ( Class < ? extends VertexValueFactory > vertexValueFactoryClass ) { VERTEX_VALUE_FACTORY_CLASS . set ( this , vertexValueFactoryClass ) ; } public void setEdgeInputFilterClass ( Class < ? extends EdgeInputFilter > edgeFilterClass ) { EDGE_INPUT_FILTER_CLASS . set ( this , edgeFilterClass ) ; } public void setVertexInputFilterClass ( Class < ? extends VertexInputFilter > vertexFilterClass ) { VERTEX_INPUT_FILTER_CLASS . set ( this , vertexFilterClass ) ; } public Class < ? extends OutEdges > getOutEdgesClass ( ) { return VERTEX_EDGES_CLASS . get ( this ) ; } public final void setOutEdgesClass ( Class < ? extends OutEdges > outEdgesClass ) { VERTEX_EDGES_CLASS . set ( this , outEdgesClass ) ; } public final void setVertexClass ( Class < ? extends Vertex > vertexClass ) { VERTEX_CLASS . set ( this , vertexClass ) ; } public final void setInputOutEdgesClass ( Class < ? extends OutEdges > inputOutEdgesClass ) { INPUT_VERTEX_EDGES_CLASS . set ( this , inputOutEdgesClass ) ; } public boolean reuseEdgeObjects ( ) { return ReuseObjectsOutEdges . class . isAssignableFrom ( getOutEdgesClass ( ) ) ; } public boolean reuseVertexObjects ( ) { return ReusesObjectsPartition . class . isAssignableFrom ( getPartitionClass ( ) ) ; } public Class < ? extends Partition > getPartitionClass ( ) { return PARTITION_CLASS . get ( this ) ; } public boolean hasVertexInputFormat ( ) { return VERTEX_INPUT_FORMAT_CLASS . get ( this ) != null ; } public void setVertexInputFormatClass ( Class < ? extends VertexInputFormat > vertexInputFormatClass ) { VERTEX_INPUT_FORMAT_CLASS . set ( this , vertexInputFormatClass ) ; } public boolean hasEdgeInputFormat ( ) { return EDGE_INPUT_FORMAT_CLASS . get ( this ) != null ; } public void setEdgeInputFormatClass ( Class < ? extends EdgeInputFormat > edgeInputFormatClass ) { EDGE_INPUT_FORMAT_CLASS . set ( this , edgeInputFormatClass ) ; } public final void setMasterComputeClass ( Class < ? extends MasterCompute > masterComputeClass ) { MASTER_COMPUTE_CLASS . set ( this , masterComputeClass ) ; } public final void addMasterObserverClass ( Class < ? extends MasterObserver > masterObserverClass ) { MASTER_OBSERVER_CLASSES . add ( this , masterObserverClass ) ; } public final void addWorkerObserverClass ( Class < ? extends WorkerObserver > workerObserverClass ) { WORKER_OBSERVER_CLASSES . add ( this , workerObserverClass ) ; } public Class < ? extends GiraphJobObserver > getJobObserverClass ( ) { return JOB_OBSERVER_CLASS . get ( this ) ; } public void setJobObserverClass ( Class < ? extends GiraphJobObserver > klass ) { JOB_OBSERVER_CLASS . set ( this , klass ) ; } public Class < ? extends GiraphJobRetryChecker > getJobRetryCheckerClass ( ) { return JOB_RETRY_CHECKER_CLASS . get ( this ) ; } public void setJobRetryCheckerClass ( Class < ? extends GiraphJobRetryChecker > klass ) { JOB_RETRY_CHECKER_CLASS . set ( this , klass ) ; } public boolean isJMapHistogramDumpEnabled ( ) { return JMAP_ENABLE . get ( this ) ; } public boolean isReactiveJmapHistogramDumpEnabled ( ) { return REACTIVE_JMAP_ENABLE . get ( this ) ; } public final void setClasses ( String name , Class < ? > xface , Class < ? > ... klasses ) { String [ ] klassNames = new String [ klasses . length ] ; for ( int i = 0 ; i < klasses . length ; ++ i ) { Class < ? > klass = klasses [ i ] ; if ( ! xface . isAssignableFrom ( klass ) ) { throw new RuntimeException ( klass + "" does not implement "" + xface . getName ( ) ) ; } klassNames [ i ] = klasses [ i ] . getName ( ) ; } setStrings ( name , klassNames ) ; } public boolean hasVertexOutputFormat ( ) { return VERTEX_OUTPUT_FORMAT_CLASS . get ( this ) != null ; } public final void setVertexOutputFormatClass ( Class < ? extends VertexOutputFormat > vertexOutputFormatClass ) { VERTEX_OUTPUT_FORMAT_CLASS . set ( this , vertexOutputFormatClass ) ; } public boolean hasVertexOutputFormatSubdir ( ) { return ! VERTEX_OUTPUT_FORMAT_SUBDIR . get ( this ) . isEmpty ( ) ; } public final void setVertexOutputFormatSubdir ( String path ) { VERTEX_OUTPUT_FORMAT_SUBDIR . set ( this , path ) ; } public final boolean doOutputDuringComputation ( ) { return DO_OUTPUT_DURING_COMPUTATION . get ( this ) ; } public final void setDoOutputDuringComputation ( boolean doOutputDuringComputation ) { DO_OUTPUT_DURING_COMPUTATION . set ( this , doOutputDuringComputation ) ; } public final boolean vertexOutputFormatThreadSafe ( ) { return VERTEX_OUTPUT_FORMAT_THREAD_SAFE . get ( this ) ; } public final void setVertexOutputFormatThreadSafe ( boolean vertexOutputFormatThreadSafe ) { VERTEX_OUTPUT_FORMAT_THREAD_SAFE . set ( this , vertexOutputFormatThreadSafe ) ; } public boolean hasEdgeOutputFormat ( ) { return EDGE_OUTPUT_FORMAT_CLASS . get ( this ) != null ; } public final void setEdgeOutputFormatClass ( Class < ? extends EdgeOutputFormat > edgeOutputFormatClass ) { EDGE_OUTPUT_FORMAT_CLASS . set ( this , edgeOutputFormatClass ) ; } public boolean hasEdgeOutputFormatSubdir ( ) { return ! EDGE_OUTPUT_FORMAT_SUBDIR . get ( this ) . isEmpty ( ) ; } public final void setEdgeOutputFormatSubdir ( String path ) { EDGE_OUTPUT_FORMAT_SUBDIR . set ( this , path ) ; } public final int getNumOutputThreads ( ) { if ( ! vertexOutputFormatThreadSafe ( ) ) { return 1 ; } else { return NUM_OUTPUT_THREADS . get ( this ) ; } } public void setNumOutputThreads ( int numOutputThreads ) { NUM_OUTPUT_THREADS . set ( this , numOutputThreads ) ; } public Class < ? extends MessageCombiner > getMessageCombinerClass ( ) { return MESSAGE_COMBINER_CLASS . get ( this ) ; } public void setMessageCombinerClass ( Class < ? extends MessageCombiner > messageCombinerClass ) { MESSAGE_COMBINER_CLASS . set ( this , messageCombinerClass ) ; } public final void setGraphPartitionerFactoryClass ( Class < ? extends GraphPartitionerFactory > graphPartitionerFactoryClass ) { GRAPH_PARTITIONER_FACTORY_CLASS . set ( this , graphPartitionerFactoryClass ) ; } public final void setVertexResolverClass ( Class < ? extends VertexResolver > vertexResolverClass ) { VERTEX_RESOLVER_CLASS . set ( this , vertexResolverClass ) ; } public final boolean getResolverCreateVertexOnMessages ( ) { return RESOLVER_CREATE_VERTEX_ON_MSGS . get ( this ) ; } public final void setResolverCreateVertexOnMessages ( boolean v ) { RESOLVER_CREATE_VERTEX_ON_MSGS . set ( this , v ) ; } public final void setVertexValueCombinerClass ( Class < ? extends VertexValueCombiner > vertexValueCombinerClass ) { VERTEX_VALUE_COMBINER_CLASS . set ( this , vertexValueCombinerClass ) ; } public final void setWorkerContextClass ( Class < ? extends WorkerContext > workerContextClass ) { WORKER_CONTEXT_CLASS . set ( this , workerContextClass ) ; } public final void setAggregatorWriterClass ( Class < ? extends AggregatorWriter > aggregatorWriterClass ) { AGGREGATOR_WRITER_CLASS . set ( this , aggregatorWriterClass ) ; } public final void setPartitionClass ( Class < ? extends Partition > partitionClass ) { PARTITION_CLASS . set ( this , partitionClass ) ; } public final void setWorkerConfiguration ( int minWorkers , int maxWorkers , float minPercentResponded ) { setInt ( MIN_WORKERS , minWorkers ) ; setInt ( MAX_WORKERS , maxWorkers ) ; MIN_PERCENT_RESPONDED . set ( this , minPercentResponded ) ; } public final int getMinWorkers ( ) { return getInt ( MIN_WORKERS , - 1 ) ; } public final int getMaxWorkers ( ) { return getInt ( MAX_WORKERS , - 1 ) ; } public final float getMinPercentResponded ( ) { return MIN_PERCENT_RESPONDED . get ( this ) ; } public final void setZooKeeperConfiguration ( String serverList ) { ZOOKEEPER_LIST . set ( this , serverList ) ; } public final boolean getSplitMasterWorker ( ) { return SPLIT_MASTER_WORKER . get ( this ) ; } public Class < ? extends MasterObserver > [ ] getMasterObserverClasses ( ) { return MASTER_OBSERVER_CLASSES . getArray ( this ) ; } public Class < ? extends WorkerObserver > [ ] getWorkerObserverClasses ( ) { return WORKER_OBSERVER_CLASSES . getArray ( this ) ; } public boolean metricsEnabled ( ) { return METRICS_ENABLE . isTrue ( this ) ; } public int getTaskPartition ( ) { return getInt ( ""mapred.task.partition"" , - 1 ) ; } public boolean isPureYarnJob ( ) { return IS_PURE_YARN_JOB . get ( this ) ; } public String getYarnLibJars ( ) { return GIRAPH_YARN_LIBJARS . get ( this ) ; } public void setYarnLibJars ( String jarList ) { GIRAPH_YARN_LIBJARS . set ( this , jarList ) ; } public int getYarnTaskHeapMb ( ) { return GIRAPH_YARN_TASK_HEAP_MB . get ( this ) ; } public void setYarnTaskHeapMb ( int heapMb ) { GIRAPH_YARN_TASK_HEAP_MB . set ( this , heapMb ) ; } public String getZookeeperList ( ) { return ZOOKEEPER_LIST . get ( this ) ; } public void setZookeeperList ( String zkList ) { ZOOKEEPER_LIST . set ( this , zkList ) ; ZOOKEEPER_IS_EXTERNAL . set ( this , false ) ; } public boolean isZookeeperExternal ( ) { return ZOOKEEPER_IS_EXTERNAL . get ( this ) ; } public String getLocalLevel ( ) { return LOG_LEVEL . get ( this ) ; } public boolean useLogThreadLayout ( ) { return LOG_THREAD_LAYOUT . get ( this ) ; } public boolean getLocalTestMode ( ) { return LOCAL_TEST_MODE . get ( this ) ; } public void setLocalTestMode ( boolean flag ) { LOCAL_TEST_MODE . set ( this , flag ) ; } public int getZooKeeperServerCount ( ) { return ZOOKEEPER_SERVER_COUNT . get ( this ) ; } public int getZooKeeperSessionTimeout ( ) { return ZOOKEEPER_SESSION_TIMEOUT . get ( this ) ; } public int getZookeeperOpsMaxAttempts ( ) { return ZOOKEEPER_OPS_MAX_ATTEMPTS . get ( this ) ; } public int getZookeeperOpsRetryWaitMsecs ( ) { return ZOOKEEPER_OPS_RETRY_WAIT_MSECS . get ( this ) ; } public boolean getNettyServerUseExecutionHandler ( ) { return NETTY_SERVER_USE_EXECUTION_HANDLER . get ( this ) ; } public int getNettyServerThreads ( ) { return NETTY_SERVER_THREADS . get ( this ) ; } public int getNettyServerExecutionThreads ( ) { return NETTY_SERVER_EXECUTION_THREADS . get ( this ) ; } public int getNettyServerExecutionConcurrency ( ) { if ( getNettyServerUseExecutionHandler ( ) ) { return getNettyServerExecutionThreads ( ) ; } else { return getNettyServerThreads ( ) ; } } public ByteBufAllocator getNettyAllocator ( ) { if ( nettyBufferAllocator == null ) { if ( NETTY_USE_POOLED_ALLOCATOR . get ( this ) ) { nettyBufferAllocator = new PooledByteBufAllocator ( NETTY_USE_DIRECT_MEMORY . get ( this ) ) ; } else { nettyBufferAllocator = new UnpooledByteBufAllocator ( NETTY_USE_DIRECT_MEMORY . get ( this ) ) ; } } return nettyBufferAllocator ; } public int getZookeeperConnectionAttempts ( ) { return ZOOKEEPER_CONNECTION_ATTEMPTS . get ( this ) ; } public int getZooKeeperMinSessionTimeout ( ) { return ZOOKEEPER_MIN_SESSION_TIMEOUT . get ( this ) ; } public int getZooKeeperMaxSessionTimeout ( ) { return ZOOKEEPER_MAX_SESSION_TIMEOUT . get ( this ) ; } public boolean getZooKeeperForceSync ( ) { return ZOOKEEPER_FORCE_SYNC . get ( this ) ; } public boolean getZooKeeperSkipAcl ( ) { return ZOOKEEPER_SKIP_ACL . get ( this ) ; } public int getMapTasks ( ) { int mapTasks = getInt ( ""mapred.map.tasks"" , - 1 ) ; if ( mapTasks == - 1 ) { throw new IllegalStateException ( ""getMapTasks: Failed to get the map "" + ""tasks!"" ) ; } return mapTasks ; } public boolean authenticate ( ) { return AUTHENTICATE . get ( this ) ; } public void setNumComputeThreads ( int numComputeThreads ) { NUM_COMPUTE_THREADS . set ( this , numComputeThreads ) ; } public int getNumComputeThreads ( ) { return NUM_COMPUTE_THREADS . get ( this ) ; } public void setNumInputSplitsThreads ( int numInputSplitsThreads ) { NUM_INPUT_THREADS . set ( this , numInputSplitsThreads ) ; } public int getNumInputSplitsThreads ( ) { return NUM_INPUT_THREADS . get ( this ) ; } public long getInputSplitMaxVertices ( ) { return INPUT_SPLIT_MAX_VERTICES . get ( this ) ; } public long getInputSplitMaxEdges ( ) { return INPUT_SPLIT_MAX_EDGES . get ( this ) ; } public void useUnsafeSerialization ( boolean useUnsafeSerialization ) { USE_UNSAFE_SERIALIZATION . set ( this , useUnsafeSerialization ) ; } public boolean useMessageSizeEncoding ( ) { return USE_MESSAGE_SIZE_ENCODING . get ( this ) ; } public void setCheckpointFrequency ( int checkpointFrequency ) { CHECKPOINT_FREQUENCY . set ( this , checkpointFrequency ) ; } public int getCheckpointFrequency ( ) { return CHECKPOINT_FREQUENCY . get ( this ) ; } public boolean useCheckpointing ( ) { return getCheckpointFrequency ( ) != 0 ; } public void setMaxTaskAttempts ( int maxTaskAttempts ) { MAX_TASK_ATTEMPTS . set ( this , maxTaskAttempts ) ; } public int getMaxTaskAttempts ( ) { return MAX_TASK_ATTEMPTS . get ( this ) ; } public int getEventWaitMsecs ( ) { return EVENT_WAIT_MSECS . get ( this ) ; } public void setEventWaitMsecs ( int eventWaitMsecs ) { EVENT_WAIT_MSECS . set ( this , eventWaitMsecs ) ; } public int getMaxMasterSuperstepWaitMsecs ( ) { return MAX_MASTER_SUPERSTEP_WAIT_MSECS . get ( this ) ; } public void setMaxMasterSuperstepWaitMsecs ( int maxMasterSuperstepWaitMsecs ) { MAX_MASTER_SUPERSTEP_WAIT_MSECS . set ( this , maxMasterSuperstepWaitMsecs ) ; } public void configureHadoopSecurity ( ) { String hadoopTokenFilePath = System . getenv ( ""HADOOP_TOKEN_FILE_LOCATION"" ) ; if ( hadoopTokenFilePath != null ) { set ( ""mapreduce.job.credentials.binary"" , hadoopTokenFilePath ) ; } } public boolean useInputSplitLocality ( ) { return USE_INPUT_SPLIT_LOCALITY . get ( this ) ; } public String getLocalHostname ( ) throws UnknownHostException { return DNS . getDefaultHost ( GiraphConstants . DNS_INTERFACE . get ( this ) , GiraphConstants . DNS_NAMESERVER . get ( this ) ) . toLowerCase ( ) ; } public void setMaxNumberOfSupersteps ( int maxNumberOfSupersteps ) { MAX_NUMBER_OF_SUPERSTEPS . set ( this , maxNumberOfSupersteps ) ; } public int getMaxNumberOfSupersteps ( ) { return MAX_NUMBER_OF_SUPERSTEPS . get ( this ) ; } public boolean isStaticGraph ( ) { return STATIC_GRAPH . isTrue ( this ) ; } public String getYourKitOutputDir ( Mapper . Context context ) { final String cacheKey = ""giraph.yourkit.outputDirCached"" ; String outputDir = get ( cacheKey ) ; if ( outputDir == null ) { outputDir = getStringVars ( YOURKIT_OUTPUT_DIR , YOURKIT_OUTPUT_DIR_DEFAULT , context ) ; set ( cacheKey , outputDir ) ; } return outputDir ; } public String getStringVars ( String key , Mapper . Context context ) { return getStringVars ( key , null , context ) ; } public String getStringVars ( String key , String defaultValue , Mapper . Context context ) { String value = get ( key ) ; if ( value == null ) { if ( defaultValue == null ) { return null ; } value = defaultValue ; } value = value . replace ( ""%JOB_ID%"" , context . getJobID ( ) . toString ( ) ) ; value = value . replace ( ""%TASK_ID%"" , context . getTaskAttemptID ( ) . toString ( ) ) ; value = value . replace ( ""%USER%"" , get ( ""user.name"" , ""unknown_user"" ) ) ; return value ; } public boolean useOneMessageToManyIdsEncoding ( ) { return MESSAGE_ENCODE_AND_STORE_TYPE . get ( this ) . useOneMessageToManyIdsEncoding ( ) ; } public boolean getCreateSourceVertex ( ) { return CREATE_EDGE_SOURCE_VERTICES . get ( this ) ; } public void setCreateSourceVertex ( boolean createVertex ) { CREATE_EDGE_SOURCE_VERTICES . set ( this , createVertex ) ; } public int getWaitTaskDoneTimeoutMs ( ) { return WAIT_TASK_DONE_TIMEOUT_MS . get ( this ) ; } public void setWaitTaskDoneTimeoutMs ( int ms ) { WAIT_TASK_DONE_TIMEOUT_MS . set ( this , ms ) ; } public boolean trackJobProgressOnClient ( ) { return TRACK_JOB_PROGRESS_ON_CLIENT . get ( this ) ; } public int getHdfsFileCreationRetries ( ) { return HDFS_FILE_CREATION_RETRIES . get ( this ) ; } public int getHdfsFileCreationRetryWaitMs ( ) { return HDFS_FILE_CREATION_RETRY_WAIT_MS . get ( this ) ; } }",Smelly
"public class JMXJsonServlet extends HttpServlet { private static final Log LOG = LogFactory . getLog ( JMXJsonServlet . class ) ; private static final long serialVersionUID = 1L ; private static final String CALLBACK_PARAM = ""callback"" ; protected transient MBeanServer mBeanServer = null ; @ Override public void init ( ) throws ServletException { mBeanServer = ManagementFactory . getPlatformMBeanServer ( ) ; } @ Override public void doGet ( HttpServletRequest request , HttpServletResponse response ) { String jsonpcb = null ; PrintWriter writer = null ; try { if ( ! HttpServer . isInstrumentationAccessAllowed ( getServletContext ( ) , request , response ) ) { return ; } JsonGenerator jg = null ; writer = response . getWriter ( ) ; jsonpcb = request . getParameter ( CALLBACK_PARAM ) ; if ( jsonpcb != null ) { response . setContentType ( ""application/javascript; charset=utf8"" ) ; writer . write ( jsonpcb + ""("" ) ; } else { response . setContentType ( ""application/json; charset=utf8"" ) ; } JsonFactory jsonFactory = new JsonFactory ( ) ; jg = jsonFactory . createJsonGenerator ( writer ) ; jg . disable ( JsonGenerator . Feature . AUTO_CLOSE_TARGET ) ; jg . useDefaultPrettyPrinter ( ) ; jg . writeStartObject ( ) ; if ( mBeanServer == null ) { jg . writeStringField ( ""result"" , ""ERROR"" ) ; jg . writeStringField ( ""message"" , ""No MBeanServer could be found"" ) ; jg . close ( ) ; LOG . error ( ""No MBeanServer could be found."" ) ; response . setStatus ( HttpServletResponse . SC_NOT_FOUND ) ; return ; } String getmethod = request . getParameter ( ""get"" ) ; if ( getmethod != null ) { String [ ] splitStrings = getmethod . split ( ""\\:\\:"" ) ; if ( splitStrings . length != 2 ) { jg . writeStringField ( ""result"" , ""ERROR"" ) ; jg . writeStringField ( ""message"" , ""query format is not as expected."" ) ; jg . close ( ) ; response . setStatus ( HttpServletResponse . SC_BAD_REQUEST ) ; return ; } listBeans ( jg , new ObjectName ( splitStrings [ 0 ] ) , splitStrings [ 1 ] , response ) ; jg . close ( ) ; return ; } String qry = request . getParameter ( ""qry"" ) ; if ( qry == null ) { qry = ""*:*"" ; } listBeans ( jg , new ObjectName ( qry ) , null , response ) ; jg . close ( ) ; } catch ( IOException e ) { LOG . error ( ""Caught an exception while processing JMX request"" , e ) ; response . setStatus ( HttpServletResponse . SC_INTERNAL_SERVER_ERROR ) ; } catch ( MalformedObjectNameException e ) { LOG . error ( ""Caught an exception while processing JMX request"" , e ) ; response . setStatus ( HttpServletResponse . SC_BAD_REQUEST ) ; } finally { if ( jsonpcb != null ) { writer . write ( "");"" ) ; } if ( writer != null ) { writer . close ( ) ; } } } private void listBeans ( JsonGenerator jg , ObjectName qry , String attribute , HttpServletResponse response ) throws IOException { LOG . debug ( ""Listing beans for "" + qry ) ; Set < ObjectName > names = null ; names = mBeanServer . queryNames ( qry , null ) ; jg . writeArrayFieldStart ( ""beans"" ) ; Iterator < ObjectName > it = names . iterator ( ) ; while ( it . hasNext ( ) ) { ObjectName oname = it . next ( ) ; MBeanInfo minfo ; String code = """" ; Object attributeinfo = null ; try { minfo = mBeanServer . getMBeanInfo ( oname ) ; code = minfo . getClassName ( ) ; String prs = """" ; try { if ( ""org.apache.commons.modeler.BaseModelMBean"" . equals ( code ) ) { prs = ""modelerType"" ; code = ( String ) mBeanServer . getAttribute ( oname , prs ) ; } if ( attribute != null ) { prs = attribute ; attributeinfo = mBeanServer . getAttribute ( oname , prs ) ; } } catch ( AttributeNotFoundException e ) { LOG . error ( ""getting attribute "" + prs + "" of "" + oname + "" threw an exception"" , e ) ; } catch ( MBeanException e ) { LOG . error ( ""getting attribute "" + prs + "" of "" + oname + "" threw an exception"" , e ) ; } catch ( RuntimeException e ) { LOG . error ( ""getting attribute "" + prs + "" of "" + oname + "" threw an exception"" , e ) ; } catch ( ReflectionException e ) { LOG . error ( ""getting attribute "" + prs + "" of "" + oname + "" threw an exception"" , e ) ; } } catch ( InstanceNotFoundException e ) { continue ; } catch ( IntrospectionException e ) { LOG . error ( ""Problem while trying to process JMX query: "" + qry + "" with MBean "" + oname , e ) ; continue ; } catch ( ReflectionException e ) { LOG . error ( ""Problem while trying to process JMX query: "" + qry + "" with MBean "" + oname , e ) ; continue ; } jg . writeStartObject ( ) ; jg . writeStringField ( ""name"" , oname . toString ( ) ) ; jg . writeStringField ( ""modelerType"" , code ) ; if ( ( attribute != null ) && ( attributeinfo == null ) ) { jg . writeStringField ( ""result"" , ""ERROR"" ) ; jg . writeStringField ( ""message"" , ""No attribute with name "" + attribute + "" was found."" ) ; jg . writeEndObject ( ) ; jg . writeEndArray ( ) ; jg . close ( ) ; response . setStatus ( HttpServletResponse . SC_NOT_FOUND ) ; return ; } if ( attribute != null ) { writeAttribute ( jg , attribute , attributeinfo ) ; } else { MBeanAttributeInfo attrs [ ] = minfo . getAttributes ( ) ; for ( int i = 0 ; i < attrs . length ; i ++ ) { writeAttribute ( jg , oname , attrs [ i ] ) ; } } jg . writeEndObject ( ) ; } jg . writeEndArray ( ) ; } private void writeAttribute ( JsonGenerator jg , ObjectName oname , MBeanAttributeInfo attr ) throws IOException { if ( ! attr . isReadable ( ) ) { return ; } String attName = attr . getName ( ) ; if ( ""modelerType"" . equals ( attName ) ) { return ; } if ( attName . indexOf ( ""="" ) >= 0 || attName . indexOf ( "":"" ) >= 0 || attName . indexOf ( "" "" ) >= 0 ) { return ; } Object value = null ; try { value = mBeanServer . getAttribute ( oname , attName ) ; } catch ( RuntimeMBeanException e ) { if ( e . getCause ( ) instanceof UnsupportedOperationException ) { LOG . debug ( ""getting attribute "" + attName + "" of "" + oname + "" threw an exception"" , e ) ; } else { LOG . error ( ""getting attribute "" + attName + "" of "" + oname + "" threw an exception"" , e ) ; } return ; } catch ( RuntimeErrorException e ) { LOG . debug ( ""getting attribute "" + attName + "" of "" + oname + "" threw an exception"" , e ) ; return ; } catch ( AttributeNotFoundException e ) { return ; } catch ( MBeanException e ) { LOG . error ( ""getting attribute "" + attName + "" of "" + oname + "" threw an exception"" , e ) ; return ; } catch ( RuntimeException e ) { LOG . error ( ""getting attribute "" + attName + "" of "" + oname + "" threw an exception"" , e ) ; return ; } catch ( ReflectionException e ) { LOG . error ( ""getting attribute "" + attName + "" of "" + oname + "" threw an exception"" , e ) ; return ; } catch ( InstanceNotFoundException e ) { return ; } writeAttribute ( jg , attName , value ) ; } private void writeAttribute ( JsonGenerator jg , String attName , Object value ) throws IOException { jg . writeFieldName ( attName ) ; writeObject ( jg , value ) ; } private void writeObject ( JsonGenerator jg , Object value ) throws IOException { if ( value == null ) { jg . writeNull ( ) ; } else { Class < ? > c = value . getClass ( ) ; if ( c . isArray ( ) ) { jg . writeStartArray ( ) ; int len = Array . getLength ( value ) ; for ( int j = 0 ; j < len ; j ++ ) { Object item = Array . get ( value , j ) ; writeObject ( jg , item ) ; } jg . writeEndArray ( ) ; } else if ( value instanceof Number ) { Number n = ( Number ) value ; jg . writeNumber ( n . toString ( ) ) ; } else if ( value instanceof Boolean ) { Boolean b = ( Boolean ) value ; jg . writeBoolean ( b ) ; } else if ( value instanceof CompositeData ) { CompositeData cds = ( CompositeData ) value ; CompositeType comp = cds . getCompositeType ( ) ; Set < String > keys = comp . keySet ( ) ; jg . writeStartObject ( ) ; for ( String key : keys ) { writeAttribute ( jg , key , cds . get ( key ) ) ; } jg . writeEndObject ( ) ; } else if ( value instanceof TabularData ) { TabularData tds = ( TabularData ) value ; jg . writeStartArray ( ) ; for ( Object entry : tds . values ( ) ) { writeObject ( jg , entry ) ; } jg . writeEndArray ( ) ; } else { jg . writeString ( value . toString ( ) ) ; } } } }",No
"public class MalformedChunkException extends Exception { private final long offset ; private final int chunkNum ; private byte [ ] badChunk ; public MalformedChunkException ( String message , Throwable cause , long offset , int chunkNum , byte [ ] badChunk ) { super ( message , cause ) ; this . offset = offset ; this . chunkNum = chunkNum ; this . badChunk = badChunk ; } public byte [ ] getBadChunk ( ) { return badChunk ; } public int getChunkNum ( ) { return chunkNum ; } }",No
" private class KTableAggregateProcessor extends AbstractProcessor < K , Change < V > > { private TimestampedKeyValueStore < K , T > store ; private TimestampedTupleForwarder < K , T > tupleForwarder ; @ SuppressWarnings ( ""unchecked"" ) @ Override public void init ( final ProcessorContext context ) { super . init ( context ) ; store = ( TimestampedKeyValueStore < K , T > ) context . getStateStore ( storeName ) ; tupleForwarder = new TimestampedTupleForwarder < > ( store , context , new TimestampedCacheFlushListener < > ( context ) , sendOldValues ) ; } @ Override public void process ( final K key , final Change < V > value ) { if ( key == null ) { throw new StreamsException ( ""Record key for KTable aggregate operator with state "" + storeName + "" should not be null."" ) ; } final ValueAndTimestamp < T > oldAggAndTimestamp = store . get ( key ) ; final T oldAgg = getValueOrNull ( oldAggAndTimestamp ) ; final T intermediateAgg ; long newTimestamp = context ( ) . timestamp ( ) ; if ( value . oldValue != null && oldAgg != null ) { intermediateAgg = remove . apply ( key , value . oldValue , oldAgg ) ; newTimestamp = Math . max ( context ( ) . timestamp ( ) , oldAggAndTimestamp . timestamp ( ) ) ; } else { intermediateAgg = oldAgg ; } final T newAgg ; if ( value . newValue != null ) { final T initializedAgg ; if ( intermediateAgg == null ) { initializedAgg = initializer . apply ( ) ; } else { initializedAgg = intermediateAgg ; } newAgg = add . apply ( key , value . newValue , initializedAgg ) ; if ( oldAggAndTimestamp != null ) { newTimestamp = Math . max ( context ( ) . timestamp ( ) , oldAggAndTimestamp . timestamp ( ) ) ; } } else { newAgg = intermediateAgg ; } store . put ( key , ValueAndTimestamp . make ( newAgg , newTimestamp ) ) ; tupleForwarder . maybeForward ( key , newAgg , sendOldValues ? oldAgg : null , newTimestamp ) ; } ",No
"public class StoreQueueCursor extends AbstractPendingMessageCursor { private static final Logger LOG = LoggerFactory . getLogger ( StoreQueueCursor . class ) ; private final Broker broker ; private int pendingCount ; private final Queue queue ; private PendingMessageCursor nonPersistent ; private final QueueStorePrefetch persistent ; private boolean started ; private PendingMessageCursor currentCursor ; public StoreQueueCursor ( Broker broker , Queue queue ) { super ( ( queue != null ? queue . isPrioritizedMessages ( ) : false ) ) ; this . broker = broker ; this . queue = queue ; this . persistent = new QueueStorePrefetch ( queue ) ; currentCursor = persistent ; } public synchronized void start ( ) throws Exception { started = true ; super . start ( ) ; if ( nonPersistent == null ) { if ( broker . getBrokerService ( ) . isPersistent ( ) ) { nonPersistent = new FilePendingMessageCursor ( broker , queue . getName ( ) , this . prioritizedMessages ) ; } else { nonPersistent = new VMPendingMessageCursor ( this . prioritizedMessages ) ; } nonPersistent . setMaxBatchSize ( getMaxBatchSize ( ) ) ; nonPersistent . setSystemUsage ( systemUsage ) ; nonPersistent . setEnableAudit ( isEnableAudit ( ) ) ; nonPersistent . setMaxAuditDepth ( getMaxAuditDepth ( ) ) ; nonPersistent . setMaxProducersToAudit ( getMaxProducersToAudit ( ) ) ; } nonPersistent . setMessageAudit ( getMessageAudit ( ) ) ; nonPersistent . start ( ) ; persistent . setMessageAudit ( getMessageAudit ( ) ) ; persistent . start ( ) ; pendingCount = persistent . size ( ) + nonPersistent . size ( ) ; } public synchronized void stop ( ) throws Exception { started = false ; if ( nonPersistent != null ) { nonPersistent . destroy ( ) ; } persistent . stop ( ) ; persistent . gc ( ) ; super . stop ( ) ; pendingCount = 0 ; } public synchronized void addMessageLast ( MessageReference node ) throws Exception { if ( node != null ) { Message msg = node . getMessage ( ) ; if ( started ) { pendingCount ++ ; if ( ! msg . isPersistent ( ) ) { nonPersistent . addMessageLast ( node ) ; } } if ( msg . isPersistent ( ) ) { persistent . addMessageLast ( node ) ; } } } public synchronized void addMessageFirst ( MessageReference node ) throws Exception { if ( node != null ) { Message msg = node . getMessage ( ) ; if ( started ) { pendingCount ++ ; if ( ! msg . isPersistent ( ) ) { nonPersistent . addMessageFirst ( node ) ; } } if ( msg . isPersistent ( ) ) { persistent . addMessageFirst ( node ) ; } } } public synchronized void clear ( ) { pendingCount = 0 ; } public synchronized boolean hasNext ( ) { try { getNextCursor ( ) ; } catch ( Exception e ) { LOG . error ( ""Failed to get current cursor "" , e ) ; throw new RuntimeException ( e ) ; } return currentCursor != null ? currentCursor . hasNext ( ) : false ; } public synchronized MessageReference next ( ) { MessageReference result = currentCursor != null ? currentCursor . next ( ) : null ; return result ; } public synchronized void remove ( ) { if ( currentCursor != null ) { currentCursor . remove ( ) ; } pendingCount -- ; } public synchronized void remove ( MessageReference node ) { if ( ! node . isPersistent ( ) ) { nonPersistent . remove ( node ) ; } else { persistent . remove ( node ) ; } pendingCount -- ; } public synchronized void reset ( ) { nonPersistent . reset ( ) ; persistent . reset ( ) ; pendingCount = persistent . size ( ) + nonPersistent . size ( ) ; } public void release ( ) { nonPersistent . release ( ) ; persistent . release ( ) ; } public synchronized int size ( ) { if ( pendingCount < 0 ) { pendingCount = persistent . size ( ) + nonPersistent . size ( ) ; } return pendingCount ; } public synchronized boolean isEmpty ( ) { return pendingCount == 0 ; } public boolean isRecoveryRequired ( ) { return false ; } public PendingMessageCursor getNonPersistent ( ) { return this . nonPersistent ; } public void setNonPersistent ( PendingMessageCursor nonPersistent ) { this . nonPersistent = nonPersistent ; } public void setMaxBatchSize ( int maxBatchSize ) { persistent . setMaxBatchSize ( maxBatchSize ) ; if ( nonPersistent != null ) { nonPersistent . setMaxBatchSize ( maxBatchSize ) ; } super . setMaxBatchSize ( maxBatchSize ) ; } public void setMaxProducersToAudit ( int maxProducersToAudit ) { super . setMaxProducersToAudit ( maxProducersToAudit ) ; if ( persistent != null ) { persistent . setMaxProducersToAudit ( maxProducersToAudit ) ; } if ( nonPersistent != null ) { nonPersistent . setMaxProducersToAudit ( maxProducersToAudit ) ; } } public void setMaxAuditDepth ( int maxAuditDepth ) { super . setMaxAuditDepth ( maxAuditDepth ) ; if ( persistent != null ) { persistent . setMaxAuditDepth ( maxAuditDepth ) ; } if ( nonPersistent != null ) { nonPersistent . setMaxAuditDepth ( maxAuditDepth ) ; } } public void setEnableAudit ( boolean enableAudit ) { super . setEnableAudit ( enableAudit ) ; if ( persistent != null ) { persistent . setEnableAudit ( enableAudit ) ; } if ( nonPersistent != null ) { nonPersistent . setEnableAudit ( enableAudit ) ; } } @ Override public void setUseCache ( boolean useCache ) { super . setUseCache ( useCache ) ; if ( persistent != null ) { persistent . setUseCache ( useCache ) ; } if ( nonPersistent != null ) { nonPersistent . setUseCache ( useCache ) ; } } @ Override public void setMemoryUsageHighWaterMark ( int memoryUsageHighWaterMark ) { super . setMemoryUsageHighWaterMark ( memoryUsageHighWaterMark ) ; if ( persistent != null ) { persistent . setMemoryUsageHighWaterMark ( memoryUsageHighWaterMark ) ; } if ( nonPersistent != null ) { nonPersistent . setMemoryUsageHighWaterMark ( memoryUsageHighWaterMark ) ; } } public synchronized void gc ( ) { if ( persistent != null ) { persistent . gc ( ) ; } if ( nonPersistent != null ) { nonPersistent . gc ( ) ; } pendingCount = persistent . size ( ) + nonPersistent . size ( ) ; } public void setSystemUsage ( SystemUsage usageManager ) { super . setSystemUsage ( usageManager ) ; if ( persistent != null ) { persistent . setSystemUsage ( usageManager ) ; } if ( nonPersistent != null ) { nonPersistent . setSystemUsage ( usageManager ) ; } } protected synchronized PendingMessageCursor getNextCursor ( ) throws Exception { if ( currentCursor == null || ! currentCursor . hasMessagesBufferedToDeliver ( ) ) { currentCursor = currentCursor == persistent ? nonPersistent : persistent ; if ( currentCursor . isEmpty ( ) ) { currentCursor = currentCursor == persistent ? nonPersistent : persistent ; } } return currentCursor ; } @ Override public boolean isCacheEnabled ( ) { boolean cacheEnabled = isUseCache ( ) ; if ( cacheEnabled ) { if ( persistent != null ) { cacheEnabled &= persistent . isCacheEnabled ( ) ; } if ( nonPersistent != null ) { cacheEnabled &= nonPersistent . isCacheEnabled ( ) ; } setCacheEnabled ( cacheEnabled ) ; } return cacheEnabled ; } }",Smelly
"public class Ownership extends WizardStep implements WizardModel . ICondition { private static final long serialVersionUID = 855618618337931784L ; private final Pattern owner = Pattern . compile ( ""\\[\\(\\d+\\)\\] .*"" ) ; private final GroupWrapper wrapper ; private final WebMarkupContainer ownerContainer ; private final AnyTypeRestClient anyTypeRestClient = new AnyTypeRestClient ( ) ; private final AnyTypeClassRestClient anyTypeClassRestClient = new AnyTypeClassRestClient ( ) ; private final GroupSearchPanel groupSearchPanel ; private final GroupRestClient groupRestClient = new GroupRestClient ( ) ; private final Fragment groupSearchFragment ; private final GroupSelectionDirectoryPanel groupDirectoryPanel ; private final UserSearchPanel userSearchPanel ; private final UserRestClient userRestClient = new UserRestClient ( ) ; private final Fragment userSearchFragment ; private final UserSelectionDirectoryPanel userDirectoryPanel ; private final Model < Boolean > isGroupOwnership ; public Ownership ( final GroupWrapper groupWrapper , final PageReference pageRef ) { super ( ) ; final ActionPermissions permissions = new ActionPermissions ( ) ; setMetaData ( MetaDataRoleAuthorizationStrategy . ACTION_PERMISSIONS , permissions ) ; permissions . authorize ( RENDER , new Roles ( StandardEntitlement . USER_SEARCH ) ) ; setTitleModel ( new ResourceModel ( ""group.ownership"" ) ) ; this . wrapper = groupWrapper ; isGroupOwnership = Model . of ( groupWrapper . getInnerObject ( ) . getGroupOwner ( ) != null ) ; final BootstrapToggleConfig config = new BootstrapToggleConfig ( ) . withOnStyle ( BootstrapToggleConfig . Style . info ) . withOffStyle ( BootstrapToggleConfig . Style . warning ) . withSize ( BootstrapToggleConfig . Size . mini ) ; add ( new BootstrapToggle ( ""ownership"" , new Model < Boolean > ( ) { private static final long serialVersionUID = 6062041315055645807L ; @ Override public Boolean getObject ( ) { return isGroupOwnership . getObject ( ) ; } } , config ) { private static final long serialVersionUID = 2969634208049189343L ; @ Override protected IModel < String > getOffLabel ( ) { return Model . of ( ""USER Owner"" ) ; } @ Override protected IModel < String > getOnLabel ( ) { return Model . of ( ""GROUP Owner"" ) ; } @ Override protected CheckBox newCheckBox ( final String id , final IModel < Boolean > model ) { final CheckBox checkBox = super . newCheckBox ( id , model ) ; checkBox . add ( new IndicatorAjaxFormComponentUpdatingBehavior ( Constants . ON_CHANGE ) { private static final long serialVersionUID = 1L ; @ Override protected void onUpdate ( final AjaxRequestTarget target ) { isGroupOwnership . setObject ( ! isGroupOwnership . getObject ( ) ) ; if ( isGroupOwnership . getObject ( ) ) { ownerContainer . addOrReplace ( groupSearchFragment ) ; groupDirectoryPanel . search ( null , target ) ; } else { ownerContainer . addOrReplace ( userSearchFragment ) ; userDirectoryPanel . search ( null , target ) ; } target . add ( ownerContainer ) ; } } ) ; return checkBox ; } } ) ; ownerContainer = new WebMarkupContainer ( ""ownerContainer"" ) ; ownerContainer . setOutputMarkupId ( true ) ; add ( ownerContainer ) ; groupSearchFragment = new Fragment ( ""search"" , ""groupSearchFragment"" , this ) ; groupSearchPanel = new GroupSearchPanel . Builder ( new ListModel < > ( new ArrayList < SearchClause > ( ) ) ) . required ( false ) . enableSearch ( Ownership . this ) . build ( ""groupsearch"" ) ; groupSearchFragment . add ( groupSearchPanel . setRenderBodyOnly ( true ) ) ; AnyTypeTO anyTypeTO = anyTypeRestClient . read ( AnyTypeKind . GROUP . name ( ) ) ; groupDirectoryPanel = GroupSelectionDirectoryPanel . class . cast ( new GroupSelectionDirectoryPanel . Builder ( anyTypeClassRestClient . list ( anyTypeTO . getClasses ( ) ) , anyTypeTO . getKey ( ) , pageRef ) . build ( ""searchResult"" ) ) ; groupSearchFragment . add ( groupDirectoryPanel ) ; userSearchFragment = new Fragment ( ""search"" , ""userSearchFragment"" , this ) ; userSearchPanel = UserSearchPanel . class . cast ( new UserSearchPanel . Builder ( new ListModel < > ( new ArrayList < SearchClause > ( ) ) ) . required ( false ) . enableSearch ( Ownership . this ) . build ( ""usersearch"" ) ) ; userSearchFragment . add ( userSearchPanel . setRenderBodyOnly ( true ) ) ; anyTypeTO = anyTypeRestClient . read ( AnyTypeKind . USER . name ( ) ) ; userDirectoryPanel = UserSelectionDirectoryPanel . class . cast ( new UserSelectionDirectoryPanel . Builder ( anyTypeClassRestClient . list ( anyTypeTO . getClasses ( ) ) , anyTypeTO . getKey ( ) , pageRef ) . build ( ""searchResult"" ) ) ; userSearchFragment . add ( userDirectoryPanel ) ; if ( isGroupOwnership . getObject ( ) ) { ownerContainer . add ( groupSearchFragment ) ; } else { ownerContainer . add ( userSearchFragment ) ; } final AjaxTextFieldPanel userOwner = new AjaxTextFieldPanel ( ""userOwner"" , ""userOwner"" , new PropertyModel < String > ( groupWrapper . getInnerObject ( ) , ""userOwner"" ) { private static final long serialVersionUID = - 3743432456095828573L ; @ Override public String getObject ( ) { if ( groupWrapper . getInnerObject ( ) . getUserOwner ( ) == null ) { return StringUtils . EMPTY ; } else { UserTO userTO = userRestClient . read ( groupWrapper . getInnerObject ( ) . getUserOwner ( ) ) ; if ( userTO == null ) { return StringUtils . EMPTY ; } else { return String . format ( ""[%s] %s"" , userTO . getKey ( ) , userTO . getUsername ( ) ) ; } } } @ Override public void setObject ( final String object ) { if ( StringUtils . isBlank ( object ) ) { groupWrapper . getInnerObject ( ) . setUserOwner ( null ) ; } else { final Matcher matcher = owner . matcher ( object ) ; if ( matcher . matches ( ) ) { groupWrapper . getInnerObject ( ) . setUserOwner ( matcher . group ( 1 ) ) ; } } } } , false ) ; userOwner . setPlaceholder ( ""userOwner"" ) ; userOwner . hideLabel ( ) ; userOwner . setReadOnly ( true ) . setOutputMarkupId ( true ) ; userSearchFragment . add ( userOwner ) ; final IndicatingAjaxLink < Void > userOwnerReset = new IndicatingAjaxLink < Void > ( ""userOwnerReset"" ) { private static final long serialVersionUID = - 7978723352517770644L ; @ Override public void onClick ( final AjaxRequestTarget target ) { send ( Ownership . this , Broadcast . EXACT , new GroupSelectionDirectoryPanel . ItemSelection < GroupTO > ( target , null ) ) ; } @ Override public String getAjaxIndicatorMarkupId ( ) { return Constants . VEIL_INDICATOR_MARKUP_ID ; } } ; userSearchFragment . add ( userOwnerReset ) ; final AjaxTextFieldPanel groupOwner = new AjaxTextFieldPanel ( ""groupOwner"" , ""groupOwner"" , new PropertyModel < String > ( groupWrapper . getInnerObject ( ) , ""groupOwner"" ) { private static final long serialVersionUID = - 3743432456095828573L ; @ Override public String getObject ( ) { if ( groupWrapper . getInnerObject ( ) . getGroupOwner ( ) == null ) { return StringUtils . EMPTY ; } else { GroupTO groupTO = groupRestClient . read ( groupWrapper . getInnerObject ( ) . getGroupOwner ( ) ) ; if ( groupTO == null ) { return StringUtils . EMPTY ; } else { return String . format ( ""[%s] %s"" , groupTO . getKey ( ) , groupTO . getName ( ) ) ; } } } @ Override public void setObject ( final String object ) { if ( StringUtils . isBlank ( object ) ) { groupWrapper . getInnerObject ( ) . setGroupOwner ( null ) ; } else { final Matcher matcher = owner . matcher ( object ) ; if ( matcher . matches ( ) ) { groupWrapper . getInnerObject ( ) . setGroupOwner ( matcher . group ( 1 ) ) ; } } } } , false ) ; groupOwner . setPlaceholder ( ""groupOwner"" ) ; groupOwner . hideLabel ( ) ; groupOwner . setReadOnly ( true ) . setOutputMarkupId ( true ) ; groupSearchFragment . add ( groupOwner ) ; final IndicatingAjaxLink < Void > groupOwnerReset = new IndicatingAjaxLink < Void > ( ""groupOwnerReset"" ) { private static final long serialVersionUID = - 7978723352517770644L ; @ Override public void onClick ( final AjaxRequestTarget target ) { send ( Ownership . this , Broadcast . EXACT , new GroupSelectionDirectoryPanel . ItemSelection < GroupTO > ( target , null ) ) ; } @ Override public String getAjaxIndicatorMarkupId ( ) { return Constants . VEIL_INDICATOR_MARKUP_ID ; } } ; groupSearchFragment . add ( groupOwnerReset ) ; } @ Override public void onEvent ( final IEvent < ? > event ) { if ( event . getPayload ( ) instanceof SearchClausePanel . SearchEvent ) { final AjaxRequestTarget target = SearchClausePanel . SearchEvent . class . cast ( event . getPayload ( ) ) . getTarget ( ) ; if ( Ownership . this . isGroupOwnership . getObject ( ) ) { final String fiql = SearchUtils . buildFIQL ( groupSearchPanel . getModel ( ) . getObject ( ) , SyncopeClient . getGroupSearchConditionBuilder ( ) ) ; groupDirectoryPanel . search ( fiql , target ) ; } else { final String fiql = SearchUtils . buildFIQL ( userSearchPanel . getModel ( ) . getObject ( ) , SyncopeClient . getUserSearchConditionBuilder ( ) ) ; userDirectoryPanel . search ( fiql , target ) ; } } else if ( event . getPayload ( ) instanceof AnySelectionDirectoryPanel . ItemSelection ) { final AnyTO sel = ( ( AnySelectionDirectoryPanel . ItemSelection ) event . getPayload ( ) ) . getSelection ( ) ; if ( sel == null ) { wrapper . getInnerObject ( ) . setUserOwner ( null ) ; wrapper . getInnerObject ( ) . setGroupOwner ( null ) ; } else if ( sel instanceof UserTO ) { wrapper . getInnerObject ( ) . setUserOwner ( sel . getKey ( ) ) ; wrapper . getInnerObject ( ) . setGroupOwner ( null ) ; } else if ( sel instanceof GroupTO ) { wrapper . getInnerObject ( ) . setGroupOwner ( sel . getKey ( ) ) ; wrapper . getInnerObject ( ) . setUserOwner ( null ) ; } ( ( AnySelectionDirectoryPanel . ItemSelection ) event . getPayload ( ) ) . getTarget ( ) . add ( ownerContainer ) ; } else { super . onEvent ( event ) ; } } @ Override public boolean evaluate ( ) { return SyncopeConsoleApplication . get ( ) . getSecuritySettings ( ) . getAuthorizationStrategy ( ) . isActionAuthorized ( this , RENDER ) ; } }",No
" public class TailFile extends AbstractProcessor { static final String MAP_PREFIX = ""file."" ; static final AllowableValue LOCATION_LOCAL = new AllowableValue ( ""Local"" , ""Local"" , ""State is stored locally. Each node in a cluster will tail a different file."" ) ; static final AllowableValue LOCATION_REMOTE = new AllowableValue ( ""Remote"" , ""Remote"" , ""State is located on a remote resource. This Processor will store state across the cluster so that "" + ""it can be run on Primary Node Only and a new Primary Node can pick up where the last one left off."" ) ; static final AllowableValue MODE_SINGLEFILE = new AllowableValue ( ""Single file"" , ""Single file"" , ""In this mode, only the one file indicated in the 'Files to tail' property will be watched by the processor."" + "" In this mode, the file may not exist when starting the processor."" ) ; static final AllowableValue MODE_MULTIFILE = new AllowableValue ( ""Multiple files"" , ""Multiple files"" , ""In this mode, the 'Files to tail' property accepts a regular expression and the processor will look"" + "" for files in 'Base directory' to list the files to tail by the processor."" ) ; static final AllowableValue FIXED_NAME = new AllowableValue ( ""Fixed name"" , ""Fixed name"" , ""With this rolling strategy, the files "" + ""where the log messages are appended have always the same name."" ) ; static final AllowableValue CHANGING_NAME = new AllowableValue ( ""Changing name"" , ""Changing name"" , ""With this rolling strategy, "" + ""the files where the log messages are appended have not a fixed name (for example: filename contaning the current day."" ) ; static final AllowableValue START_BEGINNING_OF_TIME = new AllowableValue ( ""Beginning of Time"" , ""Beginning of Time"" , ""Start with the oldest data that matches the Rolling Filename Pattern and then begin reading from the File to Tail"" ) ; static final AllowableValue START_CURRENT_FILE = new AllowableValue ( ""Beginning of File"" , ""Beginning of File"" , ""Start with the beginning of the File to Tail. Do not ingest any data that has already been rolled over"" ) ; static final AllowableValue START_CURRENT_TIME = new AllowableValue ( ""Current Time"" , ""Current Time"" , ""Start with the data at the end of the File to Tail. Do not ingest any data thas has already been rolled over or any "" + ""data in the File to Tail that has already been written."" ) ; static final PropertyDescriptor BASE_DIRECTORY = new PropertyDescriptor . Builder ( ) . name ( ""tail-base-directory"" ) . displayName ( ""Base directory"" ) . description ( ""Base directory used to look for files to tail. This property is required when using Multifile mode."" ) . expressionLanguageSupported ( ExpressionLanguageScope . VARIABLE_REGISTRY ) . addValidator ( StandardValidators . FILE_EXISTS_VALIDATOR ) . required ( false ) . build ( ) ; static final PropertyDescriptor MODE = new PropertyDescriptor . Builder ( ) . name ( ""tail-mode"" ) . displayName ( ""Tailing mode"" ) . description ( ""Mode to use: single file will tail only one file, multiple file will look for a list of file. In Multiple mode"" + "" the Base directory is required."" ) . expressionLanguageSupported ( ExpressionLanguageScope . NONE ) . required ( true ) . allowableValues ( MODE_SINGLEFILE , MODE_MULTIFILE ) . defaultValue ( MODE_SINGLEFILE . getValue ( ) ) . build ( ) ; static final PropertyDescriptor FILENAME = new PropertyDescriptor . Builder ( ) . displayName ( ""File(s) to Tail"" ) . name ( ""File to Tail"" ) . description ( ""Path of the file to tail in case of single file mode. If using multifile mode, regular expression to find files "" + ""to tail in the base directory. In case recursivity is set to true, the regular expression will be used to match the "" + ""path starting from the base directory (see additional details for examples)."" ) . expressionLanguageSupported ( ExpressionLanguageScope . VARIABLE_REGISTRY ) . addValidator ( StandardValidators . createRegexValidator ( 0 , Integer . MAX_VALUE , true ) ) . required ( true ) . build ( ) ; static final PropertyDescriptor ROLLING_FILENAME_PATTERN = new PropertyDescriptor . Builder ( ) . name ( ""Rolling Filename Pattern"" ) . description ( ""If the file to tail \""rolls over\"" as would be the case with log files, this filename pattern will be used to "" + ""identify files that have rolled over so that if NiFi is restarted, and the file has rolled over, it will be able to pick up where it left off. "" + ""This pattern supports wildcard characters * and ?, it also supports the notation ${filename} to specify a pattern based on the name of the file "" + ""(without extension), and will assume that the files that have rolled over live in the same directory as the file being tailed. "" + ""The same glob pattern will be used for all files."" ) . addValidator ( StandardValidators . NON_EMPTY_VALIDATOR ) . expressionLanguageSupported ( ExpressionLanguageScope . NONE ) . required ( false ) . build ( ) ; static final PropertyDescriptor STATE_LOCATION = new PropertyDescriptor . Builder ( ) . displayName ( ""State Location"" ) . name ( ""File Location"" ) . description ( ""Specifies where the state is located either local or cluster so that state can be stored "" + ""appropriately in order to ensure that all data is consumed without duplicating data upon restart of NiFi"" ) . required ( true ) . allowableValues ( LOCATION_LOCAL , LOCATION_REMOTE ) . defaultValue ( LOCATION_LOCAL . getValue ( ) ) . build ( ) ; static final PropertyDescriptor START_POSITION = new PropertyDescriptor . Builder ( ) . name ( ""Initial Start Position"" ) . description ( ""When the Processor first begins to tail data, this property specifies where the Processor should begin reading data. Once data has been ingested from a file, "" + ""the Processor will continue from the last point from which it has received data."" ) . allowableValues ( START_BEGINNING_OF_TIME , START_CURRENT_FILE , START_CURRENT_TIME ) . defaultValue ( START_CURRENT_FILE . getValue ( ) ) . required ( true ) . build ( ) ; static final PropertyDescriptor RECURSIVE = new PropertyDescriptor . Builder ( ) . name ( ""tailfile-recursive-lookup"" ) . displayName ( ""Recursive lookup"" ) . description ( ""When using Multiple files mode, this property defines if files must be listed recursively or not"" + "" in the base directory."" ) . allowableValues ( ""true"" , ""false"" ) . defaultValue ( ""false"" ) . required ( true ) . build ( ) ; static final PropertyDescriptor LOOKUP_FREQUENCY = new PropertyDescriptor . Builder ( ) . name ( ""tailfile-lookup-frequency"" ) . displayName ( ""Lookup frequency"" ) . description ( ""Only used in Multiple files mode and Changing name rolling strategy. It specifies the minimum "" + ""duration the processor will wait before listing again the files to tail."" ) . required ( false ) . defaultValue ( ""10 minutes"" ) . addValidator ( StandardValidators . TIME_PERIOD_VALIDATOR ) . build ( ) ; static final PropertyDescriptor MAXIMUM_AGE = new PropertyDescriptor . Builder ( ) . name ( ""tailfile-maximum-age"" ) . displayName ( ""Maximum age"" ) . description ( ""Only used in Multiple files mode and Changing name rolling strategy. It specifies the necessary "" + ""minimum duration to consider that no new messages will be appended in a file regarding its last "" + ""modification date. This should not be set too low to avoid duplication of data in case new messages "" + ""are appended at a lower frequency."" ) . required ( false ) . defaultValue ( ""24 hours"" ) . addValidator ( StandardValidators . TIME_PERIOD_VALIDATOR ) . build ( ) ; static final Relationship REL_SUCCESS = new Relationship . Builder ( ) . name ( ""success"" ) . description ( ""All FlowFiles are routed to this Relationship."" ) . build ( ) ; private volatile Map < String , TailFileObject > states = new HashMap < String , TailFileObject > ( ) ; private volatile AtomicLong lastLookup = new AtomicLong ( 0L ) ; private volatile AtomicBoolean isMultiChanging = new AtomicBoolean ( false ) ; private volatile boolean requireStateLookup = true ; @ Override protected List < PropertyDescriptor > getSupportedPropertyDescriptors ( ) { final List < PropertyDescriptor > properties = new ArrayList < > ( ) ; properties . add ( MODE ) ; properties . add ( FILENAME ) ; properties . add ( ROLLING_FILENAME_PATTERN ) ; properties . add ( BASE_DIRECTORY ) ; properties . add ( START_POSITION ) ; properties . add ( STATE_LOCATION ) ; properties . add ( RECURSIVE ) ; properties . add ( LOOKUP_FREQUENCY ) ; properties . add ( MAXIMUM_AGE ) ; return properties ; } @ Override public Set < Relationship > getRelationships ( ) { return Collections . singleton ( REL_SUCCESS ) ; } @ Override public void onPropertyModified ( final PropertyDescriptor descriptor , final String oldValue , final String newValue ) { if ( isConfigurationRestored ( ) && FILENAME . equals ( descriptor ) ) { states = new HashMap < String , TailFileObject > ( ) ; } } @ Override protected Collection < ValidationResult > customValidate ( ValidationContext context ) { final List < ValidationResult > results = new ArrayList < > ( super . customValidate ( context ) ) ; if ( context . getProperty ( MODE ) . getValue ( ) . equals ( MODE_MULTIFILE . getValue ( ) ) ) { String path = context . getProperty ( BASE_DIRECTORY ) . evaluateAttributeExpressions ( ) . getValue ( ) ; if ( path == null ) { results . add ( new ValidationResult . Builder ( ) . subject ( BASE_DIRECTORY . getName ( ) ) . valid ( false ) . explanation ( ""Base directory property cannot be empty in Multifile mode."" ) . build ( ) ) ; } else if ( ! new File ( path ) . isDirectory ( ) ) { results . add ( new ValidationResult . Builder ( ) . subject ( BASE_DIRECTORY . getName ( ) ) . valid ( false ) . explanation ( path + "" is not a directory."" ) . build ( ) ) ; } } return results ; } @ OnPrimaryNodeStateChange public void onPrimaryNodeChange ( ) { this . requireStateLookup = true ; } private List < String > lookup ( final ProcessContext context ) { lastLookup . set ( new Date ( ) . getTime ( ) ) ; long maxAge = context . getProperty ( MAXIMUM_AGE ) . getValue ( ) == null ? Long . MAX_VALUE : context . getProperty ( MAXIMUM_AGE ) . asTimePeriod ( TimeUnit . MILLISECONDS ) ; List < String > filesToTail = new ArrayList < String > ( ) ; if ( context . getProperty ( MODE ) . getValue ( ) . equals ( MODE_MULTIFILE . getValue ( ) ) ) { filesToTail . addAll ( getFilesToTail ( context . getProperty ( BASE_DIRECTORY ) . evaluateAttributeExpressions ( ) . getValue ( ) , context . getProperty ( FILENAME ) . evaluateAttributeExpressions ( ) . getValue ( ) , context . getProperty ( RECURSIVE ) . asBoolean ( ) , maxAge ) ) ; } else { filesToTail . add ( context . getProperty ( FILENAME ) . evaluateAttributeExpressions ( ) . getValue ( ) ) ; } return filesToTail ; } @ OnScheduled public void recoverState ( final ProcessContext context ) throws IOException { isMultiChanging . set ( context . getProperty ( MODE ) . getValue ( ) . equals ( MODE_MULTIFILE . getValue ( ) ) ) ; List < String > filesToTail = lookup ( context ) ; final Scope scope = getStateScope ( context ) ; final StateMap stateMap = context . getStateManager ( ) . getState ( scope ) ; if ( stateMap . getVersion ( ) == - 1L ) { initStates ( filesToTail , Collections . emptyMap ( ) , true ) ; recoverState ( context , filesToTail , Collections . emptyMap ( ) ) ; return ; } Map < String , String > statesMap = stateMap . toMap ( ) ; if ( statesMap . containsKey ( TailFileState . StateKeys . FILENAME ) && ! statesMap . keySet ( ) . stream ( ) . anyMatch ( key -> key . startsWith ( MAP_PREFIX ) ) ) { final Map < String , String > migratedStatesMap = new HashMap < > ( statesMap . size ( ) ) ; for ( String key : statesMap . keySet ( ) ) { migratedStatesMap . put ( MAP_PREFIX + ""0."" + key , statesMap . get ( key ) ) ; } migratedStatesMap . put ( MAP_PREFIX + ""0."" + TailFileState . StateKeys . LENGTH , statesMap . get ( TailFileState . StateKeys . POSITION ) ) ; statesMap = Collections . unmodifiableMap ( migratedStatesMap ) ; getLogger ( ) . info ( ""statesMap has been migrated. {}"" , new Object [ ] { migratedStatesMap } ) ; } initStates ( filesToTail , statesMap , false ) ; recoverState ( context , filesToTail , statesMap ) ; } private void initStates ( List < String > filesToTail , Map < String , String > statesMap , boolean isCleared ) { int i = 0 ; if ( isCleared ) { states . clear ( ) ; } else { if ( states . isEmpty ( ) && ! statesMap . isEmpty ( ) ) { for ( String key : statesMap . keySet ( ) ) { if ( key . endsWith ( TailFileState . StateKeys . FILENAME ) ) { int index = Integer . valueOf ( key . split ( ""\\."" ) [ 1 ] ) ; states . put ( statesMap . get ( key ) , new TailFileObject ( index , statesMap ) ) ; } } } List < String > toBeRemoved = new ArrayList < String > ( ) ; for ( String file : states . keySet ( ) ) { if ( ! filesToTail . contains ( file ) ) { toBeRemoved . add ( file ) ; cleanReader ( states . get ( file ) ) ; } } states . keySet ( ) . removeAll ( toBeRemoved ) ; for ( String file : states . keySet ( ) ) { if ( i <= states . get ( file ) . getFilenameIndex ( ) ) { i = states . get ( file ) . getFilenameIndex ( ) + 1 ; } } } for ( String file : filesToTail ) { if ( isCleared || ! states . containsKey ( file ) ) { states . put ( file , new TailFileObject ( i ) ) ; i ++ ; } } } private void recoverState ( final ProcessContext context , final List < String > filesToTail , final Map < String , String > map ) throws IOException { for ( String file : filesToTail ) { recoverState ( context , map , file ) ; } } private List < String > getFilesToTail ( final String baseDir , String fileRegex , boolean isRecursive , long maxAge ) { final Collection < File > files = FileUtils . listFiles ( new File ( baseDir ) , null , isRecursive ) ; final List < String > result = new ArrayList < String > ( ) ; final String baseDirNoTrailingSeparator = baseDir . endsWith ( File . separator ) ? baseDir . substring ( 0 , baseDir . length ( ) - 1 ) : baseDir ; final String fullRegex ; if ( File . separator . equals ( ""/"" ) ) { fullRegex = baseDirNoTrailingSeparator + File . separator + fileRegex ; } else { fullRegex = baseDirNoTrailingSeparator + Pattern . quote ( File . separator ) + fileRegex ; } final Pattern p = Pattern . compile ( fullRegex ) ; for ( File file : files ) { final String path = file . getPath ( ) ; if ( p . matcher ( path ) . matches ( ) ) { if ( isMultiChanging . get ( ) ) { if ( ( new Date ( ) . getTime ( ) - file . lastModified ( ) ) < maxAge ) { result . add ( path ) ; } } else { result . add ( path ) ; } } } return result ; } private void recoverState ( final ProcessContext context , final Map < String , String > stateValues , final String filePath ) throws IOException { final String prefix = MAP_PREFIX + states . get ( filePath ) . getFilenameIndex ( ) + '.' ; if ( ! stateValues . containsKey ( prefix + TailFileState . StateKeys . FILENAME ) ) { resetState ( filePath ) ; return ; } if ( ! stateValues . containsKey ( prefix + TailFileState . StateKeys . POSITION ) ) { resetState ( filePath ) ; return ; } if ( ! stateValues . containsKey ( prefix + TailFileState . StateKeys . TIMESTAMP ) ) { resetState ( filePath ) ; return ; } if ( ! stateValues . containsKey ( prefix + TailFileState . StateKeys . LENGTH ) ) { resetState ( filePath ) ; return ; } final String checksumValue = stateValues . get ( prefix + TailFileState . StateKeys . CHECKSUM ) ; final boolean checksumPresent = ( checksumValue != null ) ; final String storedStateFilename = stateValues . get ( prefix + TailFileState . StateKeys . FILENAME ) ; final long position = Long . parseLong ( stateValues . get ( prefix + TailFileState . StateKeys . POSITION ) ) ; final long timestamp = Long . parseLong ( stateValues . get ( prefix + TailFileState . StateKeys . TIMESTAMP ) ) ; final long length = Long . parseLong ( stateValues . get ( prefix + TailFileState . StateKeys . LENGTH ) ) ; FileChannel reader = null ; File tailFile = null ; if ( checksumPresent && filePath . equals ( storedStateFilename ) ) { states . get ( filePath ) . setExpectedRecoveryChecksum ( Long . parseLong ( checksumValue ) ) ; final Checksum checksum = new CRC32 ( ) ; final File existingTailFile = new File ( storedStateFilename ) ; if ( existingTailFile . length ( ) >= position ) { try ( final InputStream tailFileIs = new FileInputStream ( existingTailFile ) ; final CheckedInputStream in = new CheckedInputStream ( tailFileIs , checksum ) ) { try { StreamUtils . copy ( in , new NullOutputStream ( ) , states . get ( filePath ) . getState ( ) . getPosition ( ) ) ; } catch ( final EOFException eof ) { getLogger ( ) . debug ( ""When recovering state, file being tailed has less data than was stored in the state. "" + ""Assuming rollover. Will begin tailing current file from beginning."" ) ; } final long checksumResult = in . getChecksum ( ) . getValue ( ) ; if ( checksumResult == states . get ( filePath ) . getExpectedRecoveryChecksum ( ) ) { getLogger ( ) . debug ( ""When recovering state, checksum of tailed file matches the stored checksum. Will resume where left off."" ) ; tailFile = existingTailFile ; reader = FileChannel . open ( tailFile . toPath ( ) , StandardOpenOption . READ ) ; getLogger ( ) . debug ( ""Created FileChannel {} for {} in recoverState"" , new Object [ ] { reader , tailFile } ) ; reader . position ( position ) ; } else { getLogger ( ) . debug ( ""When recovering state, checksum of tailed file does not match the stored checksum. Will begin tailing current file from beginning."" ) ; } } } else { getLogger ( ) . debug ( ""When recovering state, existing file to tail is only {} bytes but position flag is {}; "" + ""this indicates that the file has rotated. Will begin tailing current file from beginning."" , new Object [ ] { existingTailFile . length ( ) , position } ) ; } states . get ( filePath ) . setState ( new TailFileState ( filePath , tailFile , reader , position , timestamp , length , checksum , ByteBuffer . allocate ( 65536 ) ) ) ; } else { resetState ( filePath ) ; } getLogger ( ) . debug ( ""Recovered state {}"" , new Object [ ] { states . get ( filePath ) . getState ( ) } ) ; } private void resetState ( final String filePath ) { states . get ( filePath ) . setExpectedRecoveryChecksum ( null ) ; states . get ( filePath ) . setState ( new TailFileState ( filePath , null , null , 0L , 0L , 0L , null , ByteBuffer . allocate ( 65536 ) ) ) ; } @ OnStopped public void cleanup ( ) { for ( TailFileObject tfo : states . values ( ) ) { cleanReader ( tfo ) ; final TailFileState state = tfo . getState ( ) ; tfo . setState ( new TailFileState ( state . getFilename ( ) , state . getFile ( ) , null , state . getPosition ( ) , state . getTimestamp ( ) , state . getLength ( ) , state . getChecksum ( ) , state . getBuffer ( ) ) ) ; } } private void cleanReader ( TailFileObject tfo ) { if ( tfo . getState ( ) == null ) { return ; } final FileChannel reader = tfo . getState ( ) . getReader ( ) ; if ( reader == null ) { return ; } try { reader . close ( ) ; getLogger ( ) . debug ( ""Closed FileChannel {}"" , new Object [ ] { reader } ) ; } catch ( final IOException ioe ) { getLogger ( ) . warn ( ""Failed to close file handle during cleanup"" ) ; } } @ Override public void onTrigger ( final ProcessContext context , final ProcessSession session ) throws ProcessException { if ( isMultiChanging . get ( ) ) { long timeSinceLastLookup = new Date ( ) . getTime ( ) - lastLookup . get ( ) ; if ( timeSinceLastLookup > context . getProperty ( LOOKUP_FREQUENCY ) . asTimePeriod ( TimeUnit . MILLISECONDS ) ) { try { final List < String > filesToTail = lookup ( context ) ; final Scope scope = getStateScope ( context ) ; final StateMap stateMap = context . getStateManager ( ) . getState ( scope ) ; initStates ( filesToTail , stateMap . toMap ( ) , false ) ; } catch ( IOException e ) { getLogger ( ) . error ( ""Exception raised while attempting to recover state about where the tailing last left off"" , e ) ; context . yield ( ) ; return ; } } } if ( requireStateLookup ) { try { recoverState ( context ) ; } catch ( IOException e ) { getLogger ( ) . error ( ""Exception raised while attempting to recover state about where the tailing last left off"" , e ) ; context . yield ( ) ; return ; } requireStateLookup = false ; } if ( states . isEmpty ( ) ) { context . yield ( ) ; return ; } for ( String tailFile : states . keySet ( ) ) { processTailFile ( context , session , tailFile ) ; } } private void processTailFile ( final ProcessContext context , final ProcessSession session , final String tailFile ) { boolean rolloverOccurred ; TailFileObject tfo = states . get ( tailFile ) ; if ( tfo . isTailFileChanged ( ) ) { rolloverOccurred = false ; final String recoverPosition = context . getProperty ( START_POSITION ) . getValue ( ) ; if ( START_BEGINNING_OF_TIME . getValue ( ) . equals ( recoverPosition ) ) { recoverRolledFiles ( context , session , tailFile , tfo . getExpectedRecoveryChecksum ( ) , tfo . getState ( ) . getTimestamp ( ) , tfo . getState ( ) . getPosition ( ) ) ; } else if ( START_CURRENT_FILE . getValue ( ) . equals ( recoverPosition ) ) { cleanup ( ) ; tfo . setState ( new TailFileState ( tailFile , null , null , 0L , 0L , 0L , null , tfo . getState ( ) . getBuffer ( ) ) ) ; } else { final String filename = tailFile ; final File file = new File ( filename ) ; try { final FileChannel fileChannel = FileChannel . open ( file . toPath ( ) , StandardOpenOption . READ ) ; getLogger ( ) . debug ( ""Created FileChannel {} for {}"" , new Object [ ] { fileChannel , file } ) ; final Checksum checksum = new CRC32 ( ) ; final long position = file . length ( ) ; final long timestamp = file . lastModified ( ) ; try ( final InputStream fis = new FileInputStream ( file ) ; final CheckedInputStream in = new CheckedInputStream ( fis , checksum ) ) { StreamUtils . copy ( in , new NullOutputStream ( ) , position ) ; } fileChannel . position ( position ) ; cleanup ( ) ; tfo . setState ( new TailFileState ( filename , file , fileChannel , position , timestamp , file . length ( ) , checksum , tfo . getState ( ) . getBuffer ( ) ) ) ; } catch ( final IOException ioe ) { getLogger ( ) . error ( ""Attempted to position Reader at current position in file {} but failed to do so due to {}"" , new Object [ ] { file , ioe . toString ( ) } , ioe ) ; context . yield ( ) ; return ; } } tfo . setTailFileChanged ( false ) ; } else { Long expectedChecksumValue = tfo . getExpectedRecoveryChecksum ( ) ; if ( expectedChecksumValue == null ) { expectedChecksumValue = tfo . getState ( ) . getChecksum ( ) == null ? null : tfo . getState ( ) . getChecksum ( ) . getValue ( ) ; } rolloverOccurred = recoverRolledFiles ( context , session , tailFile , expectedChecksumValue , tfo . getState ( ) . getTimestamp ( ) , tfo . getState ( ) . getPosition ( ) ) ; tfo . setExpectedRecoveryChecksum ( null ) ; } TailFileState state = tfo . getState ( ) ; File file = state . getFile ( ) ; FileChannel reader = state . getReader ( ) ; Checksum checksum = state . getChecksum ( ) ; if ( checksum == null ) { checksum = new CRC32 ( ) ; } long position = state . getPosition ( ) ; long timestamp = state . getTimestamp ( ) ; long length = state . getLength ( ) ; if ( file == null || reader == null ) { file = new File ( tailFile ) ; reader = createReader ( file , position ) ; if ( reader == null ) { context . yield ( ) ; return ; } } final long startNanos = System . nanoTime ( ) ; boolean rotated = rolloverOccurred ; if ( ! rotated ) { final long fileLength = file . length ( ) ; if ( length > fileLength ) { rotated = true ; } else { try { final long readerSize = reader . size ( ) ; final long readerPosition = reader . position ( ) ; if ( readerSize == readerPosition && readerSize != fileLength ) { rotated = true ; } } catch ( final IOException e ) { getLogger ( ) . warn ( ""Failed to determined the size or position of the File Channel when "" + ""determining if the file has rolled over. Will assume that the file being tailed has not rolled over"" , e ) ; } } } if ( rotated ) { try { reader . close ( ) ; getLogger ( ) . debug ( ""Closed FileChannel {}"" , new Object [ ] { reader , reader } ) ; } catch ( final IOException ioe ) { getLogger ( ) . warn ( ""Failed to close reader for {} due to {}"" , new Object [ ] { file , ioe } ) ; } reader = createReader ( file , 0L ) ; position = 0L ; checksum . reset ( ) ; } if ( file . length ( ) == position || ! file . exists ( ) ) { getLogger ( ) . debug ( ""No data to consume; created no FlowFiles"" ) ; tfo . setState ( new TailFileState ( tailFile , file , reader , position , timestamp , length , checksum , state . getBuffer ( ) ) ) ; persistState ( tfo , context ) ; context . yield ( ) ; return ; } final TailFileState currentState = state ; final Checksum chksum = checksum ; FlowFile flowFile = session . create ( ) ; final FileChannel fileReader = reader ; final AtomicLong positionHolder = new AtomicLong ( position ) ; flowFile = session . write ( flowFile , new OutputStreamCallback ( ) { @ Override public void process ( final OutputStream rawOut ) throws IOException { try ( final OutputStream out = new BufferedOutputStream ( rawOut ) ) { positionHolder . set ( readLines ( fileReader , currentState . getBuffer ( ) , out , chksum ) ) ; } } } ) ; if ( flowFile . getSize ( ) == 0 ) { session . remove ( flowFile ) ; getLogger ( ) . debug ( ""No data to consume; removed created FlowFile"" ) ; } else { final String tailFilename = file . getName ( ) ; final String baseName = StringUtils . substringBeforeLast ( tailFilename , ""."" ) ; final String flowFileName ; if ( baseName . length ( ) < tailFilename . length ( ) ) { flowFileName = baseName + ""."" + position + ""-"" + positionHolder . get ( ) + ""."" + StringUtils . substringAfterLast ( tailFilename , ""."" ) ; } else { flowFileName = baseName + ""."" + position + ""-"" + positionHolder . get ( ) ; } final Map < String , String > attributes = new HashMap < > ( 3 ) ; attributes . put ( CoreAttributes . FILENAME . key ( ) , flowFileName ) ; attributes . put ( CoreAttributes . MIME_TYPE . key ( ) , ""text/plain"" ) ; attributes . put ( ""tailfile.original.path"" , tailFile ) ; flowFile = session . putAllAttributes ( flowFile , attributes ) ; session . getProvenanceReporter ( ) . receive ( flowFile , file . toURI ( ) . toString ( ) , ""FlowFile contains bytes "" + position + "" through "" + positionHolder . get ( ) + "" of source file"" , TimeUnit . NANOSECONDS . toMillis ( System . nanoTime ( ) - startNanos ) ) ; session . transfer ( flowFile , REL_SUCCESS ) ; position = positionHolder . get ( ) ; timestamp = Math . max ( state . getTimestamp ( ) , file . lastModified ( ) ) ; length = file . length ( ) ; getLogger ( ) . debug ( ""Created {} and routed to success"" , new Object [ ] { flowFile } ) ; } tfo . setState ( new TailFileState ( tailFile , file , reader , position , timestamp , length , checksum , state . getBuffer ( ) ) ) ; session . commit ( ) ; persistState ( tfo , context ) ; } private long readLines ( final FileChannel reader , final ByteBuffer buffer , final OutputStream out , final Checksum checksum ) throws IOException { getLogger ( ) . debug ( ""Reading lines starting at position {}"" , new Object [ ] { reader . position ( ) } ) ; try ( final ByteArrayOutputStream baos = new ByteArrayOutputStream ( ) ) { long pos = reader . position ( ) ; long rePos = pos ; int num ; int linesRead = 0 ; boolean seenCR = false ; buffer . clear ( ) ; while ( ( ( num = reader . read ( buffer ) ) != - 1 ) ) { buffer . flip ( ) ; for ( int i = 0 ; i < num ; i ++ ) { byte ch = buffer . get ( i ) ; switch ( ch ) { case '\n' : { baos . write ( ch ) ; seenCR = false ; baos . writeTo ( out ) ; final byte [ ] baosBuffer = baos . toByteArray ( ) ; checksum . update ( baosBuffer , 0 , baos . size ( ) ) ; if ( getLogger ( ) . isTraceEnabled ( ) ) { getLogger ( ) . trace ( ""Checksum updated to {}"" , new Object [ ] { checksum . getValue ( ) } ) ; } baos . reset ( ) ; rePos = pos + i + 1 ; linesRead ++ ; break ; } case '\r' : { baos . write ( ch ) ; seenCR = true ; break ; } default : { if ( seenCR ) { seenCR = false ; baos . writeTo ( out ) ; final byte [ ] baosBuffer = baos . toByteArray ( ) ; checksum . update ( baosBuffer , 0 , baos . size ( ) ) ; if ( getLogger ( ) . isTraceEnabled ( ) ) { getLogger ( ) . trace ( ""Checksum updated to {}"" , new Object [ ] { checksum . getValue ( ) } ) ; } linesRead ++ ; baos . reset ( ) ; baos . write ( ch ) ; rePos = pos + i ; } else { baos . write ( ch ) ; } } } } pos = reader . position ( ) ; } if ( rePos < reader . position ( ) ) { getLogger ( ) . debug ( ""Read {} lines; repositioning reader from {} to {}"" , new Object [ ] { linesRead , pos , rePos } ) ; reader . position ( rePos ) ; } return rePos ; } } private List < File > getRolledOffFiles ( final ProcessContext context , final long minTimestamp , final String tailFilePath ) throws IOException { final File tailFile = new File ( tailFilePath ) ; File directory = tailFile . getParentFile ( ) ; if ( directory == null ) { directory = new File ( ""."" ) ; } String rollingPattern = context . getProperty ( ROLLING_FILENAME_PATTERN ) . getValue ( ) ; if ( rollingPattern == null ) { return Collections . emptyList ( ) ; } else { rollingPattern = rollingPattern . replace ( ""${filename}"" , StringUtils . substringBeforeLast ( tailFile . getName ( ) , ""."" ) ) ; } final List < File > rolledOffFiles = new ArrayList < > ( ) ; try ( final DirectoryStream < Path > dirStream = Files . newDirectoryStream ( directory . toPath ( ) , rollingPattern ) ) { for ( final Path path : dirStream ) { final File file = path . toFile ( ) ; final long lastMod = file . lastModified ( ) ; if ( file . lastModified ( ) < minTimestamp ) { getLogger ( ) . debug ( ""Found rolled off file {} but its last modified timestamp is before the cutoff (Last Mod = {}, Cutoff = {}) so will not consume it"" , new Object [ ] { file , lastMod , minTimestamp } ) ; continue ; } else if ( file . equals ( tailFile ) ) { continue ; } rolledOffFiles . add ( file ) ; } } Collections . sort ( rolledOffFiles , new Comparator < File > ( ) { @ Override public int compare ( final File o1 , final File o2 ) { final int lastModifiedComp = Long . compare ( o1 . lastModified ( ) , o2 . lastModified ( ) ) ; if ( lastModifiedComp != 0 ) { return lastModifiedComp ; } return o1 . getName ( ) . compareTo ( o2 . getName ( ) ) ; } } ) ; return rolledOffFiles ; } private Scope getStateScope ( final ProcessContext context ) { final String location = context . getProperty ( STATE_LOCATION ) . getValue ( ) ; if ( LOCATION_REMOTE . getValue ( ) . equalsIgnoreCase ( location ) ) { return Scope . CLUSTER ; } return Scope . LOCAL ; } private void persistState ( final TailFileObject tfo , final ProcessContext context ) { persistState ( tfo . getState ( ) . toStateMap ( tfo . getFilenameIndex ( ) ) , context ) ; } private void persistState ( final Map < String , String > state , final ProcessContext context ) { try { StateMap oldState = context . getStateManager ( ) . getState ( getStateScope ( context ) ) ; Map < String , String > updatedState = new HashMap < String , String > ( ) ; for ( String key : oldState . toMap ( ) . keySet ( ) ) { if ( TailFileState . StateKeys . CHECKSUM . equals ( key ) || TailFileState . StateKeys . FILENAME . equals ( key ) || TailFileState . StateKeys . POSITION . equals ( key ) || TailFileState . StateKeys . TIMESTAMP . equals ( key ) ) { getLogger ( ) . info ( ""Removed state {}={} stored by older version of NiFi."" , new Object [ ] { key , oldState . get ( key ) } ) ; continue ; } updatedState . put ( key , oldState . get ( key ) ) ; } updatedState . putAll ( state ) ; context . getStateManager ( ) . setState ( updatedState , getStateScope ( context ) ) ; } catch ( final IOException e ) { getLogger ( ) . warn ( ""Failed to store state due to {}; some data may be duplicated on restart of NiFi"" , new Object [ ] { e } ) ; } } private FileChannel createReader ( final File file , final long position ) { final FileChannel reader ; try { reader = FileChannel . open ( file . toPath ( ) , StandardOpenOption . READ ) ; } catch ( final IOException ioe ) { getLogger ( ) . warn ( ""Unable to open file {}; will attempt to access file again after the configured Yield Duration has elapsed: {}"" , new Object [ ] { file , ioe } ) ; return null ; } getLogger ( ) . debug ( ""Created FileChannel {} for {}"" , new Object [ ] { reader , file } ) ; try { reader . position ( position ) ; } catch ( final IOException ioe ) { getLogger ( ) . error ( ""Failed to read from {} due to {}"" , new Object [ ] { file , ioe } ) ; try { reader . close ( ) ; getLogger ( ) . debug ( ""Closed FileChannel {}"" , new Object [ ] { reader } ) ; } catch ( final IOException ioe2 ) { } return null ; } return reader ; } Map < String , TailFileObject > getState ( ) { return states ; } private boolean recoverRolledFiles ( final ProcessContext context , final ProcessSession session , final String tailFile , final Long expectedChecksum , final long timestamp , final long position ) { try { final List < File > rolledOffFiles = getRolledOffFiles ( context , timestamp , tailFile ) ; return recoverRolledFiles ( context , session , tailFile , rolledOffFiles , expectedChecksum , timestamp , position ) ; } catch ( final IOException e ) { getLogger ( ) . error ( ""Failed to recover files that have rolled over due to {}"" , new Object [ ] { e } ) ; return false ; } } private boolean recoverRolledFiles ( final ProcessContext context , final ProcessSession session , final String tailFile , final List < File > rolledOffFiles , final Long expectedChecksum , final long timestamp , final long position ) { try { getLogger ( ) . debug ( ""Recovering Rolled Off Files; total number of files rolled off = {}"" , new Object [ ] { rolledOffFiles . size ( ) } ) ; TailFileObject tfo = states . get ( tailFile ) ; boolean rolloverOccurred = ! rolledOffFiles . isEmpty ( ) ; if ( rolloverOccurred && expectedChecksum != null && rolledOffFiles . get ( 0 ) . length ( ) >= position ) { final File firstFile = rolledOffFiles . get ( 0 ) ; final long startNanos = System . nanoTime ( ) ; if ( position > 0 ) { try ( final InputStream fis = new FileInputStream ( firstFile ) ; final CheckedInputStream in = new CheckedInputStream ( fis , new CRC32 ( ) ) ) { StreamUtils . copy ( in , new NullOutputStream ( ) , position ) ; final long checksumResult = in . getChecksum ( ) . getValue ( ) ; if ( checksumResult == expectedChecksum ) { getLogger ( ) . debug ( ""Checksum for {} matched expected checksum. Will skip first {} bytes"" , new Object [ ] { firstFile , position } ) ; rolledOffFiles . remove ( 0 ) ; FlowFile flowFile = session . create ( ) ; flowFile = session . importFrom ( in , flowFile ) ; if ( flowFile . getSize ( ) == 0L ) { session . remove ( flowFile ) ; cleanup ( ) ; tfo . setState ( new TailFileState ( tailFile , null , null , 0L , firstFile . lastModified ( ) + 1L , firstFile . length ( ) , null , tfo . getState ( ) . getBuffer ( ) ) ) ; } else { final Map < String , String > attributes = new HashMap < > ( 3 ) ; attributes . put ( CoreAttributes . FILENAME . key ( ) , firstFile . getName ( ) ) ; attributes . put ( CoreAttributes . MIME_TYPE . key ( ) , ""text/plain"" ) ; attributes . put ( ""tailfile.original.path"" , tailFile ) ; flowFile = session . putAllAttributes ( flowFile , attributes ) ; session . getProvenanceReporter ( ) . receive ( flowFile , firstFile . toURI ( ) . toString ( ) , ""FlowFile contains bytes 0 through "" + position + "" of source file"" , TimeUnit . NANOSECONDS . toMillis ( System . nanoTime ( ) - startNanos ) ) ; session . transfer ( flowFile , REL_SUCCESS ) ; getLogger ( ) . debug ( ""Created {} from rolled over file {} and routed to success"" , new Object [ ] { flowFile , firstFile } ) ; cleanup ( ) ; tfo . setState ( new TailFileState ( tailFile , null , null , 0L , firstFile . lastModified ( ) + 1L , firstFile . length ( ) , null , tfo . getState ( ) . getBuffer ( ) ) ) ; session . commit ( ) ; persistState ( tfo , context ) ; } } else { getLogger ( ) . debug ( ""Checksum for {} did not match expected checksum. Checksum for file was {} but expected {}. Will consume entire file"" , new Object [ ] { firstFile , checksumResult , expectedChecksum } ) ; } } } } for ( final File file : rolledOffFiles ) { tfo . setState ( consumeFileFully ( file , context , session , tfo ) ) ; } return rolloverOccurred ; } catch ( final IOException e ) { getLogger ( ) . error ( ""Failed to recover files that have rolled over due to {}"" , new Object [ ] { e } ) ; return false ; } } private TailFileState consumeFileFully ( final File file , final ProcessContext context , final ProcessSession session , TailFileObject tfo ) { FlowFile flowFile = session . create ( ) ; flowFile = session . importFrom ( file . toPath ( ) , true , flowFile ) ; if ( flowFile . getSize ( ) == 0L ) { session . remove ( flowFile ) ; } else { final Map < String , String > attributes = new HashMap < > ( 3 ) ; attributes . put ( CoreAttributes . FILENAME . key ( ) , file . getName ( ) ) ; attributes . put ( CoreAttributes . MIME_TYPE . key ( ) , ""text/plain"" ) ; attributes . put ( ""tailfile.original.path"" , tfo . getState ( ) . getFilename ( ) ) ; flowFile = session . putAllAttributes ( flowFile , attributes ) ; session . getProvenanceReporter ( ) . receive ( flowFile , file . toURI ( ) . toString ( ) ) ; session . transfer ( flowFile , REL_SUCCESS ) ; getLogger ( ) . debug ( ""Created {} from {} and routed to success"" , new Object [ ] { flowFile , file } ) ; cleanup ( ) ; tfo . setState ( new TailFileState ( context . getProperty ( FILENAME ) . evaluateAttributeExpressions ( ) . getValue ( ) , null , null , 0L , file . lastModified ( ) + 1L , file . length ( ) , null , tfo . getState ( ) . getBuffer ( ) ) ) ; session . commit ( ) ; persistState ( tfo , context ) ; } return tfo . getState ( ) ; } static class TailFileObject { private TailFileState state = new TailFileState ( null , null , null , 0L , 0L , 0L , null , ByteBuffer . allocate ( 65536 ) ) ; private Long expectedRecoveryChecksum ; private int filenameIndex ; private boolean tailFileChanged = true ; public TailFileObject ( int i ) { this . filenameIndex = i ; } public TailFileObject ( int index , Map < String , String > statesMap ) { this . filenameIndex = index ; this . tailFileChanged = false ; final String prefix = MAP_PREFIX + index + '.' ; final String filename = statesMap . get ( prefix + TailFileState . StateKeys . FILENAME ) ; final long position = Long . valueOf ( statesMap . get ( prefix + TailFileState . StateKeys . POSITION ) ) ; final long timestamp = Long . valueOf ( statesMap . get ( prefix + TailFileState . StateKeys . TIMESTAMP ) ) ; final long length = Long . valueOf ( statesMap . get ( prefix + TailFileState . StateKeys . LENGTH ) ) ; this . state = new TailFileState ( filename , new File ( filename ) , null , position , timestamp , length , null , ByteBuffer . allocate ( 65536 ) ) ; } public int getFilenameIndex ( ) { return filenameIndex ; } public void setFilenameIndex ( int filenameIndex ) { this . filenameIndex = filenameIndex ; } public TailFileState getState ( ) { return state ; } public void setState ( TailFileState state ) { this . state = state ; } public Long getExpectedRecoveryChecksum ( ) { return expectedRecoveryChecksum ; } public void setExpectedRecoveryChecksum ( Long expectedRecoveryChecksum ) { this . expectedRecoveryChecksum = expectedRecoveryChecksum ; } public boolean isTailFileChanged ( ) { return tailFileChanged ; } public void setTailFileChanged ( boolean tailFileChanged ) { this . tailFileChanged = tailFileChanged ; } } static class TailFileState { private final String filename ; private final File file ; private final FileChannel reader ; private final long position ; private final long timestamp ; private final long length ; private final Checksum checksum ; private final ByteBuffer buffer ; private static class StateKeys { public static final String FILENAME = ""filename"" ; public static final String POSITION = ""position"" ; public static final String TIMESTAMP = ""timestamp"" ; public static final String CHECKSUM = ""checksum"" ; public static final String LENGTH = ""length"" ; } public TailFileState ( final String filename , final File file , final FileChannel reader , final long position , final long timestamp , final long length , final Checksum checksum , final ByteBuffer buffer ) { this . filename = filename ; this . file = file ; this . reader = reader ; this . position = position ; this . length = length ; this . timestamp = timestamp ; this . checksum = checksum ; this . buffer = buffer ; } public String getFilename ( ) { return filename ; } public File getFile ( ) { return file ; } public FileChannel getReader ( ) { return reader ; } public long getPosition ( ) { return position ; } public long getTimestamp ( ) { return timestamp ; } public long getLength ( ) { return length ; } public Checksum getChecksum ( ) { return checksum ; } public ByteBuffer getBuffer ( ) { return buffer ; } @ Override public String toString ( ) { return ""TailFileState[filename="" + filename + "", position="" + position + "", timestamp="" + timestamp + "", checksum="" + ( checksum == null ? ""null"" : checksum . getValue ( ) ) + ""]"" ; } public Map < String , String > toStateMap ( int index ) { final String prefix = MAP_PREFIX + index + '.' ; final Map < String , String > map = new HashMap < > ( 4 ) ; map . put ( prefix + StateKeys . FILENAME , filename ) ; map . put ( prefix + StateKeys . POSITION , String . valueOf ( position ) ) ; map . put ( prefix + StateKeys . LENGTH , String . valueOf ( length ) ) ; map . put ( prefix + StateKeys . TIMESTAMP , String . valueOf ( timestamp ) ) ; map . put ( prefix + StateKeys . CHECKSUM , checksum == null ? null : String . valueOf ( checksum . getValue ( ) ) ) ; return map ; } } ",Smelly
 private static class TGetDelegationTokenRespStandardSchemeFactory implements SchemeFactory { public TGetDelegationTokenRespStandardScheme getScheme ( ) { return new TGetDelegationTokenRespStandardScheme ( ) ; } ,No
"public class JmsBinding { private static final transient Log LOG = LogFactory . getLog ( JmsBinding . class ) ; private JmsEndpoint endpoint ; private XmlConverter xmlConverter = new XmlConverter ( ) ; private HeaderFilterStrategy headerFilterStrategy ; public JmsBinding ( ) { headerFilterStrategy = new JmsHeaderFilterStrategy ( ) ; } public JmsBinding ( JmsEndpoint endpoint ) { this . endpoint = endpoint ; headerFilterStrategy = endpoint . getHeaderFilterStrategy ( ) ; if ( headerFilterStrategy == null ) { headerFilterStrategy = new JmsHeaderFilterStrategy ( ) ; } } public Object extractBodyFromJms ( Exchange exchange , Message message ) { try { if ( message instanceof ObjectMessage ) { ObjectMessage objectMessage = ( ObjectMessage ) message ; return objectMessage . getObject ( ) ; } else if ( message instanceof TextMessage ) { TextMessage textMessage = ( TextMessage ) message ; return textMessage . getText ( ) ; } else if ( message instanceof MapMessage ) { return createMapFromMapMessage ( ( MapMessage ) message ) ; } else if ( message instanceof BytesMessage ) { return createByteArrayFromBytesMessage ( ( BytesMessage ) message ) ; } else if ( message instanceof StreamMessage ) { return message ; } else { return null ; } } catch ( JMSException e ) { throw new RuntimeJmsException ( ""Failed to extract body due to: "" + e + "". Message: "" + message , e ) ; } } public Map < String , Object > extractHeadersFromJms ( Message jmsMessage ) { Map < String , Object > map = new HashMap < String , Object > ( ) ; if ( jmsMessage != null ) { try { map . put ( ""JMSCorrelationID"" , jmsMessage . getJMSCorrelationID ( ) ) ; map . put ( ""JMSDeliveryMode"" , jmsMessage . getJMSDeliveryMode ( ) ) ; map . put ( ""JMSDestination"" , jmsMessage . getJMSDestination ( ) ) ; map . put ( ""JMSExpiration"" , jmsMessage . getJMSExpiration ( ) ) ; map . put ( ""JMSMessageID"" , jmsMessage . getJMSMessageID ( ) ) ; map . put ( ""JMSPriority"" , jmsMessage . getJMSPriority ( ) ) ; map . put ( ""JMSRedelivered"" , jmsMessage . getJMSRedelivered ( ) ) ; map . put ( ""JMSReplyTo"" , jmsMessage . getJMSReplyTo ( ) ) ; map . put ( ""JMSTimestamp"" , jmsMessage . getJMSTimestamp ( ) ) ; map . put ( ""JMSType"" , jmsMessage . getJMSType ( ) ) ; map . put ( ""JMSXGroupID"" , jmsMessage . getStringProperty ( ""JMSXGroupID"" ) ) ; } catch ( JMSException e ) { throw new MessageJMSPropertyAccessException ( e ) ; } Enumeration names ; try { names = jmsMessage . getPropertyNames ( ) ; } catch ( JMSException e ) { throw new MessagePropertyNamesAccessException ( e ) ; } while ( names . hasMoreElements ( ) ) { String name = names . nextElement ( ) . toString ( ) ; try { Object value = jmsMessage . getObjectProperty ( name ) ; if ( headerFilterStrategy != null && headerFilterStrategy . applyFilterToExternalHeaders ( name , value ) ) { continue ; } String key = JmsBinding . decodeFromSafeJmsHeaderName ( name ) ; map . put ( key , value ) ; } catch ( JMSException e ) { throw new MessagePropertyAccessException ( name , e ) ; } } } return map ; } protected byte [ ] createByteArrayFromBytesMessage ( BytesMessage message ) throws JMSException { if ( message . getBodyLength ( ) > Integer . MAX_VALUE ) { return null ; } byte [ ] result = new byte [ ( int ) message . getBodyLength ( ) ] ; message . readBytes ( result ) ; return result ; } public Message makeJmsMessage ( Exchange exchange , Session session ) throws JMSException { return makeJmsMessage ( exchange , exchange . getIn ( ) , session ) ; } public Message makeJmsMessage ( Exchange exchange , org . apache . camel . Message camelMessage , Session session ) throws JMSException { Message answer = null ; boolean alwaysCopy = ( endpoint != null ) ? endpoint . getConfiguration ( ) . isAlwaysCopyMessage ( ) : false ; if ( ! alwaysCopy && camelMessage instanceof JmsMessage ) { JmsMessage jmsMessage = ( JmsMessage ) camelMessage ; if ( ! jmsMessage . shouldCreateNewMessage ( ) ) { answer = jmsMessage . getJmsMessage ( ) ; } } if ( answer == null ) { answer = createJmsMessage ( camelMessage . getBody ( ) , session , exchange . getContext ( ) ) ; appendJmsProperties ( answer , exchange , camelMessage ) ; } return answer ; } public void appendJmsProperties ( Message jmsMessage , Exchange exchange ) throws JMSException { appendJmsProperties ( jmsMessage , exchange , exchange . getIn ( ) ) ; } public void appendJmsProperties ( Message jmsMessage , Exchange exchange , org . apache . camel . Message in ) throws JMSException { Set < Map . Entry < String , Object > > entries = in . getHeaders ( ) . entrySet ( ) ; for ( Map . Entry < String , Object > entry : entries ) { String headerName = entry . getKey ( ) ; Object headerValue = entry . getValue ( ) ; appendJmsProperty ( jmsMessage , exchange , in , headerName , headerValue ) ; } } public void appendJmsProperty ( Message jmsMessage , Exchange exchange , org . apache . camel . Message in , String headerName , Object headerValue ) throws JMSException { if ( headerName . startsWith ( ""JMS"" ) && ! headerName . startsWith ( ""JMSX"" ) ) { if ( headerName . equals ( ""JMSCorrelationID"" ) ) { jmsMessage . setJMSCorrelationID ( ExchangeHelper . convertToType ( exchange , String . class , headerValue ) ) ; } else if ( headerName . equals ( ""JMSReplyTo"" ) && headerValue != null ) { jmsMessage . setJMSReplyTo ( ExchangeHelper . convertToType ( exchange , Destination . class , headerValue ) ) ; } else if ( headerName . equals ( ""JMSType"" ) ) { jmsMessage . setJMSType ( ExchangeHelper . convertToType ( exchange , String . class , headerValue ) ) ; } else if ( LOG . isDebugEnabled ( ) ) { LOG . debug ( ""Ignoring JMS header: "" + headerName + "" with value: "" + headerValue ) ; } } else if ( shouldOutputHeader ( in , headerName , headerValue ) ) { String key = encodeToSafeJmsHeaderName ( headerName ) ; Object value = getValidJMSHeaderValue ( headerName , headerValue ) ; if ( value != null ) { jmsMessage . setObjectProperty ( key , value ) ; } else if ( LOG . isDebugEnabled ( ) ) { LOG . debug ( ""Ignoring non primitive header: "" + headerName + "" of class: "" + headerValue . getClass ( ) . getName ( ) + "" with value: "" + headerValue ) ; } } } protected Object getValidJMSHeaderValue ( String headerName , Object headerValue ) { if ( headerValue . getClass ( ) . isPrimitive ( ) ) { return headerValue ; } else if ( headerValue instanceof String ) { return headerValue ; } else if ( headerValue instanceof Number ) { return headerValue ; } else if ( headerValue instanceof Character ) { return headerValue . toString ( ) ; } else if ( headerValue instanceof BigDecimal || headerValue instanceof BigInteger ) { return headerValue . toString ( ) ; } else if ( headerValue instanceof CharSequence ) { return headerValue . toString ( ) ; } else if ( headerValue instanceof Boolean ) { return headerValue . toString ( ) ; } else if ( headerValue instanceof Date ) { return headerValue . toString ( ) ; } return null ; } protected Message createJmsMessage ( Object body , Session session , CamelContext context ) throws JMSException { if ( body instanceof Node ) { try { body = xmlConverter . toString ( ( Node ) body ) ; } catch ( TransformerException e ) { JMSException jmsException = new JMSException ( e . getMessage ( ) ) ; jmsException . setLinkedException ( e ) ; throw jmsException ; } } if ( body instanceof byte [ ] ) { BytesMessage result = session . createBytesMessage ( ) ; result . writeBytes ( ( byte [ ] ) body ) ; return result ; } if ( body instanceof Map ) { MapMessage result = session . createMapMessage ( ) ; Map < ? , ? > map = ( Map < ? , ? > ) body ; try { populateMapMessage ( result , map , context ) ; return result ; } catch ( JMSException e ) { LOG . warn ( ""Can not populate MapMessage will fall back to ObjectMessage, cause by: "" + e . getMessage ( ) ) ; } } if ( body instanceof String ) { return session . createTextMessage ( ( String ) body ) ; } if ( body instanceof File || body instanceof Reader || body instanceof InputStream || body instanceof ByteBuffer ) { BytesMessage result = session . createBytesMessage ( ) ; byte [ ] bytes = context . getTypeConverter ( ) . convertTo ( byte [ ] . class , body ) ; result . writeBytes ( bytes ) ; return result ; } if ( body instanceof Serializable ) { return session . createObjectMessage ( ( Serializable ) body ) ; } return session . createMessage ( ) ; } protected void populateMapMessage ( MapMessage message , Map < ? , ? > map , CamelContext context ) throws JMSException { for ( Object key : map . keySet ( ) ) { String keyString = CamelContextHelper . convertTo ( context , String . class , key ) ; if ( keyString != null ) { message . setObject ( keyString , map . get ( key ) ) ; } } } public Map < String , Object > createMapFromMapMessage ( MapMessage message ) throws JMSException { Map < String , Object > answer = new HashMap < String , Object > ( ) ; Enumeration names = message . getMapNames ( ) ; while ( names . hasMoreElements ( ) ) { String name = names . nextElement ( ) . toString ( ) ; Object value = message . getObject ( name ) ; answer . put ( name , value ) ; } return answer ; } public Set < String > getIgnoreJmsHeaders ( ) { if ( headerFilterStrategy instanceof DefaultHeaderFilterStrategy ) { return ( ( DefaultHeaderFilterStrategy ) headerFilterStrategy ) . getOutFilter ( ) ; } else { return null ; } } public void setIgnoreJmsHeaders ( Set < String > ignoreJmsHeaders ) { if ( headerFilterStrategy instanceof DefaultHeaderFilterStrategy ) { ( ( DefaultHeaderFilterStrategy ) headerFilterStrategy ) . setOutFilter ( ignoreJmsHeaders ) ; } else { } } protected boolean shouldOutputHeader ( org . apache . camel . Message camelMessage , String headerName , Object headerValue ) { return headerFilterStrategy == null || ! headerFilterStrategy . applyFilterToCamelHeaders ( headerName , headerValue ) ; } public static String encodeToSafeJmsHeaderName ( String headerName ) { return headerName . replace ( ""."" , ""_"" ) ; } public static String decodeFromSafeJmsHeaderName ( String headerName ) { return headerName . replace ( ""_"" , ""."" ) ; } }",Smelly
"public class FulltextQueryTest extends AbstractQueryTest { public void testFulltextSimpleSQL1 ( ) throws Exception { Node foo = testRootNode . addNode ( ""foo"" ) ; foo . setProperty ( ""mytext"" , new String [ ] { ""the quick brown fox jumps over the lazy dog."" } ) ; testRootNode . save ( ) ; String sql = ""SELECT * FROM nt:unstructured"" + "" WHERE jcr:path LIKE '"" + testRoot + ""/%"" + ""' AND CONTAINS(., 'fox')"" ; Query q = superuser . getWorkspace ( ) . getQueryManager ( ) . createQuery ( sql , Query . SQL ) ; QueryResult result = q . execute ( ) ; checkResult ( result , 1 ) ; } public void testFulltextSimpleSQL2 ( ) throws Exception { Node foo = testRootNode . addNode ( ""foo"" ) ; foo . setProperty ( ""mytext"" , new String [ ] { ""the quick brown fox jumps over the lazy dog."" } ) ; testRootNode . save ( ) ; String sql = ""SELECT * FROM nt:unstructured"" + "" WHERE \""jcr:path\"" = '"" + testRoot + ""/foo"" + ""' AND CONTAINS(., 'fox')"" ; Query q = superuser . getWorkspace ( ) . getQueryManager ( ) . createQuery ( sql , Query . SQL ) ; QueryResult result = q . execute ( ) ; checkResult ( result , 1 ) ; } public void testFulltextMultiWordSQL ( ) throws Exception { Node n = testRootNode . addNode ( ""node1"" ) ; n . setProperty ( ""title"" , new String [ ] { ""test text"" } ) ; n . setProperty ( ""mytext"" , new String [ ] { ""the quick brown fox jumps over the lazy dog."" } ) ; n = testRootNode . addNode ( ""node2"" ) ; n . setProperty ( ""title"" , new String [ ] { ""other text"" } ) ; n . setProperty ( ""mytext"" , new String [ ] { ""the quick brown fox jumps over the lazy dog."" } ) ; testRootNode . save ( ) ; String sql = ""SELECT * FROM nt:unstructured"" + "" WHERE \""jcr:path\"" LIKE '"" + testRoot + ""/%"" + ""' AND CONTAINS(., 'fox test')"" ; Query q = superuser . getWorkspace ( ) . getQueryManager ( ) . createQuery ( sql , Query . SQL ) ; QueryResult result = q . execute ( ) ; checkResult ( result , 1 ) ; } public void testFulltextPhraseSQL ( ) throws Exception { Node n = testRootNode . addNode ( ""node1"" ) ; n . setProperty ( ""title"" , new String [ ] { ""test text"" } ) ; n . setProperty ( ""mytext"" , new String [ ] { ""the quick brown jumps fox over the lazy dog."" } ) ; n = testRootNode . addNode ( ""node2"" ) ; n . setProperty ( ""title"" , new String [ ] { ""other text"" } ) ; n . setProperty ( ""mytext"" , new String [ ] { ""the quick brown fox jumps over the lazy dog."" } ) ; testRootNode . save ( ) ; String sql = ""SELECT * FROM nt:unstructured"" + "" WHERE \""jcr:path\"" LIKE '"" + testRoot + ""/%"" + ""' AND CONTAINS(., 'text \""fox jumps\""')"" ; Query q = superuser . getWorkspace ( ) . getQueryManager ( ) . createQuery ( sql , Query . SQL ) ; QueryResult result = q . execute ( ) ; checkResult ( result , 1 ) ; } public void testFulltextExcludeSQL ( ) throws Exception { Node n = testRootNode . addNode ( ""node1"" ) ; n . setProperty ( ""title"" , new String [ ] { ""test text"" } ) ; n . setProperty ( ""mytext"" , new String [ ] { ""the quick brown fox jumps over the lazy dog."" } ) ; n = testRootNode . addNode ( ""node2"" ) ; n . setProperty ( ""title"" , new String [ ] { ""other text"" } ) ; n . setProperty ( ""mytext"" , new String [ ] { ""the quick brown fox jumps over the lazy dog."" } ) ; superuser . getRootNode ( ) . save ( ) ; String sql = ""SELECT * FROM nt:unstructured"" + "" WHERE \""jcr:path\"" LIKE '"" + testRoot + ""/%"" + ""' AND CONTAINS(., 'text ''fox jumps'' -other')"" ; Query q = superuser . getWorkspace ( ) . getQueryManager ( ) . createQuery ( sql , Query . SQL ) ; QueryResult result = q . execute ( ) ; checkResult ( result , 1 ) ; } public void testFulltextOrSQL ( ) throws Exception { Node n = testRootNode . addNode ( ""node1"" ) ; n . setProperty ( ""title"" , new String [ ] { ""test text"" } ) ; n . setProperty ( ""mytext"" , new String [ ] { ""the quick brown fox jumps over the lazy dog."" } ) ; n = testRootNode . addNode ( ""node2"" ) ; n . setProperty ( ""title"" , new String [ ] { ""other text"" } ) ; n . setProperty ( ""mytext"" , new String [ ] { ""the quick brown fox jumps over the lazy dog."" } ) ; testRootNode . save ( ) ; String sql = ""SELECT * FROM nt:unstructured"" + "" WHERE \""jcr:path\"" LIKE '"" + testRoot + ""/%"" + ""' AND CONTAINS(., '''fox jumps'' test OR other')"" ; Query q = superuser . getWorkspace ( ) . getQueryManager ( ) . createQuery ( sql , Query . SQL ) ; QueryResult result = q . execute ( ) ; checkResult ( result , 2 ) ; } public void testFulltextIntercapSQL ( ) throws Exception { Node n = testRootNode . addNode ( ""node1"" ) ; n . setProperty ( ""title"" , new String [ ] { ""tEst text"" } ) ; n . setProperty ( ""mytext"" , new String [ ] { ""The quick brown Fox jumps over the lazy dog."" } ) ; n = testRootNode . addNode ( ""node2"" ) ; n . setProperty ( ""title"" , new String [ ] { ""Other text"" } ) ; n . setProperty ( ""mytext"" , new String [ ] { ""the quick brown FOX jumPs over the lazy dog."" } ) ; testRootNode . save ( ) ; String sql = ""SELECT * FROM nt:unstructured"" + "" WHERE \""jcr:path\"" LIKE '"" + testRoot + ""/%"" + ""' AND CONTAINS(., '''fox juMps'' Test OR otheR')"" ; Query q = superuser . getWorkspace ( ) . getQueryManager ( ) . createQuery ( sql , Query . SQL ) ; QueryResult result = q . execute ( ) ; checkResult ( result , 2 ) ; } public void testContainsStarSQL ( ) throws RepositoryException { Node n = testRootNode . addNode ( ""node1"" ) ; n . setProperty ( ""title"" , new String [ ] { ""tEst text"" } ) ; n . setProperty ( ""mytext"" , new String [ ] { ""The quick brown Fox jumps over the lazy dog."" } ) ; n = testRootNode . addNode ( ""node2"" ) ; n . setProperty ( ""title"" , new String [ ] { ""The quick brown Fox jumps over the lazy dog."" } ) ; n . setProperty ( ""mytext"" , new String [ ] { ""text text"" } ) ; testRootNode . save ( ) ; String sql = ""SELECT * FROM nt:unstructured"" + "" WHERE jcr:path LIKE '"" + testRoot + ""/%"" + ""' AND CONTAINS(., 'fox jumps')"" ; Query q = superuser . getWorkspace ( ) . getQueryManager ( ) . createQuery ( sql , Query . SQL ) ; checkResult ( q . execute ( ) , 2 ) ; } public void testContainsStarXPath ( ) throws RepositoryException { Node n = testRootNode . addNode ( ""node1"" ) ; n . setProperty ( ""title"" , new String [ ] { ""tEst text"" } ) ; n . setProperty ( ""mytext"" , new String [ ] { ""The quick brown Fox jumps over the lazy dog."" } ) ; n = testRootNode . addNode ( ""node2"" ) ; n . setProperty ( ""title"" , new String [ ] { ""The quick brown Fox jumps over the lazy dog."" } ) ; n . setProperty ( ""mytext"" , new String [ ] { ""text text"" } ) ; testRootNode . save ( ) ; String sql = ""/jcr:root"" + testRoot + ""/element(*, nt:unstructured)"" + ""[jcr:contains(., 'quick fox')]"" ; Query q = superuser . getWorkspace ( ) . getQueryManager ( ) . createQuery ( sql , Query . XPATH ) ; checkResult ( q . execute ( ) , 2 ) ; } public void testContainsPropScopeSQL ( ) throws RepositoryException { Node n = testRootNode . addNode ( ""node1"" ) ; n . setProperty ( ""title"" , new String [ ] { ""tEst text"" } ) ; n . setProperty ( ""mytext"" , new String [ ] { ""The quick brown Fox jumps over the lazy dog."" } ) ; n = testRootNode . addNode ( ""node2"" ) ; n . setProperty ( ""title"" , new String [ ] { ""The quick brown Fox jumps over the lazy dog."" } ) ; n . setProperty ( ""mytext"" , new String [ ] { ""text text"" } ) ; testRootNode . save ( ) ; String sql = ""SELECT * FROM nt:unstructured"" + "" WHERE jcr:path LIKE '"" + testRoot + ""/%"" + ""' AND CONTAINS(title, 'fox jumps')"" ; Query q = superuser . getWorkspace ( ) . getQueryManager ( ) . createQuery ( sql , Query . SQL ) ; checkResult ( q . execute ( ) , 1 ) ; } public void testContainsPropScopeXPath ( ) throws RepositoryException { Node n = testRootNode . addNode ( ""node1"" ) ; n . setProperty ( ""title"" , new String [ ] { ""tEst text"" } ) ; n . setProperty ( ""mytext"" , new String [ ] { ""The quick brown Fox jumps over the lazy dog."" } ) ; n = testRootNode . addNode ( ""node2"" ) ; n . setProperty ( ""title"" , new String [ ] { ""The quick brown Fox jumps over the lazy dog."" } ) ; n . setProperty ( ""mytext"" , new String [ ] { ""text text"" } ) ; testRootNode . save ( ) ; String sql = ""/jcr:root"" + testRoot + ""/element(*, nt:unstructured)"" + ""[jcr:contains(@title, 'quick fox')]"" ; Query q = superuser . getWorkspace ( ) . getQueryManager ( ) . createQuery ( sql , Query . XPATH ) ; checkResult ( q . execute ( ) , 1 ) ; } public void testWildcard ( ) throws RepositoryException { String content = ""The quick brown Fox jumps over the lazy dog."" ; executeContainsQuery ( ""qu*"" , content , true ) ; executeContainsQuery ( ""qu*ck"" , content , true ) ; executeContainsQuery ( ""quick*"" , content , true ) ; executeContainsQuery ( ""*quick"" , content , true ) ; executeContainsQuery ( ""qu*Ck"" , content , true ) ; executeContainsQuery ( ""*o*"" , content , true ) ; executeContainsQuery ( ""*ump*"" , content , true ) ; executeContainsQuery ( ""qu**ck"" , content , true ) ; executeContainsQuery ( ""q***u**c*k"" , content , true ) ; executeContainsQuery ( ""*uMp*"" , content , true ) ; executeContainsQuery ( ""quic?"" , content , true ) ; executeContainsQuery ( ""?uick"" , content , true ) ; executeContainsQuery ( ""qu?ck"" , content , true ) ; executeContainsQuery ( ""qu?cK"" , content , true ) ; executeContainsQuery ( ""q??ck"" , content , true ) ; executeContainsQuery ( ""?uic?"" , content , true ) ; executeContainsQuery ( ""??iCk"" , content , true ) ; executeContainsQuery ( ""*ab*"" , content , false ) ; executeContainsQuery ( ""q***j**c*k"" , content , false ) ; } public void testPredefinedEntityReference ( ) throws RepositoryException { String content = ""Max&Moritz"" ; executeContainsQuery ( ""max&moritz"" , content , true ) ; } public void testColonInContains ( ) throws RepositoryException { executeContainsQuery ( ""foo:bar"" , ""foo:bar"" , true ) ; } private void executeContainsQuery ( String statement , String content , boolean match ) throws RepositoryException { while ( testRootNode . hasNode ( nodeName1 ) ) { testRootNode . getNode ( nodeName1 ) . remove ( ) ; } testRootNode . addNode ( nodeName1 ) . setProperty ( ""text"" , content ) ; testRootNode . save ( ) ; assertContainsQuery ( statement , match ) ; } public void testFileContains ( ) throws Exception { assertFileContains ( ""test.txt"" , ""text/plain"" , ""AE502DBEA2C411DEBD340AD156D89593"" ) ; assertFileContains ( ""test.rtf"" , ""text/rtf"" , ""quick brown fox"" ) ; } private void assertFileContains ( String name , String type , String ... statements ) throws Exception { while ( testRootNode . hasNode ( nodeName1 ) ) { testRootNode . getNode ( nodeName1 ) . remove ( ) ; } Node resource = testRootNode . addNode ( nodeName1 , NodeType . NT_RESOURCE ) ; resource . setProperty ( ""jcr:mimeType"" , type ) ; InputStream stream = FulltextQueryTest . class . getResourceAsStream ( name ) ; try { resource . setProperty ( ""jcr:data"" , stream ) ; } finally { stream . close ( ) ; } testRootNode . save ( ) ; getSearchIndex ( ) . flush ( ) ; for ( String statement : statements ) { assertContainsQuery ( statement , true ) ; } } private void assertContainsQuery ( String statement , boolean match ) throws InvalidQueryException , RepositoryException { StringBuffer stmt = new StringBuffer ( ) ; stmt . append ( ""/jcr:root"" ) . append ( testRoot ) . append ( ""/*"" ) ; stmt . append ( ""[jcr:contains(., '"" ) . append ( statement ) ; stmt . append ( ""')]"" ) ; Query q = superuser . getWorkspace ( ) . getQueryManager ( ) . createQuery ( stmt . toString ( ) , Query . XPATH ) ; checkResult ( q . execute ( ) , match ? 1 : 0 ) ; stmt = new StringBuffer ( ) ; stmt . append ( ""SELECT * FROM nt:base "" ) ; stmt . append ( ""WHERE jcr:path LIKE '"" ) . append ( testRoot ) . append ( ""/%' "" ) ; stmt . append ( ""AND CONTAINS(., '"" ) . append ( statement ) . append ( ""')"" ) ; q = superuser . getWorkspace ( ) . getQueryManager ( ) . createQuery ( stmt . toString ( ) , Query . SQL ) ; checkResult ( q . execute ( ) , match ? 1 : 0 ) ; } }",Smelly
" private static class TimestampTreeReader extends TreeReader { private IntegerReader data = null ; private IntegerReader nanos = null ; private final LongColumnVector nanoVector = new LongColumnVector ( ) ; TimestampTreeReader ( Path path , int columnId , Configuration conf ) { super ( path , columnId , conf ) ; } @ Override void checkEncoding ( OrcProto . ColumnEncoding encoding ) throws IOException { if ( ( encoding . getKind ( ) != OrcProto . ColumnEncoding . Kind . DIRECT ) && ( encoding . getKind ( ) != OrcProto . ColumnEncoding . Kind . DIRECT_V2 ) ) { throw new IOException ( ""Unknown encoding "" + encoding + "" in column "" + columnId + "" of "" + path ) ; } } @ Override void startStripe ( Map < StreamName , InStream > streams , List < OrcProto . ColumnEncoding > encodings ) throws IOException { super . startStripe ( streams , encodings ) ; data = createIntegerReader ( encodings . get ( columnId ) . getKind ( ) , streams . get ( new StreamName ( columnId , OrcProto . Stream . Kind . DATA ) ) , true ) ; nanos = createIntegerReader ( encodings . get ( columnId ) . getKind ( ) , streams . get ( new StreamName ( columnId , OrcProto . Stream . Kind . SECONDARY ) ) , false ) ; } @ Override void seek ( PositionProvider [ ] index ) throws IOException { super . seek ( index ) ; data . seek ( index [ columnId ] ) ; nanos . seek ( index [ columnId ] ) ; } @ Override Object next ( Object previous ) throws IOException { super . next ( previous ) ; TimestampWritable result = null ; if ( valuePresent ) { if ( previous == null ) { result = new TimestampWritable ( ) ; } else { result = ( TimestampWritable ) previous ; } Timestamp ts = new Timestamp ( 0 ) ; long millis = ( data . next ( ) + WriterImpl . BASE_TIMESTAMP ) * WriterImpl . MILLIS_PER_SECOND ; int newNanos = parseNanos ( nanos . next ( ) ) ; if ( millis >= 0 ) { millis += newNanos / 1000000 ; } else { millis -= newNanos / 1000000 ; } ts . setTime ( millis ) ; ts . setNanos ( newNanos ) ; result . set ( ts ) ; } return result ; } @ Override Object nextVector ( Object previousVector , long batchSize ) throws IOException { LongColumnVector result = null ; if ( previousVector == null ) { result = new LongColumnVector ( ) ; } else { result = ( LongColumnVector ) previousVector ; } super . nextVector ( result , batchSize ) ; data . nextVector ( result , batchSize ) ; nanoVector . isNull = result . isNull ; nanos . nextVector ( nanoVector , batchSize ) ; if ( result . isRepeating && nanoVector . isRepeating ) { batchSize = 1 ; } for ( int i = 0 ; i < batchSize ; i ++ ) { if ( ! result . isNull [ i ] ) { long ms = ( result . vector [ result . isRepeating ? 0 : i ] + WriterImpl . BASE_TIMESTAMP ) * WriterImpl . MILLIS_PER_SECOND ; long ns = parseNanos ( nanoVector . vector [ nanoVector . isRepeating ? 0 : i ] ) ; if ( ms < 0 && ns != 0 ) { ms -= 1000 ; } result . vector [ i ] = ( ms * 1000000 ) + ns ; } } if ( ! ( result . isRepeating && nanoVector . isRepeating ) ) { result . isRepeating = false ; } return result ; } private static int parseNanos ( long serialized ) { int zeros = 7 & ( int ) serialized ; int result = ( int ) ( serialized > > > 3 ) ; if ( zeros != 0 ) { for ( int i = 0 ; i <= zeros ; ++ i ) { result *= 10 ; } } return result ; } @ Override void skipRows ( long items ) throws IOException { items = countNonNulls ( items ) ; data . skip ( items ) ; nanos . skip ( items ) ; } ",No
"public final class CarbonProperties { private static final Logger LOGGER = LogServiceFactory . getLogService ( CarbonProperties . class . getName ( ) ) ; private static final CarbonProperties CARBONPROPERTIESINSTANCE = new CarbonProperties ( ) ; private Properties carbonProperties ; private Set < String > propertySet = new HashSet < String > ( ) ; private Map < String , String > addedProperty = new ConcurrentHashMap < > ( ) ; private CarbonProperties ( ) { carbonProperties = new Properties ( ) ; loadProperties ( ) ; validateAndLoadDefaultProperties ( ) ; } public static CarbonProperties getInstance ( ) { return CARBONPROPERTIESINSTANCE ; } private void validateAndLoadDefaultProperties ( String key ) { switch ( key ) { case BLOCKLET_SIZE : validateBlockletSize ( ) ; break ; case SORT_SIZE : validateSortSize ( ) ; break ; case CARBON_DATA_FILE_VERSION : validateCarbonDataFileVersion ( ) ; break ; case CARBON_DYNAMIC_ALLOCATION_SCHEDULER_TIMEOUT : validateDynamicSchedulerTimeOut ( ) ; break ; case CARBON_PREFETCH_BUFFERSIZE : validatePrefetchBufferSize ( ) ; break ; case BLOCKLET_SIZE_IN_MB : validateBlockletGroupSizeInMB ( ) ; break ; case NUMBER_OF_COLUMN_TO_READ_IN_IO : validateNumberOfColumnPerIORead ( ) ; break ; case ENABLE_UNSAFE_SORT : validateEnableUnsafeSort ( ) ; break ; case ENABLE_OFFHEAP_SORT : validateEnableOffHeapSort ( ) ; break ; case CARBON_CUSTOM_BLOCK_DISTRIBUTION : validateCustomBlockDistribution ( ) ; break ; case ENABLE_VECTOR_READER : validateEnableVectorReader ( ) ; break ; case CSV_READ_BUFFER_SIZE : validateCarbonCSVReadBufferSizeByte ( ) ; break ; case HANDOFF_SIZE : validateHandoffSize ( ) ; break ; case CARBON_TASK_DISTRIBUTION : validateCarbonTaskDistribution ( ) ; break ; case CARBON_TIMESTAMP_FORMAT : validateTimeFormatKey ( CARBON_TIMESTAMP_FORMAT , CarbonCommonConstants . CARBON_TIMESTAMP_DEFAULT_FORMAT ) ; break ; case CARBON_DATE_FORMAT : validateTimeFormatKey ( CARBON_DATE_FORMAT , CarbonCommonConstants . CARBON_DATE_DEFAULT_FORMAT ) ; break ; case CARBON_SORT_FILE_WRITE_BUFFER_SIZE : validateSortFileWriteBufferSize ( ) ; break ; case SORT_INTERMEDIATE_FILES_LIMIT : validateSortIntermediateFilesLimit ( ) ; break ; case ENABLE_AUTO_HANDOFF : validateHandoffSize ( ) ; break ; case CARBON_SCHEDULER_MIN_REGISTERED_RESOURCES_RATIO : validateSchedulerMinRegisteredRatio ( ) ; break ; case CARBON_LOAD_SORT_MEMORY_SPILL_PERCENTAGE : validateSortMemorySpillPercentage ( ) ; break ; case CARBON_MINMAX_ALLOWED_BYTE_COUNT : validateStringCharacterLimit ( ) ; break ; case DETAIL_QUERY_BATCH_SIZE : validateDetailQueryBatchSize ( ) ; break ; case CarbonCommonConstants . CARBON_INDEX_SERVER_SERIALIZATION_THRESHOLD : validateIndexServerSerializationThreshold ( ) ; break ; case CarbonCommonConstants . CARBON_LOCAL_DICTIONARY_SIZE_THRESHOLD_IN_MB : validateAndGetLocalDictionarySizeThresholdInMB ( ) ; break ; case CarbonCommonConstants . CARBON_INDEX_SCHEMA_STORAGE : validateDMSchemaStorageProvider ( ) ; break ; default : } } private void validatePositiveInteger ( String propertyName ) { String value = getInstance ( ) . getProperty ( propertyName ) ; try { int intValue = Integer . parseInt ( value ) ; if ( intValue <= 0 ) { getInstance ( ) . removeProperty ( propertyName ) ; LOGGER . warn ( String . format ( ""The value \""%s\"" configured for key \""%s\"" "" + ""is invalid. Ignoring it"" , value , propertyName ) ) ; throw new IllegalArgumentException ( ) ; } } catch ( NumberFormatException e ) { getInstance ( ) . removeProperty ( propertyName ) ; LOGGER . warn ( String . format ( ""The value \""%s\"" configured for key \""%s\"" "" + ""is invalid. Ignoring it"" , value , propertyName ) ) ; throw e ; } } private void validateAndLoadDefaultProperties ( ) { validateBlockletSize ( ) ; validateSortSize ( ) ; validateCarbonDataFileVersion ( ) ; validateDynamicSchedulerTimeOut ( ) ; validatePrefetchBufferSize ( ) ; validateBlockletGroupSizeInMB ( ) ; validateNumberOfColumnPerIORead ( ) ; validateEnableUnsafeSort ( ) ; validateEnableOffHeapSort ( ) ; validateCustomBlockDistribution ( ) ; validateEnableVectorReader ( ) ; validateLockType ( ) ; validateCarbonCSVReadBufferSizeByte ( ) ; validateHandoffSize ( ) ; validateCarbonTaskDistribution ( ) ; validateTimeFormatKey ( CARBON_TIMESTAMP_FORMAT , CarbonCommonConstants . CARBON_TIMESTAMP_DEFAULT_FORMAT ) ; validateTimeFormatKey ( CARBON_DATE_FORMAT , CarbonCommonConstants . CARBON_DATE_DEFAULT_FORMAT ) ; validateSortFileWriteBufferSize ( ) ; validateSortIntermediateFilesLimit ( ) ; validateEnableAutoHandoff ( ) ; validateSchedulerMinRegisteredRatio ( ) ; validateWorkingMemory ( ) ; validateSortStorageMemory ( ) ; validateEnableQueryStatistics ( ) ; validateSortMemorySpillPercentage ( ) ; validateStringCharacterLimit ( ) ; validateDetailQueryBatchSize ( ) ; validateIndexServerSerializationThreshold ( ) ; validateAndGetLocalDictionarySizeThresholdInMB ( ) ; } private void validateSortIntermediateFilesLimit ( ) { validateRange ( SORT_INTERMEDIATE_FILES_LIMIT , CarbonCommonConstants . SORT_INTERMEDIATE_FILES_LIMIT_DEFAULT_VALUE , CarbonCommonConstants . SORT_INTERMEDIATE_FILES_LIMIT_MIN , CarbonCommonConstants . SORT_INTERMEDIATE_FILES_LIMIT_MAX ) ; } private void validateRange ( String key , String defaultValue , int minValue , int maxValue ) { String fileBufferSize = carbonProperties . getProperty ( key , defaultValue ) ; if ( null != fileBufferSize ) { try { int bufferSize = Integer . parseInt ( fileBufferSize ) ; if ( bufferSize < minValue || bufferSize > maxValue ) { LOGGER . warn ( ""The value \"""" + fileBufferSize + ""\"" configured for key "" + key + ""\"" is not in range. Valid range is (byte) \"""" + minValue + "" to \"""" + maxValue + "". Using the default value \"""" + defaultValue ) ; carbonProperties . setProperty ( key , defaultValue ) ; } } catch ( NumberFormatException nfe ) { LOGGER . warn ( ""The value \"""" + fileBufferSize + ""\"" configured for key "" + key + ""\"" is invalid. Using the default value \"""" + defaultValue ) ; carbonProperties . setProperty ( key , defaultValue ) ; } } } private void validateSortFileWriteBufferSize ( ) { validateRange ( CARBON_SORT_FILE_WRITE_BUFFER_SIZE , CarbonCommonConstants . CARBON_SORT_FILE_WRITE_BUFFER_SIZE_DEFAULT_VALUE , CarbonCommonConstants . CARBON_SORT_FILE_WRITE_BUFFER_SIZE_MIN , CarbonCommonConstants . CARBON_SORT_FILE_WRITE_BUFFER_SIZE_MAX ) ; } private void validateSchedulerMinRegisteredRatio ( ) { String value = carbonProperties . getProperty ( CARBON_SCHEDULER_MIN_REGISTERED_RESOURCES_RATIO , CARBON_SCHEDULER_MIN_REGISTERED_RESOURCES_RATIO_DEFAULT ) ; try { double minRegisteredResourceRatio = java . lang . Double . parseDouble ( value ) ; if ( minRegisteredResourceRatio < CARBON_SCHEDULER_MIN_REGISTERED_RESOURCES_RATIO_MIN || minRegisteredResourceRatio > CARBON_SCHEDULER_MIN_REGISTERED_RESOURCES_RATIO_MAX ) { LOGGER . warn ( ""The value \"""" + value + ""\"" configured for key "" + CARBON_SCHEDULER_MIN_REGISTERED_RESOURCES_RATIO + ""\"" is not in range. Valid range is (byte) \"""" + CARBON_SCHEDULER_MIN_REGISTERED_RESOURCES_RATIO_MIN + "" to \"""" + CARBON_SCHEDULER_MIN_REGISTERED_RESOURCES_RATIO_MAX + "". Using the default value \"""" + CARBON_SCHEDULER_MIN_REGISTERED_RESOURCES_RATIO_DEFAULT ) ; carbonProperties . setProperty ( CARBON_SCHEDULER_MIN_REGISTERED_RESOURCES_RATIO , CARBON_SCHEDULER_MIN_REGISTERED_RESOURCES_RATIO_DEFAULT ) ; } } catch ( NumberFormatException e ) { LOGGER . warn ( String . format ( ""The value \""%s\"" configured for key  \""%s\"" is invalid. "" + ""Using the default value \""%s\"""" , value , CARBON_SCHEDULER_MIN_REGISTERED_RESOURCES_RATIO , CARBON_SCHEDULER_MIN_REGISTERED_RESOURCES_RATIO_DEFAULT ) ) ; carbonProperties . setProperty ( CARBON_SCHEDULER_MIN_REGISTERED_RESOURCES_RATIO , CARBON_SCHEDULER_MIN_REGISTERED_RESOURCES_RATIO_DEFAULT ) ; } } private void validateTimeFormatKey ( String key , String defaultValue ) { String dateFormat = carbonProperties . getProperty ( key , defaultValue ) ; try { new SimpleDateFormat ( dateFormat ) ; } catch ( Exception e ) { LOGGER . warn ( String . format ( ""The value \""%s\"" configured for key \""%s\"" is invalid. "" + ""Using the default value \""%s\"""" , dateFormat , key , key ) ) ; carbonProperties . setProperty ( key , defaultValue ) ; } } private void validateCarbonCSVReadBufferSizeByte ( ) { validateRange ( CSV_READ_BUFFER_SIZE , CarbonCommonConstants . CSV_READ_BUFFER_SIZE_DEFAULT , CarbonCommonConstants . CSV_READ_BUFFER_SIZE_MIN , CarbonCommonConstants . CSV_READ_BUFFER_SIZE_MAX ) ; } private void validateLockType ( ) { String lockTypeConfigured = carbonProperties . getProperty ( LOCK_TYPE , CarbonCommonConstants . LOCK_TYPE_DEFAULT ) ; if ( lockTypeConfigured != null ) { switch ( lockTypeConfigured . toUpperCase ( ) ) { case CarbonCommonConstants . CARBON_LOCK_TYPE_ZOOKEEPER : break ; case CarbonCommonConstants . CARBON_LOCK_TYPE_CUSTOM : break ; case CarbonCommonConstants . CARBON_LOCK_TYPE_LOCAL : case CarbonCommonConstants . CARBON_LOCK_TYPE_HDFS : default : validateAndConfigureLockType ( lockTypeConfigured ) ; } } else { validateAndConfigureLockType ( null ) ; } } private void validateAndConfigureLockType ( String lockTypeConfigured ) { String lockTypeByFS = null ; Configuration configuration = FileFactory . getConfiguration ( ) ; String defaultFs = configuration . get ( ""fs.defaultFS"" ) ; if ( null != defaultFs && ( defaultFs . startsWith ( CarbonCommonConstants . HDFSURL_PREFIX ) || defaultFs . startsWith ( CarbonCommonConstants . VIEWFSURL_PREFIX ) || defaultFs . startsWith ( CarbonCommonConstants . ALLUXIOURL_PREFIX ) || defaultFs . startsWith ( CarbonCommonConstants . S3A_PREFIX ) ) ) { lockTypeByFS = CarbonCommonConstants . CARBON_LOCK_TYPE_HDFS ; } else if ( null != defaultFs && defaultFs . startsWith ( CarbonCommonConstants . LOCAL_FILE_PREFIX ) ) { lockTypeByFS = CarbonCommonConstants . CARBON_LOCK_TYPE_LOCAL ; } if ( lockTypeByFS != null && lockTypeConfigured != null && ! lockTypeConfigured . equalsIgnoreCase ( lockTypeByFS ) ) { LOGGER . warn ( ""The value \"""" + lockTypeConfigured + ""\"" configured for key "" + LOCK_TYPE + "" is invalid for current file system. "" + ""Use the default value "" + lockTypeByFS + "" instead."" ) ; } if ( lockTypeByFS != null ) { carbonProperties . setProperty ( LOCK_TYPE , lockTypeByFS ) ; } else { carbonProperties . setProperty ( LOCK_TYPE , CarbonCommonConstants . CARBON_LOCK_TYPE_LOCAL ) ; } } private void validateEnableVectorReader ( ) { String vectorReaderStr = carbonProperties . getProperty ( ENABLE_VECTOR_READER ) ; if ( vectorReaderStr == null ) { carbonProperties . setProperty ( CarbonCommonConstants . ENABLE_VECTOR_READER , CarbonCommonConstants . ENABLE_VECTOR_READER_DEFAULT ) ; vectorReaderStr = carbonProperties . getProperty ( CarbonCommonConstants . ENABLE_VECTOR_READER ) ; } boolean isValidBooleanValue = CarbonUtil . validateBoolean ( vectorReaderStr ) ; if ( ! isValidBooleanValue ) { LOGGER . warn ( String . format ( ""The enable vector reader value \""%s\"" is invalid. "" + ""Using the default value \""%s\"""" , vectorReaderStr , CarbonCommonConstants . ENABLE_VECTOR_READER_DEFAULT ) ) ; carbonProperties . setProperty ( ENABLE_VECTOR_READER , CarbonCommonConstants . ENABLE_VECTOR_READER_DEFAULT ) ; } } private void validateCustomBlockDistribution ( ) { String customBlockDistributionStr = carbonProperties . getProperty ( CARBON_CUSTOM_BLOCK_DISTRIBUTION ) ; if ( customBlockDistributionStr == null ) { carbonProperties . setProperty ( CarbonCommonConstants . CARBON_CUSTOM_BLOCK_DISTRIBUTION , CarbonCommonConstants . CARBON_CUSTOM_BLOCK_DISTRIBUTION_DEFAULT ) ; customBlockDistributionStr = carbonProperties . getProperty ( CarbonCommonConstants . CARBON_CUSTOM_BLOCK_DISTRIBUTION ) ; } boolean isValidBooleanValue = CarbonUtil . validateBoolean ( customBlockDistributionStr ) ; if ( ! isValidBooleanValue ) { LOGGER . warn ( String . format ( ""The custom block distribution value \""%s\"" is invalid. "" + ""Using the default value \""false\"""" , customBlockDistributionStr ) ) ; carbonProperties . setProperty ( CARBON_CUSTOM_BLOCK_DISTRIBUTION , ""false"" ) ; } } private void validateCarbonTaskDistribution ( ) { String carbonTaskDistribution = carbonProperties . getProperty ( CARBON_TASK_DISTRIBUTION ) ; if ( carbonTaskDistribution == null ) { carbonProperties . setProperty ( CARBON_TASK_DISTRIBUTION , CarbonCommonConstants . CARBON_TASK_DISTRIBUTION_DEFAULT ) ; carbonTaskDistribution = carbonProperties . getProperty ( CARBON_TASK_DISTRIBUTION ) ; } boolean isValid = carbonTaskDistribution . equalsIgnoreCase ( CARBON_TASK_DISTRIBUTION_MERGE_FILES ) || carbonTaskDistribution . equalsIgnoreCase ( CARBON_TASK_DISTRIBUTION_BLOCKLET ) || carbonTaskDistribution . equalsIgnoreCase ( CARBON_TASK_DISTRIBUTION_BLOCK ) || carbonTaskDistribution . equalsIgnoreCase ( CARBON_TASK_DISTRIBUTION_CUSTOM ) ; if ( ! isValid ) { LOGGER . warn ( String . format ( ""The carbon task distribution value \""%s\"" is invalid. "" + ""Using the default value \""%s\"""" , carbonTaskDistribution , CarbonCommonConstants . CARBON_TASK_DISTRIBUTION_DEFAULT ) ) ; carbonProperties . setProperty ( CARBON_TASK_DISTRIBUTION , CarbonCommonConstants . CARBON_TASK_DISTRIBUTION_DEFAULT ) ; } } private void validateEnableUnsafeSort ( ) { String unSafeSortStr = carbonProperties . getProperty ( ENABLE_UNSAFE_SORT ) ; if ( unSafeSortStr == null ) { carbonProperties . setProperty ( CarbonCommonConstants . ENABLE_UNSAFE_SORT , CarbonCommonConstants . ENABLE_UNSAFE_SORT_DEFAULT ) ; unSafeSortStr = carbonProperties . getProperty ( CarbonCommonConstants . ENABLE_UNSAFE_SORT ) ; } boolean isValidBooleanValue = CarbonUtil . validateBoolean ( unSafeSortStr ) ; if ( ! isValidBooleanValue ) { LOGGER . warn ( String . format ( ""The enable unsafe sort value \""%s\"" is invalid. "" + ""Using the default value \""%s\"""" , unSafeSortStr , CarbonCommonConstants . ENABLE_UNSAFE_SORT_DEFAULT ) ) ; carbonProperties . setProperty ( ENABLE_UNSAFE_SORT , CarbonCommonConstants . ENABLE_UNSAFE_SORT_DEFAULT ) ; } } private void validateEnableOffHeapSort ( ) { String offHeapSortStr = carbonProperties . getProperty ( CarbonCommonConstants . ENABLE_OFFHEAP_SORT ) ; if ( offHeapSortStr == null ) { carbonProperties . setProperty ( CarbonCommonConstants . ENABLE_OFFHEAP_SORT , CarbonCommonConstants . ENABLE_OFFHEAP_SORT_DEFAULT ) ; offHeapSortStr = carbonProperties . getProperty ( CarbonCommonConstants . ENABLE_OFFHEAP_SORT ) ; } boolean isValidBooleanValue = CarbonUtil . validateBoolean ( offHeapSortStr ) ; if ( ! isValidBooleanValue ) { LOGGER . warn ( String . format ( ""The enable off heap sort value \""%s\"" is invalid. "" + ""Using the default value \""%s\"""" , offHeapSortStr , CarbonCommonConstants . ENABLE_OFFHEAP_SORT_DEFAULT ) ) ; carbonProperties . setProperty ( ENABLE_OFFHEAP_SORT , CarbonCommonConstants . ENABLE_OFFHEAP_SORT_DEFAULT ) ; } } private void initPropertySet ( ) throws IllegalAccessException { Field [ ] declaredFields = CarbonCommonConstants . class . getDeclaredFields ( ) ; for ( Field field : declaredFields ) { if ( field . isAnnotationPresent ( CarbonProperty . class ) ) { propertySet . add ( field . get ( field . getName ( ) ) . toString ( ) ) ; } } declaredFields = CarbonV3DataFormatConstants . class . getDeclaredFields ( ) ; for ( Field field : declaredFields ) { if ( field . isAnnotationPresent ( CarbonProperty . class ) ) { propertySet . add ( field . get ( field . getName ( ) ) . toString ( ) ) ; } } declaredFields = CarbonLoadOptionConstants . class . getDeclaredFields ( ) ; for ( Field field : declaredFields ) { if ( field . isAnnotationPresent ( CarbonProperty . class ) ) { propertySet . add ( field . get ( field . getName ( ) ) . toString ( ) ) ; } } } private void validatePrefetchBufferSize ( ) { String prefetchBufferSizeStr = carbonProperties . getProperty ( CARBON_PREFETCH_BUFFERSIZE ) ; if ( null == prefetchBufferSizeStr || prefetchBufferSizeStr . length ( ) == 0 ) { carbonProperties . setProperty ( CARBON_PREFETCH_BUFFERSIZE , CarbonCommonConstants . CARBON_PREFETCH_BUFFERSIZE_DEFAULT ) ; } else { try { Integer . parseInt ( prefetchBufferSizeStr ) ; } catch ( NumberFormatException e ) { LOGGER . info ( ""The prefetch buffer size value \"""" + prefetchBufferSizeStr + ""\"" is invalid. Using the default value \"""" + CarbonCommonConstants . CARBON_PREFETCH_BUFFERSIZE_DEFAULT + ""\"""" ) ; carbonProperties . setProperty ( CARBON_PREFETCH_BUFFERSIZE , CarbonCommonConstants . CARBON_PREFETCH_BUFFERSIZE_DEFAULT ) ; } } } private void validateHandoffSize ( ) { String handoffSizeStr = carbonProperties . getProperty ( HANDOFF_SIZE ) ; if ( null == handoffSizeStr || handoffSizeStr . length ( ) == 0 ) { carbonProperties . setProperty ( HANDOFF_SIZE , """" + CarbonCommonConstants . HANDOFF_SIZE_DEFAULT ) ; } else { try { long handoffSize = Long . parseLong ( handoffSizeStr ) ; if ( handoffSize < CarbonCommonConstants . HANDOFF_SIZE_MIN ) { LOGGER . info ( ""The streaming segment max size configured value "" + handoffSizeStr + "" is invalid. Using the default value "" + CarbonCommonConstants . HANDOFF_SIZE_DEFAULT ) ; carbonProperties . setProperty ( HANDOFF_SIZE , """" + CarbonCommonConstants . HANDOFF_SIZE_DEFAULT ) ; } } catch ( NumberFormatException e ) { LOGGER . info ( ""The streaming segment max size value \"""" + handoffSizeStr + ""\"" is invalid. Using the default value \"""" + CarbonCommonConstants . HANDOFF_SIZE_DEFAULT + ""\"""" ) ; carbonProperties . setProperty ( HANDOFF_SIZE , """" + CarbonCommonConstants . HANDOFF_SIZE_DEFAULT ) ; } } } private void validateEnableAutoHandoff ( ) { String offHeapSortStr = carbonProperties . getProperty ( CarbonCommonConstants . ENABLE_OFFHEAP_SORT ) ; if ( offHeapSortStr == null ) { carbonProperties . setProperty ( CarbonCommonConstants . ENABLE_OFFHEAP_SORT , CarbonCommonConstants . ENABLE_OFFHEAP_SORT_DEFAULT ) ; offHeapSortStr = carbonProperties . getProperty ( CarbonCommonConstants . ENABLE_OFFHEAP_SORT ) ; } boolean isValidBooleanValue = CarbonUtil . validateBoolean ( offHeapSortStr ) ; if ( ! isValidBooleanValue ) { LOGGER . warn ( String . format ( ""The enable off heap sort value \""%s\"" is invalid. "" + ""Using the default value \""%s\"""" , offHeapSortStr , CarbonCommonConstants . ENABLE_OFFHEAP_SORT_DEFAULT ) ) ; carbonProperties . setProperty ( ENABLE_OFFHEAP_SORT , CarbonCommonConstants . ENABLE_OFFHEAP_SORT_DEFAULT ) ; } } public boolean isIndexParallelLoadingEnabled ( String databaseName , String tableName ) { String loadIndexParallel = getSessionPropertyValue ( CarbonCommonConstants . CARBON_LOAD_INDEXES_PARALLEL + databaseName + ""."" + tableName ) ; if ( loadIndexParallel == null ) { loadIndexParallel = getProperty ( CarbonCommonConstants . CARBON_LOAD_INDEXES_PARALLEL , CarbonCommonConstants . CARBON_LOAD_INDEXES_PARALLEL_DEFAULT ) ; } boolean configuredValue = Boolean . parseBoolean ( loadIndexParallel ) ; if ( configuredValue ) { LOGGER . info ( ""Loading indexes in parallel for "" + databaseName + ""."" + tableName ) ; } return configuredValue ; } private void validateBlockletGroupSizeInMB ( ) { String numberOfPagePerBlockletColumnString = carbonProperties . getProperty ( BLOCKLET_SIZE_IN_MB , CarbonV3DataFormatConstants . BLOCKLET_SIZE_IN_MB_DEFAULT_VALUE ) ; try { short numberOfPagePerBlockletColumn = Short . parseShort ( numberOfPagePerBlockletColumnString ) ; if ( numberOfPagePerBlockletColumn < CarbonV3DataFormatConstants . BLOCKLET_SIZE_IN_MB_MIN ) { LOGGER . info ( String . format ( ""Blocklet Size Configured value \""%s\"" is invalid. "" + ""Using the default value \""%s\"""" , numberOfPagePerBlockletColumnString , CarbonV3DataFormatConstants . BLOCKLET_SIZE_IN_MB_DEFAULT_VALUE ) ) ; carbonProperties . setProperty ( BLOCKLET_SIZE_IN_MB , CarbonV3DataFormatConstants . BLOCKLET_SIZE_IN_MB_DEFAULT_VALUE ) ; } } catch ( NumberFormatException e ) { LOGGER . info ( String . format ( ""Blocklet Size Configured value \""%s\"" is invalid. "" + ""Using the default value \""%s\"""" , numberOfPagePerBlockletColumnString , CarbonV3DataFormatConstants . BLOCKLET_SIZE_IN_MB_DEFAULT_VALUE ) ) ; carbonProperties . setProperty ( BLOCKLET_SIZE_IN_MB , CarbonV3DataFormatConstants . BLOCKLET_SIZE_IN_MB_DEFAULT_VALUE ) ; } LOGGER . info ( String . format ( ""Blocklet Size Configured value is \""%s\"""" , carbonProperties . getProperty ( BLOCKLET_SIZE_IN_MB , CarbonV3DataFormatConstants . BLOCKLET_SIZE_IN_MB_DEFAULT_VALUE ) ) ) ; } private void validateNumberOfColumnPerIORead ( ) { String numberOfColumnPerIOString = carbonProperties . getProperty ( NUMBER_OF_COLUMN_TO_READ_IN_IO , CarbonV3DataFormatConstants . NUMBER_OF_COLUMN_TO_READ_IN_IO_DEFAULTVALUE ) ; try { short numberOfColumnPerIO = Short . parseShort ( numberOfColumnPerIOString ) ; if ( numberOfColumnPerIO < CarbonV3DataFormatConstants . NUMBER_OF_COLUMN_TO_READ_IN_IO_MIN || numberOfColumnPerIO > CarbonV3DataFormatConstants . NUMBER_OF_COLUMN_TO_READ_IN_IO_MAX ) { LOGGER . info ( ""The Number Of pages per blocklet column value \"""" + numberOfColumnPerIOString + ""\"" is invalid. Using the default value \"""" + CarbonV3DataFormatConstants . NUMBER_OF_COLUMN_TO_READ_IN_IO_DEFAULTVALUE ) ; carbonProperties . setProperty ( NUMBER_OF_COLUMN_TO_READ_IN_IO , CarbonV3DataFormatConstants . NUMBER_OF_COLUMN_TO_READ_IN_IO_DEFAULTVALUE ) ; } } catch ( NumberFormatException e ) { LOGGER . info ( ""The Number Of pages per blocklet column value \"""" + numberOfColumnPerIOString + ""\"" is invalid. Using the default value \"""" + CarbonV3DataFormatConstants . NUMBER_OF_COLUMN_TO_READ_IN_IO_DEFAULTVALUE ) ; carbonProperties . setProperty ( NUMBER_OF_COLUMN_TO_READ_IN_IO , CarbonV3DataFormatConstants . NUMBER_OF_COLUMN_TO_READ_IN_IO_DEFAULTVALUE ) ; } } private void validateBlockletSize ( ) { String blockletSizeStr = carbonProperties . getProperty ( BLOCKLET_SIZE , CarbonCommonConstants . BLOCKLET_SIZE_DEFAULT_VAL ) ; try { int blockletSize = Integer . parseInt ( blockletSizeStr ) ; if ( blockletSize < CarbonCommonConstants . BLOCKLET_SIZE_MIN_VAL || blockletSize > CarbonCommonConstants . BLOCKLET_SIZE_MAX_VAL ) { LOGGER . info ( ""The blocklet size value \"""" + blockletSizeStr + ""\"" is invalid. Using the default value \"""" + CarbonCommonConstants . BLOCKLET_SIZE_DEFAULT_VAL ) ; carbonProperties . setProperty ( BLOCKLET_SIZE , CarbonCommonConstants . BLOCKLET_SIZE_DEFAULT_VAL ) ; } } catch ( NumberFormatException e ) { LOGGER . info ( ""The blocklet size value \"""" + blockletSizeStr + ""\"" is invalid. Using the default value \"""" + CarbonCommonConstants . BLOCKLET_SIZE_DEFAULT_VAL ) ; carbonProperties . setProperty ( BLOCKLET_SIZE , CarbonCommonConstants . BLOCKLET_SIZE_DEFAULT_VAL ) ; } } private void validateIndexServerSerializationThreshold ( ) { String serializationSizeString = carbonProperties . getProperty ( CarbonCommonConstants . CARBON_INDEX_SERVER_SERIALIZATION_THRESHOLD , CarbonCommonConstants . CARBON_INDEX_SERVER_SERIALIZATION_THRESHOLD_DEFAULT ) ; try { int serializationSize = Integer . parseInt ( serializationSizeString ) ; if ( serializationSize < CarbonCommonConstants . CARBON_INDEX_SERVER_SERIALIZATION_THRESHOLD_MIN || serializationSize > CarbonCommonConstants . CARBON_INDEX_SERVER_SERIALIZATION_THRESHOLD_MAX ) { LOGGER . info ( ""The "" + CarbonCommonConstants . CARBON_INDEX_SERVER_SERIALIZATION_THRESHOLD + "" value \"""" + serializationSize + ""\"" is invalid. Using the default value \"""" + CarbonCommonConstants . CARBON_INDEX_SERVER_SERIALIZATION_THRESHOLD_DEFAULT ) ; carbonProperties . setProperty ( CarbonCommonConstants . CARBON_INDEX_SERVER_SERIALIZATION_THRESHOLD , CarbonCommonConstants . CARBON_INDEX_SERVER_SERIALIZATION_THRESHOLD_DEFAULT ) ; } } catch ( NumberFormatException e ) { LOGGER . info ( ""The "" + CarbonCommonConstants . CARBON_INDEX_SERVER_SERIALIZATION_THRESHOLD + "" value \"""" + serializationSizeString + ""\"" is invalid. Using the default value \"""" + CarbonCommonConstants . CARBON_INDEX_SERVER_SERIALIZATION_THRESHOLD_DEFAULT ) ; carbonProperties . setProperty ( CarbonCommonConstants . CARBON_INDEX_SERVER_SERIALIZATION_THRESHOLD , CarbonCommonConstants . CARBON_INDEX_SERVER_SERIALIZATION_THRESHOLD_DEFAULT ) ; } } private void validateSortSize ( ) { String sortSizeStr = carbonProperties . getProperty ( SORT_SIZE , CarbonCommonConstants . SORT_SIZE_DEFAULT_VAL ) ; try { int sortSize = Integer . parseInt ( sortSizeStr ) ; if ( sortSize < CarbonCommonConstants . SORT_SIZE_MIN_VAL ) { LOGGER . info ( String . format ( ""The batch size value \""%s\"" is invalid. "" + ""Using the default value \""%s\"""" , sortSizeStr , CarbonCommonConstants . SORT_SIZE_DEFAULT_VAL ) ) ; carbonProperties . setProperty ( SORT_SIZE , CarbonCommonConstants . SORT_SIZE_DEFAULT_VAL ) ; } } catch ( NumberFormatException e ) { LOGGER . info ( String . format ( ""The batch size value \""%s\"" is invalid. "" + ""Using the default value \""%s\"""" , sortSizeStr , CarbonCommonConstants . SORT_SIZE_DEFAULT_VAL ) ) ; carbonProperties . setProperty ( SORT_SIZE , CarbonCommonConstants . SORT_SIZE_DEFAULT_VAL ) ; } } private void validateCarbonDataFileVersion ( ) { String carbondataFileVersionString = carbonProperties . getProperty ( CARBON_DATA_FILE_VERSION ) ; if ( carbondataFileVersionString == null ) { carbonProperties . setProperty ( CARBON_DATA_FILE_VERSION , CarbonCommonConstants . CARBON_DATA_FILE_DEFAULT_VERSION ) ; } else { try { carbonProperties . setProperty ( CARBON_DATA_FILE_VERSION , ColumnarFormatVersion . valueOf ( carbondataFileVersionString ) . name ( ) ) ; } catch ( IllegalArgumentException e ) { LOGGER . warn ( ""Specified file version property is invalid: "" + carbondataFileVersionString + "". Using "" + CarbonCommonConstants . CARBON_DATA_FILE_DEFAULT_VERSION + "" as default file version"" ) ; carbonProperties . setProperty ( CARBON_DATA_FILE_VERSION , CarbonCommonConstants . CARBON_DATA_FILE_DEFAULT_VERSION ) ; } } LOGGER . info ( ""Considered file format is: "" + carbonProperties . getProperty ( CARBON_DATA_FILE_VERSION ) ) ; } private void loadProperties ( ) { String propertyPath = System . getProperty ( CarbonCommonConstants . CARBON_PROPERTIES_FILE_PATH , CarbonCommonConstants . CARBON_PROPERTIES_FILE_PATH_DEFAULT ) ; File propertyFile = new File ( propertyPath ) ; LOGGER . info ( ""Property file path: "" + propertyFile . getAbsolutePath ( ) ) ; FileInputStream fis = null ; try { if ( propertyFile . exists ( ) ) { fis = new FileInputStream ( propertyFile ) ; carbonProperties . load ( fis ) ; } } catch ( FileNotFoundException e ) { LOGGER . error ( ""The file: "" + propertyFile . getAbsolutePath ( ) + "" does not exist"" ) ; } catch ( IOException e ) { LOGGER . error ( ""Error while reading the file: "" + propertyFile . getAbsolutePath ( ) ) ; } finally { if ( null != fis ) { try { fis . close ( ) ; } catch ( IOException e ) { LOGGER . error ( ""Error while closing the file stream for file: "" + propertyFile . getAbsolutePath ( ) ) ; } } } print ( ) ; try { initPropertySet ( ) ; } catch ( IllegalAccessException e ) { LOGGER . error ( ""Illegal access to declared field"" + e . getMessage ( ) , e ) ; } } public static String getStorePath ( ) { String storePath = getInstance ( ) . getProperty ( CarbonCommonConstants . STORE_LOCATION ) ; if ( storePath == null ) { storePath = FileFactory . getConfiguration ( ) . get ( ""hive.metastore.warehouse.dir"" ) ; } return storePath ; } public String getProperty ( String key ) { String sessionPropertyValue = getSessionPropertyValue ( key ) ; if ( null != sessionPropertyValue ) { return sessionPropertyValue ; } return carbonProperties . getProperty ( key ) ; } private String getSessionPropertyValue ( String key ) { String value = null ; CarbonSessionInfo carbonSessionInfo = ThreadLocalSessionInfo . getCarbonSessionInfo ( ) ; if ( null != carbonSessionInfo ) { SessionParams sessionParams = ThreadLocalSessionInfo . getCarbonSessionInfo ( ) . getSessionParams ( ) ; if ( null != sessionParams ) { value = sessionParams . getProperty ( key ) ; } } return value ; } public String getProperty ( String key , String defaultValue ) { String value = getProperty ( key ) ; if ( null == value ) { return defaultValue ; } return value ; } public CarbonProperties addProperty ( String key , String value ) { carbonProperties . setProperty ( key , value ) ; addedProperty . put ( key , value ) ; validateAndLoadDefaultProperties ( key . toLowerCase ( ) ) ; return this ; } public void addNonSerializableProperty ( String key , String value ) { carbonProperties . setProperty ( key , value ) ; } public CarbonProperties removeProperty ( String key ) { carbonProperties . remove ( key ) ; addedProperty . remove ( key ) ; return this ; } private ColumnarFormatVersion getDefaultFormatVersion ( ) { return ColumnarFormatVersion . valueOf ( CarbonCommonConstants . CARBON_DATA_FILE_DEFAULT_VERSION ) ; } public ColumnarFormatVersion getFormatVersion ( ) { String versionStr = getInstance ( ) . getProperty ( CARBON_DATA_FILE_VERSION ) ; if ( versionStr == null ) { return getDefaultFormatVersion ( ) ; } else { try { return ColumnarFormatVersion . valueOf ( versionStr ) ; } catch ( IllegalArgumentException e ) { return getDefaultFormatVersion ( ) ; } } } public long getMajorCompactionSize ( ) { long compactionSize ; try { compactionSize = Long . parseLong ( getProperty ( CarbonCommonConstants . CARBON_MAJOR_COMPACTION_SIZE , CarbonCommonConstants . DEFAULT_CARBON_MAJOR_COMPACTION_SIZE ) ) ; } catch ( NumberFormatException e ) { compactionSize = Long . parseLong ( CarbonCommonConstants . DEFAULT_CARBON_MAJOR_COMPACTION_SIZE ) ; } return compactionSize ; } public int getNumberOfSegmentsToBePreserved ( ) { int numberOfSegmentsToBePreserved ; try { numberOfSegmentsToBePreserved = Integer . parseInt ( getProperty ( CarbonCommonConstants . PRESERVE_LATEST_SEGMENTS_NUMBER , CarbonCommonConstants . DEFAULT_PRESERVE_LATEST_SEGMENTS_NUMBER ) ) ; if ( numberOfSegmentsToBePreserved < 0 || numberOfSegmentsToBePreserved > 100 ) { LOGGER . warn ( ""The specified value for property "" + CarbonCommonConstants . PRESERVE_LATEST_SEGMENTS_NUMBER + "" is incorrect."" + "" Correct value should be in range of 0 -100. Taking the default value."" ) ; numberOfSegmentsToBePreserved = Integer . parseInt ( CarbonCommonConstants . DEFAULT_PRESERVE_LATEST_SEGMENTS_NUMBER ) ; } } catch ( NumberFormatException e ) { numberOfSegmentsToBePreserved = Integer . parseInt ( CarbonCommonConstants . DEFAULT_PRESERVE_LATEST_SEGMENTS_NUMBER ) ; } return numberOfSegmentsToBePreserved ; } public void print ( ) { LOGGER . info ( ""------Using Carbon.properties --------"" ) ; LOGGER . info ( carbonProperties . toString ( ) ) ; } public int [ ] getCompactionSegmentLevelCount ( ) { String commaSeparatedLevels ; commaSeparatedLevels = getProperty ( CarbonCommonConstants . COMPACTION_SEGMENT_LEVEL_THRESHOLD , CarbonCommonConstants . DEFAULT_SEGMENT_LEVEL_THRESHOLD ) ; int [ ] compactionSize = getIntArray ( commaSeparatedLevels ) ; if ( 0 == compactionSize . length ) { compactionSize = getIntArray ( CarbonCommonConstants . DEFAULT_SEGMENT_LEVEL_THRESHOLD ) ; } return compactionSize ; } public int [ ] getIntArray ( String commaSeparatedLevels ) { String [ ] levels = commaSeparatedLevels . split ( "","" ) ; int [ ] compactionSize = new int [ levels . length ] ; int i = 0 ; for ( String levelSize : levels ) { try { int size = Integer . parseInt ( levelSize . trim ( ) ) ; if ( validate ( size , CarbonCommonConstants . NUMBER_OF_SEGMENT_COMPACTED_PERTIME_UPPER_LIMIT , CarbonCommonConstants . NUMBER_OF_SEGMENT_COMPACTED_PERTIME_LOWER_LIMIT , - 1 ) < 0 ) { LOGGER . warn ( ""Given value for property"" + size + "" is not proper. Taking the default value "" + CarbonCommonConstants . DEFAULT_SEGMENT_LEVEL_THRESHOLD ) ; return new int [ 0 ] ; } compactionSize [ i ++ ] = size ; } catch ( NumberFormatException e ) { LOGGER . warn ( ""Given value for property"" + CarbonCommonConstants . COMPACTION_SEGMENT_LEVEL_THRESHOLD + "" is not proper. Taking the default value "" + CarbonCommonConstants . DEFAULT_SEGMENT_LEVEL_THRESHOLD ) ; return new int [ 0 ] ; } } return compactionSize ; } private int getNumberOfCores ( String key ) { int numberOfCores ; try { numberOfCores = Integer . parseInt ( CarbonProperties . getInstance ( ) . getProperty ( key , CarbonCommonConstants . NUM_CORES_DEFAULT_VAL ) ) ; } catch ( NumberFormatException exc ) { LOGGER . warn ( ""Configured value for property "" + key + "" is wrong. Falling back to the default value "" + CarbonCommonConstants . NUM_CORES_DEFAULT_VAL ) ; numberOfCores = Integer . parseInt ( CarbonCommonConstants . NUM_CORES_DEFAULT_VAL ) ; } return numberOfCores ; } public int getNumberOfLoadingCores ( ) { return getNumberOfCores ( CarbonCommonConstants . NUM_CORES_LOADING ) ; } public int getNumberOfCompactingCores ( ) { return getNumberOfCores ( CarbonCommonConstants . NUM_CORES_COMPACTING ) ; } public int getNumberOfAltPartitionCores ( ) { return getNumberOfCores ( CarbonCommonConstants . NUM_CORES_ALT_PARTITION ) ; } public int getSortMemoryChunkSizeInMB ( ) { int inMemoryChunkSizeInMB ; try { inMemoryChunkSizeInMB = Integer . parseInt ( CarbonProperties . getInstance ( ) . getProperty ( CarbonCommonConstants . OFFHEAP_SORT_CHUNK_SIZE_IN_MB , CarbonCommonConstants . OFFHEAP_SORT_CHUNK_SIZE_IN_MB_DEFAULT ) ) ; } catch ( Exception e ) { inMemoryChunkSizeInMB = Integer . parseInt ( CarbonCommonConstants . OFFHEAP_SORT_CHUNK_SIZE_IN_MB_DEFAULT ) ; LOGGER . warn ( ""Problem in parsing the sort memory chunk size, setting with default value"" + inMemoryChunkSizeInMB ) ; } if ( inMemoryChunkSizeInMB > 1024 ) { inMemoryChunkSizeInMB = 1024 ; LOGGER . warn ( ""It is not recommended to increase the sort memory chunk size more than 1024MB, "" + ""so setting the value to "" + inMemoryChunkSizeInMB ) ; } else if ( inMemoryChunkSizeInMB < 1 ) { inMemoryChunkSizeInMB = 1 ; LOGGER . warn ( ""It is not recommended to decrease the sort memory chunk size less than 1MB, "" + ""so setting the value to "" + inMemoryChunkSizeInMB ) ; } return inMemoryChunkSizeInMB ; } public int getBatchSize ( ) { int batchSize ; try { batchSize = Integer . parseInt ( CarbonProperties . getInstance ( ) . getProperty ( CarbonCommonConstants . DATA_LOAD_BATCH_SIZE , CarbonCommonConstants . DATA_LOAD_BATCH_SIZE_DEFAULT ) ) ; } catch ( NumberFormatException exc ) { batchSize = Integer . parseInt ( CarbonCommonConstants . DATA_LOAD_BATCH_SIZE_DEFAULT ) ; } return batchSize ; } public static int getQueryBatchSize ( ) { int batchSize ; String batchSizeString = CarbonProperties . getInstance ( ) . getProperty ( CarbonCommonConstants . DETAIL_QUERY_BATCH_SIZE ) ; if ( null != batchSizeString ) { try { batchSize = Integer . parseInt ( batchSizeString ) ; } catch ( NumberFormatException ne ) { LOGGER . error ( ""Invalid inmemory records size. Using default value"" ) ; batchSize = CarbonCommonConstants . DETAIL_QUERY_BATCH_SIZE_DEFAULT ; } } else { batchSize = CarbonCommonConstants . DETAIL_QUERY_BATCH_SIZE_DEFAULT ; } return batchSize ; } public long getHandoffSize ( ) { Long handoffSize ; try { handoffSize = Long . parseLong ( CarbonProperties . getInstance ( ) . getProperty ( HANDOFF_SIZE , """" + CarbonCommonConstants . HANDOFF_SIZE_DEFAULT ) ) ; } catch ( NumberFormatException exc ) { handoffSize = CarbonCommonConstants . HANDOFF_SIZE_DEFAULT ; } return handoffSize ; } public boolean isEnableAutoHandoff ( ) { String enableAutoHandoffStr = CarbonProperties . getInstance ( ) . getProperty ( ENABLE_AUTO_HANDOFF , CarbonCommonConstants . ENABLE_AUTO_HANDOFF_DEFAULT ) ; return enableAutoHandoffStr . equalsIgnoreCase ( ""true"" ) ; } public boolean isEnableVectorReader ( ) { return getInstance ( ) . getProperty ( CarbonCommonConstants . ENABLE_VECTOR_READER , CarbonCommonConstants . ENABLE_VECTOR_READER_DEFAULT ) . equalsIgnoreCase ( ""true"" ) ; } public static boolean isEnableTableStatusBackup ( ) { return getInstance ( ) . getProperty ( CarbonCommonConstants . ENABLE_TABLE_STATUS_BACKUP , CarbonCommonConstants . ENABLE_TABLE_STATUS_BACKUP_DEFAULT ) . equalsIgnoreCase ( ""true"" ) ; } public int validate ( int actual , int max , int min , int defaultVal ) { if ( actual <= max && actual >= min ) { return actual ; } return defaultVal ; } private void validateDynamicSchedulerTimeOut ( ) { validateRange ( CARBON_DYNAMIC_ALLOCATION_SCHEDULER_TIMEOUT , CarbonCommonConstants . CARBON_DYNAMIC_ALLOCATION_SCHEDULER_TIMEOUT_DEFAULT , CarbonCommonConstants . CARBON_DYNAMIC_ALLOCATION_SCHEDULER_TIMEOUT_MIN , CarbonCommonConstants . CARBON_DYNAMIC_ALLOCATION_SCHEDULER_TIMEOUT_MAX ) ; } public int getNoUpdateDeltaFilesThresholdForIUDCompaction ( ) { int numberOfDeltaFilesThreshold ; try { numberOfDeltaFilesThreshold = Integer . parseInt ( getProperty ( CarbonCommonConstants . UPDATE_DELTAFILE_COUNT_THRESHOLD_IUD_COMPACTION , CarbonCommonConstants . DEFAULT_UPDATE_DELTAFILE_COUNT_THRESHOLD_IUD_COMPACTION ) ) ; if ( numberOfDeltaFilesThreshold < 0 || numberOfDeltaFilesThreshold > 10000 ) { LOGGER . warn ( ""The specified value for property "" + CarbonCommonConstants . UPDATE_DELTAFILE_COUNT_THRESHOLD_IUD_COMPACTION + ""is incorrect."" + "" Correct value should be in range of 0 -10000. Taking the default value."" ) ; numberOfDeltaFilesThreshold = Integer . parseInt ( CarbonCommonConstants . DEFAULT_UPDATE_DELTAFILE_COUNT_THRESHOLD_IUD_COMPACTION ) ; } } catch ( NumberFormatException e ) { LOGGER . warn ( ""The specified value for property "" + CarbonCommonConstants . UPDATE_DELTAFILE_COUNT_THRESHOLD_IUD_COMPACTION + ""is incorrect."" + "" Correct value should be in range of 0 -10000. Taking the default value."" ) ; numberOfDeltaFilesThreshold = Integer . parseInt ( CarbonCommonConstants . DEFAULT_UPDATE_DELTAFILE_COUNT_THRESHOLD_IUD_COMPACTION ) ; } return numberOfDeltaFilesThreshold ; } public int getNoDeleteDeltaFilesThresholdForIUDCompaction ( ) { int numberOfDeltaFilesThreshold ; try { numberOfDeltaFilesThreshold = Integer . parseInt ( getProperty ( CarbonCommonConstants . DELETE_DELTAFILE_COUNT_THRESHOLD_IUD_COMPACTION , CarbonCommonConstants . DEFAULT_DELETE_DELTAFILE_COUNT_THRESHOLD_IUD_COMPACTION ) ) ; if ( numberOfDeltaFilesThreshold < 0 || numberOfDeltaFilesThreshold > 10000 ) { LOGGER . warn ( ""The specified value for property "" + CarbonCommonConstants . DELETE_DELTAFILE_COUNT_THRESHOLD_IUD_COMPACTION + ""is incorrect."" + "" Correct value should be in range of 0 -10000. Taking the default value."" ) ; numberOfDeltaFilesThreshold = Integer . parseInt ( CarbonCommonConstants . DEFAULT_DELETE_DELTAFILE_COUNT_THRESHOLD_IUD_COMPACTION ) ; } } catch ( NumberFormatException e ) { LOGGER . warn ( ""The specified value for property "" + CarbonCommonConstants . DELETE_DELTAFILE_COUNT_THRESHOLD_IUD_COMPACTION + ""is incorrect."" + "" Correct value should be in range of 0 -10000. Taking the default value."" ) ; numberOfDeltaFilesThreshold = Integer . parseInt ( CarbonCommonConstants . DEFAULT_DELETE_DELTAFILE_COUNT_THRESHOLD_IUD_COMPACTION ) ; } return numberOfDeltaFilesThreshold ; } public String getGlobalSortRddStorageLevel ( ) { String storageLevel = getProperty ( CarbonCommonConstants . CARBON_GLOBAL_SORT_RDD_STORAGE_LEVEL , CarbonCommonConstants . CARBON_GLOBAL_SORT_RDD_STORAGE_LEVEL_DEFAULT ) ; boolean validateStorageLevel = CarbonUtil . isValidStorageLevel ( storageLevel ) ; if ( ! validateStorageLevel ) { LOGGER . warn ( ""The "" + CarbonCommonConstants . CARBON_GLOBAL_SORT_RDD_STORAGE_LEVEL + "" configuration value is invalid. It will use default storage level("" + CarbonCommonConstants . CARBON_GLOBAL_SORT_RDD_STORAGE_LEVEL_DEFAULT + "") to persist rdd."" ) ; storageLevel = CarbonCommonConstants . CARBON_GLOBAL_SORT_RDD_STORAGE_LEVEL_DEFAULT ; } return storageLevel . toUpperCase ( ) ; } public int getParallelismForSegmentUpdate ( ) { int parallelism = Integer . parseInt ( CarbonCommonConstants . CARBON_UPDATE_SEGMENT_PARALLELISM_DEFAULT ) ; boolean isInvalidValue = false ; try { String strParallelism = getProperty ( CarbonCommonConstants . CARBON_UPDATE_SEGMENT_PARALLELISM , CarbonCommonConstants . CARBON_UPDATE_SEGMENT_PARALLELISM_DEFAULT ) ; parallelism = Integer . parseInt ( strParallelism ) ; if ( parallelism <= 0 || parallelism > 1000 ) { isInvalidValue = true ; } } catch ( NumberFormatException e ) { isInvalidValue = true ; } if ( isInvalidValue ) { LOGGER . warn ( ""The specified value for property "" + CarbonCommonConstants . CARBON_UPDATE_SEGMENT_PARALLELISM + "" is incorrect. Correct value should be in range of 0 - 1000."" + "" Taking the default value: "" + CarbonCommonConstants . CARBON_UPDATE_SEGMENT_PARALLELISM_DEFAULT ) ; parallelism = Integer . parseInt ( CarbonCommonConstants . CARBON_UPDATE_SEGMENT_PARALLELISM_DEFAULT ) ; } return parallelism ; } public boolean isPersistUpdateDataset ( ) { String isPersistEnabled = getProperty ( CarbonCommonConstants . CARBON_UPDATE_PERSIST_ENABLE , CarbonCommonConstants . CARBON_UPDATE_PERSIST_ENABLE_DEFAULT ) ; boolean validatePersistEnabled = CarbonUtil . validateBoolean ( isPersistEnabled ) ; if ( ! validatePersistEnabled ) { LOGGER . warn ( ""The "" + CarbonCommonConstants . CARBON_UPDATE_PERSIST_ENABLE + "" configuration value is invalid. It will use default value("" + CarbonCommonConstants . CARBON_UPDATE_PERSIST_ENABLE_DEFAULT + "")."" ) ; isPersistEnabled = CarbonCommonConstants . CARBON_UPDATE_PERSIST_ENABLE_DEFAULT ; } return isPersistEnabled . equalsIgnoreCase ( ""true"" ) ; } public String getUpdateDatasetStorageLevel ( ) { String storageLevel = getProperty ( CarbonCommonConstants . CARBON_UPDATE_STORAGE_LEVEL , CarbonCommonConstants . CARBON_UPDATE_STORAGE_LEVEL_DEFAULT ) ; boolean validateStorageLevel = CarbonUtil . isValidStorageLevel ( storageLevel ) ; if ( ! validateStorageLevel ) { LOGGER . warn ( ""The "" + CarbonCommonConstants . CARBON_UPDATE_STORAGE_LEVEL + "" configuration value is invalid. It will use default storage level("" + CarbonCommonConstants . CARBON_UPDATE_STORAGE_LEVEL_DEFAULT + "") to persist dataset."" ) ; storageLevel = CarbonCommonConstants . CARBON_UPDATE_STORAGE_LEVEL_DEFAULT ; } return storageLevel . toUpperCase ( ) ; } public String getSortTempCompressor ( ) { String compressor = getProperty ( CarbonCommonConstants . CARBON_SORT_TEMP_COMPRESSOR , CarbonCommonConstants . CARBON_SORT_TEMP_COMPRESSOR_DEFAULT ) . toUpperCase ( ) ; if ( compressor . isEmpty ( ) || ""SNAPPY"" . equals ( compressor ) || ""GZIP"" . equals ( compressor ) || ""BZIP2"" . equals ( compressor ) || ""LZ4"" . equals ( compressor ) || ""ZSTD"" . equals ( compressor ) ) { return compressor ; } else { LOGGER . warn ( ""The "" . concat ( CarbonCommonConstants . CARBON_SORT_TEMP_COMPRESSOR ) . concat ( "" configuration value is invalid. Only snappy, gzip, bip2, lz4, zstd and"" ) . concat ( "" empty are allowed. It will not compress the sort temp files by default"" ) ) ; return CarbonCommonConstants . CARBON_SORT_TEMP_COMPRESSOR_DEFAULT ; } } public boolean isLoadSkewedDataOptimizationEnabled ( ) { String skewedEnabled = getProperty ( CarbonLoadOptionConstants . ENABLE_CARBON_LOAD_SKEWED_DATA_OPTIMIZATION , CarbonLoadOptionConstants . ENABLE_CARBON_LOAD_SKEWED_DATA_OPTIMIZATION_DEFAULT ) ; return skewedEnabled . equalsIgnoreCase ( ""true"" ) ; } public boolean isCarbonProperty ( String key ) { return propertySet . contains ( key ) ; } public Map < String , String > getAddedProperty ( ) { return addedProperty ; } public void addPropertyToPropertySet ( Set < String > externalPropertySet ) { propertySet . addAll ( externalPropertySet ) ; } private void validateWorkingMemory ( ) { try { String unsafeWorkingMemoryStr = carbonProperties . getProperty ( CarbonCommonConstants . UNSAFE_WORKING_MEMORY_IN_MB ) ; if ( unsafeWorkingMemoryStr == null ) { return ; } int unsafeWorkingMemory = Integer . parseInt ( unsafeWorkingMemoryStr ) ; carbonProperties . setProperty ( CarbonCommonConstants . UNSAFE_WORKING_MEMORY_IN_MB , unsafeWorkingMemory + """" ) ; } catch ( NumberFormatException e ) { LOGGER . warn ( ""The specified value for property "" + CarbonCommonConstants . UNSAFE_WORKING_MEMORY_IN_MB + "" is invalid."" ) ; } } private void validateSortStorageMemory ( ) { int unsafeSortStorageMemory ; try { String unsafeSortStorageMemoryStr = carbonProperties . getProperty ( CarbonCommonConstants . CARBON_SORT_STORAGE_INMEMORY_IN_MB ) ; if ( unsafeSortStorageMemoryStr != null ) { unsafeSortStorageMemory = Integer . parseInt ( unsafeSortStorageMemoryStr ) ; } else { unsafeSortStorageMemory = CarbonCommonConstants . CARBON_SORT_STORAGE_INMEMORY_IN_MB_DEFAULT ; } } catch ( NumberFormatException e ) { LOGGER . warn ( String . format ( ""The specified value for property %s is invalid."" + "" Taking the default value.%s"" , CarbonCommonConstants . CARBON_SORT_STORAGE_INMEMORY_IN_MB , CarbonCommonConstants . CARBON_SORT_STORAGE_INMEMORY_IN_MB_DEFAULT ) ) ; unsafeSortStorageMemory = CarbonCommonConstants . CARBON_SORT_STORAGE_INMEMORY_IN_MB_DEFAULT ; } if ( unsafeSortStorageMemory < CarbonCommonConstants . CARBON_SORT_STORAGE_INMEMORY_IN_MB_DEFAULT ) { LOGGER . warn ( ""The specified value for property "" + CarbonCommonConstants . CARBON_SORT_STORAGE_INMEMORY_IN_MB + "" is less than the default value."" + "" Taking the default value: "" + CarbonCommonConstants . CARBON_SORT_STORAGE_INMEMORY_IN_MB_DEFAULT + ""."" ) ; unsafeSortStorageMemory = CarbonCommonConstants . CARBON_SORT_STORAGE_INMEMORY_IN_MB_DEFAULT ; } carbonProperties . setProperty ( CarbonCommonConstants . CARBON_SORT_STORAGE_INMEMORY_IN_MB , unsafeSortStorageMemory + """" ) ; } private void validateEnableQueryStatistics ( ) { String enableQueryStatistics = carbonProperties . getProperty ( CarbonCommonConstants . ENABLE_QUERY_STATISTICS , CarbonCommonConstants . ENABLE_QUERY_STATISTICS_DEFAULT ) ; boolean isValidBooleanValue = CarbonUtil . validateBoolean ( enableQueryStatistics ) ; if ( ! isValidBooleanValue ) { LOGGER . warn ( String . format ( ""The enable query statistics value \""%s\"" is invalid. "" + ""Using the default value \""%s\"""" , enableQueryStatistics , CarbonCommonConstants . ENABLE_QUERY_STATISTICS_DEFAULT ) ) ; carbonProperties . setProperty ( CarbonCommonConstants . ENABLE_QUERY_STATISTICS , CarbonCommonConstants . ENABLE_QUERY_STATISTICS_DEFAULT ) ; } } public boolean isEnableQueryStatistics ( ) { String enableQueryStatistics = carbonProperties . getProperty ( CarbonCommonConstants . ENABLE_QUERY_STATISTICS , CarbonCommonConstants . ENABLE_QUERY_STATISTICS_DEFAULT ) ; return enableQueryStatistics . equalsIgnoreCase ( ""true"" ) ; } public int getHeapMemoryPoolingThresholdBytes ( ) { int thresholdSize ; try { thresholdSize = Integer . parseInt ( CarbonProperties . getInstance ( ) . getProperty ( CarbonCommonConstants . CARBON_HEAP_MEMORY_POOLING_THRESHOLD_BYTES , CarbonCommonConstants . CARBON_HEAP_MEMORY_POOLING_THRESHOLD_BYTES_DEFAULT ) ) ; } catch ( NumberFormatException exc ) { LOGGER . warn ( ""The heap memory pooling threshold bytes is invalid. Using the default value "" + CarbonCommonConstants . CARBON_HEAP_MEMORY_POOLING_THRESHOLD_BYTES_DEFAULT ) ; thresholdSize = Integer . parseInt ( CarbonCommonConstants . CARBON_HEAP_MEMORY_POOLING_THRESHOLD_BYTES_DEFAULT ) ; } return thresholdSize ; } public int getRangeColumnScaleFactor ( ) { boolean isValid = true ; int scaleFactor = 1 ; try { scaleFactor = Integer . parseInt ( CarbonProperties . getInstance ( ) . getProperty ( CarbonCommonConstants . CARBON_RANGE_COLUMN_SCALE_FACTOR , CarbonCommonConstants . CARBON_RANGE_COLUMN_SCALE_FACTOR_DEFAULT ) ) ; if ( scaleFactor < 1 || scaleFactor > 300 ) { isValid = false ; } } catch ( NumberFormatException ex ) { LOGGER . warn ( ""Range column scala factor isn't number format"" ) ; isValid = false ; } if ( isValid ) { return scaleFactor ; } else { LOGGER . warn ( ""The scale factor is invalid. Using the default value "" + CarbonCommonConstants . CARBON_RANGE_COLUMN_SCALE_FACTOR_DEFAULT ) ; return Integer . parseInt ( CarbonCommonConstants . CARBON_RANGE_COLUMN_SCALE_FACTOR_DEFAULT ) ; } } public long getSegmentLockFilesPreserveHours ( ) { long preserveSeconds ; try { int preserveHours = Integer . parseInt ( CarbonProperties . getInstance ( ) . getProperty ( CarbonCommonConstants . CARBON_SEGMENT_LOCK_FILES_PRESERVE_HOURS , CarbonCommonConstants . CARBON_SEGMENT_LOCK_FILES_PRESERVE_HOURS_DEFAULT ) ) ; preserveSeconds = preserveHours * 3600 * 1000L ; } catch ( NumberFormatException exc ) { LOGGER . warn ( ""The value of '"" + CarbonCommonConstants . CARBON_SEGMENT_LOCK_FILES_PRESERVE_HOURS + ""' is invalid. Using the default value "" + CarbonCommonConstants . CARBON_SEGMENT_LOCK_FILES_PRESERVE_HOURS_DEFAULT ) ; preserveSeconds = Integer . parseInt ( CarbonCommonConstants . CARBON_SEGMENT_LOCK_FILES_PRESERVE_HOURS_DEFAULT ) * 3600 * 1000L ; } return preserveSeconds ; } public int getInvisibleSegmentPreserveCount ( ) { int preserveCnt ; try { preserveCnt = Integer . parseInt ( CarbonProperties . getInstance ( ) . getProperty ( CarbonCommonConstants . CARBON_INVISIBLE_SEGMENTS_PRESERVE_COUNT , CarbonCommonConstants . CARBON_INVISIBLE_SEGMENTS_PRESERVE_COUNT_DEFAULT ) ) ; } catch ( NumberFormatException exc ) { LOGGER . warn ( ""The value of '"" + CarbonCommonConstants . CARBON_INVISIBLE_SEGMENTS_PRESERVE_COUNT + ""' is invalid. Using the default value "" + CarbonCommonConstants . CARBON_INVISIBLE_SEGMENTS_PRESERVE_COUNT_DEFAULT ) ; preserveCnt = Integer . parseInt ( CarbonCommonConstants . CARBON_INVISIBLE_SEGMENTS_PRESERVE_COUNT_DEFAULT ) ; } return preserveCnt ; } public String getSystemFolderLocationPerDatabase ( String databaseLocation ) { return databaseLocation + CarbonCommonConstants . FILE_SEPARATOR + CarbonTablePath . SYSTEM_FOLDER_DIR ; } public int getSortMemorySpillPercentage ( ) { int spillPercentage = 0 ; try { String spillPercentageStr = getProperty ( CARBON_LOAD_SORT_MEMORY_SPILL_PERCENTAGE , CarbonLoadOptionConstants . CARBON_LOAD_SORT_MEMORY_SPILL_PERCENTAGE_DEFAULT ) ; spillPercentage = Integer . parseInt ( spillPercentageStr ) ; } catch ( NumberFormatException e ) { spillPercentage = Integer . parseInt ( CarbonLoadOptionConstants . CARBON_LOAD_SORT_MEMORY_SPILL_PERCENTAGE_DEFAULT ) ; } return spillPercentage ; } public boolean isPushRowFiltersForVector ( ) { String pushFilters = getProperty ( CarbonCommonConstants . CARBON_PUSH_ROW_FILTERS_FOR_VECTOR , CarbonCommonConstants . CARBON_PUSH_ROW_FILTERS_FOR_VECTOR_DEFAULT ) ; return Boolean . parseBoolean ( pushFilters ) ; } public boolean isRangeCompactionAllowed ( ) { String isRangeCompact = getProperty ( CarbonCommonConstants . CARBON_ENABLE_RANGE_COMPACTION , CarbonCommonConstants . CARBON_ENABLE_RANGE_COMPACTION_DEFAULT ) ; return Boolean . parseBoolean ( isRangeCompact ) ; } private void validateSortMemorySpillPercentage ( ) { String spillPercentageStr = carbonProperties . getProperty ( CARBON_LOAD_SORT_MEMORY_SPILL_PERCENTAGE , CarbonLoadOptionConstants . CARBON_LOAD_SORT_MEMORY_SPILL_PERCENTAGE_DEFAULT ) ; try { int spillPercentage = Integer . parseInt ( spillPercentageStr ) ; if ( spillPercentage > 100 || spillPercentage < 0 ) { LOGGER . info ( String . format ( ""The sort memory spill percentage value \""%s\"" is invalid. "" + ""Using the default value \""%s\"""" , spillPercentageStr , CarbonLoadOptionConstants . CARBON_LOAD_SORT_MEMORY_SPILL_PERCENTAGE_DEFAULT ) ) ; carbonProperties . setProperty ( CARBON_LOAD_SORT_MEMORY_SPILL_PERCENTAGE , CarbonLoadOptionConstants . CARBON_LOAD_SORT_MEMORY_SPILL_PERCENTAGE_DEFAULT ) ; } } catch ( NumberFormatException e ) { LOGGER . info ( String . format ( ""The sort memory spill percentage value \""%s\"" is invalid. "" + ""Using the default value \""%s\"""" , spillPercentageStr , CarbonLoadOptionConstants . CARBON_LOAD_SORT_MEMORY_SPILL_PERCENTAGE_DEFAULT ) ) ; carbonProperties . setProperty ( CARBON_LOAD_SORT_MEMORY_SPILL_PERCENTAGE , CarbonLoadOptionConstants . CARBON_LOAD_SORT_MEMORY_SPILL_PERCENTAGE_DEFAULT ) ; } } private void validateStringCharacterLimit ( ) { int allowedCharactersLimit = 0 ; try { allowedCharactersLimit = Integer . parseInt ( carbonProperties . getProperty ( CARBON_MINMAX_ALLOWED_BYTE_COUNT , CarbonCommonConstants . CARBON_MINMAX_ALLOWED_BYTE_COUNT_DEFAULT ) ) ; if ( allowedCharactersLimit < CarbonCommonConstants . CARBON_MINMAX_ALLOWED_BYTE_COUNT_MIN || allowedCharactersLimit > CarbonCommonConstants . CARBON_MINMAX_ALLOWED_BYTE_COUNT_MAX ) { LOGGER . info ( String . format ( ""The min max byte limit for "" + ""string type value \""%s\"" is invalid. "" + ""Using the default value \""%s\"""" , allowedCharactersLimit , CarbonCommonConstants . CARBON_MINMAX_ALLOWED_BYTE_COUNT_DEFAULT ) ) ; carbonProperties . setProperty ( CARBON_MINMAX_ALLOWED_BYTE_COUNT , CarbonCommonConstants . CARBON_MINMAX_ALLOWED_BYTE_COUNT_DEFAULT ) ; } else { LOGGER . info ( ""Considered value for min max byte limit for string is: "" + allowedCharactersLimit ) ; carbonProperties . setProperty ( CARBON_MINMAX_ALLOWED_BYTE_COUNT , allowedCharactersLimit + """" ) ; } } catch ( NumberFormatException e ) { LOGGER . info ( String . format ( ""The min max byte limit for string type value \""%s\"" is invalid. "" + ""Using the default value \""%s\"""" , allowedCharactersLimit , CarbonCommonConstants . CARBON_MINMAX_ALLOWED_BYTE_COUNT_DEFAULT ) ) ; carbonProperties . setProperty ( CARBON_MINMAX_ALLOWED_BYTE_COUNT , CarbonCommonConstants . CARBON_MINMAX_ALLOWED_BYTE_COUNT_DEFAULT ) ; } } private void validateDetailQueryBatchSize ( ) { String batchSizeString = carbonProperties . getProperty ( DETAIL_QUERY_BATCH_SIZE ) ; if ( batchSizeString == null ) { carbonProperties . setProperty ( DETAIL_QUERY_BATCH_SIZE , Integer . toString ( DETAIL_QUERY_BATCH_SIZE_DEFAULT ) ) ; LOGGER . info ( ""Using default value for carbon.detail.batch.size "" + DETAIL_QUERY_BATCH_SIZE_DEFAULT ) ; } else { int batchSize ; try { batchSize = Integer . parseInt ( batchSizeString ) ; if ( batchSize < DETAIL_QUERY_BATCH_SIZE_MIN || batchSize > DETAIL_QUERY_BATCH_SIZE_MAX ) { LOGGER . warn ( ""Invalid carbon.detail.batch.size.Using default value "" + DETAIL_QUERY_BATCH_SIZE_DEFAULT ) ; carbonProperties . setProperty ( DETAIL_QUERY_BATCH_SIZE , Integer . toString ( DETAIL_QUERY_BATCH_SIZE_DEFAULT ) ) ; } } catch ( NumberFormatException ne ) { LOGGER . info ( ""Invalid carbon.detail.batch.size.Using default value "" + DETAIL_QUERY_BATCH_SIZE_DEFAULT ) ; carbonProperties . setProperty ( DETAIL_QUERY_BATCH_SIZE , Integer . toString ( DETAIL_QUERY_BATCH_SIZE_DEFAULT ) ) ; } } } private void validateDMSchemaStorageProvider ( ) { String provider = carbonProperties . getProperty ( CarbonCommonConstants . CARBON_INDEX_SCHEMA_STORAGE ) ; if ( provider == null ) { carbonProperties . setProperty ( CarbonCommonConstants . CARBON_INDEX_SCHEMA_STORAGE , CarbonCommonConstants . CARBON_INDEX_SCHEMA_STORAGE_DEFAULT ) ; } else { switch ( provider . toUpperCase ( ) ) { case CarbonCommonConstants . CARBON_INDEX_SCHEMA_STORAGE_DISK : break ; case CarbonCommonConstants . CARBON_INDEX_SCHEMA_STORAGE_DATABASE : break ; default : LOGGER . warn ( ""The value \"""" + provider + ""\"" configured for key "" + CarbonCommonConstants . CARBON_INDEX_SCHEMA_STORAGE + "" is invalid for current file system. Use the default value "" + CarbonCommonConstants . CARBON_INDEX_SCHEMA_STORAGE_DEFAULT + "" instead."" ) ; carbonProperties . setProperty ( CarbonCommonConstants . CARBON_INDEX_SCHEMA_STORAGE , CarbonCommonConstants . CARBON_INDEX_SCHEMA_STORAGE_DEFAULT ) ; } } } public boolean isDistributedPruningEnabled ( String dbName , String tableName ) { String configuredValue = getSessionPropertyValue ( CarbonCommonConstants . CARBON_ENABLE_INDEX_SERVER + ""."" + dbName + ""."" + tableName ) ; if ( configuredValue == null ) { configuredValue = getProperty ( CarbonCommonConstants . CARBON_ENABLE_INDEX_SERVER ) ; } boolean isServerEnabledByUser = Boolean . parseBoolean ( configuredValue ) ; if ( isServerEnabledByUser ) { LOGGER . info ( ""Distributed Index server is enabled for "" + dbName + ""."" + tableName ) ; } return isServerEnabledByUser ; } public boolean isIndexServerPrePrimingEnabled ( ) { String configuredValue = carbonProperties . getProperty ( CarbonCommonConstants . CARBON_INDEXSEVER_ENABLE_PREPRIMING ) ; return Boolean . parseBoolean ( configuredValue ) ; } public String getIndexServerIP ( ) { return carbonProperties . getProperty ( CarbonCommonConstants . CARBON_INDEX_SERVER_IP , """" ) ; } public int getIndexServerPort ( ) { String configuredPort = carbonProperties . getProperty ( CarbonCommonConstants . CARBON_INDEX_SERVER_PORT ) ; try { return Integer . parseInt ( configuredPort ) ; } catch ( NumberFormatException e ) { LOGGER . error ( ""Configured port for index server is not a valid number"" , e ) ; throw e ; } } public boolean isFallBackDisabled ( ) { return Boolean . parseBoolean ( carbonProperties . getProperty ( CarbonCommonConstants . CARBON_DISABLE_INDEX_SERVER_FALLBACK , ""false"" ) ) ; } public int getNumberOfHandlersForIndexServer ( ) { String configuredValue = carbonProperties . getProperty ( CarbonCommonConstants . CARBON_INDEX_SERVER_WORKER_THREADS ) ; if ( configuredValue != null ) { return Integer . parseInt ( configuredValue ) ; } return CarbonCommonConstants . CARBON_INDEX_SERVER_WORKER_THREADS_DEFAULT ; } public int getNumOfThreadsForExecutorPruning ( ) { String configuredValue = CarbonProperties . getInstance ( ) . getProperty ( CarbonCommonConstants . CARBON_MAX_EXECUTOR_THREADS_FOR_BLOCK_PRUNING ) ; if ( configuredValue == null || configuredValue . equalsIgnoreCase ( ""0"" ) ) { configuredValue = CarbonCommonConstants . CARBON_MAX_EXECUTOR_THREADS_FOR_BLOCK_PRUNING_DEFAULT ; } try { int numOfThreads = Integer . parseInt ( configuredValue ) ; LOGGER . info ( ""Value for "" + CarbonCommonConstants . CARBON_MAX_EXECUTOR_THREADS_FOR_BLOCK_PRUNING + "" is "" + numOfThreads ) ; return numOfThreads ; } catch ( NumberFormatException e ) { LOGGER . info ( configuredValue + "" is not a valid input for "" + CarbonCommonConstants . CARBON_MAX_EXECUTOR_THREADS_FOR_BLOCK_PRUNING + "", taking "" + CarbonCommonConstants . CARBON_MAX_EXECUTOR_THREADS_FOR_BLOCK_PRUNING_DEFAULT + "" as default value"" ) ; return Integer . parseInt ( CarbonCommonConstants . CARBON_MAX_EXECUTOR_THREADS_FOR_BLOCK_PRUNING_DEFAULT ) ; } } public static int getNumOfThreadsForPruning ( ) { int numOfThreadsForPruning ; String maxDriverThreadsForBockPruning = CarbonCommonConstants . CARBON_MAX_DRIVER_THREADS_FOR_BLOCK_PRUNING ; int defaultNumberOfThreads = Integer . parseInt ( CarbonCommonConstants . CARBON_MAX_DRIVER_THREADS_FOR_BLOCK_PRUNING_DEFAULT ) ; String logMessage = "" is not a valid input for "" + maxDriverThreadsForBockPruning + "". Using the default number of threads : "" + defaultNumberOfThreads ; try { numOfThreadsForPruning = Integer . parseInt ( CarbonProperties . getInstance ( ) . getProperty ( maxDriverThreadsForBockPruning , String . valueOf ( defaultNumberOfThreads ) ) ) ; if ( numOfThreadsForPruning > defaultNumberOfThreads || numOfThreadsForPruning < 1 ) { LOGGER . info ( numOfThreadsForPruning + logMessage ) ; numOfThreadsForPruning = defaultNumberOfThreads ; } } catch ( NumberFormatException e ) { LOGGER . info ( CarbonProperties . getInstance ( ) . getProperty ( maxDriverThreadsForBockPruning + logMessage ) ) ; numOfThreadsForPruning = defaultNumberOfThreads ; } return numOfThreadsForPruning ; } public static int getDriverPruningMultiThreadEnableFilesCount ( ) { int driverPruningMultiThreadEnableFilesCount = 0 ; try { driverPruningMultiThreadEnableFilesCount = Integer . parseInt ( CarbonProperties . getInstance ( ) . getProperty ( CarbonCommonConstants . CARBON_DRIVER_PRUNING_MULTI_THREAD_ENABLE_FILES_COUNT , CarbonCommonConstants . CARBON_DRIVER_PRUNING_MULTI_THREAD_ENABLE_FILES_COUNT_DEFAULT ) ) ; if ( driverPruningMultiThreadEnableFilesCount <= 0 ) { LOGGER . info ( ""The driver prunning multithread enable files count value \"""" + driverPruningMultiThreadEnableFilesCount + ""\"" is invalid. Using the default value \"""" + CarbonCommonConstants . CARBON_DRIVER_PRUNING_MULTI_THREAD_ENABLE_FILES_COUNT_DEFAULT ) ; driverPruningMultiThreadEnableFilesCount = Integer . parseInt ( CarbonCommonConstants . CARBON_DRIVER_PRUNING_MULTI_THREAD_ENABLE_FILES_COUNT_DEFAULT ) ; } } catch ( NumberFormatException e ) { LOGGER . info ( ""The driver prunning multithread enable files count value "" + ""is invalid. Using the default value \"""" + CarbonCommonConstants . CARBON_DRIVER_PRUNING_MULTI_THREAD_ENABLE_FILES_COUNT_DEFAULT ) ; driverPruningMultiThreadEnableFilesCount = Integer . parseInt ( CarbonCommonConstants . CARBON_DRIVER_PRUNING_MULTI_THREAD_ENABLE_FILES_COUNT_DEFAULT ) ; } return driverPruningMultiThreadEnableFilesCount ; } public static Long getInputMetricsInterval ( ) { String metrics = CarbonProperties . getInstance ( ) . getProperty ( CarbonCommonConstants . INPUT_METRICS_UPDATE_INTERVAL ) ; if ( metrics == null ) { return CarbonCommonConstants . INPUT_METRICS_UPDATE_INTERVAL_DEFAULT ; } else { try { long configuredValue = Long . parseLong ( metrics ) ; if ( configuredValue < 0 ) { return CarbonCommonConstants . INPUT_METRICS_UPDATE_INTERVAL_DEFAULT ; } else { return configuredValue ; } } catch ( Exception ex ) { return CarbonCommonConstants . INPUT_METRICS_UPDATE_INTERVAL_DEFAULT ; } } } public static Boolean getQueryPrefetchEnable ( ) { String prefetchEnable = CarbonProperties . getInstance ( ) . getProperty ( CarbonCommonConstants . CARBON_QUERY_PREFETCH_ENABLE ) ; if ( prefetchEnable == null ) { return Boolean . parseBoolean ( CarbonCommonConstants . CARBON_QUERY_PREFETCH_ENABLE_DEFAULT ) ; } else { return ! prefetchEnable . equalsIgnoreCase ( ""false"" ) ; } } public static Boolean isUniqueValueCheckEnabled ( ) { String needValidate = CarbonProperties . getInstance ( ) . getProperty ( CarbonCommonConstants . CARBON_UPDATE_CHECK_UNIQUE_VALUE ) ; if ( needValidate == null ) { return Boolean . parseBoolean ( CarbonCommonConstants . CARBON_UPDATE_CHECK_UNIQUE_VALUE_DEFAULT ) ; } else { return ! needValidate . equalsIgnoreCase ( ""false"" ) ; } } private void validateAndGetLocalDictionarySizeThresholdInMB ( ) { String sizeStr = carbonProperties . getProperty ( CarbonCommonConstants . CARBON_LOCAL_DICTIONARY_SIZE_THRESHOLD_IN_MB ) ; String defaultValue = Integer . toString ( CarbonCommonConstants . CARBON_LOCAL_DICTIONARY_SIZE_THRESHOLD_IN_MB_DEFAULT ) ; if ( sizeStr == null ) { carbonProperties . setProperty ( CarbonCommonConstants . CARBON_LOCAL_DICTIONARY_SIZE_THRESHOLD_IN_MB , defaultValue ) ; } else { try { int size = Integer . parseInt ( sizeStr ) ; if ( size < 0 || size == 0 || size > CarbonCommonConstants . CARBON_LOCAL_DICTIONARY_SIZE_THRESHOLD_IN_MB_MAX ) { LOGGER . info ( ""using default value of carbon.local.dictionary.size.threshold.inmb = "" + defaultValue ) ; carbonProperties . setProperty ( CarbonCommonConstants . CARBON_LOCAL_DICTIONARY_SIZE_THRESHOLD_IN_MB , defaultValue ) ; } else { LOGGER . info ( ""using carbon.local.dictionary.size.threshold.inmb = "" + size ) ; carbonProperties . setProperty ( CarbonCommonConstants . CARBON_LOCAL_DICTIONARY_SIZE_THRESHOLD_IN_MB , Integer . toString ( size ) ) ; } } catch ( Exception ex ) { LOGGER . info ( ""using default value of carbon.local.dictionary.size.threshold.inmb = "" + defaultValue ) ; carbonProperties . setProperty ( CarbonCommonConstants . CARBON_LOCAL_DICTIONARY_SIZE_THRESHOLD_IN_MB , defaultValue ) ; } } } public static String getIndexStorageProvider ( ) { String provider = CarbonProperties . getInstance ( ) . getProperty ( CarbonCommonConstants . CARBON_INDEX_SCHEMA_STORAGE ) ; if ( provider == null ) { return CarbonCommonConstants . CARBON_INDEX_SCHEMA_STORAGE_DEFAULT ; } return provider . toUpperCase ( ) ; } public static Boolean isBadRecordHandlingEnabledForInsert ( ) { String badRecordHandling = CarbonProperties . getInstance ( ) . getProperty ( CarbonCommonConstants . CARBON_ENABLE_BAD_RECORD_HANDLING_FOR_INSERT ) ; if ( badRecordHandling == null ) { return Boolean . parseBoolean ( CarbonCommonConstants . CARBON_ENABLE_BAD_RECORD_HANDLING_FOR_INSERT_DEFAULT ) ; } else { return badRecordHandling . equalsIgnoreCase ( ""true"" ) ; } } public String getDefaultCompressor ( ) { return getProperty ( CarbonCommonConstants . COMPRESSOR , CarbonCommonConstants . DEFAULT_COMPRESSOR ) ; } public static boolean isQueryStageInputEnabled ( ) { return Boolean . parseBoolean ( getInstance ( ) . getProperty ( CarbonCommonConstants . CARBON_QUERY_STAGE_INPUT , CarbonCommonConstants . CARBON_QUERY_STAGE_INPUT_DEFAULT ) ) ; } public static boolean isAuditEnabled ( ) { return Boolean . parseBoolean ( getInstance ( ) . getProperty ( CarbonCommonConstants . CARBON_ENABLE_AUDIT , CarbonCommonConstants . CARBON_ENABLE_AUDIT_DEFAULT ) ) ; } public static void setAuditEnabled ( boolean enabled ) { getInstance ( ) . addProperty ( CarbonCommonConstants . CARBON_ENABLE_AUDIT , String . valueOf ( enabled ) ) ; } }",Smelly
"class MQTTProtocolConverter { private static final Logger LOG = LoggerFactory . getLogger ( MQTTProtocolConverter . class ) ; private static final IdGenerator CONNECTION_ID_GENERATOR = new IdGenerator ( ) ; private static final MQTTFrame PING_RESP_FRAME = new PINGRESP ( ) . encode ( ) ; private static final double MQTT_KEEP_ALIVE_GRACE_PERIOD = 1.5 ; private static final int DEFAULT_CACHE_SIZE = 5000 ; private final ConnectionId connectionId = new ConnectionId ( CONNECTION_ID_GENERATOR . generateId ( ) ) ; private final SessionId sessionId = new SessionId ( connectionId , - 1 ) ; private final ProducerId producerId = new ProducerId ( sessionId , 1 ) ; private final LongSequenceGenerator messageIdGenerator = new LongSequenceGenerator ( ) ; private final LongSequenceGenerator consumerIdGenerator = new LongSequenceGenerator ( ) ; private final ConcurrentHashMap < Integer , ResponseHandler > resposeHandlers = new ConcurrentHashMap < Integer , ResponseHandler > ( ) ; private final ConcurrentHashMap < ConsumerId , MQTTSubscription > subscriptionsByConsumerId = new ConcurrentHashMap < ConsumerId , MQTTSubscription > ( ) ; private final ConcurrentHashMap < UTF8Buffer , MQTTSubscription > mqttSubscriptionByTopic = new ConcurrentHashMap < UTF8Buffer , MQTTSubscription > ( ) ; private final Map < UTF8Buffer , ActiveMQTopic > activeMQTopicMap = new LRUCache < UTF8Buffer , ActiveMQTopic > ( DEFAULT_CACHE_SIZE ) ; private final Map < Destination , UTF8Buffer > mqttTopicMap = new LRUCache < Destination , UTF8Buffer > ( DEFAULT_CACHE_SIZE ) ; private final Map < Short , MessageAck > consumerAcks = new LRUCache < Short , MessageAck > ( DEFAULT_CACHE_SIZE ) ; private final Map < Short , PUBREC > publisherRecs = new LRUCache < Short , PUBREC > ( DEFAULT_CACHE_SIZE ) ; private final MQTTTransport mqttTransport ; private final Object commnadIdMutex = new Object ( ) ; private int lastCommandId ; private final AtomicBoolean connected = new AtomicBoolean ( false ) ; private ConnectionInfo connectionInfo = new ConnectionInfo ( ) ; private CONNECT connect ; private String clientId ; private long defaultKeepAlive ; private int activeMQSubscriptionPrefetch = 1 ; private final String QOS_PROPERTY_NAME = ""QoSPropertyName"" ; public MQTTProtocolConverter ( MQTTTransport mqttTransport , BrokerContext brokerContext ) { this . mqttTransport = mqttTransport ; this . defaultKeepAlive = 0 ; } int generateCommandId ( ) { synchronized ( commnadIdMutex ) { return lastCommandId ++ ; } } void sendToActiveMQ ( Command command , ResponseHandler handler ) { command . setCommandId ( generateCommandId ( ) ) ; if ( handler != null ) { command . setResponseRequired ( true ) ; resposeHandlers . put ( command . getCommandId ( ) , handler ) ; } mqttTransport . sendToActiveMQ ( command ) ; } void sendToMQTT ( MQTTFrame frame ) { try { mqttTransport . sendToMQTT ( frame ) ; } catch ( IOException e ) { LOG . warn ( ""Failed to send frame "" + frame , e ) ; } } public void onMQTTCommand ( MQTTFrame frame ) throws IOException , JMSException { switch ( frame . messageType ( ) ) { case PINGREQ . TYPE : { LOG . debug ( ""Received a ping from client: "" + getClientId ( ) ) ; mqttTransport . sendToMQTT ( PING_RESP_FRAME ) ; LOG . debug ( ""Sent Ping Response to "" + getClientId ( ) ) ; break ; } case CONNECT . TYPE : { onMQTTConnect ( new CONNECT ( ) . decode ( frame ) ) ; LOG . debug ( ""MQTT Client "" + getClientId ( ) + "" connected."" ) ; break ; } case DISCONNECT . TYPE : { LOG . debug ( ""MQTT Client "" + getClientId ( ) + "" disconnecting"" ) ; stopTransport ( ) ; break ; } case SUBSCRIBE . TYPE : { onSubscribe ( new SUBSCRIBE ( ) . decode ( frame ) ) ; break ; } case UNSUBSCRIBE . TYPE : { onUnSubscribe ( new UNSUBSCRIBE ( ) . decode ( frame ) ) ; break ; } case PUBLISH . TYPE : { onMQTTPublish ( new PUBLISH ( ) . decode ( frame ) ) ; break ; } case PUBACK . TYPE : { onMQTTPubAck ( new PUBACK ( ) . decode ( frame ) ) ; break ; } case PUBREC . TYPE : { onMQTTPubRec ( new PUBREC ( ) . decode ( frame ) ) ; break ; } case PUBREL . TYPE : { onMQTTPubRel ( new PUBREL ( ) . decode ( frame ) ) ; break ; } case PUBCOMP . TYPE : { onMQTTPubComp ( new PUBCOMP ( ) . decode ( frame ) ) ; break ; } default : { handleException ( new MQTTProtocolException ( ""Unknown MQTTFrame type: "" + frame . messageType ( ) , true ) , frame ) ; } } } void onMQTTConnect ( final CONNECT connect ) throws MQTTProtocolException { if ( connected . get ( ) ) { throw new MQTTProtocolException ( ""All ready connected."" ) ; } this . connect = connect ; String clientId = """" ; if ( connect . clientId ( ) != null ) { clientId = connect . clientId ( ) . toString ( ) ; } String userName = """" ; if ( connect . userName ( ) != null ) { userName = connect . userName ( ) . toString ( ) ; } String passswd = """" ; if ( connect . password ( ) != null ) { passswd = connect . password ( ) . toString ( ) ; } configureInactivityMonitor ( connect . keepAlive ( ) ) ; connectionInfo . setConnectionId ( connectionId ) ; if ( clientId != null && ! clientId . isEmpty ( ) ) { connectionInfo . setClientId ( clientId ) ; } else { connectionInfo . setClientId ( """" + connectionInfo . getConnectionId ( ) . toString ( ) ) ; } connectionInfo . setResponseRequired ( true ) ; connectionInfo . setUserName ( userName ) ; connectionInfo . setPassword ( passswd ) ; connectionInfo . setTransportContext ( mqttTransport . getPeerCertificates ( ) ) ; sendToActiveMQ ( connectionInfo , new ResponseHandler ( ) { public void onResponse ( MQTTProtocolConverter converter , Response response ) throws IOException { if ( response . isException ( ) ) { Throwable exception = ( ( ExceptionResponse ) response ) . getException ( ) ; CONNACK ack = new CONNACK ( ) ; ack . code ( CONNACK . Code . CONNECTION_REFUSED_SERVER_UNAVAILABLE ) ; getMQTTTransport ( ) . sendToMQTT ( ack . encode ( ) ) ; getMQTTTransport ( ) . onException ( IOExceptionSupport . create ( exception ) ) ; return ; } final SessionInfo sessionInfo = new SessionInfo ( sessionId ) ; sendToActiveMQ ( sessionInfo , null ) ; final ProducerInfo producerInfo = new ProducerInfo ( producerId ) ; sendToActiveMQ ( producerInfo , new ResponseHandler ( ) { public void onResponse ( MQTTProtocolConverter converter , Response response ) throws IOException { if ( response . isException ( ) ) { Throwable exception = ( ( ExceptionResponse ) response ) . getException ( ) ; CONNACK ack = new CONNACK ( ) ; ack . code ( CONNACK . Code . CONNECTION_REFUSED_BAD_USERNAME_OR_PASSWORD ) ; getMQTTTransport ( ) . sendToMQTT ( ack . encode ( ) ) ; getMQTTTransport ( ) . onException ( IOExceptionSupport . create ( exception ) ) ; } CONNACK ack = new CONNACK ( ) ; ack . code ( CONNACK . Code . CONNECTION_ACCEPTED ) ; connected . set ( true ) ; getMQTTTransport ( ) . sendToMQTT ( ack . encode ( ) ) ; } } ) ; } } ) ; } void onSubscribe ( SUBSCRIBE command ) throws MQTTProtocolException { checkConnected ( ) ; Topic [ ] topics = command . topics ( ) ; if ( topics != null ) { byte [ ] qos = new byte [ topics . length ] ; for ( int i = 0 ; i < topics . length ; i ++ ) { qos [ i ] = ( byte ) onSubscribe ( command , topics [ i ] ) . ordinal ( ) ; } SUBACK ack = new SUBACK ( ) ; ack . messageId ( command . messageId ( ) ) ; ack . grantedQos ( qos ) ; try { getMQTTTransport ( ) . sendToMQTT ( ack . encode ( ) ) ; } catch ( IOException e ) { LOG . warn ( ""Couldn't send SUBACK for "" + command , e ) ; } } else { LOG . warn ( ""No topics defined for Subscription "" + command ) ; } } QoS onSubscribe ( SUBSCRIBE command , Topic topic ) throws MQTTProtocolException { ActiveMQDestination destination = new ActiveMQTopic ( convertMQTTToActiveMQ ( topic . name ( ) . toString ( ) ) ) ; ConsumerId id = new ConsumerId ( sessionId , consumerIdGenerator . getNextSequenceId ( ) ) ; ConsumerInfo consumerInfo = new ConsumerInfo ( id ) ; consumerInfo . setDestination ( destination ) ; consumerInfo . setPrefetchSize ( getActiveMQSubscriptionPrefetch ( ) ) ; consumerInfo . setDispatchAsync ( true ) ; if ( ! connect . cleanSession ( ) && ( connect . clientId ( ) != null ) ) { consumerInfo . setSubscriptionName ( connect . clientId ( ) . toString ( ) ) ; } MQTTSubscription mqttSubscription = new MQTTSubscription ( this , topic . qos ( ) , consumerInfo ) ; subscriptionsByConsumerId . put ( id , mqttSubscription ) ; mqttSubscriptionByTopic . put ( topic . name ( ) , mqttSubscription ) ; sendToActiveMQ ( consumerInfo , null ) ; return topic . qos ( ) ; } void onUnSubscribe ( UNSUBSCRIBE command ) { UTF8Buffer [ ] topics = command . topics ( ) ; if ( topics != null ) { for ( UTF8Buffer topic : topics ) { onUnSubscribe ( topic ) ; } } UNSUBACK ack = new UNSUBACK ( ) ; ack . messageId ( command . messageId ( ) ) ; sendToMQTT ( ack . encode ( ) ) ; } void onUnSubscribe ( UTF8Buffer topicName ) { MQTTSubscription subs = mqttSubscriptionByTopic . remove ( topicName ) ; if ( subs != null ) { ConsumerInfo info = subs . getConsumerInfo ( ) ; if ( info != null ) { subscriptionsByConsumerId . remove ( info . getConsumerId ( ) ) ; } RemoveInfo removeInfo = null ; if ( info != null ) { removeInfo = info . createRemoveCommand ( ) ; } sendToActiveMQ ( removeInfo , null ) ; } } public void onActiveMQCommand ( Command command ) throws Exception { if ( command . isResponse ( ) ) { Response response = ( Response ) command ; ResponseHandler rh = resposeHandlers . remove ( Integer . valueOf ( response . getCorrelationId ( ) ) ) ; if ( rh != null ) { rh . onResponse ( this , response ) ; } else { if ( response . isException ( ) ) { Throwable exception = ( ( ExceptionResponse ) response ) . getException ( ) ; handleException ( exception , null ) ; } } } else if ( command . isMessageDispatch ( ) ) { MessageDispatch md = ( MessageDispatch ) command ; MQTTSubscription sub = subscriptionsByConsumerId . get ( md . getConsumerId ( ) ) ; if ( sub != null ) { MessageAck ack = sub . createMessageAck ( md ) ; PUBLISH publish = sub . createPublish ( ( ActiveMQMessage ) md . getMessage ( ) ) ; if ( ack != null && sub . expectAck ( publish ) ) { synchronized ( consumerAcks ) { consumerAcks . put ( publish . messageId ( ) , ack ) ; } } getMQTTTransport ( ) . sendToMQTT ( publish . encode ( ) ) ; if ( ack != null && ! sub . expectAck ( publish ) ) { getMQTTTransport ( ) . sendToActiveMQ ( ack ) ; } } } else if ( command . getDataStructureType ( ) == ConnectionError . DATA_STRUCTURE_TYPE ) { Throwable exception = ( ( ConnectionError ) command ) . getException ( ) ; handleException ( exception , null ) ; } else if ( command . isBrokerInfo ( ) ) { } else { LOG . debug ( ""Do not know how to process ActiveMQ Command "" + command ) ; } } void onMQTTPublish ( PUBLISH command ) throws IOException , JMSException { checkConnected ( ) ; ActiveMQMessage message = convertMessage ( command ) ; message . setProducerId ( producerId ) ; message . onSend ( ) ; sendToActiveMQ ( message , createResponseHandler ( command ) ) ; } void onMQTTPubAck ( PUBACK command ) { short messageId = command . messageId ( ) ; MessageAck ack ; synchronized ( consumerAcks ) { ack = consumerAcks . remove ( messageId ) ; } if ( ack != null ) { getMQTTTransport ( ) . sendToActiveMQ ( ack ) ; } } void onMQTTPubRec ( PUBREC commnand ) { PUBREL pubrel = new PUBREL ( ) ; pubrel . messageId ( commnand . messageId ( ) ) ; sendToMQTT ( pubrel . encode ( ) ) ; } void onMQTTPubRel ( PUBREL command ) { PUBREC ack ; synchronized ( publisherRecs ) { ack = publisherRecs . remove ( command . messageId ( ) ) ; } if ( ack == null ) { LOG . warn ( ""Unknown PUBREL: "" + command . messageId ( ) + "" received"" ) ; } PUBCOMP pubcomp = new PUBCOMP ( ) ; pubcomp . messageId ( command . messageId ( ) ) ; sendToMQTT ( pubcomp . encode ( ) ) ; } void onMQTTPubComp ( PUBCOMP command ) { short messageId = command . messageId ( ) ; MessageAck ack ; synchronized ( consumerAcks ) { ack = consumerAcks . remove ( messageId ) ; } if ( ack != null ) { getMQTTTransport ( ) . sendToActiveMQ ( ack ) ; } } ActiveMQMessage convertMessage ( PUBLISH command ) throws JMSException { ActiveMQBytesMessage msg = new ActiveMQBytesMessage ( ) ; msg . setProducerId ( producerId ) ; MessageId id = new MessageId ( producerId , messageIdGenerator . getNextSequenceId ( ) ) ; msg . setMessageId ( id ) ; msg . setTimestamp ( System . currentTimeMillis ( ) ) ; msg . setPriority ( ( byte ) Message . DEFAULT_PRIORITY ) ; msg . setPersistent ( command . qos ( ) != QoS . AT_MOST_ONCE ) ; msg . setIntProperty ( QOS_PROPERTY_NAME , command . qos ( ) . ordinal ( ) ) ; ActiveMQTopic topic ; synchronized ( activeMQTopicMap ) { topic = activeMQTopicMap . get ( command . topicName ( ) ) ; if ( topic == null ) { String topicName = command . topicName ( ) . toString ( ) . replaceAll ( ""/"" , ""."" ) ; topic = new ActiveMQTopic ( topicName ) ; activeMQTopicMap . put ( command . topicName ( ) , topic ) ; } } msg . setJMSDestination ( topic ) ; msg . writeBytes ( command . payload ( ) . data , command . payload ( ) . offset , command . payload ( ) . length ) ; return msg ; } public PUBLISH convertMessage ( ActiveMQMessage message ) throws IOException , JMSException , DataFormatException { PUBLISH result = new PUBLISH ( ) ; short id = ( short ) message . getMessageId ( ) . getProducerSequenceId ( ) ; result . messageId ( id ) ; QoS qoS ; if ( message . propertyExists ( QOS_PROPERTY_NAME ) ) { int ordinal = message . getIntProperty ( QOS_PROPERTY_NAME ) ; qoS = QoS . values ( ) [ ordinal ] ; } else { qoS = message . isPersistent ( ) ? QoS . AT_MOST_ONCE : QoS . AT_LEAST_ONCE ; } result . qos ( qoS ) ; UTF8Buffer topicName ; synchronized ( mqttTopicMap ) { topicName = mqttTopicMap . get ( message . getJMSDestination ( ) ) ; if ( topicName == null ) { topicName = new UTF8Buffer ( message . getDestination ( ) . getPhysicalName ( ) . replace ( '.' , '/' ) ) ; mqttTopicMap . put ( message . getJMSDestination ( ) , topicName ) ; } } result . topicName ( topicName ) ; if ( message . getDataStructureType ( ) == ActiveMQTextMessage . DATA_STRUCTURE_TYPE ) { ActiveMQTextMessage msg = ( ActiveMQTextMessage ) message . copy ( ) ; msg . setReadOnlyBody ( true ) ; String messageText = msg . getText ( ) ; if ( messageText != null ) { result . payload ( new Buffer ( messageText . getBytes ( ""UTF-8"" ) ) ) ; } } else if ( message . getDataStructureType ( ) == ActiveMQBytesMessage . DATA_STRUCTURE_TYPE ) { ActiveMQBytesMessage msg = ( ActiveMQBytesMessage ) message . copy ( ) ; msg . setReadOnlyBody ( true ) ; byte [ ] data = new byte [ ( int ) msg . getBodyLength ( ) ] ; msg . readBytes ( data ) ; result . payload ( new Buffer ( data ) ) ; } else if ( message . getDataStructureType ( ) == ActiveMQMapMessage . DATA_STRUCTURE_TYPE ) { ActiveMQMapMessage msg = ( ActiveMQMapMessage ) message . copy ( ) ; msg . setReadOnlyBody ( true ) ; Map < String , Object > map = msg . getContentMap ( ) ; if ( map != null ) { result . payload ( new Buffer ( map . toString ( ) . getBytes ( ""UTF-8"" ) ) ) ; } } else { ByteSequence byteSequence = message . getContent ( ) ; if ( byteSequence != null && byteSequence . getLength ( ) > 0 ) { if ( message . isCompressed ( ) ) { Inflater inflater = new Inflater ( ) ; inflater . setInput ( byteSequence . data , byteSequence . offset , byteSequence . length ) ; byte [ ] data = new byte [ 4096 ] ; int read ; ByteArrayOutputStream bytesOut = new ByteArrayOutputStream ( ) ; while ( ( read = inflater . inflate ( data ) ) != 0 ) { bytesOut . write ( data , 0 , read ) ; } byteSequence = bytesOut . toByteSequence ( ) ; } result . payload ( new Buffer ( byteSequence . data , byteSequence . offset , byteSequence . length ) ) ; } } return result ; } public MQTTTransport getMQTTTransport ( ) { return mqttTransport ; } public void onTransportError ( ) { if ( connect != null ) { if ( connect . willTopic ( ) != null && connect . willMessage ( ) != null ) { try { PUBLISH publish = new PUBLISH ( ) ; publish . topicName ( connect . willTopic ( ) ) ; publish . qos ( connect . willQos ( ) ) ; publish . payload ( connect . willMessage ( ) ) ; ActiveMQMessage message = convertMessage ( publish ) ; message . setProducerId ( producerId ) ; message . onSend ( ) ; sendToActiveMQ ( message , null ) ; } catch ( Exception e ) { LOG . warn ( ""Failed to publish Will Message "" + connect . willMessage ( ) ) ; } } } } void configureInactivityMonitor ( short keepAliveSeconds ) { MQTTInactivityMonitor monitor = getMQTTTransport ( ) . getInactivityMonitor ( ) ; if ( monitor == null ) { return ; } long keepAliveMS = keepAliveSeconds * 1000 ; if ( LOG . isDebugEnabled ( ) ) { LOG . debug ( ""MQTT Client "" + getClientId ( ) + "" requests heart beat of  "" + keepAliveMS + "" ms"" ) ; } try { long keepAliveMSWithGracePeriod = ( long ) ( keepAliveMS * MQTT_KEEP_ALIVE_GRACE_PERIOD ) ; if ( keepAliveMSWithGracePeriod == 0 && defaultKeepAlive > 0 ) { keepAliveMSWithGracePeriod = defaultKeepAlive ; } monitor . setProtocolConverter ( this ) ; monitor . setReadCheckTime ( keepAliveMSWithGracePeriod ) ; monitor . setInitialDelayTime ( keepAliveMS ) ; monitor . startMonitorThread ( ) ; if ( LOG . isDebugEnabled ( ) ) { LOG . debug ( ""MQTT Client "" + getClientId ( ) + "" established heart beat of  "" + keepAliveMSWithGracePeriod + "" ms ("" + keepAliveMS + ""ms + "" + ( keepAliveMSWithGracePeriod - keepAliveMS ) + ""ms grace period)"" ) ; } } catch ( Exception ex ) { LOG . warn ( ""Failed to start MQTT InactivityMonitor "" , ex ) ; } } void handleException ( Throwable exception , MQTTFrame command ) { LOG . warn ( ""Exception occurred processing: \n"" + command + "": "" + exception . toString ( ) ) ; if ( LOG . isDebugEnabled ( ) ) { LOG . debug ( ""Exception detail"" , exception ) ; } try { getMQTTTransport ( ) . stop ( ) ; } catch ( Throwable e ) { LOG . error ( ""Failed to stop MQTTT Transport "" , e ) ; } } void checkConnected ( ) throws MQTTProtocolException { if ( ! connected . get ( ) ) { throw new MQTTProtocolException ( ""Not connected."" ) ; } } private String getClientId ( ) { if ( clientId == null ) { if ( connect != null && connect . clientId ( ) != null ) { clientId = connect . clientId ( ) . toString ( ) ; } else { clientId = """" ; } } return clientId ; } private void stopTransport ( ) { try { getMQTTTransport ( ) . stop ( ) ; } catch ( Throwable e ) { LOG . debug ( ""Failed to stop MQTT transport "" , e ) ; } } ResponseHandler createResponseHandler ( final PUBLISH command ) { if ( command != null ) { switch ( command . qos ( ) ) { case AT_LEAST_ONCE : return new ResponseHandler ( ) { public void onResponse ( MQTTProtocolConverter converter , Response response ) throws IOException { if ( response . isException ( ) ) { LOG . warn ( ""Failed to send MQTT Publish: "" , command , ( ( ExceptionResponse ) response ) . getException ( ) ) ; } else { PUBACK ack = new PUBACK ( ) ; ack . messageId ( command . messageId ( ) ) ; converter . getMQTTTransport ( ) . sendToMQTT ( ack . encode ( ) ) ; } } } ; case EXACTLY_ONCE : return new ResponseHandler ( ) { public void onResponse ( MQTTProtocolConverter converter , Response response ) throws IOException { if ( response . isException ( ) ) { LOG . warn ( ""Failed to send MQTT Publish: "" , command , ( ( ExceptionResponse ) response ) . getException ( ) ) ; } else { PUBREC ack = new PUBREC ( ) ; ack . messageId ( command . messageId ( ) ) ; synchronized ( publisherRecs ) { publisherRecs . put ( command . messageId ( ) , ack ) ; } converter . getMQTTTransport ( ) . sendToMQTT ( ack . encode ( ) ) ; } } } ; case AT_MOST_ONCE : break ; } } return null ; } private String convertMQTTToActiveMQ ( String name ) { String result = name . replace ( '#' , '>' ) ; result = result . replace ( '+' , '*' ) ; result = result . replace ( '/' , '.' ) ; return result ; } public long getDefaultKeepAlive ( ) { return defaultKeepAlive ; } public void setDefaultKeepAlive ( long keepAlive ) { this . defaultKeepAlive = keepAlive ; } public int getActiveMQSubscriptionPrefetch ( ) { return activeMQSubscriptionPrefetch ; } public void setActiveMQSubscriptionPrefetch ( int activeMQSubscriptionPrefetch ) { this . activeMQSubscriptionPrefetch = activeMQSubscriptionPrefetch ; } }",Smelly
"public class JmsBytesMessageTest { private static final int END_OF_STREAM = - 1 ; private final JmsMessageFactory factory = new JmsTestMessageFactory ( ) ; @ Test public void testToString ( ) throws Exception { JmsBytesMessage bytesMessage = factory . createBytesMessage ( ) ; assertTrue ( bytesMessage . toString ( ) . startsWith ( ""JmsBytesMessage"" ) ) ; } @ Test public void testResetOnNewlyPopulatedBytesMessageUpdatesBodyLength ( ) throws Exception { byte [ ] bytes = ""newResetTestBytes"" . getBytes ( ) ; JmsBytesMessage bytesMessage = factory . createBytesMessage ( ) ; bytesMessage . writeBytes ( bytes ) ; bytesMessage . reset ( ) ; assertEquals ( ""Message reports unexpected length"" , bytes . length , bytesMessage . getBodyLength ( ) ) ; } @ Test ( expected = MessageNotReadableException . class ) public void testGetBodyLengthOnNewMessageThrowsMessageNotReadableException ( ) throws Exception { JmsBytesMessage bytesMessage = factory . createBytesMessage ( ) ; bytesMessage . getBodyLength ( ) ; } @ Test public void testReadBytesUsingReceivedMessageWithNoBodyReturnsEOS ( ) throws Exception { JmsBytesMessage bytesMessage = factory . createBytesMessage ( ) ; bytesMessage . onDispatch ( ) ; assertEquals ( ""Expected input stream to be at end but data was returned"" , END_OF_STREAM , bytesMessage . readBytes ( new byte [ 1 ] ) ) ; } @ Test public void testReadBytesUsingReceivedMessageWithBodyReturnsBytes ( ) throws Exception { byte [ ] content = ""myBytesData"" . getBytes ( ) ; JmsTestBytesMessageFacade facade = new JmsTestBytesMessageFacade ( content ) ; JmsBytesMessage bytesMessage = new JmsBytesMessage ( facade ) ; bytesMessage . onDispatch ( ) ; byte [ ] receivedBytes = new byte [ content . length ] ; bytesMessage . readBytes ( receivedBytes ) ; assertTrue ( Arrays . equals ( content , receivedBytes ) ) ; assertEquals ( ""Expected input stream to be at end but data was returned"" , END_OF_STREAM , bytesMessage . readBytes ( new byte [ 1 ] ) ) ; assertEquals ( ""Message reports unexpected length"" , content . length , bytesMessage . getBodyLength ( ) ) ; } @ Test ( expected = MessageNotWriteableException . class ) public void testReceivedBytesMessageThrowsMessageNotWriteableExceptionOnWriteBytes ( ) throws Exception { byte [ ] content = ""myBytesData"" . getBytes ( ) ; JmsTestBytesMessageFacade facade = new JmsTestBytesMessageFacade ( content ) ; JmsBytesMessage bytesMessage = new JmsBytesMessage ( facade ) ; bytesMessage . onDispatch ( ) ; bytesMessage . writeBytes ( content ) ; } @ Test ( expected = MessageNotReadableException . class ) public void testNewBytesMessageThrowsMessageNotReadableOnReadBytes ( ) throws Exception { JmsBytesMessage bytesMessage = factory . createBytesMessage ( ) ; byte [ ] receivedBytes = new byte [ 1 ] ; bytesMessage . readBytes ( receivedBytes ) ; } @ Test public void testClearBodyOnReceivedBytesMessageMakesMessageWritable ( ) throws Exception { byte [ ] content = ""myBytesData"" . getBytes ( ) ; JmsTestBytesMessageFacade facade = new JmsTestBytesMessageFacade ( content ) ; JmsBytesMessage bytesMessage = new JmsBytesMessage ( facade ) ; bytesMessage . onDispatch ( ) ; assertTrue ( ""Message should not be writable"" , bytesMessage . isReadOnlyBody ( ) ) ; bytesMessage . clearBody ( ) ; assertFalse ( ""Message should be writable"" , bytesMessage . isReadOnlyBody ( ) ) ; } @ Test public void testClearBodyOnReceivedBytesMessageClearsFacadeInputStream ( ) throws Exception { byte [ ] content = ""myBytesData"" . getBytes ( ) ; JmsTestBytesMessageFacade facade = new JmsTestBytesMessageFacade ( content ) ; JmsBytesMessage bytesMessage = new JmsBytesMessage ( facade ) ; bytesMessage . onDispatch ( ) ; assertTrue ( ""Expected message content but none was present"" , facade . getBodyLength ( ) > 0 ) ; assertEquals ( ""Expected data from facade"" , 1 , facade . getInputStream ( ) . read ( new byte [ 1 ] ) ) ; bytesMessage . clearBody ( ) ; assertTrue ( ""Expected no message content from facade"" , facade . getBodyLength ( ) == 0 ) ; assertEquals ( ""Expected no data from facade, but got some"" , END_OF_STREAM , facade . getInputStream ( ) . read ( new byte [ 1 ] ) ) ; } @ Test public void testGetBodyLengthOnClearedReceivedMessageThrowsMessageNotReadableException ( ) throws Exception { byte [ ] content = ""myBytesData"" . getBytes ( ) ; JmsTestBytesMessageFacade facade = new JmsTestBytesMessageFacade ( content ) ; JmsBytesMessage bytesMessage = new JmsBytesMessage ( facade ) ; bytesMessage . onDispatch ( ) ; assertEquals ( ""Unexpected message length"" , content . length , bytesMessage . getBodyLength ( ) ) ; bytesMessage . clearBody ( ) ; try { bytesMessage . getBodyLength ( ) ; fail ( ""expected exception to be thrown"" ) ; } catch ( MessageNotReadableException mnre ) { } } @ Test public void testResetOnReceivedBytesMessageResetsMarker ( ) throws Exception { byte [ ] content = ""myBytesData"" . getBytes ( ) ; JmsTestBytesMessageFacade facade = new JmsTestBytesMessageFacade ( content ) ; JmsBytesMessage bytesMessage = new JmsBytesMessage ( facade ) ; bytesMessage . onDispatch ( ) ; byte [ ] partialBytes = new byte [ 3 ] ; bytesMessage . readBytes ( partialBytes ) ; byte [ ] partialOriginalBytes = Arrays . copyOf ( content , 3 ) ; assertTrue ( Arrays . equals ( partialOriginalBytes , partialBytes ) ) ; bytesMessage . reset ( ) ; byte [ ] resetBytes = new byte [ content . length ] ; bytesMessage . readBytes ( resetBytes ) ; assertTrue ( Arrays . equals ( content , resetBytes ) ) ; } @ Test public void testResetOnNewlyPopulatedBytesMessageResetsMarkerAndMakesReadable ( ) throws Exception { byte [ ] content = ""myBytesData"" . getBytes ( ) ; JmsTestBytesMessageFacade facade = new JmsTestBytesMessageFacade ( content ) ; JmsBytesMessage bytesMessage = new JmsBytesMessage ( facade ) ; assertFalse ( ""Message should be writable"" , bytesMessage . isReadOnlyBody ( ) ) ; bytesMessage . writeBytes ( content ) ; bytesMessage . reset ( ) ; assertTrue ( ""Message should not be writable"" , bytesMessage . isReadOnlyBody ( ) ) ; byte [ ] resetBytes = new byte [ content . length ] ; bytesMessage . readBytes ( resetBytes ) ; assertTrue ( Arrays . equals ( content , resetBytes ) ) ; } @ Test public void testReadBytesWithZeroLengthDestination ( ) throws Exception { JmsBytesMessage bytesMessage = factory . createBytesMessage ( ) ; bytesMessage . reset ( ) ; assertEquals ( ""Did not expect any bytes to be read"" , 0 , bytesMessage . readBytes ( new byte [ 0 ] ) ) ; } @ Test ( expected = IndexOutOfBoundsException . class ) public void testReadBytesWithNegativeLengthThrowsIOOBE ( ) throws Exception { JmsBytesMessage bytesMessage = factory . createBytesMessage ( ) ; bytesMessage . reset ( ) ; bytesMessage . readBytes ( new byte [ 0 ] , - 1 ) ; } @ Test ( expected = IndexOutOfBoundsException . class ) public void testReadBytesWithLengthGreatThanArraySizeThrowsIOOBE ( ) throws Exception { JmsBytesMessage bytesMessage = factory . createBytesMessage ( ) ; bytesMessage . reset ( ) ; bytesMessage . readBytes ( new byte [ 1 ] , 2 ) ; } @ Test ( expected = NullPointerException . class ) public void testWriteObjectWithNullThrowsNPE ( ) throws Exception { JmsBytesMessage bytesMessage = factory . createBytesMessage ( ) ; bytesMessage . writeObject ( null ) ; } @ Test ( expected = MessageFormatException . class ) public void testWriteObjectWithIllegalTypeThrowsMFE ( ) throws Exception { JmsBytesMessage bytesMessage = factory . createBytesMessage ( ) ; bytesMessage . writeObject ( new Object ( ) ) ; } @ Test public void testGetBodyLength ( ) throws JMSException { JmsBytesMessage msg = factory . createBytesMessage ( ) ; int len = 10 ; for ( int i = 0 ; i < len ; i ++ ) { msg . writeLong ( 5L ) ; } msg . reset ( ) ; assertTrue ( msg . getBodyLength ( ) == ( len * 8 ) ) ; } @ Test public void testReadBoolean ( ) throws JMSException { JmsBytesMessage msg = factory . createBytesMessage ( ) ; msg . writeBoolean ( true ) ; msg . reset ( ) ; assertTrue ( msg . readBoolean ( ) ) ; } @ Test public void testReadByte ( ) throws JMSException { JmsBytesMessage msg = factory . createBytesMessage ( ) ; msg . writeByte ( ( byte ) 2 ) ; msg . reset ( ) ; assertTrue ( msg . readByte ( ) == 2 ) ; } @ Test public void testReadUnsignedByte ( ) throws JMSException { JmsBytesMessage msg = factory . createBytesMessage ( ) ; msg . writeByte ( ( byte ) 2 ) ; msg . reset ( ) ; assertTrue ( msg . readUnsignedByte ( ) == 2 ) ; } @ Test public void testReadShort ( ) throws JMSException { JmsBytesMessage msg = factory . createBytesMessage ( ) ; msg . writeShort ( ( short ) 3000 ) ; msg . reset ( ) ; assertTrue ( msg . readShort ( ) == 3000 ) ; } @ Test public void testReadUnsignedShort ( ) throws JMSException { JmsBytesMessage msg = factory . createBytesMessage ( ) ; msg . writeShort ( ( short ) 3000 ) ; msg . reset ( ) ; assertTrue ( msg . readUnsignedShort ( ) == 3000 ) ; } @ Test public void testReadChar ( ) throws JMSException { JmsBytesMessage msg = factory . createBytesMessage ( ) ; msg . writeChar ( 'a' ) ; msg . reset ( ) ; assertTrue ( msg . readChar ( ) == 'a' ) ; } @ Test public void testReadInt ( ) throws JMSException { JmsBytesMessage msg = factory . createBytesMessage ( ) ; msg . writeInt ( 3000 ) ; msg . reset ( ) ; assertTrue ( msg . readInt ( ) == 3000 ) ; } @ Test public void testReadLong ( ) throws JMSException { JmsBytesMessage msg = factory . createBytesMessage ( ) ; msg . writeLong ( 3000 ) ; msg . reset ( ) ; assertTrue ( msg . readLong ( ) == 3000 ) ; } @ Test public void testReadFloat ( ) throws JMSException { JmsBytesMessage msg = factory . createBytesMessage ( ) ; msg . writeFloat ( 3.3f ) ; msg . reset ( ) ; assertTrue ( msg . readFloat ( ) == 3.3f ) ; } @ Test public void testReadDouble ( ) throws JMSException { JmsBytesMessage msg = factory . createBytesMessage ( ) ; msg . writeDouble ( 3.3d ) ; msg . reset ( ) ; assertTrue ( msg . readDouble ( ) == 3.3d ) ; } @ Test public void testReadUTF ( ) throws JMSException { JmsBytesMessage msg = factory . createBytesMessage ( ) ; String str = ""this is a test"" ; msg . writeUTF ( str ) ; msg . reset ( ) ; assertTrue ( msg . readUTF ( ) . equals ( str ) ) ; } @ Test public void testReadBytesbyteArray ( ) throws JMSException { JmsBytesMessage msg = factory . createBytesMessage ( ) ; byte [ ] data = new byte [ 50 ] ; for ( int i = 0 ; i < data . length ; i ++ ) { data [ i ] = ( byte ) i ; } msg . writeBytes ( data ) ; msg . reset ( ) ; byte [ ] test = new byte [ data . length ] ; msg . readBytes ( test ) ; for ( int i = 0 ; i < test . length ; i ++ ) { assertTrue ( test [ i ] == i ) ; } } @ Test public void testWriteObject ( ) throws JMSException { JmsBytesMessage msg = factory . createBytesMessage ( ) ; try { msg . writeObject ( ""fred"" ) ; msg . writeObject ( Boolean . TRUE ) ; msg . writeObject ( Character . valueOf ( 'q' ) ) ; msg . writeObject ( Byte . valueOf ( ( byte ) 1 ) ) ; msg . writeObject ( Short . valueOf ( ( short ) 3 ) ) ; msg . writeObject ( Integer . valueOf ( 3 ) ) ; msg . writeObject ( Long . valueOf ( 300L ) ) ; msg . writeObject ( new Float ( 3.3f ) ) ; msg . writeObject ( new Double ( 3.3 ) ) ; msg . writeObject ( new byte [ 3 ] ) ; } catch ( MessageFormatException mfe ) { fail ( ""objectified primitives should be allowed"" ) ; } try { msg . writeObject ( new Object ( ) ) ; fail ( ""only objectified primitives are allowed"" ) ; } catch ( MessageFormatException mfe ) { } } @ Test public void testClearBodyOnNewMessage ( ) throws JMSException { JmsBytesMessage bytesMessage = factory . createBytesMessage ( ) ; bytesMessage . writeInt ( 1 ) ; bytesMessage . clearBody ( ) ; assertFalse ( bytesMessage . isReadOnlyBody ( ) ) ; bytesMessage . reset ( ) ; assertEquals ( 0 , bytesMessage . getBodyLength ( ) ) ; } @ Test public void testReset ( ) throws JMSException { JmsBytesMessage message = factory . createBytesMessage ( ) ; try { message . writeDouble ( 24.5 ) ; message . writeLong ( 311 ) ; } catch ( MessageNotWriteableException mnwe ) { fail ( ""should be writeable"" ) ; } message . reset ( ) ; try { assertTrue ( message . isReadOnlyBody ( ) ) ; assertEquals ( message . readDouble ( ) , 24.5 , 0 ) ; assertEquals ( message . readLong ( ) , 311 ) ; } catch ( MessageNotReadableException mnre ) { fail ( ""should be readable"" ) ; } try { message . writeInt ( 33 ) ; fail ( ""should throw exception"" ) ; } catch ( MessageNotWriteableException mnwe ) { } } @ Test public void testReadOnlyBody ( ) throws JMSException { JmsBytesMessage message = factory . createBytesMessage ( ) ; try { message . writeBoolean ( true ) ; message . writeByte ( ( byte ) 1 ) ; message . writeByte ( ( byte ) 1 ) ; message . writeBytes ( new byte [ 1 ] ) ; message . writeBytes ( new byte [ 3 ] , 0 , 2 ) ; message . writeChar ( 'a' ) ; message . writeDouble ( 1.5 ) ; message . writeFloat ( ( float ) 1.5 ) ; message . writeInt ( 1 ) ; message . writeLong ( 1 ) ; message . writeObject ( ""stringobj"" ) ; message . writeShort ( ( short ) 1 ) ; message . writeShort ( ( short ) 1 ) ; message . writeUTF ( ""utfstring"" ) ; } catch ( MessageNotWriteableException mnwe ) { fail ( ""Should be writeable"" ) ; } message . reset ( ) ; try { message . readBoolean ( ) ; message . readByte ( ) ; message . readUnsignedByte ( ) ; message . readBytes ( new byte [ 1 ] ) ; message . readBytes ( new byte [ 2 ] , 2 ) ; message . readChar ( ) ; message . readDouble ( ) ; message . readFloat ( ) ; message . readInt ( ) ; message . readLong ( ) ; message . readUTF ( ) ; message . readShort ( ) ; message . readUnsignedShort ( ) ; message . readUTF ( ) ; } catch ( MessageNotReadableException mnwe ) { fail ( ""Should be readable"" ) ; } try { message . writeBoolean ( true ) ; fail ( ""Should have thrown exception"" ) ; } catch ( MessageNotWriteableException mnwe ) { } try { message . writeByte ( ( byte ) 1 ) ; fail ( ""Should have thrown exception"" ) ; } catch ( MessageNotWriteableException mnwe ) { } try { message . writeBytes ( new byte [ 1 ] ) ; fail ( ""Should have thrown exception"" ) ; } catch ( MessageNotWriteableException mnwe ) { } try { message . writeBytes ( new byte [ 3 ] , 0 , 2 ) ; fail ( ""Should have thrown exception"" ) ; } catch ( MessageNotWriteableException mnwe ) { } try { message . writeChar ( 'a' ) ; fail ( ""Should have thrown exception"" ) ; } catch ( MessageNotWriteableException mnwe ) { } try { message . writeDouble ( 1.5 ) ; fail ( ""Should have thrown exception"" ) ; } catch ( MessageNotWriteableException mnwe ) { } try { message . writeFloat ( ( float ) 1.5 ) ; fail ( ""Should have thrown exception"" ) ; } catch ( MessageNotWriteableException mnwe ) { } try { message . writeInt ( 1 ) ; fail ( ""Should have thrown exception"" ) ; } catch ( MessageNotWriteableException mnwe ) { } try { message . writeLong ( 1 ) ; fail ( ""Should have thrown exception"" ) ; } catch ( MessageNotWriteableException mnwe ) { } try { message . writeObject ( ""stringobj"" ) ; fail ( ""Should have thrown exception"" ) ; } catch ( MessageNotWriteableException mnwe ) { } try { message . writeShort ( ( short ) 1 ) ; fail ( ""Should have thrown exception"" ) ; } catch ( MessageNotWriteableException mnwe ) { } try { message . writeUTF ( ""utfstring"" ) ; fail ( ""Should have thrown exception"" ) ; } catch ( MessageNotWriteableException mnwe ) { } } @ Test public void testWriteOnlyBody ( ) throws JMSException { JmsBytesMessage message = factory . createBytesMessage ( ) ; message . clearBody ( ) ; try { message . writeBoolean ( true ) ; message . writeByte ( ( byte ) 1 ) ; message . writeByte ( ( byte ) 1 ) ; message . writeBytes ( new byte [ 1 ] ) ; message . writeBytes ( new byte [ 3 ] , 0 , 2 ) ; message . writeChar ( 'a' ) ; message . writeDouble ( 1.5 ) ; message . writeFloat ( ( float ) 1.5 ) ; message . writeInt ( 1 ) ; message . writeLong ( 1 ) ; message . writeObject ( ""stringobj"" ) ; message . writeShort ( ( short ) 1 ) ; message . writeShort ( ( short ) 1 ) ; message . writeUTF ( ""utfstring"" ) ; } catch ( MessageNotWriteableException mnwe ) { fail ( ""Should be writeable"" ) ; } try { message . readBoolean ( ) ; fail ( ""Should have thrown exception"" ) ; } catch ( MessageNotReadableException mnwe ) { } try { message . readByte ( ) ; fail ( ""Should have thrown exception"" ) ; } catch ( MessageNotReadableException e ) { } try { message . readUnsignedByte ( ) ; fail ( ""Should have thrown exception"" ) ; } catch ( MessageNotReadableException e ) { } try { message . readBytes ( new byte [ 1 ] ) ; fail ( ""Should have thrown exception"" ) ; } catch ( MessageNotReadableException e ) { } try { message . readBytes ( new byte [ 2 ] , 2 ) ; fail ( ""Should have thrown exception"" ) ; } catch ( MessageNotReadableException e ) { } try { message . readChar ( ) ; fail ( ""Should have thrown exception"" ) ; } catch ( MessageNotReadableException e ) { } try { message . readDouble ( ) ; fail ( ""Should have thrown exception"" ) ; } catch ( MessageNotReadableException e ) { } try { message . readFloat ( ) ; fail ( ""Should have thrown exception"" ) ; } catch ( MessageNotReadableException e ) { } try { message . readInt ( ) ; fail ( ""Should have thrown exception"" ) ; } catch ( MessageNotReadableException e ) { } try { message . readLong ( ) ; fail ( ""Should have thrown exception"" ) ; } catch ( MessageNotReadableException e ) { } try { message . readUTF ( ) ; fail ( ""Should have thrown exception"" ) ; } catch ( MessageNotReadableException e ) { } try { message . readShort ( ) ; fail ( ""Should have thrown exception"" ) ; } catch ( MessageNotReadableException e ) { } try { message . readUnsignedShort ( ) ; fail ( ""Should have thrown exception"" ) ; } catch ( MessageNotReadableException e ) { } try { message . readUTF ( ) ; fail ( ""Should have thrown exception"" ) ; } catch ( MessageNotReadableException e ) { } } @ Test public void testReadMethodsCaptureEOFExceptionThrowsMessageEOFEx ( ) throws Exception { JmsBytesMessageFacade facade = Mockito . mock ( JmsBytesMessageFacade . class ) ; InputStream bytesIn = Mockito . mock ( InputStream . class ) ; Mockito . when ( facade . getInputStream ( ) ) . thenReturn ( bytesIn ) ; Mockito . when ( bytesIn . read ( ) ) . thenThrow ( new EOFException ( ) ) ; Mockito . when ( bytesIn . read ( Mockito . any ( byte [ ] . class ) ) ) . thenThrow ( new EOFException ( ) ) ; Mockito . when ( bytesIn . read ( Mockito . any ( byte [ ] . class ) , Mockito . anyInt ( ) , Mockito . anyInt ( ) ) ) . thenThrow ( new EOFException ( ) ) ; JmsBytesMessage message = new JmsBytesMessage ( facade ) ; message . reset ( ) ; try { message . readBoolean ( ) ; } catch ( MessageEOFException ex ) { assertTrue ( ex . getCause ( ) instanceof EOFException ) ; } try { message . readByte ( ) ; } catch ( MessageEOFException ex ) { assertTrue ( ex . getCause ( ) instanceof EOFException ) ; } try { message . readBytes ( new byte [ 10 ] ) ; } catch ( MessageEOFException ex ) { assertTrue ( ex . getCause ( ) instanceof EOFException ) ; } try { message . readBytes ( new byte [ 10 ] , 10 ) ; } catch ( MessageEOFException ex ) { assertTrue ( ex . getCause ( ) instanceof EOFException ) ; } try { message . readChar ( ) ; } catch ( MessageEOFException ex ) { assertTrue ( ex . getCause ( ) instanceof EOFException ) ; } try { message . readDouble ( ) ; } catch ( MessageEOFException ex ) { assertTrue ( ex . getCause ( ) instanceof EOFException ) ; } try { message . readFloat ( ) ; } catch ( MessageEOFException ex ) { assertTrue ( ex . getCause ( ) instanceof EOFException ) ; } try { message . readInt ( ) ; } catch ( MessageEOFException ex ) { assertTrue ( ex . getCause ( ) instanceof EOFException ) ; } try { message . readLong ( ) ; } catch ( MessageEOFException ex ) { assertTrue ( ex . getCause ( ) instanceof EOFException ) ; } try { message . readShort ( ) ; } catch ( MessageEOFException ex ) { assertTrue ( ex . getCause ( ) instanceof EOFException ) ; } try { message . readUnsignedByte ( ) ; } catch ( MessageEOFException ex ) { assertTrue ( ex . getCause ( ) instanceof EOFException ) ; } try { message . readUnsignedShort ( ) ; } catch ( MessageEOFException ex ) { assertTrue ( ex . getCause ( ) instanceof EOFException ) ; } try { message . readUTF ( ) ; } catch ( MessageEOFException ex ) { assertTrue ( ex . getCause ( ) instanceof EOFException ) ; } } @ Test public void testReadMethodsCaptureIOExceptionThrowsJMSEx ( ) throws Exception { JmsBytesMessageFacade facade = Mockito . mock ( JmsBytesMessageFacade . class ) ; InputStream bytesIn = Mockito . mock ( InputStream . class ) ; Mockito . when ( facade . getInputStream ( ) ) . thenReturn ( bytesIn ) ; Mockito . when ( bytesIn . read ( ) ) . thenThrow ( new IOException ( ) ) ; Mockito . when ( bytesIn . read ( Mockito . any ( byte [ ] . class ) ) ) . thenThrow ( new IOException ( ) ) ; Mockito . when ( bytesIn . read ( Mockito . any ( byte [ ] . class ) , Mockito . anyInt ( ) , Mockito . anyInt ( ) ) ) . thenThrow ( new IOException ( ) ) ; JmsBytesMessage message = new JmsBytesMessage ( facade ) ; message . reset ( ) ; try { message . readBoolean ( ) ; } catch ( JMSException ex ) { assertTrue ( ex . getCause ( ) instanceof IOException ) ; } try { message . readByte ( ) ; } catch ( JMSException ex ) { assertTrue ( ex . getCause ( ) instanceof IOException ) ; } try { message . readBytes ( new byte [ 10 ] ) ; } catch ( JMSException ex ) { assertTrue ( ex . getCause ( ) instanceof IOException ) ; } try { message . readBytes ( new byte [ 10 ] , 10 ) ; } catch ( JMSException ex ) { assertTrue ( ex . getCause ( ) instanceof IOException ) ; } try { message . readChar ( ) ; } catch ( JMSException ex ) { assertTrue ( ex . getCause ( ) instanceof IOException ) ; } try { message . readDouble ( ) ; } catch ( JMSException ex ) { assertTrue ( ex . getCause ( ) instanceof IOException ) ; } try { message . readFloat ( ) ; } catch ( JMSException ex ) { assertTrue ( ex . getCause ( ) instanceof IOException ) ; } try { message . readInt ( ) ; } catch ( JMSException ex ) { assertTrue ( ex . getCause ( ) instanceof IOException ) ; } try { message . readLong ( ) ; } catch ( JMSException ex ) { assertTrue ( ex . getCause ( ) instanceof IOException ) ; } try { message . readShort ( ) ; } catch ( JMSException ex ) { assertTrue ( ex . getCause ( ) instanceof IOException ) ; } try { message . readUnsignedByte ( ) ; } catch ( JMSException ex ) { assertTrue ( ex . getCause ( ) instanceof IOException ) ; } try { message . readUnsignedShort ( ) ; } catch ( JMSException ex ) { assertTrue ( ex . getCause ( ) instanceof IOException ) ; } try { message . readUTF ( ) ; } catch ( JMSException ex ) { assertTrue ( ex . getCause ( ) instanceof IOException ) ; } } @ Test public void testWriteMethodsCaptureIOExceptionThrowsJMSEx ( ) throws Exception { JmsBytesMessageFacade facade = Mockito . mock ( JmsBytesMessageFacade . class ) ; OutputStream bytesOut = Mockito . mock ( OutputStream . class ) ; Mockito . when ( facade . getOutputStream ( ) ) . thenReturn ( bytesOut ) ; Mockito . doThrow ( new IOException ( ) ) . when ( bytesOut ) . write ( Mockito . anyByte ( ) ) ; Mockito . doThrow ( new IOException ( ) ) . when ( bytesOut ) . write ( Mockito . any ( byte [ ] . class ) ) ; Mockito . doThrow ( new IOException ( ) ) . when ( bytesOut ) . write ( Mockito . any ( byte [ ] . class ) , Mockito . anyInt ( ) , Mockito . anyInt ( ) ) ; JmsBytesMessage message = new JmsBytesMessage ( facade ) ; try { message . writeBoolean ( false ) ; } catch ( JMSException ex ) { assertTrue ( ex . getCause ( ) instanceof IOException ) ; } try { message . writeByte ( ( byte ) 128 ) ; } catch ( JMSException ex ) { assertTrue ( ex . getCause ( ) instanceof IOException ) ; } try { message . writeBytes ( new byte [ 10 ] ) ; } catch ( JMSException ex ) { assertTrue ( ex . getCause ( ) instanceof IOException ) ; } try { message . writeBytes ( new byte [ 10 ] , 0 , 10 ) ; } catch ( JMSException ex ) { assertTrue ( ex . getCause ( ) instanceof IOException ) ; } try { message . writeChar ( 'a' ) ; } catch ( JMSException ex ) { assertTrue ( ex . getCause ( ) instanceof IOException ) ; } try { message . writeDouble ( 100.0 ) ; } catch ( JMSException ex ) { assertTrue ( ex . getCause ( ) instanceof IOException ) ; } try { message . writeFloat ( 10.2f ) ; } catch ( JMSException ex ) { assertTrue ( ex . getCause ( ) instanceof IOException ) ; } try { message . writeInt ( 125 ) ; } catch ( JMSException ex ) { assertTrue ( ex . getCause ( ) instanceof IOException ) ; } try { message . writeLong ( 65536L ) ; } catch ( JMSException ex ) { assertTrue ( ex . getCause ( ) instanceof IOException ) ; } try { message . writeObject ( """" ) ; } catch ( JMSException ex ) { assertTrue ( ex . getCause ( ) instanceof IOException ) ; } try { message . writeShort ( ( short ) 32768 ) ; } catch ( JMSException ex ) { assertTrue ( ex . getCause ( ) instanceof IOException ) ; } try { message . writeUTF ( """" ) ; } catch ( JMSException ex ) { assertTrue ( ex . getCause ( ) instanceof IOException ) ; } } @ Test public void testHashCode ( ) throws Exception { String messageId = ""ID:SOME-ID:0:1:1"" ; JmsBytesMessage message = factory . createBytesMessage ( ) ; message . setJMSMessageID ( messageId ) ; assertEquals ( message . getJMSMessageID ( ) . hashCode ( ) , messageId . hashCode ( ) ) ; assertEquals ( message . hashCode ( ) , messageId . hashCode ( ) ) ; } @ Test public void testEqualsObject ( ) throws Exception { String messageId = ""ID:SOME-ID:0:1:1"" ; JmsBytesMessage message1 = factory . createBytesMessage ( ) ; JmsBytesMessage message2 = factory . createBytesMessage ( ) ; message1 . setJMSMessageID ( messageId ) ; assertTrue ( ! message1 . equals ( message2 ) ) ; assertTrue ( ! message2 . equals ( message1 ) ) ; message2 . setJMSMessageID ( messageId ) ; assertTrue ( message1 . equals ( message2 ) ) ; assertTrue ( message2 . equals ( message1 ) ) ; message2 . setJMSMessageID ( messageId + ""More"" ) ; assertTrue ( ! message1 . equals ( message2 ) ) ; assertTrue ( ! message2 . equals ( message1 ) ) ; assertTrue ( message1 . equals ( message1 ) ) ; assertFalse ( message1 . equals ( null ) ) ; assertFalse ( message1 . equals ( """" ) ) ; } }",Smelly
"public class PerceptronTrainer extends AbstractEventTrainer { public static final String PERCEPTRON_VALUE = ""PERCEPTRON"" ; public static final double TOLERANCE_DEFAULT = .00001 ; private int numUniqueEvents ; private int numEvents ; private int numPreds ; private int numOutcomes ; private int [ ] [ ] contexts ; private float [ ] [ ] values ; private int [ ] outcomeList ; private int [ ] numTimesEventsSeen ; private String [ ] outcomeLabels ; private String [ ] predLabels ; private double tolerance = TOLERANCE_DEFAULT ; private Double stepSizeDecrease ; private boolean useSkippedlAveraging ; public PerceptronTrainer ( ) { } public PerceptronTrainer ( TrainingParameters parameters ) { super ( parameters ) ; } public boolean isValid ( ) { String algorithmName = getAlgorithm ( ) ; return ! ( algorithmName != null && ! ( PERCEPTRON_VALUE . equals ( algorithmName ) ) ) ; } public boolean isSortAndMerge ( ) { return false ; } public AbstractModel doTrain ( DataIndexer indexer ) throws IOException { if ( ! isValid ( ) ) { throw new IllegalArgumentException ( ""trainParams are not valid!"" ) ; } int iterations = getIterations ( ) ; int cutoff = getCutoff ( ) ; AbstractModel model ; boolean useAverage = trainingParameters . getBooleanParameter ( ""UseAverage"" , true ) ; boolean useSkippedAveraging = trainingParameters . getBooleanParameter ( ""UseSkippedAveraging"" , false ) ; if ( useSkippedAveraging ) useAverage = true ; double stepSizeDecrease = trainingParameters . getDoubleParameter ( ""StepSizeDecrease"" , 0 ) ; double tolerance = trainingParameters . getDoubleParameter ( ""Tolerance"" , PerceptronTrainer . TOLERANCE_DEFAULT ) ; this . setSkippedAveraging ( useSkippedAveraging ) ; if ( stepSizeDecrease > 0 ) this . setStepSizeDecrease ( stepSizeDecrease ) ; this . setTolerance ( tolerance ) ; model = this . trainModel ( iterations , indexer , cutoff , useAverage ) ; return model ; } public void setTolerance ( double tolerance ) { if ( tolerance < 0 ) { throw new IllegalArgumentException ( ""tolerance must be a positive number but is "" + tolerance + ""!"" ) ; } this . tolerance = tolerance ; } public void setStepSizeDecrease ( double decrease ) { if ( decrease < 0 || decrease > 100 ) { throw new IllegalArgumentException ( ""decrease must be between 0 and 100 but is "" + decrease + ""!"" ) ; } stepSizeDecrease = decrease ; } public void setSkippedAveraging ( boolean averaging ) { useSkippedlAveraging = averaging ; } public AbstractModel trainModel ( int iterations , DataIndexer di , int cutoff ) { return trainModel ( iterations , di , cutoff , true ) ; } public AbstractModel trainModel ( int iterations , DataIndexer di , int cutoff , boolean useAverage ) { display ( ""Incorporating indexed data for training...  \n"" ) ; contexts = di . getContexts ( ) ; values = di . getValues ( ) ; numTimesEventsSeen = di . getNumTimesEventsSeen ( ) ; numEvents = di . getNumEvents ( ) ; numUniqueEvents = contexts . length ; outcomeLabels = di . getOutcomeLabels ( ) ; outcomeList = di . getOutcomeList ( ) ; predLabels = di . getPredLabels ( ) ; numPreds = predLabels . length ; numOutcomes = outcomeLabels . length ; display ( ""done.\n"" ) ; display ( ""\tNumber of Event Tokens: "" + numUniqueEvents + ""\n"" ) ; display ( ""\t    Number of Outcomes: "" + numOutcomes + ""\n"" ) ; display ( ""\t  Number of Predicates: "" + numPreds + ""\n"" ) ; display ( ""Computing model parameters...\n"" ) ; MutableContext [ ] finalParameters = findParameters ( iterations , useAverage ) ; display ( ""...done.\n"" ) ; return new PerceptronModel ( finalParameters , predLabels , outcomeLabels ) ; } private MutableContext [ ] findParameters ( int iterations , boolean useAverage ) { display ( ""Performing "" + iterations + "" iterations.\n"" ) ; int [ ] allOutcomesPattern = new int [ numOutcomes ] ; for ( int oi = 0 ; oi < numOutcomes ; oi ++ ) allOutcomesPattern [ oi ] = oi ; MutableContext [ ] params = new MutableContext [ numPreds ] ; for ( int pi = 0 ; pi < numPreds ; pi ++ ) { params [ pi ] = new MutableContext ( allOutcomesPattern , new double [ numOutcomes ] ) ; for ( int aoi = 0 ; aoi < numOutcomes ; aoi ++ ) params [ pi ] . setParameter ( aoi , 0.0 ) ; } EvalParameters evalParams = new EvalParameters ( params , numOutcomes ) ; MutableContext [ ] summedParams = new MutableContext [ numPreds ] ; if ( useAverage ) { for ( int pi = 0 ; pi < numPreds ; pi ++ ) { summedParams [ pi ] = new MutableContext ( allOutcomesPattern , new double [ numOutcomes ] ) ; for ( int aoi = 0 ; aoi < numOutcomes ; aoi ++ ) summedParams [ pi ] . setParameter ( aoi , 0.0 ) ; } } double prevAccuracy1 = 0.0 ; double prevAccuracy2 = 0.0 ; double prevAccuracy3 = 0.0 ; int numTimesSummed = 0 ; double stepsize = 1 ; for ( int i = 1 ; i <= iterations ; i ++ ) { if ( stepSizeDecrease != null ) stepsize *= 1 - stepSizeDecrease ; displayIteration ( i ) ; int numCorrect = 0 ; for ( int ei = 0 ; ei < numUniqueEvents ; ei ++ ) { int targetOutcome = outcomeList [ ei ] ; for ( int ni = 0 ; ni < this . numTimesEventsSeen [ ei ] ; ni ++ ) { double [ ] modelDistribution = new double [ numOutcomes ] ; if ( values != null ) PerceptronModel . eval ( contexts [ ei ] , values [ ei ] , modelDistribution , evalParams , false ) ; else PerceptronModel . eval ( contexts [ ei ] , null , modelDistribution , evalParams , false ) ; int maxOutcome = maxIndex ( modelDistribution ) ; if ( maxOutcome != targetOutcome ) { for ( int ci = 0 ; ci < contexts [ ei ] . length ; ci ++ ) { int pi = contexts [ ei ] [ ci ] ; if ( values == null ) { params [ pi ] . updateParameter ( targetOutcome , stepsize ) ; params [ pi ] . updateParameter ( maxOutcome , - stepsize ) ; } else { params [ pi ] . updateParameter ( targetOutcome , stepsize * values [ ei ] [ ci ] ) ; params [ pi ] . updateParameter ( maxOutcome , - stepsize * values [ ei ] [ ci ] ) ; } } } if ( maxOutcome == targetOutcome ) numCorrect ++ ; } } double trainingAccuracy = ( double ) numCorrect / numEvents ; if ( i < 10 || ( i % 10 ) == 0 ) display ( "". ("" + numCorrect + ""/"" + numEvents + "") "" + trainingAccuracy + ""\n"" ) ; boolean doAveraging ; doAveraging = useAverage && useSkippedlAveraging && ( i < 20 || isPerfectSquare ( i ) ) || useAverage ; if ( doAveraging ) { numTimesSummed ++ ; for ( int pi = 0 ; pi < numPreds ; pi ++ ) for ( int aoi = 0 ; aoi < numOutcomes ; aoi ++ ) summedParams [ pi ] . updateParameter ( aoi , params [ pi ] . getParameters ( ) [ aoi ] ) ; } if ( Math . abs ( prevAccuracy1 - trainingAccuracy ) < tolerance && Math . abs ( prevAccuracy2 - trainingAccuracy ) < tolerance && Math . abs ( prevAccuracy3 - trainingAccuracy ) < tolerance ) { display ( ""Stopping: change in training set accuracy less than "" + tolerance + ""\n"" ) ; break ; } prevAccuracy1 = prevAccuracy2 ; prevAccuracy2 = prevAccuracy3 ; prevAccuracy3 = trainingAccuracy ; } trainingStats ( evalParams ) ; if ( useAverage ) { for ( int pi = 0 ; pi < numPreds ; pi ++ ) for ( int aoi = 0 ; aoi < numOutcomes ; aoi ++ ) summedParams [ pi ] . setParameter ( aoi , summedParams [ pi ] . getParameters ( ) [ aoi ] / numTimesSummed ) ; return summedParams ; } else { return params ; } } private double trainingStats ( EvalParameters evalParams ) { int numCorrect = 0 ; for ( int ei = 0 ; ei < numUniqueEvents ; ei ++ ) { for ( int ni = 0 ; ni < this . numTimesEventsSeen [ ei ] ; ni ++ ) { double [ ] modelDistribution = new double [ numOutcomes ] ; if ( values != null ) PerceptronModel . eval ( contexts [ ei ] , values [ ei ] , modelDistribution , evalParams , false ) ; else PerceptronModel . eval ( contexts [ ei ] , null , modelDistribution , evalParams , false ) ; int max = maxIndex ( modelDistribution ) ; if ( max == outcomeList [ ei ] ) numCorrect ++ ; } } double trainingAccuracy = ( double ) numCorrect / numEvents ; display ( ""Stats: ("" + numCorrect + ""/"" + numEvents + "") "" + trainingAccuracy + ""\n"" ) ; return trainingAccuracy ; } private int maxIndex ( double [ ] values ) { int max = 0 ; for ( int i = 1 ; i < values . length ; i ++ ) if ( values [ i ] > values [ max ] ) max = i ; return max ; } private void displayIteration ( int i ) { if ( i > 10 && ( i % 10 ) != 0 ) return ; if ( i < 10 ) display ( ""  "" + i + "":  "" ) ; else if ( i < 100 ) display ( "" "" + i + "":  "" ) ; else display ( i + "":  "" ) ; } private static boolean isPerfectSquare ( int n ) { int root = ( int ) Math . sqrt ( n ) ; return root * root == n ; } }",Smelly
"public class IncludeFilterExecuterImpl implements FilterExecuter { protected DimColumnResolvedFilterInfo dimColumnEvaluatorInfo ; DimColumnExecuterFilterInfo dimColumnExecuterInfo ; private MeasureColumnResolvedFilterInfo msrColumnEvaluatorInfo ; private MeasureColumnExecuterFilterInfo msrColumnExecutorInfo ; protected SegmentProperties segmentProperties ; private boolean isDimensionPresentInCurrentBlock = false ; private boolean isMeasurePresentInCurrentBlock = false ; protected SerializableComparator comparator ; private boolean isNaturalSorted = false ; private byte [ ] [ ] filterValues ; private FilterBitSetUpdater filterBitSetUpdater ; public IncludeFilterExecuterImpl ( byte [ ] [ ] filterValues , boolean isNaturalSorted ) { this . filterValues = filterValues ; this . isNaturalSorted = isNaturalSorted ; this . filterBitSetUpdater = BitSetUpdaterFactory . INSTANCE . getBitSetUpdater ( FilterExecuterType . INCLUDE ) ; } public IncludeFilterExecuterImpl ( DimColumnResolvedFilterInfo dimColumnEvaluatorInfo , MeasureColumnResolvedFilterInfo msrColumnEvaluatorInfo , SegmentProperties segmentProperties , boolean isMeasure ) { this . filterBitSetUpdater = BitSetUpdaterFactory . INSTANCE . getBitSetUpdater ( FilterExecuterType . INCLUDE ) ; this . segmentProperties = segmentProperties ; if ( ! isMeasure ) { this . dimColumnEvaluatorInfo = dimColumnEvaluatorInfo ; dimColumnExecuterInfo = new DimColumnExecuterFilterInfo ( ) ; FilterUtil . prepareKeysFromSurrogates ( dimColumnEvaluatorInfo . getFilterValues ( ) , segmentProperties , dimColumnEvaluatorInfo . getDimension ( ) , dimColumnExecuterInfo , null , null ) ; isDimensionPresentInCurrentBlock = true ; isNaturalSorted = dimColumnEvaluatorInfo . getDimension ( ) . isUseInvertedIndex ( ) && dimColumnEvaluatorInfo . getDimension ( ) . isSortColumn ( ) ; } else { this . msrColumnEvaluatorInfo = msrColumnEvaluatorInfo ; msrColumnExecutorInfo = new MeasureColumnExecuterFilterInfo ( ) ; comparator = Comparator . getComparatorByDataTypeForMeasure ( FilterUtil . getMeasureDataType ( msrColumnEvaluatorInfo ) ) ; FilterUtil . prepareKeysFromSurrogates ( msrColumnEvaluatorInfo . getFilterValues ( ) , segmentProperties , null , null , msrColumnEvaluatorInfo . getMeasure ( ) , msrColumnExecutorInfo ) ; isMeasurePresentInCurrentBlock = true ; } } @ Override public BitSetGroup applyFilter ( RawBlockletColumnChunks rawBlockletColumnChunks , boolean useBitsetPipeLine ) throws IOException { if ( isDimensionPresentInCurrentBlock ) { int chunkIndex = segmentProperties . getDimensionOrdinalToChunkMapping ( ) . get ( dimColumnEvaluatorInfo . getColumnIndex ( ) ) ; if ( null == rawBlockletColumnChunks . getDimensionRawColumnChunks ( ) [ chunkIndex ] ) { rawBlockletColumnChunks . getDimensionRawColumnChunks ( ) [ chunkIndex ] = rawBlockletColumnChunks . getDataBlock ( ) . readDimensionChunk ( rawBlockletColumnChunks . getFileReader ( ) , chunkIndex ) ; } DimensionRawColumnChunk dimensionRawColumnChunk = rawBlockletColumnChunks . getDimensionRawColumnChunks ( ) [ chunkIndex ] ; BitSetGroup bitSetGroup = new BitSetGroup ( dimensionRawColumnChunk . getPagesCount ( ) ) ; filterValues = dimColumnExecuterInfo . getFilterKeys ( ) ; boolean isDecoded = false ; for ( int i = 0 ; i < dimensionRawColumnChunk . getPagesCount ( ) ; i ++ ) { if ( dimensionRawColumnChunk . getMaxValues ( ) != null ) { if ( isScanRequired ( dimensionRawColumnChunk , i ) ) { DimensionColumnPage dimensionColumnPage = dimensionRawColumnChunk . decodeColumnPage ( i ) ; if ( ! isDecoded ) { filterValues = FilterUtil . getEncodedFilterValues ( dimensionRawColumnChunk . getLocalDictionary ( ) , dimColumnExecuterInfo . getFilterKeys ( ) ) ; isDecoded = true ; } BitSet bitSet = getFilteredIndexes ( dimensionColumnPage , dimensionRawColumnChunk . getRowCount ( ) [ i ] , useBitsetPipeLine , rawBlockletColumnChunks . getBitSetGroup ( ) , i ) ; bitSetGroup . setBitSet ( bitSet , i ) ; } } else { BitSet bitSet = getFilteredIndexes ( dimensionRawColumnChunk . decodeColumnPage ( i ) , dimensionRawColumnChunk . getRowCount ( ) [ i ] , useBitsetPipeLine , rawBlockletColumnChunks . getBitSetGroup ( ) , i ) ; bitSetGroup . setBitSet ( bitSet , i ) ; } } return bitSetGroup ; } else if ( isMeasurePresentInCurrentBlock ) { int chunkIndex = segmentProperties . getMeasuresOrdinalToChunkMapping ( ) . get ( msrColumnEvaluatorInfo . getColumnIndex ( ) ) ; if ( null == rawBlockletColumnChunks . getMeasureRawColumnChunks ( ) [ chunkIndex ] ) { rawBlockletColumnChunks . getMeasureRawColumnChunks ( ) [ chunkIndex ] = rawBlockletColumnChunks . getDataBlock ( ) . readMeasureChunk ( rawBlockletColumnChunks . getFileReader ( ) , chunkIndex ) ; } MeasureRawColumnChunk measureRawColumnChunk = rawBlockletColumnChunks . getMeasureRawColumnChunks ( ) [ chunkIndex ] ; BitSetGroup bitSetGroup = new BitSetGroup ( measureRawColumnChunk . getPagesCount ( ) ) ; DataType msrType = FilterUtil . getMeasureDataType ( msrColumnEvaluatorInfo ) ; for ( int i = 0 ; i < measureRawColumnChunk . getPagesCount ( ) ; i ++ ) { if ( measureRawColumnChunk . getMaxValues ( ) != null ) { if ( isScanRequired ( measureRawColumnChunk . getMaxValues ( ) [ i ] , measureRawColumnChunk . getMinValues ( ) [ i ] , msrColumnExecutorInfo . getFilterKeys ( ) , msrColumnEvaluatorInfo . getType ( ) ) ) { BitSet bitSet = getFilteredIndexesForMeasure ( measureRawColumnChunk . decodeColumnPage ( i ) , measureRawColumnChunk . getRowCount ( ) [ i ] , useBitsetPipeLine , rawBlockletColumnChunks . getBitSetGroup ( ) , i , msrType ) ; bitSetGroup . setBitSet ( bitSet , i ) ; } } else { BitSet bitSet = getFilteredIndexesForMeasure ( measureRawColumnChunk . decodeColumnPage ( i ) , measureRawColumnChunk . getRowCount ( ) [ i ] , useBitsetPipeLine , rawBlockletColumnChunks . getBitSetGroup ( ) , i , msrType ) ; bitSetGroup . setBitSet ( bitSet , i ) ; } } return bitSetGroup ; } return null ; } private boolean isScanRequired ( DimensionRawColumnChunk dimensionRawColumnChunk , int columnIndex ) { boolean scanRequired ; if ( DataTypeUtil . isPrimitiveColumn ( dimColumnEvaluatorInfo . getDimension ( ) . getDataType ( ) ) && dimColumnEvaluatorInfo . getDimension ( ) . getDataType ( ) != DataTypes . DATE ) { scanRequired = isScanRequired ( dimensionRawColumnChunk . getMaxValues ( ) [ columnIndex ] , dimensionRawColumnChunk . getMinValues ( ) [ columnIndex ] , dimColumnExecuterInfo . getFilterKeys ( ) , dimColumnEvaluatorInfo . getDimension ( ) . getDataType ( ) ) ; } else { scanRequired = isScanRequired ( dimensionRawColumnChunk . getMaxValues ( ) [ columnIndex ] , dimensionRawColumnChunk . getMinValues ( ) [ columnIndex ] , dimColumnExecuterInfo . getFilterKeys ( ) , dimensionRawColumnChunk . getMinMaxFlagArray ( ) [ columnIndex ] ) ; } return scanRequired ; } @ Override public BitSet prunePages ( RawBlockletColumnChunks rawBlockletColumnChunks ) throws IOException { if ( isDimensionPresentInCurrentBlock ) { int chunkIndex = segmentProperties . getDimensionOrdinalToChunkMapping ( ) . get ( dimColumnEvaluatorInfo . getColumnIndex ( ) ) ; if ( null == rawBlockletColumnChunks . getDimensionRawColumnChunks ( ) [ chunkIndex ] ) { rawBlockletColumnChunks . getDimensionRawColumnChunks ( ) [ chunkIndex ] = rawBlockletColumnChunks . getDataBlock ( ) . readDimensionChunk ( rawBlockletColumnChunks . getFileReader ( ) , chunkIndex ) ; } DimensionRawColumnChunk dimensionRawColumnChunk = rawBlockletColumnChunks . getDimensionRawColumnChunks ( ) [ chunkIndex ] ; filterValues = dimColumnExecuterInfo . getFilterKeys ( ) ; BitSet bitSet = new BitSet ( dimensionRawColumnChunk . getPagesCount ( ) ) ; for ( int i = 0 ; i < dimensionRawColumnChunk . getPagesCount ( ) ; i ++ ) { if ( dimensionRawColumnChunk . getMaxValues ( ) != null ) { if ( isScanRequired ( dimensionRawColumnChunk , i ) ) { bitSet . set ( i ) ; } } else { bitSet . set ( i ) ; } } return bitSet ; } else if ( isMeasurePresentInCurrentBlock ) { int chunkIndex = segmentProperties . getMeasuresOrdinalToChunkMapping ( ) . get ( msrColumnEvaluatorInfo . getColumnIndex ( ) ) ; if ( null == rawBlockletColumnChunks . getMeasureRawColumnChunks ( ) [ chunkIndex ] ) { rawBlockletColumnChunks . getMeasureRawColumnChunks ( ) [ chunkIndex ] = rawBlockletColumnChunks . getDataBlock ( ) . readMeasureChunk ( rawBlockletColumnChunks . getFileReader ( ) , chunkIndex ) ; } MeasureRawColumnChunk measureRawColumnChunk = rawBlockletColumnChunks . getMeasureRawColumnChunks ( ) [ chunkIndex ] ; BitSet bitSet = new BitSet ( measureRawColumnChunk . getPagesCount ( ) ) ; for ( int i = 0 ; i < measureRawColumnChunk . getPagesCount ( ) ; i ++ ) { if ( measureRawColumnChunk . getMaxValues ( ) != null ) { if ( isScanRequired ( measureRawColumnChunk . getMaxValues ( ) [ i ] , measureRawColumnChunk . getMinValues ( ) [ i ] , msrColumnExecutorInfo . getFilterKeys ( ) , msrColumnEvaluatorInfo . getType ( ) ) ) { bitSet . set ( i ) ; } } else { bitSet . set ( i ) ; } } return bitSet ; } return null ; } @ Override public boolean applyFilter ( RowIntf value , int dimOrdinalMax ) { if ( isDimensionPresentInCurrentBlock ) { byte [ ] [ ] filterValues = dimColumnExecuterInfo . getFilterKeys ( ) ; byte [ ] col = ( byte [ ] ) value . getVal ( dimColumnEvaluatorInfo . getDimension ( ) . getOrdinal ( ) ) ; for ( int i = 0 ; i < filterValues . length ; i ++ ) { if ( 0 == ByteUtil . UnsafeComparer . INSTANCE . compareTo ( col , 0 , col . length , filterValues [ i ] , 0 , filterValues [ i ] . length ) ) { return true ; } } } else if ( isMeasurePresentInCurrentBlock ) { Object [ ] filterValues = msrColumnExecutorInfo . getFilterKeys ( ) ; Object col = value . getVal ( msrColumnEvaluatorInfo . getMeasure ( ) . getOrdinal ( ) + dimOrdinalMax ) ; for ( int i = 0 ; i < filterValues . length ; i ++ ) { if ( filterValues [ i ] == null ) { if ( null == col ) { return true ; } continue ; } if ( comparator . compare ( col , filterValues [ i ] ) == 0 ) { return true ; } } } return false ; } private BitSet getFilteredIndexesForMeasures ( ColumnPage columnPage , int rowsInPage , DataType msrType ) { BitSet bitSet = new BitSet ( rowsInPage ) ; FilterExecutorUtil . executeIncludeExcludeFilterForMeasure ( columnPage , bitSet , msrColumnExecutorInfo , msrColumnEvaluatorInfo , filterBitSetUpdater ) ; return bitSet ; } private BitSet getFilteredIndexesForMeasure ( ColumnPage measureColumnPage , int numberOfRows , boolean useBitsetPipeLine , BitSetGroup prvBitSetGroup , int pageNumber , DataType msrDataType ) { if ( CarbonUtil . usePreviousFilterBitsetGroup ( useBitsetPipeLine , prvBitSetGroup , pageNumber , msrColumnExecutorInfo . getFilterKeys ( ) . length ) ) { return getFilteredIndexesForMsrUsingPrvBitSet ( measureColumnPage , prvBitSetGroup , pageNumber , numberOfRows , msrDataType ) ; } else { return getFilteredIndexesForMeasures ( measureColumnPage , numberOfRows , msrDataType ) ; } } private BitSet getFilteredIndexesForMsrUsingPrvBitSet ( ColumnPage measureColumnPage , BitSetGroup prvBitSetGroup , int pageNumber , int numberOfRows , DataType msrDataType ) { BitSet bitSet = new BitSet ( numberOfRows ) ; Object [ ] filterValues = msrColumnExecutorInfo . getFilterKeys ( ) ; BitSet nullBitSet = measureColumnPage . getNullBits ( ) ; BitSet prvPageBitSet = prvBitSetGroup . getBitSet ( pageNumber ) ; SerializableComparator comparator = Comparator . getComparatorByDataTypeForMeasure ( msrDataType ) ; for ( int i = 0 ; i < filterValues . length ; i ++ ) { if ( filterValues [ i ] == null ) { for ( int j = nullBitSet . nextSetBit ( 0 ) ; j >= 0 ; j = nullBitSet . nextSetBit ( j + 1 ) ) { bitSet . set ( j ) ; } continue ; } for ( int index = prvPageBitSet . nextSetBit ( 0 ) ; index >= 0 ; index = prvPageBitSet . nextSetBit ( index + 1 ) ) { if ( ! nullBitSet . get ( index ) ) { Object msrValue = DataTypeUtil . getMeasureObjectBasedOnDataType ( measureColumnPage , index , msrDataType , msrColumnEvaluatorInfo . getMeasure ( ) ) ; if ( comparator . compare ( msrValue , filterValues [ i ] ) == 0 ) { bitSet . set ( index ) ; } } } } return bitSet ; } protected BitSet getFilteredIndexes ( DimensionColumnPage dimensionColumnPage , int numberOfRows , boolean useBitsetPipeLine , BitSetGroup prvBitSetGroup , int pageNumber ) { if ( filterValues . length > 0 && CarbonUtil . usePreviousFilterBitsetGroup ( useBitsetPipeLine , prvBitSetGroup , pageNumber , filterValues . length ) ) { return getFilteredIndexesUisngPrvBitset ( dimensionColumnPage , prvBitSetGroup , pageNumber , numberOfRows ) ; } else { return getFilteredIndexes ( dimensionColumnPage , numberOfRows ) ; } } private BitSet getFilteredIndexes ( DimensionColumnPage dimensionColumnPage , int numberOfRows ) { if ( dimensionColumnPage . isExplicitSorted ( ) ) { return setFilterdIndexToBitSetWithColumnIndex ( dimensionColumnPage , numberOfRows ) ; } return setFilterdIndexToBitSet ( dimensionColumnPage , numberOfRows ) ; } private BitSet getFilteredIndexesUisngPrvBitset ( DimensionColumnPage dimensionColumnPage , BitSetGroup prvBitSetGroup , int pageNumber , int numberOfRows ) { BitSet prvPageBitSet = prvBitSetGroup . getBitSet ( pageNumber ) ; if ( prvPageBitSet == null || prvPageBitSet . isEmpty ( ) ) { return prvPageBitSet ; } BitSet bitSet = new BitSet ( numberOfRows ) ; int compareResult = 0 ; if ( ! dimensionColumnPage . isExplicitSorted ( ) ) { for ( int index = prvPageBitSet . nextSetBit ( 0 ) ; index >= 0 ; index = prvPageBitSet . nextSetBit ( index + 1 ) ) { compareResult = CarbonUtil . isFilterPresent ( filterValues , dimensionColumnPage , 0 , filterValues . length - 1 , index ) ; if ( compareResult == 0 ) { bitSet . set ( index ) ; } } } else { for ( int index = prvPageBitSet . nextSetBit ( 0 ) ; index >= 0 ; index = prvPageBitSet . nextSetBit ( index + 1 ) ) { compareResult = CarbonUtil . isFilterPresent ( filterValues , dimensionColumnPage , 0 , filterValues . length - 1 , dimensionColumnPage . getInvertedReverseIndex ( index ) ) ; if ( compareResult == 0 ) { bitSet . set ( index ) ; } } } return bitSet ; } private BitSet setFilterdIndexToBitSetWithColumnIndex ( DimensionColumnPage dimensionColumnPage , int numerOfRows ) { BitSet bitSet = new BitSet ( numerOfRows ) ; if ( filterValues . length == 0 ) { return bitSet ; } int startIndex = 0 ; for ( int i = 0 ; i < filterValues . length ; i ++ ) { if ( startIndex >= numerOfRows ) { break ; } int [ ] rangeIndex = CarbonUtil . getRangeIndexUsingBinarySearch ( dimensionColumnPage , startIndex , numerOfRows - 1 , filterValues [ i ] ) ; for ( int j = rangeIndex [ 0 ] ; j <= rangeIndex [ 1 ] ; j ++ ) { bitSet . set ( dimensionColumnPage . getInvertedIndex ( j ) ) ; } if ( rangeIndex [ 1 ] >= 0 ) { startIndex = rangeIndex [ 1 ] + 1 ; } } return bitSet ; } private BitSet setFilterdIndexToBitSet ( DimensionColumnPage dimensionColumnPage , int numerOfRows ) { BitSet bitSet = new BitSet ( numerOfRows ) ; if ( filterValues . length == 0 ) { return bitSet ; } if ( isNaturalSorted && dimensionColumnPage . isExplicitSorted ( ) ) { int startIndex = 0 ; for ( int i = 0 ; i < filterValues . length ; i ++ ) { if ( startIndex >= numerOfRows ) { break ; } int [ ] rangeIndex = CarbonUtil . getRangeIndexUsingBinarySearch ( dimensionColumnPage , startIndex , numerOfRows - 1 , filterValues [ i ] ) ; for ( int j = rangeIndex [ 0 ] ; j <= rangeIndex [ 1 ] ; j ++ ) { bitSet . set ( j ) ; } if ( rangeIndex [ 1 ] >= 0 ) { startIndex = rangeIndex [ 1 ] + 1 ; } } } else { if ( filterValues . length > 1 ) { for ( int i = 0 ; i < numerOfRows ; i ++ ) { int index = CarbonUtil . binarySearch ( filterValues , 0 , filterValues . length - 1 , dimensionColumnPage , i ) ; if ( index >= 0 ) { bitSet . set ( i ) ; } } } else { for ( int j = 0 ; j < numerOfRows ; j ++ ) { if ( dimensionColumnPage . compareTo ( j , filterValues [ 0 ] ) == 0 ) { bitSet . set ( j ) ; } } } } return bitSet ; } @ Override public BitSet isScanRequired ( byte [ ] [ ] blkMaxVal , byte [ ] [ ] blkMinVal , boolean [ ] isMinMaxSet ) { BitSet bitSet = new BitSet ( 1 ) ; byte [ ] [ ] filterValues ; int chunkIndex = 0 ; boolean isScanRequired = false ; if ( isDimensionPresentInCurrentBlock ) { filterValues = dimColumnExecuterInfo . getFilterKeys ( ) ; chunkIndex = dimColumnEvaluatorInfo . getColumnIndexInMinMaxByteArray ( ) ; if ( DataTypeUtil . isPrimitiveColumn ( dimColumnEvaluatorInfo . getDimension ( ) . getDataType ( ) ) && dimColumnEvaluatorInfo . getDimension ( ) . getDataType ( ) != DataTypes . DATE ) { isScanRequired = isScanRequired ( blkMaxVal [ chunkIndex ] , blkMinVal [ chunkIndex ] , filterValues , dimColumnEvaluatorInfo . getDimension ( ) . getDataType ( ) ) ; } else { isScanRequired = isScanRequired ( blkMaxVal [ chunkIndex ] , blkMinVal [ chunkIndex ] , filterValues , isMinMaxSet [ chunkIndex ] ) ; } } else if ( isMeasurePresentInCurrentBlock ) { chunkIndex = msrColumnEvaluatorInfo . getColumnIndexInMinMaxByteArray ( ) ; if ( isMinMaxSet [ chunkIndex ] ) { isScanRequired = isScanRequired ( blkMaxVal [ chunkIndex ] , blkMinVal [ chunkIndex ] , msrColumnExecutorInfo . getFilterKeys ( ) , msrColumnEvaluatorInfo . getType ( ) ) ; } else { isScanRequired = true ; } } if ( isScanRequired ) { bitSet . set ( 0 ) ; } return bitSet ; } private boolean isScanRequired ( byte [ ] blkMaxVal , byte [ ] blkMinVal , byte [ ] [ ] filterValues , boolean isMinMaxSet ) { if ( ! isMinMaxSet ) { return true ; } boolean isScanRequired = false ; for ( int k = 0 ; k < filterValues . length ; k ++ ) { int maxCompare = ByteUtil . UnsafeComparer . INSTANCE . compareTo ( filterValues [ k ] , blkMaxVal ) ; int minCompare = ByteUtil . UnsafeComparer . INSTANCE . compareTo ( filterValues [ k ] , blkMinVal ) ; if ( maxCompare <= 0 && minCompare >= 0 ) { isScanRequired = true ; break ; } } return isScanRequired ; } private boolean isScanRequired ( byte [ ] blkMaxVal , byte [ ] blkMinVal , byte [ ] [ ] filterValues , DataType dataType ) { boolean isScanRequired = false ; Object minValue = DataTypeUtil . getDataBasedOnDataTypeForNoDictionaryColumn ( blkMinVal , dataType ) ; Object maxValue = DataTypeUtil . getDataBasedOnDataTypeForNoDictionaryColumn ( blkMaxVal , dataType ) ; for ( int k = 0 ; k < filterValues . length ; k ++ ) { if ( ByteUtil . UnsafeComparer . INSTANCE . compareTo ( filterValues [ k ] , CarbonCommonConstants . EMPTY_BYTE_ARRAY ) == 0 ) { return true ; } Object data = DataTypeUtil . getDataBasedOnDataTypeForNoDictionaryColumn ( filterValues [ k ] , dataType ) ; SerializableComparator comparator = Comparator . getComparator ( dataType ) ; int maxCompare = comparator . compare ( data , maxValue ) ; int minCompare = comparator . compare ( data , minValue ) ; if ( maxCompare <= 0 && minCompare >= 0 ) { isScanRequired = true ; break ; } } return isScanRequired ; } private boolean isScanRequired ( byte [ ] maxValue , byte [ ] minValue , Object [ ] filterValue , DataType dataType ) { Object maxObject = DataTypeUtil . getMeasureObjectFromDataType ( maxValue , dataType ) ; Object minObject = DataTypeUtil . getMeasureObjectFromDataType ( minValue , dataType ) ; for ( int i = 0 ; i < filterValue . length ; i ++ ) { if ( filterValue [ i ] == null ) { return true ; } if ( comparator . compare ( filterValue [ i ] , maxObject ) <= 0 && comparator . compare ( filterValue [ i ] , minObject ) >= 0 ) { return true ; } } return false ; } @ Override public void readColumnChunks ( RawBlockletColumnChunks rawBlockletColumnChunks ) throws IOException { if ( isDimensionPresentInCurrentBlock ) { int chunkIndex = segmentProperties . getDimensionOrdinalToChunkMapping ( ) . get ( dimColumnEvaluatorInfo . getColumnIndex ( ) ) ; if ( null == rawBlockletColumnChunks . getDimensionRawColumnChunks ( ) [ chunkIndex ] ) { rawBlockletColumnChunks . getDimensionRawColumnChunks ( ) [ chunkIndex ] = rawBlockletColumnChunks . getDataBlock ( ) . readDimensionChunk ( rawBlockletColumnChunks . getFileReader ( ) , chunkIndex ) ; } } else if ( isMeasurePresentInCurrentBlock ) { int chunkIndex = segmentProperties . getMeasuresOrdinalToChunkMapping ( ) . get ( msrColumnEvaluatorInfo . getColumnIndex ( ) ) ; if ( null == rawBlockletColumnChunks . getMeasureRawColumnChunks ( ) [ chunkIndex ] ) { rawBlockletColumnChunks . getMeasureRawColumnChunks ( ) [ chunkIndex ] = rawBlockletColumnChunks . getDataBlock ( ) . readMeasureChunk ( rawBlockletColumnChunks . getFileReader ( ) , chunkIndex ) ; } } } }",Smelly
 private class MyClass extends WebComponent { public MyClass ( String id ) { super ( id ) ; } ,No
public class AuthenticationException extends SecurityException { private static final long serialVersionUID = - 823479120896894071L ; public AuthenticationException ( ) { } public AuthenticationException ( String reason ) { super ( reason ) ; } },No
" private class InternalTopologyListener implements TopologyListener { @ Override public void handleTopologyEvent ( List < TopologyEvent > events ) { synchronized ( GatewayServer . this ) { for ( TopologyEvent event : events ) { Topology topology = event . getTopology ( ) ; File deployDir = calculateAbsoluteDeploymentsDir ( ) ; if ( event . getType ( ) . equals ( TopologyEvent . Type . DELETED ) ) { handleDeleteDeployment ( topology , deployDir ) ; } else { handleCreateDeployment ( topology , deployDir ) ; } } } } private void handleDeleteDeployment ( Topology topology , File deployDir ) { log . deletingTopology ( topology . getName ( ) ) ; File [ ] files = deployDir . listFiles ( new RegexFilenameFilter ( topology . getName ( ) + ""\\.(war|topo)\\.[0-9A-Fa-f]+"" ) ) ; if ( files != null ) { auditor . audit ( Action . UNDEPLOY , topology . getName ( ) , ResourceType . TOPOLOGY , ActionOutcome . UNAVAILABLE ) ; internalDeactivateTopology ( topology ) ; for ( File file : files ) { log . deletingDeployment ( file . getAbsolutePath ( ) ) ; FileUtils . deleteQuietly ( file ) ; } } } private void handleCreateDeployment ( Topology topology , File deployDir ) { try { File topoDir = calculateDeploymentDir ( topology ) ; if ( ! topoDir . exists ( ) ) { auditor . audit ( Action . DEPLOY , topology . getName ( ) , ResourceType . TOPOLOGY , ActionOutcome . UNAVAILABLE ) ; if ( topology . getProviders ( ) . isEmpty ( ) ) { throw new DeploymentException ( ""No providers found inside topology."" ) ; } log . deployingTopology ( topology . getName ( ) , topoDir . getAbsolutePath ( ) ) ; internalDeactivateTopology ( topology ) ; EnterpriseArchive ear = DeploymentFactory . createDeployment ( config , topology ) ; if ( ! deployDir . exists ( ) && ! deployDir . mkdirs ( ) ) { throw new DeploymentException ( ""Failed to create topology deployment temporary directory: "" + deployDir . getAbsolutePath ( ) ) ; } File tmp = ear . as ( ExplodedExporter . class ) . exportExploded ( deployDir , topoDir . getName ( ) + "".tmp"" ) ; if ( ! tmp . renameTo ( topoDir ) ) { FileUtils . deleteQuietly ( tmp ) ; throw new DeploymentException ( ""Failed to create topology deployment directory: "" + topoDir . getAbsolutePath ( ) ) ; } internalDeployApplications ( topology , topoDir ) ; internalActivateTopology ( topology , topoDir ) ; log . deployedTopology ( topology . getName ( ) ) ; } else { auditor . audit ( Action . REDEPLOY , topology . getName ( ) , ResourceType . TOPOLOGY , ActionOutcome . UNAVAILABLE ) ; log . redeployingTopology ( topology . getName ( ) , topoDir . getAbsolutePath ( ) ) ; internalActivateTopology ( topology , topoDir ) ; log . redeployedTopology ( topology . getName ( ) ) ; } cleanupTopologyDeployments ( deployDir , topology ) ; } catch ( Throwable e ) { auditor . audit ( Action . DEPLOY , topology . getName ( ) , ResourceType . TOPOLOGY , ActionOutcome . FAILURE ) ; log . failedToDeployTopology ( topology . getName ( ) , e ) ; } } ",No
public class DefaultBatcherBuilder implements BatcherBuilder { @ Override public BatchMessageContainer build ( ) { return new BatchMessageContainerImpl ( ) ; } },No
"public class SecTestLiterals extends TestLiterals { public SecTestLiterals ( ) { super ( new TestPackage . PlainModelFactory ( ) , ""SecTestLiterals"" ) ; } }",No
"@ InterfaceAudience . Private public class MetricsStochasticBalancer extends MetricsBalancer { private MetricsStochasticBalancerSource stochasticSource = null ; public MetricsStochasticBalancer ( ) { initSource ( ) ; } @ Override protected void initSource ( ) { stochasticSource = CompatibilitySingletonFactory . getInstance ( MetricsStochasticBalancerSource . class ) ; } @ Override public void balanceCluster ( long time ) { stochasticSource . updateBalanceCluster ( time ) ; } @ Override public void incrMiscInvocations ( ) { stochasticSource . incrMiscInvocations ( ) ; } @ Override public void balancerStatus ( boolean status ) { stochasticSource . updateBalancerStatus ( status ) ; } public void updateMetricsSize ( int size ) { stochasticSource . updateMetricsSize ( size ) ; } public void updateStochasticCost ( String tableName , String costFunctionName , String costFunctionDesc , Double value ) { stochasticSource . updateStochasticCost ( tableName , costFunctionName , costFunctionDesc , value ) ; } }",No
"public class AjaxRequestHandler implements AjaxRequestTarget { private final AbstractAjaxResponse responseObject ; private List < AjaxRequestTarget . IListener > listeners = null ; private final Set < ITargetRespondListener > respondListeners = new HashSet < ITargetRespondListener > ( ) ; protected transient boolean respondersFrozen ; protected transient boolean listenersFrozen ; private final Page page ; private PageLogData logData ; public AjaxRequestHandler ( final Page page ) { this . page = Args . notNull ( page , ""page"" ) ; responseObject = new XmlAjaxResponse ( page ) { @ Override protected void fireOnAfterRespondListeners ( final Response response ) { listenersFrozen = true ; if ( listeners != null ) { final Map < String , Component > components = Collections . unmodifiableMap ( markupIdToComponent ) ; final AjaxRequestTarget . IJavaScriptResponse jsresponse = new AjaxRequestTarget . IJavaScriptResponse ( ) { @ Override public void addJavaScript ( String script ) { writeNormalEvaluations ( response , Collections . < CharSequence > singleton ( script ) ) ; } } ; for ( AjaxRequestTarget . IListener listener : listeners ) { listener . onAfterRespond ( components , jsresponse ) ; } } } @ Override protected void fireOnBeforeRespondListeners ( ) { listenersFrozen = true ; if ( listeners != null ) { for ( AjaxRequestTarget . IListener listener : listeners ) { listener . onBeforeRespond ( markupIdToComponent , AjaxRequestHandler . this ) ; } } listenersFrozen = false ; } } ; } @ Override public Page getPage ( ) { return page ; } @ Override public void addListener ( AjaxRequestTarget . IListener listener ) throws IllegalStateException { Args . notNull ( listener , ""listener"" ) ; assertListenersNotFrozen ( ) ; if ( listeners == null ) { listeners = new LinkedList < AjaxRequestTarget . IListener > ( ) ; } if ( ! listeners . contains ( listener ) ) { listeners . add ( listener ) ; } } @ Override public final void addChildren ( MarkupContainer parent , Class < ? > childCriteria ) { Args . notNull ( parent , ""parent"" ) ; Args . notNull ( childCriteria , ""childCriteria"" ) ; parent . visitChildren ( childCriteria , new IVisitor < Component , Void > ( ) { @ Override public void component ( final Component component , final IVisit < Void > visit ) { add ( component ) ; visit . dontGoDeeper ( ) ; } } ) ; } @ Override public void add ( Component ... components ) { for ( final Component component : components ) { Args . notNull ( component , ""component"" ) ; if ( component . getOutputMarkupId ( ) == false && ! ( component instanceof Page ) ) { throw new IllegalArgumentException ( ""cannot update component that does not have setOutputMarkupId property set to true. Component: "" + component . toString ( ) ) ; } add ( component , component . getMarkupId ( ) ) ; } } @ Override public void add ( Component component , String markupId ) { responseObject . add ( component , markupId ) ; } @ Override public final Collection < ? extends Component > getComponents ( ) { return responseObject . getComponents ( ) ; } @ Override public final void focusComponent ( Component component ) { if ( component != null && component . getOutputMarkupId ( ) == false ) { throw new IllegalArgumentException ( ""cannot update component that does not have setOutputMarkupId property set to true. Component: "" + component . toString ( ) ) ; } final String id = component != null ? ( ""'"" + component . getMarkupId ( ) + ""'"" ) : ""null"" ; appendJavaScript ( ""Wicket.Focus.setFocusOnId("" + id + "");"" ) ; } @ Override public final void appendJavaScript ( CharSequence javascript ) { responseObject . appendJavaScript ( javascript ) ; } @ Override public void detach ( final IRequestCycle requestCycle ) { if ( logData == null ) { logData = new PageLogData ( page ) ; } responseObject . detach ( requestCycle ) ; } @ Override public boolean equals ( final Object obj ) { if ( obj instanceof AjaxRequestHandler ) { AjaxRequestHandler that = ( AjaxRequestHandler ) obj ; return responseObject . equals ( that . responseObject ) ; } return false ; } @ Override public int hashCode ( ) { int result = ""AjaxRequestHandler"" . hashCode ( ) ; result += responseObject . hashCode ( ) * 17 ; return result ; } @ Override public final void prependJavaScript ( CharSequence javascript ) { responseObject . prependJavaScript ( javascript ) ; } @ Override public void registerRespondListener ( ITargetRespondListener listener ) { assertRespondersNotFrozen ( ) ; respondListeners . add ( listener ) ; } @ Override public final void respond ( final IRequestCycle requestCycle ) { final RequestCycle rc = ( RequestCycle ) requestCycle ; final WebResponse response = ( WebResponse ) requestCycle . getResponse ( ) ; if ( shouldRedirectToPage ( requestCycle ) ) { IRequestHandler handler = new RenderPageRequestHandler ( new PageProvider ( page ) ) ; final String url = rc . urlFor ( handler ) . toString ( ) ; response . sendRedirect ( url ) ; return ; } respondersFrozen = true ; for ( ITargetRespondListener listener : respondListeners ) { listener . onTargetRespond ( this ) ; } final Application app = page . getApplication ( ) ; page . send ( app , Broadcast . BREADTH , this ) ; final String encoding = app . getRequestCycleSettings ( ) . getResponseRequestEncoding ( ) ; responseObject . setContentType ( response , encoding ) ; response . disableCaching ( ) ; final StringResponse bodyResponse = new StringResponse ( ) ; responseObject . writeTo ( bodyResponse , encoding ) ; CharSequence filteredResponse = invokeResponseFilters ( bodyResponse ) ; response . write ( filteredResponse ) ; } private boolean shouldRedirectToPage ( IRequestCycle requestCycle ) { if ( responseObject . containsPage ( ) ) { return true ; } if ( ( ( WebRequest ) requestCycle . getRequest ( ) ) . isAjax ( ) == false ) { return true ; } return false ; } private AppendingStringBuffer invokeResponseFilters ( final StringResponse contentResponse ) { AppendingStringBuffer responseBuffer = new AppendingStringBuffer ( contentResponse . getBuffer ( ) ) ; List < IResponseFilter > responseFilters = Application . get ( ) . getRequestCycleSettings ( ) . getResponseFilters ( ) ; if ( responseFilters != null ) { for ( IResponseFilter filter : responseFilters ) { responseBuffer = filter . filter ( responseBuffer ) ; } } return responseBuffer ; } @ Override public String toString ( ) { return ""[AjaxRequestHandler@"" + hashCode ( ) + "" responseObject ["" + responseObject + ""]"" ; } @ Override public IHeaderResponse getHeaderResponse ( ) { return responseObject . getHeaderResponse ( ) ; } @ Override public String getLastFocusedElementId ( ) { WebRequest request = ( WebRequest ) page . getRequest ( ) ; String id = request . getHeader ( ""Wicket-FocusedElementId"" ) ; return Strings . isEmpty ( id ) ? null : id ; } @ Override public Class < ? extends IRequestablePage > getPageClass ( ) { return page . getPageClass ( ) ; } @ Override public Integer getPageId ( ) { return page . getPageId ( ) ; } @ Override public PageParameters getPageParameters ( ) { return page . getPageParameters ( ) ; } @ Override public final boolean isPageInstanceCreated ( ) { return true ; } @ Override public final Integer getRenderCount ( ) { return page . getRenderCount ( ) ; } @ Override public PageLogData getLogData ( ) { return logData ; } private void assertNotFrozen ( boolean frozen , Class < ? > clazz ) { if ( frozen ) { throw new IllegalStateException ( Classes . simpleName ( clazz ) + ""s can no longer be added"" ) ; } } private void assertRespondersNotFrozen ( ) { assertNotFrozen ( respondersFrozen , AjaxRequestTarget . ITargetRespondListener . class ) ; } private void assertListenersNotFrozen ( ) { assertNotFrozen ( listenersFrozen , AjaxRequestTarget . IListener . class ) ; } }",Smelly
"@ Configuration @ PropertySource ( ""classpath:errorMessages.properties"" ) @ Provider public class RestServiceExceptionMapper implements ExceptionMapper < Exception > { private static final Logger LOG = LoggerFactory . getLogger ( RestServiceExceptionMapper . class ) ; private final ValidationExceptionMapper validationEM = new ValidationExceptionMapper ( ) ; @ Autowired private Environment env ; private static final Map < String , String > EXCEPTION_CODE_MAP = new HashMap < String , String > ( ) { private static final long serialVersionUID = - 7688359318035249200L ; { put ( ""23000"" , ""UniqueConstraintViolation"" ) ; put ( ""23505"" , ""UniqueConstraintViolation"" ) ; } } ; @ Override public Response toResponse ( final Exception ex ) { LOG . error ( ""Exception thrown"" , ex ) ; ResponseBuilder builder ; if ( ex instanceof AccessDeniedException ) { builder = null ; } else if ( ex instanceof SyncopeClientException ) { SyncopeClientException sce = ( SyncopeClientException ) ex ; builder = sce . isComposite ( ) ? getSyncopeClientCompositeExceptionResponse ( sce . asComposite ( ) ) : getSyncopeClientExceptionResponse ( sce ) ; } else if ( ex instanceof DelegatedAdministrationException || ExceptionUtils . getRootCause ( ex ) instanceof DelegatedAdministrationException ) { builder = builder ( ClientExceptionType . DelegatedAdministration , ExceptionUtils . getRootCauseMessage ( ex ) ) ; } else if ( ex instanceof EntityExistsException || ex instanceof DuplicateException || ex instanceof PersistenceException && ex . getCause ( ) instanceof EntityExistsException ) { builder = builder ( ClientExceptionType . EntityExists , getJPAMessage ( ex instanceof PersistenceException ? ex . getCause ( ) : ex ) ) ; } else if ( ex instanceof DataIntegrityViolationException || ex instanceof JpaSystemException ) { builder = builder ( ClientExceptionType . DataIntegrityViolation , getJPAMessage ( ex ) ) ; } else if ( ex instanceof ConnectorException ) { builder = builder ( ClientExceptionType . ConnectorException , ExceptionUtils . getRootCauseMessage ( ex ) ) ; } else if ( ex instanceof NotFoundException ) { builder = builder ( ClientExceptionType . NotFound , ExceptionUtils . getRootCauseMessage ( ex ) ) ; } else { builder = processInvalidEntityExceptions ( ex ) ; if ( builder == null ) { builder = processBadRequestExceptions ( ex ) ; } if ( builder == null && ex instanceof ValidationException ) { builder = builder ( validationEM . toResponse ( ( ValidationException ) ex ) ) . header ( RESTHeaders . ERROR_CODE , ClientExceptionType . RESTValidation . name ( ) ) . header ( RESTHeaders . ERROR_INFO , ClientExceptionType . RESTValidation . getInfoHeaderValue ( ExceptionUtils . getRootCauseMessage ( ex ) ) ) ; ErrorTO error = new ErrorTO ( ) ; error . setStatus ( ClientExceptionType . RESTValidation . getResponseStatus ( ) . getStatusCode ( ) ) ; error . setType ( ClientExceptionType . RESTValidation ) ; error . getElements ( ) . add ( ExceptionUtils . getRootCauseMessage ( ex ) ) ; builder . entity ( error ) ; } if ( builder == null ) { builder = Response . status ( Response . Status . INTERNAL_SERVER_ERROR ) . header ( RESTHeaders . ERROR_INFO , ClientExceptionType . Unknown . getInfoHeaderValue ( ExceptionUtils . getRootCauseMessage ( ex ) ) ) ; ErrorTO error = new ErrorTO ( ) ; error . setStatus ( Response . Status . INTERNAL_SERVER_ERROR . getStatusCode ( ) ) ; error . setType ( ClientExceptionType . Unknown ) ; error . getElements ( ) . add ( ExceptionUtils . getRootCauseMessage ( ex ) ) ; builder . entity ( error ) ; } } return builder == null ? null : builder . build ( ) ; } private ResponseBuilder getSyncopeClientExceptionResponse ( final SyncopeClientException ex ) { ResponseBuilder builder = Response . status ( ex . getType ( ) . getResponseStatus ( ) ) ; builder . header ( RESTHeaders . ERROR_CODE , ex . getType ( ) . name ( ) ) ; ErrorTO error = new ErrorTO ( ) ; error . setStatus ( ex . getType ( ) . getResponseStatus ( ) . getStatusCode ( ) ) ; error . setType ( ex . getType ( ) ) ; for ( String element : ex . getElements ( ) ) { builder . header ( RESTHeaders . ERROR_INFO , ex . getType ( ) . getInfoHeaderValue ( element ) ) ; error . getElements ( ) . add ( element ) ; } return builder . entity ( error ) ; } private ResponseBuilder getSyncopeClientCompositeExceptionResponse ( final SyncopeClientCompositeException ex ) { if ( ex . getExceptions ( ) . size ( ) == 1 ) { return getSyncopeClientExceptionResponse ( ex . getExceptions ( ) . iterator ( ) . next ( ) ) ; } ResponseBuilder builder = Response . status ( Response . Status . BAD_REQUEST ) ; List < ErrorTO > errors = new ArrayList < > ( ) ; for ( SyncopeClientException sce : ex . getExceptions ( ) ) { builder . header ( RESTHeaders . ERROR_CODE , sce . getType ( ) . name ( ) ) ; ErrorTO error = new ErrorTO ( ) ; error . setStatus ( sce . getType ( ) . getResponseStatus ( ) . getStatusCode ( ) ) ; error . setType ( sce . getType ( ) ) ; for ( String element : sce . getElements ( ) ) { builder . header ( RESTHeaders . ERROR_INFO , sce . getType ( ) . getInfoHeaderValue ( element ) ) ; error . getElements ( ) . add ( element ) ; } errors . add ( error ) ; } return builder . entity ( errors ) ; } private ResponseBuilder processInvalidEntityExceptions ( final Exception ex ) { InvalidEntityException iee = null ; if ( ex instanceof InvalidEntityException ) { iee = ( InvalidEntityException ) ex ; } if ( ex instanceof TransactionSystemException && ex . getCause ( ) instanceof RollbackException && ex . getCause ( ) . getCause ( ) instanceof InvalidEntityException ) { iee = ( InvalidEntityException ) ex . getCause ( ) . getCause ( ) ; } if ( iee != null ) { ClientExceptionType exType = iee . getEntityClassSimpleName ( ) . endsWith ( ""Policy"" ) ? ClientExceptionType . InvalidPolicy : iee . getEntityClassSimpleName ( ) . equals ( PlainAttr . class . getSimpleName ( ) ) ? ClientExceptionType . InvalidValues : ClientExceptionType . valueOf ( ""Invalid"" + iee . getEntityClassSimpleName ( ) ) ; ResponseBuilder builder = Response . status ( Response . Status . BAD_REQUEST ) ; builder . header ( RESTHeaders . ERROR_CODE , exType . name ( ) ) ; ErrorTO error = new ErrorTO ( ) ; error . setStatus ( exType . getResponseStatus ( ) . getStatusCode ( ) ) ; error . setType ( exType ) ; for ( Map . Entry < Class < ? > , Set < EntityViolationType > > violation : iee . getViolations ( ) . entrySet ( ) ) { for ( EntityViolationType violationType : violation . getValue ( ) ) { builder . header ( RESTHeaders . ERROR_INFO , exType . getInfoHeaderValue ( violationType . name ( ) + "": "" + violationType . getMessage ( ) ) ) ; error . getElements ( ) . add ( violationType . name ( ) + "": "" + violationType . getMessage ( ) ) ; } } return builder ; } return null ; } private ResponseBuilder processBadRequestExceptions ( final Exception ex ) { Class < ? > ibatisPersistenceException = null ; try { ibatisPersistenceException = Class . forName ( ""org.apache.ibatis.exceptions.PersistenceException"" ) ; } catch ( ClassNotFoundException e ) { } if ( ex instanceof WorkflowException ) { return builder ( ClientExceptionType . Workflow , ExceptionUtils . getRootCauseMessage ( ex ) ) ; } else if ( ex instanceof PersistenceException ) { return builder ( ClientExceptionType . GenericPersistence , ExceptionUtils . getRootCauseMessage ( ex ) ) ; } else if ( ibatisPersistenceException != null && ibatisPersistenceException . isAssignableFrom ( ex . getClass ( ) ) ) { return builder ( ClientExceptionType . Workflow , ""Currently unavailable. Please try later."" ) ; } else if ( ex instanceof JpaSystemException ) { return builder ( ClientExceptionType . DataIntegrityViolation , ExceptionUtils . getRootCauseMessage ( ex ) ) ; } else if ( ex instanceof ConfigurationException ) { return builder ( ClientExceptionType . InvalidConnIdConf , ExceptionUtils . getRootCauseMessage ( ex ) ) ; } else if ( ex instanceof ParsingValidationException ) { return builder ( ClientExceptionType . InvalidValues , ExceptionUtils . getRootCauseMessage ( ex ) ) ; } else if ( ex instanceof MalformedPathException ) { return builder ( ClientExceptionType . InvalidPath , ExceptionUtils . getRootCauseMessage ( ex ) ) ; } return null ; } private ResponseBuilder builder ( final ClientExceptionType hType , final String msg ) { ResponseBuilder builder = Response . status ( hType . getResponseStatus ( ) ) . header ( RESTHeaders . ERROR_CODE , hType . name ( ) ) . header ( RESTHeaders . ERROR_INFO , hType . getInfoHeaderValue ( msg ) ) ; ErrorTO error = new ErrorTO ( ) ; error . setStatus ( hType . getResponseStatus ( ) . getStatusCode ( ) ) ; error . setType ( hType ) ; error . getElements ( ) . add ( msg ) ; return builder . entity ( error ) ; } private ResponseBuilder builder ( final Response response ) { ResponseBuilder builder = JAXRSUtils . toResponseBuilder ( response . getStatus ( ) ) ; builder . entity ( response . getEntity ( ) ) ; for ( Map . Entry < String , List < Object > > entry : response . getMetadata ( ) . entrySet ( ) ) { if ( ! HttpHeaders . CONTENT_TYPE . equals ( entry . getKey ( ) ) ) { for ( Object value : entry . getValue ( ) ) { builder . header ( entry . getKey ( ) , value ) ; } } } return builder ; } private String getJPAMessage ( final Throwable ex ) { Throwable throwable = ExceptionUtils . getRootCause ( ex ) ; String message = null ; if ( throwable instanceof SQLException ) { String messageKey = EXCEPTION_CODE_MAP . get ( ( ( SQLException ) throwable ) . getSQLState ( ) ) ; if ( messageKey != null ) { message = env . getProperty ( ""errMessage."" + messageKey ) ; } } return message == null ? ( ex . getCause ( ) == null ) ? ex . getMessage ( ) : ex . getCause ( ) . getMessage ( ) : message ; } }",Smelly
"@ Tags ( { ""json"" , ""flatten"" } ) @ CapabilityDescription ( ""Provides the user with the ability to take a nested JSON document and flatten it into a simple key/value pair "" + ""document. The keys are combined at each level with a user-defined separator that defaults to '.'. "" + ""Support three kinds of flatten mode, normal, keep-arrays and dot notation for MongoDB query. "" + ""Default flatten mode is 'keep-arrays'."" ) @ SideEffectFree public class FlattenJson extends AbstractProcessor { static final Relationship REL_SUCCESS = new Relationship . Builder ( ) . description ( ""Successfully flattened files go to this relationship."" ) . name ( ""success"" ) . build ( ) ; static final Relationship REL_FAILURE = new Relationship . Builder ( ) . description ( ""Files that cannot be flattened go to this relationship."" ) . name ( ""failure"" ) . build ( ) ; static final PropertyDescriptor SEPARATOR = new PropertyDescriptor . Builder ( ) . name ( ""flatten-json-separator"" ) . displayName ( ""Separator"" ) . defaultValue ( ""."" ) . description ( ""The separator character used for joining keys. Must be a JSON-legal character."" ) . addValidator ( ( subject , input , context ) -> { if ( context . isExpressionLanguagePresent ( input ) ) { ExpressionLanguageCompiler elc = context . newExpressionLanguageCompiler ( ) ; final boolean validExpression = elc . isValidExpression ( input ) ; return new ValidationResult . Builder ( ) . subject ( subject ) . input ( input ) . valid ( validExpression ) . explanation ( validExpression ? """" : ""Not a valid Expression"" ) . build ( ) ; } boolean valid = input != null && input . length ( ) == 1 ; String message = ! valid ? ""The separator must be a single character in length."" : """" ; ObjectMapper mapper = new ObjectMapper ( ) ; String test = String . format ( ""{ \""prop%sprop\"": \""test\"" }"" , input ) ; try { mapper . readValue ( test , Map . class ) ; } catch ( IOException e ) { message = e . getLocalizedMessage ( ) ; valid = false ; } return new ValidationResult . Builder ( ) . subject ( subject ) . input ( input ) . valid ( valid ) . explanation ( message ) . build ( ) ; } ) . expressionLanguageSupported ( ExpressionLanguageScope . FLOWFILE_ATTRIBUTES ) . build ( ) ; public static final AllowableValue FLATTEN_MODE_NORMAL = new AllowableValue ( ""normal"" , ""normal"" , ""Flattens every objects into a single level json"" ) ; public static final AllowableValue FLATTEN_MODE_KEEP_ARRAYS = new AllowableValue ( ""keep arrays"" , ""keep arrays"" , ""Flattens every objects and keep arrays format"" ) ; public static final AllowableValue FLATTEN_MODE_DOT_NOTATION = new AllowableValue ( ""dot notation"" , ""dot notation"" , ""Conforms to MongoDB dot notation to update also nested documents"" ) ; public static final PropertyDescriptor FLATTEN_MODE = new PropertyDescriptor . Builder ( ) . name ( ""flatten-mode"" ) . displayName ( ""Flatten Mode"" ) . description ( ""Specifies how json is flattened"" ) . defaultValue ( FLATTEN_MODE_KEEP_ARRAYS . getValue ( ) ) . required ( true ) . allowableValues ( FLATTEN_MODE_NORMAL , FLATTEN_MODE_KEEP_ARRAYS , FLATTEN_MODE_DOT_NOTATION ) . expressionLanguageSupported ( ExpressionLanguageScope . NONE ) . build ( ) ; private List < PropertyDescriptor > properties ; private Set < Relationship > relationships ; @ Override protected void init ( final ProcessorInitializationContext context ) { List < PropertyDescriptor > props = new ArrayList < > ( ) ; props . add ( SEPARATOR ) ; props . add ( FLATTEN_MODE ) ; properties = Collections . unmodifiableList ( props ) ; Set < Relationship > rels = new HashSet < > ( ) ; rels . add ( REL_SUCCESS ) ; rels . add ( REL_FAILURE ) ; relationships = Collections . unmodifiableSet ( rels ) ; } @ Override protected List < PropertyDescriptor > getSupportedPropertyDescriptors ( ) { return properties ; } @ Override public Set < Relationship > getRelationships ( ) { return relationships ; } @ Override public void onTrigger ( final ProcessContext context , final ProcessSession session ) throws ProcessException { FlowFile flowFile = session . get ( ) ; if ( flowFile == null ) { return ; } final String mode = context . getProperty ( FLATTEN_MODE ) . getValue ( ) ; final FlattenMode flattenMode = getFlattenMode ( mode ) ; String separator = context . getProperty ( SEPARATOR ) . evaluateAttributeExpressions ( flowFile ) . getValue ( ) ; try { ByteArrayOutputStream bos = new ByteArrayOutputStream ( ) ; session . exportTo ( flowFile , bos ) ; bos . close ( ) ; String raw = new String ( bos . toByteArray ( ) ) ; final String flattened = new JsonFlattener ( raw ) . withFlattenMode ( flattenMode ) . withSeparator ( separator . charAt ( 0 ) ) . withStringEscapePolicy ( ( ) -> StringEscapeUtils . ESCAPE_JSON ) . flatten ( ) ; flowFile = session . write ( flowFile , os -> os . write ( flattened . getBytes ( ) ) ) ; session . transfer ( flowFile , REL_SUCCESS ) ; } catch ( Exception ex ) { session . transfer ( flowFile , REL_FAILURE ) ; } } private FlattenMode getFlattenMode ( String mode ) { if ( FLATTEN_MODE_NORMAL . getValue ( ) . equals ( mode ) ) { return FlattenMode . NORMAL ; } else if ( FLATTEN_MODE_DOT_NOTATION . getValue ( ) . equals ( mode ) ) { return FlattenMode . MONGODB ; } else { return FlattenMode . KEEP_ARRAYS ; } } }",No
"public class EJBQLException extends ExpressionException { public EJBQLException ( ) { super ( ) ; } public EJBQLException ( String messageFormat , Object ... messageArgs ) { super ( messageFormat , messageArgs ) ; } public EJBQLException ( String messageFormat , String expressionString , Throwable th , Object ... messageArgs ) { super ( messageFormat , expressionString , th , messageArgs ) ; } public EJBQLException ( String messageFormat , Throwable cause , Object ... messageArgs ) { super ( messageFormat , cause , messageArgs ) ; } public EJBQLException ( Throwable cause ) { super ( cause ) ; } }",No
"public class GreaterThanExpressionUnitTest { static GreaterThanExpression greaterThanExpression ; @ Test public void testEvaluateForGreaterThanExpressionWithStringDataType ( ) throws FilterUnsupportedException , FilterIllegalMemberException { ColumnExpression left = new ColumnExpression ( ""left_name"" , DataTypes . STRING ) ; left . setColIndex ( 0 ) ; ColumnExpression right = new ColumnExpression ( ""right_name"" , DataTypes . STRING ) ; right . setColIndex ( 1 ) ; greaterThanExpression = new GreaterThanExpression ( left , right ) ; RowImpl value = new RowImpl ( ) ; String [ ] row = { ""string1"" } ; String [ ] row1 = { ""String's Value"" } ; Object objectRow [ ] = { row , row1 } ; new MockUp < ExpressionResult > ( ) { Boolean returnMockFlag = true ; @ Mock public String getString ( ) { if ( returnMockFlag ) { returnMockFlag = false ; return ""string1"" ; } else { return ""String's Value"" ; } } } ; value . setValues ( objectRow ) ; ExpressionResult result = greaterThanExpression . evaluate ( value ) ; assertTrue ( result . getBoolean ( ) ) ; } @ Test public void testEvaluateForGreaterThanExpressionWithShortDataType ( ) throws FilterUnsupportedException , FilterIllegalMemberException { ColumnExpression right = new ColumnExpression ( ""id"" , DataTypes . SHORT ) ; right . setColIndex ( 0 ) ; ColumnExpression left = new ColumnExpression ( ""id"" , DataTypes . SHORT ) ; left . setColIndex ( 1 ) ; greaterThanExpression = new GreaterThanExpression ( left , right ) ; RowImpl value = new RowImpl ( ) ; Short [ ] row = { 170 } ; Short [ ] row1 = { 70 } ; Object objectRow [ ] = { row , row1 } ; value . setValues ( objectRow ) ; new MockUp < ExpressionResult > ( ) { Boolean returnMockFlag = true ; @ Mock public Short getShort ( ) { if ( returnMockFlag ) { returnMockFlag = false ; return 170 ; } else { return 70 ; } } } ; ExpressionResult result = greaterThanExpression . evaluate ( value ) ; assertTrue ( result . getBoolean ( ) ) ; } @ Test public void testEvaluateForGreaterThanExpressionWithShortDataType1 ( ) throws FilterUnsupportedException , FilterIllegalMemberException { ColumnExpression right = new ColumnExpression ( ""id"" , DataTypes . SHORT ) ; right . setColIndex ( 0 ) ; ColumnExpression left = new ColumnExpression ( ""id"" , DataTypes . SHORT ) ; left . setColIndex ( 1 ) ; greaterThanExpression = new GreaterThanExpression ( left , right ) ; RowImpl value = new RowImpl ( ) ; Short [ ] row = { 170 } ; Short [ ] row1 = { 70 } ; Object objectRow [ ] = { row , row1 } ; value . setValues ( objectRow ) ; new MockUp < ExpressionResult > ( ) { Boolean returnMockFlag = true ; @ Mock public Short getShort ( ) { if ( returnMockFlag ) { returnMockFlag = false ; return 70 ; } else { return 170 ; } } } ; ExpressionResult result = greaterThanExpression . evaluate ( value ) ; assertFalse ( result . getBoolean ( ) ) ; } @ Test public void testEvaluateForGreaterThanExpressionWithDoubleDataType ( ) throws FilterUnsupportedException , FilterIllegalMemberException { ColumnExpression right = new ColumnExpression ( ""right_contact"" , DataTypes . DOUBLE ) ; right . setColIndex ( 0 ) ; ColumnExpression left = new ColumnExpression ( ""left_contact"" , DataTypes . DOUBLE ) ; left . setColIndex ( 1 ) ; greaterThanExpression = new GreaterThanExpression ( left , right ) ; RowImpl value = new RowImpl ( ) ; Double [ ] row = { 44D } ; Double [ ] row1 = { 20D } ; Object objectRow [ ] = { row1 , row } ; value . setValues ( objectRow ) ; new MockUp < ExpressionResult > ( ) { Boolean returnMockFlag = true ; @ Mock public Double getDouble ( ) { if ( returnMockFlag ) { returnMockFlag = false ; return 44D ; } else { return 20D ; } } } ; ExpressionResult result = greaterThanExpression . evaluate ( value ) ; assertTrue ( result . getBoolean ( ) ) ; } @ Test public void testEvaluateForGreaterThanExpressionWithIntDataType ( ) throws FilterUnsupportedException , FilterIllegalMemberException { ColumnExpression right = new ColumnExpression ( ""right_number"" , DataTypes . INT ) ; right . setColIndex ( 0 ) ; ColumnExpression left = new ColumnExpression ( ""left_number"" , DataTypes . INT ) ; left . setColIndex ( 1 ) ; greaterThanExpression = new GreaterThanExpression ( left , right ) ; RowImpl value = new RowImpl ( ) ; Integer [ ] row = { 140 } ; Integer [ ] row1 = { 150 } ; Object objectRow [ ] = { row , row1 } ; value . setValues ( objectRow ) ; new MockUp < ExpressionResult > ( ) { Boolean returnMockFlag = true ; @ Mock public Integer getInt ( ) { if ( returnMockFlag ) { returnMockFlag = false ; return 150 ; } else { return 140 ; } } } ; ExpressionResult result = greaterThanExpression . evaluate ( value ) ; assertTrue ( result . getBoolean ( ) ) ; } @ Test public void testEvaluateForGreaterThanExpressionWithTimestampDataType ( ) throws FilterUnsupportedException , FilterIllegalMemberException { try { ColumnExpression left = new ColumnExpression ( ""timestamp"" , DataTypes . TIMESTAMP ) ; left . setColIndex ( 0 ) ; ColumnExpression right = new ColumnExpression ( ""timestamp"" , DataTypes . TIMESTAMP ) ; right . setColIndex ( 1 ) ; greaterThanExpression = new GreaterThanExpression ( left , right ) ; RowImpl value = new RowImpl ( ) ; DateFormat dateFormat = new SimpleDateFormat ( ""dd/MM/yyyy"" ) ; Date date = dateFormat . parse ( ""23/09/2007"" ) ; long time = date . getTime ( ) ; Timestamp [ ] row = { new Timestamp ( time ) } ; Date date1 = dateFormat . parse ( ""24/09/2007"" ) ; long time1 = date1 . getTime ( ) ; Timestamp [ ] row1 = { new Timestamp ( time1 ) } ; Object objectRow [ ] = { row1 , row } ; value . setValues ( objectRow ) ; new MockUp < ExpressionResult > ( ) { Boolean returnMockFlag = true ; @ Mock public Long getTimeAsMillisecond ( ) { if ( returnMockFlag ) { returnMockFlag = false ; return 1190592000L ; } else { return 1190505600L ; } } } ; ExpressionResult result = greaterThanExpression . evaluate ( value ) ; assertTrue ( result . getBoolean ( ) ) ; } catch ( ParseException e ) { System . out . println ( ""Error while parsing "" + e . getMessage ( ) ) ; } } @ Test public void testEvaluateForGreaterThanExpressionWithTimestampDataType1 ( ) throws FilterUnsupportedException , FilterIllegalMemberException { try { ColumnExpression left = new ColumnExpression ( ""timestamp"" , DataTypes . TIMESTAMP ) ; left . setColIndex ( 0 ) ; ColumnExpression right = new ColumnExpression ( ""timestamp"" , DataTypes . TIMESTAMP ) ; right . setColIndex ( 1 ) ; greaterThanExpression = new GreaterThanExpression ( left , right ) ; RowImpl value = new RowImpl ( ) ; DateFormat dateFormat = new SimpleDateFormat ( ""dd/MM/yyyy"" ) ; Date date = dateFormat . parse ( ""23/09/2007"" ) ; long time = date . getTime ( ) ; Timestamp [ ] row = { new Timestamp ( time ) } ; Date date1 = dateFormat . parse ( ""24/09/2007"" ) ; long time1 = date1 . getTime ( ) ; Timestamp [ ] row1 = { new Timestamp ( time1 ) } ; Object objectRow [ ] = { row1 , row } ; value . setValues ( objectRow ) ; new MockUp < ExpressionResult > ( ) { Boolean returnMockFlag = true ; @ Mock public Long getTimeAsMillisecond ( ) { if ( returnMockFlag ) { returnMockFlag = false ; return 1190505600L ; } else { return 1190592000L ; } } } ; ExpressionResult result = greaterThanExpression . evaluate ( value ) ; assertFalse ( result . getBoolean ( ) ) ; } catch ( ParseException e ) { System . out . println ( ""Error while parsing "" + e . getMessage ( ) ) ; } } @ Test public void testEvaluateForGreaterThanExpressionWithLongDataType ( ) throws FilterUnsupportedException , FilterIllegalMemberException { ColumnExpression right = new ColumnExpression ( ""contact"" , DataTypes . LONG ) ; right . setColIndex ( 0 ) ; ColumnExpression left = new ColumnExpression ( ""contact"" , DataTypes . LONG ) ; left . setColIndex ( 1 ) ; greaterThanExpression = new GreaterThanExpression ( left , right ) ; RowImpl value = new RowImpl ( ) ; Long [ ] row = { 1234567654321L } ; Long [ ] row1 = { 123456765432234L } ; Object objectRow [ ] = { row1 , row } ; value . setValues ( objectRow ) ; new MockUp < ExpressionResult > ( ) { Boolean returnMockFlag = true ; @ Mock public Long getLong ( ) { if ( returnMockFlag ) { returnMockFlag = false ; return 123456765432234L ; } else { return 1234567654321L ; } } } ; ExpressionResult result = greaterThanExpression . evaluate ( value ) ; assertTrue ( result . getBoolean ( ) ) ; } @ Test public void testEvaluateForGreaterThanExpressionWithLongDataType1 ( ) throws FilterUnsupportedException , FilterIllegalMemberException { ColumnExpression right = new ColumnExpression ( ""contact"" , DataTypes . LONG ) ; right . setColIndex ( 0 ) ; ColumnExpression left = new ColumnExpression ( ""contact"" , DataTypes . LONG ) ; left . setColIndex ( 1 ) ; greaterThanExpression = new GreaterThanExpression ( left , right ) ; RowImpl value = new RowImpl ( ) ; Long [ ] row = { 1234567654321L } ; Long [ ] row1 = { 123456765432234L } ; Object objectRow [ ] = { row1 , row } ; value . setValues ( objectRow ) ; new MockUp < ExpressionResult > ( ) { Boolean returnMockFlag = true ; @ Mock public Long getLong ( ) { if ( returnMockFlag ) { returnMockFlag = false ; return 1234567654321L ; } else { return 123456765432234L ; } } } ; ExpressionResult result = greaterThanExpression . evaluate ( value ) ; assertFalse ( result . getBoolean ( ) ) ; } @ Test public void testEvaluateForGreaterThanExpressionWithDecimalDataType ( ) throws FilterUnsupportedException , FilterIllegalMemberException { ColumnExpression right = new ColumnExpression ( ""contact"" , DataTypes . createDefaultDecimalType ( ) ) ; right . setColIndex ( 0 ) ; ColumnExpression left = new ColumnExpression ( ""contact"" , DataTypes . createDefaultDecimalType ( ) ) ; left . setColIndex ( 1 ) ; greaterThanExpression = new GreaterThanExpression ( left , right ) ; RowImpl value = new RowImpl ( ) ; BigDecimal [ ] row = new BigDecimal [ ] { new BigDecimal ( 12345.0 ) } ; BigDecimal [ ] row1 = new BigDecimal [ ] { new BigDecimal ( 123451245.0 ) } ; Object objectRow [ ] = { row1 , row } ; value . setValues ( objectRow ) ; new MockUp < ExpressionResult > ( ) { Boolean returnMockFlag = true ; @ Mock public BigDecimal getDecimal ( ) { if ( returnMockFlag ) { returnMockFlag = false ; return new BigDecimal ( 123451245.0 ) ; } else { return new BigDecimal ( 12345.0 ) ; } } } ; ExpressionResult result = greaterThanExpression . evaluate ( value ) ; assertTrue ( result . getBoolean ( ) ) ; } @ Test public void testEvaluateForGreaterThanExpressionWithDecimalDataType1 ( ) throws FilterUnsupportedException , FilterIllegalMemberException { ColumnExpression right = new ColumnExpression ( ""contact"" , DataTypes . createDefaultDecimalType ( ) ) ; right . setColIndex ( 0 ) ; ColumnExpression left = new ColumnExpression ( ""contact"" , DataTypes . createDefaultDecimalType ( ) ) ; left . setColIndex ( 1 ) ; greaterThanExpression = new GreaterThanExpression ( left , right ) ; RowImpl value = new RowImpl ( ) ; BigDecimal [ ] row = new BigDecimal [ ] { new BigDecimal ( 12345.0 ) } ; BigDecimal [ ] row1 = new BigDecimal [ ] { new BigDecimal ( 123451245.0 ) } ; Object objectRow [ ] = { row1 , row } ; value . setValues ( objectRow ) ; new MockUp < ExpressionResult > ( ) { Boolean returnMockFlag = true ; @ Mock public BigDecimal getDecimal ( ) { if ( returnMockFlag ) { returnMockFlag = false ; return new BigDecimal ( 12345.0 ) ; } else { return new BigDecimal ( 123451245.0 ) ; } } } ; ExpressionResult result = greaterThanExpression . evaluate ( value ) ; assertFalse ( result . getBoolean ( ) ) ; } @ Test public void testForGreaterThanExpressionWithDefaultCase ( ) throws FilterUnsupportedException , FilterIllegalMemberException { ColumnExpression right = new ColumnExpression ( ""contact"" , DataTypes . BOOLEAN ) ; right . setColIndex ( 0 ) ; greaterThanExpression = new GreaterThanExpression ( right , right ) ; RowImpl value = new RowImpl ( ) ; Boolean [ ] row = { true } ; Object objectRow [ ] = { row } ; value . setValues ( objectRow ) ; greaterThanExpression . evaluate ( value ) ; } @ Test public void testEvaluateForGreaterThanExpressionWithIsNullReturnTrue ( ) throws FilterUnsupportedException , FilterIllegalMemberException { ColumnExpression right = new ColumnExpression ( ""id"" , DataTypes . SHORT ) ; right . setColIndex ( 0 ) ; greaterThanExpression = new GreaterThanExpression ( right , right ) ; RowImpl value = new RowImpl ( ) ; Short [ ] row = { 15 } ; Object objectRow [ ] = { row } ; value . setValues ( objectRow ) ; new MockUp < ExpressionResult > ( ) { @ Mock public boolean isNull ( ) { return true ; } } ; new MockUp < ExpressionResult > ( ) { @ Mock public Short getShort ( ) { return 15 ; } } ; ExpressionResult result = greaterThanExpression . evaluate ( value ) ; assertFalse ( result . getBoolean ( ) ) ; } @ Test public void testEvaluateForGreaterThanExpressionWithIsNullReturnTrue1 ( ) throws FilterUnsupportedException , FilterIllegalMemberException { ColumnExpression right = new ColumnExpression ( ""id"" , DataTypes . SHORT ) ; right . setColIndex ( 0 ) ; greaterThanExpression = new GreaterThanExpression ( right , right ) ; RowImpl value = new RowImpl ( ) ; Short [ ] row = { 15 } ; Object objectRow [ ] = { row } ; value . setValues ( objectRow ) ; new MockUp < ExpressionResult > ( ) { boolean isFirst = true ; @ Mock public boolean isNull ( ) { if ( isFirst ) { isFirst = false ; return false ; } return true ; } } ; new MockUp < ExpressionResult > ( ) { @ Mock public Short getShort ( ) { return 15 ; } } ; ExpressionResult result = greaterThanExpression . evaluate ( value ) ; assertFalse ( result . getBoolean ( ) ) ; } @ Test public void testEvaluateForGreaterThanExpressionWithLeftAndRightDifferentDataType ( ) throws FilterUnsupportedException , FilterIllegalMemberException { ColumnExpression left = new ColumnExpression ( ""name"" , DataTypes . STRING ) ; left . setColIndex ( 0 ) ; ColumnExpression right = new ColumnExpression ( ""number"" , DataTypes . INT ) ; right . setColIndex ( 1 ) ; greaterThanExpression = new GreaterThanExpression ( left , right ) ; RowImpl value = new RowImpl ( ) ; String [ ] row = { ""String1"" } ; Integer [ ] row1 = { 14 } ; Object objectRow [ ] = { row , row1 } ; value . setValues ( objectRow ) ; new MockUp < ExpressionResult > ( ) { Boolean returnMockFlag = true ; @ Mock public Integer getInt ( ) { if ( returnMockFlag ) { returnMockFlag = false ; return 15 ; } else { return 14 ; } } } ; ExpressionResult result = greaterThanExpression . evaluate ( value ) ; assertTrue ( result . getBoolean ( ) ) ; } @ Test public void testEvaluateForGreaterThanExpressionWithLeftAndRightDifferentDataType1 ( ) throws FilterUnsupportedException , FilterIllegalMemberException { ColumnExpression left = new ColumnExpression ( ""name"" , DataTypes . INT ) ; left . setColIndex ( 0 ) ; ColumnExpression right = new ColumnExpression ( ""number"" , DataTypes . STRING ) ; right . setColIndex ( 1 ) ; greaterThanExpression = new GreaterThanExpression ( left , right ) ; RowImpl value = new RowImpl ( ) ; String [ ] row = { ""String1"" } ; Integer [ ] row1 = { 14 } ; Object objectRow [ ] = { row1 , row } ; value . setValues ( objectRow ) ; new MockUp < ExpressionResult > ( ) { Boolean returnMockFlag = true ; @ Mock public Integer getInt ( ) { if ( returnMockFlag ) { returnMockFlag = false ; return 15 ; } else { return 14 ; } } } ; ExpressionResult result = greaterThanExpression . evaluate ( value ) ; assertTrue ( result . getBoolean ( ) ) ; } @ Test public void testForGreaterThanExpressionWithGetString ( ) throws Exception { ColumnExpression right = new ColumnExpression ( ""right_name"" , DataTypes . STRING ) ; right . setColIndex ( 0 ) ; ColumnExpression left = new ColumnExpression ( ""left_name"" , DataTypes . STRING ) ; left . setColIndex ( 0 ) ; greaterThanExpression = new GreaterThanExpression ( left , right ) ; String expected_result = ""GreaterThan(ColumnExpression(left_name),ColumnExpression(right_name))"" ; String result = greaterThanExpression . getString ( ) ; assertEquals ( expected_result , result ) ; } }",Smelly
"public class AMQ2801Test { private static final Logger LOG = LoggerFactory . getLogger ( AMQ2801Test . class ) ; private static final String TOPICNAME = ""InvalidPendingQueueTest"" ; private static final String SELECTOR1 = ""JMS_ID"" + "" = '"" + ""TEST"" + ""'"" ; private static final String SELECTOR2 = ""JMS_ID"" + "" = '"" + ""TEST2"" + ""'"" ; private static final String SUBSCRIPTION1 = ""InvalidPendingQueueTest_1"" ; private static final String SUBSCRIPTION2 = ""InvalidPendingQueueTest_2"" ; private static final int MSG_COUNT = 2500 ; private Session session1 ; private Connection conn1 ; private Topic topic1 ; private MessageConsumer consumer1 ; private Session session2 ; private Connection conn2 ; private Topic topic2 ; private MessageConsumer consumer2 ; private BrokerService broker ; private String connectionUri ; @ Before public void setUp ( ) throws Exception { broker = new BrokerService ( ) ; broker . setDataDirectory ( ""target"" + File . separator + ""activemq-data"" ) ; broker . setPersistent ( true ) ; broker . setUseJmx ( true ) ; broker . setAdvisorySupport ( false ) ; broker . setDeleteAllMessagesOnStartup ( true ) ; broker . addConnector ( ""tcp://localhost:0"" ) . setName ( ""Default"" ) ; applyMemoryLimitPolicy ( broker ) ; broker . start ( ) ; connectionUri = broker . getTransportConnectors ( ) . get ( 0 ) . getPublishableConnectString ( ) ; } private void applyMemoryLimitPolicy ( BrokerService broker ) { final SystemUsage memoryManager = new SystemUsage ( ) ; memoryManager . getMemoryUsage ( ) . setLimit ( 5818230784L ) ; memoryManager . getStoreUsage ( ) . setLimit ( 6442450944L ) ; memoryManager . getTempUsage ( ) . setLimit ( 3221225472L ) ; broker . setSystemUsage ( memoryManager ) ; final List < PolicyEntry > policyEntries = new ArrayList < PolicyEntry > ( ) ; final PolicyEntry entry = new PolicyEntry ( ) ; entry . setQueue ( "">"" ) ; entry . setProducerFlowControl ( false ) ; entry . setMemoryLimit ( 504857608 ) ; entry . setPendingQueuePolicy ( new FilePendingQueueMessageStoragePolicy ( ) ) ; policyEntries . add ( entry ) ; final PolicyMap policyMap = new PolicyMap ( ) ; policyMap . setPolicyEntries ( policyEntries ) ; broker . setDestinationPolicy ( policyMap ) ; } @ After public void tearDown ( ) throws Exception { conn1 . close ( ) ; conn2 . close ( ) ; if ( broker != null ) { broker . stop ( ) ; } } private void produceMessages ( ) throws Exception { TopicConnection connection = createConnection ( ) ; TopicSession session = connection . createTopicSession ( false , Session . AUTO_ACKNOWLEDGE ) ; Topic topic = session . createTopic ( TOPICNAME ) ; TopicPublisher producer = session . createPublisher ( topic ) ; connection . start ( ) ; producer . setDeliveryMode ( DeliveryMode . PERSISTENT ) ; long tStamp = System . currentTimeMillis ( ) ; BytesMessage message = session2 . createBytesMessage ( ) ; for ( int i = 1 ; i <= MSG_COUNT ; i ++ ) { message . setStringProperty ( ""JMS_ID"" , ""TEST"" ) ; message . setIntProperty ( ""Type"" , i ) ; producer . publish ( message ) ; if ( i % 100 == 0 ) { LOG . info ( ""sent: "" + i + "" @ "" + ( ( System . currentTimeMillis ( ) - tStamp ) / 100 ) + ""m/ms"" ) ; tStamp = System . currentTimeMillis ( ) ; } } } private void activeateSubscribers ( ) throws Exception { conn1 = createConnection ( ) ; conn1 . setClientID ( SUBSCRIPTION1 ) ; session1 = conn1 . createSession ( true , Session . SESSION_TRANSACTED ) ; topic1 = session1 . createTopic ( TOPICNAME ) ; consumer1 = session1 . createDurableSubscriber ( topic1 , SUBSCRIPTION1 , SELECTOR1 , false ) ; conn1 . start ( ) ; conn2 = createConnection ( ) ; conn2 . setClientID ( SUBSCRIPTION2 ) ; session2 = conn2 . createSession ( true , Session . SESSION_TRANSACTED ) ; topic2 = session2 . createTopic ( TOPICNAME ) ; consumer2 = session2 . createDurableSubscriber ( topic2 , SUBSCRIPTION2 , SELECTOR2 , false ) ; conn2 . start ( ) ; } @ Test public void testInvalidPendingQueue ( ) throws Exception { activeateSubscribers ( ) ; assertNotNull ( consumer1 ) ; assertNotNull ( consumer2 ) ; produceMessages ( ) ; LOG . debug ( ""Sent messages to a single subscriber"" ) ; Thread . sleep ( 2000 ) ; LOG . debug ( ""Closing durable subscriber connections"" ) ; conn1 . close ( ) ; conn2 . close ( ) ; LOG . debug ( ""Closed durable subscriber connections"" ) ; Thread . sleep ( 2000 ) ; LOG . debug ( ""Re-starting durable subscriber connections"" ) ; activeateSubscribers ( ) ; LOG . debug ( ""Started up durable subscriber connections - now view activemq console to see pending queue size on the other subscriber"" ) ; ObjectName [ ] subs = broker . getAdminView ( ) . getDurableTopicSubscribers ( ) ; for ( int i = 0 ; i < subs . length ; i ++ ) { ObjectName subName = subs [ i ] ; DurableSubscriptionViewMBean sub = ( DurableSubscriptionViewMBean ) broker . getManagementContext ( ) . newProxyInstance ( subName , DurableSubscriptionViewMBean . class , true ) ; LOG . info ( sub . getSubscriptionName ( ) + "": pending = "" + sub . getPendingQueueSize ( ) + "", dispatched: "" + sub . getDispatchedQueueSize ( ) ) ; if ( sub . getSubscriptionName ( ) . equals ( SUBSCRIPTION1 ) ) { assertEquals ( ""Incorrect number of pending messages"" , MSG_COUNT , sub . getPendingQueueSize ( ) + sub . getDispatchedQueueSize ( ) ) ; } else { assertEquals ( ""Incorrect number of pending messages"" , 0 , sub . getPendingQueueSize ( ) ) ; } } } private TopicConnection createConnection ( ) throws Exception { ActiveMQConnectionFactory connectionFactory = new ActiveMQConnectionFactory ( ) ; connectionFactory . setBrokerURL ( connectionUri ) ; TopicConnection conn = connectionFactory . createTopicConnection ( ) ; return conn ; } }",No
"public class CommentTest extends TestCase { public static Log log = LogFactory . getLog ( CommentTest . class ) ; User testUser = null ; Weblog testWeblog = null ; WeblogEntry testEntry = null ; public CommentTest ( String name ) { super ( name ) ; } public static Test suite ( ) { return new TestSuite ( CommentTest . class ) ; } public void setUp ( ) throws Exception { TestUtils . setupWeblogger ( ) ; try { testUser = TestUtils . setupUser ( ""commentTestUser"" ) ; testWeblog = TestUtils . setupWeblog ( ""commentTestWeblog"" , testUser ) ; testEntry = TestUtils . setupWeblogEntry ( ""commentTestEntry"" , testWeblog , testUser ) ; TestUtils . endSession ( true ) ; } catch ( Exception ex ) { log . error ( ex ) ; throw new Exception ( ""Test setup failed"" , ex ) ; } } public void tearDown ( ) throws Exception { try { TestUtils . teardownWeblogEntry ( testEntry . getId ( ) ) ; TestUtils . teardownWeblog ( testWeblog . getId ( ) ) ; TestUtils . teardownUser ( testUser . getUserName ( ) ) ; TestUtils . endSession ( true ) ; } catch ( Exception ex ) { log . error ( ex ) ; throw new Exception ( ""Test teardown failed"" , ex ) ; } } public void testCommentCRUD ( ) throws Exception { WeblogEntryManager mgr = WebloggerFactory . getWeblogger ( ) . getWeblogEntryManager ( ) ; WeblogEntryComment comment = new WeblogEntryComment ( ) ; comment . setName ( ""test"" ) ; comment . setEmail ( ""test"" ) ; comment . setUrl ( ""test"" ) ; comment . setRemoteHost ( ""foofoo"" ) ; comment . setContent ( ""this is a test comment"" ) ; comment . setPostTime ( new java . sql . Timestamp ( new java . util . Date ( ) . getTime ( ) ) ) ; comment . setWeblogEntry ( TestUtils . getManagedWeblogEntry ( testEntry ) ) ; comment . setStatus ( ApprovalStatus . APPROVED ) ; mgr . saveComment ( comment ) ; String id = comment . getId ( ) ; TestUtils . endSession ( true ) ; comment = mgr . getComment ( id ) ; assertNotNull ( comment ) ; assertEquals ( ""this is a test comment"" , comment . getContent ( ) ) ; comment . setContent ( ""testtest"" ) ; mgr . saveComment ( comment ) ; TestUtils . endSession ( true ) ; comment = mgr . getComment ( id ) ; assertNotNull ( comment ) ; assertEquals ( ""testtest"" , comment . getContent ( ) ) ; mgr . removeComment ( comment ) ; TestUtils . endSession ( true ) ; comment = mgr . getComment ( id ) ; assertNull ( comment ) ; } public void testCommentLookups ( ) throws Exception { WeblogEntryManager mgr = WebloggerFactory . getWeblogger ( ) . getWeblogEntryManager ( ) ; List comments ; testEntry = TestUtils . getManagedWeblogEntry ( testEntry ) ; WeblogEntryComment comment1 = TestUtils . setupComment ( ""comment1"" , testEntry ) ; WeblogEntryComment comment2 = TestUtils . setupComment ( ""comment2"" , testEntry ) ; WeblogEntryComment comment3 = TestUtils . setupComment ( ""comment3"" , testEntry ) ; TestUtils . endSession ( true ) ; CommentSearchCriteria csc = new CommentSearchCriteria ( ) ; comments = mgr . getComments ( csc ) ; assertNotNull ( comments ) ; assertEquals ( 3 , comments . size ( ) ) ; testEntry = TestUtils . getManagedWeblogEntry ( testEntry ) ; csc . setEntry ( testEntry ) ; comments = mgr . getComments ( csc ) ; assertNotNull ( comments ) ; assertEquals ( 3 , comments . size ( ) ) ; comment3 = mgr . getComment ( comment3 . getId ( ) ) ; comment3 . setStatus ( ApprovalStatus . PENDING ) ; mgr . saveComment ( comment3 ) ; TestUtils . endSession ( true ) ; csc . setEntry ( null ) ; csc . setStatus ( ApprovalStatus . PENDING ) ; comments = mgr . getComments ( csc ) ; assertNotNull ( comments ) ; assertEquals ( 1 , comments . size ( ) ) ; csc . setStatus ( ApprovalStatus . APPROVED ) ; comments = mgr . getComments ( csc ) ; assertNotNull ( comments ) ; assertEquals ( 2 , comments . size ( ) ) ; csc . setStatus ( null ) ; csc . setOffset ( 1 ) ; comments = mgr . getComments ( csc ) ; assertNotNull ( comments ) ; assertEquals ( 2 , comments . size ( ) ) ; TestUtils . teardownComment ( comment1 . getId ( ) ) ; TestUtils . teardownComment ( comment2 . getId ( ) ) ; TestUtils . teardownComment ( comment3 . getId ( ) ) ; TestUtils . endSession ( true ) ; } public void testCommentParentDeletes ( ) throws Exception { log . info ( ""BEGIN"" ) ; try { WeblogManager wmgr = WebloggerFactory . getWeblogger ( ) . getWeblogManager ( ) ; WeblogEntryManager emgr = WebloggerFactory . getWeblogger ( ) . getWeblogEntryManager ( ) ; UserManager umgr = WebloggerFactory . getWeblogger ( ) . getUserManager ( ) ; User user = TestUtils . setupUser ( ""commentParentDeleteUser"" ) ; Weblog weblog = TestUtils . setupWeblog ( ""commentParentDelete"" , user ) ; WeblogEntry entry = TestUtils . setupWeblogEntry ( ""CommentParentDeletes1"" , weblog , user ) ; TestUtils . endSession ( true ) ; entry = TestUtils . getManagedWeblogEntry ( entry ) ; TestUtils . setupComment ( ""comment1"" , entry ) ; TestUtils . setupComment ( ""comment2"" , entry ) ; TestUtils . setupComment ( ""comment3"" , entry ) ; TestUtils . endSession ( true ) ; Exception ex = null ; try { emgr . removeWeblogEntry ( TestUtils . getManagedWeblogEntry ( entry ) ) ; TestUtils . endSession ( true ) ; } catch ( WebloggerException e ) { ex = e ; } assertNull ( ex ) ; weblog = TestUtils . getManagedWebsite ( weblog ) ; user = TestUtils . getManagedUser ( user ) ; entry = TestUtils . setupWeblogEntry ( ""CommentParentDeletes2"" , weblog , user ) ; TestUtils . endSession ( true ) ; entry = TestUtils . getManagedWeblogEntry ( entry ) ; TestUtils . setupComment ( ""comment1"" , entry ) ; TestUtils . setupComment ( ""comment2"" , entry ) ; TestUtils . setupComment ( ""comment3"" , entry ) ; TestUtils . endSession ( true ) ; ex = null ; try { weblog = TestUtils . getManagedWebsite ( weblog ) ; wmgr . removeWeblog ( weblog ) ; TestUtils . endSession ( true ) ; } catch ( WebloggerException e ) { StringWriter sw = new StringWriter ( ) ; PrintWriter pw = new PrintWriter ( sw ) ; e . printStackTrace ( pw ) ; log . info ( sw . toString ( ) ) ; ex = e ; } assertNull ( ex ) ; umgr . removeUser ( TestUtils . getManagedUser ( user ) ) ; } finally { TestUtils . endSession ( true ) ; } log . info ( ""END"" ) ; } }",Smelly
"class BooleanCompletor extends SimpleCompletor { public BooleanCompletor ( ) { super ( new String [ ] { ""true"" , ""false"" } ) ; } }",No
" private class ListBindingEnumeration extends LocalNamingEnumeration { ListBindingEnumeration ( ) { } public Object next ( ) throws NamingException { return nextElement ( ) ; } public Object nextElement ( ) { Map . Entry entry = getNext ( ) ; return new Binding ( ( String ) entry . getKey ( ) , entry . getValue ( ) ) ; } } ",No
 private static class alter_table_resultTupleSchemeFactory implements SchemeFactory { public alter_table_resultTupleScheme getScheme ( ) { return new alter_table_resultTupleScheme ( ) ; } ,No
 private static class addLocalDataMovementDetails_argsTupleSchemeFactory implements SchemeFactory { public addLocalDataMovementDetails_argsTupleScheme getScheme ( ) { return new addLocalDataMovementDetails_argsTupleScheme ( ) ; } ,No
" private class PreparedStatementWithColumnIndexes implements StatementBuilder { @ Override public Statement createStatement ( final Connection connection ) throws SQLException { return connection . prepareStatement ( sql , columnIndexes ) ; } ",No
"public class ParametersTest { @ Test public void shouldGetKeyValuesEmpty ( ) { final Parameters parameters = new Parameters ( ) ; assertThat ( Arrays . equals ( parameters . getKeyValues ( mock ( Traverser . Admin . class ) ) , new Object [ 0 ] ) , is ( true ) ) ; } @ Test public void shouldGetKeyValues ( ) { final Parameters parameters = new Parameters ( ) ; parameters . set ( null , ""a"" , ""axe"" , ""b"" , ""bat"" , ""c"" , ""cat"" ) ; final Object [ ] params = parameters . getKeyValues ( mock ( Traverser . Admin . class ) ) ; assertEquals ( 6 , params . length ) ; assertThat ( Arrays . equals ( new Object [ ] { ""a"" , ""axe"" , ""b"" , ""bat"" , ""c"" , ""cat"" } , params ) , is ( true ) ) ; } @ Test public void shouldGetKeyValuesIgnoringSomeKeys ( ) { final Parameters parameters = new Parameters ( ) ; parameters . set ( null , ""a"" , ""axe"" , ""b"" , ""bat"" , ""c"" , ""cat"" ) ; final Object [ ] params = parameters . getKeyValues ( mock ( Traverser . Admin . class ) , ""b"" ) ; assertEquals ( 4 , params . length ) ; assertThat ( Arrays . equals ( new Object [ ] { ""a"" , ""axe"" , ""c"" , ""cat"" } , params ) , is ( true ) ) ; } @ Test public void shouldGetUsingTraverserOverload ( ) { final Parameters parameters = new Parameters ( ) ; parameters . set ( null , ""a"" , ""axe"" , ""b"" , ""bat"" , ""c"" , ""cat"" ) ; assertEquals ( Collections . singletonList ( ""axe"" ) , parameters . get ( mock ( Traverser . Admin . class ) , ""a"" , ( ) -> ""x"" ) ) ; assertEquals ( Collections . singletonList ( ""bat"" ) , parameters . get ( mock ( Traverser . Admin . class ) , ""b"" , ( ) -> ""x"" ) ) ; assertEquals ( Collections . singletonList ( ""cat"" ) , parameters . get ( mock ( Traverser . Admin . class ) , ""c"" , ( ) -> ""x"" ) ) ; assertEquals ( Collections . singletonList ( ""zebra"" ) , parameters . get ( mock ( Traverser . Admin . class ) , ""z"" , ( ) -> ""zebra"" ) ) ; } @ Test public void shouldGetMultipleUsingTraverserOverload ( ) { final Parameters parameters = new Parameters ( ) ; parameters . set ( null , ""a"" , ""axe"" , ""a"" , ""ant"" , ""b"" , ""bat"" , ""b"" , ""ball"" , ""c"" , ""cat"" ) ; final Map < Object , List < Object > > params = parameters . getRaw ( ) ; assertEquals ( 3 , params . size ( ) ) ; assertEquals ( Arrays . asList ( ""axe"" , ""ant"" ) , parameters . get ( mock ( Traverser . Admin . class ) , ""a"" , ( ) -> ""x"" ) ) ; assertEquals ( Arrays . asList ( ""bat"" , ""ball"" ) , parameters . get ( mock ( Traverser . Admin . class ) , ""b"" , ( ) -> ""x"" ) ) ; assertEquals ( Collections . singletonList ( ""cat"" ) , parameters . get ( mock ( Traverser . Admin . class ) , ""c"" , ( ) -> ""x"" ) ) ; assertEquals ( Collections . singletonList ( ""zebra"" ) , parameters . get ( mock ( Traverser . Admin . class ) , ""z"" , ( ) -> ""zebra"" ) ) ; } @ Test public void shouldGetRaw ( ) { final Parameters parameters = new Parameters ( ) ; parameters . set ( null , ""a"" , ""axe"" , ""b"" , ""bat"" , ""c"" , ""cat"" ) ; final Map < Object , List < Object > > params = parameters . getRaw ( ) ; assertEquals ( 3 , params . size ( ) ) ; assertEquals ( ""axe"" , params . get ( ""a"" ) . get ( 0 ) ) ; assertEquals ( ""bat"" , params . get ( ""b"" ) . get ( 0 ) ) ; assertEquals ( ""cat"" , params . get ( ""c"" ) . get ( 0 ) ) ; } @ Test public void shouldGetRawWithMulti ( ) { final Parameters parameters = new Parameters ( ) ; parameters . set ( null , ""a"" , ""axe"" , ""b"" , ""bat"" , ""a"" , ""ant"" , ""c"" , ""cat"" ) ; final Map < Object , List < Object > > params = parameters . getRaw ( ) ; assertEquals ( 3 , params . size ( ) ) ; assertThat ( params . get ( ""a"" ) , contains ( ""axe"" , ""ant"" ) ) ; assertEquals ( ""bat"" , params . get ( ""b"" ) . get ( 0 ) ) ; assertEquals ( ""cat"" , params . get ( ""c"" ) . get ( 0 ) ) ; } @ Test public void shouldGetRawEmptyAndUnmodifiable ( ) { final Parameters parameters = new Parameters ( ) ; final Map < Object , List < Object > > params = parameters . getRaw ( ) ; assertEquals ( Collections . emptyMap ( ) , params ) ; } @ Test public void shouldGetRawExcept ( ) { final Parameters parameters = new Parameters ( ) ; parameters . set ( null , ""a"" , ""axe"" , ""b"" , ""bat"" , ""c"" , ""cat"" ) ; final Map < Object , List < Object > > params = parameters . getRaw ( ""b"" ) ; assertEquals ( 2 , params . size ( ) ) ; assertEquals ( ""axe"" , params . get ( ""a"" ) . get ( 0 ) ) ; assertEquals ( ""cat"" , params . get ( ""c"" ) . get ( 0 ) ) ; } @ Test public void shouldRemove ( ) { final Parameters parameters = new Parameters ( ) ; parameters . set ( null , ""a"" , ""axe"" , ""b"" , ""bat"" , ""c"" , ""cat"" ) ; final Map < Object , List < Object > > before = parameters . getRaw ( ) ; assertEquals ( 3 , before . size ( ) ) ; assertEquals ( ""axe"" , before . get ( ""a"" ) . get ( 0 ) ) ; assertEquals ( ""bat"" , before . get ( ""b"" ) . get ( 0 ) ) ; assertEquals ( ""cat"" , before . get ( ""c"" ) . get ( 0 ) ) ; parameters . remove ( ""b"" ) ; final Map < Object , List < Object > > after = parameters . getRaw ( ""b"" ) ; assertEquals ( 2 , after . size ( ) ) ; assertEquals ( ""axe"" , after . get ( ""a"" ) . get ( 0 ) ) ; assertEquals ( ""cat"" , after . get ( ""c"" ) . get ( 0 ) ) ; } @ Test public void shouldRemoveRefreshTraversalCache ( ) { final Parameters parameters = new Parameters ( ) ; parameters . set ( null , ""a"" , ""axe"" , ""b"" , ""bat"" , ""c"" , ""cat"" , ""c"" , mock ( Traversal . Admin . class ) , ""t"" , mock ( Traversal . Admin . class ) ) ; final Map < Object , List < Object > > before = parameters . getRaw ( ) ; assertEquals ( 4 , before . size ( ) ) ; assertEquals ( 2 , parameters . getTraversals ( ) . size ( ) ) ; assertEquals ( ""axe"" , before . get ( ""a"" ) . get ( 0 ) ) ; assertEquals ( ""bat"" , before . get ( ""b"" ) . get ( 0 ) ) ; assertEquals ( ""cat"" , before . get ( ""c"" ) . get ( 0 ) ) ; assertThat ( before . get ( ""c"" ) . get ( 1 ) , instanceOf ( Traversal . Admin . class ) ) ; assertThat ( before . get ( ""t"" ) . get ( 0 ) , instanceOf ( Traversal . Admin . class ) ) ; parameters . remove ( ""t"" ) ; final Map < Object , List < Object > > afterRemoveT = parameters . getRaw ( ) ; assertEquals ( 3 , afterRemoveT . size ( ) ) ; assertEquals ( 1 , parameters . getTraversals ( ) . size ( ) ) ; assertEquals ( ""axe"" , afterRemoveT . get ( ""a"" ) . get ( 0 ) ) ; assertEquals ( ""bat"" , afterRemoveT . get ( ""b"" ) . get ( 0 ) ) ; assertEquals ( ""cat"" , afterRemoveT . get ( ""c"" ) . get ( 0 ) ) ; assertThat ( afterRemoveT . get ( ""c"" ) . get ( 1 ) , instanceOf ( Traversal . Admin . class ) ) ; parameters . remove ( ""c"" ) ; final Map < Object , List < Object > > afterRemoveC = parameters . getRaw ( ) ; assertEquals ( 2 , afterRemoveC . size ( ) ) ; assertEquals ( 0 , parameters . getTraversals ( ) . size ( ) ) ; assertEquals ( ""axe"" , afterRemoveC . get ( ""a"" ) . get ( 0 ) ) ; assertEquals ( ""bat"" , afterRemoveC . get ( ""b"" ) . get ( 0 ) ) ; } @ Test public void shouldRename ( ) { final Parameters parameters = new Parameters ( ) ; parameters . set ( null , ""a"" , ""axe"" , ""b"" , ""bat"" , ""c"" , ""cat"" ) ; parameters . rename ( ""a"" , ""z"" ) ; final Map < Object , List < Object > > before = parameters . getRaw ( ) ; assertEquals ( 3 , before . size ( ) ) ; assertEquals ( ""axe"" , before . get ( ""z"" ) . get ( 0 ) ) ; assertEquals ( ""bat"" , before . get ( ""b"" ) . get ( 0 ) ) ; assertEquals ( ""cat"" , before . get ( ""c"" ) . get ( 0 ) ) ; } @ Test public void shouldContainKey ( ) { final Parameters parameters = new Parameters ( ) ; parameters . set ( null , ""a"" , ""axe"" , ""b"" , ""bat"" , ""c"" , ""cat"" ) ; assertThat ( parameters . contains ( ""b"" ) , is ( true ) ) ; } @ Test public void shouldNotContainKey ( ) { final Parameters parameters = new Parameters ( ) ; parameters . set ( null , ""a"" , ""axe"" , ""b"" , ""bat"" , ""c"" , ""cat"" ) ; assertThat ( parameters . contains ( ""z"" ) , is ( false ) ) ; } @ Test public void shouldGetSetMultiple ( ) { final Parameters parameters = new Parameters ( ) ; parameters . set ( null , ""a"" , ""axe"" , ""a"" , ""ant"" , ""b"" , ""bat"" , ""b"" , ""ball"" , ""c"" , ""cat"" ) ; final Map < Object , List < Object > > params = parameters . getRaw ( ) ; assertEquals ( 3 , params . size ( ) ) ; assertEquals ( ""axe"" , params . get ( ""a"" ) . get ( 0 ) ) ; assertEquals ( ""ant"" , params . get ( ""a"" ) . get ( 1 ) ) ; assertEquals ( ""bat"" , params . get ( ""b"" ) . get ( 0 ) ) ; assertEquals ( ""ball"" , params . get ( ""b"" ) . get ( 1 ) ) ; assertEquals ( ""cat"" , params . get ( ""c"" ) . get ( 0 ) ) ; } @ Test public void shouldGetDefault ( ) { final Parameters parameters = new Parameters ( ) ; parameters . set ( null , ""a"" , ""axe"" , ""b"" , ""bat"" , ""c"" , ""cat"" ) ; assertEquals ( Collections . singletonList ( ""axe"" ) , parameters . get ( ""a"" , ( ) -> ""x"" ) ) ; assertEquals ( Collections . singletonList ( ""bat"" ) , parameters . get ( ""b"" , ( ) -> ""x"" ) ) ; assertEquals ( Collections . singletonList ( ""cat"" ) , parameters . get ( ""c"" , ( ) -> ""x"" ) ) ; assertEquals ( Collections . singletonList ( ""zebra"" ) , parameters . get ( ""z"" , ( ) -> ""zebra"" ) ) ; } @ Test public void shouldClone ( ) { final Parameters parameters = new Parameters ( ) ; parameters . set ( null , ""a"" , ""axe"" , ""a"" , ""ant"" , ""b"" , ""bat"" , ""b"" , ""ball"" , ""c"" , ""cat"" ) ; final Parameters parametersClone = parameters . clone ( ) ; assertEquals ( parameters . getRaw ( ) , parametersClone . getRaw ( ) ) ; assertEquals ( parameters . getTraversals ( ) , parametersClone . getTraversals ( ) ) ; } @ Test public void shouldCloneWithTraversals ( ) { final Traversal . Admin t = mock ( Traversal . Admin . class ) ; when ( t . clone ( ) ) . thenReturn ( t ) ; final Parameters parameters = new Parameters ( ) ; parameters . set ( null , ""a"" , ""axe"" , ""a"" , ""ant"" , ""b"" , ""bat"" , ""b"" , ""ball"" , ""c"" , ""cat"" , ""t"" , t ) ; final Parameters parametersClone = parameters . clone ( ) ; assertEquals ( parameters . getRaw ( ) , parametersClone . getRaw ( ) ) ; assertEquals ( parameters . getTraversals ( ) . size ( ) , parametersClone . getTraversals ( ) . size ( ) ) ; } @ Test public void shouldBeDifferent ( ) { final Parameters parameters = new Parameters ( ) ; parameters . set ( null , ""a"" , ""axe"" , ""a"" , ""ant"" , ""b"" , ""bat"" , ""b"" , ""ball"" , ""c"" , ""cat"" ) ; final Parameters parametersDifferent = new Parameters ( ) ; parametersDifferent . set ( null , ""a"" , ""ant"" , ""a"" , ""axe"" , ""b"" , ""bat"" , ""b"" , ""ball"" , ""c"" , ""cat"" ) ; assertNotEquals ( parameters . getRaw ( ) , parametersDifferent . getRaw ( ) ) ; } @ Test public void shouldGetNoTraversals ( ) { final Parameters parameters = new Parameters ( ) ; parameters . set ( null , ""a"" , ""axe"" , ""a"" , ""ant"" , ""b"" , ""bat"" , ""b"" , ""ball"" , ""c"" , ""cat"" ) ; assertEquals ( Collections . emptyList ( ) , parameters . getTraversals ( ) ) ; } @ Test public void shouldGetTraversals ( ) { final Parameters parameters = new Parameters ( ) ; parameters . set ( null , ""a"" , ""axe"" , ""a"" , ""ant"" , ""b"" , ""bat"" , ""b"" , ""ball"" , ""c"" , ""cat"" , ""t"" , __ . outE ( ""knows"" ) ) ; assertEquals ( Collections . singletonList ( __ . outE ( ""knows"" ) ) , parameters . getTraversals ( ) ) ; } @ Test public void shouldIntegrateTraversals ( ) { final TraversalParent mock = mock ( TraversalParent . class ) ; final Parameters parameters = new Parameters ( ) ; when ( mock . integrateChild ( __ . outE ( ""knows"" ) . asAdmin ( ) ) ) . thenReturn ( null ) ; parameters . set ( mock , ""a"" , ""axe"" , ""a"" , ""ant"" , ""b"" , ""bat"" , ""b"" , ""ball"" , ""c"" , ""cat"" , ""t"" , __ . outE ( ""knows"" ) ) ; verify ( mock ) . integrateChild ( __ . outE ( ""knows"" ) . asAdmin ( ) ) ; } }",Smelly
 public static class InvalidMessageException extends PulsarClientException { public InvalidMessageException ( String msg ) { super ( msg ) ; } ,No
"public class TestOneToMany extends SingleEMFTestCase { public void setUp ( ) { setUp ( AnnoTest1 . class , AnnoTest2 . class , Flat1 . class , CLEAR_TABLES ) ; } public void testOneToMany ( ) { OpenJPAEntityManager em = emf . createEntityManager ( ) ; em . getTransaction ( ) . begin ( ) ; AnnoTest1 pc = new AnnoTest1 ( 5 ) ; pc . getOneMany ( ) . add ( new AnnoTest2 ( 15 , ""foo"" ) ) ; pc . getOneMany ( ) . add ( new AnnoTest2 ( 20 , ""foobar"" ) ) ; em . persist ( pc ) ; em . persistAll ( pc . getOneMany ( ) ) ; em . getTransaction ( ) . commit ( ) ; em . close ( ) ; em = emf . createEntityManager ( ) ; pc = em . find ( AnnoTest1 . class , new Long ( 5 ) ) ; Collection < AnnoTest2 > many = pc . getOneMany ( ) ; assertEquals ( 2 , many . size ( ) ) ; for ( AnnoTest2 pc2 : many ) { switch ( ( int ) pc2 . getPk1 ( ) ) { case 15 : assertEquals ( ""foo"" , pc2 . getPk2 ( ) ) ; break ; case 20 : assertEquals ( ""foobar"" , pc2 . getPk2 ( ) ) ; break ; default : fail ( ""unknown element:"" + pc2 . getPk1 ( ) ) ; } } em . close ( ) ; } public void testInverseOwnerOneToMany ( ) { OpenJPAEntityManager em = emf . createEntityManager ( ) ; em . getTransaction ( ) . begin ( ) ; AnnoTest1 pc = new AnnoTest1 ( 5 ) ; AnnoTest2 pc2 = new AnnoTest2 ( 15 , ""foo"" ) ; pc . getInverseOwnerOneMany ( ) . add ( pc2 ) ; pc2 . setOneManyOwner ( pc ) ; pc2 = new AnnoTest2 ( 20 , ""foobar"" ) ; pc . getInverseOwnerOneMany ( ) . add ( pc2 ) ; pc2 . setOneManyOwner ( pc ) ; em . persist ( pc ) ; em . persistAll ( pc . getInverseOwnerOneMany ( ) ) ; em . getTransaction ( ) . commit ( ) ; em . close ( ) ; em = emf . createEntityManager ( ) ; pc = em . find ( AnnoTest1 . class , new Long ( 5 ) ) ; Collection < AnnoTest2 > many = pc . getInverseOwnerOneMany ( ) ; assertEquals ( 2 , many . size ( ) ) ; for ( AnnoTest2 pc3 : many ) { assertEquals ( pc , pc3 . getOneManyOwner ( ) ) ; switch ( ( int ) pc3 . getPk1 ( ) ) { case 15 : assertEquals ( ""foo"" , pc3 . getPk2 ( ) ) ; break ; case 20 : assertEquals ( ""foobar"" , pc3 . getPk2 ( ) ) ; break ; default : fail ( ""unknown element:"" + pc3 . getPk1 ( ) ) ; } } em . close ( ) ; } }",No
"public class DefaultInputHandler extends InputHandler { public DefaultInputHandler ( View view ) { super ( view ) ; bindings = currentBindings = new Hashtable ( ) ; } public DefaultInputHandler ( View view , DefaultInputHandler copy ) { super ( view ) ; bindings = currentBindings = copy . bindings ; } public void addKeyBinding ( String keyBinding , String action ) { _addKeyBinding ( keyBinding , ( Object ) action ) ; } public void addKeyBinding ( String keyBinding , EditAction action ) { _addKeyBinding ( keyBinding , ( Object ) action ) ; } public void removeKeyBinding ( String keyBinding ) { Hashtable current = bindings ; StringTokenizer st = new StringTokenizer ( keyBinding ) ; while ( st . hasMoreTokens ( ) ) { String keyCodeStr = st . nextToken ( ) ; KeyEventTranslator . Key keyStroke = KeyEventTranslator . parseKey ( keyCodeStr ) ; if ( keyStroke == null ) return ; if ( st . hasMoreTokens ( ) ) { Object o = current . get ( keyStroke ) ; if ( o instanceof Hashtable ) current = ( ( Hashtable ) o ) ; else if ( o != null ) { current . remove ( keyStroke ) ; return ; } else { return ; } } else current . remove ( keyStroke ) ; } } public void removeAllKeyBindings ( ) { bindings . clear ( ) ; } public Object getKeyBinding ( String keyBinding ) { Hashtable current = bindings ; StringTokenizer st = new StringTokenizer ( keyBinding ) ; while ( st . hasMoreTokens ( ) ) { KeyEventTranslator . Key keyStroke = KeyEventTranslator . parseKey ( st . nextToken ( ) ) ; if ( keyStroke == null ) return null ; if ( st . hasMoreTokens ( ) ) { Object o = current . get ( keyStroke ) ; if ( o instanceof Hashtable ) { if ( ! st . hasMoreTokens ( ) ) return o ; else current = ( Hashtable ) o ; } else return o ; } else { return current . get ( keyStroke ) ; } } return null ; } public boolean isPrefixActive ( ) { return bindings != currentBindings || super . isPrefixActive ( ) ; } public boolean handleKey ( KeyEventTranslator . Key keyStroke ) { char input = '\0' ; if ( keyStroke . modifiers == null || keyStroke . modifiers . equals ( ""S"" ) ) { switch ( keyStroke . key ) { case '\n' : case '\t' : input = ( char ) keyStroke . key ; break ; default : input = keyStroke . input ; break ; } } if ( readNextChar != null ) { if ( input != '\0' ) { setCurrentBindings ( bindings ) ; invokeReadNextChar ( input ) ; repeatCount = 1 ; return true ; } else { readNextChar = null ; view . getStatus ( ) . setMessage ( null ) ; } } Object o = currentBindings . get ( keyStroke ) ; if ( o == null ) { if ( currentBindings != bindings ) { Toolkit . getDefaultToolkit ( ) . beep ( ) ; repeatCount = 1 ; setCurrentBindings ( bindings ) ; } if ( input != '\0' ) userInput ( input ) ; else { switch ( keyStroke . key ) { case KeyEvent . VK_NUMPAD0 : case KeyEvent . VK_NUMPAD1 : case KeyEvent . VK_NUMPAD2 : case KeyEvent . VK_NUMPAD3 : case KeyEvent . VK_NUMPAD4 : case KeyEvent . VK_NUMPAD5 : case KeyEvent . VK_NUMPAD6 : case KeyEvent . VK_NUMPAD7 : case KeyEvent . VK_NUMPAD8 : case KeyEvent . VK_NUMPAD9 : case KeyEvent . VK_MULTIPLY : case KeyEvent . VK_ADD : case KeyEvent . VK_SUBTRACT : case KeyEvent . VK_DECIMAL : case KeyEvent . VK_DIVIDE : KeyEventWorkaround . numericKeypadKey ( ) ; break ; } } } else if ( o instanceof Hashtable ) { setCurrentBindings ( ( Hashtable ) o ) ; return true ; } else if ( o instanceof String ) { setCurrentBindings ( bindings ) ; invokeAction ( ( String ) o ) ; return true ; } else if ( o instanceof EditAction ) { setCurrentBindings ( bindings ) ; invokeAction ( ( EditAction ) o ) ; return true ; } return false ; } public static char getSymbolicModifierName ( int mod ) { return KeyEventTranslator . getSymbolicModifierName ( mod ) ; } public static String getModifierString ( InputEvent evt ) { return KeyEventTranslator . getModifierString ( evt ) ; } public static KeyStroke parseKeyStroke ( String keyStroke ) { if ( keyStroke == null ) return null ; int modifiers = 0 ; int index = keyStroke . indexOf ( '+' ) ; if ( index != - 1 ) { for ( int i = 0 ; i < index ; i ++ ) { switch ( Character . toUpperCase ( keyStroke . charAt ( i ) ) ) { case 'A' : modifiers |= KeyEventTranslator . a ; break ; case 'C' : modifiers |= KeyEventTranslator . c ; break ; case 'M' : modifiers |= KeyEventTranslator . m ; break ; case 'S' : modifiers |= KeyEventTranslator . s ; break ; } } } String key = keyStroke . substring ( index + 1 ) ; if ( key . length ( ) == 1 ) { char ch = key . charAt ( 0 ) ; if ( modifiers == 0 ) return KeyStroke . getKeyStroke ( ch ) ; else { return KeyStroke . getKeyStroke ( Character . toUpperCase ( ch ) , modifiers ) ; } } else if ( key . length ( ) == 0 ) { Log . log ( Log . ERROR , DefaultInputHandler . class , ""Invalid key stroke: "" + keyStroke ) ; return null ; } else { int ch ; try { ch = KeyEvent . class . getField ( ""VK_"" . concat ( key ) ) . getInt ( null ) ; } catch ( Exception e ) { Log . log ( Log . ERROR , DefaultInputHandler . class , ""Invalid key stroke: "" + keyStroke ) ; return null ; } return KeyStroke . getKeyStroke ( ch , modifiers ) ; } } private static Object PREFIX_STR = ""PREFIX_STR"" ; private Hashtable bindings ; private Hashtable currentBindings ; private void setCurrentBindings ( Hashtable bindings ) { view . getStatus ( ) . setMessage ( ( String ) bindings . get ( PREFIX_STR ) ) ; currentBindings = bindings ; } public void _addKeyBinding ( String keyBinding , Object action ) { Hashtable current = bindings ; String prefixStr = null ; StringTokenizer st = new StringTokenizer ( keyBinding ) ; while ( st . hasMoreTokens ( ) ) { String keyCodeStr = st . nextToken ( ) ; if ( prefixStr == null ) prefixStr = keyCodeStr ; else prefixStr = prefixStr + "" "" + keyCodeStr ; KeyEventTranslator . Key keyStroke = KeyEventTranslator . parseKey ( keyCodeStr ) ; if ( keyStroke == null ) return ; if ( st . hasMoreTokens ( ) ) { Object o = current . get ( keyStroke ) ; if ( o instanceof Hashtable ) current = ( Hashtable ) o ; else { Hashtable hash = new Hashtable ( ) ; hash . put ( PREFIX_STR , prefixStr ) ; o = hash ; current . put ( keyStroke , o ) ; current = ( Hashtable ) o ; } } else current . put ( keyStroke , action ) ; } } }",Smelly
"public class DnEditorDialogBot extends DialogBot { public DnEditorDialogBot ( ) { super ( ""DN Editor"" ) ; } public SelectDnDialogBot clickBrowseButtonExpectingSelectDnDialog ( ) { super . clickButton ( ""Browse..."" ) ; return new SelectDnDialogBot ( ) ; } public String getDnText ( ) { return bot . comboBox ( ) . getText ( ) ; } }",No
"public class QualifiedValueShape implements Constraint { private final Shape sub ; private int qMin ; private int qMax ; private boolean qDisjoint ; public QualifiedValueShape ( Shape sub , int qMin , int qMax , boolean qDisjoint ) { this . sub = sub ; this . qMin = qMin ; this . qMax = qMax ; this . qDisjoint = qDisjoint ; } @ Override public void validateNodeShape ( ValidationContext vCxt , Graph data , Shape shape , Node focusNode ) { throw new ShaclException ( ""sh:qualifiedValueShape only valid in a property shape"" ) ; } @ Override public void validatePropertyShape ( ValidationContext vCxt , Graph data , Shape shape , Node focusNode , Path path , Set < Node > valueNodes ) { Collection < Node > sibs = siblings ( vCxt . getShapesGraph ( ) , shape ) ; Set < Node > valueNodes2 ; if ( qDisjoint ) { valueNodes2 = new HashSet < > ( ) ; for ( Node v : valueNodes ) { if ( ! conformsSiblings ( vCxt , v , sibs ) ) { valueNodes2 . add ( v ) ; } } } else { valueNodes2 = valueNodes ; } int x = 0 ; for ( Node v : valueNodes2 ) { boolean b = conforms ( vCxt , sub , v ) ; if ( b ) x ++ ; } if ( qMin >= 0 && qMin > x ) { String msg = toString ( ) + "": Min = "" + qMin + "" but got "" + x + "" validations"" ; vCxt . reportEntry ( msg , shape , focusNode , path , null , new ReportConstraint ( SHACL . QualifiedMinCountConstraintComponent ) ) ; } if ( qMax >= 0 && qMax < x ) { String msg = toString ( ) + "": Max = "" + qMax + "" but got "" + x + "" validations"" ; vCxt . reportEntry ( msg , shape , focusNode , path , null , new ReportConstraint ( SHACL . QualifiedMaxCountConstraintComponent ) ) ; } } private boolean conformsSiblings ( ValidationContext vCxt , Node v , Collection < Node > sibs ) { for ( Node sib : sibs ) { Shape sibShape = vCxt . getShapes ( ) . getShape ( sib ) ; boolean b = conforms ( vCxt , sibShape , v ) ; if ( b ) return true ; } return false ; } private static boolean conforms ( ValidationContext vCxt , Shape shape , Node v ) { ValidationContext vCxt2 = new ValidationContext ( vCxt ) ; vCxt2 . setVerbose ( false ) ; ValidationProc . execValidateShape ( vCxt2 , vCxt . getDataGraph ( ) , shape , v ) ; ValidationReport report = vCxt2 . generateReport ( ) ; return report . conforms ( ) ; } private Collection < Node > siblings ( Graph shapesGraph , Shape thisShape ) { if ( ! qDisjoint ) return Collections . emptySet ( ) ; Node thisShapeNode = thisShape . getShapeNode ( ) ; Set < Node > sibs = new HashSet < > ( ) ; List < Node > parents = G . listPO ( shapesGraph , SHACL . property , thisShapeNode ) ; parents . forEach ( s -> { List < Node > sibs1 = G . listSP ( shapesGraph , s , SHACL . property ) ; sibs . addAll ( sibs1 ) ; } ) ; Set < Node > sibShapes = new HashSet < > ( ) ; sibs . forEach ( s -> { List < Node > x = G . listSP ( shapesGraph , s , SHACL . qualifiedValueShape ) ; sibShapes . addAll ( x ) ; } ) ; sibShapes . remove ( sub . getShapeNode ( ) ) ; return sibShapes ; } @ Override public Node getComponent ( ) { return SHACL . qualifiedValueShape ; } @ Override public String toString ( ) { return String . format ( ""QualifiedValueShape[%s,%s,%s]"" , ( qMin < 0 ) ? ""_"" : Integer . toString ( qMin ) , ( qMax < 0 ) ? ""_"" : Integer . toString ( qMax ) , qDisjoint ) ; } }",No
"class NotEqualComparator extends Comparator { boolean compareStrings ( XMLString s1 , XMLString s2 ) { return ! s1 . equals ( s2 ) ; } boolean compareNumbers ( double n1 , double n2 ) { return n1 != n2 ; } }",Smelly
"public class DBGeneratorOptions extends CayenneController { protected DBGeneratorOptionsView view ; protected ObjectBinding [ ] optionBindings ; protected ObjectBinding sqlBinding ; protected ObjectBinding adapterBinding ; protected DBConnectionInfo connectionInfo ; protected Collection < DataMap > dataMaps ; protected DBGeneratorDefaults generatorDefaults ; protected Collection < DbGenerator > generators ; protected String textForSQL ; protected TableSelectorController tables ; public DBGeneratorOptions ( ProjectController parent , String title , Collection < DataMap > dataMaps ) { super ( parent ) ; this . dataMaps = dataMaps ; this . tables = new TableSelectorController ( parent ) ; this . view = new DBGeneratorOptionsView ( tables . getView ( ) ) ; this . connectionInfo = new DBConnectionInfo ( ) ; this . generatorDefaults = new DBGeneratorDefaults ( parent . getPreferenceForProject ( ) . node ( ""DbGenerator"" ) ) ; this . view . setTitle ( title ) ; initController ( ) ; connectionInfo . setDbAdapter ( ( String ) view . getAdapters ( ) . getSelectedItem ( ) ) ; tables . updateTables ( dataMaps ) ; prepareGenerator ( ) ; generatorDefaults . configureGenerator ( generators ) ; createSQL ( ) ; refreshView ( ) ; } public Component getView ( ) { return view ; } public DBGeneratorDefaults getGeneratorDefaults ( ) { return generatorDefaults ; } public String getTextForSQL ( ) { return textForSQL ; } protected void initController ( ) { DefaultComboBoxModel < String > adapterModel = new DefaultComboBoxModel < > ( DbAdapterInfo . getStandardAdapters ( ) ) ; view . getAdapters ( ) . setModel ( adapterModel ) ; view . getAdapters ( ) . setSelectedIndex ( 0 ) ; BindingBuilder builder = new BindingBuilder ( getApplication ( ) . getBindingFactory ( ) , this ) ; sqlBinding = builder . bindToTextArea ( view . getSql ( ) , ""textForSQL"" ) ; adapterBinding = builder . bindToComboSelection ( view . getAdapters ( ) , ""connectionInfo.dbAdapter"" , ""refreshSQLAction()"" , ""org.apache.cayenne.dba.JdbcAdapter"" ) ; optionBindings = new ObjectBinding [ 5 ] ; optionBindings [ 0 ] = builder . bindToStateChangeAndAction ( view . getCreateFK ( ) , ""generatorDefaults.createFK"" , ""refreshSQLAction()"" ) ; optionBindings [ 1 ] = builder . bindToStateChangeAndAction ( view . getCreatePK ( ) , ""generatorDefaults.createPK"" , ""refreshSQLAction()"" ) ; optionBindings [ 2 ] = builder . bindToStateChangeAndAction ( view . getCreateTables ( ) , ""generatorDefaults.createTables"" , ""refreshSQLAction()"" ) ; optionBindings [ 3 ] = builder . bindToStateChangeAndAction ( view . getDropPK ( ) , ""generatorDefaults.dropPK"" , ""refreshSQLAction()"" ) ; optionBindings [ 4 ] = builder . bindToStateChangeAndAction ( view . getDropTables ( ) , ""generatorDefaults.dropTables"" , ""refreshSQLAction()"" ) ; builder . bindToAction ( view . getGenerateButton ( ) , ""generateSchemaAction()"" ) ; builder . bindToAction ( view . getSaveSqlButton ( ) , ""storeSQLAction()"" ) ; builder . bindToAction ( view . getCancelButton ( ) , ""closeAction()"" ) ; view . getTabs ( ) . addChangeListener ( new ChangeListener ( ) { public void stateChanged ( ChangeEvent e ) { if ( view . getTabs ( ) . getSelectedIndex ( ) == 0 ) { refreshGeneratorAction ( ) ; } } } ) ; } protected void prepareGenerator ( ) { try { DbAdapter adapter = connectionInfo . makeAdapter ( getApplication ( ) . getClassLoadingService ( ) ) ; generators = new ArrayList < > ( ) ; for ( DataMap dataMap : dataMaps ) { this . generators . add ( new DbGenerator ( adapter , dataMap , tables . getExcludedTables ( ) , null , NoopJdbcEventLogger . getInstance ( ) ) ) ; } } catch ( Exception ex ) { reportError ( ""Error loading adapter"" , ex ) ; } } protected void createSQL ( ) { StringBuilder buf = new StringBuilder ( ) ; for ( DbGenerator generator : generators ) { Iterator < String > it = generator . configuredStatements ( ) . iterator ( ) ; String batchTerminator = generator . getAdapter ( ) . getBatchTerminator ( ) ; String lineEnd = ( batchTerminator != null ) ? ""\n"" + batchTerminator + ""\n\n"" : ""\n\n"" ; while ( it . hasNext ( ) ) { buf . append ( it . next ( ) ) . append ( lineEnd ) ; } } textForSQL = buf . toString ( ) ; } protected void refreshView ( ) { getView ( ) . setEnabled ( connectionInfo != null ) ; for ( ObjectBinding optionBinding : optionBindings ) { optionBinding . updateView ( ) ; } sqlBinding . updateView ( ) ; } public void startupAction ( ) { view . pack ( ) ; view . setDefaultCloseOperation ( WindowConstants . DISPOSE_ON_CLOSE ) ; view . setModal ( true ) ; makeCloseableOnEscape ( ) ; centerView ( ) ; view . setVisible ( true ) ; } public void refreshGeneratorAction ( ) { prepareGenerator ( ) ; refreshSQLAction ( ) ; } public void refreshSQLAction ( ) { adapterBinding . updateView ( ) ; connectionInfo . setDbAdapter ( ( String ) view . getAdapters ( ) . getSelectedItem ( ) ) ; prepareGenerator ( ) ; generatorDefaults . configureGenerator ( generators ) ; createSQL ( ) ; sqlBinding . updateView ( ) ; } public void generateSchemaAction ( ) { DataSourceWizard connectWizard = new DataSourceWizard ( this . getParent ( ) , ""Generate DB Schema: Connect to Database"" ) ; if ( ! connectWizard . startupAction ( ) ) { return ; } this . connectionInfo = connectWizard . getConnectionInfo ( ) ; refreshGeneratorAction ( ) ; Collection < ValidationResult > failures = new ArrayList < ValidationResult > ( ) ; for ( DbGenerator generator : generators ) { if ( generator . isEmpty ( true ) ) { JOptionPane . showMessageDialog ( getView ( ) , ""Nothing to generate."" ) ; return ; } try { generator . runGenerator ( connectWizard . getDataSource ( ) ) ; failures . add ( generator . getFailures ( ) ) ; } catch ( Throwable th ) { reportError ( ""Schema Generation Error"" , th ) ; } } if ( failures . size ( ) == 0 ) { JOptionPane . showMessageDialog ( getView ( ) , ""Schema Generation Complete."" ) ; } else { new ValidationResultBrowser ( this ) . startupAction ( ""Schema Generation Complete"" , ""Schema generation finished. The following problem(s) were ignored."" , failures ) ; } } public void storeSQLAction ( ) { JFileChooser fc = new JFileChooser ( ) ; fc . setDialogType ( JFileChooser . SAVE_DIALOG ) ; fc . setDialogTitle ( ""Save SQL Script"" ) ; File projectDir = new File ( getApplication ( ) . getProject ( ) . getConfigurationResource ( ) . getURL ( ) . getPath ( ) ) ; fc . setCurrentDirectory ( projectDir ) ; if ( fc . showSaveDialog ( getView ( ) ) == JFileChooser . APPROVE_OPTION ) { refreshGeneratorAction ( ) ; try { File file = fc . getSelectedFile ( ) ; FileWriter fw = new FileWriter ( file ) ; PrintWriter pw = new PrintWriter ( fw ) ; pw . print ( textForSQL ) ; pw . flush ( ) ; pw . close ( ) ; } catch ( IOException ex ) { reportError ( ""Error Saving SQL"" , ex ) ; } } } public void closeAction ( ) { view . dispose ( ) ; } public DBConnectionInfo getConnectionInfo ( ) { return this . connectionInfo ; } public void setConnectionInfo ( DBConnectionInfo connectionInfo ) { this . connectionInfo = connectionInfo ; refreshView ( ) ; } }",No
"public class Hierarchy implements LoggerRepository , RendererSupport , ThrowableRendererSupport { private LoggerFactory defaultFactory ; private Vector listeners ; Hashtable ht ; Logger root ; RendererMap rendererMap ; int thresholdInt ; Level threshold ; boolean emittedNoAppenderWarning = false ; boolean emittedNoResourceBundleWarning = false ; private ThrowableRenderer throwableRenderer = null ; public Hierarchy ( Logger root ) { ht = new Hashtable ( ) ; listeners = new Vector ( 1 ) ; this . root = root ; setThreshold ( Level . ALL ) ; this . root . setHierarchy ( this ) ; rendererMap = new RendererMap ( ) ; defaultFactory = new DefaultCategoryFactory ( ) ; } public void addRenderer ( Class classToRender , ObjectRenderer or ) { rendererMap . put ( classToRender , or ) ; } public void addHierarchyEventListener ( HierarchyEventListener listener ) { if ( listeners . contains ( listener ) ) { LogLog . warn ( ""Ignoring attempt to add an existent listener."" ) ; } else { listeners . addElement ( listener ) ; } } public void clear ( ) { ht . clear ( ) ; } public void emitNoAppenderWarning ( Category cat ) { if ( ! this . emittedNoAppenderWarning ) { LogLog . warn ( ""No appenders could be found for logger ("" + cat . getName ( ) + "")."" ) ; LogLog . warn ( ""Please initialize the log4j system properly."" ) ; LogLog . warn ( ""See http://logging.apache.org/log4j/1.2/faq.html#noconfig for more info."" ) ; this . emittedNoAppenderWarning = true ; } } public Logger exists ( String name ) { Object o = ht . get ( new CategoryKey ( name ) ) ; if ( o instanceof Logger ) { return ( Logger ) o ; } else { return null ; } } public void setThreshold ( String levelStr ) { Level l = ( Level ) Level . toLevel ( levelStr , null ) ; if ( l != null ) { setThreshold ( l ) ; } else { LogLog . warn ( ""Could not convert ["" + levelStr + ""] to Level."" ) ; } } public void setThreshold ( Level l ) { if ( l != null ) { thresholdInt = l . level ; threshold = l ; } } public void fireAddAppenderEvent ( Category logger , Appender appender ) { if ( listeners != null ) { int size = listeners . size ( ) ; HierarchyEventListener listener ; for ( int i = 0 ; i < size ; i ++ ) { listener = ( HierarchyEventListener ) listeners . elementAt ( i ) ; listener . addAppenderEvent ( logger , appender ) ; } } } void fireRemoveAppenderEvent ( Category logger , Appender appender ) { if ( listeners != null ) { int size = listeners . size ( ) ; HierarchyEventListener listener ; for ( int i = 0 ; i < size ; i ++ ) { listener = ( HierarchyEventListener ) listeners . elementAt ( i ) ; listener . removeAppenderEvent ( logger , appender ) ; } } } public Level getThreshold ( ) { return threshold ; } public Logger getLogger ( String name ) { return getLogger ( name , defaultFactory ) ; } public Logger getLogger ( String name , LoggerFactory factory ) { CategoryKey key = new CategoryKey ( name ) ; Logger logger ; synchronized ( ht ) { Object o = ht . get ( key ) ; if ( o == null ) { logger = factory . makeNewLoggerInstance ( name ) ; logger . setHierarchy ( this ) ; ht . put ( key , logger ) ; updateParents ( logger ) ; return logger ; } else if ( o instanceof Logger ) { return ( Logger ) o ; } else if ( o instanceof ProvisionNode ) { logger = factory . makeNewLoggerInstance ( name ) ; logger . setHierarchy ( this ) ; ht . put ( key , logger ) ; updateChildren ( ( ProvisionNode ) o , logger ) ; updateParents ( logger ) ; return logger ; } else { return null ; } } } public Enumeration getCurrentLoggers ( ) { Vector v = new Vector ( ht . size ( ) ) ; Enumeration elems = ht . elements ( ) ; while ( elems . hasMoreElements ( ) ) { Object o = elems . nextElement ( ) ; if ( o instanceof Logger ) { v . addElement ( o ) ; } } return v . elements ( ) ; } public Enumeration getCurrentCategories ( ) { return getCurrentLoggers ( ) ; } public RendererMap getRendererMap ( ) { return rendererMap ; } public Logger getRootLogger ( ) { return root ; } public boolean isDisabled ( int level ) { return thresholdInt > level ; } public void overrideAsNeeded ( String override ) { LogLog . warn ( ""The Hiearchy.overrideAsNeeded method has been deprecated."" ) ; } public void resetConfiguration ( ) { getRootLogger ( ) . setLevel ( ( Level ) Level . DEBUG ) ; root . setResourceBundle ( null ) ; setThreshold ( Level . ALL ) ; synchronized ( ht ) { shutdown ( ) ; Enumeration cats = getCurrentLoggers ( ) ; while ( cats . hasMoreElements ( ) ) { Logger c = ( Logger ) cats . nextElement ( ) ; c . setLevel ( null ) ; c . setAdditivity ( true ) ; c . setResourceBundle ( null ) ; } } rendererMap . clear ( ) ; throwableRenderer = null ; } public void setDisableOverride ( String override ) { LogLog . warn ( ""The Hiearchy.setDisableOverride method has been deprecated."" ) ; } public void setRenderer ( Class renderedClass , ObjectRenderer renderer ) { rendererMap . put ( renderedClass , renderer ) ; } public void setThrowableRenderer ( final ThrowableRenderer renderer ) { throwableRenderer = renderer ; } public ThrowableRenderer getThrowableRenderer ( ) { return throwableRenderer ; } public void shutdown ( ) { Logger root = getRootLogger ( ) ; root . closeNestedAppenders ( ) ; synchronized ( ht ) { Enumeration cats = this . getCurrentLoggers ( ) ; while ( cats . hasMoreElements ( ) ) { Logger c = ( Logger ) cats . nextElement ( ) ; c . closeNestedAppenders ( ) ; } root . removeAllAppenders ( ) ; cats = this . getCurrentLoggers ( ) ; while ( cats . hasMoreElements ( ) ) { Logger c = ( Logger ) cats . nextElement ( ) ; c . removeAllAppenders ( ) ; } } } final private void updateParents ( Logger cat ) { String name = cat . name ; int length = name . length ( ) ; boolean parentFound = false ; for ( int i = name . lastIndexOf ( '.' , length - 1 ) ; i >= 0 ; i = name . lastIndexOf ( '.' , i - 1 ) ) { String substr = name . substring ( 0 , i ) ; CategoryKey key = new CategoryKey ( substr ) ; Object o = ht . get ( key ) ; if ( o == null ) { ProvisionNode pn = new ProvisionNode ( cat ) ; ht . put ( key , pn ) ; } else if ( o instanceof Category ) { parentFound = true ; cat . parent = ( Category ) o ; break ; } else if ( o instanceof ProvisionNode ) { ( ( ProvisionNode ) o ) . addElement ( cat ) ; } else { Exception e = new IllegalStateException ( ""unexpected object type "" + o . getClass ( ) + "" in ht."" ) ; e . printStackTrace ( ) ; } } if ( ! parentFound ) cat . parent = root ; } final private void updateChildren ( ProvisionNode pn , Logger logger ) { final int last = pn . size ( ) ; for ( int i = 0 ; i < last ; i ++ ) { Logger l = ( Logger ) pn . elementAt ( i ) ; if ( ! l . parent . name . startsWith ( logger . name ) ) { logger . parent = l . parent ; l . parent = logger ; } } } }",Smelly
"@ Entity @ Table ( name = ""COMPUTE_RESOURCE"" ) public class ComputeResource implements Serializable { @ Column ( name = ""RESOURCE_DESCRIPTION"" ) private String resourceDescription ; @ Id @ Column ( name = ""RESOURCE_ID"" ) private String resourceId ; @ Column ( name = ""HOST_NAME"" ) private String hostName ; @ Column ( name = ""MAX_MEMORY_NODE"" ) private int maxMemoryPerNode ; @ Column ( name = ""CREATION_TIME"" ) private Timestamp creationTime ; @ Column ( name = ""UPDATE_TIME"" ) private Timestamp updateTime ; @ Column ( name = ""ENABLED"" ) private boolean enabled ; @ Column ( name = ""GATEWAY_USAGE_REPORTING"" ) private boolean gatewayUsageReporting ; @ Column ( name = ""GATEWAY_USAGE_MODULE_LOAD_CMD"" ) private String gatewayUsageModLoadCMD ; @ Column ( name = ""GATEWAY_USAGE_EXECUTABLE"" ) private String gatewayUsageExec ; public Timestamp getCreationTime ( ) { return creationTime ; } public void setCreationTime ( Timestamp creationTime ) { this . creationTime = creationTime ; } public Timestamp getUpdateTime ( ) { return updateTime ; } public void setUpdateTime ( Timestamp updateTime ) { this . updateTime = updateTime ; } public String getResourceDescription ( ) { return resourceDescription ; } public String getResourceId ( ) { return resourceId ; } public String getHostName ( ) { return hostName ; } public Boolean getEnabled ( ) { return enabled ; } public void setEnabled ( Boolean enabled ) { this . enabled = enabled ; } public void setResourceDescription ( String resourceDescription ) { this . resourceDescription = resourceDescription ; } public void setResourceId ( String resourceId ) { this . resourceId = resourceId ; } public void setHostName ( String hostName ) { this . hostName = hostName ; } public int getMaxMemoryPerNode ( ) { return maxMemoryPerNode ; } public void setMaxMemoryPerNode ( int maxMemoryPerNode ) { this . maxMemoryPerNode = maxMemoryPerNode ; } public boolean isGatewayUsageReporting ( ) { return gatewayUsageReporting ; } public void setGatewayUsageReporting ( boolean gatewayUsageReporting ) { this . gatewayUsageReporting = gatewayUsageReporting ; } public String getGatewayUsageModLoadCMD ( ) { return gatewayUsageModLoadCMD ; } public void setGatewayUsageModLoadCMD ( String gatewayUsageModLoadCMD ) { this . gatewayUsageModLoadCMD = gatewayUsageModLoadCMD ; } public String getGatewayUsageExec ( ) { return gatewayUsageExec ; } public void setGatewayUsageExec ( String gatewayUsageExec ) { this . gatewayUsageExec = gatewayUsageExec ; } }",No
"public class HdfsFileObject extends AbstractFileObject < HdfsFileSystem > { private final HdfsFileSystem fs ; private final FileSystem hdfs ; private final Path path ; private FileStatus stat ; protected HdfsFileObject ( final AbstractFileName name , final HdfsFileSystem fs , final FileSystem hdfs , final Path p ) { super ( name , fs ) ; this . fs = fs ; this . hdfs = hdfs ; this . path = p ; } @ Override public boolean canRenameTo ( final FileObject newfile ) { throw new UnsupportedOperationException ( ) ; } @ Override protected void doAttach ( ) throws Exception { try { this . stat = this . hdfs . getFileStatus ( this . path ) ; } catch ( final FileNotFoundException e ) { this . stat = null ; return ; } } @ Override protected Map < String , Object > doGetAttributes ( ) throws Exception { if ( null == this . stat ) { return super . doGetAttributes ( ) ; } final Map < String , Object > attrs = new HashMap < > ( ) ; attrs . put ( HdfsFileAttributes . LAST_ACCESS_TIME . toString ( ) , this . stat . getAccessTime ( ) ) ; attrs . put ( HdfsFileAttributes . BLOCK_SIZE . toString ( ) , this . stat . getBlockSize ( ) ) ; attrs . put ( HdfsFileAttributes . GROUP . toString ( ) , this . stat . getGroup ( ) ) ; attrs . put ( HdfsFileAttributes . OWNER . toString ( ) , this . stat . getOwner ( ) ) ; attrs . put ( HdfsFileAttributes . PERMISSIONS . toString ( ) , this . stat . getPermission ( ) . toString ( ) ) ; attrs . put ( HdfsFileAttributes . LENGTH . toString ( ) , this . stat . getLen ( ) ) ; attrs . put ( HdfsFileAttributes . MODIFICATION_TIME . toString ( ) , this . stat . getModificationTime ( ) ) ; return attrs ; } @ Override protected long doGetContentSize ( ) throws Exception { return stat . getLen ( ) ; } @ Override protected InputStream doGetInputStream ( final int bufferSize ) throws Exception { return this . hdfs . open ( this . path , bufferSize ) ; } @ Override protected long doGetLastModifiedTime ( ) throws Exception { if ( null != this . stat ) { return this . stat . getModificationTime ( ) ; } return - 1 ; } @ Override protected RandomAccessContent doGetRandomAccessContent ( final RandomAccessMode mode ) throws Exception { if ( mode . equals ( RandomAccessMode . READWRITE ) ) { throw new UnsupportedOperationException ( ) ; } return new HdfsRandomAccessContent ( this . path , this . hdfs ) ; } @ Override protected FileType doGetType ( ) throws Exception { try { doAttach ( ) ; if ( null == stat ) { return FileType . IMAGINARY ; } if ( stat . isDirectory ( ) ) { return FileType . FOLDER ; } return FileType . FILE ; } catch ( final FileNotFoundException fnfe ) { return FileType . IMAGINARY ; } } @ Override protected boolean doIsHidden ( ) throws Exception { return false ; } @ Override protected boolean doIsReadable ( ) throws Exception { return true ; } @ Override protected boolean doIsWriteable ( ) throws Exception { return false ; } @ Override protected String [ ] doListChildren ( ) throws Exception { if ( this . doGetType ( ) != FileType . FOLDER ) { throw new FileNotFolderException ( this ) ; } final FileStatus [ ] files = this . hdfs . listStatus ( this . path ) ; final String [ ] children = new String [ files . length ] ; int i = 0 ; for ( final FileStatus status : files ) { children [ i ++ ] = status . getPath ( ) . getName ( ) ; } return children ; } @ Override protected FileObject [ ] doListChildrenResolved ( ) throws Exception { if ( this . doGetType ( ) != FileType . FOLDER ) { return null ; } final String [ ] children = doListChildren ( ) ; final FileObject [ ] fo = new FileObject [ children . length ] ; for ( int i = 0 ; i < children . length ; i ++ ) { final Path p = new Path ( this . path , children [ i ] ) ; fo [ i ] = this . fs . resolveFile ( p . toUri ( ) . toString ( ) ) ; } return fo ; } @ Override protected void doRemoveAttribute ( final String attrName ) throws Exception { throw new UnsupportedOperationException ( ) ; } @ Override protected void doSetAttribute ( final String attrName , final Object value ) throws Exception { throw new UnsupportedOperationException ( ) ; } @ Override protected boolean doSetLastModifiedTime ( final long modtime ) throws Exception { throw new UnsupportedOperationException ( ) ; } @ Override public boolean exists ( ) throws FileSystemException { try { doAttach ( ) ; return this . stat != null ; } catch ( final FileNotFoundException fne ) { return false ; } catch ( final Exception e ) { throw new FileSystemException ( ""Unable to check existance "" , e ) ; } } }",Smelly
"public final class TestUtils { public static final long TEST_DATE_IN_LONG = 1418265358440L ; public static final String EMPLOYEES_ATTR = ""employees"" ; public static final String DEPARTMENT_ATTR = ""department"" ; public static final String ASSETS_ATTR = ""assets"" ; public static final String POSITIONS_ATTR = ""positions"" ; public static final String ASSET_TYPE = ""TestAsset"" ; public static final String DATABASE_TYPE = ""hive_database"" ; public static final String DATABASE_NAME = ""foo"" ; public static final String TABLE_TYPE = ""hive_table"" ; public static final String PROCESS_TYPE = ""hive_process"" ; public static final String COLUMN_TYPE = ""column_type"" ; public static final String TABLE_NAME = ""bar"" ; public static final String CLASSIFICATION = ""classification"" ; public static final String PII = ""PII"" ; public static final String SUPER_TYPE_NAME = ""Base"" ; public static final String STORAGE_DESC_TYPE = ""hive_storagedesc"" ; public static final String PARTITION_STRUCT_TYPE = ""partition_struct_type"" ; public static final String PARTITION_CLASS_TYPE = ""partition_class_type"" ; public static final String SERDE_TYPE = ""serdeType"" ; public static final String COLUMNS_MAP = ""columnsMap"" ; public static final String COLUMNS_ATTR_NAME = ""columns"" ; public static final String NAME = ""name"" ; private TestUtils ( ) { } public static String dumpGraph ( AtlasGraph < ? , ? > graph ) throws Exception { File tempFile = File . createTempFile ( ""graph"" , "".gson"" ) ; System . out . println ( ""tempFile.getPath() = "" + tempFile . getPath ( ) ) ; GraphHelper . dumpToLog ( graph ) ; FileOutputStream os = null ; try { os = new FileOutputStream ( tempFile ) ; graph . exportToGson ( os ) ; } finally { if ( os != null ) { try { os . close ( ) ; } catch ( IOException e ) { e . printStackTrace ( ) ; } } } return tempFile . getPath ( ) ; } public static void defineDeptEmployeeTypes ( TypeSystem ts ) throws AtlasException { String _description = ""_description"" ; EnumTypeDefinition orgLevelEnum = new EnumTypeDefinition ( ""OrgLevel"" , ""OrgLevel"" + _description , new EnumValue ( ""L1"" , 1 ) , new EnumValue ( ""L2"" , 2 ) ) ; StructTypeDefinition addressDetails = createStructTypeDef ( ""Address"" , ""Address"" + _description , createRequiredAttrDef ( ""street"" , DataTypes . STRING_TYPE ) , createRequiredAttrDef ( ""city"" , DataTypes . STRING_TYPE ) ) ; HierarchicalTypeDefinition < ClassType > deptTypeDef = createClassTypeDef ( DEPARTMENT_TYPE , ""Department"" + _description , ImmutableSet . < String > of ( ) , createRequiredAttrDef ( NAME , DataTypes . STRING_TYPE ) , new AttributeDefinition ( EMPLOYEES_ATTR , String . format ( ""array<%s>"" , ""Person"" ) , Multiplicity . OPTIONAL , true , DEPARTMENT_ATTR ) , new AttributeDefinition ( POSITIONS_ATTR , String . format ( ""map<%s,%s>"" , DataTypes . STRING_TYPE . getName ( ) , ""Person"" ) , Multiplicity . OPTIONAL , false , null ) ) ; HierarchicalTypeDefinition < ClassType > personTypeDef = createClassTypeDef ( ""Person"" , ""Person"" + _description , ImmutableSet . < String > of ( ) , createRequiredAttrDef ( NAME , DataTypes . STRING_TYPE ) , createOptionalAttrDef ( ""orgLevel"" , ""OrgLevel"" ) , createOptionalAttrDef ( ""address"" , ""Address"" ) , new AttributeDefinition ( DEPARTMENT_ATTR , ""Department"" , Multiplicity . REQUIRED , false , EMPLOYEES_ATTR ) , new AttributeDefinition ( ""manager"" , ""Manager"" , Multiplicity . OPTIONAL , false , ""subordinates"" ) , new AttributeDefinition ( ""mentor"" , ""Person"" , Multiplicity . OPTIONAL , false , null ) , new AttributeDefinition ( ASSETS_ATTR , String . format ( ""array<%s>"" , ASSET_TYPE ) , Multiplicity . OPTIONAL , false , null ) , createOptionalAttrDef ( ""birthday"" , DataTypes . DATE_TYPE ) , createOptionalAttrDef ( ""hasPets"" , DataTypes . BOOLEAN_TYPE ) , createOptionalAttrDef ( ""numberOfCars"" , DataTypes . BYTE_TYPE ) , createOptionalAttrDef ( ""houseNumber"" , DataTypes . SHORT_TYPE ) , createOptionalAttrDef ( ""carMileage"" , DataTypes . INT_TYPE ) , createOptionalAttrDef ( ""shares"" , DataTypes . LONG_TYPE ) , createOptionalAttrDef ( ""salary"" , DataTypes . DOUBLE_TYPE ) , createOptionalAttrDef ( ""age"" , DataTypes . FLOAT_TYPE ) , createOptionalAttrDef ( ""numberOfStarsEstimate"" , DataTypes . BIGINTEGER_TYPE ) , createOptionalAttrDef ( ""approximationOfPi"" , DataTypes . BIGDECIMAL_TYPE ) , createOptionalAttrDef ( ""isOrganDonor"" , DataTypes . BOOLEAN_TYPE ) ) ; HierarchicalTypeDefinition < ClassType > assetTypeDef = createClassTypeDef ( ASSET_TYPE , ""Asset"" + _description , ImmutableSet . < String > of ( ) , createRequiredAttrDef ( NAME , DataTypes . STRING_TYPE ) , new AttributeDefinition ( ""childAssets"" , String . format ( ""array<%s>"" , ASSET_TYPE ) , Multiplicity . OPTIONAL , false , null ) ) ; HierarchicalTypeDefinition < ClassType > managerTypeDef = createClassTypeDef ( ""Manager"" , ""Manager"" + _description , ImmutableSet . of ( ""Person"" ) , new AttributeDefinition ( ""subordinates"" , String . format ( ""array<%s>"" , ""Person"" ) , Multiplicity . COLLECTION , false , ""manager"" ) ) ; HierarchicalTypeDefinition < TraitType > securityClearanceTypeDef = createTraitTypeDef ( ""SecurityClearance"" , ""SecurityClearance"" + _description , ImmutableSet . < String > of ( ) , createRequiredAttrDef ( ""level"" , DataTypes . INT_TYPE ) ) ; ts . defineTypes ( ImmutableList . of ( orgLevelEnum ) , ImmutableList . of ( addressDetails ) , ImmutableList . of ( securityClearanceTypeDef ) , ImmutableList . of ( deptTypeDef , personTypeDef , managerTypeDef , assetTypeDef ) ) ; } public static final String DEPARTMENT_TYPE = ""Department"" ; public static final String PERSON_TYPE = ""Person"" ; public static ITypedReferenceableInstance createDeptEg1 ( TypeSystem ts ) throws AtlasException { Referenceable hrDept = new Referenceable ( DEPARTMENT_TYPE ) ; Referenceable john = new Referenceable ( PERSON_TYPE ) ; Referenceable jane = new Referenceable ( ""Manager"" , ""SecurityClearance"" ) ; Referenceable johnAddr = new Referenceable ( ""Address"" ) ; Referenceable janeAddr = new Referenceable ( ""Address"" ) ; Referenceable julius = new Referenceable ( ""Manager"" ) ; Referenceable juliusAddr = new Referenceable ( ""Address"" ) ; Referenceable max = new Referenceable ( ""Person"" ) ; Referenceable maxAddr = new Referenceable ( ""Address"" ) ; hrDept . set ( NAME , ""hr"" ) ; john . set ( NAME , ""John"" ) ; john . set ( DEPARTMENT_ATTR , hrDept ) ; johnAddr . set ( ""street"" , ""Stewart Drive"" ) ; johnAddr . set ( ""city"" , ""Sunnyvale"" ) ; john . set ( ""address"" , johnAddr ) ; john . set ( ""birthday"" , new Date ( 1950 , 5 , 15 ) ) ; john . set ( ""isOrganDonor"" , true ) ; john . set ( ""hasPets"" , true ) ; john . set ( ""numberOfCars"" , 1 ) ; john . set ( ""houseNumber"" , 153 ) ; john . set ( ""carMileage"" , 13364 ) ; john . set ( ""shares"" , 15000 ) ; john . set ( ""salary"" , 123345.678 ) ; john . set ( ""age"" , 50 ) ; john . set ( ""numberOfStarsEstimate"" , new BigInteger ( ""1000000000000000000000"" ) ) ; john . set ( ""approximationOfPi"" , new BigDecimal ( ""3.141592653589793238462643383279502884197169399375105820974944592307816406286"" ) ) ; jane . set ( NAME , ""Jane"" ) ; jane . set ( DEPARTMENT_ATTR , hrDept ) ; janeAddr . set ( ""street"" , ""Great America Parkway"" ) ; janeAddr . set ( ""city"" , ""Santa Clara"" ) ; jane . set ( ""address"" , janeAddr ) ; janeAddr . set ( ""street"" , ""Great America Parkway"" ) ; julius . set ( NAME , ""Julius"" ) ; julius . set ( DEPARTMENT_ATTR , hrDept ) ; juliusAddr . set ( ""street"" , ""Madison Ave"" ) ; juliusAddr . set ( ""city"" , ""Newtonville"" ) ; julius . set ( ""address"" , juliusAddr ) ; julius . set ( ""subordinates"" , ImmutableList . < Referenceable > of ( ) ) ; max . set ( NAME , ""Max"" ) ; max . set ( DEPARTMENT_ATTR , hrDept ) ; maxAddr . set ( ""street"" , ""Ripley St"" ) ; maxAddr . set ( ""city"" , ""Newton"" ) ; max . set ( ""address"" , maxAddr ) ; max . set ( ""manager"" , jane ) ; max . set ( ""mentor"" , julius ) ; max . set ( ""birthday"" , new Date ( 1979 , 3 , 15 ) ) ; max . set ( ""isOrganDonor"" , true ) ; max . set ( ""hasPets"" , true ) ; max . set ( ""age"" , 36 ) ; max . set ( ""numberOfCars"" , 2 ) ; max . set ( ""houseNumber"" , 17 ) ; max . set ( ""carMileage"" , 13 ) ; max . set ( ""shares"" , Long . MAX_VALUE ) ; max . set ( ""salary"" , Double . MAX_VALUE ) ; max . set ( ""numberOfStarsEstimate"" , new BigInteger ( ""1000000000000000000000000000000"" ) ) ; max . set ( ""approximationOfPi"" , new BigDecimal ( ""3.1415926535897932"" ) ) ; john . set ( ""manager"" , jane ) ; john . set ( ""mentor"" , max ) ; hrDept . set ( EMPLOYEES_ATTR , ImmutableList . of ( john , jane , julius , max ) ) ; jane . set ( ""subordinates"" , ImmutableList . of ( john , max ) ) ; jane . getTrait ( ""SecurityClearance"" ) . set ( ""level"" , 1 ) ; ClassType deptType = ts . getDataType ( ClassType . class , ""Department"" ) ; ITypedReferenceableInstance hrDept2 = deptType . convert ( hrDept , Multiplicity . REQUIRED ) ; Assert . assertNotNull ( hrDept2 ) ; return hrDept2 ; } public static TypesDef simpleType ( ) { HierarchicalTypeDefinition < ClassType > superTypeDefinition = createClassTypeDef ( ""h_type"" , ImmutableSet . < String > of ( ) , createOptionalAttrDef ( ""attr"" , DataTypes . STRING_TYPE ) ) ; StructTypeDefinition structTypeDefinition = new StructTypeDefinition ( ""s_type"" , ""structType"" , new AttributeDefinition [ ] { createRequiredAttrDef ( NAME , DataTypes . STRING_TYPE ) } ) ; HierarchicalTypeDefinition < TraitType > traitTypeDefinition = createTraitTypeDef ( ""t_type"" , ""traitType"" , ImmutableSet . < String > of ( ) ) ; EnumValue values [ ] = { new EnumValue ( ""ONE"" , 1 ) , } ; EnumTypeDefinition enumTypeDefinition = new EnumTypeDefinition ( ""e_type"" , ""enumType"" , values ) ; return TypesUtil . getTypesDef ( ImmutableList . of ( enumTypeDefinition ) , ImmutableList . of ( structTypeDefinition ) , ImmutableList . of ( traitTypeDefinition ) , ImmutableList . of ( superTypeDefinition ) ) ; } public static TypesDef simpleTypeUpdated ( ) { HierarchicalTypeDefinition < ClassType > superTypeDefinition = createClassTypeDef ( ""h_type"" , ImmutableSet . < String > of ( ) , createOptionalAttrDef ( ""attr"" , DataTypes . STRING_TYPE ) ) ; HierarchicalTypeDefinition < ClassType > newSuperTypeDefinition = createClassTypeDef ( ""new_h_type"" , ImmutableSet . < String > of ( ) , createOptionalAttrDef ( ""attr"" , DataTypes . STRING_TYPE ) ) ; StructTypeDefinition structTypeDefinition = new StructTypeDefinition ( ""s_type"" , ""structType"" , new AttributeDefinition [ ] { createRequiredAttrDef ( NAME , DataTypes . STRING_TYPE ) } ) ; HierarchicalTypeDefinition < TraitType > traitTypeDefinition = createTraitTypeDef ( ""t_type"" , ""traitType"" , ImmutableSet . < String > of ( ) ) ; EnumValue values [ ] = { new EnumValue ( ""ONE"" , 1 ) , } ; EnumTypeDefinition enumTypeDefinition = new EnumTypeDefinition ( ""e_type"" , ""enumType"" , values ) ; return TypesUtil . getTypesDef ( ImmutableList . of ( enumTypeDefinition ) , ImmutableList . of ( structTypeDefinition ) , ImmutableList . of ( traitTypeDefinition ) , ImmutableList . of ( superTypeDefinition , newSuperTypeDefinition ) ) ; } public static TypesDef simpleTypeUpdatedDiff ( ) { HierarchicalTypeDefinition < ClassType > newSuperTypeDefinition = createClassTypeDef ( ""new_h_type"" , ImmutableSet . < String > of ( ) , createOptionalAttrDef ( ""attr"" , DataTypes . STRING_TYPE ) ) ; return TypesUtil . getTypesDef ( ImmutableList . < EnumTypeDefinition > of ( ) , ImmutableList . < StructTypeDefinition > of ( ) , ImmutableList . < HierarchicalTypeDefinition < TraitType > > of ( ) , ImmutableList . of ( newSuperTypeDefinition ) ) ; } public static TypesDef defineHiveTypes ( ) { String _description = ""_description"" ; HierarchicalTypeDefinition < ClassType > superTypeDefinition = createClassTypeDef ( SUPER_TYPE_NAME , ImmutableSet . < String > of ( ) , createOptionalAttrDef ( ""namespace"" , DataTypes . STRING_TYPE ) , createOptionalAttrDef ( ""cluster"" , DataTypes . STRING_TYPE ) , createOptionalAttrDef ( ""colo"" , DataTypes . STRING_TYPE ) ) ; HierarchicalTypeDefinition < ClassType > databaseTypeDefinition = createClassTypeDef ( DATABASE_TYPE , DATABASE_TYPE + _description , ImmutableSet . of ( SUPER_TYPE_NAME ) , TypesUtil . createUniqueRequiredAttrDef ( NAME , DataTypes . STRING_TYPE ) , createOptionalAttrDef ( ""created"" , DataTypes . DATE_TYPE ) , createOptionalAttrDef ( ""isReplicated"" , DataTypes . BOOLEAN_TYPE ) , new AttributeDefinition ( ""parameters"" , new DataTypes . MapType ( DataTypes . STRING_TYPE , DataTypes . STRING_TYPE ) . getName ( ) , Multiplicity . OPTIONAL , false , null ) , createRequiredAttrDef ( ""description"" , DataTypes . STRING_TYPE ) ) ; StructTypeDefinition structTypeDefinition = new StructTypeDefinition ( ""serdeType"" , ""serdeType"" + _description , new AttributeDefinition [ ] { createRequiredAttrDef ( NAME , DataTypes . STRING_TYPE ) , createRequiredAttrDef ( ""serde"" , DataTypes . STRING_TYPE ) , createOptionalAttrDef ( ""description"" , DataTypes . STRING_TYPE ) } ) ; EnumValue values [ ] = { new EnumValue ( ""MANAGED"" , 1 ) , new EnumValue ( ""EXTERNAL"" , 2 ) , } ; EnumTypeDefinition enumTypeDefinition = new EnumTypeDefinition ( ""tableType"" , ""tableType"" + _description , values ) ; HierarchicalTypeDefinition < ClassType > columnsDefinition = createClassTypeDef ( COLUMN_TYPE , ImmutableSet . < String > of ( ) , createUniqueRequiredAttrDef ( NAME , DataTypes . STRING_TYPE ) , createRequiredAttrDef ( ""type"" , DataTypes . STRING_TYPE ) ) ; StructTypeDefinition partitionDefinition = new StructTypeDefinition ( ""partition_struct_type"" , ""partition_struct_type"" + _description , new AttributeDefinition [ ] { createRequiredAttrDef ( NAME , DataTypes . STRING_TYPE ) , } ) ; AttributeDefinition [ ] attributeDefinitions = new AttributeDefinition [ ] { new AttributeDefinition ( ""location"" , DataTypes . STRING_TYPE . getName ( ) , Multiplicity . OPTIONAL , false , null ) , new AttributeDefinition ( ""inputFormat"" , DataTypes . STRING_TYPE . getName ( ) , Multiplicity . OPTIONAL , false , null ) , new AttributeDefinition ( ""outputFormat"" , DataTypes . STRING_TYPE . getName ( ) , Multiplicity . OPTIONAL , false , null ) , new AttributeDefinition ( ""compressed"" , DataTypes . BOOLEAN_TYPE . getName ( ) , Multiplicity . REQUIRED , false , null ) , new AttributeDefinition ( ""numBuckets"" , DataTypes . INT_TYPE . getName ( ) , Multiplicity . OPTIONAL , false , null ) , } ; HierarchicalTypeDefinition < ClassType > storageDescClsDef = new HierarchicalTypeDefinition < > ( ClassType . class , STORAGE_DESC_TYPE , STORAGE_DESC_TYPE + _description , ImmutableSet . of ( SUPER_TYPE_NAME ) , attributeDefinitions ) ; AttributeDefinition [ ] partClsAttributes = new AttributeDefinition [ ] { new AttributeDefinition ( ""values"" , DataTypes . arrayTypeName ( DataTypes . STRING_TYPE . getName ( ) ) , Multiplicity . OPTIONAL , false , null ) , new AttributeDefinition ( ""table"" , TABLE_TYPE , Multiplicity . REQUIRED , false , null ) , new AttributeDefinition ( ""createTime"" , DataTypes . LONG_TYPE . getName ( ) , Multiplicity . OPTIONAL , false , null ) , new AttributeDefinition ( ""lastAccessTime"" , DataTypes . LONG_TYPE . getName ( ) , Multiplicity . OPTIONAL , false , null ) , new AttributeDefinition ( ""sd"" , STORAGE_DESC_TYPE , Multiplicity . REQUIRED , true , null ) , new AttributeDefinition ( ""columns"" , DataTypes . arrayTypeName ( COLUMN_TYPE ) , Multiplicity . OPTIONAL , true , null ) , new AttributeDefinition ( ""parameters"" , new DataTypes . MapType ( DataTypes . STRING_TYPE , DataTypes . STRING_TYPE ) . getName ( ) , Multiplicity . OPTIONAL , false , null ) , } ; HierarchicalTypeDefinition < ClassType > partClsDef = new HierarchicalTypeDefinition < > ( ClassType . class , ""partition_class_type"" , ""partition_class_type"" + _description , ImmutableSet . of ( SUPER_TYPE_NAME ) , partClsAttributes ) ; HierarchicalTypeDefinition < ClassType > processClsType = new HierarchicalTypeDefinition < > ( ClassType . class , PROCESS_TYPE , PROCESS_TYPE + _description , ImmutableSet . < String > of ( ) , new AttributeDefinition [ ] { new AttributeDefinition ( ""outputs"" , ""array<"" + TABLE_TYPE + "">"" , Multiplicity . OPTIONAL , false , null ) } ) ; HierarchicalTypeDefinition < ClassType > tableTypeDefinition = createClassTypeDef ( TABLE_TYPE , TABLE_TYPE + _description , ImmutableSet . of ( SUPER_TYPE_NAME ) , TypesUtil . createUniqueRequiredAttrDef ( NAME , DataTypes . STRING_TYPE ) , createRequiredAttrDef ( ""description"" , DataTypes . STRING_TYPE ) , createRequiredAttrDef ( ""type"" , DataTypes . STRING_TYPE ) , createOptionalAttrDef ( ""created"" , DataTypes . DATE_TYPE ) , new AttributeDefinition ( ""tableType"" , ""tableType"" , Multiplicity . REQUIRED , false , null ) , new AttributeDefinition ( ""columnNames"" , String . format ( ""array<%s>"" , DataTypes . STRING_TYPE . getName ( ) ) , Multiplicity . OPTIONAL , false , null ) , new AttributeDefinition ( ""columns"" , String . format ( ""array<%s>"" , COLUMN_TYPE ) , Multiplicity . OPTIONAL , true , null ) , new AttributeDefinition ( ""partitions"" , String . format ( ""array<%s>"" , ""partition_struct_type"" ) , Multiplicity . OPTIONAL , true , null ) , new AttributeDefinition ( ""parametersMap"" , DataTypes . mapTypeName ( DataTypes . STRING_TYPE . getName ( ) , DataTypes . STRING_TYPE . getName ( ) ) , Multiplicity . OPTIONAL , true , null ) , new AttributeDefinition ( COLUMNS_MAP , DataTypes . mapTypeName ( DataTypes . STRING_TYPE . getName ( ) , COLUMN_TYPE ) , Multiplicity . OPTIONAL , true , null ) , new AttributeDefinition ( ""partitionsMap"" , DataTypes . mapTypeName ( DataTypes . STRING_TYPE . getName ( ) , ""partition_struct_type"" ) , Multiplicity . OPTIONAL , true , null ) , new AttributeDefinition ( ""serde1"" , ""serdeType"" , Multiplicity . OPTIONAL , false , null ) , new AttributeDefinition ( ""serde2"" , ""serdeType"" , Multiplicity . OPTIONAL , false , null ) , new AttributeDefinition ( ""database"" , DATABASE_TYPE , Multiplicity . REQUIRED , false , null ) , new AttributeDefinition ( ""databaseComposite"" , DATABASE_TYPE , Multiplicity . OPTIONAL , true , null ) ) ; HierarchicalTypeDefinition < TraitType > piiTypeDefinition = createTraitTypeDef ( PII , PII + _description , ImmutableSet . < String > of ( ) ) ; HierarchicalTypeDefinition < TraitType > classificationTypeDefinition = createTraitTypeDef ( CLASSIFICATION , CLASSIFICATION + _description , ImmutableSet . < String > of ( ) , createRequiredAttrDef ( ""tag"" , DataTypes . STRING_TYPE ) ) ; HierarchicalTypeDefinition < TraitType > fetlClassificationTypeDefinition = createTraitTypeDef ( ""fetl"" + CLASSIFICATION , ""fetl"" + CLASSIFICATION + _description , ImmutableSet . of ( CLASSIFICATION ) , createRequiredAttrDef ( ""tag"" , DataTypes . STRING_TYPE ) ) ; return TypesUtil . getTypesDef ( ImmutableList . of ( enumTypeDefinition ) , ImmutableList . of ( structTypeDefinition , partitionDefinition ) , ImmutableList . of ( classificationTypeDefinition , fetlClassificationTypeDefinition , piiTypeDefinition ) , ImmutableList . of ( superTypeDefinition , databaseTypeDefinition , columnsDefinition , tableTypeDefinition , storageDescClsDef , partClsDef , processClsType ) ) ; } public static Collection < IDataType > createHiveTypes ( TypeSystem typeSystem ) throws Exception { if ( ! typeSystem . isRegistered ( TABLE_TYPE ) ) { TypesDef typesDef = defineHiveTypes ( ) ; return typeSystem . defineTypes ( typesDef ) . values ( ) ; } return new ArrayList < > ( ) ; } public static final String randomString ( ) { return randomString ( 10 ) ; } public static final String randomString ( int count ) { final String prefix = ""r"" ; return prefix + RandomStringUtils . randomAlphanumeric ( count - prefix . length ( ) ) ; } public static Referenceable createDBEntity ( ) { Referenceable entity = new Referenceable ( DATABASE_TYPE ) ; String dbName = RandomStringUtils . randomAlphanumeric ( 10 ) ; entity . set ( NAME , dbName ) ; entity . set ( ""description"" , ""us db"" ) ; return entity ; } public static Referenceable createTableEntity ( String dbId ) { Referenceable entity = new Referenceable ( TABLE_TYPE ) ; String tableName = RandomStringUtils . randomAlphanumeric ( 10 ) ; entity . set ( NAME , tableName ) ; entity . set ( ""description"" , ""random table"" ) ; entity . set ( ""type"" , ""type"" ) ; entity . set ( ""tableType"" , ""MANAGED"" ) ; entity . set ( ""database"" , new Id ( dbId , 0 , DATABASE_TYPE ) ) ; entity . set ( ""created"" , new Date ( ) ) ; return entity ; } public static Referenceable createColumnEntity ( ) { Referenceable entity = new Referenceable ( COLUMN_TYPE ) ; entity . set ( NAME , RandomStringUtils . randomAlphanumeric ( 10 ) ) ; entity . set ( ""type"" , ""VARCHAR(32)"" ) ; return entity ; } public static String createInstance ( MetadataService metadataService , Referenceable entity ) throws Exception { RequestContext . createContext ( ) ; String entityjson = InstanceSerialization . toJson ( entity , true ) ; JSONArray entitiesJson = new JSONArray ( ) ; entitiesJson . put ( entityjson ) ; CreateUpdateEntitiesResult creationResult = metadataService . createEntities ( entitiesJson . toString ( ) ) ; Map < String , String > guidMap = creationResult . getGuidMapping ( ) . getGuidAssignments ( ) ; Map < Id , Referenceable > referencedObjects = findReferencedObjects ( entity ) ; for ( Map . Entry < Id , Referenceable > entry : referencedObjects . entrySet ( ) ) { Id foundId = entry . getKey ( ) ; if ( foundId . isUnassigned ( ) ) { String guid = guidMap . get ( entry . getKey ( ) . _getId ( ) ) ; Referenceable obj = entry . getValue ( ) ; loadAndDoSimpleValidation ( guid , obj , metadataService ) ; } } List < String > guids = creationResult . getCreatedEntities ( ) ; if ( guids != null && guids . size ( ) > 0 ) { return guids . get ( guids . size ( ) - 1 ) ; } return null ; } private static Map < Id , Referenceable > findReferencedObjects ( Referenceable ref ) { Map < Id , Referenceable > result = new HashMap < > ( ) ; findReferencedObjects ( ref , result ) ; return result ; } private static void findReferencedObjects ( Referenceable ref , Map < Id , Referenceable > seen ) { Id guid = ref . getId ( ) ; if ( seen . containsKey ( guid ) ) { return ; } seen . put ( guid , ref ) ; for ( Map . Entry < String , Object > attr : ref . getValuesMap ( ) . entrySet ( ) ) { Object value = attr . getValue ( ) ; if ( value instanceof Referenceable ) { findReferencedObjects ( ( Referenceable ) value , seen ) ; } else if ( value instanceof List ) { for ( Object o : ( List ) value ) { if ( o instanceof Referenceable ) { findReferencedObjects ( ( Referenceable ) o , seen ) ; } } } else if ( value instanceof Map ) { for ( Object o : ( ( Map ) value ) . values ( ) ) { if ( o instanceof Referenceable ) { findReferencedObjects ( ( Referenceable ) o , seen ) ; } } } } } public static void resetRequestContext ( ) { String user = RequestContext . get ( ) . getUser ( ) ; RequestContext . createContext ( ) ; RequestContext . get ( ) . setUser ( user ) ; } public static void setupGraphProvider ( MetadataRepository repo ) throws AtlasException { TypeCache typeCache = null ; try { typeCache = AtlasRepositoryConfiguration . getTypeCache ( ) . newInstance ( ) ; } catch ( Throwable t ) { typeCache = new DefaultTypeCache ( ) ; } final GraphBackedSearchIndexer indexer = new GraphBackedSearchIndexer ( new AtlasTypeRegistry ( ) ) ; Configuration config = ApplicationProperties . get ( ) ; ITypeStore typeStore = new GraphBackedTypeStore ( AtlasGraphProvider . getGraphInstance ( ) ) ; DefaultMetadataService defaultMetadataService = new DefaultMetadataService ( repo , typeStore , new HashSet < TypesChangeListener > ( ) { { add ( indexer ) ; } } , new HashSet < EntityChangeListener > ( ) , TypeSystem . getInstance ( ) , config , typeCache , new InMemoryEntityAuditRepository ( ) ) ; getGraph ( ) . commit ( ) ; } public static AtlasGraph getGraph ( ) { return AtlasGraphProvider . getGraphInstance ( ) ; } public static MetadataService addSessionCleanupWrapper ( final MetadataService delegate ) { return ( MetadataService ) Proxy . newProxyInstance ( Thread . currentThread ( ) . getContextClassLoader ( ) , new Class [ ] { MetadataService . class } , new InvocationHandler ( ) { @ Override public Object invoke ( Object proxy , Method method , Object [ ] args ) throws Throwable { try { resetRequestContext ( ) ; Object result = method . invoke ( delegate , args ) ; return result ; } catch ( InvocationTargetException e ) { e . getCause ( ) . printStackTrace ( ) ; throw e . getCause ( ) ; } catch ( Throwable t ) { t . printStackTrace ( ) ; throw t ; } } } ) ; } public static MetadataRepository addTransactionWrapper ( final MetadataRepository delegate ) { return ( MetadataRepository ) Proxy . newProxyInstance ( Thread . currentThread ( ) . getContextClassLoader ( ) , new Class [ ] { MetadataRepository . class } , new InvocationHandler ( ) { @ Override public Object invoke ( Object proxy , Method method , Object [ ] args ) throws Throwable { boolean useTransaction = GraphBackedMetadataRepository . class . getMethod ( method . getName ( ) , method . getParameterTypes ( ) ) . isAnnotationPresent ( GraphTransaction . class ) ; try { resetRequestContext ( ) ; Object result = method . invoke ( delegate , args ) ; if ( useTransaction ) { System . out . println ( ""Committing changes"" ) ; getGraph ( ) . commit ( ) ; System . out . println ( ""Commit succeeded."" ) ; } return result ; } catch ( InvocationTargetException e ) { e . getCause ( ) . printStackTrace ( ) ; if ( useTransaction ) { System . out . println ( ""Rolling back changes due to exception."" ) ; getGraph ( ) . rollback ( ) ; } throw e . getCause ( ) ; } catch ( Throwable t ) { t . printStackTrace ( ) ; if ( useTransaction ) { System . out . println ( ""Rolling back changes due to exception."" ) ; getGraph ( ) . rollback ( ) ; } throw t ; } } } ) ; } public static ITypedReferenceableInstance loadAndDoSimpleValidation ( String guid , Referenceable original , MetadataRepository repositoryService ) throws AtlasException { ITypedReferenceableInstance loaded = repositoryService . getEntityDefinition ( guid ) ; doSimpleValidation ( original , loaded ) ; return loaded ; } public static ITypedReferenceableInstance loadAndDoSimpleValidation ( String guid , Referenceable original , MetadataService repositoryService ) throws AtlasException { ITypedReferenceableInstance loaded = repositoryService . getEntityDefinition ( guid ) ; doSimpleValidation ( original , loaded ) ; return loaded ; } private static void doSimpleValidation ( Referenceable original , IInstance loaded ) throws AtlasException { assertEquals ( loaded . getTypeName ( ) , original . getTypeName ( ) ) ; ClassType ct = TypeSystem . getInstance ( ) . getDataType ( ClassType . class , loaded . getTypeName ( ) ) ; for ( AttributeInfo field : ct . fieldMapping . fields . values ( ) ) { if ( field . dataType ( ) . getTypeCategory ( ) == TypeCategory . PRIMITIVE ) { if ( original . get ( field . name ) != null ) { Object rawLoadedValue = loaded . get ( field . name ) ; Object rawProvidedValue = original . get ( field . name ) ; Object convertedLoadedValue = field . dataType ( ) . convert ( rawLoadedValue , Multiplicity . REQUIRED ) ; Object convertedProvidedValue = field . dataType ( ) . convert ( rawProvidedValue , Multiplicity . REQUIRED ) ; assertEquals ( convertedLoadedValue , convertedProvidedValue ) ; } } } } public static void assertContentsSame ( Collection < String > actual , Collection < String > expected ) { assertEquals ( actual . size ( ) , expected . size ( ) ) ; Set < String > checker = new HashSet < > ( ) ; checker . addAll ( expected ) ; checker . removeAll ( actual ) ; assertEquals ( checker . size ( ) , 0 ) ; } public static void skipForGremlin3EnabledGraphDb ( ) throws SkipException { if ( TestUtils . getGraph ( ) . getSupportedGremlinVersion ( ) == GremlinVersion . THREE ) { throw new SkipException ( ""This test requires Gremlin2. Skipping test "" ) ; } } }",Smelly
"@ Test public class KeyValueTest { private static final Map < Schema , List < Object > > testData = new HashMap ( ) { private static final long serialVersionUID = - 3081991052949960650L ; { put ( BooleanSchema . of ( ) , Arrays . asList ( false , true ) ) ; put ( StringSchema . utf8 ( ) , Arrays . asList ( ""my string"" ) ) ; put ( ByteSchema . of ( ) , Arrays . asList ( ( byte ) 32767 , ( byte ) - 32768 ) ) ; put ( ShortSchema . of ( ) , Arrays . asList ( ( short ) 32767 , ( short ) - 32768 ) ) ; put ( IntSchema . of ( ) , Arrays . asList ( ( int ) 423412424 , ( int ) - 41243432 ) ) ; put ( LongSchema . of ( ) , Arrays . asList ( 922337203685477580L , - 922337203685477581L ) ) ; put ( FloatSchema . of ( ) , Arrays . asList ( 5678567.12312f , - 5678567.12341f ) ) ; put ( DoubleSchema . of ( ) , Arrays . asList ( 5678567.12312d , - 5678567.12341d ) ) ; put ( BytesSchema . of ( ) , Arrays . asList ( ""my string"" . getBytes ( UTF_8 ) ) ) ; put ( ByteBufferSchema . of ( ) , Arrays . asList ( ByteBuffer . allocate ( 10 ) . put ( ""my string"" . getBytes ( UTF_8 ) ) ) ) ; put ( ByteBufSchema . of ( ) , Arrays . asList ( Unpooled . wrappedBuffer ( ""my string"" . getBytes ( UTF_8 ) ) ) ) ; put ( DateSchema . of ( ) , Arrays . asList ( new Date ( new java . util . Date ( ) . getTime ( ) - 10000 ) , new Date ( new java . util . Date ( ) . getTime ( ) ) ) ) ; put ( TimeSchema . of ( ) , Arrays . asList ( new Time ( new java . util . Date ( ) . getTime ( ) - 10000 ) , new Time ( new java . util . Date ( ) . getTime ( ) ) ) ) ; put ( TimestampSchema . of ( ) , Arrays . asList ( new Timestamp ( new java . util . Date ( ) . getTime ( ) ) , new Timestamp ( new java . util . Date ( ) . getTime ( ) ) ) ) ; } } ; @ DataProvider ( name = ""schemas"" ) public Object [ ] [ ] schemas ( ) { return new Object [ ] [ ] { { testData } } ; } @ Test ( dataProvider = ""schemas"" ) public void testAllSchemas ( Map < Schema , List < Object > > schemas ) { for ( Map . Entry < Schema , List < Object > > keyEntry : schemas . entrySet ( ) ) { for ( Map . Entry < Schema , List < Object > > valueEntry : schemas . entrySet ( ) ) { testEncodeDecodeKeyValue ( keyEntry . getKey ( ) , valueEntry . getKey ( ) , keyEntry . getValue ( ) , valueEntry . getValue ( ) ) ; } } } private < K , V > void testEncodeDecodeKeyValue ( Schema < K > keySchema , Schema < V > valueSchema , List < K > keys , List < V > values ) { for ( K key : keys ) { for ( V value : values ) { byte [ ] data = KeyValue . encode ( key , keySchema , value , valueSchema ) ; KeyValue < K , V > kv = KeyValue . decode ( data , ( keyBytes , valueBytes ) -> new KeyValue < > ( keySchema . decode ( keyBytes ) , valueSchema . decode ( valueBytes ) ) ) ; assertEquals ( kv . getKey ( ) , key ) ; assertEquals ( kv . getValue ( ) , value ) ; } } } }",No
"public class DiskFileItem implements FileItem , FileItemHeadersSupport { private static final Logger log = LoggerFactory . getLogger ( DiskFileItem . class ) ; private static final long serialVersionUID = 2237570099615271025L ; public static final String DEFAULT_CHARSET = ""ISO-8859-1"" ; private static final String UID = UUID . randomUUID ( ) . toString ( ) . replace ( ':' , '_' ) . replace ( '-' , '_' ) ; private static final Random counter = new Random ( ) ; private String fieldName ; private final String contentType ; private boolean isFormField ; private final String fileName ; private long size = - 1 ; private final int sizeThreshold ; private final File repository ; private byte [ ] cachedContent ; private transient DeferredFileOutputStream dfos ; private transient File tempFile ; private File dfosFile ; private FileItemHeaders headers ; private transient final IFileCleaner fileUploadCleaner ; public DiskFileItem ( final String fieldName , final String contentType , final boolean isFormField , final String fileName , final int sizeThreshold , final File repository , final IFileCleaner fileUploadCleaner ) { this . fieldName = fieldName ; this . contentType = contentType ; this . isFormField = isFormField ; this . fileName = fileName ; this . sizeThreshold = sizeThreshold ; this . repository = repository ; this . fileUploadCleaner = fileUploadCleaner ; } @ Override public InputStream getInputStream ( ) throws IOException { if ( ! isInMemory ( ) ) { return new FileInputStream ( dfos . getFile ( ) ) ; } if ( cachedContent == null ) { cachedContent = dfos . getData ( ) ; } return new ByteArrayInputStream ( cachedContent ) ; } @ Override public String getContentType ( ) { return contentType ; } public String getCharSet ( ) { ParameterParser parser = new ParameterParser ( ) ; parser . setLowerCaseNames ( true ) ; Map < ? , ? > params = parser . parse ( getContentType ( ) , ';' ) ; return ( String ) params . get ( ""charset"" ) ; } @ Override public String getName ( ) { return fileName ; } @ Override public boolean isInMemory ( ) { if ( cachedContent != null ) { return true ; } return dfos . isInMemory ( ) ; } @ Override public long getSize ( ) { if ( size >= 0 ) { return size ; } else if ( cachedContent != null ) { return cachedContent . length ; } else if ( dfos . isInMemory ( ) ) { return dfos . getData ( ) . length ; } else { return dfos . getFile ( ) . length ( ) ; } } @ Override public byte [ ] get ( ) { if ( isInMemory ( ) ) { if ( cachedContent == null ) { cachedContent = dfos . getData ( ) ; } return cachedContent ; } File file = dfos . getFile ( ) ; try { return Files . readBytes ( file ) ; } catch ( IOException e ) { log . debug ( ""failed to read content of file: "" + file . getAbsolutePath ( ) , e ) ; return null ; } } @ Override public String getString ( final String charset ) throws UnsupportedEncodingException { return new String ( get ( ) , charset ) ; } @ Override public String getString ( ) { byte [ ] rawdata = get ( ) ; String charset = getCharSet ( ) ; if ( charset == null ) { charset = DEFAULT_CHARSET ; } try { return new String ( rawdata , charset ) ; } catch ( UnsupportedEncodingException e ) { return new String ( rawdata ) ; } } @ Override public void write ( final File file ) throws IOException { if ( isInMemory ( ) ) { FileOutputStream fout = new FileOutputStream ( file ) ; try { fout . write ( get ( ) ) ; } finally { fout . close ( ) ; } } else { File outputFile = getStoreLocation ( ) ; Checks . notNull ( outputFile , ""for a non-memory upload the file location must not be empty"" ) ; size = outputFile . length ( ) ; if ( ! outputFile . renameTo ( file ) ) { BufferedInputStream in = null ; BufferedOutputStream out = null ; try { in = new BufferedInputStream ( new FileInputStream ( outputFile ) ) ; out = new BufferedOutputStream ( new FileOutputStream ( file ) ) ; Streams . copy ( in , out ) ; } finally { IOUtils . closeQuietly ( in ) ; IOUtils . closeQuietly ( out ) ; } } } } @ Override public void delete ( ) { cachedContent = null ; File outputFile = getStoreLocation ( ) ; if ( ( outputFile != null ) && outputFile . exists ( ) ) { if ( Files . remove ( outputFile ) == false ) { log . error ( ""failed to delete file: "" + outputFile . getAbsolutePath ( ) ) ; } } } @ Override public String getFieldName ( ) { return fieldName ; } @ Override public void setFieldName ( final String fieldName ) { this . fieldName = fieldName ; } @ Override public boolean isFormField ( ) { return isFormField ; } @ Override public void setFormField ( final boolean state ) { isFormField = state ; } @ Override public OutputStream getOutputStream ( ) throws IOException { if ( dfos == null ) { dfos = new DeferredFileOutputStream ( sizeThreshold , new DeferredFileOutputStream . FileFactory ( ) { @ Override public File createFile ( ) { return getTempFile ( ) ; } } ) ; } return dfos ; } public File getStoreLocation ( ) { return dfos == null ? null : dfos . getFile ( ) ; } @ Override protected void finalize ( ) throws Throwable { super . finalize ( ) ; File outputFile = dfos . getFile ( ) ; if ( ( outputFile != null ) && outputFile . exists ( ) ) { if ( Files . remove ( outputFile ) == false ) { log . error ( ""failed to delete file: "" + outputFile . getAbsolutePath ( ) ) ; } } } protected File getTempFile ( ) { if ( tempFile == null ) { File tempDir = repository ; if ( tempDir == null ) { String systemTmp = null ; try { systemTmp = System . getProperty ( ""java.io.tmpdir"" ) ; } catch ( SecurityException e ) { throw new RuntimeException ( ""Reading property java.io.tmpdir is not allowed"" + "" for the current security settings. The repository location needs to be"" + "" set manually, or upgrade permissions to allow reading the tmpdir property."" ) ; } tempDir = new File ( systemTmp ) ; } try { do { String tempFileName = ""upload_"" + UID + ""_"" + getUniqueId ( ) + "".tmp"" ; tempFile = new File ( tempDir , tempFileName ) ; } while ( ! tempFile . createNewFile ( ) ) ; } catch ( IOException e ) { throw new RuntimeException ( ""Could not create the temp file for upload: "" + tempFile . getAbsolutePath ( ) , e ) ; } if ( fileUploadCleaner != null ) { fileUploadCleaner . track ( tempFile , this ) ; } } return tempFile ; } private static String getUniqueId ( ) { final int limit = 100000000 ; int current ; synchronized ( DiskFileItem . class ) { current = counter . nextInt ( ) ; } String id = Integer . toString ( current ) ; if ( current < limit ) { id = ( ""00000000"" + id ) . substring ( id . length ( ) ) ; } return id ; } @ Override public String toString ( ) { return ""name="" + getName ( ) + "", StoreLocation="" + String . valueOf ( getStoreLocation ( ) ) + "", size="" + getSize ( ) + ""bytes, "" + ""isFormField="" + isFormField ( ) + "", FieldName="" + getFieldName ( ) ; } private void writeObject ( final ObjectOutputStream out ) throws IOException { if ( dfos . isInMemory ( ) ) { cachedContent = get ( ) ; } else { cachedContent = null ; dfosFile = dfos . getFile ( ) ; } out . defaultWriteObject ( ) ; } private void readObject ( final ObjectInputStream in ) throws IOException , ClassNotFoundException { in . defaultReadObject ( ) ; OutputStream output = getOutputStream ( ) ; if ( cachedContent != null ) { output . write ( cachedContent ) ; } else { FileInputStream input = new FileInputStream ( dfosFile ) ; Streams . copy ( input , output ) ; Files . remove ( dfosFile ) ; dfosFile = null ; } output . close ( ) ; cachedContent = null ; } @ Override public FileItemHeaders getHeaders ( ) { return headers ; } @ Override public void setHeaders ( final FileItemHeaders pHeaders ) { headers = pHeaders ; } }",Smelly
"@ NoJSR250Annotations public class JMSConfiguration implements InitializingBean { public static final int DEFAULT_VALUE = - 1 ; static final boolean DEFAULT_USEJMS11 = true ; private boolean usingEndpointInfo = true ; private JmsTemplate jmsTemplate ; private AbstractMessageListenerContainer messageListenerContainer ; private JndiTemplate jndiTemplate ; private ConnectionFactory connectionFactory ; private DestinationResolver destinationResolver ; private PlatformTransactionManager transactionManager ; private boolean wrapInSingleConnectionFactory = true ; private TaskExecutor taskExecutor ; private boolean useJms11 = DEFAULT_USEJMS11 ; private boolean reconnectOnException = true ; private boolean messageIdEnabled = true ; private boolean messageTimestampEnabled = true ; private boolean pubSubNoLocal ; private Long clientReceiveTimeout ; private Long serverReceiveTimeout ; private boolean explicitQosEnabled ; private int deliveryMode = Message . DEFAULT_DELIVERY_MODE ; private int priority = Message . DEFAULT_PRIORITY ; private long timeToLive = Message . DEFAULT_TIME_TO_LIVE ; private boolean sessionTransacted ; private int concurrentConsumers = 1 ; private int maxConcurrentConsumers = 1 ; private int maxSuspendedContinuations = DEFAULT_VALUE ; private int reconnectPercentOfMax = 70 ; private volatile String messageSelector ; private boolean subscriptionDurable ; private String durableSubscriptionClientId ; private String durableSubscriptionName ; private String targetDestination ; private String replyDestination ; private String replyToDestination ; private String messageType = JMSConstants . TEXT_MESSAGE_TYPE ; private boolean pubSubDomain ; private boolean replyPubSubDomain ; private Boolean useConduitIdSelector ; private String conduitSelectorPrefix ; private boolean autoResolveDestination ; private long recoveryInterval = DEFAULT_VALUE ; private int cacheLevel = DEFAULT_VALUE ; private String cacheLevelName ; private Boolean enforceSpec ; private boolean acceptMessagesWhileStopping ; private boolean jmsProviderTibcoEms ; private String targetService ; private String requestURI ; private ConnectionFactory wrappedConnectionFactory ; private boolean autoWrappedConnectionFactory ; private JNDIConfiguration jndiConfig ; public void ensureProperlyConfigured ( org . apache . cxf . common . i18n . Message msg ) { if ( targetDestination == null || getOrCreateWrappedConnectionFactory ( ) == null ) { throw new ConfigurationException ( msg ) ; } } public String getCacheLevelName ( ) { return cacheLevelName ; } public void setCacheLevelName ( String cacheLevelName ) { this . cacheLevelName = cacheLevelName ; } public int getCacheLevel ( ) { return cacheLevel ; } public void setCacheLevel ( int cacheLevel ) { this . cacheLevel = cacheLevel ; } public long getRecoveryInterval ( ) { return recoveryInterval ; } public void setRecoveryInterval ( long recoveryInterval ) { this . recoveryInterval = recoveryInterval ; } public boolean isAutoResolveDestination ( ) { return autoResolveDestination ; } public void setAutoResolveDestination ( boolean autoResolveDestination ) { this . autoResolveDestination = autoResolveDestination ; } public boolean isUsingEndpointInfo ( ) { return this . usingEndpointInfo ; } public void setUsingEndpointInfo ( boolean usingEndpointInfo ) { this . usingEndpointInfo = usingEndpointInfo ; } public boolean isMessageIdEnabled ( ) { return messageIdEnabled ; } public void setMessageIdEnabled ( boolean messageIdEnabled ) { this . messageIdEnabled = messageIdEnabled ; } public boolean isMessageTimestampEnabled ( ) { return messageTimestampEnabled ; } public void setMessageTimestampEnabled ( boolean messageTimestampEnabled ) { this . messageTimestampEnabled = messageTimestampEnabled ; } public boolean isPubSubNoLocal ( ) { return pubSubNoLocal ; } public void setPubSubNoLocal ( boolean pubSubNoLocal ) { this . pubSubNoLocal = pubSubNoLocal ; } public Long getReceiveTimeout ( ) { return clientReceiveTimeout ; } public void setReceiveTimeout ( Long receiveTimeout ) { this . clientReceiveTimeout = receiveTimeout ; } public Long getServerReceiveTimeout ( ) { return serverReceiveTimeout ; } public void setServerReceiveTimeout ( Long receiveTimeout ) { this . serverReceiveTimeout = receiveTimeout ; } public boolean isExplicitQosEnabled ( ) { return explicitQosEnabled ; } public void setExplicitQosEnabled ( boolean explicitQosEnabled ) { this . explicitQosEnabled = explicitQosEnabled ; } public int getDeliveryMode ( ) { return deliveryMode ; } public void setDeliveryMode ( int deliveryMode ) { this . deliveryMode = deliveryMode ; } public int getPriority ( ) { return priority ; } public void setPriority ( int priority ) { this . priority = priority ; } public long getTimeToLive ( ) { return timeToLive ; } public void setTimeToLive ( long timeToLive ) { this . timeToLive = timeToLive ; } public String getMessageSelector ( ) { return messageSelector ; } public void setMessageSelector ( String messageSelector ) { this . messageSelector = messageSelector ; } public void setConduitSelectorPrefix ( String conduitSelectorPrefix ) { this . conduitSelectorPrefix = conduitSelectorPrefix ; } public String getConduitSelectorPrefix ( ) { if ( conduitSelectorPrefix == null ) { return """" ; } return conduitSelectorPrefix ; } public boolean isSetConduitSelectorPrefix ( ) { return conduitSelectorPrefix != null ; } public boolean isSubscriptionDurable ( ) { return subscriptionDurable ; } public void setSubscriptionDurable ( boolean subscriptionDurable ) { this . subscriptionDurable = subscriptionDurable ; } public String getDurableSubscriptionName ( ) { return durableSubscriptionName ; } public void setDurableSubscriptionName ( String durableSubscriptionName ) { this . durableSubscriptionName = durableSubscriptionName ; } public void afterPropertiesSet ( ) throws Exception { if ( connectionFactory == null ) { throw new RuntimeException ( ""Required property connectionfactory was not set"" ) ; } } @ Required public void setConnectionFactory ( ConnectionFactory connectionFactory ) { this . connectionFactory = connectionFactory ; } public String getTargetDestination ( ) { return targetDestination ; } public void setTargetDestination ( String targetDestination ) { this . targetDestination = targetDestination ; } public String getReplyDestination ( ) { return replyDestination ; } public void setReplyDestination ( String replyDestination ) { this . replyDestination = replyDestination ; } public String getReplyToDestination ( ) { return replyToDestination ; } public void setReplyToDestination ( String replyToDestination ) { this . replyToDestination = replyToDestination ; } public String getMessageType ( ) { return messageType ; } public void setMessageType ( String messageType ) { this . messageType = messageType ; } public boolean isPubSubDomain ( ) { return pubSubDomain ; } public void setPubSubDomain ( boolean pubSubDomain ) { this . pubSubDomain = pubSubDomain ; } public boolean isReplyPubSubDomain ( ) { return replyPubSubDomain ; } public void setReplyPubSubDomain ( boolean replyPubSubDomain ) { this . replyPubSubDomain = replyPubSubDomain ; } public boolean isUseJms11 ( ) { return useJms11 ; } public void setUseJms11 ( boolean useJms11 ) { this . useJms11 = useJms11 ; } public DestinationResolver getDestinationResolver ( ) { return destinationResolver ; } public void setDestinationResolver ( DestinationResolver destinationResolver ) { this . destinationResolver = destinationResolver ; } public boolean isSessionTransacted ( ) { return sessionTransacted ; } public void setSessionTransacted ( boolean sessionTransacted ) { this . sessionTransacted = sessionTransacted ; } public PlatformTransactionManager getTransactionManager ( ) { return transactionManager ; } public void setTransactionManager ( PlatformTransactionManager transactionManager ) { this . transactionManager = transactionManager ; } public int getConcurrentConsumers ( ) { return concurrentConsumers ; } public void setConcurrentConsumers ( int concurrentConsumers ) { this . concurrentConsumers = concurrentConsumers ; } public int getMaxConcurrentConsumers ( ) { return maxConcurrentConsumers ; } public void setMaxConcurrentConsumers ( int maxConcurrentConsumers ) { this . maxConcurrentConsumers = maxConcurrentConsumers ; } public int getMaxSuspendedContinuations ( ) { return maxSuspendedContinuations ; } public void setMaxSuspendedContinuations ( int maxSuspendedContinuations ) { this . maxSuspendedContinuations = maxSuspendedContinuations ; } public int getReconnectPercentOfMax ( ) { return reconnectPercentOfMax ; } public void setReconnectPercentOfMax ( int reconnectPercentOfMax ) { this . reconnectPercentOfMax = reconnectPercentOfMax ; } public TaskExecutor getTaskExecutor ( ) { return taskExecutor ; } public void setTaskExecutor ( TaskExecutor taskExecutor ) { this . taskExecutor = taskExecutor ; } public void setUseConduitIdSelector ( boolean useConduitIdSelector ) { this . useConduitIdSelector = useConduitIdSelector ; } public boolean isUseConduitIdSelector ( ) { if ( useConduitIdSelector == null ) { return true ; } return useConduitIdSelector ; } public boolean isSetUseConduitIdSelector ( ) { return useConduitIdSelector != null ; } public void setJndiTemplate ( JndiTemplate jndiTemplate ) { this . jndiTemplate = jndiTemplate ; } public JndiTemplate getJndiTemplate ( ) { return jndiTemplate ; } public JNDIConfiguration getJndiConfig ( ) { return jndiConfig ; } public void setJndiConfig ( JNDIConfiguration jndiConfig ) { this . jndiConfig = jndiConfig ; } public boolean isReconnectOnException ( ) { return reconnectOnException ; } public void setReconnectOnException ( boolean reconnectOnException ) { this . reconnectOnException = reconnectOnException ; } public boolean isAcceptMessagesWhileStopping ( ) { return acceptMessagesWhileStopping ; } public void setAcceptMessagesWhileStopping ( boolean acceptMessagesWhileStopping ) { this . acceptMessagesWhileStopping = acceptMessagesWhileStopping ; } public synchronized ConnectionFactory getOrCreateWrappedConnectionFactory ( ) { if ( wrappedConnectionFactory == null ) { if ( connectionFactory == null ) { connectionFactory = JMSFactory . getConnectionFactoryFromJndi ( this ) ; } if ( wrapInSingleConnectionFactory && ! ( connectionFactory instanceof SingleConnectionFactory ) ) { SingleConnectionFactory scf ; if ( useJms11 ) { if ( connectionFactory instanceof XAConnectionFactory ) { scf = new XASingleConnectionFactory ( connectionFactory ) ; } else { scf = new SingleConnectionFactory ( connectionFactory ) ; } autoWrappedConnectionFactory = true ; } else { @ SuppressWarnings ( ""deprecation"" ) SingleConnectionFactory scf2 = new org . springframework . jms . connection . SingleConnectionFactory102 ( connectionFactory , pubSubDomain ) ; scf = scf2 ; } if ( getDurableSubscriptionClientId ( ) != null ) { scf . setClientId ( getDurableSubscriptionClientId ( ) ) ; } scf . setReconnectOnException ( isReconnectOnException ( ) ) ; wrappedConnectionFactory = scf ; } else { wrappedConnectionFactory = connectionFactory ; } } return wrappedConnectionFactory ; } public ConnectionFactory getWrappedConnectionFactory ( ) { return wrappedConnectionFactory ; } public synchronized void destroyWrappedConnectionFactory ( ) { if ( autoWrappedConnectionFactory && wrappedConnectionFactory instanceof SingleConnectionFactory ) { ( ( SingleConnectionFactory ) wrappedConnectionFactory ) . destroy ( ) ; if ( connectionFactory == wrappedConnectionFactory ) { connectionFactory = null ; } wrappedConnectionFactory = null ; autoWrappedConnectionFactory = false ; } } protected ConnectionFactory getConnectionFactory ( ) { return connectionFactory ; } public boolean isWrapInSingleConnectionFactory ( ) { return wrapInSingleConnectionFactory ; } public void setWrapInSingleConnectionFactory ( boolean wrapInSingleConnectionFactory ) { this . wrapInSingleConnectionFactory = wrapInSingleConnectionFactory ; } public String getDurableSubscriptionClientId ( ) { return durableSubscriptionClientId ; } public void setDurableSubscriptionClientId ( String durableSubscriptionClientId ) { this . durableSubscriptionClientId = durableSubscriptionClientId ; } public void setTargetService ( String targetService ) { this . targetService = targetService ; } public String getTargetService ( ) { return targetService ; } public void setRequestURI ( String requestURI ) { this . requestURI = requestURI ; } public String getRequestURI ( ) { return requestURI ; } public boolean isEnforceSpec ( ) { if ( ! isSetEnforceSpec ( ) ) { return true ; } return enforceSpec ; } public void setEnforceSpec ( boolean enforceSpec ) { this . enforceSpec = enforceSpec ; } public boolean isSetEnforceSpec ( ) { return this . enforceSpec != null ; } public void setJmsTemplate ( JmsTemplate jmsTemplate ) { this . jmsTemplate = jmsTemplate ; } public JmsTemplate getJmsTemplate ( ) { return jmsTemplate ; } public AbstractMessageListenerContainer getMessageListenerContainer ( ) { return messageListenerContainer ; } public void setMessageListenerContainer ( AbstractMessageListenerContainer messageListenerContainer ) { this . messageListenerContainer = messageListenerContainer ; } public boolean isJmsProviderTibcoEms ( ) { return jmsProviderTibcoEms ; } public void setJmsProviderTibcoEms ( boolean jmsProviderTibcoEms ) { this . jmsProviderTibcoEms = jmsProviderTibcoEms ; } }",Smelly
public class EPMergedRegions extends BaseElementProcessor { public EPMergedRegions ( ) { super ( null ) ; } },No
"public class BatchLineReaderTest { private static final String TEXT_COMBINED = ""Test\r"" + ""Test2\r\n"" + ""Test3\n"" + ""Test4\r"" + ""\r"" + ""\r\n"" + ""\r\n"" + ""Test5\n"" + ""Test6\r\n"" + ""Test7\n"" + ""\n"" ; private static final String TEXT_EMPTY = """" ; @ Test public void simpleText ( ) throws Exception { final String TEXT = ""Test"" ; BatchLineReader reader = create ( TEXT ) ; assertEquals ( TEXT , reader . readLine ( ) ) ; assertNull ( reader . readLine ( ) ) ; assertNull ( reader . readLine ( ) ) ; reader . close ( ) ; } @ Test public void noText ( ) throws Exception { BatchLineReader reader = create ( TEXT_EMPTY ) ; assertNull ( reader . readLine ( ) ) ; assertNull ( reader . readLine ( ) ) ; reader . close ( ) ; } @ Test public void noBytes ( ) throws Exception { BatchLineReader reader = new BatchLineReader ( new ByteArrayInputStream ( new byte [ 0 ] ) ) ; assertNull ( reader . readLine ( ) ) ; assertNull ( reader . readLine ( ) ) ; reader . close ( ) ; } @ Test public void CRLF ( ) throws Exception { final String TEXT = ""Test\r\n"" + ""Test2"" ; BatchLineReader reader = create ( TEXT ) ; assertEquals ( ""Test\r\n"" , reader . readLine ( ) ) ; assertEquals ( ""Test2"" , reader . readLine ( ) ) ; assertNull ( reader . readLine ( ) ) ; assertNull ( reader . readLine ( ) ) ; reader . close ( ) ; } @ Test public void LF ( ) throws Exception { final String TEXT = ""Test\n"" + ""Test2"" ; BatchLineReader reader = create ( TEXT ) ; assertEquals ( ""Test\n"" , reader . readLine ( ) ) ; assertEquals ( ""Test2"" , reader . readLine ( ) ) ; assertNull ( reader . readLine ( ) ) ; assertNull ( reader . readLine ( ) ) ; reader . close ( ) ; } @ Test public void CR ( ) throws Exception { final String TEXT = ""Test\r"" + ""Test2"" ; BatchLineReader reader = create ( TEXT ) ; assertEquals ( ""Test\r"" , reader . readLine ( ) ) ; assertEquals ( ""Test2"" , reader . readLine ( ) ) ; assertNull ( reader . readLine ( ) ) ; assertNull ( reader . readLine ( ) ) ; reader . close ( ) ; } @ Test public void combined ( ) throws Exception { BatchLineReader reader = create ( TEXT_COMBINED ) ; assertEquals ( ""Test\r"" , reader . readLine ( ) ) ; assertEquals ( ""Test2\r\n"" , reader . readLine ( ) ) ; assertEquals ( ""Test3\n"" , reader . readLine ( ) ) ; assertEquals ( ""Test4\r"" , reader . readLine ( ) ) ; assertEquals ( ""\r"" , reader . readLine ( ) ) ; assertEquals ( ""\r\n"" , reader . readLine ( ) ) ; assertEquals ( ""\r\n"" , reader . readLine ( ) ) ; assertEquals ( ""Test5\n"" , reader . readLine ( ) ) ; assertEquals ( ""Test6\r\n"" , reader . readLine ( ) ) ; assertEquals ( ""Test7\n"" , reader . readLine ( ) ) ; assertEquals ( ""\n"" , reader . readLine ( ) ) ; assertNull ( reader . readLine ( ) ) ; assertNull ( reader . readLine ( ) ) ; reader . close ( ) ; } @ Test public void combinedBufferSizeTwo ( ) throws Exception { BatchLineReader reader = create ( TEXT_COMBINED , 2 ) ; assertEquals ( ""Test\r"" , reader . readLine ( ) ) ; assertEquals ( ""Test2\r\n"" , reader . readLine ( ) ) ; assertEquals ( ""Test3\n"" , reader . readLine ( ) ) ; assertEquals ( ""Test4\r"" , reader . readLine ( ) ) ; assertEquals ( ""\r"" , reader . readLine ( ) ) ; assertEquals ( ""\r\n"" , reader . readLine ( ) ) ; assertEquals ( ""\r\n"" , reader . readLine ( ) ) ; assertEquals ( ""Test5\n"" , reader . readLine ( ) ) ; assertEquals ( ""Test6\r\n"" , reader . readLine ( ) ) ; assertEquals ( ""Test7\n"" , reader . readLine ( ) ) ; assertEquals ( ""\n"" , reader . readLine ( ) ) ; assertNull ( reader . readLine ( ) ) ; assertNull ( reader . readLine ( ) ) ; reader . close ( ) ; } @ Test public void combinedBufferSizeOne ( ) throws Exception { BatchLineReader reader = create ( TEXT_COMBINED , 1 ) ; assertEquals ( ""Test\r"" , reader . readLine ( ) ) ; assertEquals ( ""Test2\r\n"" , reader . readLine ( ) ) ; assertEquals ( ""Test3\n"" , reader . readLine ( ) ) ; assertEquals ( ""Test4\r"" , reader . readLine ( ) ) ; assertEquals ( ""\r"" , reader . readLine ( ) ) ; assertEquals ( ""\r\n"" , reader . readLine ( ) ) ; assertEquals ( ""\r\n"" , reader . readLine ( ) ) ; assertEquals ( ""Test5\n"" , reader . readLine ( ) ) ; assertEquals ( ""Test6\r\n"" , reader . readLine ( ) ) ; assertEquals ( ""Test7\n"" , reader . readLine ( ) ) ; assertEquals ( ""\n"" , reader . readLine ( ) ) ; assertNull ( reader . readLine ( ) ) ; assertNull ( reader . readLine ( ) ) ; reader . close ( ) ; } @ Test public void doubleCR ( ) throws Exception { final String TEXT = ""Test\r"" + ""\r"" ; BatchLineReader reader = create ( TEXT , 1 ) ; assertEquals ( ""Test\r"" , reader . readLine ( ) ) ; assertEquals ( ""\r"" , reader . readLine ( ) ) ; reader . close ( ) ; } @ Test public void lineEqualsAndHashCode ( ) { Line l1 = new Line ( ""The first line"" , 1 ) ; Line l2 = new Line ( ""The first line"" , 1 ) ; Line l3 = new Line ( ""The second line"" , 2 ) ; assertEquals ( l1 , l2 ) ; assertFalse ( l1 . equals ( l3 ) ) ; assertTrue ( l1 . hashCode ( ) != l3 . hashCode ( ) ) ; } @ Test ( expected = IllegalArgumentException . class ) public void failBufferSizeZero ( ) throws Exception { BatchLineReader reader = create ( TEXT_EMPTY , 0 ) ; reader . close ( ) ; } @ Test ( expected = IllegalArgumentException . class ) public void failBufferSizeNegative ( ) throws Exception { BatchLineReader reader = create ( TEXT_EMPTY , - 1 ) ; reader . close ( ) ; } @ Test public void toList ( ) throws Exception { BatchLineReader reader = create ( TEXT_COMBINED ) ; List < Line > stringList = reader . toLineList ( ) ; assertEquals ( 11 , stringList . size ( ) ) ; assertEquals ( ""Test\r"" , stringList . get ( 0 ) . toString ( ) ) ; assertEquals ( ""Test2\r\n"" , stringList . get ( 1 ) . toString ( ) ) ; assertEquals ( ""Test3\n"" , stringList . get ( 2 ) . toString ( ) ) ; assertEquals ( ""Test4\r"" , stringList . get ( 3 ) . toString ( ) ) ; assertEquals ( ""\r"" , stringList . get ( 4 ) . toString ( ) ) ; assertEquals ( ""\r\n"" , stringList . get ( 5 ) . toString ( ) ) ; assertEquals ( ""\r\n"" , stringList . get ( 6 ) . toString ( ) ) ; assertEquals ( ""Test5\n"" , stringList . get ( 7 ) . toString ( ) ) ; assertEquals ( ""Test6\r\n"" , stringList . get ( 8 ) . toString ( ) ) ; assertEquals ( ""Test7\n"" , stringList . get ( 9 ) . toString ( ) ) ; assertEquals ( ""\n"" , stringList . get ( 10 ) . toString ( ) ) ; reader . close ( ) ; } @ Test public void specialCharacters ( ) throws Exception { final String text = ""\r\n"" + ""Content-Type: text/plain; charset=UTF-8\r\n"" + ""\r\n"" + ""ä€\r\n"" + ""\uFDFC\r\n"" + String . valueOf ( Character . toChars ( 0x1F603 ) ) ; BatchLineReader reader = create ( text ) ; reader . readLine ( ) ; reader . readLine ( ) ; reader . readLine ( ) ; assertEquals ( ""ä€\r\n"" , reader . readLine ( ) ) ; assertEquals ( ""\uFDFC\r\n"" , reader . readLine ( ) ) ; assertEquals ( String . valueOf ( Character . toChars ( 0x1F603 ) ) , reader . readLine ( ) ) ; assertNull ( reader . readLine ( ) ) ; reader . close ( ) ; } @ Test public void rawBytes ( ) throws Exception { byte [ ] content = new byte [ Byte . MAX_VALUE - Byte . MIN_VALUE + 1 ] ; for ( int i = Byte . MIN_VALUE ; i <= Byte . MAX_VALUE ; i ++ ) { content [ i - Byte . MIN_VALUE ] = ( byte ) i ; } BatchLineReader reader = new BatchLineReader ( new ByteArrayInputStream ( content ) ) ; final String contentString = reader . readLine ( ) + reader . readLine ( ) + reader . readLine ( ) ; assertArrayEquals ( content , contentString . getBytes ( Charset . forName ( ""ISO-8859-1"" ) ) ) ; assertNull ( reader . readLine ( ) ) ; reader . close ( ) ; } private BatchLineReader create ( final String inputString ) throws IOException { return new BatchLineReader ( new ByteArrayInputStream ( inputString . getBytes ( ""UTF-8"" ) ) ) ; } private BatchLineReader create ( final String inputString , final int bufferSize ) throws IOException { return new BatchLineReader ( new ByteArrayInputStream ( inputString . getBytes ( ""UTF-8"" ) ) , bufferSize ) ; } }",Smelly
"@ SuppressWarnings ( ""deprecation"" ) public class HLLCounterTest { ByteBuffer buf = ByteBuffer . allocate ( 1024 * 1024 ) ; Random rand1 = new Random ( 1 ) ; Random rand2 = new Random ( 2 ) ; Random rand3 = new Random ( 3 ) ; int errorCount1 = 0 ; int errorCount2 = 0 ; int errorCount3 = 0 ; @ Test public void testOneAdd ( ) throws IOException { HLLCounter hllc = new HLLCounter ( 14 ) ; HLLCounter one = new HLLCounter ( 14 ) ; for ( int i = 0 ; i < 1000000 ; i ++ ) { one . clear ( ) ; one . add ( i ) ; hllc . merge ( one ) ; assertTrue ( one . getRegisterType ( ) == RegisterType . SINGLE_VALUE ) ; } System . out . println ( hllc . getCountEstimate ( ) ) ; System . out . println ( hllc . getRegister ( ) . getRegisterType ( ) ) ; assertTrue ( hllc . getCountEstimate ( ) > 1000000 * 0.9 ) ; } @ Test public void tesSparseEstimate ( ) throws IOException { HLLCounter hllc = new HLLCounter ( 14 ) ; for ( int i = 0 ; i < 10 ; i ++ ) { hllc . add ( i ) ; } System . out . println ( hllc . getCountEstimate ( ) ) ; assertTrue ( hllc . getCountEstimate ( ) > 10 * 0.9 ) ; } @ Test public void countTest ( ) throws IOException { int n = 10 ; for ( int i = 0 ; i < 5 ; i ++ ) { count ( n ) ; n *= 10 ; } } @ Test public void mergeTest ( ) throws IOException { double error = 0 ; int n = 100 ; for ( int i = 0 ; i < n ; i += 10 ) { double e = merge ( i ) ; error += e ; } System . out . println ( ""Total average error is "" + error / n ) ; System . out . println ( ""  errorRateCount1 is "" + errorCount1 + ""!"" ) ; System . out . println ( ""  errorRateCount2 is "" + errorCount2 + ""!"" ) ; System . out . println ( ""  errorRateCount3 is "" + errorCount3 + ""!"" ) ; Assert . assertTrue ( errorCount1 <= n * 0.30 ) ; Assert . assertTrue ( errorCount2 <= n * 0.05 ) ; Assert . assertTrue ( errorCount3 <= n * 0.02 ) ; } @ Test public void compareResult ( ) throws IOException { int p = 12 ; int m = 1 < < p ; ByteBuffer buf = ByteBuffer . allocate ( 1024 * 1024 ) ; for ( int t = 0 ; t < 5 ; t ++ ) { HLLCounterOld oldCounter = new HLLCounterOld ( p ) ; HLLCounter newCounter = new HLLCounter ( p ) ; HLLCounter newCounter2 = new HLLCounter ( p ) ; int rr = rand1 . nextInt ( ) ; newCounter . add ( rr ) ; oldCounter . add ( rr ) ; assertEquals ( RegisterType . SINGLE_VALUE , newCounter . getRegisterType ( ) ) ; assertEquals ( oldCounter . getCountEstimate ( ) , newCounter . getCountEstimate ( ) ) ; buf . clear ( ) ; oldCounter . writeRegisters ( buf ) ; buf . flip ( ) ; newCounter2 . readRegisters ( buf ) ; assertEquals ( oldCounter . getCountEstimate ( ) , newCounter2 . getCountEstimate ( ) ) ; oldCounter . clear ( ) ; newCounter . clear ( ) ; newCounter2 . clear ( ) ; for ( int i = 0 ; i < 20 ; i ++ ) { int r = rand1 . nextInt ( ) ; oldCounter . add ( r ) ; newCounter . add ( r ) ; } assertEquals ( RegisterType . SPARSE , newCounter . getRegisterType ( ) ) ; assertEquals ( oldCounter . getCountEstimate ( ) , newCounter . getCountEstimate ( ) ) ; buf . clear ( ) ; oldCounter . writeRegisters ( buf ) ; buf . flip ( ) ; newCounter2 . readRegisters ( buf ) ; assertEquals ( oldCounter . getCountEstimate ( ) , newCounter2 . getCountEstimate ( ) ) ; oldCounter . clear ( ) ; newCounter . clear ( ) ; for ( int i = 0 ; i < m / 2 ; i ++ ) { int r = rand1 . nextInt ( ) ; oldCounter . add ( r ) ; newCounter . add ( r ) ; } assertEquals ( RegisterType . DENSE , newCounter . getRegisterType ( ) ) ; assertEquals ( oldCounter . getCountEstimate ( ) , newCounter . getCountEstimate ( ) ) ; buf . clear ( ) ; oldCounter . writeRegisters ( buf ) ; buf . flip ( ) ; newCounter2 . readRegisters ( buf ) ; assertEquals ( oldCounter . getCountEstimate ( ) , newCounter2 . getCountEstimate ( ) ) ; } } @ Test public void testPeekLength ( ) throws IOException { HLLCounter hllc = new HLLCounter ( 10 ) ; HLLCounter copy = new HLLCounter ( 10 ) ; byte [ ] value = new byte [ 10 ] ; for ( int i = 0 ; i < 200000 ; i ++ ) { rand1 . nextBytes ( value ) ; hllc . add ( value ) ; buf . clear ( ) ; hllc . writeRegisters ( buf ) ; int len = buf . position ( ) ; buf . position ( 0 ) ; assertEquals ( len , hllc . peekLength ( buf ) ) ; copy . readRegisters ( buf ) ; assertEquals ( len , buf . position ( ) ) ; assertEquals ( hllc , copy ) ; } buf . clear ( ) ; } @ Test public void testEquivalence ( ) { HLLCounter ha = new HLLCounter ( ) ; HLLCounter hb = new HLLCounter ( ) ; ha . add ( 1 ) ; hb . add ( 1 ) ; Assert . assertTrue ( ha . getCountEstimate ( ) == hb . getCountEstimate ( ) ) ; ha = new HLLCounter ( ) ; hb = new HLLCounter ( ) ; byte [ ] a = new byte [ ] { 0 , 3 , 4 , 42 , 2 , 2 } ; byte [ ] b = new byte [ ] { 3 , 4 , 42 } ; ha . add ( a , 1 , 3 ) ; hb . add ( b ) ; Assert . assertTrue ( ha . getCountEstimate ( ) == hb . getCountEstimate ( ) ) ; int p = 10 ; ha = new HLLCounter ( p ) ; hb = new HLLCounter ( p ) ; int m = 1 < < p ; double over = HLLCounter . OVERFLOW_FACTOR * m ; int overFlow = ( int ) over + 1000 ; for ( int i = 0 ; i < overFlow ; i ++ ) { int k = rand1 . nextInt ( ) ; ha . add ( k ) ; hb . add ( k ) ; } Assert . assertTrue ( ha . getCountEstimate ( ) == hb . getCountEstimate ( ) ) ; } @ Test public void testAutoChangeToSparse ( ) { int p = 15 ; int m = 1 < < p ; HLLCounter counter = new HLLCounter ( p ) ; assertEquals ( RegisterType . SINGLE_VALUE , counter . getRegisterType ( ) ) ; counter . add ( 1 ) ; assertEquals ( RegisterType . SINGLE_VALUE , counter . getRegisterType ( ) ) ; counter . add ( 2 ) ; assertEquals ( RegisterType . SPARSE , counter . getRegisterType ( ) ) ; double over = HLLCounter . OVERFLOW_FACTOR * m ; int overFlow = ( int ) over + 1000 ; for ( int i = 0 ; i < overFlow ; i ++ ) counter . add ( i ) ; assertEquals ( RegisterType . DENSE , counter . getRegisterType ( ) ) ; } @ Test public void testSerialilze ( ) throws Exception { int p = 15 ; int m = 1 < < p ; HLLCounter counter = new HLLCounter ( p ) ; counter . add ( 123 ) ; assertEquals ( RegisterType . SINGLE_VALUE , counter . getRegisterType ( ) ) ; checkSerialize ( counter ) ; counter . add ( 124 ) ; assertEquals ( RegisterType . SPARSE , counter . getRegisterType ( ) ) ; checkSerialize ( counter ) ; double over = HLLCounter . OVERFLOW_FACTOR * m ; int overFlow = ( int ) over + 1000 ; for ( int i = 0 ; i < overFlow ; i ++ ) counter . add ( i ) ; assertEquals ( RegisterType . DENSE , counter . getRegisterType ( ) ) ; checkSerialize ( counter ) ; } private Set < String > generateTestData ( int n ) { Set < String > testData = new HashSet < String > ( ) ; for ( int i = 0 ; i < n ; i ++ ) { String [ ] samples = generateSampleData ( ) ; for ( String sample : samples ) { testData . add ( sample ) ; } } return testData ; } private String [ ] generateSampleData ( ) { StringBuilder buf = new StringBuilder ( ) ; for ( int i = 0 ; i < 19 ; i ++ ) { buf . append ( Math . abs ( rand1 . nextInt ( ) ) % 10 ) ; } String header = buf . toString ( ) ; int size = Math . abs ( rand3 . nextInt ( ) ) % 9 + 1 ; String [ ] samples = new String [ size ] ; for ( int k = 0 ; k < size ; k ++ ) { buf = new StringBuilder ( header ) ; buf . append ( ""-"" ) ; for ( int i = 0 ; i < 10 ; i ++ ) { buf . append ( Math . abs ( rand3 . nextInt ( ) ) % 10 ) ; } samples [ k ] = buf . toString ( ) ; } return samples ; } private double merge ( int round ) throws IOException { int ln = 20 ; int dn = 100 * ( round + 1 ) ; Set < String > testSet = new HashSet < String > ( ) ; HLLCounter [ ] hllcs = new HLLCounter [ ln ] ; for ( int i = 0 ; i < ln ; i ++ ) { hllcs [ i ] = newHLLC ( ) ; for ( int k = 0 ; k < dn ; k ++ ) { String [ ] samples = generateSampleData ( ) ; for ( String data : samples ) { testSet . add ( data ) ; hllcs [ i ] . add ( Bytes . toBytes ( data ) ) ; } } } HLLCounter mergeHllc = newHLLC ( ) ; for ( HLLCounter hllc : hllcs ) { mergeHllc . merge ( hllc ) ; } double errorRate = mergeHllc . getErrorRate ( ) ; long estimate = mergeHllc . getCountEstimate ( ) ; double actualError = Math . abs ( ( double ) ( testSet . size ( ) - estimate ) / testSet . size ( ) ) ; System . out . println ( testSet . size ( ) + ""-"" + estimate + "" ~ "" + actualError ) ; Assert . assertTrue ( actualError < 0.1 ) ; if ( actualError > errorRate ) { errorCount1 ++ ; } if ( actualError > 2 * errorRate ) { errorCount2 ++ ; } if ( actualError > 3 * errorRate ) { errorCount3 ++ ; } return actualError ; } private HLLCounter newHLLC ( ) { return new HLLCounter ( 16 ) ; } private void count ( int n ) throws IOException { Set < String > testSet = generateTestData ( n ) ; HLLCounter hllc = newHLLC ( ) ; for ( String testData : testSet ) { hllc . add ( Bytes . toBytes ( testData ) ) ; } long estimate = hllc . getCountEstimate ( ) ; double errorRate = hllc . getErrorRate ( ) ; double actualError = ( double ) Math . abs ( testSet . size ( ) - estimate ) / testSet . size ( ) ; System . out . println ( estimate ) ; System . out . println ( testSet . size ( ) ) ; System . out . println ( errorRate ) ; System . out . println ( ""="" + actualError ) ; Assert . assertTrue ( actualError < errorRate * 3.0 ) ; checkSerialize ( hllc ) ; } private void checkSerialize ( HLLCounter hllc ) throws IOException { long estimate = hllc . getCountEstimate ( ) ; buf . clear ( ) ; hllc . writeRegisters ( buf ) ; buf . flip ( ) ; hllc . readRegisters ( buf ) ; Assert . assertEquals ( estimate , hllc . getCountEstimate ( ) ) ; } }",Smelly
"public class IterableUtilsTest { private Iterable < Integer > iterableA = null ; private Iterable < Long > iterableB = null ; private Iterable < Integer > emptyIterable = null ; @ Before public void setUp ( ) { final Collection < Integer > collectionA = new ArrayList < > ( ) ; collectionA . add ( 1 ) ; collectionA . add ( 2 ) ; collectionA . add ( 2 ) ; collectionA . add ( 3 ) ; collectionA . add ( 3 ) ; collectionA . add ( 3 ) ; collectionA . add ( 4 ) ; collectionA . add ( 4 ) ; collectionA . add ( 4 ) ; collectionA . add ( 4 ) ; iterableA = collectionA ; final Collection < Long > collectionB = new LinkedList < > ( ) ; collectionB . add ( 5L ) ; collectionB . add ( 4L ) ; collectionB . add ( 4L ) ; collectionB . add ( 3L ) ; collectionB . add ( 3L ) ; collectionB . add ( 3L ) ; collectionB . add ( 2L ) ; collectionB . add ( 2L ) ; collectionB . add ( 2L ) ; collectionB . add ( 2L ) ; iterableB = collectionB ; emptyIterable = Collections . emptyList ( ) ; } private static Predicate < Number > EQUALS_TWO = new Predicate < Number > ( ) { @ Override public boolean evaluate ( final Number input ) { return input . intValue ( ) == 2 ; } } ; private static Predicate < Number > EVEN = new Predicate < Number > ( ) { @ Override public boolean evaluate ( final Number input ) { return input . intValue ( ) % 2 == 0 ; } } ; @ Test public void forEach ( ) { final List < Integer > listA = new ArrayList < > ( ) ; listA . add ( 1 ) ; final List < Integer > listB = new ArrayList < > ( ) ; listB . add ( 2 ) ; final Closure < List < Integer > > testClosure = ClosureUtils . invokerClosure ( ""clear"" ) ; final Collection < List < Integer > > col = new ArrayList < > ( ) ; col . add ( listA ) ; col . add ( listB ) ; IterableUtils . forEach ( col , testClosure ) ; assertTrue ( listA . isEmpty ( ) && listB . isEmpty ( ) ) ; try { IterableUtils . forEach ( col , null ) ; fail ( ""expecting NullPointerException"" ) ; } catch ( final NullPointerException npe ) { } IterableUtils . forEach ( null , testClosure ) ; col . add ( null ) ; IterableUtils . forEach ( col , testClosure ) ; } @ Test ( expected = FunctorException . class ) public void forEachFailure ( ) { final Closure < String > testClosure = ClosureUtils . invokerClosure ( ""clear"" ) ; final Collection < String > col = new ArrayList < > ( ) ; col . add ( ""x"" ) ; IterableUtils . forEach ( col , testClosure ) ; } @ Test public void forEachButLast ( ) { final List < Integer > listA = new ArrayList < > ( ) ; listA . add ( 1 ) ; final List < Integer > listB = new ArrayList < > ( ) ; listB . add ( 2 ) ; final Closure < List < Integer > > testClosure = ClosureUtils . invokerClosure ( ""clear"" ) ; final Collection < List < Integer > > col = new ArrayList < > ( ) ; col . add ( listA ) ; col . add ( listB ) ; List < Integer > last = IterableUtils . forEachButLast ( col , testClosure ) ; assertTrue ( listA . isEmpty ( ) && ! listB . isEmpty ( ) ) ; assertSame ( listB , last ) ; try { IterableUtils . forEachButLast ( col , null ) ; fail ( ""expecting NullPointerException"" ) ; } catch ( final NullPointerException npe ) { } IterableUtils . forEachButLast ( null , testClosure ) ; col . add ( null ) ; col . add ( null ) ; last = IterableUtils . forEachButLast ( col , testClosure ) ; assertNull ( last ) ; } @ Test public void containsWithEquator ( ) { final List < String > base = new ArrayList < > ( ) ; base . add ( ""AC"" ) ; base . add ( ""BB"" ) ; base . add ( ""CA"" ) ; final Equator < String > secondLetterEquator = new Equator < String > ( ) { @ Override public boolean equate ( final String o1 , final String o2 ) { return o1 . charAt ( 1 ) == o2 . charAt ( 1 ) ; } @ Override public int hash ( final String o ) { return o . charAt ( 1 ) ; } } ; assertFalse ( base . contains ( ""CC"" ) ) ; assertTrue ( IterableUtils . contains ( base , ""AC"" , secondLetterEquator ) ) ; assertTrue ( IterableUtils . contains ( base , ""CC"" , secondLetterEquator ) ) ; assertFalse ( IterableUtils . contains ( base , ""CX"" , secondLetterEquator ) ) ; assertFalse ( IterableUtils . contains ( null , null , secondLetterEquator ) ) ; try { IterableUtils . contains ( base , ""AC"" , null ) ; fail ( ""expecting NullPointerException"" ) ; } catch ( final NullPointerException npe ) { } } @ Test public void frequency ( ) { assertEquals ( 0 , IterableUtils . frequency ( null , 1 ) ) ; assertEquals ( 1 , IterableUtils . frequency ( iterableA , 1 ) ) ; assertEquals ( 2 , IterableUtils . frequency ( iterableA , 2 ) ) ; assertEquals ( 3 , IterableUtils . frequency ( iterableA , 3 ) ) ; assertEquals ( 4 , IterableUtils . frequency ( iterableA , 4 ) ) ; assertEquals ( 0 , IterableUtils . frequency ( iterableA , 5 ) ) ; assertEquals ( 0 , IterableUtils . frequency ( iterableB , 1L ) ) ; assertEquals ( 4 , IterableUtils . frequency ( iterableB , 2L ) ) ; assertEquals ( 3 , IterableUtils . frequency ( iterableB , 3L ) ) ; assertEquals ( 2 , IterableUtils . frequency ( iterableB , 4L ) ) ; assertEquals ( 1 , IterableUtils . frequency ( iterableB , 5L ) ) ; final Iterable < Number > iterableIntAsNumber = Arrays . < Number > asList ( 1 , 2 , 3 , 4 , 5 ) ; final Iterable < Number > iterableLongAsNumber = Arrays . < Number > asList ( 1L , 2L , 3L , 4L , 5L ) ; assertEquals ( 0 , IterableUtils . frequency ( iterableIntAsNumber , 2L ) ) ; assertEquals ( 0 , IterableUtils . frequency ( iterableLongAsNumber , 2 ) ) ; final Set < String > set = new HashSet < > ( ) ; set . add ( ""A"" ) ; set . add ( ""C"" ) ; set . add ( ""E"" ) ; set . add ( ""E"" ) ; assertEquals ( 1 , IterableUtils . frequency ( set , ""A"" ) ) ; assertEquals ( 0 , IterableUtils . frequency ( set , ""B"" ) ) ; assertEquals ( 1 , IterableUtils . frequency ( set , ""C"" ) ) ; assertEquals ( 0 , IterableUtils . frequency ( set , ""D"" ) ) ; assertEquals ( 1 , IterableUtils . frequency ( set , ""E"" ) ) ; final Bag < String > bag = new HashBag < > ( ) ; bag . add ( ""A"" , 3 ) ; bag . add ( ""C"" ) ; bag . add ( ""E"" ) ; bag . add ( ""E"" ) ; assertEquals ( 3 , IterableUtils . frequency ( bag , ""A"" ) ) ; assertEquals ( 0 , IterableUtils . frequency ( bag , ""B"" ) ) ; assertEquals ( 1 , IterableUtils . frequency ( bag , ""C"" ) ) ; assertEquals ( 0 , IterableUtils . frequency ( bag , ""D"" ) ) ; assertEquals ( 2 , IterableUtils . frequency ( bag , ""E"" ) ) ; } @ Test public void frequencyOfNull ( ) { final List < String > list = new ArrayList < > ( ) ; assertEquals ( 0 , IterableUtils . frequency ( list , null ) ) ; list . add ( ""A"" ) ; assertEquals ( 0 , IterableUtils . frequency ( list , null ) ) ; list . add ( null ) ; assertEquals ( 1 , IterableUtils . frequency ( list , null ) ) ; list . add ( ""B"" ) ; assertEquals ( 1 , IterableUtils . frequency ( list , null ) ) ; list . add ( null ) ; assertEquals ( 2 , IterableUtils . frequency ( list , null ) ) ; list . add ( ""B"" ) ; assertEquals ( 2 , IterableUtils . frequency ( list , null ) ) ; list . add ( null ) ; assertEquals ( 3 , IterableUtils . frequency ( list , null ) ) ; } @ Test public void find ( ) { Predicate < Number > testPredicate = equalPredicate ( ( Number ) 4 ) ; Integer test = IterableUtils . find ( iterableA , testPredicate ) ; assertTrue ( test . equals ( 4 ) ) ; testPredicate = equalPredicate ( ( Number ) 45 ) ; test = IterableUtils . find ( iterableA , testPredicate ) ; assertTrue ( test == null ) ; assertNull ( IterableUtils . find ( null , testPredicate ) ) ; try { assertNull ( IterableUtils . find ( iterableA , null ) ) ; fail ( ""expecting NullPointerException"" ) ; } catch ( final NullPointerException npe ) { } } @ Test public void indexOf ( ) { Predicate < Number > testPredicate = equalPredicate ( ( Number ) 4 ) ; int index = IterableUtils . indexOf ( iterableA , testPredicate ) ; assertEquals ( 6 , index ) ; testPredicate = equalPredicate ( ( Number ) 45 ) ; index = IterableUtils . indexOf ( iterableA , testPredicate ) ; assertEquals ( - 1 , index ) ; assertEquals ( - 1 , IterableUtils . indexOf ( null , testPredicate ) ) ; try { IterableUtils . indexOf ( iterableA , null ) ; fail ( ""expecting NullPointerException"" ) ; } catch ( final NullPointerException npe ) { } } @ Test public void countMatches ( ) { assertEquals ( 4 , IterableUtils . countMatches ( iterableB , EQUALS_TWO ) ) ; assertEquals ( 0 , IterableUtils . countMatches ( null , EQUALS_TWO ) ) ; try { assertEquals ( 0 , IterableUtils . countMatches ( iterableA , null ) ) ; fail ( ""predicate must not be null"" ) ; } catch ( final NullPointerException ex ) { } try { assertEquals ( 0 , IterableUtils . countMatches ( null , null ) ) ; fail ( ""predicate must not be null"" ) ; } catch ( final NullPointerException ex ) { } } @ Test public void matchesAny ( ) { final List < Integer > list = new ArrayList < > ( ) ; try { assertFalse ( IterableUtils . matchesAny ( null , null ) ) ; fail ( ""predicate must not be null"" ) ; } catch ( final NullPointerException ex ) { } try { assertFalse ( IterableUtils . matchesAny ( list , null ) ) ; fail ( ""predicate must not be null"" ) ; } catch ( final NullPointerException ex ) { } assertFalse ( IterableUtils . matchesAny ( null , EQUALS_TWO ) ) ; assertFalse ( IterableUtils . matchesAny ( list , EQUALS_TWO ) ) ; list . add ( 1 ) ; list . add ( 3 ) ; list . add ( 4 ) ; assertFalse ( IterableUtils . matchesAny ( list , EQUALS_TWO ) ) ; list . add ( 2 ) ; assertEquals ( true , IterableUtils . matchesAny ( list , EQUALS_TWO ) ) ; } @ Test public void matchesAll ( ) { try { assertFalse ( IterableUtils . matchesAll ( null , null ) ) ; fail ( ""predicate must not be null"" ) ; } catch ( final NullPointerException ex ) { } try { assertFalse ( IterableUtils . matchesAll ( iterableA , null ) ) ; fail ( ""predicate must not be null"" ) ; } catch ( final NullPointerException ex ) { } final Predicate < Integer > lessThanFive = new Predicate < Integer > ( ) { @ Override public boolean evaluate ( final Integer object ) { return object < 5 ; } } ; assertTrue ( IterableUtils . matchesAll ( iterableA , lessThanFive ) ) ; final Predicate < Integer > lessThanFour = new Predicate < Integer > ( ) { @ Override public boolean evaluate ( final Integer object ) { return object < 4 ; } } ; assertFalse ( IterableUtils . matchesAll ( iterableA , lessThanFour ) ) ; assertTrue ( IterableUtils . matchesAll ( null , lessThanFour ) ) ; assertTrue ( IterableUtils . matchesAll ( emptyIterable , lessThanFour ) ) ; } public void getFromIterable ( ) throws Exception { final Bag < String > bag = new HashBag < > ( ) ; bag . add ( ""element"" , 1 ) ; assertEquals ( ""element"" , IterableUtils . get ( bag , 0 ) ) ; } @ Test ( expected = IndexOutOfBoundsException . class ) public void getFromIterableIndexOutOfBoundsException ( ) throws Exception { final Bag < String > bag = new HashBag < > ( ) ; bag . add ( ""element"" , 1 ) ; IterableUtils . get ( bag , 1 ) ; } public void firstFromIterable ( ) throws Exception { final Bag < String > bag = new HashBag < > ( ) ; bag . add ( ""element"" , 1 ) ; assertEquals ( ""element"" , IterableUtils . first ( bag ) ) ; } @ Test ( expected = IndexOutOfBoundsException . class ) public void firstFromIterableIndexOutOfBoundsException ( ) throws Exception { final Bag < String > bag = new HashBag < > ( ) ; IterableUtils . first ( bag ) ; } @ SuppressWarnings ( ""unchecked"" ) @ Test public void partition ( ) { final List < Integer > input = new ArrayList < > ( ) ; input . add ( 1 ) ; input . add ( 2 ) ; input . add ( 3 ) ; input . add ( 4 ) ; List < List < Integer > > partitions = IterableUtils . partition ( input , EQUALS_TWO ) ; assertEquals ( 2 , partitions . size ( ) ) ; Collection < Integer > partition = partitions . get ( 0 ) ; assertEquals ( 1 , partition . size ( ) ) ; assertEquals ( 2 , CollectionUtils . extractSingleton ( partition ) . intValue ( ) ) ; final Integer [ ] expected = { 1 , 3 , 4 } ; partition = partitions . get ( 1 ) ; Assert . assertArrayEquals ( expected , partition . toArray ( ) ) ; partitions = IterableUtils . partition ( ( List < Integer > ) null , EQUALS_TWO ) ; assertEquals ( 2 , partitions . size ( ) ) ; assertTrue ( partitions . get ( 0 ) . isEmpty ( ) ) ; assertTrue ( partitions . get ( 1 ) . isEmpty ( ) ) ; partitions = IterableUtils . partition ( input ) ; assertEquals ( 1 , partitions . size ( ) ) ; assertEquals ( input , partitions . get ( 0 ) ) ; try { IterableUtils . partition ( input , ( Predicate < Integer > ) null ) ; fail ( ""expecting NullPointerException"" ) ; } catch ( final NullPointerException npe ) { } } @ SuppressWarnings ( ""unchecked"" ) @ Test public void partitionMultiplePredicates ( ) { final List < Integer > input = new ArrayList < > ( ) ; input . add ( 1 ) ; input . add ( 2 ) ; input . add ( 3 ) ; input . add ( 4 ) ; final List < List < Integer > > partitions = IterableUtils . partition ( input , EQUALS_TWO , EVEN ) ; Collection < Integer > partition = partitions . get ( 0 ) ; assertEquals ( 1 , partition . size ( ) ) ; assertEquals ( 2 , partition . iterator ( ) . next ( ) . intValue ( ) ) ; partition = partitions . get ( 1 ) ; assertEquals ( 1 , partition . size ( ) ) ; assertEquals ( 4 , partition . iterator ( ) . next ( ) . intValue ( ) ) ; final Integer [ ] expected = { 1 , 3 } ; partition = partitions . get ( 2 ) ; Assert . assertArrayEquals ( expected , partition . toArray ( ) ) ; try { IterableUtils . partition ( input , EQUALS_TWO , null ) ; } catch ( final NullPointerException npe ) { } } @ Test public void testToString ( ) { String result = IterableUtils . toString ( iterableA ) ; assertEquals ( ""[1, 2, 2, 3, 3, 3, 4, 4, 4, 4]"" , result ) ; result = IterableUtils . toString ( new ArrayList < Integer > ( ) ) ; assertEquals ( ""[]"" , result ) ; result = IterableUtils . toString ( null ) ; assertEquals ( ""[]"" , result ) ; result = IterableUtils . toString ( iterableA , new Transformer < Integer , String > ( ) { @ Override public String transform ( final Integer input ) { return new Integer ( input * 2 ) . toString ( ) ; } } ) ; assertEquals ( ""[2, 4, 4, 6, 6, 6, 8, 8, 8, 8]"" , result ) ; result = IterableUtils . toString ( new ArrayList < Integer > ( ) , new Transformer < Integer , String > ( ) { @ Override public String transform ( final Integer input ) { fail ( ""not supposed to reach here"" ) ; return """" ; } } ) ; assertEquals ( ""[]"" , result ) ; result = IterableUtils . toString ( null , new Transformer < Integer , String > ( ) { @ Override public String transform ( final Integer input ) { fail ( ""not supposed to reach here"" ) ; return """" ; } } ) ; assertEquals ( ""[]"" , result ) ; } @ Test public void testToStringDelimiter ( ) { final Transformer < Integer , String > transformer = new Transformer < Integer , String > ( ) { @ Override public String transform ( final Integer input ) { return new Integer ( input * 2 ) . toString ( ) ; } } ; String result = IterableUtils . toString ( iterableA , transformer , """" , """" , """" ) ; assertEquals ( ""2446668888"" , result ) ; result = IterableUtils . toString ( iterableA , transformer , "","" , """" , """" ) ; assertEquals ( ""2,4,4,6,6,6,8,8,8,8"" , result ) ; result = IterableUtils . toString ( iterableA , transformer , """" , ""["" , ""]"" ) ; assertEquals ( ""[2446668888]"" , result ) ; result = IterableUtils . toString ( iterableA , transformer , "","" , ""["" , ""]"" ) ; assertEquals ( ""[2,4,4,6,6,6,8,8,8,8]"" , result ) ; result = IterableUtils . toString ( iterableA , transformer , "","" , ""[["" , ""]]"" ) ; assertEquals ( ""[[2,4,4,6,6,6,8,8,8,8]]"" , result ) ; result = IterableUtils . toString ( iterableA , transformer , "",,"" , ""["" , ""]"" ) ; assertEquals ( ""[2,,4,,4,,6,,6,,6,,8,,8,,8,,8]"" , result ) ; result = IterableUtils . toString ( iterableA , transformer , "",,"" , ""(("" , ""))"" ) ; assertEquals ( ""((2,,4,,4,,6,,6,,6,,8,,8,,8,,8))"" , result ) ; result = IterableUtils . toString ( new ArrayList < Integer > ( ) , transformer , """" , ""("" , "")"" ) ; assertEquals ( ""()"" , result ) ; result = IterableUtils . toString ( new ArrayList < Integer > ( ) , transformer , """" , """" , """" ) ; assertEquals ( """" , result ) ; } @ Test public void testToStringWithNullArguments ( ) { final String result = IterableUtils . toString ( null , new Transformer < Integer , String > ( ) { @ Override public String transform ( final Integer input ) { fail ( ""not supposed to reach here"" ) ; return """" ; } } , """" , ""("" , "")"" ) ; assertEquals ( ""()"" , result ) ; try { IterableUtils . toString ( new ArrayList < Integer > ( ) , null , """" , ""("" , "")"" ) ; fail ( ""expecting NullPointerException"" ) ; } catch ( final NullPointerException ex ) { } try { IterableUtils . toString ( new ArrayList < Integer > ( ) , new Transformer < Integer , String > ( ) { @ Override public String transform ( final Integer input ) { fail ( ""not supposed to reach here"" ) ; return """" ; } } , null , ""("" , "")"" ) ; fail ( ""expecting NullPointerException"" ) ; } catch ( final NullPointerException ex ) { } try { IterableUtils . toString ( new ArrayList < Integer > ( ) , new Transformer < Integer , String > ( ) { @ Override public String transform ( final Integer input ) { fail ( ""not supposed to reach here"" ) ; return """" ; } } , """" , null , "")"" ) ; fail ( ""expecting NullPointerException"" ) ; } catch ( final NullPointerException ex ) { } try { IterableUtils . toString ( new ArrayList < Integer > ( ) , new Transformer < Integer , String > ( ) { @ Override public String transform ( final Integer input ) { fail ( ""not supposed to reach here"" ) ; return """" ; } } , """" , ""("" , null ) ; fail ( ""expecting NullPointerException"" ) ; } catch ( final NullPointerException ex ) { } } }",Smelly
"public class TypeEditorTest { @ Test public void ignoreHidden ( ) throws CommitFailedException { EditorHook hook = new EditorHook ( new TypeEditorProvider ( ) ) ; NodeState root = new InitialContent ( ) . initialize ( EMPTY_NODE ) ; NodeBuilder builder = root . builder ( ) ; NodeState before = builder . getNodeState ( ) ; builder . child ( "":hidden"" ) ; NodeState after = builder . getNodeState ( ) ; hook . processCommit ( before , after ) ; before = after ; builder . child ( "":hidden"" ) . setProperty ( ""prop"" , ""value"" ) ; after = builder . getNodeState ( ) ; hook . processCommit ( before , after ) ; before = after ; builder . removeChildNode ( "":hidden"" ) ; after = builder . getNodeState ( ) ; hook . processCommit ( before , after ) ; } @ Test public void removeNonMandatoryProperty ( ) throws CommitFailedException { EffectiveType effective = createControl ( ) . createMock ( EffectiveType . class ) ; expect ( effective . isMandatoryProperty ( ""mandatory"" ) ) . andReturn ( false ) ; replay ( effective ) ; TypeEditor editor = new TypeEditor ( effective ) ; editor . propertyDeleted ( PropertyStates . createProperty ( ""mandatory"" , """" ) ) ; } @ Test ( expected = CommitFailedException . class ) public void removeMandatoryProperty ( ) throws CommitFailedException { EffectiveType effective = createControl ( ) . createMock ( EffectiveType . class ) ; expect ( effective . isMandatoryProperty ( ""mandatory"" ) ) . andReturn ( true ) ; expect ( effective . constraintViolation ( 22 , ""/"" , ""Mandatory property mandatory can not be removed"" ) ) . andReturn ( new CommitFailedException ( """" , 0 , """" ) ) ; replay ( effective ) ; TypeEditor editor = new TypeEditor ( effective ) ; editor . propertyDeleted ( PropertyStates . createProperty ( ""mandatory"" , """" ) ) ; } @ Test public void removeNonMandatoryChildNode ( ) throws CommitFailedException { EffectiveType effective = createControl ( ) . createMock ( EffectiveType . class ) ; expect ( effective . isMandatoryChildNode ( ""mandatory"" ) ) . andReturn ( false ) ; replay ( effective ) ; TypeEditor editor = new TypeEditor ( effective ) ; editor . childNodeDeleted ( ""mandatory"" , EMPTY_NODE ) ; } @ Test ( expected = CommitFailedException . class ) public void removeMandatoryChildNode ( ) throws CommitFailedException { EffectiveType effective = createControl ( ) . createMock ( EffectiveType . class ) ; expect ( effective . isMandatoryChildNode ( ""mandatory"" ) ) . andReturn ( true ) ; expect ( effective . constraintViolation ( 26 , ""/"" , ""Mandatory child node mandatory can not be removed"" ) ) . andReturn ( new CommitFailedException ( """" , 0 , """" ) ) ; replay ( effective ) ; TypeEditor editor = new TypeEditor ( effective ) ; editor . childNodeDeleted ( ""mandatory"" , EMPTY_NODE ) ; } }",No
"@ RunWith ( Parameterized . class ) @ Category ( { ClientTests . class , MediumTests . class } ) public class TestAsyncQuotaAdminApi extends TestAsyncAdminBase { @ ClassRule public static final HBaseClassTestRule CLASS_RULE = HBaseClassTestRule . forClass ( TestAsyncQuotaAdminApi . class ) ; @ BeforeClass public static void setUpBeforeClass ( ) throws Exception { TEST_UTIL . getConfiguration ( ) . setBoolean ( QuotaUtil . QUOTA_CONF_KEY , true ) ; TEST_UTIL . getConfiguration ( ) . setInt ( QuotaCache . REFRESH_CONF_KEY , 2000 ) ; TEST_UTIL . getConfiguration ( ) . setInt ( HConstants . HBASE_RPC_TIMEOUT_KEY , 60000 ) ; TEST_UTIL . getConfiguration ( ) . setInt ( HConstants . HBASE_CLIENT_OPERATION_TIMEOUT , 120000 ) ; TEST_UTIL . getConfiguration ( ) . setInt ( HConstants . HBASE_CLIENT_RETRIES_NUMBER , 2 ) ; TEST_UTIL . getConfiguration ( ) . setInt ( START_LOG_ERRORS_AFTER_COUNT_KEY , 0 ) ; TEST_UTIL . startMiniCluster ( 1 ) ; TEST_UTIL . waitTableAvailable ( QuotaTableUtil . QUOTA_TABLE_NAME ) ; ASYNC_CONN = ConnectionFactory . createAsyncConnection ( TEST_UTIL . getConfiguration ( ) ) . get ( ) ; } @ Test public void testThrottleType ( ) throws Exception { String userName = User . getCurrent ( ) . getShortName ( ) ; admin . setQuota ( QuotaSettingsFactory . throttleUser ( userName , ThrottleType . READ_NUMBER , 6 , TimeUnit . MINUTES ) ) . get ( ) ; admin . setQuota ( QuotaSettingsFactory . throttleUser ( userName , ThrottleType . WRITE_NUMBER , 12 , TimeUnit . MINUTES ) ) . get ( ) ; admin . setQuota ( QuotaSettingsFactory . bypassGlobals ( userName , true ) ) . get ( ) ; int countThrottle = 0 ; int countGlobalBypass = 0 ; for ( QuotaSettings settings : admin . getQuota ( null ) . get ( ) ) { switch ( settings . getQuotaType ( ) ) { case THROTTLE : countThrottle ++ ; break ; case GLOBAL_BYPASS : countGlobalBypass ++ ; break ; default : fail ( ""unexpected settings type: "" + settings . getQuotaType ( ) ) ; } } assertEquals ( 2 , countThrottle ) ; assertEquals ( 1 , countGlobalBypass ) ; admin . setQuota ( QuotaSettingsFactory . unthrottleUser ( userName ) ) . get ( ) ; assertNumResults ( 1 , null ) ; admin . setQuota ( QuotaSettingsFactory . bypassGlobals ( userName , false ) ) . get ( ) ; assertNumResults ( 0 , null ) ; } @ Test public void testQuotaRetrieverFilter ( ) throws Exception { TableName [ ] tables = new TableName [ ] { TableName . valueOf ( ""T0"" ) , TableName . valueOf ( ""T01"" ) , TableName . valueOf ( ""NS0:T2"" ) , } ; String [ ] namespaces = new String [ ] { ""NS0"" , ""NS01"" , ""NS2"" } ; String [ ] users = new String [ ] { ""User0"" , ""User01"" , ""User2"" } ; for ( String user : users ) { admin . setQuota ( QuotaSettingsFactory . throttleUser ( user , ThrottleType . REQUEST_NUMBER , 1 , TimeUnit . MINUTES ) ) . get ( ) ; for ( TableName table : tables ) { admin . setQuota ( QuotaSettingsFactory . throttleUser ( user , table , ThrottleType . REQUEST_NUMBER , 2 , TimeUnit . MINUTES ) ) . get ( ) ; } for ( String ns : namespaces ) { admin . setQuota ( QuotaSettingsFactory . throttleUser ( user , ns , ThrottleType . REQUEST_NUMBER , 3 , TimeUnit . MINUTES ) ) . get ( ) ; } } assertNumResults ( 21 , null ) ; for ( TableName table : tables ) { admin . setQuota ( QuotaSettingsFactory . throttleTable ( table , ThrottleType . REQUEST_NUMBER , 4 , TimeUnit . MINUTES ) ) . get ( ) ; } assertNumResults ( 24 , null ) ; for ( String ns : namespaces ) { admin . setQuota ( QuotaSettingsFactory . throttleNamespace ( ns , ThrottleType . REQUEST_NUMBER , 5 , TimeUnit . MINUTES ) ) . get ( ) ; } assertNumResults ( 27 , null ) ; assertNumResults ( 7 , new QuotaFilter ( ) . setUserFilter ( ""User0"" ) ) ; assertNumResults ( 0 , new QuotaFilter ( ) . setUserFilter ( ""User"" ) ) ; assertNumResults ( 21 , new QuotaFilter ( ) . setUserFilter ( ""User.*"" ) ) ; assertNumResults ( 3 , new QuotaFilter ( ) . setUserFilter ( ""User.*"" ) . setTableFilter ( ""T0"" ) ) ; assertNumResults ( 3 , new QuotaFilter ( ) . setUserFilter ( ""User.*"" ) . setTableFilter ( ""NS.*"" ) ) ; assertNumResults ( 0 , new QuotaFilter ( ) . setUserFilter ( ""User.*"" ) . setTableFilter ( ""T"" ) ) ; assertNumResults ( 6 , new QuotaFilter ( ) . setUserFilter ( ""User.*"" ) . setTableFilter ( ""T.*"" ) ) ; assertNumResults ( 3 , new QuotaFilter ( ) . setUserFilter ( ""User.*"" ) . setNamespaceFilter ( ""NS0"" ) ) ; assertNumResults ( 0 , new QuotaFilter ( ) . setUserFilter ( ""User.*"" ) . setNamespaceFilter ( ""NS"" ) ) ; assertNumResults ( 9 , new QuotaFilter ( ) . setUserFilter ( ""User.*"" ) . setNamespaceFilter ( ""NS.*"" ) ) ; assertNumResults ( 6 , new QuotaFilter ( ) . setUserFilter ( ""User.*"" ) . setTableFilter ( ""T0"" ) . setNamespaceFilter ( ""NS0"" ) ) ; assertNumResults ( 1 , new QuotaFilter ( ) . setTableFilter ( ""T0"" ) ) ; assertNumResults ( 0 , new QuotaFilter ( ) . setTableFilter ( ""T"" ) ) ; assertNumResults ( 2 , new QuotaFilter ( ) . setTableFilter ( ""T.*"" ) ) ; assertNumResults ( 3 , new QuotaFilter ( ) . setTableFilter ( "".*T.*"" ) ) ; assertNumResults ( 1 , new QuotaFilter ( ) . setNamespaceFilter ( ""NS0"" ) ) ; assertNumResults ( 0 , new QuotaFilter ( ) . setNamespaceFilter ( ""NS"" ) ) ; assertNumResults ( 3 , new QuotaFilter ( ) . setNamespaceFilter ( ""NS.*"" ) ) ; for ( String user : users ) { admin . setQuota ( QuotaSettingsFactory . unthrottleUser ( user ) ) . get ( ) ; for ( TableName table : tables ) { admin . setQuota ( QuotaSettingsFactory . unthrottleUser ( user , table ) ) . get ( ) ; } for ( String ns : namespaces ) { admin . setQuota ( QuotaSettingsFactory . unthrottleUser ( user , ns ) ) . get ( ) ; } } assertNumResults ( 6 , null ) ; for ( TableName table : tables ) { admin . setQuota ( QuotaSettingsFactory . unthrottleTable ( table ) ) . get ( ) ; } assertNumResults ( 3 , null ) ; for ( String ns : namespaces ) { admin . setQuota ( QuotaSettingsFactory . unthrottleNamespace ( ns ) ) . get ( ) ; } assertNumResults ( 0 , null ) ; } private void assertNumResults ( int expected , final QuotaFilter filter ) throws Exception { assertEquals ( expected , countResults ( filter ) ) ; } private int countResults ( final QuotaFilter filter ) throws Exception { int count = 0 ; for ( QuotaSettings settings : admin . getQuota ( filter ) . get ( ) ) { LOG . debug ( Objects . toString ( settings ) ) ; count ++ ; } return count ; } }",No
