{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "from prompter.random_prompter import RandomPrompter\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.metrics import matthews_corrcoef, roc_auc_score\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "cort_feature_envy_train_df = pd.read_csv('CoRT/Data Class/dataclass_df_train.csv')\n",
    "cort_feature_envy_test_df = pd.read_csv('CoRT/Data Class/dataclass_df_test.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Code</th>\n",
       "      <th>Smelly</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>875</th>\n",
       "      <td>public class JmsMessage { private Map &lt; String...</td>\n",
       "      <td>Smelly</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                  Code  Smelly\n",
       "875  public class JmsMessage { private Map < String...  Smelly"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cort_feature_envy_train_df.sample()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Rename Code column to Text\n",
    "\n",
    "cort_feature_envy_train_df.rename(columns = {'Code':'text'}, inplace = True)\n",
    "cort_feature_envy_test_df.rename(columns = {'Code':'text'}, inplace = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "from openai import OpenAI\n",
    "client = OpenAI()\n",
    "from time import sleep\n",
    "\n",
    "def get_gpt_completion(prompt):\n",
    "    sleep(1)\n",
    "    response = client.chat.completions.create(\n",
    "            model=\"gpt-4o-mini\",\n",
    "            messages=[\n",
    "                {\n",
    "                \"role\": \"system\",\n",
    "                \"content\": [\n",
    "                    {\n",
    "                    \"type\": \"text\",\n",
    "                    \"text\": \"Only give one best answer without any explanation. The answer should be form the choices given only.\"\n",
    "                    }\n",
    "                ]\n",
    "                },\n",
    "                {\n",
    "                \"role\": \"user\",\n",
    "                \"content\": [\n",
    "                    {\n",
    "                    \"type\": \"text\",\n",
    "                    \"text\":  prompt\n",
    "                    }\n",
    "                ]\n",
    "                }\n",
    "            ],\n",
    "            temperature=1,\n",
    "            max_tokens=2048,\n",
    "            top_p=1,\n",
    "            frequency_penalty=0,\n",
    "            presence_penalty=0,\n",
    "            response_format={\n",
    "                \"type\": \"text\"\n",
    "            }\n",
    ")\n",
    "\n",
    "    return response.choices[0].message.content"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "prompt = \"In terms of Data Class Smell, the following method can be classified as Smelly if it contains Data Class or No if it does not contain the smell. Only answer with the word Smelly or the word No.\\nThe code sample:{{INPUT}}\\nThe best classified as: {{TARGET}}\"\n",
    "\n",
    "random_prompter = RandomPrompter(prompt, get_completion=get_gpt_completion)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "random_prompter.fit(X=cort_feature_envy_train_df['text'], y=cort_feature_envy_train_df['Smelly'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Predicting classes for the test set...\n",
      "[=====================] 99% sample 299 / 300 Done predicting classes for the test set, you can call evaluate method to get the results\n"
     ]
    }
   ],
   "source": [
    "random_prompter.test(X_test=cort_feature_envy_test_df['text'], y_test=cort_feature_envy_test_df['Smelly'], n_shots=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "          No       0.95      0.23      0.37       150\n",
      "      Smelly       0.56      0.99      0.72       150\n",
      "\n",
      "    accuracy                           0.61       300\n",
      "   macro avg       0.75      0.61      0.55       300\n",
      "weighted avg       0.75      0.61      0.55       300\n",
      "\n"
     ]
    }
   ],
   "source": [
    "random_prompter.evaluate()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Matthews Correlation Coefficient (MCC): 0.3345301024974126\n"
     ]
    }
   ],
   "source": [
    "y_true =  random_prompter.test_df[\"class\"]\n",
    "y_pred =  random_prompter.test_df[\"preds\"]\n",
    "mcc = matthews_corrcoef(y_true, y_pred)\n",
    "print(f\"Matthews Correlation Coefficient (MCC): {mcc}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Predicting classes for the test set...\n",
      "[============        ] 55% sample 165 / 300 Error in completion for sample  165\n",
      "Error code: 429 - {'error': {'message': 'Request too large for gpt-4o-mini in organization org-ytVeK9xpa0LZyo8tAQgvK6UR on tokens per min (TPM): Limit 200000, Requested 737793. The input or output tokens must be reduced in order to run successfully. Visit https://platform.openai.com/account/rate-limits to learn more.', 'type': 'tokens', 'param': None, 'code': 'rate_limit_exceeded'}}\n",
      "[=====================] 99% sample 299 / 300 Done predicting classes for the test set, you can call evaluate method to get the results\n"
     ]
    }
   ],
   "source": [
    "random_prompter.test(X_test=cort_feature_envy_test_df['text'], y_test=cort_feature_envy_test_df['Smelly'], n_shots=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "random_prompter.flush_blocked()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "          No       0.71      0.53      0.60       150\n",
      "      Smelly       0.62      0.78      0.69       150\n",
      "\n",
      "    accuracy                           0.65       300\n",
      "   macro avg       0.66      0.65      0.65       300\n",
      "weighted avg       0.66      0.65      0.65       300\n",
      "\n"
     ]
    }
   ],
   "source": [
    "random_prompter.evaluate()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_true =  random_prompter.test_df[\"class\"]\n",
    "y_pred =  random_prompter.test_df[\"preds\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Matthews Correlation Coefficient (MCC): 0.3170077616914835\n"
     ]
    }
   ],
   "source": [
    "mcc = matthews_corrcoef(y_true, y_pred)\n",
    "print(f\"Matthews Correlation Coefficient (MCC): {mcc}\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Predicting classes for the test set...\n",
      "[=========           ] 45% sample 135 / 300 Error in completion for sample  135\n",
      "Error code: 429 - {'error': {'message': 'Request too large for gpt-4o-mini in organization org-ytVeK9xpa0LZyo8tAQgvK6UR on tokens per min (TPM): Limit 200000, Requested 705872. The input or output tokens must be reduced in order to run successfully. Visit https://platform.openai.com/account/rate-limits to learn more.', 'type': 'tokens', 'param': None, 'code': 'rate_limit_exceeded'}}\n",
      "[=============       ] 63% sample 189 / 300 Error in completion for sample  189\n",
      "Error code: 429 - {'error': {'message': 'Request too large for gpt-4o-mini in organization org-ytVeK9xpa0LZyo8tAQgvK6UR on tokens per min (TPM): Limit 200000, Requested 1180752. The input or output tokens must be reduced in order to run successfully. Visit https://platform.openai.com/account/rate-limits to learn more.', 'type': 'tokens', 'param': None, 'code': 'rate_limit_exceeded'}}\n",
      "[===============     ] 70% sample 212 / 300 Error in completion for sample  212\n",
      "Error code: 400 - {'error': {'message': \"This model's maximum context length is 128000 tokens. However, your messages resulted in 209533 tokens. Please reduce the length of the messages.\", 'type': 'invalid_request_error', 'param': 'messages', 'code': 'context_length_exceeded'}}\n",
      "[=====================] 99% sample 299 / 300 Done predicting classes for the test set, you can call evaluate method to get the results\n"
     ]
    }
   ],
   "source": [
    "random_prompter.test(X_test=cort_feature_envy_test_df['text'], y_test=cort_feature_envy_test_df['Smelly'], n_shots=3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "          No       0.75      0.51      0.61       150\n",
      "      Smelly       0.63      0.83      0.72       150\n",
      "\n",
      "    accuracy                           0.67       300\n",
      "   macro avg       0.69      0.67      0.66       300\n",
      "weighted avg       0.69      0.67      0.66       300\n",
      "\n"
     ]
    }
   ],
   "source": [
    "random_prompter.flush_blocked()\n",
    "random_prompter.evaluate()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Matthews Correlation Coefficient (MCC): 0.3597352128363246\n"
     ]
    }
   ],
   "source": [
    "y_true =  random_prompter.test_df[\"class\"]\n",
    "y_pred =  random_prompter.test_df[\"preds\"]\n",
    "mcc = matthews_corrcoef(y_true, y_pred)\n",
    "print(f\"Matthews Correlation Coefficient (MCC): {mcc}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Predicting classes for the test set...\n",
      "[=                   ] 4% sample 13 / 300 Error in completion for sample  13\n",
      "Error code: 429 - {'error': {'message': 'Request too large for gpt-4o-mini in organization org-ytVeK9xpa0LZyo8tAQgvK6UR on tokens per min (TPM): Limit 200000, Requested 706369. The input or output tokens must be reduced in order to run successfully. Visit https://platform.openai.com/account/rate-limits to learn more.', 'type': 'tokens', 'param': None, 'code': 'rate_limit_exceeded'}}\n",
      "[===                 ] 16% sample 49 / 300 Error in completion for sample  49\n",
      "Error code: 429 - {'error': {'message': 'Request too large for gpt-4o-mini in organization org-ytVeK9xpa0LZyo8tAQgvK6UR on tokens per min (TPM): Limit 200000, Requested 301937. The input or output tokens must be reduced in order to run successfully. Visit https://platform.openai.com/account/rate-limits to learn more.', 'type': 'tokens', 'param': None, 'code': 'rate_limit_exceeded'}}\n",
      "[========            ] 38% sample 114 / 300 Error in completion for sample  114\n",
      "Error code: 429 - {'error': {'message': 'Request too large for gpt-4o-mini in organization org-ytVeK9xpa0LZyo8tAQgvK6UR on tokens per min (TPM): Limit 200000, Requested 737520. The input or output tokens must be reduced in order to run successfully. Visit https://platform.openai.com/account/rate-limits to learn more.', 'type': 'tokens', 'param': None, 'code': 'rate_limit_exceeded'}}\n",
      "[===========         ] 54% sample 162 / 300 Error in completion for sample  162\n",
      "Error code: 429 - {'error': {'message': 'Request too large for gpt-4o-mini in organization org-ytVeK9xpa0LZyo8tAQgvK6UR on tokens per min (TPM): Limit 200000, Requested 741340. The input or output tokens must be reduced in order to run successfully. Visit https://platform.openai.com/account/rate-limits to learn more.', 'type': 'tokens', 'param': None, 'code': 'rate_limit_exceeded'}}\n",
      "[============        ] 56% sample 170 / 300 Error in completion for sample  170\n",
      "Error code: 429 - {'error': {'message': 'Request too large for gpt-4o-mini in organization org-ytVeK9xpa0LZyo8tAQgvK6UR on tokens per min (TPM): Limit 200000, Requested 710532. The input or output tokens must be reduced in order to run successfully. Visit https://platform.openai.com/account/rate-limits to learn more.', 'type': 'tokens', 'param': None, 'code': 'rate_limit_exceeded'}}\n",
      "[================    ] 78% sample 234 / 300 Error in completion for sample  234\n",
      "Error code: 429 - {'error': {'message': 'Request too large for gpt-4o-mini in organization org-ytVeK9xpa0LZyo8tAQgvK6UR on tokens per min (TPM): Limit 200000, Requested 712500. The input or output tokens must be reduced in order to run successfully. Visit https://platform.openai.com/account/rate-limits to learn more.', 'type': 'tokens', 'param': None, 'code': 'rate_limit_exceeded'}}\n",
      "[=====================] 99% sample 299 / 300 Done predicting classes for the test set, you can call evaluate method to get the results\n"
     ]
    }
   ],
   "source": [
    "random_prompter.test(X_test=cort_feature_envy_test_df['text'], y_test=cort_feature_envy_test_df['Smelly'], n_shots=5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "          No       0.84      0.43      0.57       150\n",
      "      Smelly       0.62      0.92      0.74       150\n",
      "\n",
      "    accuracy                           0.67       300\n",
      "   macro avg       0.73      0.67      0.65       300\n",
      "weighted avg       0.73      0.67      0.65       300\n",
      "\n"
     ]
    }
   ],
   "source": [
    "random_prompter.flush_blocked()\n",
    "\n",
    "random_prompter.evaluate()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Matthews Correlation Coefficient (MCC): 0.45123330008773854\n"
     ]
    }
   ],
   "source": [
    "y_true =  random_prompter.test_df[\"class\"]\n",
    "y_pred =  random_prompter.test_df[\"preds\"]\n",
    "mcc = matthews_corrcoef(y_true, y_pred)\n",
    "print(f\"Matthews Correlation Coefficient (MCC): {mcc}\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
